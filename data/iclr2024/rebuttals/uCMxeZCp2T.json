[
    {
        "title": "Nature-Inspired Local Propagation"
    },
    {
        "review": {
            "id": "MOceSRS01T",
            "forum": "uCMxeZCp2T",
            "replyto": "uCMxeZCp2T",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8273/Reviewer_xnxp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8273/Reviewer_xnxp"
            ],
            "content": {
                "summary": {
                    "value": "Summary:\n\nThe authors propose a framework that processes information online in a local spatiotemporal manner, motivated by biologically plausible learning schemes. They formulates continuous-time learning as an optimal control problem, connecting learning dynamics to Hamiltonian equations. They additionally show how taking the limit as propagation speed goes to infinity recovers backpropagation, suggesting backprop may emerge from local learning rules.  Ultimately, their framework requires solving Hamiltonian equations with boundary conditions, but the authors propose approximating the solution using only initial conditions via time reversal techniques."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Originality:\n\nThe authors present a novel perspective on learning by formulating it in the language of optimal control and Hamiltonian dynamics.  Using this language to connect backprop to local learning rules is, to my knowledge, novel.\n\nQuality:\n\nThe paper seems theoretically grounded, with detailed mathematical derivations connecting backpropagation in simple neural networks to hamiltonian dynamics.\n\nClarity:\n\nThe paper is reasonably well structured and explains concepts like Hamiltonian equations and optimal control accessibly. I appreciated the numerous examples, and toy experiments.  The authors are likewise honest about the theoretical nature of the work.\n\nSignificance:\n\nIf validated, demonstrating backpropagation emerging from local learning would be quite significant."
                },
                "weaknesses": {
                    "value": "It's very difficult to ascertain the significance of this work without further empirical validation.  I'd greatly encourage the authors to continue this line of work, and further to validate it on more mature learning problems.  I found the theoretical discussions to be somewhat tortuous, and the applicability of the method to be unclear.  The authors might try dramatically simplifying their presentation to make the thread between backpropagation and hamiltonian dynamics as clean as possible, and develop more experiments detailing the tradeoffs that the local learning rule implied by their work buys them."
                },
                "questions": {
                    "value": "Could the authors describe how their local learning rule relates to BPTT in more detail?\n\nCould the authors comment on the difficulty of applying their method to a more mature sequence learning problem, using, e.g., LSTMs over time-series data?\n\nCan the authors comment on the time complexity of evaluating their method relative to backpropagation?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8273/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698441135370,
            "cdate": 1698441135370,
            "tmdate": 1699637028618,
            "mdate": 1699637028618,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CBo8MQDhgQ",
                "forum": "uCMxeZCp2T",
                "replyto": "MOceSRS01T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8273/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8273/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "The encouraging comment of  continuing this line of work is very \nmuch appreciated. \nWe have been currently working on further validation \n``on more mature learning problems'', but we believe that\nbefore presenting a professional application we need to prove \nthat proposed theory is technically sound. Hence, this paper is\nprimarily intended to provide the foundation of the theory. The\nexperiments are primarily conceived to disclose the main principles more than\nfor showing advances in application domains. \nWe also fully understand the criticism on the presentation style. \nHowever, since this is the first paper which presents the theory,\nwe decided not to run the risk of a rejection of the paper due to \narguable statements. A comprehensible criticisms could have been\nthat a new theory must not be claimed only by conjectures.\nIn the near future, the Reviewer's comment will be carefully\nconsidered especially for reaching a broader scientific \ncommunity.\n\n**Q1.** Our method reduces to Backprop and GD, as explained in the\nmanuscript when we choose a directed acyclic graph and take the limit as $c\n\\to \\infty$ (classic feedforward nets used in deep learning). \nBPTT is not local in time and can only work for sequences of limited length,\nsince we need to store neural activations and delta errors for all unfolded\nnets. The distinctive feaure of the neural propagation scheme that arises\nfrom Hamiltonian equations is that such a limitation is overcome!\n\n**Q2.** This is a crucial question that we have been considering of primary\nimportance.\nWe believe that the primary challenge in appropriately\nevaluating the proposed method lies in defining an experimental setting that\ndoes not distort the online/continual nature while still factoring out \nthe effects introduced in this framework by forgetting phenomena.\nThis because what we propose opens the doors to a way of conceiving\nexperiments which can perfectly be understood when thinking of time-series\ndata (exactly what the Reviewer was considering). Other applications in other\ndomains of Machine Learning (e.g. vision, speech, and language) can be\nnaturally considered.\n\n**Q3.** From a computational point of view we can find a strict\nrelation between the computations required for BP/GD and our method. In\nparticular with reference to Eq. (14) we have that:\n\n- The forward phase of BP is replaced by the residual-like computation\nof the state equation (the first equation of the system);\n\n- The backward phase that is responsible of the computation of the delta\nerror in BP is here replaced by the computation of $\\dot p_x$\n(third equation) that are\nthe equivalent of the updates of the delta errors;\n\n- The computation of the gradients done with the BP factorization here\nis instead replaced by the computation of $\\dot p_{\\boldsymbol{w}}$ (forth\nequation);\n\n- Finally the gradient step is replaced by the update rule for the\nweights (second equation).\n\nHence the time complexity of our proposal is the same as the BP algorithm."
                    },
                    "title": {
                        "value": "Response to Reviewer xnxp"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8273/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700382392018,
                "cdate": 1700382392018,
                "tmdate": 1700385660866,
                "mdate": 1700385660866,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ydqJBFvHD6",
            "forum": "uCMxeZCp2T",
            "replyto": "uCMxeZCp2T",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8273/Reviewer_yT4E"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8273/Reviewer_yT4E"
            ],
            "content": {
                "summary": {
                    "value": "I note that I am unable to provide a good summary of this paper, as I found it very difficult to understand. See below for more details on that.\n\nThe authors introduce a graph model of a computation, as a formalisation of a neural network. Although the model is continuous time, they also introduce a quantised time version of it. Their model has a notion of spatio-temporal locality, which allows them to express some constraints on the computation. They introduce a variational problem, although it wasn't clear to me what the relevance of this particular functional or its stationarity is. This allows the authors to derive a set of Hamiltonian equations. After this, I lost track of the direction the paper was going: the locality constraints were reconsidered, and there was a consideration of boundary conditions, followed by the introduction of some time-reversal transformations that I didn't understand in this context.\n\nI wasn't able to understand how the conclusion related to the mathematics presented."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "n/a"
                },
                "weaknesses": {
                    "value": "In my opinion the main weakness in this paper is that it does not explain itself adequately for the target audience. I'm not an expert in the field presented in the paper, but I am, I think, representative in terms of experience and knowledge of the ICLR audience, and I wasn't able to understand what this paper was trying to say. I think an ICLR paper should be able to: explain it's key finding, what this is, and why it's important to anyone in the audience; and should provide sufficient information for an interested non-specialist reader to understand the paper in detail if they are willing to put in the work. I don't feel that the paper met either of these criteria.\n\nI would recommend that the authors either consider submitting the paper to a specialist journal, where the audience might be better matched to its content, or rewriting considerably to clearly explain the problem in the context of machine learning in general if they wish to submit to another general conference."
                },
                "questions": {
                    "value": "My limited ability to understand the paper limits the number of questions I have.\n\nOne thing that stood out to me was the authors introduce the paper by noting that many ML approaches require a large amount of pre-collected data, whereas the techniques to be described in the paper will work \"on-line\", using a limited capacity memory to interpret the stream of information as it comes in in a causal way. This sounds a lot like reinforcement learning. Indeed there are some further resonances with reinforcement learning further through the paper where the authors mention dynamic programming, and their introduction of a Lagrangian-like variational objective, and the subsequent transformation into a Hamiltonian problem reminds one of the relationship between value functions and the local behaviour of optimal policies. I think if the authors wish to present to a broad audience it would be useful to address this question of the relationship to reinforcement learning, which is likely to come up."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8273/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698696575414,
            "cdate": 1698696575414,
            "tmdate": 1699637028493,
            "mdate": 1699637028493,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LJIk3y4TXf",
                "forum": "uCMxeZCp2T",
                "replyto": "ydqJBFvHD6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8273/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8273/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "The Reviewer's comment on the presentation of the paper is understandable.\nWe agree with the comment that the paper might not reach a broad\naudience. However, we are proposing a new approach that we believe to be relevant in the lifelong learning scenario.\nAs such, we need to fully convince the scientific community of the technical\nsoundness and, in particular, that the Hamiltonian equations yields a local\nspatiotemporal process which replaces Backpropation. While we considered to\nexpose our results by adopting a more qualitative descriptions, we decided to\ngive up so as not to run the risk of a rejection of the paper due to arguable\nstatements. A comprehensible criticisms could have been that a new theory\nmust not be claimed only by conjectures.  However, in the near future, our\nambition is exactly what the Reviewer was asking: to present the paper to a\nbroad audience and, especially to explore relationship to reinforcement\nlearning."
                    },
                    "title": {
                        "value": "Response to Reviewer yT4E"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8273/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700382527205,
                "cdate": 1700382527205,
                "tmdate": 1700385640395,
                "mdate": 1700385640395,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Rf53BbtpGh",
            "forum": "uCMxeZCp2T",
            "replyto": "uCMxeZCp2T",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8273/Reviewer_gou7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8273/Reviewer_gou7"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a framework that treats an online learning setting for RNNs as a variational problem and allows to look at backpropagation as a special case. They use the Hamiltonian equations to represent the minimality conditions and propose an approximation method for the problem with boundary conditions. \n\n**Disclaimer**: This paper is quite far from the area of my expertise (reinforcement learning, graph neural networks), and I won't be able to assess the technical excellence of the work,  I have not checked the proofs. However, I still think my review can be useful to the authors as an outsider's view, especially as the authors state in the conclusion that \"the application to real-world problems need to activate substantial efforts on different application domains.\" Therefore, while not being totally ignorant in dynamical systems / optimal control, I ask the AC take my review as an evaluation of paper's readability and accessibility for the non-theoretical researchers that will potentially widen the target audience. I will also reflect this in the 'Confidence' section. For the time-being, I will put the score as 6, and, might update it post-rebuttal after engaging with the authors and other reviewers."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The framework proposed by the paper connects several seemingly unrelated concepts and allows to look at the commonly accepted things from a totally different angle (e.g. backpropagation)."
                },
                "weaknesses": {
                    "value": "* **Clarity**. While paper pays a lot of attention to careful notation and definition of the computational model, some of the concepts come out of the blue, either undefined or defined much later into the paper.\n\t* I understand that some of the concepts are not defined as they are common knowledge in the field (e.g. costates). However, my comment above is not only about those (see below)\n\t* What is pre-algorithmic view?\n\t* 'spatiotemporal locality' comes up already in the abstract/intro, but gets defined much later after all the computational model formalism is done.\n\t* I don't think, IN^i from (5) is defined.\n* **Lack of examples**. I understand that it is common in the theoretical community to define things in a most general way possible. However, I think it will be highly beneficial to bring parallels to the machine learning case by giving examples even for the variables involved. For example, $l(w, x, t)$ comes up in equation 8, but only much later (Theorem 2 at the bottom of next page) the paper mentions that this can be a sum of the regularisation term and an indicator function on the neurons outputs multiplied by some function L, i.e this is a loss function! Same applies to other variables, e.g. $\\xi$ and $\\mathbf{u}$. Section 2 defines $u$ as d-dimensional and $\\mathbf{w}$ as a concatenation of all weights in the network, i.e. n-dimensional. However, the function $l$ defined in (9) takes $\\mathbf{w}, x, t$ as inputs, but function $l$ in (11) takes $\\mathbf{u}, \\xi, t$ as inputs. If I understand it correctly, these $\\mathbf{u}$ is a control variable and is not the same as the input trajectory defined in Section 2. But having a clear example would greatly decrease the confusion.\n* **Existing literature**. The paper is motivated by biological learning where the organisms do not have access to the entire data collection (\"the agent can only use buffers of limited dimensions for storing the processed information\") However, the paper ignores the existing literature on Online Learning and Online Optimisation, that are highly related to the topic. Putting the work into this context would be highly beneficial for the community."
                },
                "questions": {
                    "value": "* Could you elaborate on the meaning of 'temporal horizon' in Section 2? Imagine we have an RNN which we update using gradient descent. The inputs have temporal aspect (e.g. sequences of real numbers), and the updates have temporal aspect (each weight updates adds one to the time subscript of the weight). Which one do you imply in Section 2? Do you intertwine the two as you mention in the second paragraph of Section 1 (\"we assume that learning and inference develop jointly\")? Could you provide a toy example?\n* \"we show that the on-line computation described in the paper yields spatiotemporal locality, thus addressing also the longstanding debate on Backpropagation biological plausibility\". Could you provide a couple of references on the debate and add a sentence or two explaining how your result affect the debate.\n* Section 2 defines the computational model based on a digraph. Should there also be an acyclicity constraint that does not allow \"inputs -> A-> B->A\" within the same time step?\n* For me, equation 8 comes out of the blue. Section (2) introduces the computational model and the constraints on it. Beginning of Section 3 mention CAL (Betti et al., 2019) for FNN (feedforward NN?). And then you say \"we claim that in an online setting the laws of learning for recurrent architectures can also be characterized by minimality of a class of functional. In what follows we will then concider variational problems for the functional of the form\". Could you explain where does equation 8 come from? Is the mc/2 * |w|^2 the reqularisation term? If yes, does the $l$ in equation 8 differ from the $l$ in Theorem 2 that already includes the regularisation term?\n* \"The local structure of equation 10, that comes from the locality of the computational model from Section 2 guarantees the locality of Hamilton's equation 12\". Could you, please, explain why this is the case?\n* Beginning of page 5 mentions backprop for FNN leading to equation 15 after introducing normalised costates. Could you explain the jump from considering RNNs to FNNs?\n* (Corollary 1) \"the proof comes immediately from equation 16.\" Could you add a couple of explicit steps for me to understand why this is the case?\n* \"This is a strong indication that when solving Hamilton's equations with an initial condition on $p_w$ we will end up with a solution that is far from the minimum\". How does this relate to any of the practical consequences on learning algorithms, e.g. backpropagation?\n### Nits\n\n* \"Spectacular results achieved in machine learning, ..., rely on large data collections. On the opposite, intelligent processes in nature arise without the need for such collections\"\n\t* True, but having access to libraries and archives have significantly boosted our ability to do science and fuelled the progress.\n* page 5, \"Theorem 2 other than giving us a spatio-temporal ... show\". Is there a word missing here?\n* footnote 5: \"... class of cohercive potentials V\" Should be \"coercive\"?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8273/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698709742320,
            "cdate": 1698709742320,
            "tmdate": 1699637028375,
            "mdate": 1699637028375,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1C6cKh3IiC",
                "forum": "uCMxeZCp2T",
                "replyto": "Rf53BbtpGh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8273/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8273/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer gou7 (part 1)"
                    },
                    "comment": {
                        "value": "Many thanks to the Reviewer for his humble approach.  When looking at the\nconstructive his criticisms, it looks like his/her expertise in\nreinforncement learning led to understanding the paper much more than what\nmentioned in the \"Disclaimer part.\"\nWe have tried to use some of the comments exposed in the weakness section\nto improve the presentation. In particular we tried to clarify some terms\nlike `\"pre-algorithmic algorithm\" and to immediately comment on the role\nof loss function of the term $\\ell$ right after Eq. (8). We furthermore\nchanged the notation for the general variable that indicate the $\\boldsymbol{w}$\ncomponent of the state that was previously denoted as $\\boldsymbol{u}$ and\nnow it is named $\\boldsymbol{\\omega}$ to further disambiguate it from\nthe input variable $u$. We would also like to remark that the ${\\rm IN}$ function is\ndefined on right after Eq. (5). In what follows we will answer to the precise\nquestions that the Reviewer formulated in the corresponding section of\nhis/her review.\n\n**Q1.** Yes, in this work, we are mainly concerned with online\ncomputations where there is a strong connection between the time that\ncaptures the dynamics of the sequence we are processing, expressed in our\nnotation by the function $t \\mapsto u(t)$, and the dynamics of the parameters\nof the model defined by the map $t \\mapsto \\boldsymbol{w}(t)$. Many learning\nprotocols can be cast in this framework, ranging from reinforcement learning,\nlifelong and online continual learning.  The specific strong emphasis in this\npaper is that we look for a learning framework which can work without\naccessing large data collections, but simply by processing and properly\nrepresenting the information as it is comes from sensors over the given\ntemporal horizon (agent life span).\n\n**Q2.** We have added the references and commented how our\napproach contributes to the mentioned problem.\n\n**Q3.** Perhaps we understood the comment, but we invite the Reviewer\nto ask again if we didn't grasp the essence of the question. \nCycles like $A\\to B\\to A$ amongst non-input units are permitted \nsince our assumptions correspond to typical recurrent nets. However, the\nconsistent computational scheme that we adopt does require that the\nprocessing does not take place \"within the same time step\"! In general, in\nthe discrete setting of computation, we need a delay, while in the continuous\nframework this correspond to the introduction of temporal derivatives of the\nstate. \n\n**Q4.** The term $\\int_0^T\n\\ell(\\boldsymbol{w}(t),\nx(t;\\boldsymbol{w}),t))\\phi(t)\\, dt,$\ncomes from the ergodic transposition of the\nfunctional risk inspired by classical mechanics as discussed in\n(Betti et al., 2019). The basic idea is that when dealing with time and with a\nstream of information the expectation of the loss that defines the empirical\nrisk can be rewritten as a sum over time. In our case however, differently\nfrom previous works in this directions, we are considering recurrent\ncomputations and, therefore, the term $x(t;\\boldsymbol{w})$  is a solution of the\nrecurrent dynamics expressed by Eq. (4). As correctly noticed by the Reviewer,\nfunction $\\ell$ can itself contain a regularization term\non the weights (like the classical weight decay). However it is important to\nadd an additional *temporal regularization term* that links the weights\nat different temporal instant of the form $\\int_0^T\nmc/2|\\dot\\boldsymbol{w}|^2\\, \\phi(t) dt$ for at least two reasons:\nfirstly, it promotes\nconvergence and the smoothness of the solution and, secondly, it enables\nthe explicit calculation of the Hamiltonian in as in Eq. (11); \nhence, there is always a classic regularization term on the weights and also \nan appropriate temporal regularization term on the derivative of the weights \nthat is consistently considered in Eq. (8) and in Theorem 2. \n\n**Q5.**\nThis is because the fact that we are considering the particular set\nof differential constraints in Eq. (10) allows us (by using the\ntechniques of optimal control) to describe the stationary point of\n(9) in terms again of local differential equations (Hamilton Equation).\nIn this equation, in addition to the spatial locality, the presence of time\nderivatives gives rise to local temporal propagation."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8273/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700386228128,
                "cdate": 1700386228128,
                "tmdate": 1700386228128,
                "mdate": 1700386228128,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kBe9WIfbnx",
                "forum": "uCMxeZCp2T",
                "replyto": "Rf53BbtpGh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8273/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8273/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer gou7 (part 2)"
                    },
                    "comment": {
                        "value": "**Q6.**\nWhile the reduction for $c\\to\\infty$ can be formally done in general\nas suggested for instance in Corollary 1, it only describes a meaningful and\nviable computational scheme only when we have a directed acyclic graph\n(which correspond to the FNN case).\nSo the reduction indeed makes sense only under the additional hypothesis\nthat are the one that makes possible to apply the standard Backpropagation\nalgorithm. \n\n**Q7.** Consider the last equation in the system of Eq. (16) with all\n$c_i=c$, and group them as follows\n$$ \\lambda^i_x -\\sigma'(a_i)\\sum_{k\\in{\\rm ch}(i)}\\lambda^k_x w_{ki} - L_{\\xi_i}(x,t)\\sigma'(a_i)= \\frac{1}{c} \\dot \\lambda^i_x -\\frac{1}{c}\\biggl[-\\frac{\\dot\\phi}{\\phi}+\\frac{d}{dt}\\log(\\sigma'(a_i))\\biggr] \\lambda^i_x,$$\nnow the rhs of this equation as $c\\to\\infty$ formally goes to $0$ and\nwe are left with the desired equation.\n\n**Q8.** This implies that, in general, it is not possible to simply define\nlearning/optimization theories that operate in a temporal environment solely\nin terms of optimization problems for integral functionals (like the one in\nEq. 8), unless the problem is small enough to be solved in a batch-mode\nfashion. This observation is also related to the fact that the solution of\ncalculus of variations typically describes elliptic problems, and they are\nincompatible with hyperbolic problems, which is usually the a class of\nproblems that are suitable to describe temporal evolution (like learning in\nthis context).\nThis is why the discussion proposed in Section 4, addressing boundary\nconditions, is instrumental to enable the use of such tools within the\ncontext of learning.\n\n**\"Nits\"** We have address them directly in the revised manuscript."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8273/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700386464767,
                "cdate": 1700386464767,
                "tmdate": 1700386464767,
                "mdate": 1700386464767,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "yLww6WdMP9",
            "forum": "uCMxeZCp2T",
            "replyto": "uCMxeZCp2T",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8273/Reviewer_YNF2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8273/Reviewer_YNF2"
            ],
            "content": {
                "summary": {
                    "value": "The paper develops a spatiotemporal local learning rule. To develop it authors treat a learning rule as a solution to a variational problem for the special class of functional that can be solved using Hamilton's equations. The authors show how this rule can be reduced to backpropagation and to backpropagation with momentum as specific cases."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "I can not describe strengths and weaknesses based on my current understanding of the paper. I hope I will update these sections when the authors answer my questions. \n\nPlease see the questions section."
                },
                "weaknesses": {
                    "value": "--"
                },
                "questions": {
                    "value": "1) Can you elaborate more how Corollary 1 can be viewed as backpropagation and Proposition 4 as GD with momentum?\n2) Can you recommend an open source to understand how Corollary 1 can be viewed as backpropagation along with the Gori et al. (2023)?\n3) Can a different choice of \\phi lead to different learning rules in Proposition 4? Or does it lead only to different schedules for momentum? \n4) Can you write algorithms for the proposed learning rules (including sign flipping algorithm)?\n5) Can you motivate the form of functional in Eq. 8? Specifically, why regularization on weight acceleration is important?\n6) How q x^2 /2 can be interpreted as the accuracy term in Section 4.2?\n7) What are z, u and x in Fig. 1-4? z is target, x is a vector predicted with LSTM, and u is input? I failed to see how objectives in section 4.2 encourage x to be close to z. Can you elaborate on this? \n8) You mentioned that the proposed algorithm overcomes the limitation of backpropagation through time, but at the same time the algorithm converges to backpropagation when c \u2192 to infinity. Can you elaborate on this?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "--"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8273/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698864630555,
            "cdate": 1698864630555,
            "tmdate": 1699637028273,
            "mdate": 1699637028273,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MAKWn1P0jy",
                "forum": "uCMxeZCp2T",
                "replyto": "yLww6WdMP9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8273/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8273/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for his fairness in the evaluation and for having posed\nmany specific question that will surely help to improve the quality of the\nmanuscript.\n\n**Q1.** Corollary 1 shows that in the limit of infinite speed of\npropagation ($c\\to+\\infty$) the differential equation for the \nrescaled costates, the $\\lambda_x^i$, described in Eq. (16) (last equation)\nsatisfy exactly the classical equation for the delta error terms used in\nthe Backpropagation algorithm. This reduction, which in Corollary 1\nis formally expressed in the general setting, make sense only in the\ncase when the graph that we consider is acyclic which is an assumption\nrequired by Backprop. In this case, which correspond to the classical\narchitectures of FNN\nwe can choose, as it is usually done, the set of output nodes to be the\none at the \"end\" or at the \"top\" of the architecture, i.e. the ones\nthat have no childrens ($i\\in O$ implies ${\\rm ch}(i)=\\emptyset$.\nThen if we look at Eq. (17):\n$$\n\\lambda^i_x= \\sigma'(a_i)\\sum_{k\\in{\\rm ch}(i)}\\lambda^k_x w_{ki} + L_{\\xi_i}(x,t)\\sigma'(a_i),\n$$\nwe can make the following observations: *i.* if $i$ is an output neurons,\n$i\\in O$, then the sum $\\sum_{k\\in{\\rm ch}(i)}$ is empty and we get\n$$\\lambda^i_x = L_{\\xi_i}(x,t)\\sigma'(a_i)$$\nwhich is exactly the statement that\nthe delta error on the output neurons is simply the gradient of the loss\nwith respect to their activation, *ii.* when $i\\ne O$ it is\nthe second term that vanishes since, as we remarked in Theorem 2 $L$\nonly depends on the value of the neurons in the output and reduces to\n$$ \\lambda^i_x= \\sigma'(a_i)\\sum_{k\\in{\\rm ch}(i)}\\lambda^k_x w_{ki},$$\nthat again is exactly the classical way in which the delta error is computed\nin Backprop.\n\nFor what concerns Proposition 4 connections with GD with momentum can be\nbetter understood as follows. The second formula in Eq. (20) has the form\n$$\\ddot w_{ij}+\\theta \\dot w_{ij} + \\gamma \\nabla_{u_{ij}} E(w,t)=0$$\nwhere $E$ is a generic compound loss.\nThis is the case \nsince the term $V_{u_{ij}}(\\boldsymbol{w},t)$ is an explicit gradient of\na regularization loss with respect to the weight $w_{ij}$ and $\\lambda^i_x x_j$\nis the Backprop factorization  of the gradient of the loss\nthat involves the outputs of the NN with respect again to the weight\n$w_{ij}$. If you consider an Euler discretization of this ODE\nyou end up with\n$$\\frac{1}{\\tau}(w_{ij}^{k+1}-2 w_{ij}^k +w_{ij}^{k-1})\n+\\theta(w_{ij}^{k+1}-w_{ij}^k)+\\gamma \\nabla_{u_{ij}} E(w^k, t_k)=0$$\nthat can be rearranged into the GD with momentum update rule\n$$w_{ij}^{k+1}=w_{ij}^k -\\alpha \\nabla_{u_{ij}} E(w^k, t_k) +\\beta(w^k_{ij}-w^{k-1}_{ij}).$$\nInterestingly this continuous interpretation \nwas already introduced in the vary same paper that proposed for the\nfirst time the GD with momentum method, namely in\nB. T. Polyak, *U.S.S.R. Comput. Math. Math. Phys.* 4,1\u201317 (1964).\n\n**Q2.**\nAs explained in the response to Q1, any textbook that explains in details the\nBackprop algorithm is ok. An excellent, widely available reference is the\nclassical Rumelhart, David E., James L. McClelland, and PDP Research\nGroup. \"Parallel distributed processing, volume 1: Explorations in the\nmicrostructure of cognition: Foundations.\" (1986).\nFor a completely open source material you can look for instance at this\nlecture note (section 6) available online \nhttps://www.cs.cornell.edu/courses/cs5740/2016sp/resources/backprop.pdf\nwhich appears to be ok but of which we cannot guarantee\ncorrectness of all its parts.\n\n**Q3.** The structure of the learning rule (not the precise form\nhowever!) that one can achieve with a general $\\phi$ is described by\nEq.~(16). A meaningful generalization of Proposition 4 with general $\\phi$\ncan be achieved if we choose $\\phi$ such that $\\dot\\phi/\\phi>0$. The effect\non the resulting method is not simply that of having a time dependent\ncoefficient in front of the momentum term as the choice of $\\phi$ also\ninfluences the computation of the delta-term-like variables\n$\\dot\\lambda$. Hence, to some extent, the Reviewer's intuition that a truly\ndifferent learning rule might arise makes sense. However, the concrete impact\nin the process of learning has still to be explored."
                    },
                    "title": {
                        "value": "Response to Reviewer YNF2 (part 1)"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8273/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700383489214,
                "cdate": 1700383489214,
                "tmdate": 1700385093117,
                "mdate": 1700385093117,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2SyJLFnFh8",
                "forum": "uCMxeZCp2T",
                "replyto": "yLww6WdMP9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8273/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8273/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q4.** The algorithmic description of the proposed rules\nbasically relies on the explicit Euler approximation scheme of an ODE.\n[As a reference you can look at the classical book\nRichard, L., Faires J Douglas, and M. Annette.\nNumerical analysis. sengage, 2016.]\nFor instance in the case of the ``sign-flipping algorithm'' the \nonce you choose a temporal discretization step $\\tau>0$ the algorithm looks\nlike this\n\n1. Randomly initialize the state and costate variables and set the sign\nterm in Eq. (23) equal to $1$: $s\\gets 1$;\n2. Compute the update terms following Eq.(14):\n\n    - $\\Delta x_i\\gets c_i\\Bigl(-x_i +\\sigma\\Bigl(\\sum_{j\\in{\\rm pa}(i)} w_{ij}x_j\\Bigr)\\Bigr)$\n\n    - $\\Delta w_{ij}\\gets -p^{ij}_\\boldsymbol{w}/(mc)$\n\n    - $\\Delta p^i_x\\gets c_i p_x^i-\\sum_{k\\in{\\rm ch}(i)} c_k  \\sigma'\\Bigl(\\sum_{j\\in{\\rm pa}(k)} w_{kj}x_j\\Bigr)p_x^k w_{ki} - c L_{\\xi_i}(x,t)$\n\n    - $\\Delta p_{\\boldsymbol{w}}^{ij}(t)\\gets - c_i p^i_x \\sigma'\\Bigl(\\sum_{m\\in{\\rm pa}(i)} w_{im}x_m\\Bigr)x_j - c k V_{u_{ij}}(\\boldsymbol{w},t)$\n\n3. Update all the variables according to the implicit Euler scheme:\n\n    - $x_i\\gets x_i +\\tau s \\Delta x_i$\n\n    - $w_{ij}\\gets w_{ij} +\\tau s \\Delta w_{ij}$\n\n    - $p^i_x \\gets p^i_x +\\tau s \\Delta p^i_x$\n\n    - $ p_{\\boldsymbol{w}}^{ij} \\gets p_\\boldsymbol{w}^{ij}+\\tau s \\Delta p^{ij}_\\boldsymbol{w}$$\n\n4. Recompute  $s$ according to Eq. (24).\n5.  If this is not the last iteration go back to step 2.\n\n**Q5.** The regularization on the velocity of the weights it is\nimportant for at least two reasons: firstly it promotes convergence in the\nparameters of the models, as well as the smoothness of the overall learning\nprocess, and secondly enables the explicit calculation of the Hamiltonian in\nas in Eq. (11); without this term the Hamiltonian would have been defined in\nterms of another implicit minimization problem.\n\n**Q6.** In the classical LQ problem the objective is to have bring the state variable\nas close as zero as possible, while also keeping small values of the control\nparameters, hence the more the term $x^2/2$ is weighted (by taking higher value\nof $q$) the more the solution is expected to accurately favour the zero,\nconstant solution. In the experiment done with the sinusoidal signal there\nis indeed a misprint in the text the functional that we are considering is\n$G(v)=\\int_0^T q (x-z)^2/2+rv^2/2 + r_w^2\\, dt$ so that $q (x-z)^2/2$\nhas a direct interpretation as accuracy parameter. This has been now\ncorrected in the revised version.\n\n**Q7.** In this figure $x$ is the value of the output neuron,\n$z$ is the target and $u$ is an input as in Eq. (5) (notice that however in\nthis experiment it is just a null signal). As explained in\nQ6, the actual accuracy term that is used in the experiments is $q (x-z)^2/2$\nwhich should clarify the Reviewer's legitimate question.\n\n**Q8.** The proposed theory works in general for a directed graph\nwith the properties described in Section 2, which basically correspond with\nrecurrent neural network architectures. However as we remarked also in Q1.,\nwhile the reduction for $c\\to\\infty$ can be formally done in general as\nsuggested for instance in Corollary 1, it only describes a meaningful and\nviable computational scheme only when we have a directed acyclic graph (case\nfor which Backprop can be used).\nSo the reduction indeed makes sense only under the additional hypothesis at\nthe basis of standard Backpropagation algorithm. In all other general cases,\nthat are the one of interest for this study, the expression we found in the\nlimit are just formal expressions. However, what is really important is that\nthe proposed theory clearly leads to a spatiotemporal local propagation\nscheme which, to the best of our knowledge, is an open problem for recurrent\nneural nets."
                    },
                    "title": {
                        "value": "Response to Reviewer YNF2 (part 2)"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8273/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700385000221,
                "cdate": 1700385000221,
                "tmdate": 1700385121293,
                "mdate": 1700385121293,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]