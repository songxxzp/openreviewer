[
    {
        "title": "SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with Backtracking"
    },
    {
        "review": {
            "id": "HaiQU2IBS3",
            "forum": "FJWT0692hw",
            "replyto": "FJWT0692hw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8061/Reviewer_aeRK"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8061/Reviewer_aeRK"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces SequenceMatch to alleviate the compounding error problem in large language model generation.\nFirst, it introduces a backspace action token to delete the inappropriate token generated in the last step. Second, it introduces a new training objective that minimizes the occupancy divergence between the dataset and the learned model, instead of simply maximizing the likelihood of the ground truth next tokens in the output distribution. Experimental results show that SequenceMatch can improve the accuracy in the arithmetic add-or-sub-in-base sub-task of the match dataset, and improve the mauve score in the openwebtext dataset."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The motivation is convincing\n- The method is novel\n- The paper writes well"
                },
                "weaknesses": {
                    "value": "- The experiment section is not so convincing. The method is evaluated mainly in two settings. In the first setting, the method shows a significant improvement on a subtask of the math dataset. But how about the other sub-tasks? We don\u2019t know if the method can generalize well on other tasks. In the second method, the method has a slightly better mauve score, but the perplexity score drops by a large margin. How can we know that this method indeed improves the model generation?\n- The method relies on negative sampling, but there is no reasonable negative sampling strategy provided for open language tasks. This paper provides two negative sampling strategies: random noise and ground-truth noise. As the authors also mentioned in Sec. 6.1, the ground-truth noise needs to be manually constructed for different tasks. The random noise simply samples other tokens in the vocabulary. Both strategies look hard to generalize to open tasks, as it is almost impossible to design ground-truth noise for all the tasks in the world, and the vocabulary for open tasks is too large (the whole token codebook) for the random noise to get meaningful negative samples easily. Thinking about applying SeqenceMatch to the pretraining of LLMs like Llama2, what negative sampling strategy should be used?"
                },
                "questions": {
                    "value": "Does the method affect the combinational generalization? Given the famous avocado armchair as an example. Assume we have a training dataset that contains avocados, and different types of armchairs but doesn\u2019t contain avocado armchairs. Does the method discourage the model from combinationally generalizing to avocado armchairs, as it is not included in the training set?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8061/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8061/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8061/Reviewer_aeRK"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8061/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698568188131,
            "cdate": 1698568188131,
            "tmdate": 1699636996731,
            "mdate": 1699636996731,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5NdW1zIyjT",
                "forum": "FJWT0692hw",
                "replyto": "HaiQU2IBS3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8061/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8061/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer aeRK"
                    },
                    "comment": {
                        "value": "Thanks for your insightful review. Similarly to reviewer TvsS, you touch on some very important points relating to the tradeoff between different divergences. We answer your specific questions below:\n\n\"__In the second method, the method has a slightly better mauve score, but the perplexity score drops by a large margin.__\"\n+ We agree that the behavior of the perplexity is counter-intuitive. However, in our setting the perplexity does not necessarily correspond to the probability of generating a sequence. We use the term perplexity in the usual way: to denote the exponential of the average negative log likelihood of the next action. Usually the perplexity on the train set directly corresponds to the probability of generating in-distribution sequences. However, in the case with a backspace token, this is not necessarily true, since the probability of generating a sequence must be computed by marginalizing over all the possible sequences of actions (including backtracking via the backspace) that could generate the sequence.\n+ As an example, if we consider a very simple language with tokens \u2018A\u2019 and \u2018B\u2019, where the dataset consists only of sequences \u2018AAAAA\u2026\u2019, we can generate an in-distribution sequence by following a policy of sampling A,B uniformly, and then choosing <backspace> if we last sampled a B. We will eventually always generate \u2018AAAAA\u2026\u2019, but the perplexity on the dataset is not 1, as it would be for a simple autoregressive model that always generated \u2018AAAAA..\u2019. Indeed, a drawback of our method is that we lose the ability to compute the probability of generating a sequence. However, in practice these probabilities do not tend to be very useful for e.g. anomaly detection, so we think it is a good trade-off for the ability to backtrack.\n\n\"__There is no reasonable negative sampling strategy provided for open language tasks.__\"\n+ One possible sampling strategy is the uniform random strategy. As seen in figure 3 and table 2, this has advantages over no added noise. Figure 3 also shows that problem-specific noise can be advantageous. For the problem of open language tasks, uniform noise would be the default, but potentially there could be ways to develop tailored noise, although these are speculative for the time being. For instance, if we assume access to an LLM of similar size, we could use it as an oracle to generate eg incorrect French words in a translation task. We could also use crowd workers to generate text and record the complete generative process, including any backspaces used by the workers.\n\n\"__Thinking about applying SeqenceMatch to the pretraining of LLMs like Llama2, what negative sampling strategy should be used?__\"\n+ As mentioned above, the random uniform sampling is a baseline approach which gives some advantage. Other approaches could be investigated, including using other models to generate plausible (but incorrect) continuation tokens.\n\n\"__Does the method discourage the model from combinationally generalizing to avocado armchairs, as it is not included in the training set?__\"\n+ This is a great question. Unfortunately, we don\u2019t have a way to answer it theoretically; at least, we\u2019re unaware of a mathematical formalism of the combinatorial generalization phenomenon. Intuitively, we think it\u2019s likely that the loss encourages more mode-concentrating behavior in exchange for increased probability of staying in-distribution, as discussed in the response to reviewer TvsS. This would lead to decreased levels of \u2018combinatorial generalization\u2019. Of course, in the setting of language models, we could argue that hallucinations are an example of incorrect generalization, where a model is happy to continue generating details of events that did not happen. Perhaps in this setting, or settings such as question answering, it would be better if the level of generalization was lower.\n\nPlease let us know if there are any remaining questions; we would be happy to discuss them!"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8061/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700256214044,
                "cdate": 1700256214044,
                "tmdate": 1700256214044,
                "mdate": 1700256214044,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "l1QIrStFKC",
                "forum": "FJWT0692hw",
                "replyto": "5NdW1zIyjT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8061/Reviewer_aeRK"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8061/Reviewer_aeRK"
                ],
                "content": {
                    "title": {
                        "value": "Response to author comments"
                    },
                    "comment": {
                        "value": "Thank you for answering my questions! The explanation of why real perplexity is hard to compute in the proposed method makes sense. However, since perplexity is one of the most important metrics in LLMs, is it possible to construct some approximation (e.g., by marginalizing over cases where there are zero, one or two <backspace> action in the response) and see if the perplexity score can approach the baseline?"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8061/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700649292142,
                "cdate": 1700649292142,
                "tmdate": 1700649292142,
                "mdate": 1700649292142,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1yeImbvzww",
            "forum": "FJWT0692hw",
            "replyto": "FJWT0692hw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8061/Reviewer_roYx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8061/Reviewer_roYx"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses the problem of learning autoregressive models for (discrete) sequence modeling. It identifies two drawbacks of traditional maximum likelihood approaches: Firstly, such techniques, like behavioral cloning, allocate weights to sequences based on their prevalence in the training set. They do not consider the problem of guiding the autoregressive model when it starts to be out-of-distribution. To tackle this issue, the authors draw inspiration from Garg et al. 2021 and put forth a non-adversarial objective aimed at minimizing multiple divergences. A distinguishing feature from Garg et al. 2021 is their extension of the methodology to infinite-dimensional state spaces. The second drawback is that classical auto-regressive methods can go OOD by predicting bad tokens. To address this, the authors introduce an innovative approach of incorporating a \"backspace\" token, which has the capability to erase the preceding token. To facilitate the model in learning when to generate this backspace token, the authors suggest the introduction of noise into the training sequences. They then enhance these sequences with the backspace token, employing the modified sequences as training data. Additionally, they present a systematic method to process the backspace tokens in transformers using masking. This ensures that the renowned high-speed learning capabilities of transformer models on GPUs remain uncompromised.\n\nThey compare their approach with classical approaches on an arithmetic task, and on text generation, with positive results showing the effectiveness of the two components."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is very well written and addresses a significant and relevant issue. It offers a solution designed to minimize various divergences associated with sequence generation. Notably, the authors introduce the innovative concept of a \"backspace\" token, alongside presenting a proficient method to seamlessly incorporate this token into the training set. Furthermore, the experimental outcomes presented are both compelling and convincing. The contributions may be of the interest of a large audience."
                },
                "weaknesses": {
                    "value": "The paper proposes two distinct contributions. Firstly, it extends the work of Garg et al. 2021 to handle an infinite-dimensional state space. However, based on my understanding, this extension doesn't seem particularly pertinent to the problems explored in the experimental section. While I'm somewhat familiar with Garg et al.'s work (having read it for this review), the nuances differentiating the two papers aren't immediately clear to me. I'd encourage the authors to better identify these differences more explicitly. While Garg et al. 2021 delves into reinforcement learning, the authors of the current paper narrow their focus to sequence generation, which can be seen as a simpler challenge than the broader realm of RL. The originality of this contribution remains somewhat ambiguous to me.\n\nThe paper's second contribution (introducing backspace) is more algorithmic and makes sense, especially given the efficient implementation strategy the authors have introduced. However, this contribution stands independent of the first, resulting in a paper that seems to amalgamate two separate ideas. While the combined nature of these contributions makes the proposed model efficient, it also emphasizes that individually these contributions are not so strong. \n\n(Small remark: bibliography is in the supplementary material and has to be moved back to the main paper)"
                },
                "questions": {
                    "value": "* Please better identify what is the contribution w.r.t Garg et al. 2021"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No concerns"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8061/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698773163991,
            "cdate": 1698773163991,
            "tmdate": 1699636996597,
            "mdate": 1699636996597,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2XBqds6xaZ",
                "forum": "FJWT0692hw",
                "replyto": "1yeImbvzww",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8061/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8061/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer roYx"
                    },
                    "comment": {
                        "value": "Thanks for your thoughtful and comprehensive review. Your main question was about the relation of the two contributions, and the novelty of the approach compared to Garg [2021]. We hope to have answered this question in the global response.\n\n__Please better identify what is the contribution w.r.t Garg et al. 2021__\n+ See global response\n\nPlease let us know if there are any remaining questions or aspects of the questions we have not addressed, and we would be very happy to discuss them!"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8061/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700256095390,
                "cdate": 1700256095390,
                "tmdate": 1700256095390,
                "mdate": 1700256095390,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "OIIpZgSQ5U",
            "forum": "FJWT0692hw",
            "replyto": "FJWT0692hw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8061/Reviewer_n9EH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8061/Reviewer_n9EH"
            ],
            "content": {
                "summary": {
                    "value": "This paper formulates autoregressive sequence generation as an imitation learning (IL) problem. To tackle the compounding error issue brought by the original MLE objective, it minimizes the occupancy divergence between the sampled sequences from the model and the data distributions. The paper further proposes a masking scheme that allows generation with a backspace action."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This paper offers a novel perspective for sequence modeling by formulating it as an IL problem. It tackles the error compounding issue, a significant drawback of sequence modeling, by adopting a divergence minimization approach.\n2. The backspace action is novel for sequence modeling. Allowing backtracking during decoding may greatly benefit tasks in reasoning and planning.\n3. The experiments demonstrate using backspace improves the accuracy and detects OOD cases."
                },
                "weaknesses": {
                    "value": "1. The authors only present results on two tasks. It would be more convincing to add more results on, e.g., summarization, translation, and more complicated reasoning tasks.\n2. The method induces nonnegligible training overhead due to sampling trajectories and using a complex loss objective. Also, using backspace introduces some inference overhead -- is the case of rolling back a long segment very unlikely?\n3. The proposed formulation in Sec 3 seems to be an application of Garg et al. (2021) to the case of sequence modeling. May authors elaborate the technical novelties w.r.t. Garg et al. (2021)?"
                },
                "questions": {
                    "value": "See weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No ethic concerns."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8061/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699569659754,
            "cdate": 1699569659754,
            "tmdate": 1699636996479,
            "mdate": 1699636996479,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jMP9cdxCkM",
                "forum": "FJWT0692hw",
                "replyto": "OIIpZgSQ5U",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8061/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8061/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer n9EH"
                    },
                    "comment": {
                        "value": "Thanks for your helpful review. We answer your questions below.\n\n\"__It would be more convincing to add more results on, e.g., summarization, translation, and more complicated reasoning tasks.__\"\n+ See global response\n\n\"__The method induces nonnegligible training overhead due to sampling trajectories and using a complex loss objective__\"\n+ We give some numerical details on the training overhead in the appendix, section F. The overhead of the loss itself is mainly due to the loss of specialized cuda kernels for causally-masked attention. The overhead of the sampling is fundamentally unavoidable, however. It can be amortized by keeping a replay buffer of previously-generated samples and using those stale replays during training. Since the loss approach is off-policy, using stale replays is valid. If this approach is deployed at a large scale during pre-training, we could also parallelize the generation during training--one machine or set of GPUs could be used to continuously generate sequences, and the parameters for the generation machine updated periodically.\n\n\"__Also, using backspace introduces some inference overhead -- is the case of rolling back a long segment very unlikely?__\"\n+ Yes, it\u2019s unlikely. In fact, even under high levels of noise, the generated sequences do not contain many backspaces. With 20% of tokens subject to additional noise, the rate of backspaces in the arithmetic task was around 1.5% of all actions for the SequenceMatch-trained model. It was rare to have more than one backspace in a row. On the other hand, we found that of the cases where backspace is used, it is around 90% accurate--it only removes a correct token 10% of the time. \n\n\"__May authors elaborate the technical novelties w.r.t. Garg et al. (2021)?__\"\n+ See global response\n\nIf there are any remaining uncertainties, we are happy to answer them during the discussion phase."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8061/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700255979460,
                "cdate": 1700255979460,
                "tmdate": 1700255979460,
                "mdate": 1700255979460,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "apAP5m8Ejz",
                "forum": "FJWT0692hw",
                "replyto": "MO0Isnac0e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8061/Reviewer_n9EH"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8061/Reviewer_n9EH"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for providing detailed comparison with existing works and adding new experimental results. I have no additional questions."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8061/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700702223504,
                "cdate": 1700702223504,
                "tmdate": 1700702223504,
                "mdate": 1700702223504,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "w7p4l7GDRA",
            "forum": "FJWT0692hw",
            "replyto": "FJWT0692hw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8061/Reviewer_TvsS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8061/Reviewer_TvsS"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces SequenceMatch - a novel minimization objective for training autoregressive models.  The proposed approach trains using the chi^2 divergence rather than the standard KL maximum likelihood (ML) objective.  An estimator for the loss is defined and a training algorithm is given.  A backspace token is added additionally to account for the model generating more OOD sequences given the changed objective.Results are provided for fine-tuning on a math dataset and OpenWebText generation"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The proposed work tackles an important problem in the generation on OOD sequences and proposes a new approach which the authors derive and give a practical estimator for.  The ideas were studied in prior VI and generative model literature but appear to be new for language models - the application in this work.\n* It is appreciated that the authors have suggested a novel theoretical approach demonstrating that one does not need to do any variational bound, nor adversarial training to compute the loss.  This makes the proposed approach easier to implement and use.  The authors also derived an empirical estimator for practical purpose.  The idea of using the backspace to handle the generation of more OOD sequences is also good, which although the proposed approach introduces a new problem of more diverse generations, the additional backspace helps address this.\n* Overall the paper is well-written and motivates itself well from prior literature in imitation learning."
                },
                "weaknesses": {
                    "value": "* The authors propose using the chi-sq divergence but do not motivate using the chi-sq over other f-divergences only citing its use in prior works.  A more natural divergence based on f-divergences and shortcomings of KL is the Jensen-Shannon (JSD), which also has the benefit of being symmetric and adds the reverse KL.  Why have the authors not compared with other divergences or why did these divergences not perform well?\n* The proposed work provides an estimator but does not show any properties of the new estimator (consistency, unbiasedness, etc.).  Historically, the MLE has been nice properties, but it is unclear whether Eq (4) has any nice properties with relation to the true divergence. \n* Performance of the proposed approach does not perform much better than the MLE except for MAUVE, when the data does not appear to be OOD (OpenWebText).  Additional experiments on OOD datasets (would artifical noise)   would supplement the results and show better performance potentially.\n* The SequenceMatch approach is relatively slow taking 1.5-8x the training time.  Due to the number of gradient updates, it may also be prohibitively expensive for full-finetuning.  However, this is not discussed in the paper."
                },
                "questions": {
                    "value": "* Can the authors clarify the Figure 1 example? My intuition is that the MLE should come from KL(p_{data} | p_{model}), which is defined in the example whereas the reverse KL(p_{model} | p_{data}) is not.  Isn't this suggesting the reverse KL is desired?\n* There is an implicit assumption in this work that the KL divergence is not a good metric because what we desire is for the model not to generate when the true data distribution has probability 0.  The work does not discuss the opposite, however where the data distribution has non-zero mass, KL minimization will encourage the model to always try to match the distribution - an explicit advantage of KL.  Without minimizing KL my concern is that we do not cover the full data distribution.  Explicitly, to address the main metric of interest in 2.1.1, implicitly the reverse KL would be a good choice to optimize.  This can be a problem especially for a large model or small data.\n* Given that the new metric may not cover the full distribution as well as KL minimization evaluation on retrieval or Q/A tasks where information is needed - will further improve the paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8061/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8061/Reviewer_TvsS",
                        "ICLR.cc/2024/Conference/Submission8061/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8061/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699586939176,
            "cdate": 1699586939176,
            "tmdate": 1700633728875,
            "mdate": 1700633728875,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "45eWxo6ngZ",
                "forum": "FJWT0692hw",
                "replyto": "w7p4l7GDRA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8061/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8061/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer TvsS"
                    },
                    "comment": {
                        "value": "Thank you for your thoughtful and detailed review. You raise several excellent points which we answer here.\n\n\"__Why have the authors not compared with other divergences or why did these divergences not perform well?__\"\n\n+ On prototyping iterations of the project, we tried different divergences and observed that they did not work as well as the $\\chi^2$-divergence. In particular, we observed that the Q-values (logits) would become very large and training would be unstable for divergences other than $\\chi^2$. Previous work showed that the $\\chi^2$ divergence had the strongest performance in high-dimensional tasks (e.g. appendix B.2. in [Garg 2021]). Furthermore, other work such as [Al-Hafez et al 2023] has provided theoretical justification for this improved performance, namely the fact that the optimal Q-values are bounded.\n+ From a practical point of view, the reverse KL divergence and JS divergence pose algorithmic challenges, since the function $\\phi(x)$ in equation 4 is $1 + \\log x$ and $\\log (2 - \\exp(-x))$, which are only defined for $x > 0$ and $x > -\\log 2$ respectively. This would require constraining $\\ell(s,a) - \\gamma V(s\u2019)$ for all states, actions, next states $s,a,s\u2019$. It\u2019s not obvious how to algorithmically enforce such a constraint given that we are parameterizing $\\ell$. Another option is to form a relaxation for $\\phi$ with e.g. a very large negative value where $x$ is out of the domain of $\\phi$, but this makes optimization very unstable.\nWe are attempting ablations with different divergences, using the relaxation-based method, which we will hopefully have available by the end of the author-reviewer discussion period.\n\n\"__Does not show any properties of the new estimator (consistency, unbiasedness, etc.)__\"\n\n+ Thank you for pointing this out. The estimator in equation 4 is a plug-in estimator for the population objective stated in the previous section. As such, under modest conditions it is unbiased and consistent, in the sense that the expected value of ${\\hat J}(\\ell_{\\theta})$ is $J(\\ell_{\\theta})$ and ${\\hat J}(\\ell_{\\theta})$ converges in probability to $J(\\ell_\\theta)$ as we increase the number of sequences used in the estimator. For simplicity in equation 4 we present the estimator using a single sequence. In practice we always average the loss over several sequences, with a batch size of 64 typical. Using conditions such as boundedness of the logits and $\\phi = x^2 - x^2/4$ for the $\\chi^2$-divergence, proof of unbiasedness follows from linearity of expectation, and consistency from the central limit theorem. We will include these proofs in the next version of the appendix. \n\n[Continued in next reply]"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8061/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700255502594,
                "cdate": 1700255502594,
                "tmdate": 1700255610318,
                "mdate": 1700255610318,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EFC44ESajj",
                "forum": "FJWT0692hw",
                "replyto": "88DcwOGiF0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8061/Reviewer_TvsS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8061/Reviewer_TvsS"
                ],
                "content": {
                    "title": {
                        "value": "Response to author comments"
                    },
                    "comment": {
                        "value": "Thank you for addressing the questions raised in the review. \n\nI appreciate the clarification on the properties of the estimator in Eq.4 and note that the authors have given justification for why the chosen divergence is used over existing divergences both for the imitation learning setup and properties of the divergences. For this reason I am willing to increase my score to above the acceptance threshold.\n\nStill, I believe the paper is lacking comparison with other divergences - it can't be said empirically that penalization from chi^2 is better. Further, there are claims the authors have highlighted - \"especially for a task such as question-answering, where receiving a coherent but non-diverse response is generally preferred to a set of diverse but incoherent results.\"  - that should be tested to demonstrate that training with the new divergence leads to performance increase on benchmark downstream tasks."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8061/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700633698426,
                "cdate": 1700633698426,
                "tmdate": 1700633698426,
                "mdate": 1700633698426,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]