[
    {
        "title": "Guiding Language Models Reasoning with Planning Tokens"
    },
    {
        "review": {
            "id": "T0pBfrh14Z",
            "forum": "UJkgGbLfWA",
            "replyto": "UJkgGbLfWA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8094/Reviewer_UavC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8094/Reviewer_UavC"
            ],
            "content": {
                "summary": {
                    "value": "This paper uses planning tokens to guide large language models for math reasoning problems.  The planning tokens are discrete latent variables, which are append to each reasoning step generated by chain-of-thoughts reasonings.  The authors explore both K-means and Soft-VAE based clustering methods to generate the planning tokens for each reasoning steps.  Empirical experiments on three math reasoning datasets with three language models show the proposed method is effective."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The proposed method is attractive and novel due to the combination with discrete latent variable models with large language models. \n2. The empirical improvements of LLaMa2 (13B) achieved by this method seem to be significant."
                },
                "weaknesses": {
                    "value": "The main method is similar to prefix tuning.  However, there lacks of a strong baselines compared to prefix tuning.  For example, when the cluster number is equal to 5,  simply appending 5 trainable tokens in the front of each question should be a simple prefix-tuning baseline.  What are the performances? \n\n2. All the experiments are based on human annotated reasoning steps on math problems.  It is unknown that how well the proposed method can generalize for automatically produced reasoning steps for general reasoning problems.  Since the title is not specific to math problems,  in order to achieve the wide-range claim in the title, it is necessary to investigate more general reasoning problems. \n\n3.  When doing cluster for each reasoning step, the contextual information of each step seems not explored.  In section 2.3.2, to obtain the representation vector, each reasoning step is separately encoded.  The authors should consider a contextual version, which use the prefix reasoning steps and the question context to generate the representation vectors of the current step. \n4. Soft-VAE is not novel.  Why not simply using VQ-VAE? \n5. Although in the introduction, one important motivation is to address the issues of the reasoning steps progressively drifting away from the correct reasoning flow,  there are on such designs or reasoning in later sections of why the planned token helps on this issue.  In my view,  a hierarchical generation might be better correlated with this motivation.  First, given the question context.   Second, we tune the language models to generate the planning tokens.   Third, and then based on the question context and the planning tokens, for each reasoning step, we first copy a specific planning token generated from  the second step, and then output the reasoning process.  But in this method, the second step is missing, which I therefore hypothesize that there lacks a correspondance between the proposed method and the motivation.  \n6. The analysis of the planning tokens should be enriched. Currently, the analysis is quite weak and not enough."
                },
                "questions": {
                    "value": "1. Do you do the clustering based on the training set or just do the clustering using the test set? \n2. In Section 3.1, why do you subsample 1K test samples from GSM8K and MATH?  Why not using all the test sets? \n3. The optimal setting of the number of cluster can be varied across datasets. It is better to also perform ablation studies on the other dataset. \n\nMinors: \nIn Table 2, the dataset (GSM8K) and the model (LLaMA2 7B) should be explicitly described."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8094/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698573117914,
            "cdate": 1698573117914,
            "tmdate": 1699637002777,
            "mdate": 1699637002777,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "R787LL1uRq",
                "forum": "UJkgGbLfWA",
                "replyto": "T0pBfrh14Z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8094/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8094/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your detailed review. Below is our response to the weakness section:\n\n1. **Compare to prefix tuning**: Please refer to the general response. We have tried the prefix tuning baseline in the early stage of the project; they perform significantly worse than our current baselines: N/A (full fine-tuning/LORA), and General (adding the same prefix tokens in front of each step). We will include these results in our main table.\n2. **Title**: While our proposed method has great potential on applying to various kinds of reasoning, our empirical results are currently focused on the math word problem datasets. We will restrict our title to math reasoning by changing it to: Guiding Language Models Math Reasoning with Planning Tokens\n3. **Contextual information of each step**: We actually have already taken the contextual information into consideration, by using the contextualized embedding of each reasoning step produced by the base LLM. More specifically, we concatenate the question and reasoning steps, and encode the whole sequence with the base LLM. We then average the contextual embeddings of all tokens in a reasoning step. This makes the embedding of each reasoning step conditioned on the previous ones. We will clarify this important detail in the paper.\n4. **VQ-VAE v.s. SQ-VAE**: We actually tried VQ-VAE first, and found it is very unstable to train on the step embeddings, so we switched to a soft version of it. We agree that this soft version of VQ-VAE is not a significantly novel contribution. Instead, this is an implementation choice for our proposed method.\n5. **Hierarchical generation**: Thanks for the suggestion. We tried to adopt a sparse attention scheme in the earlier stage of the project to enforce a stronger dependency constraint between the planning tokens and the reasoning step that follows, similarly to what you are suggesting. More specifically, we modified the attention mask to make the generated step only depend on the corresponding planning tokens and the planning tokens to only depend on the previous planning tokens and the question, however the performance dropped quite dramatically, showing that the flexibility induced by full attention is important for final performance. Also, note that hierarchical generation usually comes at the cost of more difficult parallelization, given that two LLMs (planner and generator) might need to be kept in memory. All in all, these are interesting avenues to be explored, but the simplicity and effectiveness of our approach remain still attractive in our opinion.\n6. **Analysis of planning tokens**: We kindly ask the reviewer to provide some more details on which kind of analysis is missing. In section 3.3, we first provide an analysis of the error rate versus the reasoning length. Then we provide a detailed error taxonomy. Finally, we provide a probing-based analysis of the inference planning token types on page 8, titled \u201cDistinguishability of the Induced Clusterings\u201d.\n\nBelow is our response to the question section:\n\n1. **Clustering**: We only do clustering on the training set. The testing set is not used in our learning process.\n2. **Testing set subsampling**: Because at testing time, the model will need to generate a long sequence of text as the solution, which makes testing slow. Considering our time and computing constraints, we decided to restrict the size of our testing sets to speed up our experiments. Thank you for pointing this out. We will clarify this experimental choice in the paper.\n3. **Ablation on all datasets**: We would love to provide them on all datasets, but we weren\u2019t able to do so because of our time and compute constraints, since these experiments are expensive to run."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8094/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700019981631,
                "cdate": 1700019981631,
                "tmdate": 1700019981631,
                "mdate": 1700019981631,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EALTMNzVcg",
                "forum": "UJkgGbLfWA",
                "replyto": "bSqJ8aebSo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8094/Reviewer_UavC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8094/Reviewer_UavC"
                ],
                "content": {
                    "comment": {
                        "value": "I have read all the rebuttal and the new version.  \n\n1. Why the tunable parameters of Prefix and SQ-VAE are different?  If the number of the planned tokens are the same, the tunable parameters should be the same. \n\n2. For the analysis,  I did not feel the current analysis establish a good connection to why the induced token help on reasoning.  On one side, for different contexts,  if the induced tokens are the same,  do they belong to the similar problems?  On the other side,   if the thoughts belongs to the same pattern for two different problems,  are they intuitive enough for us to interpret we can solve similar problems using the same strategy.  At least some pattern analysis instead of single induced cluster should be reported. \n\nCurrently,  I will keep my original score but if the prefix tuning setting is no problem,  I will improve it to 6.  Thanks."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8094/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700708326196,
                "cdate": 1700708326196,
                "tmdate": 1700708326196,
                "mdate": 1700708326196,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BL11Eu9d5l",
                "forum": "UJkgGbLfWA",
                "replyto": "T0pBfrh14Z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8094/Reviewer_UavC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8094/Reviewer_UavC"
                ],
                "content": {
                    "comment": {
                        "value": "Did you try prefix tuning with LoRa? In this setting, for prefix tuning the tunable tokens are randomly initialized and do not represent an explicit cluster.  For SQ-VAE, the planned tokens are induced by your method. This is the only difference. LoRA is kept the same.   \n In this way, the number of tunable parameters should be the same."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8094/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700723173283,
                "cdate": 1700723173283,
                "tmdate": 1700723215463,
                "mdate": 1700723215463,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "chvPRYgjz9",
            "forum": "UJkgGbLfWA",
            "replyto": "UJkgGbLfWA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8094/Reviewer_9J4w"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8094/Reviewer_9J4w"
            ],
            "content": {
                "summary": {
                    "value": "To tackle the issue of lack of consistency among reasoning steps in solving math word problems, this paper introduces planning tokens to help with \u2018global\u2019 reasoning. Clustering  (Soft Q-VAE) is used to learn the planning tokens along with existing reasoning datasets and parameter efficient fine-tuning. Contributions include the different clustering methods and a detailed error analysis."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- Originality: Most existing work on improving reasoning focuses on better prompting techniques which makes the use of planning tokens more original. \n- Quality: The method development and experimental results are thorough. \n- Clarity: The paper was easy to understand. \n- Significance: Similar to originality, the planing tokens can be widely incorporated into many other ideas."
                },
                "weaknesses": {
                    "value": "- The training process relies heavily on the annotated reasons which limit the flexibility of the model. \n- The performance on the MATH dataset is notably lower than the others."
                },
                "questions": {
                    "value": "- Do the mistakes from the MATH dataset fall under the same error taxonomy (from section 3.3) as the GSM8K and Aqua datasets?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8094/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8094/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8094/Reviewer_9J4w"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8094/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698623381540,
            "cdate": 1698623381540,
            "tmdate": 1699637002645,
            "mdate": 1699637002645,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LuuMJ7q5WJ",
                "forum": "UJkgGbLfWA",
                "replyto": "chvPRYgjz9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8094/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8094/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your positive review!\n\nThe MATH dataset is significantly more difficult compared to the other two datasets. It remains challenging for very strong LLMs, such as GPT-4.\n\n* Data source: The MATH dataset comes from the AMC math competitions. In contrast, GSM8K comes from middle school and high school math exams; AQUA comes from multiple choice GRE math tests. \n* Answer format: The answers of MATH data are free-form text, e.g., Latex expressions such as \\frac{1-\\sqrt{2}}{2}, which makes it hard for the model to get every bit of the answer correctly. In contrast, the answers of GSM8K are single int numbers; the answers of AQUA are single characters, indicating one of the choices. \n\nWhen we summarize the error taxonomy, we take all three datasets into consideration. However, most of the mistakes in the MATH dataset fall in the wrong logic category, as the problems are not that obvious to approach, and the model seems to be confused about what the next step should be. Thanks for pointing this out. We will include an error taxonomy of MATH in the paper."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8094/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700019757256,
                "cdate": 1700019757256,
                "tmdate": 1700019757256,
                "mdate": 1700019757256,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "E4eQeSo214",
            "forum": "UJkgGbLfWA",
            "replyto": "UJkgGbLfWA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8094/Reviewer_C3Cd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8094/Reviewer_C3Cd"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes to augment \"planning tokens\" in reasoning text in fine-tuning LLM and update the embeddings of \"planning tokens\" together with other params. \n\nExperiments show that this trick has positive effects."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper tries multiple ways to infer latent planning token types. \n\nThe experiment results are solid."
                },
                "weaknesses": {
                    "value": "The significance of this paper is low because tuning augmented tokens is not a new thing in NLP and the empirical findings in this paper are not interesting conditioned on previous work. I personally learned nothing from the paper. \n\nThe paper cites no previous work that learns augmented tokens. \n\nRelated references are: \n\nLi and Liang, 2021 Prefix-Tuning\nQin and Eisner, 2021 Learning how to ask"
                },
                "questions": {
                    "value": "NA"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8094/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698721657872,
            "cdate": 1698721657872,
            "tmdate": 1699637002514,
            "mdate": 1699637002514,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xQc3zX93HJ",
                "forum": "UJkgGbLfWA",
                "replyto": "E4eQeSo214",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8094/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8094/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for pointing out the related works that we missed; we will adjust the text accordingly.\n\nWe emphasize that we are not claiming that tuning augmented tokens is a contribution of this work. Many existing works on prompt/prefix tuning [1-3] served as inspiration for our method. The main contribution of our work lies in a particular application of soft tokens for significantly improving the reasoning ability of modern LLMs.\n\nMany differences distinguish our work from [2] and [3]:\n\n* **Latent token type**: All previous approaches assume the ground-truth information about the token type to be given both for training and, crucially, testing. For example, [3] assumes knowledge of the relation type. In our work, we explore a more general setting, in which the token type is a latent variable and we train the reasoning model to directly predict the planning token at inference time. Therefore, the model needs to infer the planning token type from the previous reasoning steps. In one of our baseline settings, we use `Arithmetic` planning tokens, which is a particular case of token type inference informed by prior knowledge: the arithmetic operation can be understood as a relation type that links inputs and reasoning steps. Empirical results (Table 1) show that the planning tokens inferred by K-Means and SQ-VAE always provide better performance than the Arithmetic planning tokens, which indicate the importance of a learning-based token type inference algorithm. \n* **Fixed token location**: Our planning tokens do not have a fixed location in the input prompt as in [1-3]. Instead, they will be freely generated by the model during the inference time, instead of being fed as input prompts. We only provide those inferred planning tokens in the training data, and they are added at multiple places of the sequence, instead of only in the front or in the middle.\n* **Integrability**: Our method is supposed to be integrated into other training/fine-tuning paradigms (e.g. full fine-tuning or LORA) to improve LLM\u2019s math reasoning capacity, instead of using on its own. \n* **Harder task**: In this work, we test the proposed methods on a set of math reasoning tasks, which are arguably more difficult than the relation completion tasks used in [3]. Our method is designed to specifically enhance the reasoning abilities of modern decoder-only LLMs. This is in contrast to [3], which is built for relation completion tasks in the context of masked LMs. As shown in the general response, simple prompt/prefix tuning systems underperform in our setting.\n\nTo address the reviewer's statement on novelty, we reiterate our contributions which distinguish us from the related work raised in the review:\n\n* As shown in our general response, traditional prompt/prefix tuning techniques do not work well on hard math reasoning tasks, our method redesigned the old paradigm and turned it into a strong auxiliary technique to improve the math reasoning capabilities of other fine-tuning paradigms.\n* Planning tokens improve the intra-step consistency of the generated solution, and increase the model\u2019s reasoning capacity by specializing it to different reasoning types.\n* Our method is able to infer the type of latent planning tokens instead of using fixed, predefined types.\n\n[1] Lester, Brian, Rami Al-Rfou, and Noah Constant. \"The Power of Scale for Parameter-Efficient Prompt Tuning.\" Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 2021.\n\n[2] Li, Xiang Lisa, and Percy Liang. \"Prefix-Tuning: Optimizing Continuous Prompts for Generation.\" Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021.\n\n[3] Qin, Guanghui, and Jason Eisner. \"Learning How to Ask: Querying LMs with Mixtures of Soft Prompts.\" Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT). 2021."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8094/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700019646015,
                "cdate": 1700019646015,
                "tmdate": 1700019646015,
                "mdate": 1700019646015,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SHqIww5C64",
                "forum": "UJkgGbLfWA",
                "replyto": "7XBgjaoIRu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8094/Reviewer_C3Cd"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8094/Reviewer_C3Cd"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate your clarification and new results. But I am not convinced of the contribution of this work and let me try to explain. \n\n> The main contribution of our work lies in a particular application of soft tokens for significantly improving the reasoning ability of modern LLMs.\n\nFirst, application of soft tokens to a specific reasoning task is not a technical innovation by itself, unless well-suited architectural or methodological changes have been made for this application. \n\nSecond, repitching this paper needs significant structural revisions of the paper, in parallel to the local clarifying edits that you have already done (thank you for doing it btw). \n\n> ground-truth information about the token type to be given both for training and, crucially, testing.\n\nI doubt this. \n\nThe idea of using soft tokens is to tune input embeddings of some new token types, which may or may not be initialized with existing tokens. In [3], some tokens are initialized in sophisticated ways, but it doesn't mean that their token types are restricted, does it? \n\n> they will be freely generated by the model during the inference time, instead of being fed as input prompts. We only provide those inferred planning tokens in the training data, and they are added at multiple places of the sequence, instead of only in the front or in the middle. \n\nI agree that this is a new technique, for which I would like to consider raising my score. \n\nBut I am afraid this technique is still in a broken / limited form. \n\nCorrect me if I am wrong: do you learn to infer the position of latent tokens during training? If not, then inference will mostly mimic what the LM has seen during training, right? Then what drives the generation of latent tokens is still where you choose to place them in training data, right? \n\nIn addition, as I understand of [1]-[3], \"prefix-tuning\" is just a name and soft tokens are also added somewhere else but not only at the beginning of the prompts. \n\n> improve LLM\u2019s math reasoning capacity,\n\nWhy math specifically but not other kinds of reasoning? Why not language modeling in general? The argument for math seems arbitrary to me."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8094/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688890676,
                "cdate": 1700688890676,
                "tmdate": 1700688890676,
                "mdate": 1700688890676,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "XP3HmzAGY8",
            "forum": "UJkgGbLfWA",
            "replyto": "UJkgGbLfWA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8094/Reviewer_1L1z"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8094/Reviewer_1L1z"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the way of using planning tokens to improve LLMs on reasoning consistency. Experiment results show that the proposed method outperforms finetuning LLMs directly. Analysis results provide intuitions to show how the proposed method works."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Generally, this is a good paper. The paper is well-written, and the idea is quite interesting. The proposed method is novel and comprehensive experiments are done to prove that the method works."
                },
                "weaknesses": {
                    "value": "The proposed method is similar to prefix-tuning. This could be added as a baseline for comparison. Besides, there are some prompt-based methods targeted for reasoning consistency, which can also be added in experiments. Only comparing with full finetuning may not be enough."
                },
                "questions": {
                    "value": "See weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8094/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698769812398,
            "cdate": 1698769812398,
            "tmdate": 1699637002368,
            "mdate": 1699637002368,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bCLBgjf9Wl",
                "forum": "UJkgGbLfWA",
                "replyto": "XP3HmzAGY8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8094/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8094/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your positive review. We have tried prefix-tuning baselines in the early stage of the project; they were significantly worse than our current baselines: N/A (full fine-tuning/LORA), and General (adding the same prefix tokens in front of each step). Please refer also to the general response. Thanks for pointing this out. We will update these results in our result section and add discussion.\n\nWe kindly ask the reviewer to further clarify which prompt-based methods they referred to as our potential baselines. We are happy to add them!\n\n[1] Lester, Brian, Rami Al-Rfou, and Noah Constant. \"The Power of Scale for Parameter-Efficient Prompt Tuning.\" Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 2021.\n\n[2] Li, Xiang Lisa, and Percy Liang. \"Prefix-Tuning: Optimizing Continuous Prompts for Generation.\" Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8094/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700019336765,
                "cdate": 1700019336765,
                "tmdate": 1700019336765,
                "mdate": 1700019336765,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]