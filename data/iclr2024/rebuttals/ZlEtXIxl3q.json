[
    {
        "title": "Contrastive losses as generalized models of global epistasis"
    },
    {
        "review": {
            "id": "DBqqjtyL9a",
            "forum": "ZlEtXIxl3q",
            "replyto": "ZlEtXIxl3q",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission262/Reviewer_68Sm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission262/Reviewer_68Sm"
            ],
            "content": {
                "summary": {
                    "value": "A global epistasis model for protein fitness assumes that the observed experimental fitness is g(f(x)), where x is the protein sequence, f is a simple (perhaps additive) function of the sequence, and g is a scalar -> scalar nonlinear function that reflects the non-linearity of the measurement process. The goal is to identify the latent function f(). They explore the use of learning-to-rank losses when fitting this model, as these losses are invariant to any monotone g(). They draw on some results from the compressed sensing literature, some experiments on synthetic data, and some experiments on a standard protein fitness prediction benchmark to argue that fitting models with a loss based on the Bradley-Terry ranking model is better than using mean squared error."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "I liked section 2.1. I think that the 'epistatic domain' is a nice formalism for reasoning about a particular kind of sparsity of the fitness landscape, and I'll use this in the future.\nI appreciate that the paper calls more attention to global epistasis. It's an elegant idea that is often overlooked."
                },
                "weaknesses": {
                    "value": "All of the experiments evaluate fitness prediction in terms of spearman correlation. It's not surprising that training using a BT loss improves spearman correlation vs. MSE, since the BT loss can be seen as a differentiable relaxation of the negative spearman correlation. Therefore, I didn't find this result particularly exciting. It is a common observation in machine learning that a particular downstream metric can be improved by using a loss function that approximates it, and the learning-to-rank framework described in this paper is well established.\n\nSimilarly, I don't agree with the assertion that spearman correlation is a good surrogate metric for a model's usefulness for protein engineering. Suppose that fitness values appear in the range [0, 10] and that the best fitness seen so far in a protein engineering project is 6. Since we want to use this model to design new proteins, we don't care if it predicts 3 for a protein that actually has fitness 2. On the other hand, predicting 5.5 for a protein that has true fitness 6.5 could lead to a missed opportunity for ML-guided design. Good eval metrics should think asymmetrically about precision vs. recall of finding proteins with good fitness, etc. Finally, spearman correlation is confusing because it's unclear what the optimal value is. Given the noise level of the assay, I know the optimal MSE. What's the optimal spearman correlation, though?\n\nThe paper's goal is to fit models on experimental data to estimate a latent fitness function. However, the exposition assumes that these observations are noiseless, which is quite unrealistic. Further, in my experience noise is often heteroskedastic, where the noise level can be assumed to depend on g(f()). For example, the read-out from many assays is baesed on counts from DNA sequencing, and these are subject to Poisson noise. The BT loss strikes me as being not particularly robust to noise, since it could easily flip the binary fitness(A) > fitness(B) label if the noise is large relative to the difference between the fitness of A and B. \n\nSection 3.2  on the 'fitness-epistasis uncertainty principle' is grounded in some results from the compressed sensing literature. It's interesting background on CS, and I enjoyed reading it, but I found the conclusions from the section too informal to be useful.\n\nI found that the paper wasn't sufficiently grounded in standard statistical terminology about model estimation. Can you please discuss the identifiability of the global epistasis model? Does the change of loss function change identifiability? Also, you claim that the BT loss will result in better sample complexity. Maximum likelihood estimation has optimal sample complexity for parameter identification. Can you discuss the suitability of the BT loss in terms of whether the BT model reflects the observation process for the data? Is the goal to identify the latent function f()? What does that mean when f() is only identifiable up to a monotonic transformation (since the inverse transformation could be absorbed into g)?\n\nIn my prior reading on global epistasis, I hadn't seen the assumption that g() was monotonic. In many situtations, this isn't the case. For example, for many genes in the body it is hazardous if too much or too little of it is expressed, so g() is an upside-down U. In my experience with enzyme engineering, if an enzyme is too active it may kill the host cell used to express it. It seems that your framework does not generalize to this case."
                },
                "questions": {
                    "value": "Can you please respond to my 'weaknesses' section?\n\nHow would your theoretical results or results on N-K landscapes change if the observed fitness values had noise added?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission262/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697655192442,
            "cdate": 1697655192442,
            "tmdate": 1699635951863,
            "mdate": 1699635951863,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "WFNHiBdllc",
                "forum": "ZlEtXIxl3q",
                "replyto": "DBqqjtyL9a",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission262/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission262/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response to Reviewer 68Sm (part 1)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the thoughtful comments. We are eager to work with the reviewer to improve the paper and are hopeful that our point-by-point response below will help alleviate their most pressing concerns.\n\n> All of the experiments evaluate fitness prediction in terms of spearman correlation. It's not surprising that training using a BT loss improves spearman correlation vs. MSE, since the BT loss can be seen as a differentiable relaxation of the negative spearman correlation. Therefore, I didn't find this result particularly exciting. It is a common observation in machine learning that a particular downstream metric can be improved by using a loss function that approximates it, and the learning-to-rank framework described in this paper is well established.\n\nWe agree with the reviewer that the improved performance of the BT loss over the MSE loss in terms of Spearman correlation is intuitive. However, the BT loss has not been used for fitness prediction previously and we were able to achieve improved performance on a metric that is common in the field (Spearman correlation). This is still an important contribution, even if the result is intuitive in retrospect.\n\nFurther, the improved performance in benchmark tasks of models trained with the BT loss is not the only contribution of the paper. We have demonstrated that the BT loss is an effective technique for modeling global epistasis that allows one to recover a latent fitness function. Recovering such a latent fitness function is a problem that has been approached by a number of previous papers (Sailer & Harms, 2017 and Otwinowski et al., 2018 being two prominent examples), and we have shown that our method can do so while making fewer assumptions about the form of the global epistasis nonlinearity than these previous works (which are assumed to be power transforms or 3-splines in the aforementioned papers). The task of recovering a latent fitness function is important because it removes the spurious, or \u201cphantom\u201d, epistatic interactions that appear in a fitness function that has been affected by global epistasis, allowing for proper interpretation of the primary interactions that drive fitness. The latent fitness function is often interesting biologically as it can be a better measure of biophysical properties when the global non-linearity is caused by an artifact of the measurement process. Effectively solving this problem is a contribution of our paper, outside of the performance on benchmark tasks. We will clarify this in the introduction and discussion of our paper.\n\nPlease see the following comments for the rest of our response to the reviewer."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission262/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700168155106,
                "cdate": 1700168155106,
                "tmdate": 1700168355865,
                "mdate": 1700168355865,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LELy5vUIQI",
                "forum": "ZlEtXIxl3q",
                "replyto": "DBqqjtyL9a",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission262/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission262/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response to Reviewer 68Sm (part 2)"
                    },
                    "comment": {
                        "value": "> Similarly, I don't agree with the assertion that spearman correlation is a good surrogate metric for a model's usefulness for protein engineering. Suppose that fitness values appear in the range [0, 10] and that the best fitness seen so far in a protein engineering project is 6. Since we want to use this model to design new proteins, we don't care if it predicts 3 for a protein that actually has fitness 2. On the other hand, predicting 5.5 for a protein that has true fitness 6.5 could lead to a missed opportunity for ML-guided design. Good eval metrics should think asymmetrically about precision vs. recall of finding proteins with good fitness, etc. \n\nWe have used test set Spearman correlation as our primary metric for assessing model performance because it is commonly used in benchmarking fitness prediction methods (see the [FLIP](https://benchmark.protein.properties) and [ProteinGym](https://www.proteingym.org/home) benchmarks for two prominent examples that employ Spearman correlation as the primary metric). We will clarify this in the paper, as it is not explicitly stated as our motivation for using Spearman correlation. \n\nHowever, we agree with the reviewer that the primary concern for protein engineering is tail performance rather than bulk correlation. In order to strengthen the results of the paper, we have now done an initial comparison of the tail performance of models trained with the BT and MSE losses on the GB1 predictions tasks in the FLIP benchmark. We follow [Gelman et al., 2021](https://www.pnas.org/doi/10.1073/pnas.2104878118) and consider the recall of the models in classifying the top sequences in the test set. In particular, we calculate the top 10% recall as the fraction of the sequences in the true top 10% of sequences in the test set that are in the top 10% of model predictions on the test set. For all splits except the Sampled split, models trained with the BT loss achieve statistically significant (p < 0.05) improvements over models trained with the MSE loss. In the case of the Sampled split, the MSE loss performs slightly better, but the difference is not statistically significant. The results of this analysis are summarized in the table below, where entries in the table correspond to the mean +/- std.dev. of top 10% recall over 10 random restarts of the models:\n\n| Split   | Bradley-Terry | MSE |\n| ----------- | ----------- | -----------|\n| Low-vs-High | 0.442 +/- 0.024  | 0.381 +/- 0.028 | \n| 1-vs-Rest | 0.138 +/- 0.051| 0.097 +/- 0.030 | \n| 2-vs-Rest | 0.282 +/- 0.008| 0.250 +/- 0.030 | \n| 3-vs-Rest | 0.664 +/- 0.014| 0.539 +/- 0.084 | \n| Sampled | 0.815 +/- 0.010| 0.823 +/- 0.010 |\n\nWe will add these results, as well as corresponding results for the AAV and Meltome FLIP benchmarks to the Appendix and discuss the importance of metrics such as the top 10% recall for protein engineering in the main text.\n\n> Finally, spearman correlation is confusing because it's unclear what the optimal value is. Given the noise level of the assay, I know the optimal MSE. What's the optimal spearman correlation, though?\n\nIn the paper\u2019s noiseless simulations, the optimal spearman is 1. Given a noise level of an assay, it is possible to find the optimal spearman by parametric resampling of the noise on the test set. In realistic fitness prediction scenarios, the correct noise model is unknown and complex so one cannot know either the optimal Spearman nor MSE. The reviewer\u2019s concern of course applies to all papers that use Spearman correlation as a metric, and it is outside the scope of our paper to resolve this broader concern.\n\nPlease see the following comments for the rest of our response to the reviewer."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission262/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700168316010,
                "cdate": 1700168316010,
                "tmdate": 1700168347125,
                "mdate": 1700168347125,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CnRUssiXP0",
                "forum": "ZlEtXIxl3q",
                "replyto": "bQSWY5ClYO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission262/Reviewer_68Sm"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission262/Reviewer_68Sm"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the detailed response.\n\nI think we all agree that the use of spearman correlation in the literature is fraught, and that it's worth using it for the sake of comparison to prior work, as long as we consider other evaluation metrics too.\n\nIn my initial review I asked for some clarification about how your proposed results on recovery of the latent fitness function extend to a practical setting where there is noise in the assay. It would be easy to add noise in your simulation environment. How does that change things? In particular, noise occurs in two places. The latent fitness function is noisy (e.g., cells can be at different points in their life cycle and this affects all sorts of genotype-fitness relationships) and the experimental readout is noisy (due to NGS, masspec, etc). \n\nAlso, I don't see a satisfactory definition of what it means to 'recover' the latent fitness function. Can you please formally define this?"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission262/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700511069590,
                "cdate": 1700511069590,
                "tmdate": 1700511069590,
                "mdate": 1700511069590,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "JJmIDjiqw9",
            "forum": "ZlEtXIxl3q",
            "replyto": "ZlEtXIxl3q",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission262/Reviewer_7udB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission262/Reviewer_7udB"
            ],
            "content": {
                "summary": {
                    "value": "In this study, optimization of Bradley-Terry (BT) contrastive loss is proposed to recover the latent fitness function corrupted by the effect of global epistasis. The proposed approach relies on the monotonic property of the global epistatic effect and does not require any assumption on the exact model of global epistasis. With simulated data, it is shown that BT loss achieves better estimation of fitness function than MSE loss, and it is more robust to the extent of corruption, measured by the entropy of epistatic representation, caused by the global epistasis. The advantage of using BT loss is also demonstrated for the protein fitness prediction on different splits of GB1, AAV, and thermostability datasets designed by the FLIP benchmark."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1)\tDemonstrating the benefits of a ranking based loss for fitness prediction\n2)\tNice experiments were designed to show the advantage of the contrastive loss in recovering the latent fitness model corrupted by global epistasis."
                },
                "weaknesses": {
                    "value": "See questions below"
                },
                "questions": {
                    "value": "1)\tWhat statistical test was used to measure the significance of improvements in Figure 3? I am asking this because in some splits the performance of BT loss is almost the same as MSE loss, but the reported p-value is significant (examples: samples and 7-vs-rest in AAV).\n2)\tIn the splits where BT loss provides better performance (Figure 3), it is hypothesized that **it could be partially due to the corruption of fitness function with global epistasis**. I am curious to know how this can be proved.\n3)\tIn Figure 1, are the coefficients in the epistatic domain normalized? The scale of $\\hat{f}$ does not match f, which is expected.\n4)\tHave you also tested BT loss on fitness prediction for other datasets such as the ones compiled by the DeepSequence paper (https://www.nature.com/articles/s41592-018-0138-4)? I understand the use of FLIP datasets for the task of benchmark, however I am not sure how challenging FLIP splits are compared to other datasets out there.\n5)\tWhere do you expect ranking-based losses not to perform as good as MSE losses for protein fitness prediction?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission262/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission262/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission262/Reviewer_7udB"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission262/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698828514107,
            "cdate": 1698828514107,
            "tmdate": 1699635951794,
            "mdate": 1699635951794,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "EGxg0vmmRJ",
                "forum": "ZlEtXIxl3q",
                "replyto": "JJmIDjiqw9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission262/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission262/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 7udB (part 1)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the helpful feedback. We are hopeful that we can resolve each of the reviewer\u2019s concerns in the specific responses below:\n\n> 1. What statistical test was used to measure the significance of improvements in Figure 3? I am asking this because in some splits the performance of BT loss is almost the same as MSE loss, but the reported p-value is significant (examples: samples and 7-vs-rest in AAV). \n\nWe used a standard independent t-test with Bonferroni correction for multiple comparisons. Despite the bars having the visually similar heights, the differences between the methods are significant because the error bars over the random restarts for many of the splits are very small. For example, in the AAV \u201cSampled\u201d split, the standard deviations of spearman correlations for the MSE and Bradley Terry losses are about 7e-4 and 4e-4, respectively. We will add a Table to the Appendix containing the numerical means and standard deviations for all of the bars shown in Figure 3, in order to clarify why the differences are significant.\n\n> 2. In the splits where BT loss provides better performance (Figure 3), it is hypothesized that it could be partially due to the corruption of fitness function with global epistasis. I am curious to know how this can be proved.\n\nWe do not know of a straightforward path towards proving or disproving this hypothesis. The hypothesis was based on the analogy between the improved performance of the Bradley-Terry loss over the MSE loss in the simulated case when global epistasis was present, and the improved performance of the Bradley-Terry loss over the MSE loss in the case of real data. There may be multiple reasons for the improved performance in real data, and we do not immediately know how we could prove that the improved performance is due to the presence of global epistasis. Therefore, we will remove this sentence from the text in order to avoid making an untestable hypothesis.\n\n> 3. In Figure 1, are the coefficients in the epistatic domain normalized? The scale of f_hat does not match f, which is expected.\u201d\n\nYes, the coefficients in the epistatic domain are normalized such that the sum of the squared magnitudes sum to one. We will correct the axis label and figure caption to clarify this. \n\nPlease see the next comment for the rest of our response."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission262/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700069614547,
                "cdate": 1700069614547,
                "tmdate": 1700069614547,
                "mdate": 1700069614547,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7DlO7510he",
            "forum": "ZlEtXIxl3q",
            "replyto": "ZlEtXIxl3q",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission262/Reviewer_uFyB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission262/Reviewer_uFyB"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors focus on the problem of inferring fitness functions from experimental data, a relevant problem for protein engineering. To this end, the authors propose utilizing contrastive losses, such as the Bradley-Terry loss, to extract the underlying latent function from a global epistasis model. Furthermore, the authors argue that the choice of a contrastive loss may have other advantages of Mean Squared Error, especially for estimating ranking functions. They evaluate their approach on the FLIP dataset."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Contrastive learning has demonstrated promise in the field of computer vision; this paper shows a novel application of this concept to the field of Biology.\n\n2. The paper has a strong theoretical foundation and is well presented. \n\n3. Quantitative results are convincing and promising."
                },
                "weaknesses": {
                    "value": "1. The empirical evaluation has focused only on a single benchmark, FLIP. It would strengthen the paper if the approach was validated with even more datasets."
                },
                "questions": {
                    "value": "1. Is there any way to extend the empirical evaluation beyond the FLIP benchmark?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission262/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699546123957,
            "cdate": 1699546123957,
            "tmdate": 1699635951704,
            "mdate": 1699635951704,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "leaeW1Yv0e",
                "forum": "ZlEtXIxl3q",
                "replyto": "7DlO7510he",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission262/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission262/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer uFyB"
                    },
                    "comment": {
                        "value": "We thank the reviewer for reading the paper and providing helpful comments. Responses to specific comments below:\n\n> Is there any way to extend the empirical evaluation beyond the FLIP benchmark?\n\nProteinGym (https://www.proteingym.org/home) is another benchmark besides FLIP that can be used to validate sequence-to-fitness prediction models for proteins. This benchmark contains 94 curated datasets that relate sequences to experimentally-determined fitness values for a wide variety of proteins. ProteinGym is larger than FLIP; however, FLIP has a number of advantages that make it more appropriate for our use case:\n1. FLIP curates specific dataset splits that are relevant for protein engineering (e.g. the two-vs-many split in which one predicts the fitness of sequences with 3 or more mutations using data only from sequences 2 or fewer mutations). These splits can be far more challenging for supervised models than a standard uniform split. In contrast, ProteinGym only curates complete datasets which the user must split themselves (usually by a standard uniform split). Therefore, FLIP provides a more challenging and diverse set of prediction tasks than ProteinGym, despite being an overall smaller benchmark.\n2. ProteinGym was curated primarily to benchmark zero-shot prediction from pre-trained Protein Language Models. Therefore, the benchmark results that are presented on the ProteinGym webpage are not directly comparable to results from training a supervised model on the data. In contrast, FLIP was curated specifically to benchmark supervised sequence-to-fitness models for proteins, and therefore our results are directly comparable to those presented in the FLIP paper.\n\nDespite these advantages of FLIP, we have now downloaded the ProteinGym benchmark data and begun to compare models trained with the MSE and Bradley-Terry losses on this data. At this time, we have only been able to run this comparison on one of the ProteinGym datasets: CAPSD_AAV2S_Sinai_substitutions_2021. For this dataset, we created 10 uniform 80/20 train/test splits and trained CNNs on each of the training datasets, using either the MSE or Bradley-Terry loss and all of the same model and training parameters as is used in the FLIP benchmark. We then calculated the Spearman correlation between the test set labels and model predictions in each corresponding test set. In this case, the models trained with the Bradley-Terry loss achieved a small but statistically-significant performance gain over the MSE loss (Spearman=0.9089 +/- 0.0038 and Spearman=0.9048 +/- 0.0037 for the Bradley-Terry and MSE losses, respectively, with p=0.027). If the reviewer thinks it will strengthen the paper, then we are happy to run this test for more of the ProteinGym datasets and add a table to the appendix displaying the results, though we will be unlikely to test all 94 datasets due to time and compute constraints."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission262/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700069130925,
                "cdate": 1700069130925,
                "tmdate": 1700069130925,
                "mdate": 1700069130925,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "OvxxkoyJ7v",
            "forum": "ZlEtXIxl3q",
            "replyto": "ZlEtXIxl3q",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission262/Reviewer_6v5p"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission262/Reviewer_6v5p"
            ],
            "content": {
                "summary": {
                    "value": "This study explores the estimation of fitness functions in protein engineering, which are complex mappings from biological sequences to properties of interest. The authors focus on global epistasis models that use a sparse latent fitness function transformed by a monotonic nonlinearity to predict measurable fitness.\n\nContribution: In this supervised learning setting, the authors introduce a rank-based contrastive loss approach, and show that it yields better results than an MSE loss-based approach (especially for small datasets), using both simulations and a benchmark dataset."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Innovative use of supervised contrastive learning for fitness prediction.\n- Empirical validation of proposed methods using simulations."
                },
                "weaknesses": {
                    "value": "- presentation could be improved\n- More results are needed in order to delineate the regimes where the presented results hold true\n- Absence of simple baselines for comparative analysis"
                },
                "questions": {
                    "value": "1) Clarity on \"Corrupting Data\": While recognising that the term \"corrupting data\" might be specific jargon within the authors' field, I find its usage potentially confusing. It typically suggests that data has been made less accurate. In contrast, from a machine learning standpoint, the issues you're addressing appear to be related to the complexity introduced by non-linear relationships, which need complex models that may overfit, particularly when models are trained to predict the exact observed values (y).\n\n2) It would be highly beneficial to demonstrate the specific regimes in which your observations about the Bradley-Terry loss are valid. Specifically, it's important to determine whether the improvements attributed to the BT loss over the MSE loss are unique to the complex models with epistatic interactions, or if similar benefits could be observed with simpler models, such as a linear model subjected to the same monotonic warping (i.e., the nonlinearity introduced by global epistasis). To address this, I recommend varying the degree of interaction order in your simulations.\n\n3) I would recommend including a comparison with a more straightforward baseline to further validate the proposed approach. Specifically, it would be informative to see how a simple quantile transformation of the outcome data (to uniform or Gaussian distributions) performs in conjunction with Mean Squared Error (MSE) loss. This could serve as a more direct way to deal with the non-linear transformations introduced by global epistasis and might provide a competitive baseline to the BT loss approach.\n\n4) Minor: To avoid confusion with unsupervised contrastive learning methods, it would be beneficial to explicitly state that the contrastive learning approach employed is supervised. (e.g., you could say \"supervised contrastive learning loss\")\n\nIf the authors can address these concerns and provide clarifications, I would be open to revisiting and potentially improving my score."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission262/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699576283003,
            "cdate": 1699576283003,
            "tmdate": 1699635951638,
            "mdate": 1699635951638,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "j56vxumjJl",
                "forum": "ZlEtXIxl3q",
                "replyto": "OvxxkoyJ7v",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission262/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission262/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 6v5p"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the helpful feedback. We are eager to provide new experiments and writing clarifications to respond to each of the concerns of the reviewer. We respond to each question in turn below:\n1. **On \u201ccorruption\u201d language**: it is helpful to know that this is confusing language. We had meant to use it to refer to the effect that global epistasis produces a dense epistatic representation (similar to the effect of noise), which results in higher sample complexity. The reviewer\u2019s point is well taken that this is a distinct negative outcome from the effects of noise and therefore we should not use \u201ccorruption\u201d to refer to global epistasis. We will update the manuscript to remove this language.\n2. **On testing our methods with varying degrees of interaction orders**: We agree that testing our method for different degrees of interaction order is useful. We repeated the simulation described in Section 3.1 (\u201cRecovery from complete data\u201d) with K=1 (i.e. an additive latent fitness function) and K=3 (up to third-order interactions), in addition to the K=2 setting used in the main text; the results of these additional simulations are shown in Appendix B of the initial submission, which was mistakenly not referenced in the main text (we will add a reference in Section 3.1). These results show that the complete data recovery result is maintained in for all of these interaction order regimes. Further, we have now repeated the simulation results described in Section 3.3 (\u201cSimulations with incomplete data\u201d) for K=1 and K=3 and these results will be added to the Appendix. We have created analogous figures to Figure 2b and 2c using the results from these K=1 and K=3 simulations. Comparing these to Figure 2b and 2c (which are based on simulations using K=2) we find that:\n\n   * The results in Figure 2b are qualitatively similar to the analogous results for the K=1 and K=3 simulations. In particular, the MSE loss shows a clear drop in performance as the entropy of the observed fitness function increases, while the Bradley-Terry loss is more robust to this increase in entropy.\n\n   * The results in Figure 2c are qualitatively similar to the analogous results for the K=1 and K=3 simulations. In the K=1 case, the distinction between the MSE and Bradley-Terry losses is not as large as in the K=2 and K=3 cases, because both losses are able to achieve high performance at small training set sizes (i.e. spearman > 0.9 at 100 training samples). However, if we increase the intensity of the nonlinearity by using a setting of alpha=20 instead of alpha=10, then the distinction between the losses is similar to that observed in Figure 2c. This indicates that the Bradley-Terry loss can still be useful for modeling additive latent fitness functions under global epistasis, but the nonlinearity of global epistasis must be more extreme to observe large performance gains over the MSE loss. The results of these simulations for the alpha=20 setting will also be added to the Appendix.\n3. **On comparing to a baseline method based on quantile transformations**: We thank the reviewer for suggesting this baseline method. We have tested this baseline method in a simulation analogous to that described in Section 3.1 (\u201cRecovery from complete data\u201d); in particular we tested the ability of quantile transformation to recover a latent fitness function from complete data that has been affected by global epistasis. We found that quantile transformations do perform quite well at recovering the latent fitness function (R^2 =0.951 and R^2=0.963 for quantile transformations to normal and uniform distributions, respectively), but not as well as the Bradley-Terry loss (R^2=0.999, as seen in Figure 1c in the main text). Further, we are committed to testing the baseline method in the simulations described in Section 3.3 (\u201cSimulations with incomplete data\u201d) in order to compare the baseline to the Bradley-Terry loss in a more realistic scenario. \nWe note that the baseline method described by the reviewer makes stronger assumptions about the nature of the latent fitness function than the Bradley-Terry loss, and this may be the reason for the difference in performance in the complete data case. In particular, the baseline method assumes the latent fitness function follows either a uniform or normal distribution, while the Bradley-Terry loss makes no such assumption. Considering that these methods are similar in their implementation difficulty (both require fewer than 10 lines of code), the Bradley-Terry loss is preferable because it requires fewer assumptions and appears to provide better performance. \n4. **On clarifying that we use supervised contrastive losses**: It is helpful to know that this is a point of confusion. We will add a sentence to the Methods that clarifies that we use supervised rather than unsupervised contrastive losses, and reinforce this point by referring to \u201csupervised contrastive losses\u201d wherever appropriate."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission262/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700006621877,
                "cdate": 1700006621877,
                "tmdate": 1700006621877,
                "mdate": 1700006621877,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "le4JRsSzX8",
                "forum": "ZlEtXIxl3q",
                "replyto": "OvxxkoyJ7v",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission262/Reviewer_6v5p"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission262/Reviewer_6v5p"
                ],
                "content": {
                    "title": {
                        "value": "Remaining concerns"
                    },
                    "comment": {
                        "value": "Thank you for your detailed responses and for the openness to address the provided feedback.\n\n1) Thanks, glad you found this comment helpful. Minor, but will make your work more accessible and impactful.\n\n2) Regarding the effectiveness of the Bradley-Terry loss across varying interaction orders (K=1, K=2, and K=3), I've noticed a potential disconnect between the presentation in your paper and the data provided. It appears that the benefits of the Bradley-Terry loss are not solely tied to the complexities of epistasis (K>1), but are also evident in simpler scenarios such as K=1, which representing warped latent additive models. This observation suggests that the advantages of the Bradley-Terry loss may extend beyond handling epistatic interactions to include any scenario with non-Gaussian outcomes. It's crucial to explicitly address this in your paper, as it could significantly broaden the applicability and understanding of the Bradley-Terry loss's effectiveness.\n\n3) In your response, you mention testing the ability of quantile transformation to recover a latent fitness function from complete data affected by global epistasis. I think the baselines should be quantile transformation, then training with MSE loss. Is this what you have done?\nOn the comments you made on the number of lines of code: while the Bradley-Terry loss may be concise in terms of code implementation, it is essential to consider the broader aspects of simplicity, particularly in terms of conceptual understanding and practical application. The contrastive nature of the Bradley-Terry loss, focusing on pairwise comparisons, represents a paradigm shift from more traditional regression-based approaches. Rank-transformation + train with MSE remains the simple baseline to beat here.\n\n4) My comment refers more to the abstract and intro. This is a supervised ML setting. It is beneficial to make this clear early in the paper. Btw, this is very minor at this point."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission262/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700068420734,
                "cdate": 1700068420734,
                "tmdate": 1700068447171,
                "mdate": 1700068447171,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]