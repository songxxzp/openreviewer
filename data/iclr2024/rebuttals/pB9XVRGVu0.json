[
    {
        "title": "GeRA: Label-Efficient Geometrically Regularized Alignment"
    },
    {
        "review": {
            "id": "Tm1FCDxRXe",
            "forum": "pB9XVRGVu0",
            "replyto": "pB9XVRGVu0",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6501/Reviewer_gPXV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6501/Reviewer_gPXV"
            ],
            "content": {
                "summary": {
                    "value": "The manuscript presents a novel semi-supervised method termed as Geometrically Regularized Alignment (GeRA) to effectively align the embedding spaces of pretrained encoders. This approach is characterized by its alignment of two distinct latent spaces into a unified space, leveraging a dual penalty system. The first penalty is a contrastive loss that ensures corresponding points in these spaces are brought close together, while the second, a geometric loss, preserves the inherent local geometry of spaces as learned by the pretrained encoders. A distinguishing feature of this work is the introduction of the geometric loss, which constructs a kernel matrix over neighbors for each sample, aiming to minimize potential distortions when projecting each space in the shared one."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The manuscript stands out for its clarity and coherent flow, providing readers with a well-motivated and well-structured presentation.\n- The GeRA method's modality-agnostic nature makes it broadly applicable wherever pretrained models are utilized.\n- The introduction of geometric regularization in this context is both original and intuitive, to the best of the reviewer knowledge. The simplicity of the idea that neighboring points in the source spaces should remain neighbors in the aligned space, thus preserving the semantic structures, is a strength of this work.\n- The ablation studies presented in the paper are  comprehensive and convincing, enhancing  the presented results.\n- The benchmark against ASIF, and subsequently extending this comparison to other pretrained models, is a strong selling point.  \n- A well-thought hyperparameter search has been executed. Notably, also the competitor ASIF has gone through an hyperparameter search."
                },
                "weaknesses": {
                    "value": "- While the paper reports performance improvements, it lacks clarity on their statistical significance. For instance, when a 3% improvement in performance is highlighted, it becomes crucial to understand the variance arising from different initialization seeds. Reporting standard deviations would have offered a clearer picture of the model's robustness and reliability.\n- The manuscript introduces additional hyperparameters, yet it does not provide sufficient insight into their impact on downstream performance. Without guiding intuition, the only approach seems to be extensive hyperparameter tuning, which might be computationally expensive and time-consuming.\n- The discussion regarding inference time, particularly in relation to ASIF that performs vector search (i.e. retrieval) using cosine similarity, may be misleading. Existing libraries, such as faiss [1], offer methodologies for more efficient vector searches (e.g., approximate or hierarchical techniques). As such, the paper's emphasis on superior performance compared to a naive ASIF implementation could potentially be misleading to the reader.\n- There is no publicly available code to reproduce the work.\n\nOverall, I think this paper is good enough to be accepted. However, the work would benefit from further validation, specifically regarding the statistical significance of the improvements reported. *The reviewer is ready to further raise the score if the authors present additional evidence regarding the statistical significance.*\n\n---\n\n[1] Johnson, Jeff, Matthijs Douze, and Herv\u00e9 J\u00e9gou. 2017. \u201cBillion-Scale Similarity Search with GPUs.\u201d, IEEE Transactions on Big Data."
                },
                "questions": {
                    "value": "- The manuscript does not discuss the interplay between the density of the latent space and the preservation of its geometry. In particular for spaces where the points density changes in different regions, it may be problematic to use the same neighbors selection strategy for the whole space\n - The paper presents notably low performance figures for ASIF in the domain of speech-text alignment. How do these figures relate to the findings of [2] when using ASIF? An explanation or a comparative insight would help in contextualizing the reported results better and understanding potential disparities or improvements.\n\n---\n\n[2] Gary Wang, Kyle Kastner, Ankur Bapna, Zhehuai Chen, Andrew Rosenberg, Bhuvana Ramabhadran, and Yu Zhang. Understanding shared speech-text representations. In ICASSP 2023-2023  IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6501/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6501/Reviewer_gPXV",
                        "ICLR.cc/2024/Conference/Submission6501/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6501/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698762503410,
            "cdate": 1698762503410,
            "tmdate": 1700470264754,
            "mdate": 1700470264754,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6LL0aKKdcL",
                "forum": "pB9XVRGVu0",
                "replyto": "Tm1FCDxRXe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6501/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6501/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer Questions"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their questions and comments. Please see our responses below.\n\n> While the paper reports performance improvements, it lacks clarity on their statistical significance. For instance, when a 3% improvement in performance is highlighted, it becomes crucial to understand the variance arising from different initialization seeds. Reporting standard deviations would have offered a clearer picture of the model's robustness and reliability.\n\nWe conducted 5 runs with 100K paired points for both GeRA and unregularized contrastive learning, of the experiment presented in Figure 3. We report the mean and standard deviation below.\n\nGeRA:\nMEAN:  0.3507\nSTD: 0.0063\n\nContrastive Loss:\nMEAN: 0.3105\nSTD: 0.0048\n\nASIF is not probabilistic and returns constant results.\n\nThis indicates that the performance of GeRA is insensitive to initialization and the improvement over vanilla contrastive loss is significant. Obtaining standard deviations for all experiments takes time and is not feasible within the discussion period, but we will add standard deviations to our figures in the final draft.\n\n> The manuscript introduces additional hyperparameters, yet it does not provide sufficient insight into their impact on downstream performance. Without guiding intuition, the only approach seems to be extensive hyperparameter tuning, which might be computationally expensive and time-consuming.\n\nThe main additional hyperparameters in comparison to vanilla contrastive loss that may require some tuning are $\\alpha$ (balancing the contrastive loss term and the geometric loss term) and kernel hyperparameter $\\epsilon$. The choice of $\\alpha$ signifies the degree to which we focus on preserving local geometry at the expense of potentially reducing the alignment quality. The kernel scale $\\epsilon$ defines the notion of neighborhood size in the kernel. We set it to equal to the mean of the pairwise distances in the neighborhood, multiplied by a constant, which is the tuned hyper-parameter. Setting a lower constant puts more weight on similarities of closer neighbors in the kernel construction, decreasing the effective neighborhood size in the kernel (see equation 4) and focusing on more localized features. \n\nAll other introduced hyperparameters have clear trends in terms of their effect on performance as demonstrated by our ablation studies, presented in Figure 7. We summarize the results below:\n\n* *Number of Neighbors*: Most significant is the size of the neighborhood. The intuition here is the more samples we have in our neighborhood, i.e., the larger the kernel matrix $W$, the better we can capture the local geometry and hence preserve it. Figure 7 (left) clearly shows that the number of neighbors strongly correlates with the downstream alignment performance. However, the marginal increase in performance seems to diminish with larger neighborhoods, indicating already good performance using relatively small numbers of neighbors.\n\n* *Sampling Technique*: We examined different ways of sampling the neighbors and found that the sampling technique has an effect on performance. We aim to select samples that best represent the local geometry. Hence, selecting only the closest neighbors preserves locality best. However, to obtain better continuity of the embedding space, and increase the amount of information gathered from the neighbors in different epochs, we subsample the neighbors from a larger neighborhood. Figure 7 (middle) demonstrates that sampling neighborhood points with a bias towards closest neighbors, i.e., higher probability of sampling closer neighbors while still including some information about further points, performs best overall.\n\n* *Kernel Type*: Figure 7 (right) shows that the choice of the kernel type, i.e., the neighborhood encoding method affects performance as well. This plot demonstrates that the heat kernel is the best performing kernel, indicating its superiority in capturing the local geometry. This is also underlined by the theoretical properties of the heat kernel that can capture the geometry of the manifold and hence meets our expectations.\n\nWe added these clarifications and details to Appendix A.2.2 in the paper as well."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700254469994,
                "cdate": 1700254469994,
                "tmdate": 1700255437005,
                "mdate": 1700255437005,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vQFAlztIIC",
                "forum": "pB9XVRGVu0",
                "replyto": "Tm1FCDxRXe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6501/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6501/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer Questions - Continue"
                    },
                    "comment": {
                        "value": "> The discussion regarding inference time, particularly in relation to ASIF that performs vector search (i.e. retrieval) using cosine similarity, may be misleading. Existing libraries, such as faiss [1], offer methodologies for more efficient vector searches (e.g., approximate or hierarchical techniques). As such, the paper's emphasis on superior performance compared to a naive ASIF implementation could potentially be misleading to the reader\n\nTo address this question, we examine the performance of ASIF with Faiss for neighborhood computation in terms of accuracy and computation time, leveraging Faiss's efficiency for neighbor and similarity computation. For comparability, we mirrored the approximation conditions that we already used when precomputing the nearest neighbors for the GeRA method. This involved quantizing vectors using 64 bits and employing 50 clusters with \u2018nprobe=5\u2019. The following table shows the resulting zero-shot accuracies on the ImageNet data for different numbers of paired points ($M$) (an experiment similar to the one depicted in Figure 3), with and without faiss:\n| Method | $M=10^3$ | $M=2.5\\times 10^3$ | $M=10^4$ | $M=2.5\\times 10^4$ | $M=10^5$ | $M=2.5\\times 10^5$ | $M=10^6$ | \n|-----------------|------------|------------|------------|------------|------------|------------|------------|\n| ASIF | $0.06$ | $0.1$ | $0.18$ | $0.26$ | $0.37$ | $0.44$ | $0.53$ | \n| ASIF+faiss | $0.04$ | $0.06$ | $0.11$ | $0.17$ | $0.22$ | $0.22$ | $0.28$ | \n\nThis table depicts that the downstream performance of ASIF drops significantly when using faiss. \n\nIn addition, in terms of computation times, using faiss for computing sparse vector representations in ASIF did not improve the overall run times for the number of points considered (up to $10^6$). This is mainly due to the computation of cosine similarities between the representations of the different modalities for each new input point, which requires computing intersection of indices that cannot be vectorized. This approach will be beneficial when there are significantly more paired points.\n\nWhile other ways of implementing ASIF more efficiently could be explored further, considering the substantially decreased zero-shot performance presented in the table, the run-time discussion of ASIF in the paper is fair.\n\n> There is no publicly available code to reproduce the work\n\nWe will publish the code on acceptance\n\n> The manuscript does not discuss the interplay between the density of the latent space and the preservation of its geometry. In particular for spaces where the points density changes in different regions, it may be problematic to use the same neighbors selection strategy for the whole space\n\nThank you for pointing this out. We added more details about how we compute the kernel scale $\\epsilon$ to Appendix A.2.2, which addresses this point. In order to allow better adaptability of the kernel to neighborhoods of different sizes and densities, we compute the kernel scale $\\epsilon$ as follows: $\\epsilon = \\sigma \\times\\mathrm{mean}(\\mathrm{pairwise\\  euclidean\\  distances})$, where $\\sigma$ is the tuned hyperparameter (constant).\n\nHence, by including the average distances within each neighborhood in the kernel normalization, the kernel adapts to the local scales and characteristics of these neighborhoods.\n\n> The paper presents notably low performance figures for ASIF in the domain of speech-text alignment. How do these figures relate to the findings of [2] when using ASIF? An explanation or a comparative insight would help in contextualizing the reported results better and understanding potential disparities or improvements\n\nThank you for pointing out this relevant paper. Our results and the results presented in [2] using ASIF highlight the main advantage of our approach over ASIF. When the uni-modal embedding spaces are different, as suggested by [2] for the speech and text modalities, we hypothesize that ASIF needs a lot more paired samples to properly align the spaces, since extrapolation from a limited number of pairs is likely to be inaccurate. Moreover, the performance obtained by ASIF in [2] is using encoders that were trained on data that included paired points from the two modalities. In contrast, in our experiments, we use encoders that were trained on purely uni-modal data, and that may be the source of the performance gap. Our method for alignment of the uni-modal models combines the strengths of contrastive alignment with paired data, to match the uni-modal embedding spaces, and preserving the geometry of the respective spaces, thus it is more robust to the differences in uni-modal embedding spaces. For instance, in Figure 6, we see that vanilla contrastive loss performs quite well in aligning uni-modal models, significantly outperforming ASIF (unlike the text-image experiment in Figure 3), while our method further improves the performance of contrastive loss.\n\nWe added this discussion and citation of [2] to Appendix A.2.3 in the paper"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700254657773,
                "cdate": 1700254657773,
                "tmdate": 1700255801582,
                "mdate": 1700255801582,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iBJPabkMuc",
                "forum": "pB9XVRGVu0",
                "replyto": "vQFAlztIIC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6501/Reviewer_gPXV"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6501/Reviewer_gPXV"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the detailed rebuttal provided in response to the comments and questions regarding the manuscript.  The responses have not only clarified all the concerns but also enhanced the overall work.\n\nThus, I am increasing my score and firmly reccommending acceptance."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700470247489,
                "cdate": 1700470247489,
                "tmdate": 1700470247489,
                "mdate": 1700470247489,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wTjho23txK",
            "forum": "pB9XVRGVu0",
            "replyto": "pB9XVRGVu0",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6501/Reviewer_G2FF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6501/Reviewer_G2FF"
            ],
            "content": {
                "summary": {
                    "value": "This paper aims to improve the training of multi-modal models from pretrained unimodal models. The paper proposes the method GeRA that adds a regularization loss to the multi-modal contrastive loss such that the local geometry of the original embedding spaces of each modality is preserved (Eq. 3: geometric regularization). The regularization term is based on a kernel function of the locality around each point that encourages the nearest neighbors to stay in their relative positions. The experiments section evaluates the effectiveness of the geometric regularization compared with various baselines on the CC12m and concludes that the method is effective in a low data regime."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Results in Figure 3 and Figure 6 show that the proposed method is better than training with contrastive loss and two other baselines when training on fewer than 10^5 paired data points on both image-text and speech-text alignment tasks.\n- GeRA has been shown to be effective for two alignment learning tasks, image-text and speech-text alignment, in the low-data regime."
                },
                "weaknesses": {
                    "value": "- One of the major motivations in the introduction for the method is to use unpaired data for training. However, I cannot find any experiment in section 5 that trains on a mixture of unpaired and paired data where paired data is small. If so, please name the dataset used in section 5. Is unpaired data referring to the data used for pretraining the models? If no experiments are done that use unpaired data during the alignment, at least the following sentence in the abstract should be corrected: \u201cOur method leverages the manifold geometry of unpaired (unlabeled) data to improve alignment performance.\u201d and the following sentence in Section 3: \u201c...we propose to leverage unlabeled (unpaired) points from each modality to preserve the rich geometric structure of their original embedding spaces.\u201d\n- The effectiveness of the method is limited to the low-data regime with paired data fewer than 10^5 samples and the performance is significantly lower than a model trained with just one order of magnitude more paired samples. So at least for image-text and speech-text modalities where available paired data is significantly more than 10^5, it is not clear how the proposed method can be helpful. In other words, when would it be useful to use GeRA instead of ASIF or the standard contrastive loss? Would it be for training other multi-modal models where the paired data is few? If so, do authors believe that the two examples of image-text and speech-text can be extrapolated to other multi-modal models?"
                },
                "questions": {
                    "value": "- Figure 1: This figure is interesting and shows that the nearest neighbors remain relatively the same. Is there a standard evaluation metric that is improved because the geometry of modalities remains almost the same? Most of section 5 considers evaluation metrics specific to multi-modal models. Can we also evaluate these models for unimodal metrics such as unimodal retrieval such as image-image text-text retrieval?\n- Is Figure 1 related to any model trained and evaluated in Section 5? Can we confirm that the model trained with GeRA is also a strong model according to zero-shot metrics?\n- Eq. 3: What is the dimensionality of W? Is it MxM or N_k x N_k? Is the loss meaningful even if the nearest neighbors in the original and the new space are different?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6501/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698798885914,
            "cdate": 1698798885914,
            "tmdate": 1699636729087,
            "mdate": 1699636729087,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vRFB8GW3F3",
                "forum": "pB9XVRGVu0",
                "replyto": "wTjho23txK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6501/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6501/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer Questions"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their questions and comments. Please see our responses below.\n\n> One of the major motivations in the introduction for the method is to use unpaired data for training. However, I cannot find any experiment in section 5 that trains on a mixture of unpaired and paired data where paired data is small. If so, please name the dataset used in section 5. Is unpaired data referring to the data used for pretraining the models?\n\nThank you for pointing out this source of confusion. We added a clarification in Section 5.1 in the paper (paragraph Unpaired points) and in Section 5.4 (paragraph Dataset) that in all experiments we make use of both paired points, in the contrastive loss, and unpaired points, in the geometric loss when training the alignment neural networks: \n\nSection 5.1: \u201cTo preserve the local geometry of the pretrained unimodal models, we use unpaired points from each modality to compute the geometric regularization in equation 1. For the image and text experiments, we discard the pairing information of $6\\times 10^6$ data points from CC12M and treat them as unpaired points used in the geometric regularization.\u201d\n\nSection 5.4: \u201cIn this experiment, we used up to $10^5$ paired points in the contrastive loss, and additional $10^5$ unpaired points in the geometric regularization.\u201d\n\nIn addition, we add the following clarification in Appendix A.2.1: \u201cTo give a bit more detail on the use of unpaired data in our experiments, in the image-text experiments, the dataset we used for training is CC12M which is a paired dataset. However, during training we only consider the pairings for a small number of samples and use the (fraction of) remaining samples as unpaired data to simulate a scenario where there are limited amounts of paired data and many unpaired data points. More concretely, we take $M$ paired samples (used for contrastive loss) and include $N \\gg M$ unpaired samples (distinct from the paired points used in the contrastive loss), where the unpaired points for each modality are chosen randomly and independently of the other modality. We leverage the unpaired data in the neighborhoods of each paired datapoint, and construct the kernels in the geometric regularization based on these neighboring unpaired points. Note that for a pair $(x,y)$, the neighborhood for $x$ is in general not the same as the neighborhood for $y$, i.e., the neighbors do not have to be pairs themselves.\u201d\n\n> The effectiveness of the method is limited to the low-data regime with paired data fewer than 10^5 samples and the performance is significantly lower than a model trained with just one order of magnitude more paired samples. So at least for image-text and speech-text modalities where available paired data is significantly more than 10^5, it is not clear how the proposed method can be helpful. In other words, when would it be useful to use GeRA instead of ASIF or the standard contrastive loss? Would it be for training other multi-modal models where the paired data is few? If so, do authors believe that the two examples of image-text and speech-text can be extrapolated to other multi-modal models?\n\nThe method presented in this work is model-agnostic and can therefore be applied to any combination of modalities, given good pre-trained unimodal models. GeRA is especially useful in modality pairs for which there are limited amounts of paired data points, as demonstrated by Figures 3 through 6, for relatively few paired data points. \n\nWe demonstrate our approach on the image-text and speech-text modality pairs due to their clear ground truth, but it can be applied to any modality pair. Hence, as pointed out correctly by the reviewer GeRA will be especially useful for modalities where the amount of paired data is low.\nComparing to ASIF, there are two limiting factors:\n\n1. In the original paper, ASIF's evaluation was limited to the ViT image encoder - a very specific image encoder - that was partially trained on ImageNet images during pretraining. In Fig 10 we use different pretrained encoders. These results show that, compared to GeRA, ASIF struggles much more with other choices of encoders as well as when it comes to retrieving CC12M images and captions (See Figure 4). \n\n2. ASIF has much higher inference time than GeRA."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700253944609,
                "cdate": 1700253944609,
                "tmdate": 1700254628096,
                "mdate": 1700254628096,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Sk59kjZuUd",
                "forum": "pB9XVRGVu0",
                "replyto": "HWyib21yIp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6501/Reviewer_G2FF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6501/Reviewer_G2FF"
                ],
                "content": {
                    "title": {
                        "value": "I thank the authors. Some of my concerns are resolved, however, three concerns need more discussions."
                    },
                    "comment": {
                        "value": "I thank the authors for their response. Some of my concerns are resolved, however, three concerns under W.2 Q.1 and Q.3 would need more discussions.\n\n**W.1** I cannot find any experiment \u2026 that trains on a mixture of unpaired and paired data.\nThe added text in Section 5.1 and Section 5.4 clarifies it.\n\n**W.2** The effectiveness of the method is limited to the low-data regime. When would it be useful to use GeRA \u2026?\nI thank the authors for confirming my understanding. I would count the limited scale of experiments (diversity of datasets and modalities) as a weakness but I don\u2019t count it as a major weakness.\n\n**Q.1** Is there a standard evaluation metric that is improved? Can we evaluate these models for unimodal metrics such as unimodal retrieval?\nNew results in the rebuttal partially answers this question. I recommend performing the standard image-image retrieval and text-text retrieval evaluations and report recall@1 separately for all models.\n\n**Q.2** Can we confirm that the model trained with GeRA is also a strong model according to zero-shot metrics?\nThe added text in A.1 and the rebuttal comment clarifies it.\n\n**Q.3**  What is the dimensionality of W? Is the loss meaningful even if the nearest neighbors in the original and the new space are different?\nThe answer says the N_k refers to a set of k neighbors in the original space.  In that case, the geometric loss depends on the embeddings of data points that don\u2019t exist in a mini-batch if we randomly sample training data. Is there a lookup table that stores all the embeddings of NNs for all points? Does one need to include all the original NNs for all points in a mini-batch? This leads me to a new question and potential concern: **What is the cost of computing the geometric regularization?**"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700615037109,
                "cdate": 1700615037109,
                "tmdate": 1700615037109,
                "mdate": 1700615037109,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HvKxQrrIKP",
                "forum": "pB9XVRGVu0",
                "replyto": "wTjho23txK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6501/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6501/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer's Comment"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the comment. Please see our responses below.\n\n> The effectiveness of the method is limited to the low-data regime.\n\nWhile mostly motivated by low-data scenarios, GeRA can also take advantage of more data. This is indicated by Figure 3-Figure 7, in which GeRA consistently outperforms the vanilla CL loss, which was used to train models like CLIP, when increasing the number of paired points. However, studying GeRA in scenarios with very large paired datasets is out of the scope of this paper, since we focus on facilitating better alignment specifically in the low data regime.\n\n> Is there a standard evaluation metric that is improved?\n\nIn uni-modal self-supervised literature, using uni-modal model embeddings for classification is standard. Our ImageNet experiment, conducted in response to the reviewer's query, demonstrates that GeRA enhances performance over unregularized contrastive learning.\n\n> Can we evaluate these models for unimodal metrics such as unimodal retrieval? New results in the rebuttal partially answers this question. I recommend performing the standard image-image retrieval and text-text retrieval evaluations and report recall@1 separately for all models.\n\nOur main focus is on multi-modal alignment, and we believe multi-modal metrics should be the primary concern to evaluate the performance of alignment transformation functions. While we acknowledge that uni-modal metrics are useful for analyzing neighborhood consistency, our experiments in Figure 1 and the image-to-image kNN accuracy on ImageNet demonstrate that GeRA's alignment transformation functions achieve superior performance in uni-modal metrics for in-distribution data and in zero-shot settings. Furthermore, the results of this experiment are indicative of uni-modal retrieval and recall@1 metrics, due to the use of k-NN (examined with different 'k' values), which relies on the proximity of the images in the embedded space. We will additionally investigate the uni-modal classification performance with more models and linear probing in the final draft.\n\n> Is there a lookup table that stores all the embeddings of NNs for all points? Does one need to include all the original NNs for all points in a mini-batch?\n\nWe use the Faiss library [1] to precompute the nearest neighbors for each sample. With approximation methods, this process takes approximately 50 minutes for 6 million embedding points. Incorporating these neighbors into the minibatch for geometric computation does introduce additional computational overhead. However, as shown in Figure 9, which details the training time of our geometrically regularized alignment, training is completed within a reasonable time. It takes 20 hours even with 150 neighbors, using a single NVIDIA GeForce RTX 3090 GPU.\n\n[1] Johnson, Jeff, Matthijs Douze, and Herv\u00e9 J\u00e9gou. 2017. \u201cBillion-Scale Similarity Search with GPUs.\u201d, IEEE Transactions on Big Data.\n\n> What is the cost of computing the geometric regularization?\n\nThe computational cost of geometric regularization scales asymptotically with the square of the neighborhood points count in the geometrical loss computation. However, this cost is relatively minor compared to the computational graph's construction during backpropagation which has a larger computational constant. In our experiments, the overhead increased approximately linearly with the number of neighbors per batch. Figure 9 in our paper illustrates the training time for GeRA across various neighborhood sizes. We will also include a line for training time without geometric regularization as a reference."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700681787251,
                "cdate": 1700681787251,
                "tmdate": 1700684243192,
                "mdate": 1700684243192,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "240Kf7w9Al",
            "forum": "pB9XVRGVu0",
            "replyto": "pB9XVRGVu0",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6501/Reviewer_cT78"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6501/Reviewer_cT78"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a method for addressing the challenge of multi-modal alignment with a focus on preserving local geometric structure and efficiently utilizing unlabeled data. The paper makes several contributions to the field, including geometry-preserving alignment, label efficiency, and modality-agnostic formulation. The authors demonstrated the effectiveness of the proposed GeRA method in various settings"
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The proposed method stands out by focusing on preserving local geometric structures, which are critical for retaining the rich semantic information within the manifold structure.\n\nThe method can capture additional information from pretrained unimodal encoders, making it highly valuable in scenarios where paired data is limited.\n\ndoes not rely on domain-specific knowledge or augmentation and can be applied across various encoders and data modalities, as long as pretrained models are available."
                },
                "weaknesses": {
                    "value": "The author proposed the kernel based encoding methods for capturing the local geometric information of each sample. There are several existing works proposed in a while for capturing the local geometric in RKHS in semi-supervised settings, through either constructing neighbor data dependent norms or leveraging the Laplacian graphs in manifold regularization, list a few below:\n\nV. Sindhwani, et al.   Beyond the point cloud: from transductive to semi-supervised learning \n \nX. Zhu, et al.   Semi-supervised learning using gaussian fields and harmonic functions\n\nFrom this point of view, the employment of the heat kernel seems to be the main contribution of this work, thus slightly weakening the novelty.\nAs the author mentioned, there is a clear limitation related to the batch size and computational cost of this method, have the author conducted any analysis based on what could be the trade off due to this limitation? What could be the scenario in which this method may not work well due to this?"
                },
                "questions": {
                    "value": "As listed in weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6501/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698801598710,
            "cdate": 1698801598710,
            "tmdate": 1699636728975,
            "mdate": 1699636728975,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "aAicLEAS2T",
                "forum": "pB9XVRGVu0",
                "replyto": "240Kf7w9Al",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6501/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6501/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer Questions"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their questions and comments. Please see our responses below.\n\n> The author proposed the kernel based encoding methods for capturing the local geometric information of each sample. There are several existing works proposed in a while for capturing the local geometric in RKHS in semi-supervised settings, through either constructing neighbor data dependent norms or leveraging the Laplacian graphs in manifold regularization, list a few below: \nV. Sindhwani, et al. Beyond the point cloud: from transductive to semi-supervised learning \nX. Zhu, et al. Semi-supervised learning using gaussian fields and harmonic functions \nFrom this point of view, the employment of the heat kernel seems to be the main contribution of this work, thus slightly weakening the novelty.\n\nThe papers mentioned by the reviewer are highly relevant and we thank the reviewer for pointing them out. We added the following to the `related work\u2019 section in the paper (starting in line 108):\n\n\u201cIn the context of semi-supervised learning, Sindhwani, et al., Zhu, et al., propose frameworks for integrating geometry learned from both labeled and unlabeled data into classification algorithms based on the graph Laplacian (Sindhwani, et al.), and based on a Gaussian random field model (Zhu, et al.). These works, however, focus on a uni-modal supervised learning setting and do not address semi-supervised alignment of data from multiple modalities.\u201d\n\nThese papers are related in the sense that they address the incorporation of unlabeled points into kernel methods to facilitate semi-supervised learning, but both focus on learning purely within a single modality in a supervised learning setting. In contrast, we focus on the objective of multi-modal alignment with limited paired data, and hence the main novelty of our paper is not the geometric regularization term itself, but rather the whole framework. We achieve our main objective of aligning multi-modal data by combining two concepts that have not been studied together so far: (1) alignment of uni-modal pre-trained models and (2) a geometric regularization term aimed at preserving local neighborhood structures of the uni-modal models.\n\nThe use of geometric information in learning tasks is indeed a highly studied topic, yet the effective incorporation and design of geometric regularizers for different learning problems, especially involving deep learning, is non-trivial.\n\n> As the author mentioned, there is a clear limitation related to the batch size and computational cost of this method, have the author conducted any analysis based on what could be the trade off due to this limitation? What could be the scenario in which this method may not work well due to this?\n\nThe computational limitations stem from the number of neighbors used in the kernel construction. We demonstrated that using more neighbors improves downstream performance (see Figure 7). However, increasing the number of neighbors limits the number of paired points used for the contrastive loss part in each batch. Therefore, the main trade-off is between performance gained by increasing the batch size of paired points in the contrastive loss, and the performance gained by using neighborhood geometry as a regularizer. Figure 7 demonstrates that there is a large increase in performance when adding the regularization term, even for small neighborhoods, and then a small marginal increase for larger neighborhoods. Therefore, using smaller neighborhoods for kernel construction reduces computational overhead, while preserving most of the benefits obtained by using the geometric regularization."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700253676478,
                "cdate": 1700253676478,
                "tmdate": 1700255274104,
                "mdate": 1700255274104,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zeT7qWEZR3",
            "forum": "pB9XVRGVu0",
            "replyto": "pB9XVRGVu0",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6501/Reviewer_GTA6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6501/Reviewer_GTA6"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new semi-supervised method for cross-modality alignment, named Geometrically Regularized Alignment (GeRA). Compared with regular aligning loss, GeRA includes Geometric Regularization, which force to preserve the neighborhood structure of nearby unpaired points."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The whole paper is well written and easy to follow.\n- To effeciently align embedding spaces of unimodal encoders by preserving the locality of unparied points is convincing.\n- The figures and charts are well-presented. Both Fig1 and Fig2 illustrates GeRA clearly."
                },
                "weaknesses": {
                    "value": "- This paper has limited novelty. Adding a geometrically regularization term is too conventional in manifold learning.\n- The motivation of this paper needs further discussion. There are millions or even billions of paired  speech-text and image-text  data, why do we need a label-efficient semi-supervised method?"
                },
                "questions": {
                    "value": "- Please explain my questions mentioned in Weakness.\n- How long does it take to get the nearest neighbor information?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6501/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6501/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6501/Reviewer_GTA6"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6501/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698839935932,
            "cdate": 1698839935932,
            "tmdate": 1699636728869,
            "mdate": 1699636728869,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VoGq8fW526",
                "forum": "pB9XVRGVu0",
                "replyto": "zeT7qWEZR3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6501/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6501/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer Questions"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their questions and comments. Please see our responses below.\n\n> This paper has limited novelty. Adding a geometrically regularization term is too conventional in manifold learning.\n\nOur objective in this paper is to align multiple modalities given limited amounts of paired data. From this perspective, the main novelty of our paper is not the geometric regularization term itself, but rather the entire framework. \nOur work combines two concepts that have not previously been studied together: preserving uni-modal geometry using a geometric loss term and multi-modal alignment based on uni-modal models. When the amount of paired data is limited, a multi-modal model cannot be sufficiently trained from scratch. In addition, we demonstrate that aligning embedding spaces of pre-trained unimodal models without taking into account the local geometry degrades performance and distorts neighborhood structures. We thus propose a new semi-supervised framework for aligning pre-trained unimodal models that preserves the local neighborhood structures. This resultes in improved performance in multi-modal zero-shot and retrieval tasks.\n\nSecondarily, geometric regularization is indeed a pillar of machine learning theory and practice, and the design of effective geometric regularizers for different learning problems is far from trivial. The use of this time-tested and effective strategy for a new problem in machine learning should not be grounds for rejection, especially since our particular regularization technique is new. \n\n> The motivation of this paper needs further discussion. There are millions or even billions of paired speech-text and image-text data, why do we need a label-efficient semi-supervised method?\n\nOur approach is model-agnostic and can therefore be applied to any combination of modalities, given good pre-trained unimodal models. GeRA is indeed especially useful in modality pairs for which there are limited amounts of paired data points, as demonstrated by Figures 3 through 6, for relatively few paired data points. In this paper, we demonstrate our approach on relatively small datasets of the image-text and speech-text modality pairs due to their availability and clear ground truth, however, it can be applied to any modality pair.\n\n> How long does it take to get the nearest neighbor information?\n\nUsing Faiss [*] for computing 800 nearest neighbors for 6 millions vectors in a 768 dimensional space it takes 45 to 55 minutes on a NVIDIA GeForce RTX 3090. We added these details to Appendix A.2.1 in the paper as well. \n\n[*] Johnson, Jeff, Matthijs Douze, and Herv\u00e9 J\u00e9gou. 2017. \u201cBillion-Scale Similarity Search with GPUs.\u201d, IEEE Transactions on Big Data."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700253500676,
                "cdate": 1700253500676,
                "tmdate": 1700253500676,
                "mdate": 1700253500676,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uDzXxDHAbx",
                "forum": "pB9XVRGVu0",
                "replyto": "VoGq8fW526",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6501/Reviewer_GTA6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6501/Reviewer_GTA6"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you to the authors for their detailed explanation. However, I still have a major concern.\n\nThe authors stated, \"Our objective in this paper is to align multiple modalities with limited paired data. The main novelty of our work lies not in the geometric regularization term itself, but in the entire framework.\" However, the evaluation of this framework was conducted using speech-text and image-text data, which typically have an abundance of paired data. To effectively assess the framework's utility, it would be crucial to test it in scenarios where paired data across multiple modalities are genuinely scarce.\n\nUpon a thorough review of the entire rebuttal and the comments from other reviewers, I noticed that reviewer G2FF also identified this as an issue. Consequently, I have decided to keep my original rating unchanged.\""
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700593853413,
                "cdate": 1700593853413,
                "tmdate": 1700593853413,
                "mdate": 1700593853413,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]