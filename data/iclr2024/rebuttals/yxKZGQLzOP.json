[
    {
        "title": "Generating Pragmatic Examples to Train Neural Program Synthesizers"
    },
    {
        "review": {
            "id": "uRk01htinO",
            "forum": "yxKZGQLzOP",
            "replyto": "yxKZGQLzOP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6796/Reviewer_3Xjo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6796/Reviewer_3Xjo"
            ],
            "content": {
                "summary": {
                    "value": "The authors present a framework built on the Rational Speech Acts model that iteratively tunes a listener and speaker model to generate programs fitting a spec. This framework can essentially be viewed as a bootstrapping method to build a dataset and listener and speaker models in a more efficient way than blindly sampling programs. Experiments on a regex dataset show that this framework outperforms naively training a single L/S model pair with a moderately sized dataset as well as prompting a LLM. This framework also outperforms using a human dataset instead of a listener."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The presented method outperforms the literal and GPT baselines. It also outperforms HFT which suggests that the iterative listener training makes a difference.\n- The method outperforms a small human labeled dataset, which suggests that it may be better to use this method if one does not have access to lots of human annotations.\n- The method converges at a comprable rate to the literal and HFT methods, so the bootstrapping method appears to work."
                },
                "weaknesses": {
                    "value": "- The method is only tested on a regex dataset. This ignores programs that cannot be written as regexes and more complicated programs.\n- This paper only compares the pragmatic framework against the literal and HFT baselines, which are derivatives of the pragmatic framework. While there is a comparison against GPT3.5, I would have liked to see other program synthesis baselines that do similar things for a more thorough comparison.\n- There are no ablations on the number of samples needed to get good performance and other similar hyperparameters."
                },
                "questions": {
                    "value": "- Will the dataset be released?\n- How do you guarantee your base program/sample dataset has sufficient coverage to get a usable listener/speaker model? Do you have a prior over which programs and samples may be more useful for training a model?\n- What distribution do you use to sample the set of rows and columns to update for RSA?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6796/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6796/Reviewer_3Xjo",
                        "ICLR.cc/2024/Conference/Submission6796/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6796/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697939573755,
            "cdate": 1697939573755,
            "tmdate": 1700512582017,
            "mdate": 1700512582017,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "p8bH6bS1ju",
                "forum": "yxKZGQLzOP",
                "replyto": "uRk01htinO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6796/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6796/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 3Xjo"
                    },
                    "comment": {
                        "value": "> Will the dataset be released?\n\nYes! It\u2019s included in the supplement.\n\n> How do you guarantee your base program/sample dataset has sufficient coverage to get a usable listener/speaker model? \n\nWe train the base models on randomly sampled program-specification pairs to initialize them as capable program synthesis models as described in section 3.2 of the paper and section 1 of the General Response.\n\n> Do you have a prior over which programs and samples may be more useful for training a model?\n\nYes, we use a prior over programs based on Ye et al. (2020) that is described in section 4.1 and appendix A of the paper.\n \n> What distribution do you use to sample the set of rows and columns to update for RSA?\n\nWe use the listener model to generate programs consistent with the prior example (\u201cab\u201d, \u2713) and the speaker model to generate examples consistent with the target program +b* as shown in Figure 1 of the paper. So, for the given example, in the second turn of the simulated interaction we may get a set of programs [a?b?, a+b+, a*b+c?] and examples [(\u201caab\u201d, \u2713), (\u201cabb\u201d, \u2713), (\u201caa\u201d, \u2713), (\u201cb\u201d, \u2717)], and use those to construct the consistency matrix over which we perform RSA inference. \n\n> This paper only compares the pragmatic framework against the literal and HFT baselines, which are derivatives of the pragmatic framework. While there is a comparison against GPT3.5, I would have liked to see other program synthesis baselines that do similar things for a more thorough comparison.\n\nIn section 1 of the General Response, we detail why the Literal model is not derivative of our pragmatic approach, and in itself a standard program synthesis baseline. In section 3 we describe some findings from running a symbolic regex-specific program synthesizer.\n\n## Ablations\n> There are no ablations on the number of samples needed to get good performance and other similar hyperparameters.\n\nFigure 5 presents the performance of the model over rounds of training. Since each round corresponds to training on a new set of (in this case 1024) program-specification pairs, this is an ablation that looks at the number of samples (where each program-specification pair counts as a sample) required to get good performance. We find that model performance increases over rounds of training, highlighting the value of iterated training. \n\nWe have also added a comparison to one epoch of training on two different sets of program-specification pairs. One set of 5120 pairs is generated using the base speaker and listener models, corresponding to training on the same number of programs as the Pragmatic model, but in one round, effectively ablating the effect of iterated training. Training in a single round does not perform as well as training in multiple rounds of training. \n\nWe also compare to training on 400 pairs from the speaker in the 5th round of training, and find that this performs quite well, suggesting that a speaker in later rounds of training produces informative examples.\n\nIf you were referring to a different ablation, please let us know so we can clarify our method.\n\n## References\nXi Ye, Qiaochu Chen, Isil Dillig, and Greg Durrett. Benchmarking multimodal regex synthesis with\ncomplex structures. In Proceedings of the 58th Annual Meeting of the Association for Computa-\ntional Linguistics, pp. 6081\u20136094, Online, July 2020. Association for Computational Linguistics.\ndoi: 10.18653/v1/2020.acl-main.541. URL https://aclanthology.org/2020.acl-main.541."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6796/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700159654606,
                "cdate": 1700159654606,
                "tmdate": 1700159654606,
                "mdate": 1700159654606,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "J3koaqNPYK",
                "forum": "yxKZGQLzOP",
                "replyto": "WgW3YSozbx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6796/Reviewer_3Xjo"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6796/Reviewer_3Xjo"
                ],
                "content": {
                    "comment": {
                        "value": ">We train the base models on randomly sampled program-specification pairs to initialize them as capable program synthesis models as described in section 3.2 of the paper and section 1 of the General Response.\n\nI re-read those sections and my understanding is the same as before in that you sample uniformly from the input space. As this input space can be very large, how do you ensure that you get sufficient signal for \"rare\" programs?"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6796/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700504866948,
                "cdate": 1700504866948,
                "tmdate": 1700504866948,
                "mdate": 1700504866948,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rNJoYyFojV",
                "forum": "yxKZGQLzOP",
                "replyto": "dBHdBtQfp0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6796/Reviewer_3Xjo"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6796/Reviewer_3Xjo"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response. I have raised my score to a 6."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6796/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700512565582,
                "cdate": 1700512565582,
                "tmdate": 1700512565582,
                "mdate": 1700512565582,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "UwFy6kIB9L",
            "forum": "yxKZGQLzOP",
            "replyto": "yxKZGQLzOP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6796/Reviewer_h5RG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6796/Reviewer_h5RG"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors propose a method for program synthesis (specifically the programming-by-examples variety of it) framed as a two-player game. A _speaker_ model $S$ is charged with generating informative examples, which a _listener_ model $L$ uses to generate programs; within this setup, a given set of examples can be consistent with multiple programs. The authors get around this difficulty by devising an approximation of a pre-existing Bayesian scheme, dubbed RSA. Using LLMs as speaker and listener models, and by performing RSA only on a partial consistency matrix $M$ of programs/examples pairs sampled from them (instead of the full matrix which is prescribed by exact RSA), the authors make it possible to select the examples which are most informative for a given program, resolving the aforementioned ambiguity. These examples are then added to the dataset of (example, program) pairs and used to train the speaker and listener in an Expert Iteration fashion. \nThe authors demonstrate that their proposed method, trained using only synthetic data and their ExpIt-like procedure, performs better than a set of baselines, including a model trained on high quality data sourced from human annotators, and GPT 3.5."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- While RSA is not novel in itself, the paper is anyway quite novel in making it applicable to a large-scale program synthesis task, and in using LLMs to model speaker and listener.\n- The paper is accessible and written well, though it does contain a very large number of details and some typos.\n- The authors set up a comprehensive experimental pipeline inclusive of humans in the loop. Most papers on code synthesis do not actually test their methods \"in the wild\", while this paper does.\n- The proposed method does beat the considered baselines by a good margin."
                },
                "weaknesses": {
                    "value": "- It appears that one assumption of RSA is that given a certain example, the literal listener $L_0$ should assign equal probability to all programs consistent with it. This is unlikely to be the case once $L_0$ is a neural net, unless this has been perfectly trained.\n- Synthetic data needs to be available to pre-train the literal speaker and listener models. These might not be available when considering more rich \"programming\" languages than regexs.\n- Both the training and evaluation protocols are quite complex, meaning that multiple reads of the paper  are necessary to get all of the details.\n- The set of baselines considered is somewhat narrow, and does not include any previous efforts on the particular task considered (i.e. inferring regular expressions). The authors compare only against effectively an ablation of their own method (LITERAL), their method but trained on a set of human-annotated data (HFT), and a generalist LLM (GTP 3.5)."
                },
                "questions": {
                    "value": "- As mentioned above, the RSA framework assumes $L_0$ to assign equal probability to all consistent programs, which is not going to be the case once it is approximated with a Neural Net. Could the authors comment on this?\n- The literal listener $S_0$ is not defined in section 2. Only $L_0$ and $S_1$ are defined. Could the authors provide a definition?\n- Why didn't the authors include any baselines (neural or not) specific to the task of inferring regexs?\n- Some details of the evaluation protocol are a bit obscure. First of all, how do the authors compute their top-1 metric on the validation dataset, when doing model selection? They only provide a definition of the metric as part of the final human trial, so it's not clear how the model would be prompted when computing it at the model selection stage.\n- The authors state that \"TOP-1@$t$ measures whether the model's top-1 matches intended regular expression at any point at turn $t$ of the interaction\". Is it at any point, or a turn $t$? Since the interaction ends after a match is achieved, it can only be at turn $t$, but the text is ambiguous.\n- The authors detail their inference procedure in section 4.4. Therein they state that programs inconsistent with a given example are filtered out. Shouldn't they be left in in order to build the consistency matrix $M$? Does this paragraph only detail the inference protocol for the evaluation phase, or also for the training phase? This is not clear.\n- I assume that the numbers reported in the tables refer to the _fraction_ of instances in which an interaction was successful at time $t$, so it's technically incorrect that the metrics measure \"whether\" something happens. They actually measure \"how often\" it happens over a set of interactions. It would be helpful to the reader to amend this somewhat inaccurate language.\n- From section 4.7: \"4 shows the progression of...\" 4 what? I assume that this actually refers to figure 3 and this is a typo.\n- From the intro: \"A synthesizer trainer in the style of Devlin et al....\" what does this mean? Could the authors be more explicit?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No concerns."
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6796/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6796/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6796/Reviewer_h5RG"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6796/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698683470737,
            "cdate": 1698683470737,
            "tmdate": 1699636785373,
            "mdate": 1699636785373,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "al7kOB68Jt",
                "forum": "yxKZGQLzOP",
                "replyto": "UwFy6kIB9L",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6796/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6796/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer h5RG"
                    },
                    "comment": {
                        "value": "> As mentioned above, the RSA framework assumes to assign equal probability to all consistent programs, which is not going to be the case once it is approximated with a Neural Net. Could the authors comment on this?\n\nThis is correct \u2013 it is not possible to model a uniform distribution over all consistent programs using the literal listener. We also added a prior term to the description of the L0 computation, thanks for pointing it out. This prior is implicitly modeled by the base model when it is trained. However, this non-uniform prior is used only when we sample from the base model. We follow prior work (Pu et al., 2020) and explicitly impose a uniform prior over the sampled programs (that we use to populate the consistency matrix we perform RSA inference over). We have amended the text of Section 3.2 to convey this more clearly.\n\n> The literal [speaker] $S_0$ is not defined in section 2. Only $L_0$ and $S_1$ are defined. Could the authors provide a definition?\n\nWe amended the paper to include the definition of $S_0$ analogous to $L_0$: $S_0(example|program) \\propto M(example, program)P(example)$\n\n> Why didn't the authors include any baselines (neural or not) specific to the task of inferring regexs?\n\nIn section 3 of the General Response we describe some findings from running a symbolic regex-specific program synthesizer.\n\n> Some details of the evaluation protocol are a bit obscure. First of all, how do the authors compute their top-1 metric on the validation dataset, when doing model selection? They only provide a definition of the metric as part of the final human trial, so it's not clear how the model would be prompted when computing it at the model selection stage.\n\nHere is how we perform model selection. Given a model, we present the examples (a single string-label pair) from the validation set one example at a time, in sequence, and count the fraction of instances in which the model recovers the correct program. This fraction is used to score the models. This is similar to the replay setting which we use to evaluate GPT-3.5.\n\n> The authors state that \"TOP-1@t measures whether the model's top-1 matches intended regular expression at any point at turn of the interaction\". Is it at any point, or a turn t? Since the interaction ends after a match is achieved, it can only be at turn , but the text is ambiguous.\n\nYes, this is a typo, thanks for pointing it out! We mean that for a turn t, the TOP-1@t metric measures the fraction of tasks solved after t turns are complete (that is, the user has provided t examples).\n\n> The authors detail their inference procedure in section 4.4. Therein they state that programs inconsistent with a given example are filtered out. Shouldn't they be left in in order to build the consistency matrix M? Does this paragraph only detail the inference protocol for the evaluation phase, or also for the training phase? This is not clear.\n\nThe protocol is for both training and inference. We want the model to learn how to disambiguate between consistent programs, assuming that the base model is already effective at finding a consistent program. Note that the programs sampled are consistent with the given specification, but may be inconsistent with other examples sampled by the speaker that are not yet added to the specification, which builds a consistency matrix with both 1s and 0s.\n\n> I assume that the numbers reported in the tables refer to the fraction of instances in which an interaction was successful at time, so it's technically incorrect that the metrics measure \"whether\" something happens. They actually measure \"how often\" it happens over a set of interactions. It would be helpful to the reader to amend this somewhat inaccurate language.\n\nWe will amend the explanation of the method to make this clear.\n\n> From section 4.7: \"4 shows the progression of...\" 4 what? I assume that this actually refers to figure 3 and this is a typo.\n\nThis is a typo, thanks for catching it!\n\n> From the intro: \"A synthesizer trainer in the style of Devlin et al....\" what does this mean? Could the authors be more explicit?\n\nWe elaborate on this in section 1 of the General Response. We have also updated section 3.2 to make this more clear."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6796/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700159236706,
                "cdate": 1700159236706,
                "tmdate": 1700159236706,
                "mdate": 1700159236706,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3v3dpKA9c3",
                "forum": "yxKZGQLzOP",
                "replyto": "al7kOB68Jt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6796/Reviewer_h5RG"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6796/Reviewer_h5RG"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their response to my questions and the modifications they have carried out on the paper.\nI do not have any further points to raise and those I did raise were anyway fairly minor in nature. My score remains therefore unchanged."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6796/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700484305479,
                "cdate": 1700484305479,
                "tmdate": 1700484305479,
                "mdate": 1700484305479,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "A0bw3CnzUe",
            "forum": "yxKZGQLzOP",
            "replyto": "yxKZGQLzOP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6796/Reviewer_Lieb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6796/Reviewer_Lieb"
            ],
            "content": {
                "summary": {
                    "value": "The paper scales pragmatic inference for program synthesis to realistic problem\nsizes using neural networks. The authors introduce a listener and a speaker\nneural model and train these iteratively. The models are used to generate\ndatasets containing increasingly informative program specifications, and they\nthemselves are trained further on these datasets in each iteration. To build the\ndataset, the models suggest candidate specifications, and the specifications to\nbe included are chosen from these using pragmatic inference (the Rational Speech\nActs framework).\n\nThe method is evaluated on the task of inferring regular expressions from a set\nof examples in a human interaction study with 11 participants and outperforms a\nbase literal model, a human finetuned model, and GPT-3.5."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Scaling up pragmatic inference for realistic program synthesis could open up\npromising future research.\n\nThe paper is clearly written with illustrative figures. I found the explanation\nof the pragmatic model of program synthesis really good and easy to follow.\n\nThe paper includes a real-world study of program synthesis with 11 human\nparticipants."
                },
                "weaknesses": {
                    "value": "I believe the main weakness of the paper is that the presented method is not\ncompared to any existing neural program synthesis system (like DeepCoder,\nPCCoder, DreamCoder, CrossBeam, LambdaBeam, etc.). I think this would be\nimportant as the main thesis of the paper is scaling up pragmatic inference to\nthe level of these systems. It would also be good to include a domain for\nsynthesizing programs that's more general and widespread in the literature than\nregexes.\n\nI think that Section 4.6 about the human annotated dataset should be earlier as\nit's already referred to earlier.\n\nSome typos:\n- Introduction: \"an user\", \"coorporative\", \"human ... atempt to communicate\",\n  \"of of\"\n- page 3 top line \"an sampled example\"\n- 4.3 Measurement: \"top-1 matches THE intended regular expression\"\n- 4.7 Results: \"informatively\", \"4\" should be \"Figure 3\"\n- 6 Related work: \"datas\""
                },
                "questions": {
                    "value": "I couldn't understand the argument for sampling a subset of the consistency\nmatrix $M$ in 3.3. If $M$ is sparse, why does that allow us to sample a subset\nof the rows and columns? Wouldn't we mostly sample zeros? Or is there a strategy\nfor sampling (e.g., sampling dense areas) which is not mentioned?\n\nI also don't understand exactly how the conditioning on previous examples are\ndone when sampling in terms of the consistency matrix. Could you elaborate on\nthat?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6796/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6796/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6796/Reviewer_Lieb"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6796/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698766063379,
            "cdate": 1698766063379,
            "tmdate": 1700560114518,
            "mdate": 1700560114518,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MMbFs4H3cy",
                "forum": "yxKZGQLzOP",
                "replyto": "A0bw3CnzUe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6796/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6796/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Lieb"
                    },
                    "comment": {
                        "value": "## Sampling from the consistency matrix\n> I couldn't understand the argument for sampling a subset of the consistency matrix in 3.3. If M is sparse, why does that allow us to sample a subset of the rows and columns? Wouldn't we mostly sample zeros? \n\nWe use M to refer to the _entire_ consistency matrix with all programs and examples. So, sampling a set of columns at random would mean choosing a set of random programs, and sampling a set of rows would be choosing a set of examples at random. In the context of Figure 1 (where the target program is a+b*), an example of these samples may be [\u201cp+q*\u201d, \u201chg*\u201d, \u201cjk+\u201d], and [(\u201cxyz\u201d, \u2713), (\u201cij\u201d, \u2713), (\u201cjld\u201d, \u2713)]. The part of the consistency matrix corresponding to these examples would be full of 0s.\nInstead, if we use the listener to generate programs consistent with the prior example (\u201cab\u201d, \u2713) and the speaker to generate examples consistent with the target program +b*, we may get a set of programs [a?b?, a+b+, a*b+c?] and examples [(\u201caab\u201d, \u2713), (\u201cabb\u201d, \u2713), (\u201caa\u201d, \u2713), (\u201cb\u201d, \u2717)], as shown in the figure. We can see again in the figure that this matrix is a lot less sparse than the case of choosing programs and examples to populate the matrix as discussed earlier.\n\n> Or is there a strategy for sampling (e.g., sampling dense areas) which is not mentioned? \n\nThe only strategy we use is filtering for consistency with the previous examples (for the listener) and the program (for the speaker). We do not use any other sampling strategies.\n\n## Conditioning on previous examples\n> I also don't understand exactly how the conditioning on previous examples are done when sampling in terms of the consistency matrix. Could you elaborate on that?\n\nWhen generating examples at each turn, we resample the rows (programs) and columns (examples) based on the examples already added to the specification. This allows us to look at a relevant sample of the consistency matrix, as explained above. \nReferring to Figure 1 of the paper, we unroll an interaction between the speaker and listener models over a sequence of turns. In the first turn, there are no prior examples. The speaker generates examples only based on the target program (in this case a+b*), and the listener synthesizes programs that satisfy an empty specification. We then perform RSA inference and select an example to add to the specification. In the figure, this example is shown to be (\u201cab\u201d, \u2713). For the next turn, we use the specification built so far (now [(\u201cab\u201d, \u2713)]) as inputs to the speaker and listener models, and sample the next example as shown in the figure. This example is added to the specification, and the process is repeated."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6796/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700159070239,
                "cdate": 1700159070239,
                "tmdate": 1700159070239,
                "mdate": 1700159070239,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WBd6dvtXdY",
                "forum": "yxKZGQLzOP",
                "replyto": "XgvA7zyWxz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6796/Reviewer_Lieb"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6796/Reviewer_Lieb"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "Thank you for your thoughtful answers and clear explanations.\n\nEspecially point 2 in the general response - that the proposed method is model agnostic - improved my understanding, I have not thought of it this way. I've increased my score because of this, and I think this could be emphasized in the paper. \n\nI still think that it would be good to have a domain besides regexes. Also, if I understand correctly, the additional experiments have a mismatch between domain and method (as not all of the constructs can be used)."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6796/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700560474829,
                "cdate": 1700560474829,
                "tmdate": 1700560474829,
                "mdate": 1700560474829,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9QlIbtTa5u",
            "forum": "yxKZGQLzOP",
            "replyto": "yxKZGQLzOP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6796/Reviewer_Dg1v"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6796/Reviewer_Dg1v"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on program synthesis by example for regexes. It aims to learn a program synthesis model that reasons pragmatically. As many possible programs can meet ambiguous input example specifications, counterfactual thinking should be usefully employed to differentiate among the many valid hypotheses. Other works have investigated this possibility, most under the rational speak acts (RSA) framework, but this kind of reasoning is intractable to do exactly for non-trivial domains. The paper suggests a bootstrapped learning approach to overcome this limitation, by jointly learning a speaker model (which suggests pragmatic examples given an input program) and a listener model (which suggests a likely program, given a list of assumed pragmatic examples). Over multiple rounds, these networks are trained on one another\u2019s predictions, chosen according to an RSA methodology, made tractable by restricting the hypothesis space according to the programs sampled from the model. Experiments with human-trials demonstrate that listener models trained in this framework perform better than comparison approaches."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "I enjoyed this paper and I would support its acceptance into the conference proceedings. \n\nThe proposed approach is sensible and well-explained. The methodology appears quite general, and should be able to be used broadly as it requires no human GT data during training. In fact, the human GT data that is used in validation seems like it could be removed, as based on the trend in figure 5 it doesn\u2019t appear as though the method is overfitting in any sense over bootstrapping rounds.\n\nThe experimental design and presentation is sound and convincing for the regexes inference domain. The paper mainly validates the proposed system with human-trials, which makes sense as its hard otherwise to source \u2018pragmatic\u2019 examples, and it confirms the system would actually be easier to work with for an end-user"
                },
                "weaknesses": {
                    "value": "While a lot of effort has gone into validating the system is working for this particular regex domain, the paper does not explore other problem settings to any degree. I don\u2019t think this is a major limitation, but it is probably holding the paper\u2019s rating back slightly. The impressive results on one-domain are likely of interest to a subset of the ICLR community, but showing that this methodology can generalize effectively across domains would broaden this interest. As a note, I don\u2019t even think these other domains would need to be *more difficult* than regexes (e.g. like python code generation mentioned in the conclusion), but could even be other domains of similar complexity. \n\nIn some ways the comparison against HFT is a bit unfair, as the proposed method has effectively unlimited training data (although only a set amount of bootstrapping rounds are employed), whereas HFT is fine-tuned with a fixed amount of human-feedback. To get a \u201cfairer\u201d upper-bound of how \u201cgood\u201d the pragmatic examples produced by the system are with respect to the human provided exemplars, it might be good to include an additional condition where the listener model is fine-tuned on a fixed amount of data (i.e. the same amount as used in HFT) where the I/O examples are produced by the final speaker model. \n\nMinor:  \n\nThere is a connection to be made between the proposed method and bootstrapped \u201cwake-sleep\u201d approaches for program synthesis [1,2]. Both learn \u201cgenerative\u201d and \u201cinference\u201d models that learn on one another\u2019s outputs. The modeling set-ups are different, as these wake-sleep approaches move towards a target distribution, whereas the proposed method optimizes for synthetic training data that matches a prior desiderata (pragmatic I/O examples), but these ideas are close enough that they should be discussed within the related work section. \n\n[1] DreamCoder: growing generalizable, interpretable knowledge with wake\u2013sleep Bayesian program learning\n[2] Learning to learn generative programs with Memoised Wake-Sleep"
                },
                "questions": {
                    "value": "(1) The proposed system effectively improves the listener model by finding \u201cbetter\u201d synthetic training I/O examples, where better means there is a pragmatic connection between the examples and the target program. However, it\u2019s unclear if this improvement changes the upper-bound of the listener model performance, or if it just helps the listener model reach a good performance with less training iterations. Training the base model for 300k programs, for a single epoch, it's not clear whether the model has started to plateau in performance. It would be helpful to provide evidence that the base model has saturated, by e.g. plotting validation performance over pretraining iterations. What would this plot look like?\n\n(2) It\u2019s also not clear to me why starting from a pretrained model like ByT5 would be necessary or helpful. The programs come from a constrained DSL, where unlimited synthetic data can be sampled, so it should be possible to train the base models from scratch. It would be good to include an ablation on how starting with or without pretraining affects the proposed method. What is the justification for starting with a pretrained model?\n\n(3) Much of the evaluation is based off of human-interactions, which is present only in limited quantities. Are there any metrics which could be evaluated without human interactions? For instance, what about the following set-up:\n\n1. Pick a target regular expression and a single I/O example at random\n2. The listener samples a target expression given the current specification\n3. With respect to (2), the speaker samples an example, which is annotated as consistent/inconsistent by an oracle\n4. Repeat steps 2 and 3 until the listener samples the *correct* target expression\n\nThe metric would then be the number of example generations needed for the listener to predict the correct regular expression, where the idea would be that as the speaker is better at producing \"pragmatic\" examples it should require less steps versus a baseline that for instance randomly sampled an example. Beyond serving an evaluation set-up that requires no human-data, this kind of framework could conceivably even be useful for \u201creal-world\u201d applications: e.g. this could reduce the burden on an end-user, who instead of having to think up new examples as input, would just need to label them.\n\n## Minor:\n\n(4) Is the hypotheses set in Appendix D randomly sampled programs from the DSL? Please make this clear. More generally, some of the terminology used in the pseudo-code could be more directly mapped back to concepts in the main paper, or given a more detailed treatment in the supplemental text. \n\nThere is a typo in the figure 3 caption: metrix"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6796/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6796/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6796/Reviewer_Dg1v"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6796/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698770753746,
            "cdate": 1698770753746,
            "tmdate": 1699636785150,
            "mdate": 1699636785150,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "DNZrqnqz2A",
                "forum": "yxKZGQLzOP",
                "replyto": "9QlIbtTa5u",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6796/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6796/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Dg1v"
                    },
                    "comment": {
                        "value": "## 1. Speaker generates high-quality examples in later rounds of training\n> In some ways the comparison against HFT is a bit unfair, as the proposed method has effectively unlimited training data (although only a set amount of bootstrapping rounds are employed), whereas HFT is fine-tuned with a fixed amount of human-feedback. To get a \u201cfairer\u201d upper-bound of how \u201cgood\u201d the pragmatic examples produced by the system are with respect to the human provided exemplars, it might be good to include an additional condition where the listener model is fine-tuned on a fixed amount of data (i.e. the same amount as used in HFT) where the I/O examples are produced by the final speaker model.\n\nWe have added a comparison to Figure 5 in the updated draft.\n\nThe ability to train on large amounts of synthetically generated data has been vital in making neural and neuro-symbolic program synthesis approaches (such as RobustFill, DeepCoder, etc.) work. Our work is in a similar spirit, and asks whether we can make such synthetically generated data more closely resemble the examples that a human user would provide while using the system. \n\nHence, our proposed approach can be used to generate a very large number of examples at a much lower cost than having users provide examples. So, even if each example produced by our method is of lower quality or utility than a human-provided example, the ability to scale our approach better than having users annotate data means that we can achieve comparable results at a lower cost, even if we use more examples overall. \n\nWe did run the experiment of finetuning the base model on 400 program-specification pairs from the speaker in the 5th round of training, and find that it performs quite close to the full pragmatic training, suggesting that these examples have comparable value to human-provided examples. Note that these 400 examples cannot be obtained without going through the other rounds of training too, and this experiment is meant to illustrate the utility of examples.\n\n## 2. Base model performance plateaus during training\n> (1) The proposed system effectively improves the listener model by finding \u201cbetter\u201d synthetic training I/O examples, where better means there is a pragmatic connection between the examples and the target program. However, it\u2019s unclear if this improvement changes the upper-bound of the listener model performance, or if it just helps the listener model reach a good performance with less training iterations. Training the base model for 300k programs, for a single epoch, it's not clear whether the model has started to plateau in performance. It would be helpful to provide evidence that the base model has saturated, by e.g. plotting validation performance over pretraining iterations. What would this plot look like?\n\nFigure 6 in the updated draft plots the validation metric (Top-1 success) on the validation set (40 program-specification pairs). We see that the base model has started to plateau in performance after 1 epoch of training (9375 steps). We have also updated Appendix B with this experiment.\n\n## 3. Pretrained checkpoints help the base models\n> (2) It\u2019s also not clear to me why starting from a pretrained model like ByT5 would be necessary or helpful. The programs come from a constrained DSL, where unlimited synthetic data can be sampled, so it should be possible to train the base models from scratch. It would be good to include an ablation on how starting with or without pretraining affects the proposed method. What is the justification for starting with a pretrained model?\n\nWe also observe a substantial gain in sample-efficiency from using a pretrained model (as seen in the plot in Figure 6 of the updated draft). But, in general we agree with your statement that with the ability to generate unlimited synthetic data, we expect that we can start with a randomly initialized model and train until we are able to match the performance of starting with a pretrained model. However, since our goal here is to have a strong base synthesizer (while being agnostic to the specific type of base synthesizer), we opted to use a pretrained model in the interest of sample-efficiency.\n\n## 4. Human vs automated evaluation\n> (3) Much of the evaluation is based off of human-interactions, which is present only in limited quantities. [...] would just need to label them.\n\nSince the goal of building this kind of synthesizer is to better interpret human communication, the most faithful evaluation is to have humans interact with this kind of system. Having a model stand in for a human in evaluation might not be representative of the results of human interaction. With specific reference to an algorithm like the one you proposed, the choice of a random I/O example at the first turn is already a significant deviation from human behavior, since a human\u2019s first example would also be chosen informatively. This would in turn influence every future turn of interaction too."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6796/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700161450880,
                "cdate": 1700161450880,
                "tmdate": 1700161450880,
                "mdate": 1700161450880,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DTcF0YxTs9",
                "forum": "yxKZGQLzOP",
                "replyto": "9QlIbtTa5u",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6796/Reviewer_Dg1v"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6796/Reviewer_Dg1v"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the author's responses - I remain positive on the paper and I still supports its acceptance. \n\n```We did run the experiment of finetuning the base model on 400 program-specification pairs from the speaker in the 5th round of training, and find that it performs quite close to the full pragmatic training, suggesting that these examples have comparable value to human-provided examples. Note that these 400 examples cannot be obtained without going through the other rounds of training too, and this experiment is meant to illustrate the utility of examples.```\n\nThank you for running this experiment -- I agree with your assessment, and to put it on my own words: this experiments shows that speaker model (once trained) is able to generate training pairs at a similar quality to humans (in terms of impact on training). This is a compelling point in favor of the method that I think should make its way into the discussion. \n\n ```Since the goal of building this kind of synthesizer is to better interpret human communication, the most faithful evaluation is to have humans interact with this kind of system. Having a model stand in for a human in evaluation might not be representative of the results of human interaction. With specific reference to an algorithm like the one you proposed, the choice of a random I/O example at the first turn is already a significant deviation from human behavior, since a human\u2019s first example would also be chosen informatively. This would in turn influence every future turn of interaction too.```\n\nYes certainly there is no perfect replacement for human-studies, and any automatic metric that tries to capture human-interactions will have flaws, but I still maintain that trying to develop such metrics can be quite useful, for both this work and for future works that will try to improve within this design space. If the choice of the first random I/O has a massive impact on how many tries it takes to find the *right expression*, this is something that can be quantified with this metric (e.g. by choosing the I/O pair randomly, or having a human provide only the first I/O pair).\n\nFigure 6 \u2013 not a major point, but I really think more epochs should be added to this plot, there is still very little evidence of plateauing, especially with how noisy top-1 is as a metric (as it doesn't take into account near misses). \n\nFinally, I would once again encourage the authors to consider discussing the connections to the bootstrapped learning methods [1] and [2] -- these are useful ideological connections that future readers of the paper may benefit from."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6796/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700509967160,
                "cdate": 1700509967160,
                "tmdate": 1700510024195,
                "mdate": 1700510024195,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MbjwJzqSyX",
                "forum": "yxKZGQLzOP",
                "replyto": "9QlIbtTa5u",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6796/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6796/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for engaging without response!\n\nWe re-ran the literal listener training for additional epochs, and found that there is an improvement in performance as the base model is trained for longer. Since we train our models with linear learning rate decay, we tried two values for the maximum number of epochs \u2014 3 and 20 (the model being trained for 20 epochs did not finish training in the course of author response, but we include partial results from it), and we show the validation performance in Figure 7. We see that the model trained for 3 epochs achieves higher performance. To ensure a fair comparison of our pragmatic training procedure against a stronger listener, we also present preliminary results training the pragmatic model starting with the new base model. Given time constraints, these experiments did not finish running, but preliminary evidence already shows that our pragmatic training procedure is able to significantly outperform the stronger base model even before convergence (Figures 8a,b). We this conclude that, irrespective of the base model, our approach is able to improve the performance of a synthesizer trained with uninformatively selected examples. Please refer to the PDF for these figures.\n\nWe have also added some discussion about other iterated bootstrap training to the paper to highlight these connections to the literature."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6796/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700657693399,
                "cdate": 1700657693399,
                "tmdate": 1700657717218,
                "mdate": 1700657717218,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]