[
    {
        "title": "Impact of Molecular Representations on Deep Learning Model Comparisons in Drug Response Predictions"
    },
    {
        "review": {
            "id": "8ncmmmoMb1",
            "forum": "u8L1zzGXRq",
            "replyto": "u8L1zzGXRq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8496/Reviewer_jtTX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8496/Reviewer_jtTX"
            ],
            "content": {
                "summary": {
                    "value": "Using the CTRPv2 dataset and a training orchestration system called CMP-CV, the authors train different deep learning architectures using different molecular representations, then perform an exploratory data analysis on the errors those models make, slicing up the errors by different molecular properties. They show that the error distributions are non-uniform across these properties."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- The authors call to attention to the fact that predictive error is typically non-uniform."
                },
                "weaknesses": {
                    "value": "- This paper is primarily an EDA of the errors of trained models, and does not rise to the level of making a contribution significant enough for a main track paper, and is better suited for a workshop.\n- The authors use too much space describing CMP-CV, which appears to be a standard job orchestrator, and does not rise to the level of making a contribution. More writing should be dedicated to describing how the metrics were actually computed (see Questions).\n- The authors point out the non-uniformity of errors, but do not provide actionable recommendations on how one ought to proceed with this knowledge.\n- R2, RMSE and MAE are correlated, no need to show them all in Figure 1.\n- The trends for all models in Figures 3 and 4 are roughly the same, suggesting that the non-uniformity in prediction error is due more to the dataset than any choice of architecture or molecular representation.\n- The UMAPs of Figure 6 are very uninformative, and do not appear to support the author's point, unless there are many red Xs at each point in the space. The point of this figure could be expressed very differently, perhaps by tanimoto similarities of these clusters compared to average similarity or something like that.\n- The point of Tables 2 and 3 could be expressed in just a few lines.\n- The paper says that 10 models were trained on 10 random train/val/test splits, which is not standard practice - the test set is usually fixed across all CV splits."
                },
                "questions": {
                    "value": "- many of the details of how metrics were obtained are left out, e.g.\n  - What exactly does each model predict? It seems to be gene expression values, but it is not clear in the paper\n  - If expression values, then how do the authors get to single R2, RMSE, and MAE values in Figure 1? The line \"This figure delineates the areas where each model exhibited the highest number of errors\" is not clear.\n- How were the bins of Tables 2 and 3 chosen?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8496/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698623740804,
            "cdate": 1698623740804,
            "tmdate": 1699637061358,
            "mdate": 1699637061358,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vtvfoWq3Ry",
                "forum": "u8L1zzGXRq",
                "replyto": "8ncmmmoMb1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8496/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8496/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer jtTX"
                    },
                    "comment": {
                        "value": "Thank you so much for reviewing our work and for the valuable comments. Please note that the changes we made in the revised paper are temporally highlighted in blue. Also, Figure and Table number have changed in the revised version.\n\n- About the contribution of this work (weakness 1):\nIn this work, we use errors made by models in different regions of the molecular descriptor space to compare drug/molecule representations used by different models. In the revised version, we have also shown how this knowledge on domain-based errors can be used to improve model accuracies (section 2.4.2). Also, we introduce a web application that allows users to find models better suited for drugs having specific molecular properties (section 2.4.1).\n\n- About CMP-CV (weakness 2):\nWe rewrote the sections pertaining to CMP/CV to better describe it\u2019s role (section 2.1). The main contribution of this work is to compare drug representations used by models in terms of model errors in different regions in the molecular descriptor space and provide insight on the limitations of each representation. In the revised version we have clarified the prediction target (section 2.4, lines 153-154).\n\n- About recommendations (weakness 3):\nAs mentioned in the response to weakness 1, in the revised version, we demonstrate how this knowledge can be used to improve model accuracies (section 2.4.2).\n\n- About Figure 1 (Figure 2 in the revised version)(weakness 4):\nIn the revised version, we provide only R2 and RMSE results (Figure 2) as these are the most popular metrics used by the cancer drug respones prediction models.\n\n- About the impact of molecular representation (weakness 5):\nIt is true that the trends for different models are similar. However, we also notice that magnitude of the model errors in a given descriptor domain vary across different models. We hypothesize that one reason for this variation is the differences in the expressiveness of the representations used in different models.\n\n- About UMAP results (weakness 6):\nWe feel the UMAP is simply a visualization that highlights whether there is a structurally relevant reason as to why there may be high error for a given feature. So, if a large cluster of red X\u2019s appeared on the UMAP, there would be reason to believe that the high error could be due to the structure but if there are a lot of spread-out red X\u2019s, the given error is not necessarily related to the structure. However, we agree this wasn\u2019t described well in the paper and have chosen to move it to the appendix as it does not provide the take home message intended.\n\n- About Table 2 and 3 (weakness 7):\nWe agree that the main takeaways of Table 2 and 3 can be expressed using sentences. In the revised version we keep only Table 2 in the main text (now part of Figure 4) as it makes it easier for the reader to clearly see the changes in models\u2019 rankings in different regions of the descriptor space. We moved Table 3 and 4 to the Appendix.\n\n- About test set (weakness 8):\nFor a given train/validation/test split, all the models used same train, validation and test data. We wanted to make predictions using all the data. This is why we split the dataset into train, validation and test folds in a cross validated manner. Had we used a fixed test set our results would only correspond to a smaller subset of the drug-cell line combinations, thus limiting the validity of our conclusions. \n\n\n- About the prediction target (Question 1):\n\n   - (Question 1.1) \u201cWhat exactly does each model predict?\u201d : \n\n   - Answer: We predict the drug response value, which is quantified by the \u201cArea Under the Dose Response Curve\u201d. We had mentioned this in lines 152-153. In the revised version we also added the sentence \u201cThis AUCDR is what the CDRP models attempt to predict\u201d to further clarify what the models predict (lines 153-154).\n\n   - (Question 1.2) \u201cIf expression values, then how do the authors get to single R2, RMSE, and MAE values in Figure 1? The line \"This figure delineates the areas where each model exhibited the highest number of errors\" is not clear.\u201d:\n\n   - Answer: As mentioned above we predict one drug response value per drug -cell line combination. Thus, we get a single values for R2, RMSE and MAE.\n\n- About defining the bins (Question 2):\n\n    - Answer: In the revised version, we added a description on how the bins were found (lines 162-166). \u201cThese bins define the domains of the descriptors. Domain boundaries of continuous descriptors were found using NumPy\u2019s histogram function. Every unique value of a categorical descriptor was considered as a domain. A categorical descriptor is defined as one which consists of less than 20 unique integer values.\u201d"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8496/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700693289041,
                "cdate": 1700693289041,
                "tmdate": 1700693687129,
                "mdate": 1700693687129,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "H85Ji9DeXx",
            "forum": "u8L1zzGXRq",
            "replyto": "u8L1zzGXRq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8496/Reviewer_69P5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8496/Reviewer_69P5"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents an empirical study aimed at analyzing the performance of existing deep learning models for drug response prediction. The authors introduce CMP-CV, a framework for cross-validating multiple deep learning models using user-specified parameters and evaluation metrics. This study utilizes the CTRPv2 dataset to compare eight models across four different molecule representations. The experimental results highlight the significant impact of molecular representation on the prediction performance of deep learning models for drug response prediction."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This paper addresses an important application of machine learning in drug discovery.\n\n- The authors provide the code necessary for reproducing the experiments."
                },
                "weaknesses": {
                    "value": "- While the paper offers some insights into existing machine learning models, its technical novelty within the machine learning context is somewhat restricted. In particular, its primary contribution lies in error analysis to find which areas in the drug space the ML models does not achieve good performances rather than shedding a light on developing novel methods to enhance prediction performance for drug response. This aspect may fall short of the acceptance criteria for ICLR.\n\n- The conclusion that molecular representation significantly influences drug response prediction performance appears to be straightforward and lacks novel insights for the ML-based drug discovery community."
                },
                "questions": {
                    "value": "Please see the Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8496/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8496/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8496/Reviewer_69P5"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8496/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698765078029,
            "cdate": 1698765078029,
            "tmdate": 1699637061217,
            "mdate": 1699637061217,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fgHdQxZtOQ",
                "forum": "u8L1zzGXRq",
                "replyto": "H85Ji9DeXx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8496/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8496/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 69P5"
                    },
                    "comment": {
                        "value": "Thank you so much for reviewing our work and for the valuable comments. Please note that the changes we made in the revised paper are temporally highlighted in blue. Also, Figure and Table number have changed in the revised version.\n\nThe major goal of this work is to create a framework to understand the limitations in the drug representations used by models. The users of this framework use this kind of understanding to improve the models. In the revised version of the paper, we have provided an example for how to potentially use domain errors to improve model predictions (section 2.4.2). We pretrained the GraphDRP model to predict molecular descriptors corresponding to largest domain errors and used these pretrained weights to retrain a drug response prediction model. We find that this strategy improves both R2 and reduces domain-based errors. \n\nAlso, in this work, we provide more information about which components of the drug representation could affect the prediction accuracies of the models studied in this work. As far as we know, ours is the first work that analyses model prediction errors in terms of domains in the drug descriptor space. In the revised version, we also introduce a web application that allows users to find models better suited for drugs having specific molecular properties (section 2.4.1)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8496/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700692829625,
                "cdate": 1700692829625,
                "tmdate": 1700692855016,
                "mdate": 1700692855016,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "p94Gp2yA9c",
            "forum": "u8L1zzGXRq",
            "replyto": "u8L1zzGXRq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8496/Reviewer_gDji"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8496/Reviewer_gDji"
            ],
            "content": {
                "summary": {
                    "value": "Certain models for drug response predictions favour certain drug representation, and this is a recurring problem in feature-based drug prediction tasks. This paper studies the inductive bias of drug representation in drug response prediction tasks.\n\nThe authors demonstrate that molecular descriptors and SMILES strings are effective drug representations for drug response prediction tasks."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The problem of studying the inductive biases for drug response prediction is interesting and relevant in drug discovery. I found the analysis on the effectiveness of certain representations across drug domains interesting, for example, the takeaway that the descriptor and morgan representation models are more effective with highly soluble drug candidates is neat. This includes the importance measure of molecular descriptors that are tightly captured by certain representations."
                },
                "weaknesses": {
                    "value": "The biggest weakness of this work is the writing. I found the writing to be very difficult to follow. Couple points:\n\n- Why is the method (CMP-CV) left to the end of the paper after the results?\n- It required a few reads to disambiguate between feature space, representation, molecular descriptors, drug domains, and drug regions. I think in the next iteration of this work, time needs to be invested to expand on the different terminology used in this paper. \n- In Figure 1, why are the duplicates in the x-axis and the legend?\n- In Page 4, section 2.3.1, paragraph 2, is it not rather that the ML model appears to perform better when the log S of the drug is *more* than -7 ?\n- In Figure 1&2, why do refer to the Area Under the Roc Curve (AUC), when the results are for the R2, RMSE and MAE ?\n\nI am also still unsure what is the CMP-CV workflow exactly. It seems to be more of an engineering effort, that is largely handled by the CANDLE framework?"
                },
                "questions": {
                    "value": "Could the authors help me understand what is the key contribution of the CMP-CV workflow? It appears to be a hyperparameter sweep that is commonly used to evaluate machine learning models."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8496/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699288869570,
            "cdate": 1699288869570,
            "tmdate": 1699637061104,
            "mdate": 1699637061104,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "inQRK98fty",
                "forum": "u8L1zzGXRq",
                "replyto": "p94Gp2yA9c",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8496/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8496/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer gDji"
                    },
                    "comment": {
                        "value": "Thank you so much for reviewing our work and for the valuable comments. Please note that the changes we made in the revised paper are temporally highlighted in blue. Also, Figure and Table number have changed in the revised version.\n\n- About (CMP-CV) left to the end (weakness 1):\nWe agree that there is some confusion regarding how we presented the details on CMP/CV. In the revised version, we provided a clearer description about how CMP/CV facilitates large scale domain-based model/representation comparison (section 2.1).\n\n- About feature space, representation, molecular descriptors, drug domains, and drug regions (weakness 2):\nWe improved the introduction of terminology in the revised version (lines 92-95 and 162-166). The term \u2018feature\u2019 is replaced with \u2018descriptor\u2019. \u2018Drug domains\u2019 and \u2018drug regions\u2019 are replaced with \u2018descriptor domains\u2019. A drug molecule can be represented using molecular descriptors. The space formed by a set of descriptors (descriptor1, descriptor2, descriptor3,\u2026. ) is called the descriptor space. Each molecular descriptor can be divided into domains defined by two boundary values (lower and upper limits). \n\n- About duplicates in the x-axis (weakness 3):\nEach image in Figure 1 (now Figure 2) shows performance of the same 8 models in terms of three different metrics, R2, RMSE and MAE. The color codes in the legend represent the molecular representation used in each of the 8 models. This is why each color is repeated in each image. For example, \u2018Morgan\u2019 and \u2018HiDRA\u2019 models use Morgan fingerprints to represent the drug molecule. Thus, a single color (blue) is used to color the bars corresponding to \u2018Morgan\u2019 and \u2018HiDRA\u2019 models accuracies. We understand that this could be little confusing. We added a sentence in the figure caption clarifying the meaning of the legend colors.\n\n- About page 4, section 2.3.1, paragraph 2 (weakness 4):\nWe have mentioned that \u201cnone of the ML models appear to perform well when the logS of the drugs is less than -7\u201d. This fact is true. The models\u2019 errors are largest in the logS <-7 region. We have also stated that \u201ctheir errors decrease as the drug solubility increases\u201d, which I think is similar to what the reviewer tries to point out here.\n\n- About Area Under the Roc Curve (AUC) (weakness 5):\nR2, RMSE and MAE were calculated using the predicted and actual drug response value. The drug response value in this case is Area Under the dose response Curve. We notice we have used AUC in two different contexts in the text. One is to denote area under the dose response curve. And the other is to denote the general classification metric area under the roc curve. This is a mistake. In the revised version, we used AUCDR to denote the area under the dose response curve.\n\n- About CMP-CV workflow (weakness 6 and question 1):\nAddressed in the response to weakness 1."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8496/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700692645049,
                "cdate": 1700692645049,
                "tmdate": 1700693844694,
                "mdate": 1700693844694,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0jqXC1RTlA",
            "forum": "u8L1zzGXRq",
            "replyto": "u8L1zzGXRq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8496/Reviewer_Pfg9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8496/Reviewer_Pfg9"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents an automated cross-validation framework for drug response, coined CMP-CV, which trains multiple models with user-specified parameters and evaluation metrics. To achieve this, this paper benchmarked the commonly utilized drug representations (graph, molecular descriptors, molecular finger prints, and SMILES) on the proposed CMP-CV. The authors analyzed the results in various evaluation metrics, including average prediction error."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is well-written and easy to understand.\n- The paper studies an important task of ML for drug discovery, which suffers from the lack of general benchmarks for evaluation."
                },
                "weaknesses": {
                    "value": "- Unclear contribution: The paper compares existing methods based on the already proposed dataset. The evaluation metrics are also common, e.g., AUC, prediction error.  It is unclear which parts are the main contribution of this work.\n\n- Insufficient analysis: Although figure 2 and table 2,3,4 seem interesting, the paper only presents the results without analysis, e.g., hypothesis or justification.\n\n- Lack of descriptions about core technique: This paper repeatedly refer CANDLE framework. However, the description in Section 3.2 does not provide sufficient information to understand the framework.\n\n- Lack of comparison with other benchmarks: There are several benchmarks for drug discovery, e.g., [1], [2]. However, there is no comparison about those works.\n\n[1] Wu et al., MoleculeNet: a Benchmark for Molecular Machine Learning, Chemical Science 2018\\\n[2] Stanley et al., FS-Mol A Few-Shot Learning Dataset of Molecules, NeurIPS 2021"
                },
                "questions": {
                    "value": "- What does the overlapped vertical bar mean? (in Figure 3, Morgan-ATSC7p and ExtraTrees-ATSC7p)\n\n- Please provide the more description of CANDLE framework and the contribution of this paper upon (or based on) the CANDLE framework.\n\n- What is the main novelty of this work? In other words, what was the main difficulty to make this benchmark? Isn't this work a simple combination of existing methods, dataset, and evaluation metrics?\n\n- What is the main advantage of this benchmark, compared to prior benchmarks [1,2] for drug discovery?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8496/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8496/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8496/Reviewer_Pfg9"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8496/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699509628270,
            "cdate": 1699509628270,
            "tmdate": 1699637060997,
            "mdate": 1699637060997,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "w02qQgl51H",
                "forum": "u8L1zzGXRq",
                "replyto": "0jqXC1RTlA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8496/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8496/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Pfg9"
                    },
                    "comment": {
                        "value": "Thank you so much for reviewing our work and for the valuable comments. Please note that the changes we made in the revised paper are temporally highlighted in blue. Please note that Figure and Table number have changed in the revised version.\n\n- About Unclear contribution (weakness 1):\nWe think the reason for this confusion could be Figure 2 (Figure 1 in the old version). Figure 2 is to depict how model comparison is typically carried out using the metrics based on the average prediction errors across all the data points in the test set.  However, our objective in this work is to perform an extended model comparison in terms of prediction errors in different domains of the drug descriptor space. We have mentioned this fact in lines 47-55 and 158-159. In the revised version, we also modified text to clarify the role of Figure 2 results (lines 156-159). Our hypothesis is that, since a drug can be represented in terms molecular descriptors, the errors in different regions of the molecular descriptor space reflect strengths and weaknesses of the drug representation. Our goal is to compare models in terms of these strengths/weaknesses of the drug representation.\n\n- About Insufficient analysis (weakness 2):\nAs mentioned in the previous note, our hypothesis is that a drug can be represented in terms of molecular descriptors therefore enabling us to compare models in terms of their prediction errors in different regions in the molecular descriptor space. We agree that we have not provided sufficient justification. In the revised version of the paper, we provide details how the molecular descriptors corresponding to largest domain errors can be potentially used to pretrain models and thereby to reduce the prediction errors (section 2.4.2, lines 238-248).\n\n- About Lack of descriptions (weakness 3):\nWe agree that sufficient information about the CANDLE framework is not provided in the main text. This is mainly due to the page limit. In the revised version, we described CANDLE and CMP/CV in more detail in the main text (section 2.1).\n\n- About Lack of comparison (weakness 4):\nOur goal of this work is to introduce an alternate model comparison method for which we used drug response prediction as a test case. We agree that carrying out our analysis using more datasets is important. However, such analysis for datasets in Moleculenet cannot be carried out using the drug response prediction models we have used in this work. In a future work, we plan to extend this work to perform our model/representation comparison using several benchmark datasets including Moleculenet.\n\n- About overlapped bars (question 1):\nFigure 3 shows descriptors corresponding to largest and smallest drug response prediction errors in descriptor domains. The prediction errors of a model vary across different regions of a given descriptor. For Morgan model, ATSC7p descriptor\u2019s domain errors are among the largest domain errors and also among the smallest domain errors. In the revised version, to avoid confusion, we removed the overlapping bars from Figure 4 (now Figure 5).\n\n\n- About CANDLE (question 2):\nPlease refer section 2.1\n\n- About novelty (question 3):\nThe novelty of this work is the method to compare models and molecular representations using the domain errors in the molecular descriptor space; not just using the averaged errors like RMSE and MAE. Using CMP/CV, we provide an automated framework to do this comparison for different hyperparameter combinations (In the revised version we have added more clarification on the role of CMP-CV (section 2.1)). The knowledge on such domain-based errors facilitates decision making regarding when and how to use models. For example, according to logS graph in Figure 3, we find that none of the models are suitable to make predictions when very low solubility (logS < -7) drugs are involved.\n\nAs we now know certain representations are worse in the low solubility regime than other, this kind of information also facilitates coming up with improvements to models\u2019 representations. In the revised paper, we have introduced our web application that can rank models based on drug properties selected by a user (section 2.4.1, lines 199-207).\n\n- Main advantage (question 4):\nAs mentioned in the previous note, the main advantage is that we get more insight about a model\u2019s drug representation in terms of different molecular descriptors. This can lead to model improvements. Traditional comparison metrics like R2, RMSE do not provide such insights. (first mentioned in lines 47-55)"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8496/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700692521171,
                "cdate": 1700692521171,
                "tmdate": 1700693864456,
                "mdate": 1700693864456,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RoY7NwY24H",
                "forum": "u8L1zzGXRq",
                "replyto": "0jqXC1RTlA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8496/Reviewer_Pfg9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8496/Reviewer_Pfg9"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the rebuttal."
                    },
                    "comment": {
                        "value": "Thank the authors for their reply. In this moment, I still have some remaining concerns.\n\n---\n[About unclear contribution, W1]: I agree with the reviewer 69P5 and jtTX, which pointed out that the main contribution of this work, i.e., error analysis, is not significant for a main track paper.\n\n---\n[About lack of descriptions, W3]: While I appreciate the authors' efforts to revise their manuscript, some terminologies are still vague. For example, what is HPC infrastructure? How are they constructed? Does the authors implemented it? or borrowed from existing framework?\n\n---\n[About lack of comparison, W4]: I partly agree that MoleculeNet cannot be carried out using the drug response prediction models. Then, is this paper the first work to benchmark drug response prediction models?"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8496/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700717835123,
                "cdate": 1700717835123,
                "tmdate": 1700717857911,
                "mdate": 1700717857911,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]