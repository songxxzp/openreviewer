[
    {
        "title": "Using Attention to Weight Particles in Particle Filters"
    },
    {
        "review": {
            "id": "J62wmvjJ8d",
            "forum": "UeGTOoPDu6",
            "replyto": "UeGTOoPDu6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3888/Reviewer_1peL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3888/Reviewer_1peL"
            ],
            "content": {
                "summary": {
                    "value": "This is an evaluation of an alternative particle filter weighting heuristic, using dot-product similaraties (inspired by the current popularity of transformers) instead of conventional particle weights.\n\nThe approach is evaluated in the context of localization (and navigation) in a toy 3D environment, measuring accuracy and runtime, and it is also applied for synchronizing real audio tracks."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- Improving the effectiveness of particle filtering is an important problem, though the proposed method has some issues (see weaknesses).\n- The exposition is generally easy to follow.\n- The chosen evaluation experiments make sense, albeit somewhat limited in scope.\n- A runtime evaluation is included."
                },
                "weaknesses": {
                    "value": "- A related work section is missing entirely.\nThis is not justified from my perspective, there are plenty of works on how particle filters can be extended to neural state-space models (e.g. see [1, 2, 3]), where emissions and transitions parameterised by neural nets lead to advanced methods for both inference, and the respectively particle weighting.\nTo improve the paper, such methods should be discussed and the differences to them should be used to motivate the research.\n- The probabilistic theory behind particle filters is not discussed in enough detail, and it is not used to justify the selected weighting scheme. Therefore, the choice to use dot-product attention as particle weights appears to be a heuristic. While there are many cases where heuristics can be useful, I could not find a precise argument in the paper for why the authors believe it would work better. The method would benefit from a more precise positioning, and ideally a better description of the mathematical fundamentals and how the method fits in their context.\n- If I am interpreting them correctly, the empirical results do not show a significant advantage of the proposed particle weighting heuristic. Neither in figure 2 (which compares the results for the localization task), nor in Table 1 (which has the navigation results). The statement \"the two functions usually perform the same\" (comparing the Gaussian weighting baseline and the proposed method) does not match with the reported navigation success rates.\n- The runtime of the method is not better than the considered Gaussian baseline on the CPU. The differences in reported runtime on GPU seem small, and might be due to GPU execution overheads (e.g. memory transfers or peculiarities of the used torch primitives). It would make sense to plot the GPU and CPU runtime results on different scales, and for the GPU many more particles should be considered.\n- In terms of the 3D toy localization environment:\n    - The experiments seem to assume a baseline with a Gaussian emission $\\mathcal{N}(\\mathbf{x}; \\mathbf{z}, \\sigma^2\\mathbf{I})$ over observations $\\mathbf{x}$ centered on a latent state (i.e. particle) $\\mathbf{z}$, i.e. as if the emission model is an identity with noise $\\mathbf{x} = f(\\mathbf{z}) + \\mathbf{e}$. But this is not what is happening in practice (based on the provided anonymized code), it should be corrected.\n    - I find the term \"particle observations\" inaccurate, particularly because these are apparently different from the standard agent observations. I believe what was meant by this was the particles themselves, or a deterministic function thereof. I think this should be corrected.\n    - The histograms in fig 2 are not normalized, which makes it harder to compare the methods.\n\nI am sorry, but based on the overall results I cannot readily accept the claims that the proposed scheme is comparable in accuracy, but faster than conventional PF evaluations.\nThe paper would benefit from a more principled mathematical motivation behind the proposed weighting. It would also benefit from a thorougher evaluation that pinpoints potential advantages.\n\n[1] Maddison, C.J., Lawson, J., Tucker, G., Heess, N., Norouzi, M., Mnih, A., Doucet, A. and Teh, Y. Filtering variational objectives. NeurIPS 2017.\n\n[2] Le, T.A., Igl, M., Rainforth, T., Jin, T. and Wood, F. Auto-encoding sequential monte carlo. ICLR 2018.\n\n[3] Corenflos, A., Thornton, J., Deligiannidis, G. and Doucet, A. Differentiable Particle Filtering via Entropy-Regularized Optimal Transport. ICML 2021"
                },
                "questions": {
                    "value": "In the provided code it seems the Gaussian weights of the localization task are based on the difference between range readings and the offsets between the particles and the known landmark coordinates, am I interpreting this correctly? If so this should be described better in the main text."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3888/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698686737726,
            "cdate": 1698686737726,
            "tmdate": 1699636347616,
            "mdate": 1699636347616,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "TlKh6B8IBS",
            "forum": "UeGTOoPDu6",
            "replyto": "UeGTOoPDu6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3888/Reviewer_8Hzj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3888/Reviewer_8Hzj"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes to use softmax dot-product attention to weight the consistency of particles in particle-filtering-based state estimation. The classical way of weighting particles is performed using a Gaussian probability distribution, in which a partition is weighted by how consistent it is with the observed data from sensors.\n\nThe idea is straightforward so the author investigated in a few physical and temporal localization and navigation tasks (physical experiment via simulation and real music localization data)."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* It is rare to see the application of softmax dot-product attention in state estimation. So it is definitely a novel idea.\n* The paper has a clear introduction which led to the main idea.  The paper is clearly written and easily understandable by providing intuitive examples (figure 1) and high-level figures (e.g., Figure 3).\n* The paper also presents the computational comparison between the normal weighting and the attention based weighting and also found out that via GPU, the attention version actually outperformed the Gaussian PDF. So it seems the attention weighting is able to utilize the GPU (parallel computing) better."
                },
                "weaknesses": {
                    "value": "* The contribution seems very limited and the application scope is widely unknown. (I would actually recommend to use a different revenue for publishing, e.g. a sub-track of the main conference)\n* As the author already pointed out in section 2, attention might be more intuitive to be used as a measure for vectors with similar magnitude. This assumption is not usually valid in most state estimation scenarios.\n* The sharpness parameterization the author introduced in section 2 lacks better explanation, where \\alpha=1/4 seems more like a magic number and lacks theoretical support."
                },
                "questions": {
                    "value": "* How do you come up with the number \\alpha and the sharpness parameter? Is there any more explanation you can provide?\n* How would you relax the assumption of vector magnitude (in a similar scale)? Otherwise it seems really limited in a tracking application."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "n/a"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3888/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698731009663,
            "cdate": 1698731009663,
            "tmdate": 1699636347535,
            "mdate": 1699636347535,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "ZJUb6iaN6v",
            "forum": "UeGTOoPDu6",
            "replyto": "UeGTOoPDu6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3888/Reviewer_EvVM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3888/Reviewer_EvVM"
            ],
            "content": {
                "summary": {
                    "value": "This paper examines the possibility of using attention (borrowed from neural networks and large language models) to act as the observation probability (weight) for a particle filter, as applied to localization and navigation (in robotics and in music segments). Attention is compared to the conventional Gaussian error estimation. Results are somewhat equivocal, and the authors discuss where attention could be useful and where it will not be helpful."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Using attention is a very interesting idea that was worth the attempt, especially given how central it is to LLMs. However, the attention has overall similar performance to Gaussian (though in quite different ways) - but to the authors' credit they seek to give insights into where attention could be useful and where it is not.\n\n- Two quite different experiments (agent navigation, music localization) were tested, and the authors are very candid with how the systems performed."
                },
                "weaknesses": {
                    "value": "- There really isn't much in it between Gaussian error and attention, in both performance and speed.\n\n- Although the authors spend time discussing where attention may be useful, the discussion is not concrete enough to make it easy to predict ahead of time where it definitely will work well. That would be a tough task I know, but it would raise the paper's stock considerably.\n\n- In brief, the paper is fine as a piece of research and the topic is a valid one, there just isn't enough 'weight' in the paper (results, insights, techniques) to justify recommending it for ICLR. It's a pity because I found the paper to be a good read."
                },
                "questions": {
                    "value": "- Whilst the authors discuss what attention could be useful for, they tend to be rooted in the reader understanding exactly what attention is. A stronger insight or actionable method by which attention can be 'cajoled' into being a good weighting measure would be ideal, but I am not sure this is realistically achievable by the authors and/or anyone else?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3888/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698752655130,
            "cdate": 1698752655130,
            "tmdate": 1699636347440,
            "mdate": 1699636347440,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "GM5SNSjGfE",
            "forum": "UeGTOoPDu6",
            "replyto": "UeGTOoPDu6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3888/Reviewer_Vkcn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3888/Reviewer_Vkcn"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes to use the attention computation mechanic used in transformers to compute token weights to compute weights of particles in a particle filter. Several experiments are performed to evaluate the accuracy in contrast to a simple Gaussian weighting scheme as well as the runtime performance."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "From the description of the paper it is not obvious what the strengths of the proposed approaches are."
                },
                "weaknesses": {
                    "value": "The description of the method feels incomplete as the text mainly gives general explanations and seemingly unrelated anecdotes. Overall the section feels like an extended introduction to the method, but is missing the crucial details. Given the simplicity of particle filters a good way to make the method clearer would be to provide pseudo code of the entire system and use that to explain the details of the proposed approach.\n\nThe resampling methodology utilized is very non-standard, at least as far as typical robotics applications go. Resampling is performed by resampling particles with a likelihood proportional to their weight, resulting in possible duplicate particles without any arbitrary noise addition. The separation of such duplicate particles is ensured through the stochastic motion model. Such a motion model appears to be missing, or at least not fully explained in the paper. \n\nThe experimental section does not demonstrate the ability of the proposed mechanism to be a suitable replacement for even a Gaussian weighting mechanism. In the navigation results shown in Table 1, the proposed method has a success rate of 29% while the Gaussian weighting has 100%. The paper states that both methods achieve similar performance, however, I'm unsure how this can be considered similar. The same holds for the second scenario. Even in  the higher dimensional task in Section 3.3 the Gaussian method has clearly lower error. Finally, the runtime numbers show that both methods seem to be roughly equal when the standard deviations are considered. If runtime wasn't reported per step but over a longer horizon the differences might be bigger or better visible.\n\nFrom a robotics point of view the localization setup in the experiments is severely limited. For one it appears that only position information is considered and orientation is omitted. Second, the observations are against landmarks with a simplistic range error model. This kind of setup could also be approached with a Kalman filter which should be one of the comparisons. The scenario in which a particle filter is often employed is when using an occupancy grid map based sensor model with complex stochastic motion models. Such a setup would be significantly more convincing and possible able to demonstrate the utility of the proposed approach.\n\nIn it's current form the paper lacks the necessary detail about the method and the results do not demonstrate the benefits of the proposed method."
                },
                "questions": {
                    "value": "- How does the proposed method work on more complex sensor models?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3888/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699316350755,
            "cdate": 1699316350755,
            "tmdate": 1699636347345,
            "mdate": 1699636347345,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]