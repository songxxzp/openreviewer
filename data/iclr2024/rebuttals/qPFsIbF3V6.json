[
    {
        "title": "Guess & Sketch: Language Model Guided Transpilation"
    },
    {
        "review": {
            "id": "geOOiN11eZ",
            "forum": "qPFsIbF3V6",
            "replyto": "qPFsIbF3V6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4175/Reviewer_LBov"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4175/Reviewer_LBov"
            ],
            "content": {
                "summary": {
                    "value": "this work presents a way of transpilation: turning one assembly code into another functionally equivalent assembly code.\n\nthe main techniques consists of: using a LM to generate candidate programs. from the internal values of the LM 1) alignment/attention and 2) uncertainty, generate localized sketches with holes for the candidate program. this localized sketch is then solved, with the holes resolved to values that are provably equivalent to the source code's corresponding fragments. the fragments are then stitched together, finishing the transpilation process.\n\nresults show the proposed method beats a reasonable set of baselines -- a heuristic based transpiler, and few-shot using gpt4."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "## the good part of quality: that it worked\nThe presented method works, on a domain of highly structured translation task (i.e. highly stylized texts), something a language model should perform very well at, and it shows. The extra care taken to correct the translation locally is a reasonable yet good idea to complement the weakness of the language model.\n\nThe benchmark is thorough, and the evaluation (on what is being shown) is solid. \n\n## clarity\nI am very grateful how this work is able to encapsulate the domain specific aspects of compiler and assembly, so that the top level algorithm remains accessible to the ML audience. Thank you!\n\n## novelty : fair\nI think it is a straight forward paper, and it outlined reasonable decompositions of the transpiling tasks to LLM and a symbolic solver."
                },
                "weaknesses": {
                    "value": "## the not so good part of quality:\n\n### evaluation set is small \nThis work can be significantly beefed up with a synthetic test set. Evaluation on mere 100s of programs is likely not sufficient. Since it is possible to compile C into both architectures, and since test generation / fuzzing is a well established approach, this work can benefit from an artificial/synthetic test set consists of about ~1k programs, to evaluate the correctness of the transpiler more thoroughly. \n\n### lack of statistic tests\nAt least we should see confidence intervals of the results, or some kind of t-test to make sure that the proposes method is better than the baseline not due to noise. Kindly ask your colleagues in statistics to look over your tables and give recommendations on how it could be made bullet proof.\n\nI would love to see this update in the rebuttal period.\n\n## fit of venue\nWhile I think this is a good paper, it might be a better fit at PLDI. As I am unsure what is the AI/ML lessons gained from this work, other than it is possible to build such a system, and some relatively detailed finding on how well language models are at learning over a highly stylized text (assembly code) when compared to English sentences.\n\nHowever, as other application papers of the compiler flavour has a precedence of appearing at ICLR, this is not a major concern."
                },
                "questions": {
                    "value": "## program equivalence?\n\nAs I understand program equivalence is an undecidable problem. If I recall correctly, synthesis systems like sketch does not have a way to fully verify the SKETCH and the SPEC are identical over all input-outputs, but only over a bounded domain?\n\nIs this an issue for your work? Or is it because everything is bounded to begin with, as we're working over assembly and we only need to account for, for instance, 16 bits integers or similar ? Or is it some Z3 theory magic that allows for a DSL which programs can be reasoned for full equivalence?\n\nAt any rate, this should probably be clarified in the paper.\n\n## successfully compile = ?\n\nIf I read correctly, success is measured over a set of input-output test cases to see if the input code runs the same as the compiled output code. Is this related to the program equivalence problem above somehow? Is this comprehensive enough to make sure the transpiling is not mistaken?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4175/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4175/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4175/Reviewer_LBov"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4175/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698816391423,
            "cdate": 1698816391423,
            "tmdate": 1700720297950,
            "mdate": 1700720297950,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "IKob4uYySa",
                "forum": "qPFsIbF3V6",
                "replyto": "geOOiN11eZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4175/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4175/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your careful consideration and detailed review of GUESS & SKETCH. The questions and suggestions about evaluation have been illuminating, and we respond to them below.\n\n**Re: evaluation set is small.**\n\nThanks for the feedback.  \n\nTo further rigorously evaluate the correctness of the GUESS & SKETCH transpiler against the most competitive transpiler baseline, we collected an additional test set of 82 real-world programs, and conducted experiments in both translation directions. The results show that our method correctly transpiles 41.5% of programs from RISC to ARM, compared to 34.1% by the Encoder-Decoder, and 51.2% from ARM to RISC, compared to 37.8% by the Encoder-Decoder. Details are further shared in the Appendix, section B. \n\nWe note that we were limited by the goal of collecting high quality, evaluable programs. The hundreds of programs used in the existing test sets are collected from real mathematic programming challenge problems, computer program performance benchmarks, and realistic interactive programs.\n\n**Re: lack of statistical tests**\n\nThanks for the suggestion.\n\nWe ran statistical tests on our results. The top two competitive baselines are the engineered Transpiler and the Encoder-Decoder. The z-score against the Transpiler is 6.89 and against the Encoder-Decoder is 4.57, both of which allow us to conclude with a significance level of 0.01 that GUESS & SKETCH outperforms the baselines. While we agree that thousands of synthetic programs could provide additional support for comparing the transpilation methods, the existing results do show strong statistical significance.\n\n**Re: fit of venue**\n\nWe agree that cross-disciplinary nature of this work makes it a suitable paper for multiple different venues. We note previous ICLR submissions that explored code generation/translation (Synchromesh, Poesy et al. 2022; Leveraging Automated Unit Tests for Unsupervised Code Translation, Rosier et al. 2022; InCoder, Fried et al. 2023; Binding Language Models in Symbolic Languages, Cheng et al. 2023; DocPrompting, Zhou et al. 2023; etc.) and compiler innovation (DLVM, Wei et al. 2018; Code Translation with Compiler Representations, Szafraniec et al. 2023; etc.) have also been well-received.  Given the machine learning and program synthesis backbone of GUESS & SKETCH, as well as the real-world application of the task proposed, we think that many members of the ICLR audience would be interested in reading and building on this work.\n\n**Re: measuring success and \u201cprogram equivalence\u201d**\n\nWe use test case input-output equivalence to measure success in the transpilation task. This is not a true measure for program equivalence, but this evaluation setup has been used as a proxy for success in related works in inductive program synthesis (Flashfill, Gulwani 2011; DreamCoder, Ellis et al. 2020) and today's major code generation benchmarks (HumanEval, Chen et al. 2021; MBPP, Austin et al. 2021; APPS, Hendricks et al. 2021).\n\n**Re: verification of subprogram equivalence in Sketch**\n\nYes you are correct that this domain needs to be specified for Sketch. We fix the domain of inputs over which Sketch verifies equality. This input domain can be restricted for this domain, specifically by the registers of the assembly architectures used, which in this work is size-64 bitvectors."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4175/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700229924160,
                "cdate": 1700229924160,
                "tmdate": 1700229924160,
                "mdate": 1700229924160,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NKGUdCO3jn",
                "forum": "qPFsIbF3V6",
                "replyto": "IKob4uYySa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4175/Reviewer_LBov"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4175/Reviewer_LBov"
                ],
                "content": {
                    "title": {
                        "value": "substantial response that warrants a raised score"
                    },
                    "comment": {
                        "value": "thanks for addressing these concerns, I'm raising my score to 7, but since there is no 7, I rounded up to 8.\nI do think this work is substantial enough and thorough enough after the updates."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4175/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700720413166,
                "cdate": 1700720413166,
                "tmdate": 1700720413166,
                "mdate": 1700720413166,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Z4w14pVdEj",
            "forum": "qPFsIbF3V6",
            "replyto": "qPFsIbF3V6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4175/Reviewer_awtu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4175/Reviewer_awtu"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents an approach for translating low-level assembly programs into higher-level code for the purpose of analysis and human understanding. The approach is based on a combination of neural processing and symbolic program translation. The proposed approach,  called GUESS & SKETCH, extracts alignment information from features of the neural language model and passes it to a symbolic solver to perform \"transpilation\". The paper also presents experiments illustrating the benefits of GUESS & SKETCH as compared to GPT-4 and an engineered \"transpiler\"."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "The paper is well written and presents a clear contribution. The combination of generative language models and program synthesis by sketching is new and it is shown to be effective as compared to state of the art techniques."
                },
                "weaknesses": {
                    "value": "I could not understand the correctness guarantee provided by the approach. The authors say \"the correctness of GUESS & SKETCH is always lower-bounded by the correctness of the initial guess\" -- the authors should explain what they mean by lower bound here. If the translation is incorrect, how can it be useful in practice?\n\nThe scalability is unclear.  What s the largest program that has been translated using the approach presented here?"
                },
                "questions": {
                    "value": "Please see above?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4175/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4175/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4175/Reviewer_awtu"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4175/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698821551991,
            "cdate": 1698821551991,
            "tmdate": 1699636383507,
            "mdate": 1699636383507,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "EwGjAVzn15",
                "forum": "qPFsIbF3V6",
                "replyto": "Z4w14pVdEj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4175/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4175/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their comments. The questions raised highlight important clarifications about the benefits of our approach.\n\n**Re: correctness lower bound**\n\nLet us clarify this statement, as we did not mean to overclaim here. What we mean by \u201cthe correctness of GUESS & SKETCH is always lower-bounded by the correctness of the initial guess\u201d is that *if* the initial guess generated by the language model is correct, then GUESS & SKETCH does nothing additional and simply returns the correct guess. If the original generation is incorrect, GUESS & SKETCH may or may not be able to correct it. Therefore, GUESS & SKETCH is always lower-bounded in correctness by the correctness of the language model. Note that GUESS & SKETCH, and no existing neural approach, *guarantee* correctness of the translation.\n\n**Re: downstream use of incorrect translation**\n\nAn incorrect translation may not be directly useful as-is. Subsequent post-processing may be used to correct an incorrect translation. In this work, we show how an automated solver-based post-processing step (SKETCH) can perform corrections. Other future work may examine other methods of correction, such as with hints to humans, synthesis engines, or other language models. \n\n**Re: scalability**\n\nGUESS & SKETCH is limited to *functions* that are shorter than the context window of the underlying language model. The context window of the language model used in this paper is 2048 tokens, but could be exteneded. Since multiple functions compose a full program, the program can be arbritrarily long. The largest program we successfully transpile is fannkuch-redux-3 in the Benchmarks dataset. It has 10 functions and 1 header. In ARM, this is 4297 tokens total (longest function has 1405 tokens). In RISC, this is 3877 tokens total (longest function has 1321 tokens)."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4175/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700230008963,
                "cdate": 1700230008963,
                "tmdate": 1700230008963,
                "mdate": 1700230008963,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iqVHJ3GvOw",
                "forum": "qPFsIbF3V6",
                "replyto": "EwGjAVzn15",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4175/Reviewer_awtu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4175/Reviewer_awtu"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarifications. I maintain my score."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4175/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700586723446,
                "cdate": 1700586723446,
                "tmdate": 1700586723446,
                "mdate": 1700586723446,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "PZAO8ki9Ov",
            "forum": "qPFsIbF3V6",
            "replyto": "qPFsIbF3V6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4175/Reviewer_nDKt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4175/Reviewer_nDKt"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents an approach for machine language translation. They attempt to utilise a generative language model with a confidence score to identify uncertain blocks or \"guesses\" which can then be symbolically solved using a neuro-symbolic solver. They rely on Sketch (Solar-Lexama  et al)  prior work for handling the expansion/completion of the uncertain tokens. The authors perform experiments on other three datasets (Unix, Euler, Benchmarks) outperforming or equal (in rare cases) in all test settings."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- While a simple concept, the method outperforms prior work\n- The concept of uncertainty is a good mapping to identify holes in the generated program\n- Evaluation is robust and thorough, providing analysis of failure cases\n- Authors identify a setting for Neuro-symbolic approaches to work stably and outperform prior works"
                },
                "weaknesses": {
                    "value": "- Novelty within this approach is quite limited the translation is a standard approach the confidence is simple (see below), and they use an existing neuro-symbolic solver therefore, it is more on the sole idea of putting these together. This is the main criticism. However, they outperform prior work, and the idea is interesting and technically sound. \n- Confidence is very trivially explained. In general, deep models are very confident even when they are wrong. It isn't clear how this was implemented and is critical to the method. As the author's rely on this to identify potential errors for solving.\n- The parameter lambda is not ablated on as the threshold for identifying blocks. It is unclear if this is set low to allow more errors i.e. false negatives but to make the result more robust."
                },
                "questions": {
                    "value": "- Explain more how the confidence is applied and used is it based on prior work as there is significant literature in this area\n- Does the Lamda hyper-parameter effect the output, was this ablated on, but not included?\n- Why do you choose only the region of error to be solved? Did you consider using a buffer before and after as well to increase the consistency across the section and provide context?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4175/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698828060512,
            "cdate": 1698828060512,
            "tmdate": 1699636383422,
            "mdate": 1699636383422,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lBmeO0bTTl",
                "forum": "qPFsIbF3V6",
                "replyto": "PZAO8ki9Ov",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4175/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4175/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your insights and questions. We have incorporated feedback to clarify how we use model prediction confidence and determine regions of error to correct. Please find below detailed responses and updated draft to address the listed questions.\n\n**Re: novelty**\n\nWe agree that the final version of GUESS & SKETCH is quite simple. We experimented with more complex methods, but were able to simplify things down to a few core ideas (model confidence \u2192 sketch solver). We believe that this simplicity is an advantage for using this approach in practice. \n\n**Re: model prediction confidence. is this an imperfect measure of mistakes**\n\nOur goal of identifying potential mistakes is to filter which output subsequences to correct, since correcting every output subsequences is too computationally expensive. Indeed, as previous works have studied (R-U-Sure, Johnson et al. 2023, 'Generation Probabilities Are Not Enough', Vasconcelos et al. 2023), the underlying language model can be very confident about incorrect predictions, so confidence alone may not be sufficient to identify all errors. However, empirically in this domain we found that there was significant signal in this property, as shown by the experimental results. While neither confidence nor attention provide hard guarentees, they both provide signal in this domain. Future versions of GUESS & SKETCH can be further improved by devising better domain-general heuristics for identifying potential errors.\n\n**Re: ablation on gamma hyper-parameter**\n\nThanks for the suggestion. \n\nWe ran an ablation study on the gamma hyperparameter with the Project Euler test set. We found that a range of gamma hyper parameters still produces the same results. We sweep across gamma values: 0.8, 0.9, and 0.95 to study this trade-off between computation time and correctness. We find that across these gamma values, the number of corrected programs is the same, but the inference runtime increases with gamma. From 0.8 to 0.95, the inference time increases by 2.2x. This suggests that the model is extremely confident on most tokens, and that even a low-gamma is able to find plausible errors. \n\n**Re: how do we choose the region of error to be solved?**\n\nThe region of error to be solved must be a contiguous subsequence whose source semantics can be extracted for the SKETCH step. In the assembly domain, we exploit the domain specific idea of a \u201cpure basic blocks\u201d. This is based on standard basic blocks (Computer Architecture, Patterson & Hennessy) and described further in Appendix A.1. For this problem and SKETCH setup, these block are functionally independent, so we would not improve by larger regions. For other domains we agree that we might need to expand the subsequence could provide more context."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4175/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700230196243,
                "cdate": 1700230196243,
                "tmdate": 1700230196243,
                "mdate": 1700230196243,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]