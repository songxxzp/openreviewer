[
    {
        "title": "Zero-Level-Set Encoder for Neural Distance Fields"
    },
    {
        "review": {
            "id": "p9wGGmVNJ2",
            "forum": "BC4AUywMow",
            "replyto": "BC4AUywMow",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3753/Reviewer_ysCV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3753/Reviewer_ysCV"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces an encoder/decoder neural network designed to predict Signed Distance Functions (SDFs). This network is trained using the Eikonal equation, eliminating the need for ground truth SDF supervision. The pipeline takes a 3D meshe as input and subsequently outputs the SDF value at any specified query point."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "No training ground truth SDFs are required, which saves a bit of preprocessing computations. The network is trained using the Eikonal equation, eliminating the need for densely-sampled and accurate signed distances during training (which can nonetheless be obtained very easily, see weaknesses).\n\nThe new encoder architecture uses a unique multi-scale hybrid system that combines graph-based and voxel-based components, integrating both mesh and grid convolutions with projections from the mesh to the grid, at multiple scales.\n\nThe paper provides a solution for cases where surface normals are not well-defined, which is a common challenge in 3D geometry: simply using an unoriented cosine similarity.\n\nWriting is very clear."
                },
                "weaknesses": {
                    "value": "My central and huge concern is about the utility of such a pipeline: it inputs a mesh, outputs its SDF. This function (computing an SDF) can quickly be performed without any learning based technique, using standard geometric computing librairies like IGL or trimesh.\nAll the information is already present in the mesh! Why use a network to learn it?\nOverall, using a neural network for this introduces computational overhead (the network needs to be trained), complexity, un-explainability, approximations, and has no clear motivation. \n\nFrom this stems another weakness: the comparison with other baselines is unfair, since Convoccnet, IFNet and ONet take pointclouds as inputs, not meshes. In other words, they reconstruct a surface from an incomplete input, while the proposed pipeline has access to a full mesh.\n\nIf the method was about robustly getting an SDF out of a poorly triangulated mesh, then the whole paper needs to be rewritten with this target in mind. This means that the introduction should clearly set this goal, and the experiment sections needs to be reworked in order to include experiments on broken meshes with different defects, on which standard libraries fail.\n\nAlternatively, if the method is about a novel mesh encoder network, then the task and decoder need to be changed to something else than regressing an SDF - part segmentation, classification\u2026.\n\nFinally, if the point is about demonstrating that an SDF can be learned without explicit supervision, only by solving the Eikonal equation: this has already been demonstrated in SAL and SAL++ (Atzmon et al., these references are missing). For the cases shown in this submission, this is a made up problem, since ground truth SDF values can easily be computed, and are even used in the network evaluation. In other words, this does not enable new applications."
                },
                "questions": {
                    "value": "Mostly: Why use a neural network to replace a traditional pipeline?\n\nHow does the proposed method perform in scenarios with noisy or incomplete data (pointclouds instead of meshes)?\nHow does the computational efficiency of the proposed method compare to traditional methods, especially in large-scale applications?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3753/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697547980196,
            "cdate": 1697547980196,
            "tmdate": 1699636331598,
            "mdate": 1699636331598,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZFT2N5bsh5",
                "forum": "BC4AUywMow",
                "replyto": "p9wGGmVNJ2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3753/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3753/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Official Review by Reviewer ysCV"
                    },
                    "comment": {
                        "value": "Thank you for the feedback on our paper. To address most of your concerns we would like to refer you to the [Authors Statement](). For completeness we have included a response to the second part of the second question here. \n\n***\n\n> [Q2] How does the proposed method perform in scenarios with noisy or incomplete data (pointclouds instead of meshes)? How does the computational efficiency of the proposed method compare to traditional methods, especially in large-scale applications?\n\nRegarding the comparison to traditional methods - we assume this refers to traditional surface reconstruction methods - we may revisit in the future. While a direct comparison would be interesting, we wanted to focus on comparisons with neural approaches in this work."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3753/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700253203920,
                "cdate": 1700253203920,
                "tmdate": 1700253203920,
                "mdate": 1700253203920,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "bsDIwzV0FZ",
            "forum": "BC4AUywMow",
            "replyto": "BC4AUywMow",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3753/Reviewer_Msao"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3753/Reviewer_Msao"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes to represent 3D geometry using neural networks, using an encoder-decoder architecture. Using this design, it primarily addresses the task of 3D shape reconstruction from meshes. \nThe major technical contribution is the \"hybrid\" encoder architecture. Given a mesh, the method uses (1) a graph convolutional encoder to extract per-vertex features; (2) a multi-resolution grid structure to accumulate features from the vertices on grid nodes.\nThe authors also leverages the Eikonal loss to learn the neural signed distance field, obviating the need for pre-computing the SDF values in the training data. Although this is also claimed as a major contribution, it has been widely used in the neural shape modeling literature as of 2023.\nExperiments have validated some of the design choices (such as the interpolation scheme when aggregating the grid features), and have compared to a few recent baselines. In general, the proposed method does show superior performance in terms of local geometric details. However, quantitative results do not consistently surpass certain baselines and some more recent work should have been considered as baselines."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The hybrid encoder architecture is an intuitive design that makes sense, and is clearly demonstrated. Since the input are meshes, leveraging the graph convolution to extract features is a clever design which can (intuitively) bring extra information about the surface than only using the grid structures as in previous work (e.g. ConvONet and IFNet).\n\n- The reconstructed surfaces have good quality especially in terms of local geometric details. On the airplane examples (as in the supplementary video), the model also shoes good performance reconstructing thin and (pontentially non-manifold) structures such as the fin and wings."
                },
                "weaknesses": {
                    "value": "- Motivation: First of all, I'm wondering what's the practical application of the proposed method. The method assumes a mesh as input and aims to reconstruct a signed distance function from it, which also represents the geometry. If we already have the geometry well represented by a mesh, why is it necessary to reconstruct an SDF from it at a cost of losing certain surface details? On the other hand, given a mesh, one can directly compute the (signed) distance function by computing the distance from the query point to the surface. What's the benefit of introducing a neural network?\n\n- Technical technical contribution: \n   - The Eikonal loss is considered as a major technical novelty, but it has been proposed for learning 3D shapes in (Gropp et al. 2020) \n \"Implicit Geometric Regularization for Learning Shapes (IGR)\", and widely adopted for rendering implicit geometry (e.g. NeuS [Wang et al. NeurIPS 2021], VolSDF [Yariv et al. NeurIPS 2021]) and other downstream tasks such modeling deformable shapes (e.g. SCANimate [Saito et al. 2021]). This hurts a major technical contribution of this paper. At least the IGR paper by Gropp et al. should be cited and discussed. \n   - While the hybrid encoder is interesting, the whole pipeline is more of a straightforward combination of standard modules (as of 2023) such as the graph convolution encoder, the multi-resolution features (as in IF-Net and NGLOD), and Siren decoder (as in the SIREN paper by Sitzmann et al). While admittedly this shouldn't be a major weakness per se, it is crucial to have more thorough ablation experiments to validate the intuitive combination. Most importantly, the graph conv + grid conv encoder is the key contribution. What would happen if the graph conv is shut down and one only uses the traditional point-encoder by densely sampling points from the input mesh surface? What if one doesn't use grid projection+interpolation at all, and simply uses the interpolated feature at the query point's nearest point on the mesh surface? To me, such experiments are critical in validating the technical contributions, but are missing. \n\n- Experiments. \n   - First of all, all baseline methods are from 2020 and do not represent the state-of-the-art performance. For example, POCO (Boulch et al., CVPR 2022) can be considered as a stronger baseline model for reconstructing shapes. \n   - In terms of model performance, the proposed method has significantly higher \"relative error\" than IFNet on all datasets and there lacks a sound explanation supported by experiments. Again, given a mesh, computing the *accurate* SDF is straightforward, but from table 1, the proposed method cannot reproduce this property, which thus undermines its potential in the applications.\n   - (minor) Table 2 only reports numbers on the Dragons and states 'results on other datasets are similar' -- I'd recommend showing all the results to make this statement more convincing."
                },
                "questions": {
                    "value": "- For the baselines in Sec. 4.3, how many points are sampled from the mesh surface before sending into the encoder?\n- In page 6, \"Competing methods\" paragraph, it is stated that the baseline methods are equipped with the same SIREN decoder as used in the proposed method. Does this yield a better performance than the original version of these models using their own decoder?\n- In page 5, paragraph below Eq. 2 states that the last two terms in Eq. 2 are redundant but can improve training. Is there experimental results that support this argument?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "I do not have ethical concerns about this submission."
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3753/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3753/Reviewer_Msao",
                        "ICLR.cc/2024/Conference/Submission3753/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3753/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698678019794,
            "cdate": 1698678019794,
            "tmdate": 1700705294552,
            "mdate": 1700705294552,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "37VOlsLfQd",
                "forum": "BC4AUywMow",
                "replyto": "bsDIwzV0FZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3753/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3753/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Official Review by Reviewer Msao (1/2)"
                    },
                    "comment": {
                        "value": "We appreciate the critical feedback and would like to address your concerns about our paper in the following.\n\n## Weaknesses\n\n> [W1] Motivation: First of all, I'm wondering what's the practical application of the proposed method. [...] On the other hand, given a mesh, one can directly compute the (signed) distance function by computing the distance from the query point to the surface. What's the benefit of introducing a neural network?\n\nSee the [Authors Statement]().\n\n***\n\n> [W2.1] The Eikonal loss is considered as a major technical novelty, but it has been proposed for learning 3D shapes [...] This hurts a major technical contribution of this paper. At least the IGR paper by Gropp et al. should be cited and discussed.\n\nSee the [Authors Statement]().\n\n***\n\n> [W2.2] While the hybrid encoder is interesting, the whole pipeline is more of a straightforward combination of standard modules (as of 2023) [...]. While admittedly this shouldn't be a major weakness per se, it is crucial to have more thorough ablation experiments to validate the intuitive combination. [...] To me, such experiments are critical in validating the technical contributions, but are missing.\n\nSee the [Authors Statement]().\n\n***\n    \n> [W3.1] First of all, all baseline methods are from 2020 and do not represent the state-of-the-art performance. For example, POCO (Boulch et al., CVPR 2022) can be considered as a stronger baseline model for reconstructing shapes.\n\nThank you for suggesting a more recent work as a baseline alternative. While we would also like to compare with this method, the additional complexity of attention-based interpolation of features makes this method more expensive than other baselines. This should not rule the method out per-se, but it definitely makes it harder to justify comparisons with this method, when performance is desirable. We may however revisit this suggestion.\n\n***\n\n> [W3.2] In terms of model performance, the proposed method has significantly higher \"relative error\" than IFNet on all datasets and there lacks a sound explanation supported by experiments. Again, given a mesh, computing the *accurate* SDF is straightforward, but from table 1, the proposed method cannot reproduce this property, which thus undermines its potential in the applications.\n\nWe believe this is somewhat of a misinterpretation of the presented results. Our method has \"slightly\" higher relative error than IF-Net on most datasets, especially when compared to the other baselines. The intuitive explanation that we provide in the paper, is that our grid is sparse by design and has less degrees of freedom at distances far from the surface, resulting in larger relative errors, even though the accuracy at the surface is clearly better (see Chamfer distance and surface point loss). \n\nNevertheless, as we now also train only on point clouds, we have to rerun the evaluation and will have to select a more suitable metric for comparing point clouds, as the *accurate* SDF computation becomes non-trivial. Other related works suggest to use e.g. the Hausdorff distance or the normal consistency loss in addition to the Chamfer distance. We will update the metrics in main document once we obtain them.\n\n***\n\n> [W3.3] (minor) Table 2 only reports numbers on the Dragons and states 'results on other datasets are similar' -- I'd recommend showing all the results to make this statement more convincing.\n\nThe deforming dragons experiment is absolutely representative for the model performance during ablation, but a more complete picture could be provided by giving metrics for the other datasets in the future. We will keep this suggestion in mind for the future, thank you."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3753/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700253081439,
                "cdate": 1700253081439,
                "tmdate": 1700253081439,
                "mdate": 1700253081439,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Jh3A93CjLv",
                "forum": "BC4AUywMow",
                "replyto": "bsDIwzV0FZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3753/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3753/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Official Review by Reviewer Msao (2/2)"
                    },
                    "comment": {
                        "value": "## Questions\n\n> [Q1] For the baselines in Sec. 4.3, how many points are sampled from the mesh surface before sending into the encoder?\n\nWe apologize for the oversight of not mentioning this explicitly. We send all of the mesh vertices into the encoder. Along with using raw data for training and testing, we found it would be helpful to be able to have an architecture that is agnostic to the number of input points. We have extended the other baselines to be able to do the same, as their underlying methods, e.g. PointNet or occupancy-driven CNNs  are also agnostic to the number of input points. The same holds true for our presented network architecture.\n\nAs we show in our results, and especially on the datasets with wildly varying vertex counts (ShapeNet and Thingi10k), it is quite possible to achieve good results using a variable number of input points. That being said, additional points for training are sampled in the manner described in Section 3.3 on page 5.\n\n***\n\n> [Q2] In page 6, \"Competing methods\" paragraph, it is stated that the baseline methods are equipped with the same SIREN decoder as used in the proposed method. Does this yield a better performance than the original version of these models using their own decoder?\n\nIt was in our opinion the fairest way to do the comparisons. As was shown in previous papers on using network derivatives, ReLU activations (usually employed in the other baseline decoders) typically perform worse than sin activations. While it might be possible to yield better results when training the baseline methods on very densely sampled ground truth signed distance values, as used to be done in the past, our method obviates the need for these values to be precomputed. We believe it was therefore not possible to use the decoders of the respective methods in a \"fair\" way, without compromising the comparison in one way or another.\n\n***\n\n> [Q3] In page 5, paragraph below Eq. 2 states that the last two terms in Eq. 2 are redundant but can improve training. Is there experimental results that support this argument?\n\nIn tests leading up to the solution for flipped surface normals, we have attempted to entirely remove the loss specifying the direction of the surface normal. This however resulted in less detailed and more \"washed-out\" surfaces.\nIn early tests we have also observed, that removing the exponential term which \"pushes\" non-zero SDF values away from the surface, resulted in slightly noisier SDF values far away from the surface. In early tests, it could also cause convergence issues during training at times, yet at that time the architecture had not been finalized and the error could have originated from other sources. We will consider running experiments to support this claim but will remove it from the paper for the time being."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3753/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700253103224,
                "cdate": 1700253103224,
                "tmdate": 1700253103224,
                "mdate": 1700253103224,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "c5TZjmiTvi",
                "forum": "BC4AUywMow",
                "replyto": "Jh3A93CjLv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3753/Reviewer_Msao"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3753/Reviewer_Msao"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks to the authors for the detailed clarifications and the experimental results unlisted in the original submission. My questions are mostly addressed by these arguments and would suggest adding these nice arguments to the final version."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3753/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700699179414,
                "cdate": 1700699179414,
                "tmdate": 1700699179414,
                "mdate": 1700699179414,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GYDjT6D90q",
                "forum": "BC4AUywMow",
                "replyto": "37VOlsLfQd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3753/Reviewer_Msao"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3753/Reviewer_Msao"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the clarifications but I'm still not sure if I can get the response to W3.2. It's true that the proposed model only takes point cloud as input, but that sounds to me more like a design choice to drop the mesh connectivity information -- since the application is mesh-to-SDF, the input to the whole system is a mesh, and computation of the accurate SDF is straightforward. Am I missing something?\n\nAlso regarding W3.3, while I understand that intuitively the dragon experiment is representative as it is sufficiently challenging, I still believe that it is not sufficiently scientific to simply state that results on other datasets are similar without actually showing the results. If the experiments are done, the results can simply be shown in the final version."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3753/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700699637289,
                "cdate": 1700699637289,
                "tmdate": 1700699637289,
                "mdate": 1700699637289,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KveK9q2esd",
                "forum": "BC4AUywMow",
                "replyto": "SPKYKZP2TK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3753/Reviewer_Msao"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3753/Reviewer_Msao"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the updated version with additional results, ablations and discussions of related work. The new version looks definitely more solid than the original submission. The Author Statement in the rebuttal has clarified the motivation behind the work. \n\nHowever I do still have a concern. Now that the method has a big change than the original submission version (i.e. the assumed input to the pipeline is now a pure point cloud without connectivity information; originally it is a mesh), I'm wondering the importance of the graph convolution module in the pipeline, as this is the key differentiator in the encoder architecture from the baselines, e.g. ConvONet or IF-Net. Since the connectivity for the graph convolution is constructed using KNN search (in the updated paper version), I'm wondering, how much additional information does the graph conv module introduce than the grid convolution module? In other words, does the performance gain brought by the graph conv module in the new Table 2 because of the extra network parameters it introduces, or by the connectivity information that it leverages? \n\nA concrete counter-example is when applying the method on articulated data, e.g. human body (as used in many relevant works, e.g. SAL and IGR). When a human has a cross-arm pose, the knn graph construction would associate a point from the hand to the torso. But intrinsically the geodesic distance on the body manifold between the hand and torso should remain large no matter the pose. In this conflicting example, would the graph conv module in the proposed method help, or hurt?\n\nBased on my mixed observations and thoughts above, I would raise my rating to a boarderline score."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3753/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700705213057,
                "cdate": 1700705213057,
                "tmdate": 1700705213057,
                "mdate": 1700705213057,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "NugdJvBwDN",
            "forum": "BC4AUywMow",
            "replyto": "BC4AUywMow",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3753/Reviewer_ruBo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3753/Reviewer_ruBo"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an efficient encoder-decoder architecture to encode 3D shapes as implicit neural signed distance fields. The core idea is to combine graph and voxel-based encoders coupled with an implicit decoder that can be trained using the Eikonal equation enforced on the shape boundary using surface samples without the need for computing signed distance values on the ground truth data. A modified loss function is also presented for handling meshes that are not watertight or have unoriented normals."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The ability to fit a neural network to a shape without having access to ground truth signed distances values is a big strength.\n- The method is conceptually simple and easy to understand, while being effective and efficient. It has been demonstrated on various datasets where it outperformed other chosen related work.\n- The hybrid graph and voxel based encoder is interesting and novel, and could be significant for future research involving mesh encoding in general."
                },
                "weaknesses": {
                    "value": "- One the main contributions of the paper is the hybrid graph and voxel based encoder, but it is not evaluated comprehensively.  An ablation study on completely removing the graph and voxel based components of the encoder would be useful in understanding the importance of this contribution.\n- Some very relevant papers are missing in comparisons and related work. These works can also encode a shape into a neural field without having access to ground truth SDF values at the sample points:\n  - SAL: Sign Agnostic Learning of Shapes from Raw Data (CVPR 2020)\n  - Implicit Geometric Regularization for Learning Shapes (ICML 2020)\n  - SALD: Sign Agnostic Learning With Derivatives (ICLR 2021)"
                },
                "questions": {
                    "value": "- How important are the individual graph and voxel components of the proposed encoder network, and the encoder network itself as a whole? An ablation study would be helpful to understand this contribution better.\n- How does the proposed method compare against the missing related work listed above in the Weaknesses section? While not all of these works are encoder-decoder models, a comparison is necessary since they too share the advantage of the proposed method of not requiring ground truth SDF values at samples."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3753/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698897547082,
            "cdate": 1698897547082,
            "tmdate": 1699636331422,
            "mdate": 1699636331422,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bPxhsfegfa",
                "forum": "BC4AUywMow",
                "replyto": "NugdJvBwDN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3753/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3753/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Official Review by Reviewer ruBo"
                    },
                    "comment": {
                        "value": "Thank you very much for the insightful review. We are glad that the main points of our paper seem to have come across well. We have found both questions/ concerns to be valuable for improving our paper and discuss these in the [Authors Statement]()."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3753/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700252918522,
                "cdate": 1700252918522,
                "tmdate": 1700252918522,
                "mdate": 1700252918522,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xSB22QNPqe",
                "forum": "BC4AUywMow",
                "replyto": "bPxhsfegfa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3753/Reviewer_ruBo"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3753/Reviewer_ruBo"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for revised ablation study on the hybrid architecture and the discussion on the missing related works. My concerns have been largely addressed and I think these will be great additions to the final paper."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3753/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700717463441,
                "cdate": 1700717463441,
                "tmdate": 1700717463441,
                "mdate": 1700717463441,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]