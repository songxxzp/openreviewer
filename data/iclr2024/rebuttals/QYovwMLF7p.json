[
    {
        "title": "ProFITi: Probabilistic Forecasting of Irregular Time Series via Conditional Flows"
    },
    {
        "review": {
            "id": "bwxTblLguz",
            "forum": "QYovwMLF7p",
            "replyto": "QYovwMLF7p",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1300/Reviewer_jB4x"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1300/Reviewer_jB4x"
            ],
            "content": {
                "summary": {
                    "value": "Authors posit a new normalizing flow model for time series forecasting. They introduce two key components, the Shiesh activation function and SITA.\n\nEdit: After reading author responses and reviewer comments, I have decided to maintain my score."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Shiesh seems to have good performance for normalizing flow models. I wonder if the authors have done experimentation with regards to the activation function in particular for other normalizing flow models?\n\nThe ablation studies conducted are quite thorough with respect to each of the components, and authors offer solid error bars for each of the results.\n\nProposed Shiesh activation function and SITA are both well formulated and grounded. These should also be able to be extended to alternative flow models."
                },
                "weaknesses": {
                    "value": "Figure 1: I'm not sure what this is trying to illustrate, since you're comparing a target bimodal distribution against two other linear gaussian models, and doesn't do much to highlight the novelty of ProFITi.\n\nExperiments seem to only consist of ECG based dataset, which is heavily periodic and consists of similar patterns. Would be interesting to see other datasets here.\n\nMinor typo: \"Both, Leaky\" doesn't need a comma."
                },
                "questions": {
                    "value": "What activation function is used in ProFITi-Shiesh?\nAuthors also mention Leaky ReLU but do not note where it is."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1300/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1300/Reviewer_jB4x",
                        "ICLR.cc/2024/Conference/Submission1300/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1300/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698269679812,
            "cdate": 1698269679812,
            "tmdate": 1701059943090,
            "mdate": 1701059943090,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lvEfTh1isi",
                "forum": "QYovwMLF7p",
                "replyto": "bwxTblLguz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1300/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1300/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer jB4x"
                    },
                    "comment": {
                        "value": "We thank you for your positive review. We address your concerns below:\n\n## w1. Figure 1: I'm not sure what this is trying to illustrate, since you're comparing a target bimodal distribution against two other linear gaussian models, and doesn't do much to highlight the novelty of ProFITi.\n- Existing models for probabilistic IMTS forecasting predict only Gaussian distributions (ex. HETVAE, CRU, GRU-ODE, Neural Flows). So fig. 1 is a simple illustration of the goals and achievements of our model ProFITi: to quantify uncertainty in a richer manner. We edited the introduciton to make this clearer.\n\n## w2. Experiments seem to only consist of ECG based dataset, which is heavily periodic and consists of similar patterns. Would be interesting to see other datasets here.\n- We agree. We added experiments on USHCN, an IMTS climate dataset that also has been previously used in the literature (De Brouwer et al. 2019, Schirmer et al. 2022, Yalavarthi et al. 2023) to section 7.\n\n## w3. Minor typo: \"Both, Leaky\" doesn't need a comma.\n- Fixed. Thanks!\n\n## q1. What activation function is used in ProFITi-Shiesh? Authors also mention Leaky ReLU but do not note where it is.\n- ProFITi-Shiesh does not contain any activation function in the flow\n  model. It is used as ablation to demonstrate the use of a non-linear \n  activation function in ProFITi. \n- Leaky ReLU with very small slope (0.01) for the negative values suffers\n  from the vanishing gradient problem. Therefore no results\n  are shown. We added this information to Appendix H.1."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1300/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700265811375,
                "cdate": 1700265811375,
                "tmdate": 1700266468612,
                "mdate": 1700266468612,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "gJOHboNn0H",
            "forum": "QYovwMLF7p",
            "replyto": "QYovwMLF7p",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1300/Reviewer_qpff"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1300/Reviewer_qpff"
            ],
            "content": {
                "summary": {
                    "value": "The work proposes a probabilistic forecasting for irregular time series using conditional normalizing flows."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The probabilistic forecasting of irregular timeseries is an important problem and the use of normalizing flow for this scope is interesting.\n\nIntroduction of a new activation function having the characteristics useful for the normalizing flows."
                },
                "weaknesses": {
                    "value": "In my opinion could be interesting to assess the behavior of the proposed model in several conditions in terms of percentage of missing values, sparsity of the time steps. In fact the irregular time series are very important and to give researcher an evaluation of these aspects could help to understand the quality/limitations of the proposed work.\n\nThe authors use likelihood to assess the quality of the forecast also for marginal and point forecast. In that case I think could be useful to have other metrics as RMSE, MAPE or other that is more related to the prediction error.\n\nThe computational effort of proposed solution is not provided and is not compared to other possible solutions. Some results are provided in appendix but only for a particular dataset."
                },
                "questions": {
                    "value": "\u00a73 - IMTS Query section, in the definition of QA(C), what is the meaning of $|x^{qu}|=|y|$? After, when you talk about NJNL, looks like $|.|$ means lenght of, but authors should describe clearlry the symbols they use.\n\nIn the IMTS probabilistic forecasting problem\n\"(with $min_k t_{n,k}^{qu} > max_i t_{n,i}^{obs}$)\" --> the reader is lead to think that $t_{n,k}^{qu}$ is the k-th observation of the n-th query and the same for $t_{n,i}^{obs}$ but a clarification would be better.\n\nWhat is the meaning of $\\pi^{-1}$ in equation 4?\n\nIn eq. 7 $X_{:,1:|X|-1}$ is the matrix X except the last column?\nIn eq. 7 $X_{:,|X|}$ is the last column of matrix X ?\n\nIn the protocol authors said that they use the first 36 hours of observations and forecast next 3 time steps. These time step is, looking at Appendix A, 1 hour for Physionet, 30minute for MIMIC-III, 1 minute for MIMIC-IV. Is this right? \nMoreover, is there a way to indicate the time sparsity of considered timeseries in oder to understand how the timeseries considered are not uniformly spaced? \n\nThe section 6 and figure 3 should be improved in order to make clearer the architecture.\nIn equation 11 the $x_k$ is the $h$ of figure 3?\nWhat is the meaning of S in fig. 3?\n\nIn Fig. 9 the Grafiti+ returns only a region an not the trajectories? Is it possible to compare the confidence regions of ProFITi and GraFITi+? \n\nSome general comments (also present in the Weakness section)\nIn my opinion could be interesting to assess the behavior of the proposed model in several conditions in terms of percentage of missing values, sparsity of the time steps. In fact the irregular time series are very important and to give researcher an evaluation of these aspects could help to understand the quality/limitations of the proposed work.\n\nThe authors use likelihood to assess the quality of the forecast also for marginal and point forecast. In that case I think could be useful to have other metrics as RMSE, MAPE or other that is more related to the prediction error.\n\nThe computational effort of proposed solution is not provided and is not compared to other possible solutions. Some results are provided in appendix but only for a particular dataset."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1300/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1300/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1300/Reviewer_qpff"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1300/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698677903437,
            "cdate": 1698677903437,
            "tmdate": 1700667804111,
            "mdate": 1700667804111,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZROLXwUAKL",
                "forum": "QYovwMLF7p",
                "replyto": "gJOHboNn0H",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1300/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1300/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer qpff"
                    },
                    "comment": {
                        "value": "Thank you for the detailed review. We address the concerns below:\n\n## w1+q8. In my opinion could be interesting to assess the behavior of the proposed model in several conditions in terms of percentage of missing values, sparsity of the time steps. In fact the irregular time series are very important and to give researcher an evaluation of these aspects could help to understand the quality/limitations of the proposed work.\n- We agree. We added an ablation study with varying sparsity levels\n  (time sparsity and missing values) in Appendix H.5, H.6. Our findings\n  show that even in an extremely sparse scenario, where 90% of samples\n  (or timepoints) are missing, ProFITi consistently outperforms both\n  Neural Flows and GraFITi+.\n\n## w2+q9. The authors use likelihood to assess the quality of the forecast also for marginal and point forecast. In that case I think could be useful to have other metrics as RMSE, MAPE or other that is more related to the prediction error.\n- We **do use MSE** to evaluate models w.r.t. point forecasts (tab. 4).\n\n## w3+q10. The computational effort of proposed solution is not provided and is not compared to other possible solutions. Some results are provided in appendix but only for a particular dataset.\n- In the updated version, we included the **runtime per epoch \n   for all models and datasets** in Table 3.\n- Our main claim is to provide a **more accurate model**, not to provide a faster\n  model (contribution 5). Thus we gave more room to evaluation w.r.t. accuracy\n  but w.r.t. scalability.\n  \n## q1. \u00a73 - IMTS Query section, in the definition of $\\text{QA(C)}$, what is the meaning of |x^\\text{qu}| = |y|?\n- yes, |.| denotes the length of a sequence. We added a brief section on notation (appendix A).\n\n## q2. In the IMTS probabilistic forecasting problem (with $\\min_k t^\\text{qu}_{n,k} > \\max_i t^\\text{obs}_{n, i}$) --> the reader is lead to think that is the k-th observation of the n-th query \n- You are right. We added a respective note to section 3.\n\n## q3. What is the meaning of $\\pi^{-1}$ in equation 4?\n- for permutations $\\pi$, one often writes $x^{\\pi}$ to denote the application of the permutation $\\pi$ to vector x. \n- $\\pi^{-1}$ is permutations that are inverse w.r.t $\\pi$. $(x^\\pi)^{\\pi^{-1}} = x$\n- we added a brief section on notation (appendix A). \n\n## q4. In eq. 7 $X_{:, 1:|X|-1}$ is the matrix X except the last column? In eq. 7 $X_{:, |X|}$ is the last column of matrix X ?\n- yes. We added this, too, to the notation section (appendix A).\n\n## q5. In the protocol authors said that they use the first 36 hours of observations and forecast next 3 time steps. These time step is, looking at Appendix A, 1 hour for Physionet, 30minute for MIMIC-III, 1 minute for MIMIC-IV. Is this right? Moreover, is there a way to indicate the time sparsity of considered timeseries in oder to understand how the timeseries considered are not uniformly spaced?\n- Yes, the observation intervals are data set specific.\n- We added an additional column \"time sparsity\" to table 5 that quantifies\n  the sparsity of the time series (as proxy measure for its irregularity).\n\n## q6. The section 6 and figure 3 should be improved in order to make clearer the architecture. In equation 11 the $x_k$ is the h of figure 3? What is the meaning of S in fig. 3?\n- Yes, $h_k$ are the encoded $x_k$ and replace $x_k$ everywhere (as stated \n  below their definition in paragraph \"Query embedding\": \"take the roles\n  of the $x_k$\").\n- $S$ is the sorting criterion introduced at the end of section 5.\n- We added references for all symbols in fig. 3 to their respective definitions to make navigation between formulas and the diagram faster.\n  \n## q7. In Fig. 9 the Grafiti+ returns only a region an not the trajectories? Is it possible to compare the confidence regions of ProFITi and GraFITi+?\n- Since ProFITi provides non-parametric distribution, it is difficult to plot the confidence regions for multiple points simultaneuously. Hence, although it is interesting, we do not want to pursue the idea."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1300/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700265685640,
                "cdate": 1700265685640,
                "tmdate": 1700265685640,
                "mdate": 1700265685640,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MkjPudFnhe",
                "forum": "QYovwMLF7p",
                "replyto": "ZROLXwUAKL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1300/Reviewer_qpff"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1300/Reviewer_qpff"
                ],
                "content": {
                    "comment": {
                        "value": "After reading other reviews, authors replies, and revised manuscript, I decided to improve my initial score."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1300/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700667775448,
                "cdate": 1700667775448,
                "tmdate": 1700667775448,
                "mdate": 1700667775448,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "XoixNfuvGH",
            "forum": "QYovwMLF7p",
            "replyto": "QYovwMLF7p",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1300/Reviewer_DHMB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1300/Reviewer_DHMB"
            ],
            "content": {
                "summary": {
                    "value": "The paper focuses on probabilistic forecasting of irregularly sampled multivariate time series with missing values. The authors propose to use conditional continuous normalizing flow to construct the distribution instead of making an assumption on the target distribution as done in the literature. Moreover, they provide a novel invertible equivariant transformation, and a novel non-linear, invertible, differentiable activation function, which can be used in normalizing flows. Finally, they conduct extensive experiments on three real-world IMTS datasets and show that the proposed model (PROFITI) outperforms baselines in terms of normalized joint negative log-likelihood."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The exploration of predicting changes in the joint distribution of time series is an important and valuable problem, which is crucial for downstream tasks in various domains. While previous literature has predominantly focused on regular time series, the paper's contribution in addressing the prediction of joint distributions in irregular time series is commendable. Moreover,  the paper showcases a significant amount of effort and extensive work. The authors present compelling evidence of the effectiveness of their proposed method. The results indicate that the approach performs well in predicting the joint distribution."
                },
                "weaknesses": {
                    "value": "1. The requirement of permutation invariance, as proposed by the authors, is questionable in time series analysis and may not be suitable for this domain. The authors argue that a density model should produce equivalent density values when the outputs are swapped, which is a reasonable expectation in the context of static generative models. However, in the time series setting, where the joint distribution of variables $y_1,...,y_K$ occurring at different time steps is considered, the presence of serial dependencies becomes crucial. Unfortunately, the permutation invariant requirement, which treats the order of data points as interchangeable, risks disrupting these vital temporal dependencies. In contrast, if the objective is to forecast the joint distribution of variables occurring at the same time step, the permutation invariant requirement might be deemed necessary. \n\n2. The rationale behind utilizing self-attention as the vector field in the proposed work is not clear. It seems redundant to introduce self-attention into the vector field, given that neural networks inherently possess permutation invariance properties with respect to the input. Therefore, a more explicit justification is needed to understand the motivation behind incorporating self-attention in this context. Moreover, it is worth noting that existing literature, such as [1], has already proposed the use of conditional normalizing flow models for forecasting the joint distribution of time series. Therefore, it is crucial to highlight the distinctions between the proposed work and the existing literature that necessitate the use of self-attention and the introduction of a more complex invertible self-attention mechanism.\n\n\n[1] Rasul, K., Sheikh, A. S., Schuster, I., Bergmann, U., & Vollgraf, R. (2020). Multivariate probabilistic time series forecasting via conditioned normalizing flows. arXiv preprint arXiv:2002.06103."
                },
                "questions": {
                    "value": "1. In the paragraph \u201cInvariant conditional normalizing flows,\u201d the authors claim that x is the predictor, which can be grouped into K elements and common elements. The statement confuses me. It is not clear why x contains common elements. Could the authors provide a concrete example of the general setting and explain the statement in the paragraph? \n\n2. What is the meaning of the L.H.S. in Eqn. (4)? There is a superscript $\\pi^{-1}$ on the L.H.S. in Eqn. (4), what does it mean?\n\n3. The choice of $\\epsilon$ in Eqn. (6) should affect the training results. Should it be determined before training? Or should it be termed as a hyperparameter during training? Should there be an investigation about the choice of $\\epsilon$?\n\n4. Why use the GraFITi model to encode the historical data? Compared to the prevalent model used to model irregular time series, such as GRU-ODE-Bayes [2] or  Neural CDE [3], what is the advantage of GraFITi?\n\n5. Most literature use CRPS and CRPS_sum to evaluate the performance, e.g., [1, 4-6]. Why authors do not follow the literature?\n\n[2] De Brouwer, E., Simm, J., Arany, A., & Moreau, Y. (2019). GRU-ODE-Bayes: Continuous modeling of sporadically-observed time series. Advances in neural information processing systems, 32.\n\n[3] Kidger, P., Morrill, J., Foster, J., & Lyons, T. (2020). Neural controlled differential equations for irregular time series. Advances in Neural Information Processing Systems, 33, 6696-6707.\n\n[4] Salinas, D., Bohlke-Schneider, M., Callot, L., Medico, R., & Gasthaus, J. (2019). High-dimensional multivariate forecasting with low-rank gaussian copula processes. Advances in neural information processing systems, 32.\n\n[5] Salinas, D., Flunkert, V., Gasthaus, J., & Januschowski, T. (2020). DeepAR: Probabilistic forecasting with autoregressive recurrent networks. International Journal of Forecasting, 36(3), 1181-1191.\n\n[6] Rasul, K., Seward, C., Schuster, I., & Vollgraf, R. (2021). Autoregressive denoising diffusion models for multivariate probabilistic time series forecasting. In International Conference on Machine Learning (pp. 8857-8868). PMLR."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1300/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1300/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1300/Reviewer_DHMB"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1300/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698725820744,
            "cdate": 1698725820744,
            "tmdate": 1699636056982,
            "mdate": 1699636056982,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "EOPypaOeVO",
                "forum": "QYovwMLF7p",
                "replyto": "XoixNfuvGH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1300/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1300/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer DHMB"
                    },
                    "comment": {
                        "value": "Thanks for your detailed review. We address the comments below:\n\n## w1. The requirement of permutation invariance, as proposed by the authors, is questionable in time series analysis\n\n- Permutation invariance is crucial **w.r.t. channels**: it should not matter,\n  if you query for channel 1 or channel 2 first. \n- Permutation invariance **w.r.t. time points** is not a necessary property\n  of a good model due to the causal aspects you mention. But it is a\n  **very successful property** of most state-of-the-art models in vision and\n  time series. This motivated us to search for a novel invertible variant\n  that can be used in conjunction with normalizing flows.\n- All queries carry the **time point as an attribute** ($q_k$ in the paper), \n  like positional encodings in transformers, so that the model can\n  detect and represent temporal dependencies, of course.\n- We added a respective paragraph to our problem analysis section 3.\n\n## w2a. The rationale behind utilizing self-attention as the vector field in the proposed work is not clear. It seems redundant to introduce self-attention into the vector field, given that neural networks inherently possess permutation invariance properties with respect to the input.\n- Standard fully connected layers in neural networks are not permutation invariant: for example, if the weight matrix is W = [[1,0],[0,1]] the identity, then the output Wx = x varies under permutations, e.g., W[1,0] = [1,0], but W[0,1]= [0,1].\n- Invariance partially is crucial, partially is highly promising as explained above (see w1).\n\n## w2b. existing literature, such as [1], has already proposed the use of conditional normalizing flow models for forecasting the joint distribution of time series\n- MAF (Rasul et al. 2020, [1]) is a model for **regularly sampled, fully observed time series** data, while ours is for **irregularly sampled time series with missing values** (also see table 1). \n- Forecasting queries for fully observed, regularly sampled data **always have the same size**, thus any (conditional) normalizing flow model can be used.\n- But forecasting queries for irregularly sampled time series with missing data **have varying sizes** (both w.r.t. to missing time points and missing observation values), and thus standard normalizing flow models are not applicable (column \"joint\" in table 1). This is one of the fundamental research problems we aimed to solve in our paper. Combining attention (allowing flexible size) with invertibility (to be used in a normalizing flow) is how we solved the problem. In consequence, MAF cannot predict joint distributions over channels and time points for any of the datasets in our evaluation.\n- We added this delineation to the related work section 2.\n\n## q1. In the paragraph \u201cInvariant conditional normalizing flows,\u201d the authors claim that $x$ is the predictor, which can be grouped into $K$ elements and common elements. The statement confuses me. It is not clear why $x$ contains common elements. Could the authors provide a concrete example of the general setting and explain the statement in the paragraph?\n- in IMTS forecasting you have both inputs, \n  1. a variable number of queries $x^\\text{qu}_1,...,x^\\text{qu}_K$ (each a time point and channel), for each of which you want an output (the predicted value at that time point in that channel) and \n  2. the past observed time series $x^\\text{obs}$ (see section 3, \"IMTS probabilistic forecasting problem\"). \n  So here: $(x_1,...x_K):= (x^\\text{qu}_1,...,x^\\text{qu}_K)$, $x^\\text{com} := x^\\text{obs}$.\n- we added this example early in section 4.\n\n## q2. What is the meaning of the L.H.S. in Eqn. (4)? There is a superscript $\\pi^{-1}$ on the L.H.S. in Eqn. (4), what does it mean?\n- for permutations $\\pi$, one often writes $x^{\\pi}$ to denote the application of the permutation $\\pi$ to vector $x$. \n- $\\pi^{-1}$ is also a permutation which is inverse of $\\pi$.\n- here it means, that $f$ is equivariant: if you permute inputs $z$ and $x$, then the outputs of $f$ are permuted the same way. \n- we added a brief section on notation (Appendix A). \n\n## q3. The choice of $\\epsilon$ in Eqn. (6) should affect the training results. Should it be determined before training? Or should it be termed as a hyperparameter during training? Should there be an investigation about the choice of?\n- yes, you are right, it does. It is a hyperparameter.\n- we clarified this next to Eq. 6. \n- we use $A^\\text{tri}$ (Eq. 9 of revised version) as a vector field in all our experiments and set $\\epsilon = 0.1$. It is also shown in Figure 2. We corrected the typo in Eq. 15 in the revised version (from ISA to SITA) which could have caused the confusion.\n- we added an ablation study for varying $\\epsilon$ in $A^{\\text{tri}}$ (appendix H.4)."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1300/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700264793448,
                "cdate": 1700264793448,
                "tmdate": 1700264793448,
                "mdate": 1700264793448,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "if1wlvCvQC",
                "forum": "QYovwMLF7p",
                "replyto": "EOPypaOeVO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1300/Reviewer_DHMB"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1300/Reviewer_DHMB"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the authors' reply. For the response of w1, I agree that the permutation invariance is crucial w.r.t. channels. However, I am curious if it is too strong to use permutation invariance w.r.t. time points in time series forecasting, and I do not understand why permutation invariance w.r.t. time points is a very successful property of most state-of-the-art models in vision and time series. For example, if we have an irregular multivariate time series of two variables and want to estimate the joint distribution of $y_1^1, y_1^2$, and $y_2^1, y_3^2$ (the superscript indicates channel, and the subscript indicates time). The permutation w.r.t. channel implies that it can be decomposed as $$p(y_1^1, y_1^2)=p(y_1^1) p(y_1^2| y_1^1)= p(y_1^2) p(y_1^1| y_1^2). $$ However, the permutation w.r.t. time demonstrates that it can be decomposed as $$p(y_2^1, y_3^2)=p(y_2^1) p(y_3^2| y_2^1)= p(y_3^2) p(y_2^1| y_3^2).$$ What does $p(y_2^1| y_3^2)$ mean? Does it mean predicting the value at $t_2$ by conditioning the value at $t_3$? In addition, Rasul et al. (2020) use conditional normalizing flow (MAF) to estimate the joint distribution of time series at the next time point. It is a regular time series, but they never consider permutation invariance across various channels. Indeed, I hope authors can demonstrate the essential of permutation invariance w.r.t time through an experiment or theoretical analysis."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1300/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700548504119,
                "cdate": 1700548504119,
                "tmdate": 1700548504119,
                "mdate": 1700548504119,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "V5a21r7GMw",
            "forum": "QYovwMLF7p",
            "replyto": "QYovwMLF7p",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1300/Reviewer_JdGh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1300/Reviewer_JdGh"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the problem of probabilistic forecasting of time series with irregular samples and missing values. Authors propose a new architecture based on conditional normalizing flows that can handle both, irregularity and missing values, and learns a joint distribution of the forecast targets. The proposed approach relies on the new invertible self-attention layer and a new activation function. The authors benchmark their method on 3 real-world datasets and showcase superior performance in terms of log-likelihood."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "## Originality \nTo my best knowledge, the invertible self-attention layer and the activation functions are new\n## Quality \n* The presented approach can be learnt end-to-end without additional steps like solving ODE\n* Experiments use a wide set of baselines\n* Ablation study is performed\n## Clarity \nAuthors do a good job motivating and explaining their design choices, but overall exposition is still pretty convoluted\n## Significance\nExperimental results show a significant improvement in log likelihood. New attention layer can be potentially used in other algorithms with normalizing flows, so the work can potentially have wide impact."
                },
                "weaknesses": {
                    "value": "* My main concern is that it seems like most improvement comes from using GraFITi embeddings, which are not used by the baselines. \n* Evaluation covers only three datasets from very similar domain\n* The modelling limitations of the method are not clear. What kind of distributions can be modelled with the proposed flows?"
                },
                "questions": {
                    "value": "* Please adjust the abstract in line with ICLR formatting instructions\n* It would be beneficial to study what kind of distributions can be modelled with the proposed flows.\n* I wonder whether other methods would fare better if computed on the same GraFITi embeddings. Can you add a combination of other baselines with GraFITi and another option in the ablation study that doesn\u2019t use it?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1300/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698786231907,
            "cdate": 1698786231907,
            "tmdate": 1699636056903,
            "mdate": 1699636056903,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "i6JqOFjBcu",
                "forum": "QYovwMLF7p",
                "replyto": "V5a21r7GMw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1300/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1300/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer jdGH"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the valuable feedback. Responses to the weakness and questions are as follows\n\n## w1. My main concern is that it seems like most improvement comes from using GraFITi embeddings, which are not used by the baselines.\n- Many baseline models such as NeuralFlows and GRU-ODE do not use\n  query encoders and thus cannot (easily) be extended to use \n  GraFITi.\n- But to disentangle lifts originating from GraFITi from those originating\n  from ProFITi, we added the model GraFITi+: the full GraFITi encoder\n  plus a simple uncertainty quantification model, a Gaussian (see table 4).\n- We added a note to section 7 Experiments.\n\n## w2+q3.  Evaluation covers only three datasets from very similar domain\n- We agree. We added experiments on USHCN, an IMTS climate dataset \n  that also has been previously used in the literature (De Brouwer et al. 2019, \n  Schirmer et al. 2022, Yalavarthi et al. 2023) to section 7.\n\n## w3+q2. The modeling limitations of the method are not clear. What kind of distributions can be modeled with the proposed flows?\n- ProFITi is a normalizing flow model, as such it is not limited to a distribution\n  with a fixed shape like the Gaussians. \n- However, quantifying the exact expressive power of normalizing flow \n  models is an active research topic of its own and beyond the scope of our\n  paper (see, e.g., Kong/Chaudhuri 2020):\n- We added a note to section 2 Literature review.\n\n## q1. Please adjust the abstract in line with ICLR formatting instructions\n- Fixed. Thanks!\n\nKong, Zhifeng, and Kamalika Chaudhuri. \u201cThe Expressive Power of a\n   Class of Normalizing Flow Models.\u201d In Proceedings of the Twenty\n   Third International Conference on Artificial Intelligence and\n   Statistics, 3599\u20133609. PMLR, 2020. https://proceedings.mlr.press/v108/kong20a.html."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1300/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700264235963,
                "cdate": 1700264235963,
                "tmdate": 1700264235963,
                "mdate": 1700264235963,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IisAOxIfTF",
                "forum": "QYovwMLF7p",
                "replyto": "i6JqOFjBcu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1300/Reviewer_JdGh"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1300/Reviewer_JdGh"
                ],
                "content": {
                    "comment": {
                        "value": "After reading other reviews and authors replies, I am inclined to maintain my score."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1300/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700665987126,
                "cdate": 1700665987126,
                "tmdate": 1700665987126,
                "mdate": 1700665987126,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]