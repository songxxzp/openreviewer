[
    {
        "title": "Defining and extracting generalizable interaction primitives from DNNs"
    },
    {
        "review": {
            "id": "wMWzOKj3or",
            "forum": "OCqyFVFNeF",
            "replyto": "OCqyFVFNeF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission861/Reviewer_MRpB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission861/Reviewer_MRpB"
            ],
            "content": {
                "summary": {
                    "value": "This paper delves into the realm of deep neural networks (DNNs), addressing a critical gap in understanding the interactions encoded by these models. Unlike existing interaction extraction methods, which lack theoretical guarantees for transferability, this work introduces a precise definition for the transferability of interaction primitives. Building on this foundation, the authors propose a novel method aimed at extracting interactions with maximal generalization power across different DNN architectures. Extensive experiments across language and image domains validate the effectiveness of the proposed method, demonstrating enhanced generalization of extracted interactions.\n\nThis paper makes a significant stride in demystifying the interactions encoded by deep neural networks, introducing novel concepts and methodologies backed by solid experimental evidence. Addressing the highlighted weaknesses and questions will further fortify the paper's contributions, making it a valuable addition to the field of DNN interpretability."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1. Relevance and Timeliness: Given the burgeoning interest in interpretability of DNNs, this paper tackles a pertinent and significant problem, contributing to a better understanding of how DNNs encode interactions.\n\n2. Innovative Conceptualization: The introduction of \"interaction primitive transferability\" is a novel and insightful contribution, offering a new lens through which to evaluate and understand interaction primitives in DNNs.\n\n3. Rigorous Experimental Validation: The authors have conducted a comprehensive set of experiments across various settings and domains, including both language and image data, which robustly demonstrate the effectiveness of the proposed method."
                },
                "weaknesses": {
                    "value": "1. Clarification on Parameter Selection: The paper could benefit from a more detailed discussion on the choice of the parameter \u03b1, including its impact on the balance between two competing objectives and its sensitivity to variations.\n\n2. Inconsistencies in Performance Improvements: The observed discrepancies in performance improvements between different tasks (i.e., more pronounced improvements in BERT-base and BERT-large compared to LLaMA and OPT-1.3B) warrant a deeper investigation and explanation.\n\n3. Interpretability of Extracted Interactions: While the paper demonstrates the effectiveness of the proposed method in extracting distinctive interactions, a more explicit exploration of the interpretability of these interactions, especially in the context of more powerful models like BERT-large, would add valuable insights."
                },
                "questions": {
                    "value": "1. Parameter Sensitivity: Could the authors provide a more comprehensive analysis on the choice and sensitivity of \u03b1? An ablation study exploring how variations in \u03b1 affect the outcomes would enhance the paper\u2019s rigor.\n\n2. Discrepancies in Performance: What factors contribute to the observed variations in performance improvements across different tasks? A detailed examination of this phenomenon would provide clarity and strengthen the paper\u2019s contributions.\n\n3. Exploration of Interpretability: Can the authors elaborate on whether the distinctive interactions extracted from more powerful models, such as BERT-large, result in enhanced interpretability? An in-depth discussion on this aspect would be highly beneficial."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission861/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698727386215,
            "cdate": 1698727386215,
            "tmdate": 1699636012611,
            "mdate": 1699636012611,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NQKOU34SFk",
                "forum": "OCqyFVFNeF",
                "replyto": "wMWzOKj3or",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission861/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission861/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your insightful comments and suggestions. We would like to answer all the questions and clarify your concerns. We have carefully revised the paper in blue according to your suggestions.\n\n**Q1: Asking to conduct ablation studies.**\n\n> Q1: \"a more detailed discussion on the choice of the parameter $\\alpha$\" \"An ablation study exploring how variations in $\\alpha$ affect the outcomes\"\n\n**A1:** Thank you. We have followed your suggestions to **conduct a new ablation study** to illustrate the impact of $\\alpha$. Specifically, we jointly extracted two sets of AND-OR interactions from the $\\rm BERT_{BASE}$ and $\\rm BERT_{LARGE}$ models, which were trained by [cite 1] and further finetuned by us for sentiment classification on the SST-2 dataset. We set the $\\alpha$ values to [0, 0.2, 0.4, 0.6, 0.8, 1.0] for comparison. Figure 8 in the revised paper shows that as $\\alpha$ increases, the sparsity of the extracted interactions increased and the generalization power of the extracted interactions gradually decreased. Please see Figure 8 in Appendix K for details of the new ablation study.\n\n[cite 1] Devlin, J., et al. Bert: Pre-training of deep bidirectional transformers for language understanding. In NAACL, 2019.\n\n\n\n**Q2: Inconsistencies in performance Improvements.**\n\n> Q2: \"The observed discrepancies in performance improvements \u2026 warrant a deeper investigation and explanation.\"\n\n**A2:** Thank you. This is a deep insight into the LLMs in feature representations. Since LLaMA and OPT-1.3B have much more parameters than BERT-Base and BERT-Large, it is often widely believed that these two LLMs can better converge to the true language knowledge in the training data. Although the following answer is far beyond the research in this paper, we are still glad to answer this question.\n\nWe can roughly understand this phenomenon by clarifying the following two phenomena. **First, through extensive experiments, the authors have found that the learning of a DNN usually has two phases, i.e., the learning of new interactions and the forgotten of incorrectly learned interactions** (this is our on-going research). In most cases, after the forgetting phase, the remained interactions of an LLM are usually shared by other LLMs. The high similarity of interactions between LLMs has also been observed in [cite 2].\n\n**Second, compared to LLMs, relatively small models are less powerful to remove all incorrectly learned interactions.** For example, a simple model is usually less powerful to regress a complex function. The less powerful models (BERT-Base and BERT-Large) are not powerful enough to accurately encode the potentially complex interactions.\n\n**Therefore, small models are more likely to represent various incorrect interactions to approximate the true target of the task. This may partially explains the high difficulty of extracting common interactions from two BERT models, as well as why the proposed method shows more improvements in the generalization power of interactions on BERT models.**\n\n**Experimental verification.** To this end, we have further **conducted a new experiment** to compare the interactions extracted from two LLMs, i.e., LLaMA and Aquila-7B [cite 3].  As Figure 11 in Appendix N shows, two LLMs usually encode much more similar interactions than two not-so-large models. These experiments partially verify our hypothesis. \n\n[cite 2] Shen, W., et al. Can the Inference Logic of Large Language Models be Disentangled into Symbolic Concepts? arXiv preprint arXiv:2304.01083, 2023.\n\n[cite 3] BAAI. Aquila-7B, 2023. URL https://huggingface.co/BAAI/Aquila-7B."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission861/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700332919385,
                "cdate": 1700332919385,
                "tmdate": 1700334894607,
                "mdate": 1700334894607,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gNo5GU4Gl0",
                "forum": "OCqyFVFNeF",
                "replyto": "wMWzOKj3or",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission861/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission861/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q3: Insights into the interpretability of extracted interactions.**\n\n> Q3: \"Can the authors elaborate on whether the distinctive interactions extracted from more powerful models, such as BERT-large, result in enhanced interpretability?\"\n\n**A3:** A good suggestion. We believe that the interaction is a better perspective to explain the representation similarity between different AI models than other metrics. It is because different AI models usually have different structures, and their features are not directly aligned to each other. It is a significant challenge to quantify the similarity of two DNNs. For example, let $f_A$ and $f_B$ denote the features of two networks A and B. Then, we learn an model $g$ to align $f_B$ to $f_A$, via $g=argmin \\vert\\vert f_A-g(f_B)\\vert\\vert^2$. Either $2\\vert\\vert f_A-g(f_B) \\vert\\vert / (\\vert\\vert f_A\\vert\\vert +\\vert\\vert g(f_B)\\vert\\vert)$, or $cos(f_A,g(f_B))$ still has certain technical flaws in evaluating the distance/similarity of two features. It is because we cannot theoretically guarantee that the numerical classification utilities of $f_A$, $g(f_B)$, and $f_A-g(f_B)$ are exactly proportional to their feature strength $\\vert\\vert f_A\\vert\\vert$, $\\vert\\vert g(f_B)\\vert\\vert$, and $\\vert\\vert f_A-g(f_B)\\vert\\vert$. Similarly, there is no theoretical guarantee for the faithfulness of $cos(f_A,g(f_B))$.\n\nIn comparison, when we use interactions, [cite 4] have found that the network output can be faithfully decomposed into different interaction effects, no matter whether two DNNs have fully different architectures. Besides, because the interaction effect is directly responsible for network output, we do not face the problem that the feature strength is not the classification utility. **Therefore, we can use the similarity of interactions as the similarity of inference logics of two DNNs.**\n\nFurthermore, we have **conducted a new experiment** to compare the interactions extract from two LLMs, i.e., LLaMA and Aquila-7B\u00a0[cite 3]. As Figure 11 in Appendix N shows, a pair of LLMs usually share more ratio of interactions than other pairs of language models. It means that most LLMs may usually converge to the same set of potentially true interactions, as long as the LLM has a huge number of parameters and is well trained on extensive data. We believe that our finding may help people interpret the common learning direction of different LLMs.\n\n[cite 3] BAAI. Aquila-7B, 2023. URL https://huggingface.co/BAAI/Aquila-7B.\n\n[cite 4] Li, M., et al. Does a neural network really encode symbolic concept? In ICML, 2023."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission861/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700333034034,
                "cdate": 1700333034034,
                "tmdate": 1700334913272,
                "mdate": 1700334913272,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Bj480LkqQJ",
            "forum": "OCqyFVFNeF",
            "replyto": "OCqyFVFNeF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission861/Reviewer_GVkW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission861/Reviewer_GVkW"
            ],
            "content": {
                "summary": {
                    "value": "The main challenge in explainable AI is to effectively summarize the knowledge encoded by a deep neural network (DNN) into a few symbolic primitive patterns without losing significant information. To tackle this, Ren et al. (2023) established a series of theorems demonstrating that a DNN's inference score can be explained as a small set of interactions between input variables. However, these interactions lack generalizability and thus cannot be considered as faithful primitive patterns encoded by the DNN. To address this, the authors propose  a method to extract interactions that are common to different DNNs trained for the same task."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is well-written and easy to follow.\n- The experimental design is comprehensive, covering aspects of both NLP and vision, which provides a broad perspective.\n- The paper focus on the interesting the generalization problem of interaction , which is a interesting problem."
                },
                "weaknesses": {
                    "value": "- The paper does not sufficiently explain why generalizable interactions are important for AI interpretability. Although generalizability is critical in AI algorithms, especially when dealing with different tasks or data from different domains. However, the authors focus on explainable AI, and the generalizability is defined on different models of the same task, which does not align with the conventional understanding of DNN generalizability.\n- The proofs in the paper rely on two papers currently under review ([1,2] See appendix C). This poses a problem as the validity and peer-review status of these references are uncertain. Moreover, it would be beneficial for the readers if detailed derivations of Equation 11 were provided to better understand and verify the proofs.\n- While the paper provides a clear mathematical definition for generalizable interactions, it lacks a discussion on the existence of generalizable interactions. Moreover, the method proposed in the paper is derived heuristically using Occam's Razor principle instead of being grounded on mathematical theorems satisfying the definition. The paper does not satisfactorily address why this approach would yield generalizable interactions.\n- The experimental section of the paper only compares the proposed method with a single baseline. Including more baselines could strengthen the paper's persuasiveness.\n\n[1] Technical note: Defining and quantifying and-or interactions for faithful and concise explanation of dnns.\n\n[2] Where we have arrived in proving the emergence of sparse symbolic concepts in ai models."
                },
                "questions": {
                    "value": "See weekness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission861/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission861/Reviewer_GVkW",
                        "ICLR.cc/2024/Conference/Submission861/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission861/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698742457982,
            "cdate": 1698742457982,
            "tmdate": 1700737012826,
            "mdate": 1700737012826,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AAusm1ovFy",
                "forum": "OCqyFVFNeF",
                "replyto": "Bj480LkqQJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission861/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission861/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks a lot for all the valuable comments and suggestions. We would like to answer all the questions and clarify your concerns. Besides, we have carefully revised the paper in blue according to your suggestions. \n\n**Please let us know as soon as possible, if you have any further questions or concerns.**\n\n**Q1: $\\color{blue}{\\textsf{Ask for the importance of generalizable interactions for AI interpretability.}}$**\n\n> Q1: \"why generalizable interactions are important for AI interpretability\" \"the generalizability is defined on different models of the same task, which does not align with the conventional understanding of DNN generalizability.\"\n\n**A1:** Thank you. Unlike traditional studies on the generalization power of a DNN, **our research is led by a different motivation**, i.e., exploring the optimal way to explain inference logics of a DNN into symbolic interaction concepts. To this end, although the huge gap between symbolism and connectionism is well known, the counter-intuitive phenomenon of the sparsity of interactions in [cite 1] provides a new potential for the breakthrough of the seemingly impossible task. Specifically, previous studies [cite 1] [cite 2] have observed the sparsity of the interactions extracted in well-trained DNNs (in fact, this has been partially proven [cite 3] under three common conditions).\n\n**Therefore, our study of ensuring the interactions' generalization power may serve the last piece to prove/identify the symbolic/sparse interactions that faithfully explain a DNN.** If we simultaneously ensure that (1) each DNN just encodes a small number of salient interactions, comparing with all $2^n$ potential combinations in the input variables, (2) a small number of salient interactions can universally match the DNN outputs on all $2^n$ randomly masked sample $\\\\{\\mathbf{x}_S|S\\subseteq N\\\\}$, and (3) most interactions are generalizable over different DNNs trained for the same task, then we can consider that we have faithfully defined interaction concepts encoded by a DNN.\n\nThe proof of a DNN\u2019s encoding of symbolic interactions may help future analysis of generalization power of an AI model. First, **theoretically, we can redefine the generalization power of a DNN based on the learned interactions encoded by the DNN in future work.** In fact, the vanilla Harsanyi interaction has been used to explain the generalization power of a DNN [cite 4], in which low-order interactions have been found to have higher generalization power than high-order interactions. Other traditional studies mainly analyze generalization power in terms of the accuracy and the loss difference between training and testing samples. However, none of these metrics can reflect the intrinsic mechanism of the generalization power of a DNN. In comparison, the interaction concept provides us an alternative perspective to redefine the generalization of a DNN. Specifically, given multiple DNNs trained for the same task and an input sample, if an interaction can be extracted from all/most of these DNNs, then we consider it generalizable. In this way, we can identify a set of generalizable interactions and a set of non-generalizable interactions, which show much deeper insights into the generalization power of a DNN.\n\n[cite 1] Li, M., et al. Does a neural network really encode symbolic concept? In ICML, 2023.\n\n[cite 2] Ren, J., et al. Defining and quantifying the emergence of sparse concepts in dnns. In CVPR, 2023.\n\n[cite 3] Ren, Q., et al. Where we have arrived in proving the emergence of sparse symbolic concepts in ai models. arXiv preprint arXiv:2305.01939, 2023.\n\n[cite 4] Zhou, H., et al. Concept-Level Explanation for the Generalization of a DNN. arXiv preprint arXiv:2302.13091, 2023.\n\n**Q2: Asking for the proof of Theorem 3.**\n\n> Q2: \"if detailed derivations of Equation 11 were provided\" \"The proofs in the paper rely on two papers currently under review ([1,2] See appendix C). \"\n\n**A2:** Thank you very much for your careful review. Please see the revised derivations of the Equation (11) in Appendix D.\n\nFirst, the proposed loss function of learning generalizable interactions does **not** rely on the proof of two papers [cite 3] [cite 5]. We can still extract generalizable interactions without Theorem 3.\n\nSecond, the sparsity of interactions has been widely observed in many studies [cite 1] [cite 2], so that we actually do **not** need the two under-review papers [cite 3] [cite 5]\u00a0to support the design of our algorithm.\u00a0To this end, we are sorry that we use the inaccurate statements that mislead the understanding of Theorem 3. We have revised the paper in Theorem 3 and Proposition 1."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission861/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700269606220,
                "cdate": 1700269606220,
                "tmdate": 1700272832857,
                "mdate": 1700272832857,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kVMemXerlA",
                "forum": "OCqyFVFNeF",
                "replyto": "Bj480LkqQJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission861/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission861/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**A2:** Besides, the proposed universal-matching theorem on AND interactions has been proved in an CVPR paper [cite 2], as $\\forall T\\subseteq N, v(\\mathbf{x}\\_T)=\\sum_{S\\subseteq T}I\\_{\\text{\\rm and}}(S|\\mathbf{x})$. Then, we can prove the universal-matching theorem on both AND interactions and OR interactions (shown as the revised Theorem 3) in Appendix C. Then, according to the finding that well-trained DNNs tend to encode sparse interactions in [cite 1], we can also obtain the proposition $\\forall T\\subseteq N, v(\\mathbf{x}\\_T) \\approx v(\\mathbf{x}\\_\\emptyset) + \\sum\\nolimits_{\\emptyset \\neq S\\subseteq T: S\\in \\Omega^{\\text{\\rm and}}}I\\_{\\text{\\rm and}}(S|\\mathbf{x}\\_T) + \\sum\\nolimits_{S\\cap T \\neq \\emptyset:S\\in \\Omega^{\\text{\\rm or}}}I_{\\text{\\rm or}}(S|\\mathbf{x}_T)$. Given the findings in [cite 1], the proof of the sparsity of interactions in [cite 3] is no long so important to prove our conclusion.\n\n[cite 1] Li, M., et al. Does a neural network really encode symbolic concept? In ICML, 2023.\n\n[cite 2] Ren, J., et al. Defining and quantifying the emergence of sparse concepts in dnns. In CVPR, 2023.\n\n[cite 3] Ren, Q., et al. Where we have arrived in proving the emergence of sparse symbolic concepts in ai models. arXiv preprint arXiv:2305.01939, 2023.\n\n[cite 5] Li, M., et al.  Technical note: Defining and quantifying and-or interactions for faithful and concise explanation of dnns, 2023. arXiv preprint arXiv:2304.13312, 2023.\n\n**Q3:  \"it lacks a discussion on the existence of generalizable interactions\"**\n\n**A3:** Thank you. Theoretically, there is no guarantee that generalizable interactions necessarily exist. However, empirically, [cite 1] has observed that for many different tasks (e.g., image classification on the MNIST dataset and image classification on the CelebA-eyeglasses datasets), different DNNs trained for the same task all encode similar interactions. This is the motivation of this study, and we decide to go beyond empirical comparisons and formally design a loss function to learn generalizable interactions.\n\nIn addition, we have **conducted more experiments** to show the generalization interactions between more DNNs (i.e., between the LLaMA and  Aquila-7B [cite 6]). Please see Appendix L for details.\n\nAlthough we cannot strictly prove that such generalization power of interactions is a generic property for all tasks, experiments show that most DNNs exhibit interactions with considerable generalization power. We believe this will provide new insights into the representation quality of a DNN.\n\n[cite 1] Li, M., et al. Does a neural network really encode symbolic concept? In ICML, 2023.\n\n[cite 6] BAAI. Aquila-7B, 2023. URL https://huggingface.co/BAAI/Aquila-7B.\n\n**Q4: Discussion on \"the method proposed in the paper is derived heuristically using Occam's Razor principle\"**\n\n> Q4:  \"The paper does not satisfactorily address why this approach would yield generalizable interactions.\"\n\n**A4:** Thank you, but the generalization power of interactions is **not** guaranteed by the Occam\u2019s Razor principle, although we do use this principle in Equation (6). Instead, we design a specific loss $\\Vert\\rm{rowmax}({I}\\_{\\text{\\rm and}})\\Vert_1 +\\Vert\\rm{rowmax}({I}\\_{\\text{\\rm or}})\\Vert_1$ in Equation (5), which exclusively penalizes non-generalizable interactions. Here, let us be given $m$ interactions on the same subset $S$, $I_{\\rm and}^{(1)}(S|x), I_{\\rm and}^{(2)}(S|x),...,I_{\\rm and}^{(m)}(S|x)$, extracted from $m$ DNNs. We consider the interaction with the maximum absolute value $max_i \\vert I_{\\rm and}^{(i)}(S|x)\\vert$ as the outlier effect that is exclusively contained by a single DNN. Thus, this loss only penalizes the outlier effect to boost the generalization power. For example, given $I^{(1)}(S|x)$ and $I^{(2)}(S|x)$ for the  same set of input variables $S\\subseteq N$ extracted from two DNNs, if this interaction is non-generalizable, it usually means that the interactions extracted from two DNNs have significantly different effects on the model output. In this way, the loss in Equation (5) directly pushes the most salient interaction towards the other interactions, thereby making interactions in different DNNs similar to each other.\n\nWe have revised the paper to clarify this in the paragraph under Equation (6)."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission861/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700270291469,
                "cdate": 1700270291469,
                "tmdate": 1700703836281,
                "mdate": 1700703836281,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aEpGC6RJW1",
                "forum": "OCqyFVFNeF",
                "replyto": "KVjc80TBPK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission861/Reviewer_GVkW"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission861/Reviewer_GVkW"
                ],
                "content": {
                    "comment": {
                        "value": "Thnak you for answering the questions detailed, I appretiate the proof of Eq 11 and the new experiments. Most of my concerns are addressed. I will increase the score accorddingly."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission861/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700729434940,
                "cdate": 1700729434940,
                "tmdate": 1700729434940,
                "mdate": 1700729434940,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8NOtmjUgjP",
            "forum": "OCqyFVFNeF",
            "replyto": "OCqyFVFNeF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission861/Reviewer_f9us"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission861/Reviewer_f9us"
            ],
            "content": {
                "summary": {
                    "value": "The paper begins by revisiting Harsayni's 1963 decomposition of Shapley values into \"and\" cohorts, and extends the idea to a claim that the output of a neural network can be decomposed into sparse contributions from \"and\" and \"or\" cohorts (Theorem 3).  Then it observes that such a composition could be ambiguous, and that it might not generalize to other models of the same data.  Then it proposes a framework for finding small and/or cohorts by optimizing for sparsity (eq 4), and further for maximizing sparsity while blending in another loss term that takes account sharing of variables in some way (eqs 5, 6).  Then it introduces a noising scheme (page 7) and proposes optimizing the search for cohorts in the presence of some level of noise.  Finally, the paper sets up experiments to search for such and/or cohorts within the behavior of a few large neural networks, examining extremely small subsets of the behavior of those network (reducing to 8-10 input variables), by manually selecting 8 patches within MNIST images of \"3\"s and 10 tokens for each set of inputs for SQuAD and SST-2 data sets, and examining the ability to find and/or cohorts that explain behavior of BERT, Llama, ResNet, etc.  It claims that with these methods it able to distinguish interactions that are shared between different models, and interactions that are in common."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The goal of trying to fully explain a neural network's behavior by decomposing it into just AND and OR interactions is admirable, and so is the ambition of attempting to apply such analysis to huge models such as Llama and BERT and VGG-16.\n\nThe focus on looking for commonalities between different models is interesting: it is an open and interesting question whether different models trained to solve the same task solve them in the same way or different ways, and how to understand the differences."
                },
                "weaknesses": {
                    "value": "The paper does not refer to other work in examining shared features between networks, for example: https://arxiv.org/abs/2306.09346\n\nThe conclusions drawn from the paper are both noncommittal and unconvincing.  For example, the paper claims \"The sparsity and universal-matching property of interactions provide lots of evidence to faithfully explain DNNs with interactions.\"  However, the methods are considered over only tiny subsets of just 8 or 10 features, (e.g., explained in appendix G, just 8 hand-chosen patches of images of MNIST \"3\" digits, or just 10 words out of the hundreds for each example in the NLP data sets).  As a result, what is being explained with these methods cannot be claimed to be faithful to \"ResNet\" or \"BERT Large,\" but actually a very miniscule slice of the behavior of those huge networks.  The claim of faithfulness is not backed up empirically.\n\nThe methods are not clearly presented.  The main method comes down to Equation 6.  However most of the pages of the paper are spent on discussing Theorem 3, which is only tangentially related to the method and which does not clarify what the method actually does. For example, how continuous neural network features are discretized for the and-or analysis is not discussed at all.  How the search to optimize the discrete objective in Eq 6 is not discussed, and the level of sparsity, or the number of cohorts found in a typical solution is not revealed in concrete terms. If the goal is to clearly explain the method, it would be more helpful to move the tangential theorems to the appendix and spend more pages explaining equation 6 more precisely, with both concrete examples of how the interaction matrices are formatted, and concrete examples of how a search over cohorts would work in a specific small example.  Since runtime seems to be a major concern, it should be discussed. The size of the sets of features is small enough that it seems that a real-data example of how the method operates on a single example could be shown in detail.\n\nThe experiment results are very unclear, and it seems like it would be very difficult to reproduce the results given the information provided.  For example, in results in Fig 2 and 3 the y axis \"Interaction Strength\" is not explained other than that \"it is in log space\" or \"it is the ratio of shared interactions\".  What number is this this strength, and in what units? Beyond the lack of units, after the results are shown, they are not analyzed.  By analyzing the log-odds output of the ground-truth label, it looks like it is measuring faithfulness, but the plot captions claim a measurement of \"interaction strength\".  How interactions are being measured is not clear.  There is a very tiny 1/20 |I(s)|_max inside one of the plots that looks like a hint, but it is not explained.  Similarly, the units for Figure 4 are not explained.  All experiments are compared to a \"Traditional\" baseline which is not explained or summarized other than a reference to \n\nFigure 5 shows some qualitative differences, but it is not clear what conclusions should be drawn from the differences.  For example, it shows that a disjunction \"Ring just cold wet Seattle...\" etc is promoted from the \"Distinctive interactions\" column using Traditional methods to the \"Shared interactions\" column in the Our method.  Is this a success or is this a failure?  If there are two different ways of identifying the interactions, does the new way provide more insight?  Or are they just different? Figure 5 select \"some of the sailent\" interactions - is it cherry-picked?  What does it look like when not?"
                },
                "questions": {
                    "value": "What is the runtime complexity of the method?\nIn the three data settings (or in the half dozen models) what are the actual numbers of cohorts of AND and OR variables that are found that achieve a specific high level of faithfulness?\nHow are features discretized for analysis?\nWhat are the units of measure for interaction strength?\nWhat can we conclude about the similarity between VGG and ResNet, or the similarity between BERT base and BERT large?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission861/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698855048451,
            "cdate": 1698855048451,
            "tmdate": 1699636012443,
            "mdate": 1699636012443,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xZI9tZvF5r",
                "forum": "OCqyFVFNeF",
                "replyto": "8NOtmjUgjP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission861/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission861/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for your comments, which help us much improve the paper in the rebuttal phase. It seems that most concerns (Q3, Q4, Q5, Q6, Q8) mainly focused on the clarity of the technical details. We have carefully revised the paper in blue according to your suggestions on the paper-writing issues. We have also carefully answered all other questions, and have conducted new experiments as you requested.\n\n**Please let us know as soon as possible, if you have any further questions or concerns.**\n\n**Q1: Discussion on the recommended paper in ICCV 2023.**\n>Q1: \"refer to other work in examining shared features between networks\"\n\n**A1:** Thank you. This paper is interesting. Unlike our objective of faithfully explaining DNNs into symbolic interactions, that paper identifies units (convolutional kernels) in different DNNs that share similar concepts. Beyond the analysis of feature maps of different units, our paper discovers that different DNNs trained for the same task tend to learn similar sets of interactions, as long as the different neural networks are sufficiently optimized, no matter whether these DNNs have different architectures and parameters. For example, as Figure 4 shows, two completely different LLMs surprisingly encode two similar sets of sparse interactions (phrases). Therefore, our attempt of extracting common interactions shared by different DNNs provides a new direction of pursuing the essential explanation of a DNN\u2019s feature representations.\n\nNevertheless, we have cited and discussed this paper in Appendix A in the revised paper. \n\n**Q2: $\\color{blue}{\\textsf{Asking about the evidence for the faithfulness of the sparsity and universal-matching.}}$** \n>Q2: Concerning the paper's claim that \"The sparsity and universal-matching property of interactions \u2026to faithfully explain DNNs with interactions\".\"the methods are considered over only tiny subsets of just 8 or 10 features \u2026cannot be claimed to be faithful to 'ResNet' or 'BERT Large' \", \"The claim of faithfulness is not backed up empirically.\"\n\n**A2:** It is a very good question. Let us clarify both in the theoretical proofs and in experiments for the faithfulness of the sparsity and universal-matching. \n\nTheoretically, the faithfulness means that given an input with $n$ variables, we must prove that (1) the DNN only encodes a small number of salient interactions $\\Omega$, comparing with all $2^n$ potential combinations of the input variables, i.e., $\\vert\\Omega\\vert \\ll 2^n$, and that (2) the network outputs on all $2^n$ randomly masked samples $\\\\{\\mathbf{x}_S|S\\subseteq N\\\\}$ can be well matched by a few interactions in $\\Omega=\\\\{S\\subseteq N: \\vert I(S|x) \\vert > \\tau\\\\}$, $\\Omega$ is defined in the eighth paragraph in Section 2.1\u00a0in the revised paper. These two terms have been proved in Theorem 1, Theorem 3 and Proposition 1\u00a0in the revised paper.\n\nThen, in practice, considering the $2^n$ computational complexity, we have followed settings in [cite 1] to extract interactions between a set of randomly selected input variables $N=\\\\{1,2,\u2026,t\\\\}, (t<n)$ (other unselected $(n-t)$ input variables will remain unmasked, leaving the original state unchanged). In this case, faithfulness does not mean that our interactions explain all the inference logic encoded between all $n$ input variables for a given sample $x$ in the pre-trained DNN. Instead, it only means that the extracted interactions can also accurately match the inference logic encoded between the selected $t$ input variables for a given sample $x$ in the DNN. We have clarified this in Appendix G in the revised paper. \n\n**Experimental verification.** In addition, we have further conducted **a new experiment** to verify the faithfulness when we explain interactions between all input variables. To this end, for the sentiment classification task on the SST-2 dataset in ${\\rm BERT_{BASE}}$, we selected sentences containing 15 tokens to verify the faithfulness of the sparsity in Proposition 1 and\u00a0the\u00a0universal-matching property in Theorem 3.\u00a0All tokens are selected as input variables.  We focused on the matching errors $\\epsilon_T=v^{\\rm approx}(x_T) - v(x_T), v^{\\rm approx}(x_T):=v(x_{\\emptyset})+ \\sum_{\\emptyset\\ne S\\subseteq T : S\\in \\Omega^{\\rm and}}I_{\\text{\\rm and}}(S|x_T) + \\sum_{ S\\cap T \\neq \\emptyset: S\\in \\Omega^{\\text{\\rm or}}}I_{\\rm or}(S|x_T)$ for all masked samples \u00a0$x_T, \\forall T\\subseteq N$. Specifically, we observed whether the real network output on the masked sample $v(x_T ),\u00a0\\forall T\\subseteq N$ can be well approximated by interactions. We have verified that the extracted salient interactions in $\\Omega$ faithfully explain the model output, i.e., $\\forall T\\subseteq N, v(x_T) \\approx v(x_{\\emptyset})+ \\sum_{\\emptyset\\ne S\\subseteq T : S\\in \\Omega^{\\rm and}}I_{\\text{\\rm and}}(S|x_T) + \\sum_{ S\\cap T \\neq \\emptyset: S\\in \\Omega^{\\text{\\rm or}}}I_{\\rm or}(S|x_T)$. Please see\u00a0Appendix G\u00a0 in the revised paper for more details."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission861/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700265401204,
                "cdate": 1700265401204,
                "tmdate": 1700265401204,
                "mdate": 1700265401204,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "87k12wOVoM",
                "forum": "OCqyFVFNeF",
                "replyto": "8NOtmjUgjP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission861/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission861/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**A2:**\n[cite 1] Li, M., et al. Does a neural network really encode symbolic concept? In ICML, 2023.\n\n**Q3: $\\color{blue}{\\textsf{About paper writing.}}$**\n\n> Q3: \"how continuous neural network features are discretized for the and-or analysis\"\n\n**A3:** Thank you. We have followed your suggestion to clarify how to define discretized interactions for continuous input variables in blue in the footnote [3]. We did not discretize the continuous values of each input variable. Instead, we simply followed [cite 1] to mask each input variable $i\\in N\\setminus S$ by defining and using baseline values (see Appendix C for the definition of the baseline values in the revised paper). For example, for the image dataset, we used zero as the baseline value to represent the masked state of the input variable in $i\\in N\\setminus S$ (see Appendix M.2 for experimental details in the revised paper). In this way, for each input sample with $n$ input variables, there are a total of $2^n$ different masked states $\\\\{x_S\\\\}$, as described in the tenth paragraph of Section 2.1. Therefore, the masked and unmasked states are two discretized states for each input variable, so that we can define the discretized interactions  $I_{\\rm and}$ and $I_{\\rm or}$ based on the masked samples in Equations (1) and (2). \n\n[cite 1] Li, M., et al. Does a neural network really encode symbolic concept? In ICML, 2023.\n\n**Q4: $\\color{blue}{\\textsf{About paper writing. Ask for detailed explanation for Equation 6.}}$**\n\n> Q4: \"How the search to optimize the discrete objective in Eq 6 is not discussed, and the level of sparsity\" \"the number of cohorts found in a typical solution is not revealed in concrete terms\" \"with both concrete examples of how the interaction matrices are formatted \u2026 in a specific small example\" \"a real-data example of how the method operates on a single example could be shown in detail\"\n\n**A4:** Thank you. Please see answers to Q3 for the concerns on the discretization problem. Then, let us answer other concerns as follows.\n\n$\\bullet$ The optimization of the loss function in Equation (6) is simply based on the gradient descent method. This is because the parameter $\\gamma_{T}\\in R$ to be optimized is continuous, rather than discrete. As mentioned in the first paragraph of Section 2.3, we learned the optimal values of $\\gamma_{T}, T\\subseteq N$ to decompose the model output $v(x_T)$ into two terms $v_{\\rm and}(x_T)$ and $v_{\\rm or}(x_T)$. The loss was designed to boost the sparsity of interactions, which ensured the sparsity of interactions. That is, such optimal values of $\\gamma_{T}$ are learned to make most interactions almost zero effect, $I_{\\rm and}(T|x) \\approx 0$ and $I_{\\rm or}(T|x) \\approx 0$.\n\n$\\bullet$ **The number of interactions been optimized.** During the optimization process, the loss in Equation (6) is applied to all $2^n$ interactions. After  the learning of parameters $\\\\{\u00a0\\gamma_T | T\\subseteq N\\\\}$, we compute the $2^n$ interactions based on Equations (1) and (2). Most of these interactions have almost zero effect. We select interactions which are greater than the threshold $\\tau$ as salient interactions. The final number of salient interactions is determined by the threshold $\\tau$. Please see the eighth paragraph of Section 2.1 for details.\n\nBesides, we have also **conducted experiments** to show the number of salient interactions extracted by optimizing the loss in Equation (6). For example, Figure 2 shows that Equation (6) extracts 2915 salient interactions  ($\\approx$ 0.71%) \u00a0from the $(2\\cdot2^{10})\\times200$\u00a0AND-OR interactions extracted from a total of 200 samples in the\u00a0${\\rm BERT_{BASE}}$ model, when we set the threshold $\\tau=1/20\\cdot\\max_S\\vert I(S|x)\\vert$.\n\n$\\bullet$ The interaction matrices in Equation (6) are formulated in the first sentence below Equation (5). \n\nLet us use a concrete example to illustrate how the interaction matrices are formatted in a toy example. Let us consider two pre-trained DNNs $v^{(1)}$, $v^{(2)}$ and an input sample $x$ with $N=\\\\{1,2\\\\}$ variables, and take the AND interaction matrix ${I}\\_{\\rm and}$ in Equation (6) as an example (the OR interaction matrix can be obtained similarly). First, we get all $2^2$ AND interactions extracted from the $i$-th model $\\mathbf{I}^{(i)}\\_{\\rm and}=[ I\\_{\\rm and}(T_1|x), I\\_{\\rm and}(T_2|x), I\\_{\\rm and}(T_3|x), I\\_{\\rm and}(T_4|x)]^\\intercal \\in \\mathbb{R}^{2^2}$, according to the description of Equation (4). Here, each interaction value $I_{\\rm and}(T_k|x) \\in \\mathbb{R}, T_k \\subseteq N$ denotes the interaction value of each masked sample $x_{T_k}$ and is computed by Equation (1). Second, the AND interaction matrix ${I}\\_{\\rm and}= \\left[ \\mathbf{I}^{(1)}\\_{\\rm and}, \\mathbf{I}^{(2)}_{\\rm and} \\right] \\in \\mathbb{R}^{2^2\\times 2}$ denotes the interaction values corresponding to the $2^2$ masked samples for each of the two models."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission861/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700266115170,
                "cdate": 1700266115170,
                "tmdate": 1700268594705,
                "mdate": 1700268594705,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LmKLDpbmHX",
                "forum": "OCqyFVFNeF",
                "replyto": "87k12wOVoM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission861/Reviewer_f9us"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission861/Reviewer_f9us"
                ],
                "content": {
                    "comment": {
                        "value": "Several things remain unclear in the paper.\n\n* Exactly what is the procedure that is being done in the paper?  Can you give a concrete example of the experimental procedure from beginning to end for one of your small experimental settings?\n* The existing text does not make it clear.  For example, despite the rebuttal assertion, Appendix C does not define baseline values.  It also does not clearly define the masking procedure, for example, there is no variable for the mask nor is there a formula describing the relationship between the mask and x and b.  An end-to-end example on a simplified case (e.g., mnist) might be helpful to clarify.\n* Similarly, appendix M.2 does not seem to exist in the revision.  The additional examples in Figure 10 are just the same as the previously given ones and do not add further clarity.\n\nThe paper's extraordinary claim, i.e., that DNNs can be analyzed as simple binary predicate and/or logic, requires extraordinary care, clarity and evidence, but the current paper does not meet that standard.\n\nThe paper would be improved it were restructured, with a clear formulation section defining all the notation and the experimental procedure from beginning to end, with an example.  However, that would be a more significant rewrite than has currently been done.\n\nScore remains a 5."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission861/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700658143029,
                "cdate": 1700658143029,
                "tmdate": 1700658143029,
                "mdate": 1700658143029,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hnaTjtYJCt",
                "forum": "OCqyFVFNeF",
                "replyto": "8NOtmjUgjP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission861/Reviewer_f9us"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission861/Reviewer_f9us"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the detailed example.\n\nProviding such an example in a concrete case brings the paper in right direction because it makes the paper more accessible and more likely to be reproducible. However, my concerns about the clarity of the main paper remain.  It would be helpful if the main paper included a clearer statement of both the method (more succinctly than your new appendix) and, especially if the main paper provided more of a discussion situating the new approach within the context of a broader range of related work.\n\nFor example: once the masking approach of the paper is clarified, the paper should also clarify how it differs from, or how it addresses limitations of previous methods that use masking to explain the behavior of a network (these include Petsiuk 2019, Fong 2017, Dabkowski 2017, Hanjie Chen 2020,  and recently Johannes Linder 2022).  What problems with those previous research works are addressed by this new paper's methods?  The paper would benefit from a much more detailed discussion of other papers that have taken a related approach, and how they relate to the current work.\n\nIf rewritten with both (1) this clarity of the current method and (2) and its relation to the broader research context, the paper would be stronger, but my recommendation is that the paper still needs a major revision to reach this level of clarity.  It would best be done as a major revision for another venue. (Remaining a 5)"
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission861/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737334975,
                "cdate": 1700737334975,
                "tmdate": 1700738266736,
                "mdate": 1700738266736,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CECG4CGYdx",
                "forum": "OCqyFVFNeF",
                "replyto": "8NOtmjUgjP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission861/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission861/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your feedback. We are glad to answer your questions. However, if you still have new concerns, we have no time to answer your new feedback before the deadline. \n\nCompared to traditional masking methods, our approach is quite different.  Instead, our approach aims to obtain an essential representation of the model's inference logic. We try to mimic the final output of the neural network with a sparse, small number of interactions. In contrast, these traditional masking methods have fully different tasks and different motivations."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission861/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740681353,
                "cdate": 1700740681353,
                "tmdate": 1700740820931,
                "mdate": 1700740820931,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]