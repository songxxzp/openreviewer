[
    {
        "title": "CAST: Cluster-Aware Self-Training for Tabular Data"
    },
    {
        "review": {
            "id": "v4TVxFoFvK",
            "forum": "NDfxOMJqgL",
            "replyto": "NDfxOMJqgL",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2320/Reviewer_b9QV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2320/Reviewer_b9QV"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed a simple but effective self-training method for tabular data, which takes the cluster assumption to regularize confidence values. Experiments on four datasets demonstrate the superiority of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed method is well motivated by the observations shown in Fig. 1, namely, pseudo-labels that lie in high-density regions are more reliable than those that lie in low-density regions.\n2. The paper is well-written and organized in general. The simple modifications on the confidence value proved to be effective through experiments on four tabular datasets."
                },
                "weaknesses": {
                    "value": "1. The density estimation plays an important role in the proposed method. However, the authors only spend a few words saying that the density is estimated using the prior knowledge derived from the labeled training data distribution. I am confused when reading this part of the method and hope the authors can provide more details on that.\n2. Just as the authors have claimed, the only difference between CAST and the conventional self-training algorithm is the use of regularized confidence. In other words, it seems that the proposed method has no specific designs for tabular data. Thus, I wonder if it is possible to supply a bit more results on other forms of data to show the proposed method is a general solution in self-training.\n3. Are the best choices of the hyper-parameter $\\alpha$ the same across different datasets? Would the optimal value be influenced by the number of samples in the dataset?\n4. There are some related self-training enhanced clustering methods such as SCAN (ECCV 2020), SPICE (TIP 2022), and TCL (IJCV 2022), that the authors are encouraged to include in the related works.\n5. The meaning of the abbreviation could be provided in the caption of Table 1 to improve readability."
                },
                "questions": {
                    "value": "Please refer to the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2320/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697875069914,
            "cdate": 1697875069914,
            "tmdate": 1699636164490,
            "mdate": 1699636164490,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2hdjkxxrmr",
                "forum": "NDfxOMJqgL",
                "replyto": "v4TVxFoFvK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2320/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2320/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We deeply appreciate your constructive feedback on our manuscript. Your insights have helped us refine our work, and we have updated the manuscript accordingly.\n\n---\n\n### Weakness 1\nThe density estimation plays an important role in the proposed method. However, the authors only spend a few words saying that the density is estimated using the prior knowledge derived from the labeled training data distribution. I am confused when reading this part of the method and hope the authors can provide more details on that.\n\n*Answer:* We apologize for any confusion regarding the density estimation method in our manuscript. To clarify, we have revised the method section to detail the process as follows.\n\nWe get the estimated density for unlabeled samples by extracting the prior knowledge using a density estimator $\\textit{D}_{t}$ (e.g. multivariate kernel density estimator or empirical likelihood) which is fitted to the labeled training data distribution\nHere, the prior knowledge $\\boldsymbol{\\gamma}$ for each class is defined as follows:\n\n$$\n\\boldsymbol{\\gamma}^{(i)} \\leftarrow \\textit{D}_{t}(\\boldsymbol{x}^{(i)}), \\quad \\text{where} \\quad \\boldsymbol{\\gamma}^{(i)} = \\text{[}{\\gamma}_1, \\gamma_2, ... , \\gamma_N\\text{]}\n$$\n\nThen, we normalize $\\boldsymbol{\\gamma}$ using a min-max scaler because the scale of $\\boldsymbol{\\gamma}$ varies among implementations, and we need a relative measure to align unlabeled samples.\n\nAnd we leave the specific choice of density estimator for CAST to implementation as we believe open to extension is a crucial component for the versatility. For example, CAST which uses dataset-specific density estimator might be surpass CAST-D or CAST-L on the specific dataset. Our implementation of CAST-D and CAST-L are shown in Appendix D.\n\n\n### Weakness 2\nJust as the authors have claimed, the only difference between CAST and the conventional self-training algorithm is the use of regularized confidence. In other words, it seems that the proposed method has no specific designs for tabular data. Thus, I wonder if it is possible to supply a bit more results on other forms of data to show the proposed method is a general solution in self-training.\n\n*Answer:* We agree with your observation that the core idea of CAST, which involves adjusting the prediction confidence based on the cluster assumption, could extend to data types beyond tabular data. However, as we now note in our conclusion, the current implementation of CAST is limited by the absence of suitable density estimation methods for non-tabular data types, such as images or text. The structured nature of tabular data allows for clear density estimation from labeled training datasets as tabular data ensures that each feature occupies a specific, fixed position within the table. But there is no such characteristics in other data types. This limitation is now explicitly acknowledged in our manuscript.\n\n### Weakness 3\nAre the best choices of the hyper-parameter $\\alpha$ the same across different datasets? Would the optimal value be influenced by the number of samples in the dataset?\n\n*Answer:* As indicated in Figure 6 of our manuscript, there is no universally optimal choice for the hyperparameter $\\alpha$. Its optimal value varies based on various factors, even within the same dataset, such as the number of training samples, classifier architecture, and self-training algorithms. Therefore, we recommend a specific range for tuning $\\alpha$ to accommodate these variations.\n\n\n### Weakness 4\nThere are some related self-training enhanced clustering methods such as SCAN (ECCV 2020), SPICE (TIP 2022), and TCL (IJCV 2022), that the authors are encouraged to include in the related works.\n\n*Answer:* After reading the suggested literature, we have included SPICE (TIP 2022) and TCL (IJCV 2022) in the related works section as follows: Niu et al. (2022) ensure the reliability of pseudo-labels through the use of a semantically consistent ratio, while Li et al. (2022) enhance clustering performance by selectively incorporating the most confident predictions from each cluster. We also agree that SCAN (ECCV 2020) is significant in semi- and self-supervised learning, but their work does not improve self-training. Therefore, we exclude it from our related works section as it does not align directly with our work on enhanced self-training.\n\n\n### Weakness 5\nThe meaning of the abbreviation could be provided in the caption of Table 1 to improve readability.\n\n*Answer:* We have included detailed explanations of the abbreviations in the caption of Table 1.\n\n---\n\nWe hope these revisions adequately address your concerns and further clarify our research contributions. We are grateful for your valuable insights and remain open to any further feedback."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2320/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700161833813,
                "cdate": 1700161833813,
                "tmdate": 1700162519372,
                "mdate": 1700162519372,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "cseLqwlpeB",
            "forum": "NDfxOMJqgL",
            "replyto": "NDfxOMJqgL",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2320/Reviewer_QLpL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2320/Reviewer_QLpL"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a new calibration strategy for self-training on tabular data. The strategy is based on an algorithm outputting a confidence score for each input sample that linearly interpolates between the confidence score provided by the classifier and its scaled version. Specifically, the scaling factor incorporated the low-density assumption, thus being proportional to the data density. It is estimated either using a kernel density estimator or a Naive Bayes-like generative model. The overall calibration strategy can be easily plugged into existing self-training algorithms. Experiments are conducted on different toy and tabular datasets showcasing (i) the versatility of the approach for being easily applied to different self-training variants (fixed/adaptive threshold, noise filtering) and different classifiers (decision trees, MLPs) and (ii) the superiority against basic calibration strategies."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The idea is simple, yet novel (**Novelty**)\n2. The paper is clear and easy to read (**Clarity**)\n3. Code is provided. However, no additional check on replicability has been performed (**Reproducibility**)"
                },
                "weaknesses": {
                    "value": "1. The scope of applicability of the proposed solution is quite narrow. Indeed, the proposed solution seems to be applicable to low dimensional datasets and it is not clear how well the solution scales and generalises to more realistic high-dimensional datasets (**Significance**)\n2. The proposed solution requires a density estimation step and therefore it is more computationally demanding with respect to the considered baselines. Experiments should provide also this information (**Quality**)\n3. The cluster assumption (or equivalently the low-density separation) can be cheaply incorporated by leveraging techniques based on entropy minimisation for semi-supervised learning. A discussion and possibly experimental comparison against such techniques is missing (**Quality**). For instance, see [1-3]\n4. Limitations are not discussed (**Quality**)\n\n**References**\n\n[1] Semi-supervised Learning by Entropy Minimisation. NeurIPS 2004\n\n[2] Towards making unlabeled data never hurt. PAMI 2015\n\n[3] MixMatch: A Holistic Approach to Semi-Supervised Learning. NeurIPS 2019"
                },
                "questions": {
                    "value": "Please find below some questions related to the above mentioned weaknesses plus some more detailed ones about the experiments:\n1. Can you please elaborate on the 4 above-mentioned weaknesses?\n2. Regarding experiments on toy datasets, is there any reason why temperature scaling is not shown?\n3. In almost all experiments there is a significant difference between the two proposed ways of estimating the density (CAST-D and CAST-L). Can you please discuss about this aspect? Is this issue related to an improper hyperparameter tuning?\n4. In Figure 5, can you please explain why the performance decrease with a larger amount of labeled examples, as this seems a counterintuitive result?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2320/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2320/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2320/Reviewer_QLpL"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2320/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698419235745,
            "cdate": 1698419235745,
            "tmdate": 1700386967922,
            "mdate": 1700386967922,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "RQSTTOQPaC",
                "forum": "NDfxOMJqgL",
                "replyto": "cseLqwlpeB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2320/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2320/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors (1)"
                    },
                    "comment": {
                        "value": "We are grateful for your insightful feedback and the opportunity to further clarify and enhance our manuscript.\n\n---\n\n### Weakness 1\nThe scope of applicability of the proposed solution is quite narrow. Indeed, the proposed solution seems to be applicable to low dimensional datasets and it is not clear how well the solution scales and generalizes to more realistic high-dimensional datasets *(Significance)*\n\n*Answer:* We understand the concern about CAST's scalability to high-dimensional datasets. To address this, we included results from the Bioresponse dataset in OpenML-CC18, which is notably high-dimensional with 1777 features and 3751 samples. The results, detailed in Table 11 in Appendix I, demonstrate that CAST effectively handles high-dimensional data, showing significant improvements of CAST.\n\n| | Method  | Relative Improvement | | Method  | Relative Improvement |\n|---------|---------|----------|---------|---------|----------|\n| | Baseline| -0.024    | | Baseline| 0.155   |\n| | TS      | 0.052   | | TS      | 0.290  |\n| | HB      | 0.022    | | HB      | 0.354    |\nFPL| SP    | -0.058    |CPL| SP    | 0.265    |\n| | GP      | 0.567    | | GP      | 0.249    |\n| | CAST-D  | 0.688    | | CAST-D  | 2.454    |\n| | CAST-L  | 1.150    | | CAST-L  | 1.821    |\n\n### Weakness 2\nThe proposed solution requires a density estimation step and therefore it is more computationally demanding with respect to the considered baselines. Experiments should provide also this information (*Quality*)\n\n*Answer:* We have added detailed information about CAST\u2019s computational cost in Appendix H. The computational costs for CAST-D and CAST-L were benchmarked against the training time of XGBoost, using a single CPU core of Ryzen 5975wx and one RTX 4090. The results indicate that CAST's computational demand is comparable to the training time of XGBoost and significantly lower than that of neural networks.\n\n|            |            |            |           |         |         |    Time (s)  |       |         |          |           |          |            |\n|------------|--------|--------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|\n|            |            | 6M mortality | |          | diabetes |       |          | ozone |           |           | cmc  |            |  \n|            | XGB    | FT     | MLP   | XGB   | FT    | MLP   | XGB   | FT    | MLP   | XGB   | FT    | MLP   |\n| Training   | 5.25   | 749.02 | 96.97 | 0.10  | 26.85 | 9.40  | 0.51  | 89.57 | 14.32 | 0.19  | 27.90 | 16.12 |\n| CAST-D     |    | 7.13      |      |   | 0.15     |      |   | 0.50    |      |  | 0.25      |      |\n| CAST-L     |  | 3.99      |     |  | 0.14      |      |   | 0.48     |      |   | 0.19     |     | \n|            |            |            |       Relative    |      additional   |     overhead    |       of CAST     |  compared     |     to training    |   time (%)        |           |          |            |\n|            |            | 6M mortality | |          | diabetes |       |          | ozone |           |           | cmc  |            |  \n|            | XGB    | FT     | MLP   | XGB   | FT    | MLP   | XGB   | FT    | MLP   | XGB   | FT    | MLP   |\n| CAST-D   | 135.84 | 0.95   | 7.35  | 148.15| 0.57  | 1.63  | 98.72 | 0.56  | 3.51  | 127.70| 0.89  | 1.53  |\n| CAST-L   | 76.08  | 0.53   | 4.12  | 133.65| 0.52  | 1.47  | 94.99 | 0.54  | 3.38  | 97.35 | 0.68  | 1.17  |\n\n### Weakness 3\nThe cluster assumption (or equivalently the low-density separation) can be cheaply incorporated by leveraging techniques based on entropy minimisation for semi-supervised learning. A discussion and possibly experimental comparison against such techniques is missing (*Quality*). For instance, see [1-3]\n\n*Answer:* Self-training is a version of the entropy minimization algorithm, which minimizes the likelihood deprived of the entropy of the partition [1]. It constructs hard (one-hot) labels from high-confidence predictions on unlabeled data to implicitly achieve entropy minimization [2]. We have clarified that self-training is inherently an entropy minimization algorithm. And we acknowledge the significance of entropy minimization techniques in semi-supervised learning. However, we intentionally did not compare CAST with other SSL techniques including other entropy minimization algorithms as our aim is to demonstrate whether self-training can be improved by solely refining confidence or not. Note that, our manuscript\u2019s central question is \u2018Can we improve self-training for tabular data by making confidence more reliable, without altering the self-training algorithm or model architecture?\u2019."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2320/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700161517948,
                "cdate": 1700161517948,
                "tmdate": 1700162644108,
                "mdate": 1700162644108,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "C2UdFO7sZH",
                "forum": "NDfxOMJqgL",
                "replyto": "cseLqwlpeB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2320/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2320/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors (2)"
                    },
                    "comment": {
                        "value": "### Weakness 4\nLimitations are not discussed (*Quality*)\n\n*Answer:* We apologize for the missing limitation of CAST. The manuscript now explicitly states the limitation in the conclusion section that CAST is its inapplicability to domains such as images or text as there are no suitable density estimation methods. The structured nature of tabular data allows for clear density estimation from labeled training datasets as tabular data ensures that each feature occupies a specific, fixed position within the table. But there are no such characteristics in other data types.\n\n---\n\n### Question 1\nCan you please elaborate on the 4 above-mentioned weaknesses?\n\n*Answer:* Please see the above answers.\n\n\n### Question 2\nRegarding experiments on toy datasets, is there any reason why temperature scaling is not shown?\n\n*Answer:* The purpose of the experiments with toy dataset is to demonstrate the ineffectiveness of calibrated confidence in self-training context. We conclude that a single calibration method suffices for the presentation, and we select histogram binning since it is simple and has a lower ECE (Expected Calibration Error) error than temperature scaling.\n\n\n### Question 3 \nIn almost all experiments there is a significant difference between the two proposed ways of estimating the density (CAST-D and CAST-L). Can you please discuss about this aspect? Is this issue related to an improper hyperparameter tuning?\n\n*Answer:* The observed difference stems from distinct implementations. For example, CAST-D uses the Aitchison-Aitken kernel for categorical features, while CAST-L uses the likelihood of each distinct value from their empirical distribution. This is not related to improper hyperparameter tuning, as we conducted an exhaustive grid search for optimal alpha selection.\n\n\n### Question 4\nIn Figure 5, can you please explain why the performance decrease with a larger amount of labeled examples, as this seems a counterintuitive result?\n\n*Answer:* The observed performance decrease with a larger amount of labeled examples aligns with findings from several studies [3,4,5]. It illustrates that semi-supervised learning improvements often inversely correlate with labeled sample proportions, which is a commonly observed phenomenon. Therefore, it is not counterintuitive result of our work.\n\n\n[1] Amini, Massih-Reza, and Patrick Gallinari. \"Semi-supervised logistic regression.\" ECAI. Vol. 2. No. 4. 2002.\n\n[2] Berthelot, David, et al. \"Mixmatch: A holistic approach to semi-supervised learning.\" Advances in neural information processing systems 32 (2019).\n\n[3] Rizve, Mamshad Nayeem, et al. \"In defense of pseudo-labeling: An uncertainty-aware pseudo-label selection framework for semi-supervised learning.\" arXiv preprint arXiv:2101.06329 (2021).\n\n[4] Yang, Lihe, et al. \"St++: Make self-training work better for semi-supervised semantic segmentation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.\n\n[5] Xu, Ran, et al. \"Neighborhood-regularized self-training for learning with few labels.\" arXiv preprint arXiv:2301.03726 (2023).\n\n---\n\nWe hope these comprehensive responses address your concerns and provide a clearer understanding of our research. We sincerely appreciate your guidance and are open to further feedback."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2320/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700161679197,
                "cdate": 1700161679197,
                "tmdate": 1700161679197,
                "mdate": 1700161679197,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SBzICFl0rC",
                "forum": "NDfxOMJqgL",
                "replyto": "C2UdFO7sZH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2320/Reviewer_QLpL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2320/Reviewer_QLpL"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for Answer, Major Concerns are Still Not Addressed"
                    },
                    "comment": {
                        "value": "Dear Authors,\n\nfirst of all, thank you for the answers and the clarifications.\nAfter going through the rebuttal, I feel there are still unaddressed concerns. Please find below additional questions (also considering the new experiments):\n- (**Experiment/Stability/Significance**) Why in Table 11 on the sick dataset does CAST completely fail? This makes me wonder about the stability of the results. Could you please estimate the variance of the results and provide the confidence intervals for at least the tables in the main paper?\n- (**Experiment/Time comparison**) Regarding time, can you please show how does the approach scale in time over dimensions (also on the higher dimensional dataset bioresponse)? Moreover, the comparison should be conducted with the other baselines you have considered in Table 1. I can imagine that temperature scaling has a bigger advantage in terms of computation over the proposed solution. Then, what it the real advantage of the proposed solution in practice?\n- (**Scope/Significance**) Can you please elaborate more on the weakness 4, as I don\u2019t understand what you mean by \u201cinapplicability to domains such as images or text as there are no suitable density estimation methods\u201d. As far as I know, there are ways to learn the density on both images and text, what about the area of generative models? Also, if the claim about the limited applicability of the approach is true, the results would have little scope and marginal significance.\n- (**Experiments/Quality**) While I appreciate the discussion about entropy minimisation in semi-supervised learning. I don't see why an experimental comparison is ruled out by that. Are there no semi-supervised approaches for tabular data?"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2320/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700392591586,
                "cdate": 1700392591586,
                "tmdate": 1700392591586,
                "mdate": 1700392591586,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "6JWNLSb3XK",
            "forum": "NDfxOMJqgL",
            "replyto": "NDfxOMJqgL",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2320/Reviewer_QRTY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2320/Reviewer_QRTY"
            ],
            "content": {
                "summary": {
                    "value": "In the paper \"CAST: Cluster-Aware Self-Training for Tabular Data\" the authors propose an approach to self-training for tabular data. The basic idea of the approach is to take into account how densely populated the dataset is around candidate data points for generating pseudo labels. More specifically, the density is used for regularizing class confidences discounting confidences in less densely populated realms of the space."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed method is relatively simple and thus relatively easy to implement.\n- The related work is nicely surveyed."
                },
                "weaknesses": {
                    "value": "- The paper is not self-contained, i.e., there are gaps in the proposed methodology. For example, in Eq. 2 the authors state that prior knowledge is encoded in terms of a vector $\\gamma$ and $\\gamma$ is assigned the output of some function TD(). However, the function is not clearly described. Only \"prior knowledge which is derived from the labeled training data distribution TD\"  is mentioned in the text. Probably TD is on purpose quite vague. However, there is not even a single mention of what this could be. It is also confusing that it seems to be the labeled training data distribution, however, this distribution should at maximum be implicitly given by the data sample.\n- In Algorithm 1 the $\\gamma$ does not even occur. I assume it is somewhere hidden in the $\\Phi$ which supposedly does the pseudo-labeling. However, $\\Phi$ is nowhere given concretely. Not even in the appendix -- at least I could not find it there. Still, in the text, the authors write that Algorithm 1 is the complete algorithm but only a very basic self-training framework is given there -- nothing special about CAST as a standalone method. Also, the loop is terminating with respect to some unknown termination condition of $\\Phi$ which is neither elaborated.\n- While the experimental evaluation section covers most of the section, taking different perspectives and viewing angles, the breadth of the study is quite limited. In the main paper, the study comprises 4 real-world datasets with an additional 16 datasets in the appendix for a limited set of methods. Considering that there is no theoretical support for the claims, the underpinning of the claims made in the paper is quite weak. \n- Speaking about the empirical evaluation: While relative improvements over a baseline might be the primary goal, with which I agree, it is relatively hard to interpret the significance of the results. In particular, it impedes the application of a statistical test whether the results are significant. From the results, the differences are probably significant but still it is very hard to interpret and I would prefer plain results even though metrics might differ."
                },
                "questions": {
                    "value": "- How is $\\gamma$ computed? What are the requirements or desiderata for computing $\\gamma$ to yield a sound approach?\n- What is the termination criterion in relation to $\\Phi$?\n- How is the pseudo-labeling $\\Phi$ done?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2320/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698678421828,
            "cdate": 1698678421828,
            "tmdate": 1699636164344,
            "mdate": 1699636164344,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dtOxj6w3GX",
                "forum": "NDfxOMJqgL",
                "replyto": "6JWNLSb3XK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2320/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2320/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your thoughtful and detailed feedback on our manuscript. Your comments have been invaluable in improving the clarity and depth of our work.\n\n---\n\n### Weakness 1\nThe paper is not self-contained, i.e., there are gaps in the proposed methodology. For example, in Eq. 2 the authors state that prior knowledge is encoded in terms of a vector $\\gamma$ and $\\gamma$ is assigned the output of some function TD(). However, the function is not clearly described. Only \"prior knowledge which is derived from the labeled training data distribution TD\" is mentioned in the text. Probably TD is on purpose quite vague. However, there is not even a single mention of what this could be. It is also confusing that it seems to be the labeled training data distribution, however, this distribution should at maximum be implicitly given by the data sample.\n\n*Answer:* We apologize for any confusion regarding the density estimation process in our methodology. We have revised the methods section to provide a clearer explanation as follows.\n\nWe get the estimated density for unlabeled samples by extracting the prior knowledge using a density estimator $\\textit{D}_{t}$ (e.g. multivariate kernel density estimator or empirical likelihood) which is fitted to the labeled training data distribution.\nHere, the prior knowledge $\\boldsymbol{\\gamma}$ for each class is defined as follows:\n\n$$\n\\boldsymbol{\\gamma}^{(i)} \\leftarrow \\textit{D}_{t}(\\boldsymbol{x}^{(i)}), \\quad \\text{where} \\quad \\boldsymbol{\\gamma}^{(i)} = \\text{[}{\\gamma}_1, \\gamma_2, ... , \\gamma_N\\text{]}\n$$\n\nThen, we normalize $\\boldsymbol{\\gamma}$ using a min-max scaler because the scale of $\\boldsymbol{\\gamma}$ varies among implementations, and we need a relative measure to align unlabeled samples.\n\nAnd we leave the specific choice of density estimator for CAST to implementation as we believe open to extension is a crucial component for the versatility. For example, CAST which uses dataset-specific density estimator might be surpass CAST-D or CAST-L on the specific dataset. Our implementation of CAST-D and CAST-L are shown in Appendix D.\n\nThe reason for using the labeled training data distribution in CAST is to enable the regularization of confidence for each class. This is achieved by utilizing class-specific estimated density, which is derived from the labeled data distribution.\n\n\n\n### Weakness 2\nIn Algorithm 1 the $\\gamma$ does not even occur. I assume it is somewhere hidden in the $\\Phi$ which supposedly does the pseudo-labeling. However, $\\Phi$ is nowhere given concretely. Not even in the appendix -- at least I could not find it there. Still, in the text, the authors write that Algorithm 1 is the complete algorithm but only a very basic self-training framework is given there -- nothing special about CAST as a standalone method. Also, the loop is terminating with respect to some unknown termination condition of $\\Phi$ which is neither elaborated.\n\n*Answer:* We appreciate your feedback on the lack of clarity regarding $\\Phi$ in Algorithm 1. $\\Phi$ is the pseudo-labeling algorithm that adopts equation (4), and its specific implementation can vary. CAST is designed to the following question that we raised in the Introduction section: \u2018Can we improve self-training for tabular data by making confidence more reliable, without altering the self-training algorithm or model architecture?\u2019. In essence, CAST is an enhanced self-training algorithm which regularizes the confidence of the classifier to be aware of the cluster assumption without altering the self-training algorithm. Therefore, we present the conventional self-training algorithm which adopts regularized confidence for pseudo-labeling as pseudo-code of CAST. And we did not specify a particular $\\Phi$ within the pseudo-code, as CAST is designed to be compatible with any self-training algorithm, irrespective of the pseudo-labeler employed. Lastly, the termination condition for $\\Phi$ is implementation-specific and hence was not explicitly defined."
                    },
                    "title": {
                        "value": "Official Comment by Authors (1)"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2320/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700159556963,
                "cdate": 1700159556963,
                "tmdate": 1700159733307,
                "mdate": 1700159733307,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ItyMpO3wHL",
                "forum": "NDfxOMJqgL",
                "replyto": "6JWNLSb3XK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2320/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2320/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "### Weakness 3\nWhile the experimental evaluation section covers most of the section, taking different perspectives and viewing angles, the breadth of the study is quite limited. In the main paper, the study comprises 4 real-world datasets with an additional 16 datasets in the appendix for a limited set of methods. Considering that there is no theoretical support for the claims, the underpinning of the claims made in the paper is quite weak.\n\n*Answer:* We appreciate your insight into the need for a more details are needed to underpin our claims. To address this, we've included the following explanations in Appendix C. \n\nSelf-training is a version of the entropy minimization algorithm, which minimizes the likelihood deprived of the entropy of the partition [1]. It constructs hard (one-hot) labels from high-confidence predictions on unlabeled data to implicitly achieve entropy minimization [2]. The entropy minimization techniques assume that the cluster assumption is ensured in the dataset [3], and aim that the classifier learns the low-density separations in the data. However, unreliable pseudo-labels that lie in low-density regions, stemming from erroneous confidence, violate the assumption and consequently disrupt the classifier's ability to learn the separations among classes. On the other hand, CAST forces the pseudo-labels in low-density regions to have lower confidence to avoid the violation of the assumption. Therefore, CAST achieves more reliable pseudo-labels resulting in successful entropy minimization.\n\n\n### Weakness 4\nSpeaking about the empirical evaluation: While relative improvements over a baseline might be the primary goal, with which I agree, it is relatively hard to interpret the significance of the results. In particular, it impedes the application of a statistical test whether the results are significant. From the results, the differences are probably significant but still it is very hard to interpret and I would prefer plain results even though metrics might differ.\n\n*Answer:* We understand the difficulty in interpreting relative improvements and have now included absolute performance in Table 1 and Table 11 in Appendix J. Additionally, we applied statistical tests to show that the performance improvements of CAST are not coincidence, whereas the calibrated confidence based self-trainings are. Concretely, there are some experiments that calibrated confidence based self-training outperform naive confidence based self-training, but statistical test verifies that calibrating the confidence is meaningless in the context of self-training."
                    },
                    "title": {
                        "value": "Official Comment by Authors (2)"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2320/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700159654466,
                "cdate": 1700159654466,
                "tmdate": 1700159722269,
                "mdate": 1700159722269,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "30GKVwHA52",
                "forum": "NDfxOMJqgL",
                "replyto": "6JWNLSb3XK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2320/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2320/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors (3)"
                    },
                    "comment": {
                        "value": "### Question 1\nHow is $\\gamma$ computed? What are the requirements or desiderata for computing $\\gamma$ to yield a sound approach?\n\n*Answer:* We get $\\gamma$ using a density estimator $\\textit{D}_{t}$ which is fitted to the labeled training data distribution. The natural characteristic of the tabular data is each feature occupies a specific, fixed position within the table. This allows us directly to extract prior knowledge from the labeled training dataset unlike other domains (e.g., image or text) where do not have such rules. There are various successful approaches regarding density estimation for tabular data [4,5]. We extract prior knowledge using multivariate kernel density estimator and empirical likelihood.\n\n### Question 2\nWhat is the termination criterion in relation to $\\Phi$?\n\n*Answer:* The termination criterion depends on the implementation of $\\Phi$. For example, if the $\\Phi$ is fixed-threshold pseudo-labeling, the termination condition is when no performance gain is achieved. On the other hand, if the $\\Phi$ is curriculum pseudo-labeling, it is when there are no unlabeled data left to label.\n \n### Question 3\nHow is the pseudo-labeling $\\Phi$ done?\n\n*Answer:* The pseudo-labeler $\\Phi$ can be any algorithm suitable for pseudo-labeling, such as fixed-threshold pseudo-labeling or curriculum pseudo-labeling as we designed CAST to maintain versatility. It depends on the implementation of the user. For example, within fixed-threshold pseudo-labeling strategies, pseudo-labels are designated once their confidences meet or exceed a certain threshold. Meanwhile, curriculum pseudo-labeling strategies generate pseudo-labels based on a threshold but operate under the premise that samples with higher confidence are easier for the classifier to handle.\n\n\n[1] Amini, Massih-Reza, and Patrick Gallinari. \"Semi-supervised logistic regression.\" ECAI. Vol. 2. No. 4. 2002.\n\n[2] Berthelot, David, et al. \"Mixmatch: A holistic approach to semi-supervised learning.\" Advances in neural information processing systems 32 (2019).\n\n[3] Grandvalet, Yves, and Yoshua Bengio. \"Semi-supervised learning by entropy minimization.\" Advances in neural information processing systems 17 (2004).\n\n[4] Devroye, Luc. A course in density estimation. Birkhauser Boston Inc., 1987.\n\n[5] Silverman, Bernard W. Density estimation for statistics and data analysis. Routledge, 2018.\n\n\n---\n\nWe hope these revisions provide clarity and address your concerns. We are grateful for your guidance and remain open to any further feedback."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2320/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700159927889,
                "cdate": 1700159927889,
                "tmdate": 1700159927889,
                "mdate": 1700159927889,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "NgKtRdiP4a",
            "forum": "NDfxOMJqgL",
            "replyto": "NDfxOMJqgL",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2320/Reviewer_DTs7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2320/Reviewer_DTs7"
            ],
            "content": {
                "summary": {
                    "value": "This paper aims to use self-training to handle the tabular data learning without altering the self-training algorithm or model architecture."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This paper delves into the confidences of pseudo-labels in self-training from the perspective of cluster assumption, providing a new view for the field of self-training. In addition, the proposed CAST is easy to follow."
                },
                "weaknesses": {
                    "value": "- From the Introduction, I cannot get the significant relationship between tabular data and the proposed self-training method. The motivation and organization of this paper should be further clarified.\n- In addition, the difficulties brought by tabular data over the general unstructured data (e.g., images, texts) in machine learning have not been discussed. In detail, they only stated that the GBDT is suitable for tabular data, while they do not explain why other methods are not suitable.\n- In my view, CAST is not a tabular data-specific method. Its idea is to adjust the prediction confidence based on the cluster assumption, which is also available for other data types. I think that this discussion should be included and the corresponding experiments are needed."
                },
                "questions": {
                    "value": "Please refer to Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2320/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2320/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2320/Reviewer_DTs7"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2320/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698742755789,
            "cdate": 1698742755789,
            "tmdate": 1700726953767,
            "mdate": 1700726953767,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Idg2Jnj7kI",
                "forum": "NDfxOMJqgL",
                "replyto": "NgKtRdiP4a",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2320/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2320/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your valuable feedback on our manuscript. We have carefully considered your comments and have revised our manuscript accordingly to address the concerns raised.\n\n---\n\n### Weakness 1 and 2\nFrom the Introduction, I cannot get the significant relationship between tabular data and the proposed self-training method. The motivation and organization of this paper should be further clarified. In addition, the difficulties brought by tabular data over the general unstructured data (e.g., images, texts) in machine learning have not been discussed. In detail, they only stated that the GBDT is suitable for tabular data, while they do not explain why other methods are not suitable.\n\n*Answer:* We acknowledge the need for a clearer exposition of the relationship between tabular data and our proposed self-training method. To address this, we clarify why we study the primary question, \u2018Can we improve self-training for tabular data by making confidence more reliable, without altering the self-training algorithm or model architecture?\u2019, in this paper for tabular data, specifically in the second paragraph of the Introduction as follows:\n\nVarious studies have proposed solutions to counteract the noise in pseudo-labels induced by erroneous confidence, but they have diminished the simplicity and versatility of self-training. Concretely, they often necessitate modifications to self-training algorithms or alterations in the model architectures (Li & Zhou, 2005; Tanha et al., 2017; Rizve et al., 2021; Seibold et al., 2022). Furthermore, most of them are not applicable to gradient boosting decision trees (GBDT) as they are designed for neural networks. These limitations pose a substantial impediment to practitioners who want to apply reliable self-training on the tabular data where GBDTs have been the dominant architectures (Kaggle, 2021; Borisov et al., 2022; Shwartz-Ziv & Armon, 2022). Therefore, we conclude that any enhanced self-training for the tabular domain must maintain simplicity and versatility. Consequently, we study a natural but ignored question: *Can we improve self-training for tabular data by making confidence more reliable, without altering the self-training algorithm or model architecture?*\n\n\n### Weakness 3\nIn my view, CAST is not a tabular data-specific method. Its idea is to adjust the prediction confidence based on the cluster assumption, which is also available for other data types. I think that this discussion should be included, and the corresponding experiments are needed.\n\n*Answer:* We agree with your observation that the core idea of CAST, which involves adjusting the prediction confidence based on the cluster assumption, could extend to data types beyond tabular data. However, as we now note in our conclusion, the current implementation of CAST is limited by the absence of suitable density estimation methods for non-tabular data types, such as images or text. The structured nature of tabular data allows for clear density estimation from labeled training datasets as tabular data ensures that each feature occupies a specific, fixed position within the table. But there are no such characteristics in other data types. This limitation is now explicitly acknowledged in our manuscript.\n\n---\n\nWe hope these revisions and clarifications address your concerns and enhance the understanding of our research's contributions and limitations. We are grateful for the opportunity to improve our work and welcome any further suggestions you may have."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2320/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700159125493,
                "cdate": 1700159125493,
                "tmdate": 1700159687841,
                "mdate": 1700159687841,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dIFGCDkQHW",
                "forum": "NDfxOMJqgL",
                "replyto": "Idg2Jnj7kI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2320/Reviewer_DTs7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2320/Reviewer_DTs7"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your detailed rebuttal. I have gone through your feedbacks and other reviewers' comments. I think I indeed misunderstand your method. I am willing to raise my score to 5 and discuss with other reviewers for further decision."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2320/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700726945420,
                "cdate": 1700726945420,
                "tmdate": 1700726945420,
                "mdate": 1700726945420,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5GhZPR6wQ7",
            "forum": "NDfxOMJqgL",
            "replyto": "NDfxOMJqgL",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2320/Reviewer_USSG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2320/Reviewer_USSG"
            ],
            "content": {
                "summary": {
                    "value": "This pager proposes a simple way to generate reliable pseudo-labels by assigning high confidence to pseudo-labels in high-density regions and low confidence to those in low-density regions. The proposed method could be plugged into current self-training algorithms and tabular models, and extensive experiments validate the effectiveness of this method. However, there lacks detailed analysis (empirical or theoretical) or insights on why it works, and the reliable pseudo-labels are not adequately verified in real scenarios."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This work proposes a simple but effective way to generate reliable pseudo-labels, which multiples the original pseudo labels with a density score. The method is simple and could be incorporated with various existing algorithms, and extensive experiments validate the effectiveness of it."
                },
                "weaknesses": {
                    "value": "After reading this paper carefully, I have some concerns:\n1. There lacks detailed analysis on why this method works. And I wonder whether it has some relationship with label smoothing techniques. And I would recommend the authors to give more in-depth analysis, either empirical or theoretical. Also, the 'cluster assumption' or the reliable pseudo-labels should be checked or verified in real datasets. For example, why they are reliable and can we explain it?\n2. I believe there are many many semi-supervised learning methods, but there are only 5 baselines, which I think is not enough and representative for SSL. \n3. Some of the datasets are not open-sources, e.g., 6M mortality."
                },
                "questions": {
                    "value": "Please refer to Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2320/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698870095819,
            "cdate": 1698870095819,
            "tmdate": 1699636164179,
            "mdate": 1699636164179,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "L1MaYSu9mX",
                "forum": "NDfxOMJqgL",
                "replyto": "5GhZPR6wQ7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2320/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2320/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the time and effort you have invested in reviewing our manuscript. We greatly appreciate your insightful comments and suggestions, which have provided us with valuable perspectives on our work.\n\n---\n\n### Weakness 1 \nThere lacks detailed analysis on why this method works. And I wonder whether it has some relationship with label smoothing techniques. And I would recommend the authors to give more in-depth analysis, either empirical or theoretical. Also, the 'cluster assumption' or the reliable pseudo-labels should be checked or verified in real datasets. For example, why they are reliable and can we explain it?\n\n*Answer:* We appreciate your insight on the need for a more comprehensive analysis of CAST's efficacy. To address this, we've included the following explanations in Appendix C. \n\nSelf-training is a version of the entropy minimization algorithm, which minimizes the likelihood deprived of the entropy of the partition [1]. It constructs hard (one-hot) labels from high-confidence predictions on unlabeled data to implicitly achieve entropy minimization [2]. The entropy minimization techniques assume that the cluster assumption is ensured in the dataset [3], and aim that the classifier learns the low-density separations in the data. However, unreliable pseudo-labels that lie in low-density regions, stemming from erroneous confidence, violate the assumption and consequently disrupt the classifier's ability to learn the separations among classes. On the other hand, CAST forces the pseudo-labels in low-density regions to have lower confidence to avoid the violation of the assumption. Therefore, CAST achieves more reliable pseudo-labels resulting in successful entropy minimization.\n\nAnd Label smoothing employs soft labels rather than hard labels, such as one-hot encoded vectors, with the aim of preventing the model from becoming overly confident in its predictions. In contrast, CAST specifically aims to reduce the confidence of pseudo-labels in low-density regions, ensuring that unreliable pseudo-labels are not generated. The labels used in CAST remain hard labels. \n\nLastly, we demonstrate that pseudo-labels in high-density regions are more accurate than those in low-density regions in Figure 1 using 6-month mortality prediction post-acute myocardial infarction (6M mortality) dataset which is sourced from Korea Acute Myocardial Infarction Registry (KAMIR). The Figure 1 shows the heuristic evidence supporting for the cluster assumption.\n\n\n### Weakness 2\n I believe there are many many semi-supervised learning methods, but there are only 5 baselines, which I think is not enough and representative for SSL.\n\n*Answer:* We acknowledge the extensive variety of semi-supervised learning (SSL) methods available such as VIME [4]. However, most of the people have used GBDTs for tabular data which are not compatible with most of SSL approaches. Therefore, we focus on self-training which is universal applicable approach and study \u2018Can we improve self-training for tabular data by making confidence more reliable, without altering the self-training algorithm or model architecture?\u2019. Hence, our research intentionally does not compare CAST with other SSL techniques because our objective is not to challenge the efficacy of these techniques per se, but to demonstrate that self-training can indeed be improved through refined confidence without modifying the self-training algorithms or model architectures.\n\n\n### Weakness 3\nSome of the datasets are not open-sources, e.g., 6M mortality.\n\n*Answer:* We understand the concern regarding the use of the non-open source 6M mortality dataset. To balance this, we incorporated 19 open-source datasets from OpenML-CC18, providing a broad and diverse evaluation of CAST. These datasets, coupled with the 6M mortality dataset, offer a robust assessment of CAST\u2019s performance and versatility. The consistent results across these varied datasets confirm CAST's effectiveness and its applicability to a wide range of scenarios.\n\n\n[1] Amini, Massih-Reza, and Patrick Gallinari. \"Semi-supervised logistic regression.\" ECAI. Vol. 2. No. 4. 2002.\n\n[2] Berthelot, David, et al. \"Mixmatch: A holistic approach to semi-supervised learning.\" Advances in neural information processing systems 32 (2019).\n\n[3] Grandvalet, Yves, and Yoshua Bengio. \"Semi-supervised learning by entropy minimization.\" Advances in neural information processing systems 17 (2004).\n\n[4] Yoon, Jinsung, et al. \"Vime: Extending the success of self-and semi-supervised learning to tabular domain.\" Advances in Neural Information Processing Systems 33 (2020): 11033-11043.\n\n---\n\nWe hope that our responses adequately address your concerns and demonstrate the value and robustness of our work. We look forward to any further suggestions or comments you may have."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2320/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700158640512,
                "cdate": 1700158640512,
                "tmdate": 1700159952850,
                "mdate": 1700159952850,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GBnQFCXG1b",
                "forum": "NDfxOMJqgL",
                "replyto": "L1MaYSu9mX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2320/Reviewer_USSG"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2320/Reviewer_USSG"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "Thanks for your rebuttal. Some of my concerns are addressed, and I would like to keep my score."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2320/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700712464549,
                "cdate": 1700712464549,
                "tmdate": 1700712464549,
                "mdate": 1700712464549,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]