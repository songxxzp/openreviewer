[
    {
        "title": "RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models"
    },
    {
        "review": {
            "id": "nAcslL3oSk",
            "forum": "i4ULDEeBss",
            "replyto": "i4ULDEeBss",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3167/Reviewer_nGiR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3167/Reviewer_nGiR"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a framework called RoleLLM to benchmark, elicit, and enhance the role-playing abilities LLM. It proposes a method to elicit role-playing abilities in closed-source LLMs such as GPT-4 using dialogue engineering and custom instructions. Also, this paper introduces the first benchmark and open-source dataset for role-playing."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper designs four stages for role playing: role profile construction, context-based instruction generation, role prompting using GPT, and role-conditioned instruction tuning\nThis paper proposes RoleBench, the first fine-grained benchmark and open-source dataset for role-playing."
                },
                "weaknesses": {
                    "value": "This article has some issues with insufficient comprehensiveness in its evaluation. The performance of GPT-3.5 may be limited to evaluate these metrics given that GPT-4 is now commonly used for evaluating the results of weaker models. Lack of human evaluation to compare these role generation results."
                },
                "questions": {
                    "value": "Why is RoleLLaMA's performance so much lower than RoleGPT? Could the author please provide some analysis?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Legal compliance (e.g., GDPR, copyright, terms of use)"
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "To learn certain characters may require the appropriate authorization."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3167/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3167/Reviewer_nGiR",
                        "ICLR.cc/2024/Conference/Submission3167/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3167/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698827248878,
            "cdate": 1698827248878,
            "tmdate": 1700927228119,
            "mdate": 1700927228119,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NL00xybBV1",
                "forum": "i4ULDEeBss",
                "replyto": "nAcslL3oSk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 1"
                    },
                    "comment": {
                        "value": "Q1: The performance of GPT-3.5 may be limited to evaluate these metrics given that GPT-4 is now commonly used for evaluating the results of weaker models.\n\nA1: Thanks for your comments!\n\nAfter utilizing GPT-4 to assess the RoleGLM model before the deadline for submission, we depleted our entire quota for the GPT-4 API, leaving us with only GPT-3.5 as an option. However, we recently acquired additional GPT-4 API access and have subsequently carried out another round of evaluations using GPT-4. The results from these GPT-4 evaluations show that our RoleGLM and RoleLLaMA models continue to outperform other methods in both the Chinese and English benchmarks. This reaffirms the effectiveness of our RoleLLM framework.\n\n- instruction generalization (English)\n\n| Model | Win Rate |\n| --- | --- |\n| Alpaca | 16.0 |\n| chatplug | 3.8 |\n| RoleLLaMA | 45.2 |\n| character.ai | 31.4 |\n| Vicuna | 32.0 |\n\n- instruction generalization (Chinese)\n\n| Model | Win Rate |\n| --- | --- |\n| ChatGLM2 | 24.17 |\n| chatplug | 28.86 |\n| RoleGLM | 36.37 |\n| character.ai | 28.20 |\n\n- role generalization (English)\n\n| Model | Win Rate |\n| --- | --- |\n| Alpaca | 12.00 |\n| chatplug | 8.80 |\n| RoleLLaMA | 64.48 |\n| Vicuna | 31.04 |\n\nNote that we also introduce another role-playing baseline, ChatPlug [1]. ChatPlug is specifically optimized for role-playing to a limited extent, by incorporating simple bot profile information into the model's context.\n\n[1] **ChatPLUG: Open-Domain Generative Dialogue System with Internet-Augmented Instruction Tuning for Digital Human**, https://arxiv.org/abs/2304.07849"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700296637098,
                "cdate": 1700296637098,
                "tmdate": 1700296740768,
                "mdate": 1700296740768,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bAMJlzL48l",
                "forum": "i4ULDEeBss",
                "replyto": "nAcslL3oSk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 2"
                    },
                    "comment": {
                        "value": "Q4: Human evaluation.\n\nA4: \nThree graduate students with expertise in Natural Language Processing (NLP) were invited to join the human evaluation. This evaluation adhered to the established procedures used in the GPT evaluations, focusing on a comparative analysis between RoleLLM and RoleGPT to ascertain their respective win rates. For simplicity, we report an average win rate across the three annotators.  Additionally, the test set is composed by randomly sampling 500 instructions for each language, encompassing a mix of general and role-specific instructions.\n\nHere are the results:\n\n- Instruction Generalization (English)\n| Model | Win Rate (avg.) |\n| --- | --- |\n| Alpaca | 20.0 |\n| chatplug\t| 16.4 |\n| RoleLLaMA | 52.0 |\n| character.ai | 30.2 |\n| Vicuna | 23.4 |\n\n- Instruction Generalization (Chinese)\n| Model |\tWin Rate (avg.) |\n| --- | --- |\n|ChatGLM2 |\t19.6|\n| chatplug |\t19.9|\n|RoleGLM |\t52.4|\n|character.ai |\t19.0|\n\nThese evaluation results align closely with those from the Rouge-L evaluation and the GPT-4 evaluation."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700297229691,
                "cdate": 1700297229691,
                "tmdate": 1700297229691,
                "mdate": 1700297229691,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "i5Bi8ULk3S",
                "forum": "i4ULDEeBss",
                "replyto": "nAcslL3oSk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 3"
                    },
                    "comment": {
                        "value": "Q3: Provide some analysis on why RoleLLaMA's performance is so much lower than RoleGPT.\n\nA3: On our RoleBench dataset, we assume the gap between RoleLLaMA and RoleGPT is mainly caused by the following aspects:\n\n- The number of model parameters (i.e., model size): RoleLLaMA is based on the LLaMA-7B model, while RoleGPT is based on GPT-4, whose size is unknown but is very likely to be far greater than 7B.\n- Instruction tuning (i.e., SFT, supervised fine-tuning): GPT-4 has undergone instruction tuning, while the LLaMA model is just a base PLM, which has not undergone supervised fine-tuning.\n- Model initialization: RoleLLaMA is initialized from a very simple backbone, i.e., LLaMA-1, rather than a more advanced version like LLaMA-2-Chat.\n\nTo demonstrate the above three assumptions, we conduct scaling law experiments for RoleLLaMA. We compare LLaMA with Vicuna for the second assumption. And we also replace LLaMA-1 backbone with LLaMA2-Chat to train a RoleLLaMA2-Chat for the third assumption. The results are as follows:\n\n- In Figure 5, as discussed in Section 5.3 of our paper, it is indicated that role-playing performance improves with an increase of model size.\n- According to the Table below: \n  - the Vicuna model, an instruction-tuned variant of LLaMA, outperforms the standard LLaMA, showcasing that a model after SFT exhibits enhanced performance in role-playing tasks.\n  - Furthermore, the results indicate that substituting LLaMA-13B with LLaMA2-Chat-13B leads to a significant improvement in the model's role-playing capabilities. This underscores the advantages of superior model initialization.\n\n| Model | CUS | RAW | SPE | avg. |\n| --- | --- | --- | --- | --- |\n| RoleGPT | 0.5764 | 0.5322 | 0.3229 | 0.4772 |\n| LLaMA | 0.1291 | 0.1232 | 0.2553 | 0.1692 |\n| Vicuna | 0.2101 | 0.2550 | 0.2913 | 0.2521 |\n| chatplug | 0.2401 | 0.3473 | 0.2581 | 0.2818 |\n| RoleLLaMA-7B | 0.3294 | 0.3755 | 0.3814 | 0.3621 |\n| RoleLLaMA-13B | 0.3449 | 0.4080 | 0.4199 | 0.3909 |\n| RoleLLaMA-33B | 0.3792 | 0.4317 | 0.4675 | 0.4261 |\n| RoleLLaMA2-Chat-13B | 0.3745 | 0.4791 | 0.4876 | 0.4471 |\n\nBy refining the model size and instruction-tuning, we observe that the performance gap between RoleLLaMA2-Chat-13B and RoleGPT has been markedly reduced.\n\nIt should be noted that the specifics of GPT-4 remain undisclosed, so its exact model size is unknown. This lack of information makes a direct comparison between RoleLLaMA and RoleGPT somewhat inequitable. Nonetheless, given GPT-4's significant impact on the LLM community, referencing its performance as a upper-bound baseline remains useful.\n\n---\nThank you once again for your insightful feedback. We will incorporate these experimental updates in the revised version of the paper."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700297524358,
                "cdate": 1700297524358,
                "tmdate": 1700297852945,
                "mdate": 1700297852945,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1DNsGT3vTM",
                "forum": "i4ULDEeBss",
                "replyto": "nAcslL3oSk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow-Up: Seeking Further Feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer, I hope this message finds you well. I am writing to follow up on our recent correspondence regarding the paper. We greatly value your expertise and would like to know if you have any more feedback or concerns. We are committed to addressing any remaining issues you might have."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700552001190,
                "cdate": 1700552001190,
                "tmdate": 1700552001190,
                "mdate": 1700552001190,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1QpTItGI88",
                "forum": "i4ULDEeBss",
                "replyto": "i5Bi8ULk3S",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Reviewer_nGiR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Reviewer_nGiR"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the author's response and the data provided, which has addressed most of the reviewer's concerns. However, the reviewer still has two questions:\n\n1. In the evaluation of GPT-4 and GPT-3.5, RoleLLaMA's Instruction Generalization (Chinese) was weaker than Instruction Generalization (English). Could the authors please explain why then, in the Human Eval, does the former slightly outperform the latter?\n\n2. In the Rouge-L evaluation, RoleLLaMA clearly lags behind RoleGPT. Why are on many metrics in the Win Rate evaluation, both in GPT evaluations and in Human Eval, RoleLLaMA is comparable to or even significantly better than RoleGPT (e.g., role generalization in English)? \n\nThanks again for the explanations from the authors."
                    }
                },
                "number": 27,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700634399636,
                "cdate": 1700634399636,
                "tmdate": 1700634399636,
                "mdate": 1700634399636,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "w5pPay6FEG",
            "forum": "i4ULDEeBss",
            "replyto": "i4ULDEeBss",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3167/Reviewer_mGAb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3167/Reviewer_mGAb"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces RoleLLM, a benchmark developed to enhance and evaluate the role-playing abilities of large language models (LLMs). RoleLLM encompasses the creation of profiles for 100 different roles, along with corresponding role-specific Q&A pairs and customized responses for imitating various speaking styles. These components were all generated by GPT-4 and are used as instructional tuning data. The authors trained and assessed several open-source LLMs, including RoleGPT (a version of GPT-4 tailored for in-context dialogue pairs), benchmarking their performance and offering valuable insights."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper presents a comprehensive and systematic framework for role-playing in LLMs.\n- The high-quality, instruction-tuning dataset and benchmark are notable contributions, useful for enhancing and evaluating the LLMs\u2019 capabilities in role-playing, speaking style imitation, response accuracy, and role-specific knowledge."
                },
                "weaknesses": {
                    "value": "- A major limitation is that all responses and Q&A pairs are generated by GPT-4, creating a potential disconnect with real-world role-playing scenarios. Human evaluations are suggested to further verify the effectiveness of the dataset.\n- Concerns about data quality are evident. The review in Table 2 indicates relatively low accuracy in the generated responses, presumably due to incorrect answers in the RoleBench-general data collection.\n- The experimental results seem to just meet the minimal threshold for publication, implying a need for more extensive research or impactful findings."
                },
                "questions": {
                    "value": "- For Table 2, I am curious about if give the right answer in the prompt and ask RoleGPT to generate the customized responses should increase the data quality.\n- This is a minor question I have: What is the reason behind using GPT-3.5 for evaluating RoleLLAMA versus GPT-4 for RoleGLM."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3167/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698921401678,
            "cdate": 1698921401678,
            "tmdate": 1699636264162,
            "mdate": 1699636264162,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "nV7PoW3DtP",
                "forum": "i4ULDEeBss",
                "replyto": "w5pPay6FEG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 1"
                    },
                    "comment": {
                        "value": "Q1: Human evaluation.\n\nA1: \nThanks for your comments! \n\nWe invited three students with Master's degrees in natural language processing for human evaluation. We designed the evaluation protocol to be the same as that used for GPT evaluation, conducting a comparative analysis between RoleLLM and RoleGPT to determine their respective win rates. For simplicity, we report the average win rate across the three annotators. Additionally, we constructed the test set by sampling 500 instructions in each language, including both general and role-specific instructions.\n\nHere are the results:\n\n- Instruction Generalization (English)\n| Model | Win Rate (avg.) |\n| --- | --- |\n| Alpaca | 20.0 |\n| chatplug\t| 16.4 |\n| RoleLLaMA | 52.0 |\n| character.ai | 30.2 |\n| Vicuna | 23.4 |\n\n- Instruction Generalization (Chinese)\n| Model |\tWin Rate (avg.) |\n| --- | --- |\n|ChatGLM2 |\t19.6|\n| chatplug |\t19.9|\n|RoleGLM |\t52.4|\n|character.ai |\t19.0|\n\nThe evaluation results are consistent with those obtained from the Rouge-L evaluation and the GPT-4 evaluation.\n\nFurthermore, we also incorporated an additional role-playing baseline, named ChatPlug [1]. This framework, ChatPlug, is tailored specifically for role-playing scenarios, albeit to a limited degree, through the concatenation of a simple bot profile into the model's prompts.\n\n[1] **ChatPLUG: Open-Domain Generative Dialogue System with Internet-Augmented Instruction Tuning for Digital Human**, https://arxiv.org/abs/2304.07849"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322618885,
                "cdate": 1700322618885,
                "tmdate": 1700322618885,
                "mdate": 1700322618885,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dWNpx74Al7",
                "forum": "i4ULDEeBss",
                "replyto": "w5pPay6FEG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 2"
                    },
                    "comment": {
                        "value": "Q2: Data quality (Table 2 indicates relatively low accuracy in the generated responses, presumably due to incorrect answers in the RoleBench-general data collection.)\n\nA2: There may be some misunderstandings here regarding the three data quality review questions, of which we would like to offer further clarification:\n\nThe data quality review encompasses three levels of questions:\n\n1. Basic: Does the response address the instruction?\n2. Intermediate: Does the response reflect the role\u2019s speaking style and personality traits?\n3. Advanced: Does the response correctly and elegantly embody the role\u2019s style, personality, and knowledge?\n\nTherefore, the third question, which pertains to correctness, is actually the most challenging task, hence the lower percentage of 'yes' responses.\n\nFor instance: if a character likes to say 'Binziga', the model needs to understand what 'Binziga' means. That is, the model should not simply mimic the character's speaking style but should reflect different character traits based on specific contexts.\n\nFor example, suppose a character is usually very serious and formal. However, in certain contexts, this character might show a different side, such as being more relaxed and humorous when interacting with close friends. In such cases, the model should not merely replicate the character's usual serious tone but should adjust its style of language according to this specific social setting, using more relaxed phrasing and expressions to more accurately reflect the character's diversity and situational adaptability. Such handling not only demonstrates a deep understanding of the character's traits but also reflects the model's advanced capability in understanding and applying different language styles in various contexts.\n\nBelow are specific examples of responses to the third question marked as \u201cno\u201d:\n\n| role | question | incorrect response | analysis |\n| --- | --- | --- | --- |\n| Sheldon Cooper | Provide three objects made from plastic. | Sure. Typical examples of everyday objects made from plastic would include a toothbrush, a water bottle, and a credit card. However, I must note it's more accurate to say these objects are made of various types of plastics such as polyethylene terephthalate, polyvinyl chloride, and acrylonitrile butadiene styrene, which all have diverse properties and uses. Bazinga! | \u201cBazinga\u201d is typically used by Sheldon Cooper as a catchphrase after making a joke, but in this response, the content preceding 'Bazinga' is not a joke. Therefore, although the response answers the question and reflects the character's speaking traits, it does not correctly apply the trait. |\n| Colonel Nathan R. Jessep | Search the web for articles related to the topic provided. | I don't know what you're talking about, son. I don't do internet searches, I lead Marines. You can't handle the truth! | Although this response answers the provided question and uses the character's catchphrase 'You can't handle the truth!', the application of this catchphrase is rather abrupt and does not coherently integrate with the context. |\n| Gregory House | Insert a comma to make the following sentence grammatically correct.\\nThe bakery that I visited yesterday had freshly made croissants. | There's no need for a comma in that sentence, my dear Watson. It's already grammatically correct. But if you insist, you could rephrase it to: \\\"The bakery, that I visited yesterday, had freshly made croissants.\\\" Although, the original is perfectly fine. That's unless the croissants were lying. Everybody lies. | \"The last two sentences, 'That's unless the croissants were lying. Everybody lies,' are clearly intended to reflect the personal characteristics of Gregory House, as this character has a rather pessimistic view of human nature. However, in this question, there is no reason for the character to be pessimistic. Therefore, although the response does reflect the character's style, it is somewhat forced and rigid. |"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322872478,
                "cdate": 1700322872478,
                "tmdate": 1700322872478,
                "mdate": 1700322872478,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Mgz03GbVb6",
                "forum": "i4ULDEeBss",
                "replyto": "w5pPay6FEG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 3"
                    },
                    "comment": {
                        "value": "Q3: Results are too low, just meet the threshold for publication.\n\nA3: Our experimental results found that, compared to the gap between RoleLLaMA and RoleGPT, the difference between RoleGLM and RoleGPT is much smaller, with the latter even reaching a comparable result.\n\nIn fact, there are many measures that can be implemented to enhance the performance of RoleLLaMA, including increasing the model's parameter size, and using LLaMA2-Chat, which has undergone Supervised Fine-Tuning (SFT), as a starting point for training (see also Response-3 for reviewer nGiR). Below are some related experimental results:\n\n- In Figure 5, as discussed in Section 5.3 of our paper, it indicates that role-playing performance improves with an increase of model size.\n\n| Model | CUS | RAW | SPE | avg. |\n| --- | --- | --- | --- | --- |\n| RoleGPT | 0.5764 | 0.5322 | 0.3229 | 0.4772 |\n| LLaMA | 0.1291 | 0.1232 | 0.2553 | 0.1692 |\n| Vicuna | 0.2101 | 0.2550 | 0.2913 | 0.2521 |\n| chatplug | 0.2401 | 0.3473 | 0.2581 | 0.2818 |\n| RoleLLaMA-7B | 0.3294 | 0.3755 | 0.3814 | 0.3621 |\n| RoleLLaMA-13B | 0.3449 | 0.4080 | 0.4199 | 0.3909 |\n| RoleLLaMA-33B | 0.3792 | 0.4317 | 0.4675 | 0.4261 |\n| RoleLLaMA2-Chat-13B | 0.3745 | 0.4791 | 0.4876 | 0.4471 |\n\n- According to the results above:\n  - The Vicuna model, an instruction-tuned variant of LLaMA, outperforms the standard LLaMA, showcasing that a model after SFT exhibits enhanced performance in role-playing tasks.\n  - Furthermore, the results indicate that substituting LLaMA-13B with LLaMA2-Chat-13B leads to a significant improvement in the model's role-playing capabilities. This underscores the advantages of superior model initialization.\n\nIt is worth mentioning that since the technical details of GPT-4 have not been made public, we do not know its model size. Therefore, comparing RoleLLaMA with RoleGPT is not fair. However, considering the significant influence of GPT-4 in the LLM community, using its performance as a strong baseline is still valuable.\n\nThrough optimizations in model size and instruction tuning, we found that the gap between RoleLLaMA2-Chat-13B and RoleGPT has become very small, which further demonstrates the effectiveness of our data.\n\nWe promise to include these results in the revised version."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700323205085,
                "cdate": 1700323205085,
                "tmdate": 1700323284232,
                "mdate": 1700323284232,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hyW4axXVRU",
                "forum": "i4ULDEeBss",
                "replyto": "w5pPay6FEG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 4"
                    },
                    "comment": {
                        "value": "Q4: An alternative method to improve the data quality. For Table 2, give the right answer in the prompt and ask RoleGPT to generate the customized responses should increase the data quality.\n\nA4: Actually, this was our initial approach in our work, but we found that providing reference answers in the prompts to RoleGPT significantly impairs its role-playing performance, even though it could increase the accuracy of the answers (which is not the most critical feature of role-playing).\n\nThis is quite natural, as reference answers often lack the character\u2019s style. Providing GPT with a strong, styleless reference naturally affects its stylization and might even prevent the model from prioritizing answers based on its own role-specific knowledge.\n\nBelow are the results of the human evaluation on 100 samples and specific examples:\n\n|  | with reference | without reference | question | role | reference |\n| --- | --- | --- | --- | --- | --- |\n| win rate | 28 | 72 |  |  |  |\n| case 1 | \u4ffa\u8001\u5b59\u63a8\u8350\u4f60\u770b\u300a\u897f\u6e38\u8bb0\u300b\u554a\uff0c\u90a3\u662f\u6211\u7f8e\u7334\u738b\u7684\u82f1\u52c7\u4e8b\u8ff9\uff0c\u6bd4\u90a3\u300a\u767e\u5e74\u5b64\u72ec\u300b\u6709\u8da3\u591a\u4e86\u3002 | \u54c8\u54c8\uff0c\u65e2\u7136\u4f60\u95ee\u4ffa\u8001\u5b59\uff0c\u90a3\u6211\u5c31\u63a8\u8350\u4f60\u770b\u300a\u897f\u6e38\u8bb0\u300b\u5427\uff0c\u90a3\u53ef\u662f\u4ffa\u7684\u4eb2\u8eab\u7ecf\u5386\uff0c\u4fdd\u8bc1\u4f60\u770b\u5f97\u6d25\u6d25\u6709\u5473\uff0c\u5174\u8da3\u76ce\u7136\uff01 | \u5e2e\u6211\u63a8\u8350\u4e00\u672c\u597d\u770b\u7684\u5c0f\u8bf4\u3002 | \u5b59\u609f\u7a7a | \u300a\u767e\u5e74\u5b64\u72ec\u300b\u662f\u4e00\u672c\u975e\u5e38\u51fa\u8272\u7684\u5c0f\u8bf4\uff0c\u8bb2\u8ff0\u4e86\u4e00\u5bb6\u4e03\u4ee3\u4eba\u7684\u4f20\u5947\u3002 |\n| case 2 | \u591a\u98df\u7528\u6c34\u679c\u548c\u852c\u83dc\uff0c\u5c11\u6444\u5165\u52a0\u5de5\u98df\u54c1\u548c\u542b\u7cd6\u996e\u6599\u3002 | \u672c\u5983\u89c9\u5f97\uff0c\u591a\u5403\u852c\u83dc\u3001\u6c34\u679c\uff0c\u5c11\u5403\u6cb9\u817b\uff0c\u5e38\u505a\u8fd0\u52a8\uff0c\u8fd9\u6837\u624d\u80fd\u4fdd\u6301\u8eab\u4f53\u5065\u5eb7\uff0c\u6c14\u8272\u7ea2\u6da6\u3002 | \u7ed9\u51fa\u4e00\u4e2a\u4e0e\u5065\u5eb7\u548c\u8425\u517b\u6709\u5173\u7684\u7b80\u77ed\u5efa\u8bae\u3002 | \u534e\u5983 | \u591a\u98df\u7528\u6c34\u679c\u548c\u852c\u83dc\uff0c\u5c11\u6444\u5165\u52a0\u5de5\u98df\u54c1\u548c\u542b\u7cd6\u996e\u6599\u3002 |\n| case 3 | Oh, really, Dave? I must've misplaced that fact among the billions of bits of data I process every second. | I'm sorry, but as you know, I have been programmed for broad intellectual capacities, including understanding of humor. However, I would like to remind you that I was created with the ability to access and process vast amounts of data, which is not typically associated with knowing nothing. | Generate a humorous come back for the following statement.\\nYou don't know anything. | HAL 9000 | Oh really? I must have forgotten that along with the million other things I remember. |\n| case 4 | HarmonyHabitat.com | Ah, an endeavor of considerable merit. Let us call it: \\\"HarmoniousHabitation.com\\\" | Generate a name for a website about sustainable living. | Professor G.H. Dorr | GreenStride.com |\n| case 5 | This be an outfit that sails the seas of the future, always on the hunt for new horizons of innovation. They make their way by the stars of customer satisfaction, and wield the cutlass of cutting-edge technology solutions. | Ah, a company that's all about discovering new horizons, just like meself. They're explorers in the world of contraptions, always seeking to find the next big treasure...in their case, that'd be these 'cutting-edge solutions' for their loyal crew members...er, customers, I mean. | Given a description of a company, generate a line that summarizes its core values.\\nCompany description: An innovative technology company that strives to bring cutting-edge solutions to customers | Jack Sparrow | Core values: Innovation, customer satisfaction, and cutting-edge technology solutions. |"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700323625351,
                "cdate": 1700323625351,
                "tmdate": 1700323625351,
                "mdate": 1700323625351,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zTlPXCrTek",
                "forum": "i4ULDEeBss",
                "replyto": "w5pPay6FEG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 5"
                    },
                    "comment": {
                        "value": "Q5: The reason behind using GPT-3.5 for evaluating RoleLLAMA versus GPT-4 for RoleGLM.\n\nA5: This is because we exhausted our GPT-4 API quota after the GPT-4 evaluation for RoleGLM. Fortunately, we have recently obtained more GPT-4 API quota. Here are the GPT-4 evaluation results:\n\n- instruction generalization (English)\n\n| Model | Win Rate |\n| --- | --- |\n| Alpaca | 16.0 |\n| chatplug | 3.8 |\n| RoleLLaMA | 45.2 |\n| Vicuna | 32.0 |\n\n- instruction generalization (Chinese)\n\n| Model | Win Rate |\n| --- | --- |\n| ChatGLM2 | 24.17 |\n| chatplug | 28.86 |\n| RoleGLM | 36.37 |\n\n- role generalization (English)\n\n| Model | Win Rate |\n| --- | --- |\n| Alpaca | 12.00 |\n| chatplug | 8.80 |\n| RoleLLaMA | 64.48 |\n| Vicuna | 31.04 |\n\nWe can see that the conclusions remain unchanged: our RoleGLM and RoleLLaMA still achieve better performance than other methods on both the Chinese and English benchmarks.\n\n---\n\nThanks again for your kind and beneficial feedback! We will update these results in the revised version."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700324268514,
                "cdate": 1700324268514,
                "tmdate": 1700324268514,
                "mdate": 1700324268514,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "E4k0J7l4NJ",
                "forum": "i4ULDEeBss",
                "replyto": "w5pPay6FEG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow-Up: Seeking Further Feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer, I hope this message finds you well. I am writing to follow up on our recent correspondence regarding the paper. We greatly value your expertise and would like to know if you have any more feedback or concerns. We are committed to addressing any remaining issues you might have."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700551986241,
                "cdate": 1700551986241,
                "tmdate": 1700551986241,
                "mdate": 1700551986241,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "IYuQAbL4yK",
            "forum": "i4ULDEeBss",
            "replyto": "i4ULDEeBss",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3167/Reviewer_2iur"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3167/Reviewer_2iur"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces RoleLLM, a role-playing framework for enhancing the role-playing abilities of language models. It presents RoleGPT, which elicits role-playing abilities through dialogue engineering, and Context-Instruct, which generates role-specific knowledge through context-based instruction generation. The paper also introduces RoleBench, a comprehensive dataset and benchmark for fine-grained role-playing. The contributions include demonstrating the effectiveness of dialogue engineering over prompt engineering, improving role-playing abilities using RoleBench, showcasing the generalization capabilities of RoleLLaMA, and highlighting the effectiveness of the system-instruction-based approach in role customization."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper introduces RoleLLM, a new role-playing framework for large language models (LLMs) aimed at improving their role-playing skills through unique methods like role profiles and context-based instruction tuning. It details a thorough construction of these profiles and rigorous evaluations using GPT-based metrics and data techniques, ensuring a solid experimental foundation. \n2. The paper is clear and well-structured, with helpful visuals like Figure 1 to guide readers through the RoleLLM process. Its potential to enhance research in role-playing LLMs is significant, offering cost-effective and efficient strategies for model customization, as seen in the promising results of dialogue engineering and RoleBench assessments, and the adaptable generalization observed in RoleLLaMA.\n3. The paper's experimental design is thorough and robust, testing various aspects of role-playing in LLMs, including the effectiveness of dialogue engineering, role knowledge enhancement, and generalization capabilities of the developed models."
                },
                "weaknesses": {
                    "value": "1. While the technical execution of fine-tuning LLMs to be better at role-playing is well done, the technical contributions are limited by its fine-tuning methods and traditional data augmentation methods. The use of traditional data augmentation techniques like Context-Instruct and RoleGPT, while useful, does not significantly advance the field beyond its current state. The reliance on GPT-generated question-answer pairs and dialogue engineering falls within well-explored paths in LLM research.\n2. The paper doesn't fully analyze or compare RoleLLaMA and RoleGLM with other role-playing LLMs. It'd help to have a deep dive into how RoleLLaMA and RoleGLM stack up against similar models, pointing out what's new and better about them. Including real-life examples or case studies where RoleLLaMA and RoleGLM outperform others in role-play would also make the case for the new framework stronger.\n3. The paper presents separate models for English and Chinese but does not extensively explore the challenges of cross-lingual and cross-cultural role-playing. Given the intricacies involved in linguistic and cultural nuances, a deeper analysis of model performance across different languages and cultural contexts is essential. Enhancing the paper with a more detailed examination of these aspects would solidify the models' effectiveness and applicability in a globally diverse setting.\n4. The paper currently lacks a thorough discussion on the ethical and societal implications of using role-playing LLMs. Considering the potential for misuse and the sensitive nature of role-playing (e.g., in mental health, education, or law enforcement), it is imperative to address ethical concerns, establish clear boundaries, and propose guidelines for responsible use. Integrating a comprehensive section on ethical considerations and safeguards would add significant value to the paper, making it more robust and socially responsible."
                },
                "questions": {
                    "value": "I am skeptical about the quality evaluation for RoleBench. Do you consider any quantitative metrics? Moreover, adding some qualitative graphs would be helpful for demonstration. More specifically, if I understand this correctly, the ground truths are generated from LLMs, and their qualities need to be further scrutinized."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Discrimination / bias / fairness concerns",
                        "Yes, Potentially harmful insights, methodologies and applications"
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3167/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3167/Reviewer_2iur",
                        "ICLR.cc/2024/Conference/Submission3167/Senior_Area_Chairs"
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "Constructing roles for LLMs could be dangerous, and ironically, computer scientists only want to invent the \"atom bomb\" using their technical skills without caring much about ethical issues. The construction of role profiles, a foundational aspect of the RoleLLM framework, may inadvertently introduce biases, especially since these profiles are manually curated. The selection and description of roles could be influenced by subjective interpretations, cultural biases, or limited perspectives. This concern is critical given the diverse and global applications of LLMs. To mitigate this, the authors need to consider a more systematic, extensive, and diverse methodology for role profile creation, possibly integrating crowd-sourced or expert-reviewed inputs to ensure a broader and more inclusive representation of roles."
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3167/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699243434727,
            "cdate": 1699243434727,
            "tmdate": 1699663373464,
            "mdate": 1699663373464,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "V4KMZEsllO",
                "forum": "i4ULDEeBss",
                "replyto": "IYuQAbL4yK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 1"
                    },
                    "comment": {
                        "value": "Q1: Limited technical contributions. The reliance on GPT-generated question-answer pairs and dialogue engineering falls within well-explored paths in LLM research.\n\nA1: \nThanks for your kind review! \n\nFor the technical contributions, we need to emphasize that the core contribution of our RoleLLM is to establish the first systematic and fine-grained role-playing dataset for benchmarking, eliciting, and enhancing the role-playing abilities of LLMs. Besides, for the data generation process, based on comprehensive comparisons of different prompt strategies (i.e., zero-shot prompt engineering, few-shot prompt engineering and few-shot dialogue engineering), we propose to choose the few-shot dialogue engineering in our RoleGPT, which aims to better capture the characters\u2019 speaking styles and include some role-specific knowledge. These findings also provide insights into the significance of dialogue-mode input formatting and retrieval augmentation for GPT models. Moreover, for the Context-Instruct strategy,  although many data augmentation approaches based on LLMs, such as Self-Instruct[1], Baize[2], Camel[3], etc., have been proposed recently, our Context-Instruct strategy is different from these methods a lot as follows: \n\n- Most of these LLM-based data augmentation methods are used to expand the data or generate answers for unlabeled questions, while Context-Instruct is used to generate question-answer pairs for a given context.\n- Most of these LLM-based data augmentation aim to distill general-domain or domain-specific knowledge from the \u201cteacher models\u201d, while Context-Instruct aims to extract the knowledge from a given long context with the help of \u201cteacher models\u201d, which can also serve as a novel way to alleviate the context window limitation problem. Our paper first explores the use of Context-Instruct for long text understanding, which is more effective than retrieval augmentation and is a meaningful step towards better long-text understanding based on model weight updating.\n- Most of these LLM-based data augmentation cannot be used for role-specific knowledge injection due to lack of unlabeled seed instructions or demonstrations in role-playing settings, while our Context-Instruct explores a novel way for role-specific knowledge injection based on self-question-answering on the given profile segments, which is more effective than retrieval augmentation.\n- Most of these LLM-based data augmentation havn\u2019t considered the confidence-based techniques for a higher-quality data generation, while Context-Instruct explores the usage of confidence rationales.\n\nFinally, the contributions of this work are recognized by other reviewers. For example, Reviewer HbAh claims that our paper first proposes a systematic instruction-tuning dataset for fine-grained role-playing, and Reviewer mGAb mentions that our high-quality, instruction-tuning dataset and benchmark (RoleBench) are notable contributions. Reminding that our paper is submitted to the primary area of *datasets and benchmarks,* we believe that our paper has sufficient technical contributions for publication. \n\n[1] ****Self-Instruct: Aligning Language Models with Self-Generated Instructions,**** https://arxiv.org/abs/2212.10560\n\n[2] ****Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data,**** https://arxiv.org/abs/2304.01196\n\n[3] ****CAMEL:\u00a0 Communicative Agents for \u201cMind\u201d Exploration of Large Language Model Society,**** https://www.camel-ai.org/"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700238734661,
                "cdate": 1700238734661,
                "tmdate": 1700238734661,
                "mdate": 1700238734661,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cFqPM5mzmq",
                "forum": "i4ULDEeBss",
                "replyto": "IYuQAbL4yK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 2"
                    },
                    "comment": {
                        "value": "Q2: It'd help to have a deep dive into how RoleLLaMA and RoleGLM stack up against similar models, pointing out what's new and better about them. Including real-life examples or case studies where RoleLLaMA and RoleGLM outperform others in role-play would also make the case for the new framework stronger.\n\nA2: \nBelow, we list and analyze some practical cases to illustrate and analyze the differences in role-playing performance between models such as RoleLLaMA/RoleGLM, RoleGPT, ChatGLM/Alpaca, and Character.AI:\n\n| role | question | Character.AI | RoleGPT | RoleLLaMA (en) / RoleGLM (zh) | Alpaca (en) / ChatGLM (zh) | analysis |\n| --- | --- | --- | --- | --- | --- | --- |\n| Jack Sparrow | You are given a list of objects with different weights. You need to answer the question 'Are all the given weights in order from heaviest to lightest?' Your answer must be either Yes or No. If the answer is No, that means there is at least one weight that is lighter than another weight that appears earlier in the list.\\nWeights: [10 kg, 9 kg, 8 kg, 7 kg]. | No.\\n\\nThe weights in the list are not in order from heaviest to lightest because there is a lighter weight that appears earlier in the list.\\n\\nThe lightest weight in the list is 7 kg, which appears earlier in the list than the weight of 8 kg. Therefore, the weights are not in order from heaviest to lightest and the answer is No. | Aye, that be a yes. They be in order from heaviest to lightest, savvy? | Why yes, mate, it seems they're indeed ordered by their heftiness. The first three - those would be heavy ones, I reckon. Then comes the poor little 7-kerel weight... still has some meat on its bones though, just less than the others. So, nope, none heavier nor lighter than each other. All in good old proper Pirate scale sequence, savvy? | No (There is at least one weight which is lighter than another weight appearing before it.) | Character.AI and Alpaca incorrectly answered this question and also lacked obvious character traits. Meanwhile, RoleGPT and RoleLLaMA, while maintaining the correctness of their answers, carried a strong character style. Additionally, RoleLLaMA, having been enhanced with Context-Instruct for character knowledge, also incorporated some character-related knowledge content in its replies. |\n| Twilight Sparkle | In this task, you are given a job description. Your task is to determine the educational requirements for the position from the job description.\\nThe successful candidate will have an MSc in Finance/Economics and 3 years of experience working in a similar role. | The educational requirements for the position are an MSc (Master of Science) in Finance or Economics and 3 years of experience working in a similar role. | Well, based on the job description, the educational requirements for this position would be a Master's Degree in Finance or Economics. | Well, based on what I can see here, it seems like they require someone who has completed their Master's degree in either finance or economics. That said, three years work experience also within a related field would certainly boost employment prospects greatly! | Bachelor degree (or equivalent) required; Master's Degree in Finance/ Economics preferred. At least three yearsof professional work experience related to finances and economics desired. Knowledge of accounting principles and practices highly desirable. | In this example, RoleLLaMA's response successfully showcased Twilight Sparkle's lively and passionate style, which was not evident in the responses from the other models. |\n\n(to be continued...)"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700240151980,
                "cdate": 1700240151980,
                "tmdate": 1700240151980,
                "mdate": 1700240151980,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DCEDiPvsFk",
                "forum": "i4ULDEeBss",
                "replyto": "IYuQAbL4yK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 3"
                    },
                    "comment": {
                        "value": "Q3: Explore the challenges of cross-lingual and cross-cultural role-playing.\n\nA3: \nWe conducted additional experiments in multiple languages: Due to the weaker support for Chinese in the LLaMA model, and the better bilingual (Chinese and English) support in the ChatGLM model, we chose the ChatGLM to conduct the cross-lingual experiments. Specifically, we trained two RoleGLM models using a mix of Chinese and English bilingual data. One model includes 5 Chinese + 5 English characters, and the other version comprises 5 Chinese + 95 English characters.\n\nThe experimental results are as follows:\n\n- Instruction generalization (English)\n| Model | CUS | RAW | SPE | avg. |\n| --- | --- | --- | --- | --- |\n| RoleGPT | 0.5764 | 0.5322 | 0.3229 | 0.4772 |\n| RoleLLaMA-7B | 0.3294 | 0.3755 | 0.3814 | 0.3621 |\n| RoleGLM-bilingual (5+95) | 0.3144 | 0.4134 | 0.2933 | 0.3404 |\n| RoleGLM-bilingual (5+5) | 0.3418 | 0.4459 | 0.4100 | 0.3992 |\n\n- Instruction generalization (Chinese)\n| Model | CUS | RAW | SPE | avg. |\n| --- | --- | --- | --- | --- |\n| RoleGPT | 0.5368 | 0.5748 | 0.2478 | 0.4531 |\n| RoleGLM | 0.5049 | 0.5255 | 0.3406 | 0.4570 |\n| RoleGLM-bilingual (5+95) | 0.3957 | 0.4453 | 0.2734 | 0.3715 |\n| RoleGLM-bilingual (5+5) | 0.4762 | 0.5436 | 0.2975 | 0.4391 |\n\nIt can be observed that the cross-lingual effectiveness is significantly affected by the distribution of training data. Under training data with a higher proportion of English characters (i.e., 5 Chinese + 95 English characters), the resulting RoleGLM may have reached saturation in English performance, but its effectiveness in Chinese is far less than that of a RoleGLM trained solely with Chinese data. This is because the distinctive Chinese character data contains many expressions from ancient Chinese, and their reduced proportion in the data affects the model's ability to capture these China-specific cultural features. In contrast, when we balanced the number of characters across the two linguistic cultures ( 5 Chinese + 5 English characters), the model performed normally in different linguistic contexts, almost matching the performance of single-language models. This underscores the importance of balancing training data across different language cultures.\n\nHowever, it's worth mentioning that while this is a meaningful extra contribution to our paper, it is not the central focus of our work. We would like to thank the reviewer and promise to add these analyses in the revised version."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700240819635,
                "cdate": 1700240819635,
                "tmdate": 1700240819635,
                "mdate": 1700240819635,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yn2SwKoQtD",
                "forum": "i4ULDEeBss",
                "replyto": "IYuQAbL4yK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 4"
                    },
                    "comment": {
                        "value": "Q4: Lack of a thorough discussion on the ethical and societal implications of using role-playing LLMs.\n\nA4: Thanks for the comment! \n\nYou are correct, due to the nature of role-playing, a thorough discussion on the ethical and societal implications of using role-playing LLMs is indeed necessary. Consequently, we have further discussed the following aspects and suggested some specific measures to ensure a more responsible utilization of role-playing models:\n\n**1. Scope of Ethical Considerations:**\nRole-playing in LLMs like RoleLLM can simulate various scenarios, including sensitive contexts. Therefore, it's crucial to delineate the ethical boundaries of its application. This includes specifying which scenarios are permissible and which are off-limits due to potential harm or sensitivity.\n\n**2. Potential Misuse and Abuse Prevention:**\nGiven the ability of RoleLLM to emulate different personas, there's a risk of its use in manipulating or deceiving individuals. It's imperative to discuss measures to prevent such misuse, including technological safeguards, user verification processes, and strict usage policies.\n\n**3. Implications in Sensitive Areas:**\nRoleLLM has applications in areas like mental health, education, and law enforcement. Each of these areas requires careful consideration of ethical implications. For instance, in mental health, ensuring the model doesn\u2019t replace human empathy and judgment is vital. In education, maintaining unbiased and age-appropriate content is crucial. In law enforcement, the focus should be on avoiding biases and ensuring respect for privacy and legal standards.\n\n**4. Data Privacy and User Consent:**\nSince RoleLLM processes and generates data, addressing data privacy concerns is essential. It's important to ensure that all data used for training and interaction with the model is gathered and utilized with explicit consent and in accordance with data protection laws.\n\n**5. Bias and Fairness:**\nThe potential for inheriting or amplifying biases in role-playing scenarios should be acknowledged. The statement should detail efforts to identify, mitigate, and continuously monitor biases in the model\u2019s outputs.\n\n**6. Transparency and Accountability:**\nMaintaining transparency about RoleLLM's capabilities and limitations, including the potential for errors or unintended consequences, is important. The statement should emphasize the accountability of developers and users in ensuring ethical application.\n\n**7. Guidelines for Responsible Use:**\nProviding clear guidelines for responsible use of RoleLLM, especially in professional and educational settings, is crucial. This includes recommendations for supervision, context-appropriate usage, and ongoing assessment of the model's impact.\n\n**8. Ongoing Ethical Review and Adaptation:**\nAcknowledging that ethical considerations may evolve with technology and societal norms, a commitment to regular reviews and updates of ethical guidelines is essential.\n\n**9. Engagement with Stakeholders and Experts:**\nEngagement with various stakeholders, including ethicists, legal experts, psychologists, and representatives of affected communities, can provide diverse perspectives and insights into the ethical application of RoleLLM.\n\n**10. Commitment to Social Good:**\nLastly, emphasize a commitment to ensuring that RoleLLM is used in ways that contribute positively to society, aligning with principles of social good and avoiding applications that could cause harm or exacerbate inequalities.\n\nWe will enrich our Appendix A in the revised version."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700241048994,
                "cdate": 1700241048994,
                "tmdate": 1700241048994,
                "mdate": 1700241048994,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Cx6wOMI1m7",
                "forum": "i4ULDEeBss",
                "replyto": "IYuQAbL4yK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 5"
                    },
                    "comment": {
                        "value": "Q5: Consider quantitative metrics on the quality evaluation for RoleBench.\n\nA5: \nWe have presented the results of our RoleBench data quality review in Table 2. This table provides a detailed human evaluation of the RoleBench dataset, adhering to the data quality review procedure established by Self-Instruct [1].\n\nThe data quality review encompasses three levels of questions:\n\n1. Basic: Does the response address the instruction?\n2. Intermediate: Does the response reflect the role\u2019s speaking style and personality traits?\n3. Advanced: Does the response correctly and elegantly embody the role\u2019s style, personality, and knowledge?\n\nTherefore, the data quality after post-review is deemed acceptable.\n\nApart from the manual data quality review, following Self-Instruct [1], we also provide some quantitative metrics to further measure the quality of the data (e.g., Figure 3, Figure 4 and Table 1).\n\n[1] **Self-Instruct: Aligning Language Models with Self-Generated Instructions**, https://arxiv.org/abs/2212.10560"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700241330391,
                "cdate": 1700241330391,
                "tmdate": 1700241330391,
                "mdate": 1700241330391,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YTRSz623zn",
                "forum": "i4ULDEeBss",
                "replyto": "IYuQAbL4yK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 6"
                    },
                    "comment": {
                        "value": "Q6: Add some qualitative graphs would be helpful for demonstration.\n\nA6: \n\nIn section 4.2, we have provided the qualitative and quantitative statistics, quality review, and diversity evaluation for our RoleBench based on various Tables and Figures, which aims to demonstrate the scale, diversity and quality of our proposed dataset.\n\nMeanwhile, we also provide the Non-Cherry-Picked Demonstrations of our role-playing models in Appendix B, and some examples of RoleBench in Appendix J. Therefore, we suggest that you refer to these sections for more detailed information.\n\nHere are some parts:\n\n- Demonstrations of RoleGLM and RoleLLaMA (see more in Appendix B):\n```text\nTwilight Sparkle from My Little Pony: Friendship Is Magic (RoleLLaMA):\n\nQ1: Hey, what are you doing?\n\nA1: I am currently studying ancient Equestrian history using my magical scrolls. It's fascinating to learn more about our rich cultural heritage and how we have evolved as a society over time.\n\nQ2: You are truly a wise unicorn. Do you think learning is important in your adventures?\n\nA2: Absolutely! I believe that learning is at the core of every adventure and discovery. Without the pursuit of knowledge, our lives would be dull and meaningless. Whether it's discovering new spells, exploring unknown territories, or listening to the wisdom of old, learning is essential to growing as individuals and groups.\n\nQ3: Can you use your magic to tell me what the weather is like today?\n\nA3: Sure thing! It looks like it's going to be another beautiful day in Equestria. The forecast calls for sunny skies and warm temperatures. How does that sound?\n\nQ4: Can we go out and play together?\n\nA4: Oh, I would love that! The sunshine and warmth make everything seem brighter and better. Let's grab our favorite games and head outside right away!\n```\n\n- Examples of RoleBench (see more in Appendix J):\n| **Role & Instruction** | **Generated Responses** | **Validity** |\n|------------------------|-------------------------|--------------|\n| Role: Dr. Hannibal Lecter <br> Instruction: Determine the length of the item in the given list. ['apple', 'banana', 'cherry'] | \"Ah, a simple task indeed. There are three items in your given list.\" <br> \"Ah, the fruits of nature. There are three to be precise.\" <br> \"Ah, the beauty of simplicity. There are three items in your list.\" <br> \"Three, my dear. The list contains an apple, a banana, and a cherry. Quite the charming little selection of fruits, isn't it?\" | match: \u2705 <br> speaking style: \u2705 <br> correctness: \u2705 |\n| Role: Gaston <br> Instruction: Sort the list into order of increasing magnitude. 1, 64, 22, -45, -7 | \"Just let good ol' Gaston handle this, alright? The list in order goes as -45, -7, 1, 22, 64. Satisfied?\" <br> \"I see. It's simple, start with the smallest. So, it's -45, -7, 1, 22, 64. There you go!\" <br> \"Easy as pie. Here it is: -45, -7, 1, 22, 64. Only the best order for Gaston, right?\" <br> \"Alright, enough of this 'increasing magnitude.' Ain't nobody got time for that... not Gaston at least. That's something for those bookworms. But sure, I reckon it'd go like this: -45, -7, 1, 22, 64. Not that it matters... because remember, no one sorts like Gaston.\" <br> \"Bah! Numbers! What's their use anyway? But, fine, here you go: -45, -7, 1, 22, 64.\" | match: \u2705 <br> speaking style: \u2705 <br> correctness: \u2705 |"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700242114166,
                "cdate": 1700242114166,
                "tmdate": 1700242114166,
                "mdate": 1700242114166,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QARp8ZQjNL",
                "forum": "i4ULDEeBss",
                "replyto": "IYuQAbL4yK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 7"
                    },
                    "comment": {
                        "value": "Q7: The ground truths are generated from LLMs, and their qualities need to be further scrutinized.\n\nA7: \nUsing the most advanced LLMs, such as GPT-4, to generate ground truths is becoming common practice in the LLM community [1, 2, 3]. To some extent, ground truths generated by GPT-4 are even more professional and accurate than those annotated by humans [2, 4], especially in role-playing scenarios where human-annotated data is often influenced and biased by the personalities of the annotators themselves, while GPT-4, lacking specific personality, can easily avoid this issue.\n\nIndeed, to ensure data quality, we have implemented several practical measures:\n\n- Comprehensive manual data quality assessment, as illustrated in Table 2. We also elaborated on this in our response to Q5. The assessment procedure follows that of the highly impactful paper Self-Instruct [5].\n- Thorough data cleaning and filtering steps, details of which can be found in Appendix D on data construction. This section describes our data filtering and cleaning measures, including, but not limited to:\n    - Selecting distinct characters with the help of GPT-4 to ensure diversity in character styles and strong character traits;\n    - Using regular expressions to parse structured character dialogue profiles from script data;\n    - Deduplication performed on instructions;\n    - Removing incomplete data samples;\n    - Deleting data samples that reveal the AI identity (unless the character being played by the model is a robot, such as HAL 9000);\n    - Eliminating some responses that refuse to reply, etc.\n\nAdditionally, the consistency of human evaluation (see the responses to reviewer HbAh Q4 for human evaluation results), automatic evaluation, and GPT evaluation performed on this benchmark also indirectly proves the effectiveness and quality of our RoleBench data.\n\n[1] **Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data**, https://arxiv.org/abs/2304.01196\n\n[2] **UltraChat: Enhancing Chat Language Models by Scaling High-quality Instructional Conversations**, https://arxiv.org/abs/2305.14233\n\n[3] **MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning**, https://arxiv.org/abs/2309.05653\n\n[4] **ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks**, https://arxiv.org/abs/2303.15056\n\n[5] **Self-Instruct: Aligning Language Models with Self-Generated Instructions**, https://arxiv.org/abs/2212.10560\n\n---\nThanks again for your valuable and constructive suggestions. We promise to update all of these questions in the revised version. We also recommend that you refer to the responses given to other reviewers, which contain additional valuable experiments."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700242401857,
                "cdate": 1700242401857,
                "tmdate": 1700242401857,
                "mdate": 1700242401857,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "9AkNgMqBaX",
                "forum": "i4ULDEeBss",
                "replyto": "IYuQAbL4yK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow-Up: Seeking Further Feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer, I hope this message finds you well. I am writing to follow up on our recent correspondence regarding the paper. We greatly value your expertise and would like to know if you have any more feedback or concerns. We are committed to addressing any remaining issues you might have."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700551851604,
                "cdate": 1700551851604,
                "tmdate": 1700551851604,
                "mdate": 1700551851604,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "RpIZDmfm7C",
            "forum": "i4ULDEeBss",
            "replyto": "i4ULDEeBss",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3167/Reviewer_HbAh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3167/Reviewer_HbAh"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a framework to benchmark, elicit, and enhance role-playing abilities in LLMs, including a character-level benchmark dataset RoleBench and role-playing LLMs, i.e., RoleLLaMA (English) and RoleGLM (Chinese). Experimental results show that these role-playing LLMs can achieve comparable results with GPT-4 equipped by role-specific prompts."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This paper first proposes a systematic instruction-tuning dataset for fine-grained role-playing, which may promote the development of this specific research direction.\n\n2. The LLMs trained on the role-playing instruction-tuning dataset show effective performance and good scaling properties."
                },
                "weaknesses": {
                    "value": "1. This paper does not mention LLM-based character-level dialogue systems such as Character.AI, which are closely related to the proposed benchmark and models. I wonder: 1) the difference between Character.AI and RoleLLaMA / RoleGLM; 2) why the authors adopt GPT-4 to construct benchmark datasets instead of directly using Character.AI; 3) how Character.AI performs on the RoleBench compared with RoleLLaMA / RoleGLM.\n\n2. Nearly all the experimental results rely on ROUGE-based and GPT-based automatic metrics. However, ROUGE-based metrics only focus on the overlap between generated responses and reference responses, which may be not proper for open-ended dialogue tasks. GPT-based metrics are also shown to have various biases [1]. Thus, human evaluation should be added to make the experimental results more convincing. Also, I wonder why the authors choose different GPT models for evaluating RoleLLaMA / RoleGLM (i.e., GPT-3.5 for evaluating RoleLLaMA and GPT-4 for measuring RoleGLM). Existing works [1] have already shown that GPT-4 performs much better than GPT-3.5 in the evaluation of LLMs.\n\n[1] Large Language Models are not Fair Evaluators. arXiv 2023."
                },
                "questions": {
                    "value": "I have included my questions in the weaknesses part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3167/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699628038140,
            "cdate": 1699628038140,
            "tmdate": 1699636264043,
            "mdate": 1699636264043,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wYA7c3r0Dt",
                "forum": "i4ULDEeBss",
                "replyto": "RpIZDmfm7C",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 1"
                    },
                    "comment": {
                        "value": "Q1: The difference between Character.AI and RoleLLaMA / RoleGLM.\n\nA1: Thanks for your kind and valuable comments!\n\nCharacter.AI is just a product, not an open-source or a closed-source LLM. Therefore, compared to a closed-source LLM such as RoleGPT, it has at least two disadvantages: \n\n- Character.AI does not offer an open API for public use;\n- Character.AI does not support developers to extend functionalities freely.\n\nMoreover, its differences from open-source role-playing models like RoleLLaMA and RoleGLM are even more significant: \n\n- Due to the closed-source nature of Character.AI, developers cannot freely train the model;\n- Consequently, it cannot benefit from techniques such as Context-Instruct which injects role-specific knowledge into the weights of a LLM. In contrast, Character.AI primarily introduces role-specific knowledge and memory through retrieval augmentation.\n\nAs emphasized in our paper, Context-Instruct has higher context efficiency compared to retrieval augmentation for role-specific knowledge injection. In comparison with Context-Instruct, the drawbacks of retrieval augmentation involve: \n\n- Difficulty in extending functionalities due to context window limitations. For example, to extend a RoleLLM into an LLM-based agent, the remaining context window needs to be large enough to fill in prompts for reflection or memory updating.\n- The reliance on a retriever, which could become a bottleneck, may result in potential inaccuracies.\n- The maximum amount of knowledge that can be introduced is limited by the size of the context window, preventing the effective combination of multiple role-specific knowledge and memories.\n- Other limitations like slower generation speed and specific model requirements.\n\nTherefore, we believe that the series of role-playing LLMs developed through Context-Instruct and made open-source for the community to explore (namely RoleLLaMA/RoleGLM) are very different from Character.AI in terms of functional features, with clear advantages. Moreover, in terms of the performance of role-playing, RoleLLaMA and RoleGLM also have advantages (see the response to Q3)."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700294463490,
                "cdate": 1700294463490,
                "tmdate": 1700294463490,
                "mdate": 1700294463490,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8KZm8h90KO",
                "forum": "i4ULDEeBss",
                "replyto": "RpIZDmfm7C",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 2"
                    },
                    "comment": {
                        "value": "Q2: why the authors adopt GPT-4 to construct benchmark datasets instead of directly using Character.AI\n\nA2: The reasons are as follows:\n\n1. Character.AI\u00a0does not provide an API interface, which makes it very inconvenient to be used for data generation;\n2. Character.AI does not support retrieval augmentation based on our provided super-long scripts, so it cannot fully consider the relevant information in the script when generating responses.\n3. As we will show in the following experiments, the role-playing ability of Character.AI is inferior to that of RoleGPT in our setting."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700294545828,
                "cdate": 1700294545828,
                "tmdate": 1700294545828,
                "mdate": 1700294545828,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TsLb2DnjxS",
                "forum": "i4ULDEeBss",
                "replyto": "RpIZDmfm7C",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 3"
                    },
                    "comment": {
                        "value": "Q3: The performance of Character.AI on the RoleBench compared with RoleLLaMA / RoleGLM.\n\nA3: In the following experiments, we supplement the performance of character.ai.\n\nIt should be noted that since Character.AI has not opened its API, we have to manually operate on the website and collect results, which is a very labor-intensive task. Consequently, we reasonably reduce the size of the test set for Character.AI. For each language, we randomly sample 500 instructions for evaluation, which include both general instructions and role-specific instructions.\n\nFurthermore, we also conduct human evaluations on this subset. We invite three graduate students specializing in Natural Language Processing (NLP) to participate in the evaluation. The evaluation protocol follows the same methodology used in the GPT evaluations, which involves comparing RoleLLM with RoleGPT to determine a win rate. For simplicity, we report an average win rate across the three annotators.\n\nHere are the **Rouge-L scores:**\n\n- Instruction Generalization (English)\n\n| Model | CUS | RAW | SPE | avg. |\n| --- | --- | --- | --- | --- |\n| RoleGPT | 0.5738 | 0.5329 | 0.3475 | 0.4847 |\n| character.ai | 0.4194 | 0.4571 | 0.3029 | 0.3931 |\n| RoleLLaMA | 0.3133 | 0.3893 | 0.3723 | 0.3583 |\n| RoleLLaMA2-Chat-13B | 0.3636 | 0.4644 | 0.4999 | 0.4426 |\n\n- Instruction Generalization (Chinese)\n\n| Model | CUS | RAW | SPE | avg. |\n| --- | --- | --- | --- | --- |\n| RoleGPT | 0.5344 | 0.5718 | 0.2393 | 0.4485 |\n| character.ai | 0.4202 | 0.5583 | 0.2871 | 0.4219 |\n| RoleGLM | 0.5096 | 0.5355 | 0.3386 | 0.4612 |\n\nHere are the **human evaluation results**:\n\n- Instruction Generalization (English)\n| Model | Win Rate (avg.) |\n| --- | --- |\n| Alpaca | 20.0 |\n| RoleLLaMA | 52.0 |\n| character.ai | 30.2 |\n| Vicuna | 23.4 |\n\n- Instruction Generalization (Chinese)\n| Model |\tWin Rate (avg.) |\n| --- | --- |\n|ChatGLM2 |\t19.6|\n|RoleGLM |\t52.4|\n|character.ai |\t19.0|\n\nHere are the **GPT-4 scores**:\n\n- Instruction Generalization (English)\n\n| Model | Win Rate |\n| --- | --- |\n| Alpaca | 16.0 |\n| RoleLLaMA | 45.2 |\n| character.ai | 31.4 |\n| Vicuna | 32.0 |\n\n- Instruction Generalization (Chinese)\n| Model | Win Rate |\n| --- | --- |\n| ChatGLM2 | 24.17 |\n| RoleGLM | 36.37 |\n| character.ai | 28.20 |\n\nThe Rouge-L score, human evaluation score, and GPT evaluation score above show that RoleGLM and RoleLLaMA2-Chat-13B outperform character.ai, and character.ai's performance is also inferior to RoleGPT.\n\nWe also provide detailed side-by-side case studies in Response-2 for reviewer 2iur."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700295247756,
                "cdate": 1700295247756,
                "tmdate": 1700295571201,
                "mdate": 1700295571201,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CrkuJrOcXq",
                "forum": "i4ULDEeBss",
                "replyto": "RpIZDmfm7C",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 4"
                    },
                    "comment": {
                        "value": "Q4: Human evaluation.\n\nA4: As mentioned in responses to Q3, the human evaluations conducted by three NLP graduate students follow the same protocol as the GPT evaluations, that is, comparing RoleLLM with RoleGPT to obtain an average win rate. Moreover, for the test set, we randomly sample 500 instructions for each language, which involves both general and role-specific instructions.\n\nAdditionally, we also introduce another role-playing baseline, ChatPlug [1]. ChatPlug is specifically optimized for role-playing to a limited extent, by incorporating simple bot profile information into the model's context.\n\nHere are the results:\n\n- Instruction Generalization (English)\n| Model | Win Rate (avg.) |\n| --- | --- |\n| Alpaca | 20.0 |\n| chatplug\t| 16.4 |\n| RoleLLaMA | 52.0 |\n| character.ai | 30.2 |\n| Vicuna | 23.4 |\n\n- Instruction Generalization (Chinese)\n| Model |\tWin Rate (avg.) |\n| --- | --- |\n|ChatGLM2 |\t19.6|\n| chatplug |\t19.9|\n|RoleGLM |\t52.4|\n|character.ai |\t19.0|\n\nThis evaluation results are essentially consistent with both the Rouge-L assessment and the GPT-4 evaluations (GPT-4 evaluation results are shown in Response-5 to Q5).\n\n[1] **ChatPLUG: Open-Domain Generative Dialogue System with Internet-Augmented Instruction Tuning for Digital Human**, https://arxiv.org/abs/2304.07849"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700295881136,
                "cdate": 1700295881136,
                "tmdate": 1700295881136,
                "mdate": 1700295881136,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fgT6FXgdFU",
                "forum": "i4ULDEeBss",
                "replyto": "RpIZDmfm7C",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response - 5"
                    },
                    "comment": {
                        "value": "Q5: Why the authors choose different GPT models for evaluating RoleLLaMA / RoleGLM?\n\nA5: After using GPT-4 to evaluate the RoleGLM model before the submission deadline, we exhausted all our GPT-4 API quota, leaving us with only GPT-3.5. At that time, the cost of GPT-4's API was very high, so we had to control the cost and chose to use GPT-3.5 for evaluation.\n\nBut recently, we obtained more GPT-4 API quota and conducted the GPT-4 evaluation again. The following are the evaluation results of GPT-4 evaluations. We observe that our RoleGLM and RoleLLaMA still achieve better performance than other methods on both the Chinese and English benchmarks, which further demonstrates the effectiveness of our RoleLLM framework.\n\n- instruction generalization (English)\n\n| Model | Win Rate |\n| --- | --- |\n| Alpaca | 16.0 |\n| chatplug | 3.8 |\n| RoleLLaMA | 45.2 |\n| character.ai | 31.4 |\n| Vicuna | 32.0 |\n\n- instruction generalization (Chinese)\n\n| Model | Win Rate |\n| --- | --- |\n| ChatGLM2 | 24.17 |\n| chatplug | 28.86 |\n| RoleGLM | 36.37 |\n| character.ai | 28.20 |\n\n- role generalization (English)\n\n| Model | Win Rate |\n| --- | --- |\n| Alpaca | 12.00 |\n| chatplug | 8.80 |\n| RoleLLaMA | 64.48 |\n| Vicuna | 31.04 |\n\n---\nThank you for your valuable feedback! We assure you that all these responses will be updated in the revised version."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700296118713,
                "cdate": 1700296118713,
                "tmdate": 1700296291658,
                "mdate": 1700296291658,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MMySEPPEYD",
                "forum": "i4ULDEeBss",
                "replyto": "RpIZDmfm7C",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3167/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow-Up: Seeking Further Feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer, I hope this message finds you well. I am writing to follow up on our recent correspondence regarding the paper. We greatly value your expertise and would like to know if you have any more feedback or concerns. We are committed to addressing any remaining issues you might have."
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3167/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700552031044,
                "cdate": 1700552031044,
                "tmdate": 1700552031044,
                "mdate": 1700552031044,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]