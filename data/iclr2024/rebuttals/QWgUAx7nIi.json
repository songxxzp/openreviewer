[
    {
        "title": "Contrastive Graph Autoencoder for Geometric Polygon Retrieval from Building Datasets"
    },
    {
        "review": {
            "id": "VXVVY9nKU5",
            "forum": "QWgUAx7nIi",
            "replyto": "QWgUAx7nIi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2269/Reviewer_sEzw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2269/Reviewer_sEzw"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a method to embed a polygon, which can be applied to polygon retrieval. The core of the method is to train an auto-encoder together with a contrastive learning loss. Since both reconstruction loss and contrastive learning loss doesn\u2019t require human labels, their method can be unsupervised and scalable. The paper validates their method on multiple datasets including both synthetic and real-world datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The proposed method doesn\u2019t require any human labels and thus is scalable, particularly useful to the applications in the GIS domain where unlabelled data are sufficient due to crowd-source platforms like OpenOSM. \n\nThe proposed method also shows very promising results in the real world dataset."
                },
                "weaknesses": {
                    "value": "The paper has several weaknesses which I\u2019ll detail below: \n\nThe paper has a very limited comparison with baselines. The results only show the comparison between the different variants of the proposed methods, despite the fact that there are multiple existing works that tried to solve this problem like Yan et al as mentioned in the paper. \n\nFrom my viewpoint, the impact of this paper on future research is quite limited. The proposed method is not new -- it's known that t contrastive learning together with autoencoder is better than one of them only, which limits its inspiration to future works. Also, the proposed method is not fully explored. For example, the most recent polygonal learning [1] lists two principled ways to encode the polygon geometry. The paper should also discuss, probably also try the better backbone and provide some insights. \n\nSome important implementation details are missing, especially for the dataset preprocessing. \nThe reason why I think it\u2019s important is because preprocessing might be able to help representation learning. For example, if the dataset is pre-aligned (rotation, scale, or translation), the representation learning would be much easier. Basically, different preprocessing might lead to very different performance. Thus, the paper should stress it in a very clear way. \n\nSome claims of the paper are not fully validated. The paper claims that the proposed method is robust to the node count, rotations, etc. However, I\u2019m not sure how the method achieves this. The paper doesn\u2019t validate it using experiments or proof. \n\nIn short, I think the paper still requires a bit of work to polish before it is ready to be published. Although the presented method is effective in some datasets, the comparison is limited. Because of this, I\u2019m not fully convinced that the proposed method is state-of-the-art. Also, the paper has other limitations that I detailed above.\n\nBut I\u2019m glad to hear back from authors during rebuttal in case I misunderstand anything. \n\n[1] Mai et al. Towards General-Purpose Representation Learning of Polygonal Geometries."
                },
                "questions": {
                    "value": "Please address the questions and concerns that I have above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2269/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698735905192,
            "cdate": 1698735905192,
            "tmdate": 1699636159776,
            "mdate": 1699636159776,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Zt7THYVGJj",
                "forum": "QWgUAx7nIi",
                "replyto": "VXVVY9nKU5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2269/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2269/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer sEzw"
                    },
                    "comment": {
                        "value": "## Reviewer sEzw\n\n**Comment sEzw-1** The paper has a very limited comparison with baselines. The results only show the comparison between the different variants of the proposed methods, despite the fact that there are multiple existing works that tried to solve this problem like Yan et al as mentioned in the paper.\n\n\n> **Response sEzw-1** We will provide additional results from the angular count (non-ML) method [Arkin, Esther M., et al.], used as one of  benchmarks in [Yan, Xiongfeng, et al.]. \n\n\n**Comment sEzw-2** \u2026 the proposed method is not fully explored. For example, the most recent polygonal learning [1] lists two principled ways to encode the polygon geometry. The paper should also discuss, probably also try the better backbone and provide some insights.\n\n> **Response sEzw-2** We will attempt comparison with the methods of [Mai, Gengchen, et al.]. Note that in [Mai, Gengchen, et al.], the ResNet1D (a spatial domain polygon encoder, similar to [Yan, Xiongfeng, et al.]) and NUFT encoders (a fourier transform-based encoding method) are proposed for polygon embeddings to solve for shape classification of polygon geometries. The two encoding methods are tested on dataset MNIST-cplx70k, and we would like to point out that the Glyph dataset tested in our study likely presents a more challenging tasks to learning models (26 class vs. 10 class, as well as a less regular  (as not gridded) appearance of glyph outlines extracted directly from glyph representations and not raster images). We note that in the study of baseline [Yan, Xiongfeng, et al.], similar non-ML FT-based methods [Ai, Tinghua, et al.] are already tested on the same OSM dataset as here, but show lesser performance. \n\n\n**Comment sEzw-3** Some important implementation details are missing, especially for the dataset preprocessing. \u2026 For example, if the dataset is pre-aligned (rotation, scale, or translation), the representation learning would be much easier.\n\n> **Response sEzw-3** We note that the dataset preparation and testing of the present manuscript is fully documented in the reference provided as **Anonymous**. This manuscript is currently under double blind closed review, focusing on contributions distinct from this paper (comparison of architectures and data preprocessing in a classification task). We shall attempt to include as much detail here, enabling us to understand the dataset preparation applied here for one-shot retrieval, without jeopardizing the above review process. \n> To mitigate the concerns of **Reviewer sEzw** regarding the issue of data preprocessing, we update the anonymous Figshare URL provided in Reproducibility Statement section, adding the implementation code of data preparation of three datasets (Glyph, OSM and Melbourne). We also note that there is no pre-alignement between the training dataset and the arbitrary rotations of buildings in the real world.\n\n\n**Comment sEzw-4** Some claims of the paper are not fully validated. The paper claims that the proposed method is robust to the node count, rotations, etc. However, I\u2019m not sure how the method achieves this.\n\n> **Response sEzw-4** Please, refer to **Response SxCs-2**."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2269/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700019444027,
                "cdate": 1700019444027,
                "tmdate": 1700019444027,
                "mdate": 1700019444027,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xQ3s8EHFAt",
                "forum": "QWgUAx7nIi",
                "replyto": "Zt7THYVGJj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2269/Reviewer_sEzw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2269/Reviewer_sEzw"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the feedback!"
                    },
                    "comment": {
                        "value": "Thanks for the feedback and sorry for the late! \n\nHowever, sorry I'm not sure I'm fully convinced. \n\nFirst, as authors said, baselines are indeed missing, which I think might take quite a bit time to polish. Because the paper might ends up with a totally new story after these baselines are included.\n\nAnd then regarding proof about free of vertex count, I read the comments the authors provided to other reviewer. Honestly, I'm not very convinced. Because being free of vertex count is a bit strong claim whereas some example results provided during rebuttal are insufficient. To support this strong claim, I would suggest having more controlled experiments -- e.g., error analysis of model prediction for the different vertex count, or mathematically show the proof behind.  \n\nThus, I tend to keep my original rating."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2269/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685017407,
                "cdate": 1700685017407,
                "tmdate": 1700685017407,
                "mdate": 1700685017407,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "PTRJpklYSk",
            "forum": "QWgUAx7nIi",
            "replyto": "QWgUAx7nIi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2269/Reviewer_R5mS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2269/Reviewer_R5mS"
            ],
            "content": {
                "summary": {
                    "value": "The paper considers a geographic retrieval problem, querying a \"map\" with polygons to search for similar shapes. The paper considers the state of the art and prior work using graphical autoencoders (GAEs).  They seek to provide an improved solution that is robust to holes and translations of the polygons, problems that have affected prior solutions. They pick up a method that came from point cloud application, and incorporate contrastive learning to gain robustness. The writing is clear and the contribution and novelty are explained. The paper presents experiments and compares to the prior GAE solution as a baseline."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The work builds logically on the prior art and is well motivated to add robustness.  The contrastive learning framework allows the authors to introduce controlled deficits, adding or removing nodes and/or edges.   \n\nThe authors work on known and available data sets and publish their code.  \n\nThe comparison with the GAE as baseline seems fair.  The method is a logical extension and handles cases that the baseline does not."
                },
                "weaknesses": {
                    "value": "The paper would benefit from an algorithm statement (say, in a Figure, or a flow diagram with equation references).  This should include a listing of all the learnable parameters, and their dimensions.  For example, after eqn (3)  and eqn (4) there are MLPs, but not clear where these are specified. \n\nIt isn\u2019t clear if other (not necessarily ML-based) methods using geometry would work for these problems. The ideas of deformable templates and fitting are old, e.g., in the medical imaging literature.  However, the reviewer is not expert on these older methods. \n\nThe proposed method handles new cases, which is an important generalization, and shows better Hausdorf metrics for retrieving similar shapes in data.  However, it isn\u2019t clear if this is now a \u201csolved\u201d problem or if more work is needed to generalize."
                },
                "questions": {
                    "value": "Please say more about how eqn (6) is interpreted as a probability (or an estimate of a probability).\n\nDid you consider different augmentation ratios r other than 20%?\n\nFrom a practical perspective, are the results good enough to develop a tool that is broadly applicable?  What challenges remain?\n\nCan you comment on the relation to this work: \u201cGraph Contrastive Learning with Implicit Augmentations\u201d, Arxiv, Nov 2022, and graph augmentation in general?\n\nAfter eqn (9), should the losses all be weighted equally?  Should this be tuned for the application?\n\nWhat are the tradeoffs with the k-NN, and choosing k?  How does this potentially help with a search, and does growing k imply more \"incorrect\" or bad cases to be reported?\n\nSection 2.1: This seems intuitive but perhaps good to exactly define \u201clinear ring\u201d."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2269/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698763352427,
            "cdate": 1698763352427,
            "tmdate": 1699636159679,
            "mdate": 1699636159679,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "BpVgcbNyxF",
                "forum": "QWgUAx7nIi",
                "replyto": "PTRJpklYSk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2269/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2269/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer R5mS"
                    },
                    "comment": {
                        "value": "## Reviewer R5mS\n\n> **General Response** We will include an algorithm statement (possibly, as suggested, as a flow diagram with references to equations). And the listing of learnable parameters and their dimensions. This will specifically include the MLP specification for Eq 3 and 4, and a clarification for Eq 6.\n\n\n**Comment R5mS-1** Please say more about how eqn (6) is interpreted as a probability (or an estimate of a probability).\n\n\n> **Response R5mS-1** Eq. 6 calculates the reconstructed adjacency matrix $A$ from the node feature embedding $Z$. We apply a sigmoid activation ($\\sigma$) to the square matrix of $Z$ to compute the probability between edges (i.e., ($z_i$, $z_j$) $\\in$ $A$).\n\n\n**Comment R5mS-2** Did you consider different augmentation ratios r other than 20%?\n\n\n> **Response R5mS-2** We did not consider different augmentation ratios $r$ other than 20% in our study. To clarify, the augmentation ratio $r$ indicates, for a single polygon ($G$ = {$A$, $X$}), $r$% of node and edge are perturbed in graph augmentation (node -> node removal, edge -> edge addition). Rule of thumb is that after graph augmentation, the augmented graph $G$* should preserve its semantic information (qualitatively, geometric appearance). We deem $r$ = 20% a valid threshold for the study. \n\n\n**Comment R5mS-3** From a practical perspective, are the results good enough to develop a tool that is broadly applicable? What challenges remain?\n\n\n> **Response R5mS-3** We believe that these results are robust enough for a shape retrieval tool. We note that often individual building shapes are not deterministic of e.g., building function, and this may be revealed by analyzing the appearance of a broader embedding of buildings of similar shapes (typical British terrace houses, a sequence of elongated houses of a rectangular shape, adjacent and (topologically) touching each other) [L\u00fcscher, P., Weibel, R. and Burghardt, D.]. Models interpreting shapes in their local embedding are subject of future research. \n\n\n**Comment R5mS-4** Can you comment on the relation to this work: \u201cGraph Contrastive Learning with Implicit Augmentations\u201d, Arxiv, Nov 2022, and graph augmentation in general?\n\n\n> **Response R5mS-4** We were not aware of this preprint, this has only appeared after our submission, thank you for bringing this to our attention. In *Anonymous*, we explore similar graph augmentation techniques, independently. We will cite and contrast our contribution.\n\n\n**Comment R5mS-5** After eqn (9), should the losses all be weighted equally? Should this be tuned for the application?\n\n> **Response R5mS-5** In our study, the GAE reconstruction and contrastive losses are weighted equally. $L = (\\alpha) * (L_N + L_E) + (1 - \\alpha) * L_C$, with $\\alpha$ = 0.5. We have found that in the current experiments an equal weighting of GAE reconstruction loss ($L_N$ + $L_E$, Eq. 5 - 7) and contrastive loss ($L_C$, Eq. 8 - 9) was suitable but in future research we will consider tuning the weights. \n\n**Comment R5mS-6** What are the tradeoffs with the k-NN, and choosing k? How does this potentially help with a search, and does growing k imply more \"incorrect\" or bad cases to be reported?\n\n\n> **Response R5mS-6** We choose $k$ = 6  based on the convergence of the deficit of Haudorff distance between neighbors (i.e., Table 2, row 1, 1st NN -> 2nd NN (0.218 -> 0.238, 0.02 deficit) and 5th NN -> 6th NN (0.265 -> 0.271, 0.006 deficit)). \nIn the t-SNE plot (Figure 2), we observe that both GAEs encode the latent embedding of polygons of similar geometric shapes (or of the same semantic class of alphabet letters) closer in latent space. \nHence the shape extraction task is done by finding the k-nearest neighbors of embedding of query shapes. Intuitively, yes, growing $k$ implies retrieving more cases that are less similar as indicated in quantitative results (Table 1-3). Hausdorff distance of 1st NN is generally lower than 6th NN. \n\n\n**Comment R5mS-7** Section 2.1: This seems intuitive but perhaps good to exactly define \u201clinear ring\u201d.\n\n\n> **Response R5mS-7** According to Open Geospatial Consortium. Opengis simple features specification for SQL revision 1.0, 2003, the linear ring is defined as \u201csimple geometries [aka, without self intersections], where rings are defined by a series of points with linear interpolation between points, and the first and last point are identical.\u201d We will add this to the manuscript."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2269/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700019404884,
                "cdate": 1700019404884,
                "tmdate": 1700029921056,
                "mdate": 1700029921056,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vIJqElFqMQ",
            "forum": "QWgUAx7nIi",
            "replyto": "QWgUAx7nIi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2269/Reviewer_SxCs"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2269/Reviewer_SxCs"
            ],
            "content": {
                "summary": {
                    "value": "The study presents a novel approach, the Contrastive Graph Autoencoder (CGAE), to effectively retrieve polygons with similar shapes from geographic maps, a task that has been challenging due to the complexity of polygon geometries and their susceptibility to transformations like rotation and reflection.\n\nCGAE, utilizing advanced graph message-passing, feature augmentation, and contrastive learning, excels in encoding distinctive latent representations of polygon shapes, facilitating more accurate geometry retrieval. CGAE outperforms traditional graph-based autoencoders (GAEs) through experiments with real-world building map datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. In contrast to traditional models and state-of-art learning-based graph autoencoders, CGAE is independent of polygonal vertex counts\n2. CGAE is capable of retrieving polygons with or without holes\n3. CGAE is robust to polygon reflections and rotations\n4. CGAE can effectively generalize to large polygon datasets"
                },
                "weaknesses": {
                    "value": "Lack of important experimental results that support the conclusions. See questions for details."
                },
                "questions": {
                    "value": "1. The author claimed the proposed method could retrieve polygons with holes better than existing methods, but did not provide quantitative metrics like persistent diagram whose 0-th dimension topological feature represents the number of component and 1-th dimension topological feature represents number of holes. \n\n2. The author claimed the proposed method is free of polygonal vertex counts which is a major benefit over the traditional methods and other graph autoencoders, but I cannot find any experiment results in the paper that can support such claim. Basically CGAE is close to GAE in terms of architecture so why CGAE can scale significantly better than GAE? I think the author should provide more evidences and arguments to this point since it is a critical contribution claimed by the author.\n\n3. Why is CGAE robust to polygon rotations and reflections given that the proposed contrastive loss mainly focuses on local perturbation?\n\n4. Can you clarify this sentence\n\n` CGAE generalizes effectively the geometric information learned from simple polygons to complex shapes, demonstrating a desirable model property, i.e., decoupling of shape detail (i.e., polygon vertex count) from classification accuracy.`\n\nI'm a bit confused about what classification means here."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2269/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698851589260,
            "cdate": 1698851589260,
            "tmdate": 1699636159600,
            "mdate": 1699636159600,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TVBNiLexvI",
                "forum": "QWgUAx7nIi",
                "replyto": "vIJqElFqMQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2269/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2269/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer SxCs Q 1 - 2"
                    },
                    "comment": {
                        "value": "**Comment SxCs-1** The author claimed the proposed method could retrieve polygons with holes better than existing methods, but did not provide quantitative metrics like persistent diagram whose 0-th dimension topological feature represents the number of component and 1-th dimension topological feature represents number of holes.\n\n\n> **Response SxCs-1** Thanks for the suggestion. We update the manuscript by generating persistent diagrams for ten query geometries from the Melbourne dataset (as demonstrated in Appendix, Figure 10-11), showing the number of components (indicated by 0-th dimension topological features) and number of holes (indicated by 0-th dimension topological features). Note that the polygon geometries in Melbourne dataset (in total of 37139 samples) contains varying number of holes and are difficult to quantify as compared to other synthetic datasets (such as Glyph dataset and MNIST-cplx70k dataset in [Mai, Gengchen, et al.]). \n\n**Comment SxCs-2** The author claimed the proposed method is free of polygonal vertex counts which is a major benefit over the traditional methods and other graph autoencoders, but I cannot find any experiment results in the paper that can support such claim. Basically CGAE is close to GAE in terms of architecture so why CGAE can scale significantly better than GAE? I think the author should provide more evidences and arguments to this point since it is a critical contribution claimed by the author.\n\n> **Response SxCs-2** Recall that our models are trained on the synthetic Glyph dataset and tested on real-world building footprints (OSM and Melbourne dataset). The number of vertex counts of the real-world building footprints vary compared to the synthetic dataset. \nThe experimental results demonstrate how the current method is free of vertex count dependency are shown in the Appendix, Figures 10 - 11. Take as example query shapes 3 and 4 ( complex circular polygons with a single hole). The baseline GAE extracts polygons with over-simplified exteriors, which are not geometrically similar to the queries. CGAE, oppositely, can extract polygons with complex exteriors that are similar to the queries. In queries 5 - 7, GAE and CGAE fetch polygons for complex rectangular queries with or without holes. CGAE is capable of extracting rectangular counterparts for complex rectangular queries whereas GAE only identifies over-simplified rectangular polygons. We finally investigate CGAE\u2019s capability of retrieving polygons for complex queries with multiple holes.\nWe update the manuscript by adding additional experiment results in Appendix, Figures 12 - 13. The two figures demonstrate the qualitative results of proposed CGAE and baseline GAE on simplified polygon geometries (with trivial vertices removed) by the topology-preserving Douglas-Peucker algorithm [Saalfeld, Alan.].\nWe also address the comment  \u201cCGAE scales better than GAE\u201d. We do *not* make any such claim - they are equivalent in how they scale, but CGAE is more robust and accurate.\nComparing Figures 6-7 (original sample from OSM dataset in [Yan, Xiongfeng, et al.]) to Figures 8-9 (rotated sample from OSM dataset in [Yan, Xiongfeng, et al.]), we observe how the baseline GAE is sensitive to rotations/reflections of buildings, failing to extract similar shapes when query shapes are rotated. The empirical quantitative results (in Table 1 Glyph-R, and Table 2 OSM-R) further support this claim."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2269/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700019567815,
                "cdate": 1700019567815,
                "tmdate": 1700019567815,
                "mdate": 1700019567815,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Us4cpnwajw",
                "forum": "QWgUAx7nIi",
                "replyto": "vIJqElFqMQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2269/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2269/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer SxCs Q 3 - 4"
                    },
                    "comment": {
                        "value": "**Comment SxCs-3** Why is CGAE robust to polygon rotations and reflections given that the proposed contrastive loss mainly focuses on local perturbation?\n\n\n> **Response SxCs-3** We attribute the CGAE\u2019s robustness to geometric transformations (i.e., rotations and reflections) to two aspects: 1. The Message-passing layers. Empirical results in the ablation study (Table 1, Glyph-R and Table 2, OSM-R) support that argument. GIN and EdgeConv (message-passing backbones) improves model performance on both datasets; and 2. Graph reconstruction based on both node-wise and edge-wise features (Eq. 5-7). In particular, compared to baseline GAE, the proposed CGAE reconstructs graph features from the perturbed node-wise and edge-wise features given by graph augmentations, forcing the graph autoencoder to reconstruct proper graph embedding from the perturbed latent embedding. This is supported by the quantitative results of ($L_N$ + $L_E$) in ablation study (Table 1-2) . \n\n\n**Comment SxCs-4** Can you clarify this sentence \u201cCGAE generalizes effectively the geometric information learned from simple polygons to complex shapes, demonstrating a desirable model property, i.e., decoupling of shape detail (i.e., polygon vertex count) from classification accuracy.\u201d I'm a bit confused about what classification means here.\n\n\n> **Response SxCs-4** We rephrase the sentence into \u201cCGAE generalizes effectively the geometric information learned from simple polygons to complex shapes, demonstrating a desirable model property, i.e., decoupling of shape detail (i.e., polygon trivial vertex count.\u201d) from shape retrieval accuracy."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2269/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700019597084,
                "cdate": 1700019597084,
                "tmdate": 1700019597084,
                "mdate": 1700019597084,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "DWoMncH6yL",
            "forum": "QWgUAx7nIi",
            "replyto": "QWgUAx7nIi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2269/Reviewer_sWPL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2269/Reviewer_sWPL"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a way to encode building footprint polygons using a message-passing graph encoder trained with node, edge and contrastive losses. The method improves upon the cited prior work (Yan et al.) by handling polygons with holes, being more discriminative because of the additional losses, and being more robust to noise via additional augmentations."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The method is well-argued and technically sound, the technical contributions over the cited prior work (Yan et al.) are reasonable, and the results are good."
                },
                "weaknesses": {
                    "value": "I am a little unsure about the magnitude of the contribution here. By and large, it rests on three features:\n\n1. A new (compared to Yan et al., but not new overall) GNN backbone that can accommodate graphs with multiple connected components\n2. An edge-preservation loss.\n3. A contrastive loss.\n\nThese are perfectly reasonable and I have no specific criticisms of these choices. But I am not sure there is any insight that is specific to _polygons_, and as a result the method ends up as a way to retrieve arbitrary graphs (I think) and hence ends up in a much larger solution space of prior work on retrieval from collections of graphs, e.g.\n\nLi et al., \"Graph Matching Networks for Learning the Similarity of Graph Structured Objects\", ICML 2019\n\nor (for 3D layouts) Li et al., \"GRASS: Generative Recursive Autoencoders for Shape Structures\", SIGGRAPH 2017\n\nMinor:\n- Several parts of the text have \"massage-passing\" instead of \"message-passing\""
                },
                "questions": {
                    "value": "Apropos the comments above: what in the method is specific to polygons? Would this work for arbitrary graphs? Could improvements be made by considering the graphs are specifically non-intersecting polygon boundary loops?\n\nThe authors evaluate on the Glyph benchmark but only compare to ablated versions corresponding to a baseline GAE method obtained by ablation (with different backbones). There must be other relevant baseline methods for graph/polygon/glyph/sketch retrieval?\n\nIs there a specific need, in the studied domain of building footprints, to consider the precise topology of the input polygons? E.g. if a straight boundary segment is subdivided into several smaller segments by inserting vertices, the footprint is geometrically the same. But the descriptor will presumably change. Is this desired behavior or not? I understand the authors do additional augmentation to be robust to geometric and topological noise, but this sort of variation appears to be beyond the scope of that augmentation.\n\nIn this context, why not just encode the raster footprints instead of the non-regular vector representations? Building footprints are surely simple enough that the advantages of vector representations for complex geometry don't really apply."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2269/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698956397956,
            "cdate": 1698956397956,
            "tmdate": 1699636159540,
            "mdate": 1699636159540,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jIZuPTIORG",
                "forum": "QWgUAx7nIi",
                "replyto": "DWoMncH6yL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2269/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2269/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer sWPL"
                    },
                    "comment": {
                        "value": "## Reviewer sWPL\n \n**Comment sWPL-1** What in the method is specific to polygons? Would this work for arbitrary graphs? Could improvements be made by considering the graphs are specifically non-intersecting polygon boundary loops?\n \n> **Response sWPL-1** In our submission we focus on the retrieval of *simple* (as in, without self loops , intersections, and tangents) polygons *embedded* in 2D space, with linear segment edges. This provides a strong inferential bias to the retrieval method. The generalisation to arbitrary graphs ( e.g., social networks, etc) that only capture topology, but not geometry is not assured, and not the focus here. In such arbitrary graphs the planarity is not guaranteed. Here, the spatial embedding of the vertices is as important as the ring topology of the vertex connectivity. Hence we assume that any graphs where this method contributes should include, broadly speaking, geometry (shapes) as well as topology (the location of the vertices provides an inferential bias).\n\n**Comment sWPL-2** The authors evaluate on the Glyph benchmark but only compare to ablated versions corresponding to a baseline GAE method obtained by ablation (with different backbones). There must be other relevant baseline methods for graph/polygon/glyph/sketch retrieval?\n\n> **Response sWPL-2** Please, see also Response **sEzw-1**.\n\n**Comment sWPL-3** Is there a specific need, in the studied domain of building footprints, to consider the precise topology of the input polygons? E.g. if a straight boundary segment is subdivided into several smaller segments by inserting vertices, the footprint is geometrically the same. But the descriptor will presumably change. Is this desired behavior or not? \n\n> **Response sWPL-3** We design our system to mimic the perspective of human perception of shapes. This is what is here captured by \u201ctrivial vertex count independence\u201d (i.e., colinear vertices taht do not add \u201cinformation). See response **SxCs-2** and **sEzw-4**.\n\n\n**Comment sWPL-4** In this context, why not just encode the raster footprints instead of the non-regular vector representations? Building footprints are surely simple enough that the advantages of vector representations for complex geometry don't really apply.\n\n> **Response sWPL-4** Rasterization, conceptually equivalent to aggregation of trivial vertices into buckets, does help in some cases (and is the traditional approach to handling vector shape data in ML thus far, with the exceptions noted in the literature review). Then the results will be critically dependent on augmentation, much more than here. Aggregation is also significantly dependent on the granularity of the raster imposed (and leads to artifacts, known in the geographical literature as the modifiable areal unit problem)."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2269/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700018933979,
                "cdate": 1700018933979,
                "tmdate": 1700018933979,
                "mdate": 1700018933979,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JWOfaV8XS5",
                "forum": "QWgUAx7nIi",
                "replyto": "jIZuPTIORG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2269/Reviewer_sWPL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2269/Reviewer_sWPL"
                ],
                "content": {
                    "title": {
                        "value": "Thanks!"
                    },
                    "comment": {
                        "value": "I thank the authors for their responses to my questions. However, I am unfortunately still not convinced the paper is above the acceptance bar.\n\nThe author response still does not clarify why the method is designed in a way specific to simple polygons. I cannot see anything in the architecture specific to simple polygons and not to arbitrary graphs embedded in the plane -- bias towards polygons seems to come only from the training data. (By arbitrary graphs I did not mean graphs that have only topology and no embedding geometry. I meant graphs that are embedded in the plane, but are not necessarily polygons.)\n\nRe baselines, I would include raster baselines, and while such baselines would indeed require augmentation, synthetic augmentation (auto-rotate, reflect, translate, etc) is standard and easy to produce, and raster-based backbones are much better understood and likely more powerful. It is not at all clear to me that raster baselines would be worse than the proposed method in practice, even if they have occasional resolution shortcomings (the test shapes in the paper don't seem to have such high-frequency detail). There should be plenty of work on raster-based retrieval of glyphs or other silhouette images.\n\nI understand the point about simplifying collinear or non-informative vertices via Douglas-Puecker, but as in the other reviewer discussion, it is not clear whether DP can reliably converge to the same unique piecewise linear approximation of a curve starting from two very different oversegmented approximations, or whether the network is (largely) invariant to whatever it does converge to. Much more validation is needed to show that the method is robust to subdivision and discretization choices."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2269/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700711735150,
                "cdate": 1700711735150,
                "tmdate": 1700711735150,
                "mdate": 1700711735150,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "11UJmUpDo1",
                "forum": "QWgUAx7nIi",
                "replyto": "ODjwfxcglB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2269/Reviewer_sWPL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2269/Reviewer_sWPL"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "Thanks for your comments. My point is simply that in assessing contributions to solving a target problem, it helps to look for the design decisions that directly address the specifics of the problem. In this case, the graph encoder is not specific to polygons, leaving open the possibility of better architectures that _do_ take advantage of the specifics of polygonal graphs. Otherwise, the authors get, for want of a better phrase, \"less credit\" for applying an unmodified generic approach.\n\nI disagree re the raster baseline. Building footprints seem particularly well-suited to rasterization, having simple, blocky structure and little high-frequency detail. Even a 512x512 raster would likely be enough in the vast majority of cases, differences finer than one pixel being at the level of natural noise. Many of the most successful retrieval algorithms on other vector representations (e.g. 3D meshes) operate via raster algorithms (e.g. see Su et al., \"Multi-view Convolutional Neural Networks for 3D Shape Recognition\", ICCV 2015). The storage representation need not constrain the retrieval representation -- I do not understand in which practical context a pure vector algorithm is \"sorely missing\".\n\nRe DP, sorry if that was unclear. By \"convergence\" I simply meant the result of applying DP to a point sequence. Of course it is deterministic (modulo degeneracies or symmetries). What I meant was that if the same canonical curve (say a circle) is approximated with two different piecewise linear sequences (which might naturally happen because of noise or human bias), and then you simplified each independently with DP, then the two simplified results would very likely not be identical, and your algorithm may or may not be robust to the differences."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2269/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700717431075,
                "cdate": 1700717431075,
                "tmdate": 1700717431075,
                "mdate": 1700717431075,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]