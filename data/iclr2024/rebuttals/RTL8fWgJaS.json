[
    {
        "title": "Self-Specialization: Uncovering Latent Expertise within Large Language Models"
    },
    {
        "review": {
            "id": "hu3hs512uX",
            "forum": "RTL8fWgJaS",
            "replyto": "RTL8fWgJaS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6554/Reviewer_PQqS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6554/Reviewer_PQqS"
            ],
            "content": {
                "summary": {
                    "value": "This study is driven by the observed limitations of pre-trained large language models (LLMs) when handling specialized tasks, particularly in the biomedical question and answering domain.\n\nThe underlying issues stem from the practice of fine-tuning these LLMs on broad instruction datasets, which often results in only marginal enhancements for niche domains.\n\nTo address this, the authors introduce a novel technique termed \"self-specialization.\" Unlike the conventional self-alignment method, self-specialization incorporates domain-specific seeds and an external knowledge retriever. This strategy cultivates an instruction dataset tailored to the specific needs of the target domain.\n\nEmpirical results highlight the efficacy of this approach: LLMs that underwent self-specialization significantly outperformed their non-specialized counterparts."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Methodology: The self-specialization technique introduced is both straightforward and powerful. The authors effectively demonstrate that, by refining the instruction dataset for a target domain, one can substantially elevate the performance of an LLM.\n\n- Results: The outcomes are compelling. The self-specialized technique not only outpaces the baseline LLM with general instruction tuning across various NLP tasks, but even a 30B self-specialized model can occasionally surpass larger models of 65B capacity.\n\n- Structured Presentation & Clear Communication: This research is characterized by its lucid motivation and coherent narrative, seamlessly bridging the gap between identified issues and the proposed solutions. The results are presented with clarity, reinforcing the dominance of the introduced methods."
                },
                "weaknesses": {
                    "value": "At its core, the proposed method is somewhat an amalgamation of existing concepts. While termed \"self-specialization\", it essentially contrasts with \"self-alignment\" (for instance, as seen in Alpaca) and incorporates \"domain-specific knowledge-guided generation\". The enhancements observed are not surprising since the retrieval-augmented generation, grounded on specific knowledge retrieval, naturally offers a more thorough and targeted knowledge base for instruction tuning. Thus, one could argue that self-specialization is essentially self-alignment augmented with RAG, somewhat constraining its novelty.\n\nFurthermore, rather than relying on RAG to generate the instruction dataset with the foundational model, the authors might have delved deeper into refining the dataset construction process. Several uncharted avenues remain: (1) devising superior methods for seed generation, considering aspects like topic ratios or instruction diversity; (2) optimizing answer generation for the instructions, with focus on enhancing and validating answer quality. Regrettably, this research offers only a cursory exploration in these dimensions."
                },
                "questions": {
                    "value": "- In 4.1, the authors mentioned 5K synthetic instruction dataset is generated. Was there any reason for this number? If we increase/decrease the number, how would the yielded instruction-tuned model perform?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6554/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6554/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6554/Reviewer_PQqS"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6554/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697998554715,
            "cdate": 1697998554715,
            "tmdate": 1699636740071,
            "mdate": 1699636740071,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wFXfTZIOfb",
                "forum": "RTL8fWgJaS",
                "replyto": "hu3hs512uX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for your thoughtful and constructive review of our work. We appreciate your positive comments on our method, results, and presentations, as well as your concerns on our contributions. Down below, we address each of your comments and questions in detail.\n\n>***At its core, the proposed method is somewhat an amalgamation of existing concepts. ...***\n\nWe appreciate your valuable comments. While our method builds upon existing concepts of self-alignment and retrieval-augmentation, its unique angle lies in its efficient and practical use of the latent knowledge within LLMs to specialize them. This is a significant departure from standard general self-alignment and demonstrates a novel application in the field of domain specialization. While retrieval-augmentation is generally recognized for enhancing model capabilities at inference, our work explores its impact within a self-alignment (i.e., data generation) framework, which was unknown. In fact, one of the interesting and surprising findings we demonstrated was the effectiveness of self-specialization even without relying on the retrieval component while it does help to some extent, highlighting its simplicity and practicality. \n\nFinally, we would also like to note that our observation that language model specialization can be achieved in a parameter-efficient (QLoRA) way and by applying (our updated) self-alignment technique is new and valuable. This opens an exciting opportunity for efficient multi-specialized models, where a single base LLM is loaded once and is surrounded by a set of low-memory-footprint specialized modules in-memory, delivering all the specialization of interest without re-loading, a highly practical scenario enabled by our work. As an example, we successfully self-specialized the same LLaMA-2-7B base model to both biomed and finance domains, enabling the aforementioned efficient serving of specialization scenarios.\n\n>***Furthermore, rather than relying on RAG to generate the instruction dataset with the foundational model, the authors might have delved deeper into refining the dataset construction process. \u2026***\n\nWe thank you for your insightful suggestions regarding the refinement of the dataset construction process. Your points about exploring advanced methods for seed generation and optimizing answer generation are indeed valuable. In our current research, while we have initiated steps towards these directions, the primary focus has been on demonstrating the efficacy of the self-specialization approach itself. We believe our initial effort in this direction can serve as a foundational framework, unveiling for the first time (to the best of our knowledge) the possibility of effectively specializing models in a parameter-efficient way and without any expensive specialization domain data collection, by extracting the specialization data from the model itself. We believe our work opens interesting opportunities for further exploration and advanced refinement upon our work in future work.\n\n>***In 4.1, the authors mentioned 5K synthetic instruction dataset is generated. Was there any reason for this number? \u2026***\n\nThe selection of this number was simply a pragmatic decision, balancing computational feasibility with the need for a sufficiently diverse set of instructions for effective model specialization. We recognize that variations in dataset size could impact performance, typically with smaller datasets potentially leading to poorer results and larger ones to better results to some extent. We do think how to select the optimal number of synthetically generated data depending on target domains/tasks could be another interesting dimension to investigate, since this is challenging in low-data scenarios where automatic hyperparameter tuning might be infeasible, as also seen in previous works on self-alignment [1, 2], which relies on arbitrary numbers.\n\n[1] Wang, Yizhong et al. \u201cSelf-Instruct: Aligning Language Models with Self-Generated Instructions.\u201d ACL 2023.\n\n[2] Sun, Zhiqing et al. \u201cPrinciple-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision.\u201d Neurips 2023."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6554/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699899112967,
                "cdate": 1699899112967,
                "tmdate": 1699899112967,
                "mdate": 1699899112967,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MkxDSzs27Q",
                "forum": "RTL8fWgJaS",
                "replyto": "hu3hs512uX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking Forward to Your Reply"
                    },
                    "comment": {
                        "value": "Dear Reviewer PQqS, \n\nSince the discussion period is ending tomorrow, we would greatly appreciate it if you could take a look at our response to your review and let us know if you have any remaining questions. Otherwise, we would really appreciate it if you could support the paper by increasing the score. We look forward to hearing from you and addressing any remaining concerns before the end of the discussion period.\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6554/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700590963816,
                "cdate": 1700590963816,
                "tmdate": 1700590963816,
                "mdate": 1700590963816,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gLRzB8sF2u",
                "forum": "RTL8fWgJaS",
                "replyto": "MkxDSzs27Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6554/Reviewer_PQqS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6554/Reviewer_PQqS"
                ],
                "content": {
                    "title": {
                        "value": "Thanksf for youre response"
                    },
                    "comment": {
                        "value": "Thanks for the response from the authors. I generally agree with the empirical gain and practical value of the work. The proposed \"self-alignment in domain specialization\" is interesting and is important in practice. However, I would like to keep the score since there still lies the concern about the novelty and technical depth of the proposed framework. As mentioned before, the way this framework achieves \"domain specialization\" lies in retrieving domain knowledge and augmenting the teacher large language model, which is worth a deeper exploration. The proposed \"qLoRA\" scenario is interesting but is not considered as the contribution of this paper."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6554/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700615849017,
                "cdate": 1700615849017,
                "tmdate": 1700615849017,
                "mdate": 1700615849017,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mF1aR8rk5G",
                "forum": "RTL8fWgJaS",
                "replyto": "hu3hs512uX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank You for Sharing Your Perspective!"
                    },
                    "comment": {
                        "value": "Thank you for sharing your perspective! It appears there might be a misunderstanding about the role of retrieval augmentation, which we would like to clarify. In our work, the primary mechanism for achieving domain specialization in large language models (LLMs) is not predominantly reliant on retrieval augmentation. Instead, our approach focuses on uncovering and leveraging the latent expertise within LLMs themselves. The novelty of our method lies in its ability to tap into this inherent capacity of LLMs to specialize in specific domains, rather than merely the use of retrieval augmentation.\n\nIn support of this, we refer you to the results presented in Table 2 of our paper. Here, we demonstrated the significant effectiveness of our self-specialization, independent of the retrieval component, where we observed an 8.5 F1 improvement compared to the base model, which is surprising. You mentioned that the enhancement through retrieval augmentation is not surprising - the reality is that the contribution of retrieval in self-specialization is relatively marginal, less than 1 point. \n\nWe would like to re-emphasize that while retrieval augmentation does play a role in our framework, it serves as an additional enhancement rather than a fundamental necessity. We hope this clarification sheds light on the fundamental aspects of our approach and reassures the intended focus of our research."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6554/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700628957662,
                "cdate": 1700628957662,
                "tmdate": 1700628957662,
                "mdate": 1700628957662,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "TYt3sx7sOB",
            "forum": "RTL8fWgJaS",
            "replyto": "RTL8fWgJaS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6554/Reviewer_CV1V"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6554/Reviewer_CV1V"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a self-specialization mechanism to automatically generate domain-specific instructional data and improve language model performance within specialized domains. The proposed approach is straightforward: 1) sample seed instructions from established NLP benchmarks within the target domain; 2) utilize the language model to generate new domain-specific instructions based on the initially sampled seeds; 3) employ domain-relevant unlabeled documents to generate responses corresponding to the generated instructions; 4) fine-tune the language model using the synthesized instructions, resulting in the development of a final domain-specialized model."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well-motivated, as specializing the language model in a specific domain is an area of interest. Additionally, the paper is well-structured and easy to follow."
                },
                "weaknesses": {
                    "value": "Despite the promising results reported in this paper within the biomedical domain, I still feel uncertain about its contribution for the following reasons:\n1) The experimental results are not convincing. Table 1 reports the comparative results of the base model and the self-specialized model, with the authors stating \"the scores (F1) witness a rise from 25.15 to 36.63 in a zero-shot setting.\" However, this is the average result, and the datasets \"BioASQ-Yesno\" and \"Medical Drugs\" contribute the most differences, with a difference of around 60-70 in \"BioASQ-Yesno. I highly doubt the correctness of the results for this dataset. This is a binary classification dataset, and the base model performs much worse than random guessing (50.0 if labels are balanced), which is the first odd point. Secondly, as the number of demonstrations increases, the F1 score of the base model surprisingly decreases. This implies that the base model must learn information from the prompted demonstrations. If the model is not performing well on a dataset, the F1 score should remain almost the same or should not exhibit such consistent declines. I am considering if the authors mistakenly reversed the labels of \"yes\" and \"no,\" leading to these counterintuitive results.\nIf we exclude the \"BioASQ-Yesno\" and \"Medical Drugs\" datasets, the average F1 score improvement is down to around 2.5, far less than the reported 11.48 (36.63 - 25.15). This makes doubt not only on the reported results in Table 1 but also on Fig. 4 and its claims of the model's superiority over all 65B models despite its \u22482.2x smaller size.\n2) The Gouge-L scores for the \"DDI\" and \"Medical\" datasets are identical to their respective F1 scores. I haven't investigated if this is possible, but please check the reported results carefully.\n3) During the seed generation phase, the proposed method requires the NLP benchmarks in the target domain. This limits the proposed approach to extend to other domains, as not all domains have this NLP benchmark accessible. With the paper using 80 seeds, one possible solution could be manually generating them; however, the paper didn't mention this point.\n4) How about the results if applying the proposed scheme to a larger model, such as LLaMA-65B? The base model used in the paper initially shows not good results (20-30 F1 scores), which are relatively easy to improve. If a larger model with better initial results is used, is it still feasible to have improvement through the proposed scheme? \n5) Some places lack professional writing. For example, in Eq. (3), $p_{lm}$ is introduced without prior definition. While the intended meaning may be inferred, a scientific paper should maintain consistency and rigor in its notation and explanations."
                },
                "questions": {
                    "value": "Please consider the questions I listed in the Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6554/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698677222599,
            "cdate": 1698677222599,
            "tmdate": 1699636739912,
            "mdate": 1699636739912,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "WvxkWOledm",
                "forum": "RTL8fWgJaS",
                "replyto": "TYt3sx7sOB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for your thoughtful and constructive review of our work. We appreciate your positive comments recognizing the motivation of our work, and the quality of our paper, as well as concerns which we understand. Down below, we address each of your comments in detail.\n\n>***The experimental results are not convincing. \u2026***\n\nWe truly appreciate your critical scrutiny of our results, particularly the below-random performance observed on the \u201cBioASQ-Yesno\u201d, which is one out of 10 different datasets we evaluated. The nature of our evaluation is indeed the key to understanding these results. In our study, as described in Section 4.1, we treat all tasks as a unified text generation problem, aiming to assess the realistic capabilities of following instructions, consistent with established practices in biomedical instruction tuning literature [1]. This means that the model could generate responses that are not confined to \u201cyes\u201d or \u201cno\u201d labels, but rather any possible sequence of text, including those that are entirely out of the space of expected answers, not following and understanding the specialized instructions. Even if converting the minimum F1 score as 50 (random guessing), the average difference between the self-specialized and base model will be 8.6 (36.63 - 28.03), which is still significant. However, we believe that our current evaluation is fairer and preferable, because in a realistic scenario where a user prompts a model to solve a certain task (e.g., classification) without the assumption about a task type, and gets a totally wrong response out of the label space, evaluating such a response as correct would not make sense.\n\nIn response to the second point about the decreased performances with increased demonstrations in 2 out of 10 datasets, after careful examination, we can assure that the labels (e.g., \u201cyes\u201d and \u201cno\u201d) were correctly applied, and there was no reversal issue in our evaluation. The decrease in scores can be rather attributed to the model's sensitivity [2] or interference among demonstrations [3] under in-context learning (ICL). In fact, it can even be noticed in the original GPT-3 paper [4] that additional demonstrations do not always lead to better performance and can indeed sometimes result in a notable decrease, demonstrating an inherent challenge in ICL. Taking the best, average, worst over different k-shot (0, 1, 5) configurations for each dataset to address the concern of sensitivity to some extent, we still observed significant gaps compared to the base one (please see the table of results below and Table 4 in Appendix).\n\nWe updated our paper to include these clarifications to address your concerns. We firmly believe our results are correct. To further alleviate any doubts, we kindly refer you to Table 1 in Section 4.2 where we have extended our experiments to the financial domain, employing various (10) datasets to demonstrate the validity and versatility (up to 14.53 average gain).\n\n| \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | Best \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | Average\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | Worst\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\n|---------------|--------------------|--------------------|--------------------|\n| **Dataset** \u00a0 \u00a0 \u00a0 | **Base / Self-Spec.**\u00a0 | **Base / Self-Spec.**\u00a0 | **Base / Self-Spec.**\u00a0 |\n| BioASQ-Factoid | 51.96 / **57.61**\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 43.47 / **50.00** \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 30.9 / **37.35**\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\n| BioASQ-List\u00a0 \u00a0 | **47.57** / 46.99\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 42.91 / **44.57** \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 35.09 / **42.17** \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\n| BioASQ-Yesno \u00a0 | 21.20 / **95.20** \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 13.60 / **91.49**\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 8.80 / **85.27** \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\n| PubMedQA \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | **31.69** / 31.31\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 24.19 / **26.78** \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 11.98 / **24.16** \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\n| AnatEM \u00a0 \u00a0 \u00a0 | 9.63 / **21.25** \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 7.93 / **16.33**\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 6.59 / **11.99**\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\n| BioNLP13CG \u00a0 \u00a0 \u00a0 \u00a0 | 26.03 / **41.16**\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 24.19 / **32.63** \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 21.76 / **24.93** \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\n| NCBI \u00a0 \u00a0 | 27.88 / **46.54**\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 21.44 / **34.67** \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | **17.99** / 14.35 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\n| DDI\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 51.00 / **53.4**\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 49.86 / **51.47** \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 49.20 / **49.4** \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\n| Medical Drugs\u00a0 | 35.00 / **65.80**\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 19.27 / **51.07** \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 11.40 / **32.80**\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\n| HoC\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | **62.84** / 62.65\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | **26.40** / 25.42\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 2.44 / **6.01** \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\n| **Average**\u00a0 \u00a0 | 36.48 / **52.19**\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 27.33 / **42.44** \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 19.62 / **32.84** \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6554/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699898899421,
                "cdate": 1699898899421,
                "tmdate": 1699898899421,
                "mdate": 1699898899421,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sIt69nHUGb",
                "forum": "RTL8fWgJaS",
                "replyto": "TYt3sx7sOB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking Forward to Your Reply"
                    },
                    "comment": {
                        "value": "Dear Reviewer CV1V, \n\nSince the discussion period is ending tomorrow, we would greatly appreciate it if you could take a look at our response to your review and let us know if you have any remaining questions. Otherwise, we would really appreciate it if you could support the paper by increasing the score. We look forward to hearing from you and addressing any remaining concerns before the end of the discussion period.\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6554/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700590926575,
                "cdate": 1700590926575,
                "tmdate": 1700590926575,
                "mdate": 1700590926575,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ovcz9U3K2e",
                "forum": "RTL8fWgJaS",
                "replyto": "sIt69nHUGb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6554/Reviewer_CV1V"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6554/Reviewer_CV1V"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your response! I appreciate your effort to improve the paper.  However, this does not change the problem of the lack of novelty and technique contribution of the paper. I will my score unchanged."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6554/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700621243989,
                "cdate": 1700621243989,
                "tmdate": 1700621243989,
                "mdate": 1700621243989,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lzwFEh4Zwi",
                "forum": "RTL8fWgJaS",
                "replyto": "TYt3sx7sOB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank You for Your Reply!"
                    },
                    "comment": {
                        "value": "Thank you for your reply! We are glad to see your recognition of our efforts to improve our paper based on your review. Unfortunately, we do not see any comments about the novelty or technical aspects in your review. Rather, it was primarily about the validity of experiments, leading to a score of 3. We sincerely thank you for your critical evaluation, as it has provided us with the opportunity to improve our paper. We believe our response along with additional experiments effectively addressed your concern mentioned in the review. We respectfully request a reconsideration of your assessment of our work. We remain open to any further feedback or clarifications you may deem necessary."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6554/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700629245763,
                "cdate": 1700629245763,
                "tmdate": 1700629245763,
                "mdate": 1700629245763,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "msMvr8IOkK",
            "forum": "RTL8fWgJaS",
            "replyto": "RTL8fWgJaS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6554/Reviewer_Kzpe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6554/Reviewer_Kzpe"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on self-alignment for expert domain specialization. It first conducts a benchmarking of existing aligned models, i.e., Alpaca-65B and Dromedary-65B, revealing that existing self-aligned models achieve marginal improvements compared to the original model. Then, it proposes a self-specialization method that leverages domain-specific unlabelled data and a few labeled seeds for the self-alignment process. The experiments on a medical domain show the proposed method outperforms its base model, and larger popular models as well."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The topic of specialization is important for deploying LLM to a specified domain.\n2. The paper is well-written and easy to follow.\n3. The idea of self-specialization is interesting, which utilizes both seed instructions and generated ones together.\n4. Several experiments are conducted to evaluate the proposed method. The proposed self-specialization method outperforms the base model and larger LLaMA variants."
                },
                "weaknesses": {
                    "value": "1. The benchmark only includes two aligned models. Better to include more aligned models for comprehensive benchmarking.\n2. It claims that 'we hypothesize that the model expertise in different domains resides in \u201csuperposition\u201d in the model\u2019s parameters and hidden states'. But there are no further theoretical explanations or experimental results to support this claim. If the \"superposition\" could be explained in details, the application scope of the proposed method may be more clear.\n3. The metrics of the y-axes should be added in figure 2 and 5."
                },
                "questions": {
                    "value": "1. Why do you choose the two aligned models? Why not include other models for benchmarking?\n2. Does the selection of seed instructions affect the final performance? If so, how do you eliminate this effect?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6554/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6554/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6554/Reviewer_Kzpe"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6554/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698681420796,
            "cdate": 1698681420796,
            "tmdate": 1699636739747,
            "mdate": 1699636739747,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pVioK2WM9w",
                "forum": "RTL8fWgJaS",
                "replyto": "msMvr8IOkK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate your positive reviews recognizing the importance of the topic, the quality of the paper, the idea, and the efforts on experiments. Down below, we address each of your comments and questions in detail.\n\n>***Why do you choose the two aligned models? Why not include other models for benchmarking?***\n\nThank you for your inquiry regarding our choice of aligned models for benchmarking. Our decision was driven by specific criteria aligned with the key scenarios and objectives of our study. A central aspect of our research is the exploration of self-specialization under low-data scenarios. In this context, self-aligned models that are developed from scratch, such as Dromedary, are particularly relevant. These models represent a critical baseline for comparison as they do not rely extensively on large volumes of human-labeled data. At the time of our benchmarking, Dromedary was considered new and a strong model in this category. While Alpaca, which utilizes GPT-3.5 instead of LLaMA-65B for data generation, does not strictly fall under the category of self-aligned models, it was included to provide a benchmark for the upper bounds of performance achievable through automatic alignment methods.\n\nIn response to Reviewer T5kV\u2019s request, we have also conducted additional experiments comparing our self-specialized model with models that have undergone domain-specific pre-training (MedLLaMA-13B and PMC-LLaMA-7B/-13B, please see Figure 7 and Appendix C for the results). In short, the results indicate that our self-specialized 7B model is better than the 13B baselines including the one pre-trained on a huge domain-specific corpus (i.e., medicine) and the one further instruction-tuned using labeled data. Moreover, we also show (in the same Fig. 7, Appendix C) that our approach can be effectively applied on top of domain-specific pre-training demonstrating even further gains without requiring any additional (costly to collect) domain-specific data.\n\n>***It claims that 'we hypothesize that the model expertise in different domains resides in \u201csuperposition\u201d in the model\u2019s parameters and hidden states'. But there are no further theoretical explanations or experimental results to support this claim. ...***\n\nWe appreciate your interest in our intuition. We concur that this concept, which posits that domain-specific knowledge exists in a latent form within LLMs, is a foundation of our approach. Our hypothesis is grounded in the idea that these models, due to their extensive pre-training on diverse datasets, inherently possess a broad spectrum of knowledge, which is not explicitly structured but rather intermingled within their parameters and hidden states.\n\nTo empirically validate, we demonstrated the effectiveness and versatility of our self-specialization method across various domains (biomediacal and sports domains in the original paper, and also for the finance domain in response to Reviewer T5kV\u2019s comment). These experiments show that by explicitly leveraging this latent knowledge, we can significantly enhance the model's performance in specific domains. For example, we successfully self-specialized the same LLaMA-2-7B base model to both biomed and finance domains enhancing its performance in both, thus supporting our hypotheses that these expertises have been \u201csuperimposed\u201d inside that model, while our self-specialization approach helped surface them. These results serve as practical evidence supporting our hypothesis, illustrating that LLMs can be effectively aligned to specific domains despite the latent and unstructured nature of their knowledge.\n\nWe believe that the theoretical exploration of this hypothesis would be both important and intriguing. However, such an investigation would extend beyond the scope of our initial study, which focuses on the practical application and empirical validation of the concept.\n\n>***The metrics of the y-axes should be added in figure 2 and 5.***\n\nThank you for pointing this out! We explicitly added the used metrics, the F1 score, to figures 2 and 5."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6554/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699898744205,
                "cdate": 1699898744205,
                "tmdate": 1699898744205,
                "mdate": 1699898744205,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "S8dAqMaTaE",
                "forum": "RTL8fWgJaS",
                "replyto": "msMvr8IOkK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking Forward to Your Reply"
                    },
                    "comment": {
                        "value": "Dear Reviewer Kzpe, \n\nSince the discussion period is ending tomorrow, we would greatly appreciate it if you could take a look at our response to your review and let us know if you have any remaining questions. We look forward to hearing from you and addressing any remaining concerns before the end of the discussion period.\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6554/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700590851562,
                "cdate": 1700590851562,
                "tmdate": 1700590902891,
                "mdate": 1700590902891,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MaRHyQozue",
                "forum": "RTL8fWgJaS",
                "replyto": "S8dAqMaTaE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6554/Reviewer_Kzpe"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6554/Reviewer_Kzpe"
                ],
                "content": {
                    "title": {
                        "value": "Response to the comments from the authors"
                    },
                    "comment": {
                        "value": "Dear authors,\n\nThanks for the clarification. I also appreciate your efforts on improving the paper. I will keep my score and have no further questions.\n\nBest"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6554/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700642371196,
                "cdate": 1700642371196,
                "tmdate": 1700642371196,
                "mdate": 1700642371196,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ANdAjxWhid",
            "forum": "RTL8fWgJaS",
            "replyto": "RTL8fWgJaS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6554/Reviewer_T5kV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6554/Reviewer_T5kV"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a method called self-specialization, which extends the self-instruct method to a specific domain. The experimental results are evaluated on a set of biomedical tasks using two LLMs. The problem addressed in this paper is interesting and the experiment results show promise. However, the paper can be significantly improved by generalizing the proposed method to at least another domain, as the main contribution of the paper lies in the proposal of a method for domain specification. Additionally, the effectiveness of the proposed method, which is based on finetuning, needs to be clarified as the baseline performance is based on in-context learning. To improve the clarity of the method, an ablation study should be included, e.g., examining the contribution of domain-specific response generation to the overall performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is well-written and easy to follow, providing sufficient technical details. The authors also mention that the data, code, and trained model will be open source.\n- The empirical findings demonstrate that incorporating unlabeled data positively impacts the model's ability to effectively respond to queries within a specialized domain, particularly in the challenging context of biomedical research."
                },
                "weaknesses": {
                    "value": "- The proposed method, self-specialization, is an extension of the self-instruct [1] work to recover certain expertise in the LLMs. However, the method is only designed and evaluated for one specific domain without showcasing its generalization ability to other domains.\n- The compared methods in the paper are based on zero-shot/few-shot settings, while the proposed method uses LoRA for finetuning. It would be beneficial to include stronger task-specific comparison methods to better illustrate the effectiveness of the proposed approach.\n- Since the method has multiple components, it would be helpful to show the contribution of each component to the overall performance. For example, how does domain-specific response generation impact the final results?\n- The performance in the knowledge sparse domain is uncertain. It is understood that domain response generation involving harnessing knowledge is one of the main contributors to the specification, but it is important to understand the method's bottleneck when existing knowledge is limited for certain domains.\n- The paper should discuss potential data contamination and address how the authors ensure that the data for downstream testing does not overlap with the generated data.\n\n[1] Wang, Yizhong, et al. \"Self-instruct: Aligning language model with self generated instructions.\" arXiv preprint arXiv:2212.10560 (2022)."
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6554/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699043898243,
            "cdate": 1699043898243,
            "tmdate": 1699636739635,
            "mdate": 1699636739635,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "u9j7e6G081",
                "forum": "RTL8fWgJaS",
                "replyto": "ANdAjxWhid",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for your thoughtful and constructive review of our work. We appreciate your positive comments recognizing the quality of our paper and our findings, as well as your concerns to improve our work. Down below, we address each of your comments in detail.\n\n>***The method is only designed and evaluated for one specific domain without showcasing its generalization ability to other domains.***\n\nWe understand your concern about the generalizability of our method to other domains. To address your concern, we have evaluated our Self-Specialization method on the finance domain (10 popular financial NLP datasets covering 6 tasks), demonstrating similar effectiveness (up to 14.53 average gain) to the one observed for biomedicine. The finance domain results have been added to Table 1. This new result, along with our original findings in biomedicine, showcases the versatility of our self-specialization approach across varied specialization domains.\n\n>***The compared methods in the paper are based on zero-shot/few-shot settings, while the proposed method uses LoRA for finetuning. \u2026***\n\nIn our study, the primary objective was to enhance the base model's domain-specific capabilities through self-specialization, a process inherently different from conventional fine-tuning approaches. Although the process utilizes LoRA for specialization, it is important to note that our approach fundamentally relies on synthetic data generated by the model itself. This unique aspect sets our method apart, as it effectively starts from scratch, focusing on self-generated, domain-specific instructional data for low-data scenarios. Finally, the base model and the base model improved through our Self-Specialization (using synthetic self-generated data) are compared fairly in the same zero-shot/few-shot setting. Hence we believe the comparison is fair.\n\nNevertheless, in response to your valuable feedback, we have conducted additional experiments comparing our self-specialized model with models that have undergone domain-specific pre-training (MedLLaMA-13B and PMC-LLaMA-7B/-13B, please see Figure 7 and Appendix C for the results). In short, the results indicate that our self-specialized 7B model is better than the 13B baselines including the one pre-trained on a huge domain-specific corpus (i.e., medicine) and the one further instruction-tuned using labeled data. In the same Figure (Fig. 7, Appendix C) we also show that our Self-Specialization can be effectively applied on top of the domain specific pre-training demonstrating further improvements, thus underlining even more its practical potential.\n\n> ***Since the method has multiple components, it would be helpful to show the contribution of each component to the overall performance. \u2026***\n\nFor the component contribution, we kindly refer the reviewer to section 4.3 where we provide ablations & analyses including the effect of domain-specific response generation (i.e., external knowledge)."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6554/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699898416570,
                "cdate": 1699898416570,
                "tmdate": 1699898416570,
                "mdate": 1699898416570,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Ya5mz74rNT",
                "forum": "RTL8fWgJaS",
                "replyto": "ANdAjxWhid",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking Forward to Your Reply"
                    },
                    "comment": {
                        "value": "Dear Reviewer T5kV, \n\nSince the discussion period is ending tomorrow, we would greatly appreciate it if you could take a look at our response to your review and let us know if you have any remaining questions. Otherwise, we would really appreciate it if you could support the paper by increasing the score. We look forward to hearing from you and addressing any remaining concerns before the end of the discussion period.\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6554/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700590800202,
                "cdate": 1700590800202,
                "tmdate": 1700590800202,
                "mdate": 1700590800202,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5HEbsmkMAv",
                "forum": "RTL8fWgJaS",
                "replyto": "Ya5mz74rNT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6554/Reviewer_T5kV"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6554/Reviewer_T5kV"
                ],
                "content": {
                    "title": {
                        "value": "Official Review"
                    },
                    "comment": {
                        "value": "Thanks for your detailed response! I will keep my score since the method's performance in evaluated domains, and contributions from different modules are not convincing, as well as model's overall performance can be significantly attributed to the data overlap."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6554/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700696353998,
                "cdate": 1700696353998,
                "tmdate": 1700696353998,
                "mdate": 1700696353998,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "01gWlynbUU",
                "forum": "RTL8fWgJaS",
                "replyto": "ANdAjxWhid",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6554/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank You for Your Reply"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their thoughtful comment, yet we would like to respectfully disagree. The whole point of our self-specialization approach is to improve the model\u2019s specialized domain performance using self-generated synthetic data. The fine-tuning data in our approach is self-generated by the model and hence there can be no overlap between fine-tuning data and target domain data. If the reviewer is worried about any potential overlap between target domain test data and the base model pre-training, then please note that we always compare the base model performance and our self-specialized model performance. Intuitively, both models share the same real data pre-training by design, hence our improvement (using only synthetic self-generated data) is completely fair. This is further strengthened by the fact that our main specialization performance gains could be obtained without any retrieval - on synthetic self-generated data alone. No matter whether the reviewer agrees with our arguments, we would like to thank the reviewer for giving us the opportunity to improve our paper."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6554/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700703567305,
                "cdate": 1700703567305,
                "tmdate": 1700703567305,
                "mdate": 1700703567305,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]