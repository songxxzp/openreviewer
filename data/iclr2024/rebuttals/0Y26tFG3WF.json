[
    {
        "title": "Inducing Precision in Lagrangian Neural Networks : Proof of concept application on Chaotic systems"
    },
    {
        "review": {
            "id": "AM5rZnrwGG",
            "forum": "0Y26tFG3WF",
            "replyto": "0Y26tFG3WF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
            ],
            "content": {
                "summary": {
                    "value": "This paper aims to approximate chaotic systems using Lagrangian Neural Networks (LNN) with better precision. A new LNN architecture is proposed to emphasize the importance of significant bits. A new regularization term is added to ensure the accuracy of each significant bit. Experimental results demonstrate that the proposed LNN can achieve better precision."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. It is important to pursue precision when approximating chaotic systems since a small error can cause long-term large errors.\n2. The proposed method is succinct and easy to understand.\n3. Experimental results verify the efficacy of the proposed method."
                },
                "weaknesses": {
                    "value": "The motivation of the regularized term is not convincing. Adding a regularization term is a tradeoff between the original objective (Eq. (7)) and the regularization term (Eq. (9)). In common cases, minimizing the regularization term will make the original objective larger. In this paper, the original objective cares more about higher decimals, while the regularization treats all decimals equally. Thus, adding the regularization term will inevitably sacrifice the accuracy of higher decimals, which hurts the original objective. To my understanding, the original objective already reflects the precision requirement when approximating chaotic systems, and the regularization term only plays a negative role."
                },
                "questions": {
                    "value": "There are many minor problems in this paper. Part of them are listed below.\n1. In the tile, the colon is closer to proof rather than networks.\n2. In the abstract, the abbreviation LNN appears on the 3rd line but its full name still occurs on the 10th line. After the abbreviation appears for the first time, it would be better to use the abbreviation rather than the full name.\n3. On the 2nd line in the introduction, the citation is of the form \"Name (year)\". But the name is not a part of the sentence, thus it would be better to use the form \"(Name, year)\".\n4. Above Eq. (1), \"it's\" should be \"its\".\n5. The first paragraph in the introduction is too long (more than 1 page), and readers may lose the central idea easily. It would be better to separate it into several paragraphs.\n6. Below Eq. (2), \"maybe\" should be \"may be\".\n7. Significant digits or significant bits are not defined.\n8. The form of citation of equations is not unified. Both \"Equation 6\" and \"Eqn. 6\" occur."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6604/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698318638390,
            "cdate": 1698318638390,
            "tmdate": 1699636752693,
            "mdate": 1699636752693,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5MofVgWe1p",
                "forum": "0Y26tFG3WF",
                "replyto": "AM5rZnrwGG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "The authors of this paper would like to thank the reviewer for the considerate comments and verbose and corrections pointed out. The revised manuscript has addressed the comments. \n\nRegarding Weaknesses pointed out :\n\nA straightforward explanation would be that the relative squared error approximates heavily on solution space approximates where there is considerable deviation from the expected solution space. In other words the squared error approximates has a natural weighting towards the most significant bits of interest, due to the relative increase of its penalty magnitude in the event of misprediction of a more significant bit. The regularization term acts as the explicit and equally weighted conditioning for estimating the relative accuracy of the predicted set of significant bits, independently. To sum up, the negative log likelihood loss must be minimized along with the prediction loss so as to obtain optimality."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700458684394,
                "cdate": 1700458684394,
                "tmdate": 1700458684394,
                "mdate": 1700458684394,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gAV2cBWEyu",
                "forum": "0Y26tFG3WF",
                "replyto": "5MofVgWe1p",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for answering. It is true that both significant bits (i.e., higher decimals) and other bits (i.e., lower decimals) are important and we should optimize all of them in the ideal case. But in most problems, we cannot minimize the square loss term and the regularization term at the same time. By adding the regularizer, we may sacrifice the square loss. Thus, I persist that the regularization is not well motivated and prefer to maintain my rating unchanged."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700490759463,
                "cdate": 1700490759463,
                "tmdate": 1700490759463,
                "mdate": 1700490759463,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KPHT6iDFqC",
                "forum": "0Y26tFG3WF",
                "replyto": "pJEqj8yd65",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "content": {
                    "comment": {
                        "value": "To my current understandings, the regularization is a kind of reweighting: significant bits have large weights in the square loss term, while all bits are treated in the same way in the regularization term. This means that the regularization term makes the significant bits less significant. Then minimizing the regularized objective will lead to more accurate insignificant bits and less accurate significant bits (compared to minimizing the square loss). As a result, I believe that less accurate significant bits (outputted by minimizing the regularized objective) will hurt the model more than less accurate insignificant bits (outputted by minimizing the square loss). Based on this, I am still not convinced of the proposed reguarization method."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700634129725,
                "cdate": 1700634129725,
                "tmdate": 1700634129725,
                "mdate": 1700634129725,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4o3eFvDGO1",
                "forum": "0Y26tFG3WF",
                "replyto": "5ln7OULaIX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "content": {
                    "comment": {
                        "value": "I acknowledge the motivation of making insignificant bits accurate under the prerequisite of not sacrificing the accuracy of significant bits. But I am not convinced of the prerequisite, i.e., the objective functions are conflicting. For simplicity, let A be the square loss, and B is the regularizer ($\\lambda O_{reg}$). Authors claim that minimizing A+B will obtain a solution that is no worse than (under the criterion A) the solution of minimizing A. This is opposite to intuition and might occur when the algorithm of minimizing A is not well designed. If there is some special mechanism that supports authors' claim and refutes the intuition, I think such a mechanism is the central part of this paper and should be explained in more detail."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700639362470,
                "cdate": 1700639362470,
                "tmdate": 1700639362470,
                "mdate": 1700639362470,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fVEjBhwCF4",
                "forum": "0Y26tFG3WF",
                "replyto": "AM5rZnrwGG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Added clarification for non-conflicting nature of each objective component,\n\nComponent 1 : $O_{pred}$ (MSE) - Nature: Non-negative. \nComponent 2 : $O_{reg}$ (Cross Entropy) - Nature: Non-negative. \n\nMagnitude comparison in a general case, for relative assessment of prediction accuracy of the same quantity:\n\n$O_{reg}$ >= $O_{pred}$, Since, Cross Entropy generally greater that MSE for the same prediction assessment. Here, the authors agree with the reviewer that if the overall loss was $O_{pred}$ + $O_{reg}$, magnitude of one would overshadow the other. \n\nHowever, in the proposed setting the same is relatively weighted, that is overall loss = $O_{pred}$ + $\\lambda$$O_{reg}$, where $\\lambda$ is the hyper-parameter that is tuned to make sure the relative weighting is such that one does not overshadow the other. Note that in all ideal cases : $\\lambda$ <= 1. \n\nThe components thereby are non-conflicting since they have the same nature (one doesn't cancel the other) and they are relative weighted (one doesn't overshadow the other)."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700640607795,
                "cdate": 1700640607795,
                "tmdate": 1700640643760,
                "mdate": 1700640643760,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5CsZsQri8P",
                "forum": "0Y26tFG3WF",
                "replyto": "AM5rZnrwGG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "content": {
                    "comment": {
                        "value": "Let's think the optimization in a mathematical way. For simplicity, we first define the following notations:\n1. $O_{p}^{(1)}$ is the square loss of the solution by minimizing square loss (eq. 7).\n2. $O_{r}^{(1)}$ is the cross entropy loss of the solution by minimizing square loss (eq. 7).\n3. $O_{p}^{(2)}$ is the square loss of the solution by minimizing regularized loss (eq. 10).\n4. $O_{r}^{(2)}$ is the cross entropy loss of the solution by minimizing regularized loss (eq. 10).\n\nIn an ideal case, if both solutions are global minimizer, then it can be shown that $O_{p}^{(1)} \\leqslant O_{p}^{(2)}$ and $O_{r}^{(1)} \\geqslant O_{r}^{(2)}$. And when $N=1$, these two inequalities become equalities or strict inequalities at the same time. Then my question is what happens in experiments? Or what is expected to occur? Based on the relationf of $>$, $=$, and $<$ for these two pairs, there are 9 cases:\n1. $O_{p}^{(1)} > O_{p}^{(2)}$ or $O_{r}^{(1)} < O_{r}^{(2)}$ (corresponds to 5 cases). This contradicts the intuition from theoretical results. This might happen in experiments since we cannot obtain the global minimizer. Then it would be necessary to explain the gap between theories and practices.\n2. $O_{p}^{(1)} = O_{p}^{(2)}$ and $O_{r}^{(1)} = O_{r}^{(2)}$ (corresponds to 1 case). Then the proposed regularization is meaningless since it does not change the solution by minimizing (7).\n3. $O_{p}^{(1)} = O_{p}^{(2)} , O_{r}^{(1)} > O_{r}^{(2)}$ or $O_{p}^{(1)} < O_{p}^{(2)} , O_{r}^{(1)} = O_{r}^{(2)}$ (corresponds to 2 cases). This cannot happen when $N=1$. If this is the case when $N>1$, the first case means that directly minimizing eq. (7) does not obtain a better solution than minimizing eq. (10), while the second case implies that directly minimizing eq. (10) does not achieve a better solution than minimizing eq. (7). This is contrary to intuition and needs more explanations.\n4. $O_{p}^{(1)} < O_{p}^{(2)}$ and $O_{r}^{(1)} > O_{r}^{(2)}$ (corresponds to 1 case). This is the case that matches the theoretical intuition. If this happens, the prediction made by minimizing eq. (10) is less accurate, and the deviations from the solution will be larger as time increases."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700649634391,
                "cdate": 1700649634391,
                "tmdate": 1700653331544,
                "mdate": 1700653331544,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tAXlzuYCq3",
                "forum": "0Y26tFG3WF",
                "replyto": "Sjwo4GI0rw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "content": {
                    "comment": {
                        "value": "Sorry for the typo in the last response, $O_{p}^{(2)}$ and $O_{r}^{(2)}$ are the square loss and cross entropy loss of the solution by minimizing $O_{total}$ (not cross entropy loss). The last response is asking the difference between the minimizer of square loss and that of the regularized loss (eq. 10). $N$ is the number of data points, consistent with the definition in the paper."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700651134337,
                "cdate": 1700651134337,
                "tmdate": 1700651134337,
                "mdate": 1700651134337,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XBYW8pkSgc",
                "forum": "0Y26tFG3WF",
                "replyto": "AM5rZnrwGG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Please note the discussion and intuition for the proposed objective:\n\nStarting with the fact that the no of datapoints is never equal to 1 in the proposed setting or the original LNN setting since LNN's are known to be notorious for their data requirements. \n\nOptimising squared error alone: $O^{(1)}_p$ will not guarantee convergence of Cross entropy objective, Since lower order bits would be poorly constrained and in stochastic optimisation settings achieving such precision would be not possible in finite time since the gradient magnitudes are small and unstable enough to be non contributing to any effective weight updates (true for most neural network based regression settings), and for the same $O^{(1)}_r$ which indicates the prediction accuracy of all bits of cannot be minimised beyond a point. \n\nJoint optimisation with relative weighted sum (proposed setting): Since it's difficult to exactly assess the convergence behaviour of joint optimisation setting, let's consider the following scenario: The LNN is optimised using squared error (Eq. 7) alone as the objective for some no of steps, and a state is achieved where the precision is no longer improvable because MSE is now unstable. Note that in such a stage the most significant bits would be predicted right. What one would require now is to introduce an objective that is more stable and directly contributing at such a stage, with similar magnitude and does not contradict what's optimised already. The scaled cross entropy term acts as the same, since it's conditioning each bit individually bit without relative weighting, the contribution from already optimised bits would be zero and hence has no adverse effect on the optimisation carried out by using squared error. The role of cross entropy at such as stage would be to improve the prediction accuracy of the lower order bits."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700653329482,
                "cdate": 1700653329482,
                "tmdate": 1700653376399,
                "mdate": 1700653376399,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uMlq8EMmSr",
                "forum": "0Y26tFG3WF",
                "replyto": "AM5rZnrwGG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the detailed explanation.\n\nThis response answers the relation between the second pair: $O_{r}^{(1)} > O_{r}^{(2)}$ because minimizing the square loss in practice will not lead to the convergence of lower order bits and the cross entropy loss will be large. This answer is consistent with theoretical intuition and can be a motivation for the proposed regularization.\n\nHowever, our purpose is to control the deviations from the true solution. Then the relationship of the first pair ($O_{p}^{(1)}$ and $O_{p}^{(2)}$) is also important. Furthermore, the regularized loss (eq. 10) gives lower order bits more significance (compared with the square loss). It is also important to discuss the influence of higher order bits and lower order bits on the deviations to motivate the regularization."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700654385240,
                "cdate": 1700654385240,
                "tmdate": 1700654431703,
                "mdate": 1700654431703,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0dnN5MTKlr",
                "forum": "0Y26tFG3WF",
                "replyto": "AM5rZnrwGG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "An simplistic explanation would be by considering the scenario as in the previous comment:  The LNN is optimised using squared error (Eq. 7) alone as the objective for some no of steps, and a state is achieved where the precision is no longer improvable because MSE is now unstable. Note that in such a stage the most significant bits would be predicted right.  \n\nNow the addition of cross-entropy would have the following implications: Since, larger order bits are already optimised the same won't contribute towards the Cross entropy value, that is their relative contribution would be zero, since they're already predicted right. Now the contributing part (lower order bits) are consequently optimised, the same would improve the accuracy of the overall solution, therefore improving the squared error too implicitly. \n\nOn other note, an objective consisting of relative weighted MSE and cross-entropy is not something new in the deep learning literature, quoting specifically the class of Actor Critic methods from the Deep Reinforcement Learning (DRL) literature, the objective of such methods usually consists of two relatively weighted terms : the actor loss and the critic loss, where the actor loss is usually the cross entropy estimate based on the predicted and expected action spaces and the critic loss is a squared error between the predicted and expected state values, the applicability and relative superiority of actor critic algorithms on comparison with counterparts that use value loss or policy loss alone is well established.\n\nA classic and well established class of application of DRL is in the production of human level game playing agents, please find two attached references which uses a class of actor critic algorithms, and specifically uses an objective function similar to the proposed work : (sum of cross entropy and squared error);\n\nSilver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., Lai, M., Guez, A., Lanctot, M., Sifre, L., Kumaran, D., Graepel, T. and Lillicrap, T., 2018. A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. Science, 362(6419), pp.1140-1144.\n\nZhang, Hongming, and Tianyang Yu. \"AlphaZero.\" Deep Reinforcement Learning: Fundamentals, Research and Applications (2020): 391-415."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700656077438,
                "cdate": 1700656077438,
                "tmdate": 1700657006707,
                "mdate": 1700657006707,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CL28NoksQQ",
                "forum": "0Y26tFG3WF",
                "replyto": "AM5rZnrwGG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "content": {
                    "comment": {
                        "value": "After the addition of cross entropy loss, we cannot guarantee that the larger order bits do not change. By minimizing the regularized loss, the loss of larger order bits may increase together with the loss decrease of lower order bits.\n\nSuch a combinition is a kind of reweighting of the significance of different bits. It is important to clarify the reason for decreasing the significance of higher order bits by analyzing the influence of different bits on the deviations."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700657064736,
                "cdate": 1700657064736,
                "tmdate": 1700657114348,
                "mdate": 1700657114348,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sbJAWNV4b0",
                "forum": "0Y26tFG3WF",
                "replyto": "9KabYtEzMI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for providing the related literatures. But my central concern is not the convergence. My concern is about the comparison between minimizing the square loss and minimizing the regularized loss. Currently, I am not convinced on the explanations about \"minimizing the regularized loss will lead to a smaller deviation from the true solution\" based on two facts:\n1. Minimizing the regularized loss cannot guarantee more accurate higher order bits and lower order bits at the same time.\n2. The relationship between deviations and different order bits is not discussed."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700658867212,
                "cdate": 1700658867212,
                "tmdate": 1700658867212,
                "mdate": 1700658867212,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "te4oRTrglN",
                "forum": "0Y26tFG3WF",
                "replyto": "AM5rZnrwGG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "The squared loss is analogous to the value loss in actor critic and the regularisation is analogous to the policy loss, since it can be seen that the same is assured to converge without conflicts producing one of the worlds best game playing agents, there is no reason to believe there would be any form of conflicts in the objective itself. \n\n\n\nAlso it would be great to provide solid grounds for believing otherwise, or provide an example literature where such an objective loss is proven to diverge or conflict each other's optimality. \n\n1. The base intuition is that minimising the regularisation component would guarantee that every predicted bit is exactly the expected bit. Added to the same the squared loss ensures that the higher order bits are predicted right anyway , hence the regularisation builds upon what's provided by squared error to condition explicitly on even the lowest bit of interest, thus improving the overall prediction. In short, it's quite obvious that jointly minimising the regularised loss with the squared loss component present improves the precision, on top of that the regularisation method as proposed here is unique for that fact that one can provide explicit conditioning on bits of significantly lower order magnitude, thus improving the overall precision of the proposed solution.\n\n2. Solution deviation is maximum when the higher order bits are mis-predicted, however in chaotic systems the deviation would still show up even if bits of lower considerably lower order magnitude contribution is mis-predicted, when the solution is estimated for considerably large time-intervals, hence to obtain a valid solution space for a large enough time interval of interest, a minimum precision scale is necessary for each system. For which the proposed work introduces a scalable method by which arbitrary precision standards could be achieved."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659690068,
                "cdate": 1700659690068,
                "tmdate": 1700661408613,
                "mdate": 1700661408613,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dSknvIOwch",
                "forum": "0Y26tFG3WF",
                "replyto": "te4oRTrglN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "content": {
                    "comment": {
                        "value": "The similarity between the proposed regularization and DRL is a good story but is not sufficient to support the regularization and the complex algorithm:\n1. The success of a method in one area does not promise its success in another area. AlphaZero is designed to play chess, shogi and go, while the task here is learning a chaotic dynamical system. These are two completely different problems. Even in game playing, AlphaZero only performs best on several games.\n2. A key idea in one model itself cannot make a new model success. The loss design is just one of many techniques to make AlphaZero work.\n3. To my understandings, the similarity is very limited. In the Q Actor Critic algorithm, the square loss is used to learn parameters of Q function, while the cross entropy loss is used to learn parameters of policy. The Q function and policy are two independent parts of the model. While in the proposed regularization, both losses are based on the same set of parameters.\n\nFinally, other reviewers also point out the problem about the algorithm and explanations. Reviewer HA5A says \"I believe that the paper would greatly benefit from a simpler algorithm and better explanation\" and asks for \"some experiments showing that varying machine precision is not enough\". Reviewer 2inG asks for \"applying their method to more challenging datasets\". Therefore, I think all reviewers are not convinced. Thus, it would be better to reorganize the paper, clearly demonstrate the motivation, explain the algorithm in detail, and conduct more convincing experiments and comparison."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700663080533,
                "cdate": 1700663080533,
                "tmdate": 1700663080533,
                "mdate": 1700663080533,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fVg9FxZZ1G",
                "forum": "0Y26tFG3WF",
                "replyto": "AM5rZnrwGG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "The understanding outlined is partially accurate except for the fact that for most of the modern actor critic implementations a single multi-output network is used to model both the Q or value function and the policy function, which is optimised using the relative weighted sum of both the value and policy losses. It's understandable that one algorithm cannot perform nominally in all conditions and there would be inherent limitations. The point we authors are trying to raise is that the components in the joint objective function is non-conflicting. \n\nThe proposed work is a proof of concept for the relative scalability of the same in terms of achievable precision and the consequences the same in achieving more accurate long term solutions for systems that exhibit chaotic behaviour. More complex systems such as ones that require more complex constraints such as contact constraints are beyond the scope of the current study. however it maybe noted that the generality of the proposed approach extends beyond the augmentation of Vanilla-LNN."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700665732966,
                "cdate": 1700665732966,
                "tmdate": 1700665776897,
                "mdate": 1700665776897,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "30UwNm3OLT",
                "forum": "0Y26tFG3WF",
                "replyto": "fVg9FxZZ1G",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "content": {
                    "comment": {
                        "value": "After the long discussion, it becomes clearer why the regularization works. There are some further questions that I would like to confirm with authors.\n1. Is the LNN large enough to make the problem realizable (i.e., there exists an LNN with 0 loss)? If this is the case, then minimizers of the square loss and regularized loss are equivalent, which implies that the cross entropy loss does not hurt the square loss. The difference between these two losses are from practical optimization.\n2. Is there any noise in the training? In common machine learning tasks, labels may have noise. In this paper, the cross entropy loss forces LNN to have accurate output on lower bits, which may suffer from the risk of fitting noise. If the task here has no noise, then this is not an issue.\n3. Square loss alone cannot guarantee accurate prediction on lower bits, while square loss and cross entropy loss can. Then a natural question is: can cross entropy loss alone guarantee accurate prediction on lower bits? To my current understandings, the answer is yes. And I am wondering can we just minimize the cross entropy loss?"
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700715587636,
                "cdate": 1700715587636,
                "tmdate": 1700715587636,
                "mdate": 1700715587636,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hyUJe00ZgL",
                "forum": "0Y26tFG3WF",
                "replyto": "pqNoM21CpU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_88d6"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for detailed explanations. The answers of 2 and 3 completely solve my questions, and I think the motivation of the regularization is convincing now. It would be better to contain part of the discussions in the paper to make the proposed method clearly motivated."
                    }
                },
                "number": 28,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700739237814,
                "cdate": 1700739237814,
                "tmdate": 1700739237814,
                "mdate": 1700739237814,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "viNwIZzZDn",
            "forum": "0Y26tFG3WF",
            "replyto": "0Y26tFG3WF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6604/Reviewer_2inG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6604/Reviewer_2inG"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a variant of the Lagrangian Neural Network (LNN) model for inducing higher precision outputs. The authors are motivated by chaotic systems, where slightly-inaccurate predictions can diverge quickly from the ground truth. In particular, the authors propose to output each binary bit of a traditional LNN's output, and they introduce several new regularization terms to supplement the regular LNN objective towards the goal of higher binary precision. The authors test their proposed model on the double pendulum and Henon-Heiles chaotic systems, with improvements over the original LNN architecture in the amount of steps before the predictions of each chaotic system's state diverges from the truth."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The method is unorthodox in the sense that neural network predictions are typically not performed as classification over the significant bits of the output. However, the authors design a training policy that carefully considers possible issues during training (such as the increasing $\\mu_{TC}$ scale term and the proposed regularization term), which is appreciated. \n\nFor instance, $O_{reg}$ is used to supplement, not replace, the $O_{pred}$ MSE loss, and $O_{TC}$ is a good heuristic to deal with the situation in which the Lagrangian of a given system does not have a known analytical form. The increase weight of $\\mu_{TC}$ is also a good solution to reduce instability from the initial transient stages of training.\n\nThe authors also compare between various choices of the precision parameter $k$, and they empirically show that the results of using low $k$ values are similar to the results of the original LNN model, which is an interesting result."
                },
                "weaknesses": {
                    "value": "There is little to no explanation, intuition, or motivation about why this method should be superior to standard regression techniques optimizing with mean squared error. In general, there are several methodological concerns I have. For instance, computing the explicit Lagrangian using eq. 8 and comparing it with the ground truth MSE loss seems equivalent to the standard LNN formulation. Thus, the novelty of this method is in the regularization term $O_{reg}$ and in the regularization method to deal with unknown Lagrangians for the underlying system. Can the authors provide some intuition for why $O_{reg}$ is added and why it improves performance? Also, in what sense does $O_{reg}$ provide a regularization effect?\n\nThere is also no discussion and comparison to prior variants of LNNs. One such paper is Finzi et al., 2020, which also performs experiments on the double pendulum. I would strongly recommend the authors perform numerical experiments to compare against other prior LNN variants, not just the original LNN model. Furthermore, there is little to no discussion in the introduction about these LNN variants. At the very least, I would like to see some discussion about prior improvements to the LNN/Hamiltonian neural network (HNN) architectures.\n\nFurthermore, the evaluation for this method seems a bit limited. Recent extensions of LNNs and HNNs target more difficult problems, such as 5-pendulums (Finzi et al., 2020) and pendulums with friction (Zhong et al., 2021). Given these prior works, I would also strongly recommend the authors add more challenging case studies (e.g., any of the ones mentioned earlier) and compare to prior methods.\n\nIn summary, if the authors wish to convince the readers of the novelty and contribution of their work, I would recommend adding a deeper explanation and intuition for this method, adding more difficult test cases, and adding comparisons with other LNN variants (not just the baseline paper).\n\n**References:** \n* Finzi, M., Wang, K. A., & Wilson, A. G. (2020). Simplifying hamiltonian and lagrangian neural networks via explicit constraints. Advances in neural information processing systems, 33, 13880-13889.\n* Zhong, Y. D., Dey, B., & Chakraborty, A. (2021). Extending lagrangian and hamiltonian neural networks with differentiable contact models. Advances in Neural Information Processing Systems, 34, 21910-21922."
                },
                "questions": {
                    "value": "* In $O_{reg}$, the least significant bits in the output appear to be weighted the same as the most significant bits. Is there a particular reason for this? Did the authors try a relative weighting between the most and least significant bits?\n* In computation of $L_{pred}$, the authors mention that they round the sigmoid output of the model for each bit. How is this implemented in a differentiable way to allow for backpropagation through $O_{pred}$?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6604/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6604/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6604/Reviewer_2inG"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6604/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698382026695,
            "cdate": 1698382026695,
            "tmdate": 1699636752552,
            "mdate": 1699636752552,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mc2rE8OoLa",
                "forum": "0Y26tFG3WF",
                "replyto": "viNwIZzZDn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Regarding weaknesses pointed out :\n\nThe authors of this paper would like to thank the reviewer for the insights provided to improve the manuscript. The additional component (Eq. 9) in the objective function helps to explicitly condition on each significant bit of interest on the binary representation of the lagrangian estimate, thus improving the overall precision of the same. The same would enable the solution validity of deterministic chaotic systems to be extrapolated to larger domains of interest, or in other words the term helps in improving the generalizability of the solution space formed beyond what\u2019s possible using alternative literature, which is demonstrated in Figs. 2(b) and 3(b), the same can also be confirmed by direct comparison with relative error margins obtained by (Finzi et al., 2020) on their version of experiments performed on the double pendulum system on similar time domains. Thus proving a regularization effect on the estimated solution space.\n\nA discussion outlining the relative comparison has been added quoting the previous works focused on improving the original LNN formulation and what sets the proposed approach apart from the same.\n\n\nThe authors of this paper acknowledge that there are specific works that focus on improving the original Lagrangian Neural Network formulation, however this work takes a different approach to augment the original formulation. Specifically for estimating accurate long term solutions of dynamic systems that exhibit deterministic chaotic behavior. An additional section has been added in the conclusion section on the revised manuscript that specifically compares the error margins obtained as per the proposed approach and comparable experiments done in other LNN variants such as Finzi et al 2020, Zhong et al., 2021  which aims to improve accuracy and data efficiency by the addition of explicit  physical constraints. It\u2019s also worth pointing out that the approach proposed in the work (the specific neural network architecture augmentations and the precision regularization) is general enough to be adapted to other formulations. \n\nAnders to specific Questions :\n\nAn straightforward explanation would be that the relative squared error approximates heavily on solution space approximates where there is considerable deviation from the expected solution space. In other words the squared error approximates has a natural weighting towards the most significant bits of interest, due to the relative increase of its penalty magnitude in the event of misprediction. The regularization term acts as the explicit and equally weighted conditioning for estimating the relative accuracy of the predicted set of significant bits.\n\nThe gradients are estimated by bypassing the rounding operation, although the rounding operation is important to obtain the Lagrangian estimate, the operation would cause the network to be rendered non-differentiable. In other words, we customize the gradient computation step such that  the effects of the rounding operation are non reflective on the gradient map."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700458803929,
                "cdate": 1700458803929,
                "tmdate": 1700458803929,
                "mdate": 1700458803929,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xgCVNnGh3q",
                "forum": "0Y26tFG3WF",
                "replyto": "mc2rE8OoLa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_2inG"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_2inG"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your clarifications and answers to my questions.\n\nHowever, I am still not convinced about the contribution of this work in the context of prior LNN modifications. The authors mention that an additional section was added to the conclusion to compare against other LNN variants such as Finzi et al., 2020 and Zhong et al., 2021. Since this is a key point of mine, I would like to see this additional discussion explicitly. Would the authors be able to quote the passage that they added?\n\nAlso, a suggestion I still have (from my initial review) for the authors is applying their method to more challenging datasets, as in Finzi et al., 2020 and Zhong et al., 2021. I'm afraid that without a comparison with prior/baseline methods on more challenging settings, it is difficult to see how this work fits into the context of prior works.\n\nAs such, I will maintain my score as it is for now. However, I would be willing to re-evaluate my score if new quantitative results and comparisons were to be presented."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700475449005,
                "cdate": 1700475449005,
                "tmdate": 1700475449005,
                "mdate": 1700475449005,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PWGAevDJWE",
                "forum": "0Y26tFG3WF",
                "replyto": "zBOCPIYpFR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_2inG"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_2inG"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the expansion of the manuscript to include a comparison of the strengths and weaknesses of the proposed work with prior works. Would the authors be able to quote any passages relevant to our discussion here?"
                    }
                },
                "number": 29,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700739365316,
                "cdate": 1700739365316,
                "tmdate": 1700739365316,
                "mdate": 1700739365316,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "i5gpjoOlXN",
            "forum": "0Y26tFG3WF",
            "replyto": "0Y26tFG3WF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6604/Reviewer_HA5A"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6604/Reviewer_HA5A"
            ],
            "content": {
                "summary": {
                    "value": "Lagrangian neural networks have emerged as a promising approach to learning the dynamical behavior of a system from data. However, its limited precision hurts the prediction of long-time sequences, in particular, if the system is chaotic. The paper introduces a modification of the LNN framework where precision is explicitly modeled and shows that it improves prediction error in two empirical settings."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The problem studied is well justified. The description of the neural architecture used, and of the task studied is clear."
                },
                "weaknesses": {
                    "value": "I found the algorithm extremely convoluted, which is, in general, not a good sign for its robustness. It could be justified if simpler solutions, such as changing the default float32 in Jax to float64, do not work. However, the authors do not provide any data points suggesting that these simpler approaches do not work.\n\nThe experiments are too limited for me to be able to judge if the approach works.\n\nAdditionally, I found it a bit weird that only the original Lagrangian Neural Network paper is cited (and compared to), as papers improving the idea have been published since then (e.g., Finzi et al 2020)."
                },
                "questions": {
                    "value": "See Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6604/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6604/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6604/Reviewer_HA5A"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6604/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698394012622,
            "cdate": 1698394012622,
            "tmdate": 1699636752390,
            "mdate": 1699636752390,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZljogglSa0",
                "forum": "0Y26tFG3WF",
                "replyto": "i5gpjoOlXN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "The authors of the paper would like to thank the reviewer for his considerate set of comments and a revised manuscript is created to address the crucial points. While the precision can be increased from 32 to 64, it should be noted that errors in integration will creep into the solution, which for a chaotic system such as those studied in this work, will result in significant deviations from the true solution as time increases. The key idea in this work is to train the network to understand a chaotic system for a certain amount of time, and then use the trained network to extrapolate to much larger times.  One essential point to note is that the proposed approach enables adding an arbitrary level constraint on the precision scale of the solution space of any dynamic system of interest. The novelty of the work is solely based on the explicit conditioning mechanism outlined, which allows arbitrary constraints on each significant digit of interest. Varying the machine precision from float32 to float64 allows for the accommodation of an additional significant digits, however the same would have minimal effect on the overall precision of the solution, since in finite time stochastic optimization settings such the parametric optimization of a neural network the impact of the lower order digits on the relative error term is negligible (by virtue of its magnitude), the same consequently mean a negligible contribution or effect on each gradient update operation.\n\n\nThe proposed approach is a proof of concept, where explicit precision constraints could be enforced on the solution space of any given dynamic system, and as an example application, we demonstrate the applicability of the approach on dynamic systems that exhibit deterministic chaos. The cases chosen are two well known chaotic systems, i.e., the double pendulum and the henon-heiles problems. As seen in Figs. 2(b) and 3(b), the network is able to predict the solution up to 20 and 60 seconds, respectively. Furthermore, the parameter \u2018k\u2019 which decides the number of output branches of the neural network (the number of significant digits of interest) can control the precision required by the user for the problem at hand. Therefore, we feel that the present studies show the efficacy of the proposed formulation. The fact that precision can be enforced to a required level in the solution space possible using the proposed approach is the main novelty of the present work. Indicative results outlining the relative change in the error margin upon the variation of the scale parameter \u2018k\u2019 is outlined in figures 2(b) and 3(b) with an observable consistency in the trends shown.\n\nThe authors of this paper acknowledge that there are specific works that focus on improving the original Lagrangian Neural Network formulation. An additional section has been added in the conclusion section on the revised manuscript that specifically compares the error margins obtained as per the proposed approach and comparable experiments done in other LNN variants such as Finzi et al 2020, Zhong et al., 2021  which aims to improve accuracy and data efficiency by the addition of explicit physical constraints, the same improves the relative accuracy in the time domain of interest, and not extrapolate the solution beyond the same.. However, the present work takes a different approach to augment the original formulation. Specifically, for estimating accurate long term solutions of dynamic systems that exhibit deterministic chaotic behavior. It\u2019s also worth pointing out that the approach proposed in the work (the specific neural network architecture augmentations and the precision regularization) is general enough to be adapted to other formulations."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700458851859,
                "cdate": 1700458851859,
                "tmdate": 1700458851859,
                "mdate": 1700458851859,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nBJfnyrVfX",
                "forum": "0Y26tFG3WF",
                "replyto": "ZljogglSa0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_HA5A"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6604/Reviewer_HA5A"
                ],
                "content": {
                    "comment": {
                        "value": "I would like to thank the authors for the clarifications they provided.\n\nUnfortunately, I still think the paper needs substantial modifications before being in a good enough state to be accepted.\nAs touched upon in my review, here are the points I think should be covered in an updated version:\n- some experiments showing that varying machine precision is not enough (on top of the discussion that the authors provided in their answer).\n- as also mentioned by other reviewers, I believe that the paper would greatly benefit from a simpler algorithm and better explanation.\n- a better comparison to previous works would help in understanding the specific contributions of this paper."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6604/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700471534509,
                "cdate": 1700471534509,
                "tmdate": 1700471534509,
                "mdate": 1700471534509,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]