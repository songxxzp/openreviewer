[
    {
        "title": "Everybody Needs a Little HELP: Explaining Graphs via Hierarchical Concepts"
    },
    {
        "review": {
            "id": "8OCxGG2jeZ",
            "forum": "wrqAn3AJA1",
            "replyto": "wrqAn3AJA1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8164/Reviewer_zgh9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8164/Reviewer_zgh9"
            ],
            "content": {
                "summary": {
                    "value": "The article introduces Hierarchical Explainable Latent Pooling (HELP), an innovative graph pooling method designed to enhance the interpretability of Graph Neural Networks (GNNs). HELP operates by continuously pooling nodes with similar embeddings in the graph, merging these embeddings through average pooling in a hierarchical manner across various levels by k-means. This method allows HELP to identify and elucidate concepts in the input graph pertinent to the model's predictions, with these concepts evolving and increasing in complexity at higher pooling levels. Moreover, this paper designs a new metric Concept Conformity to measure the quality of a concept which is demonstrated better than existing metric in three aspects. Experimental results indicate that HELP matches the performance of leading GNNs while uncovering concepts that are more consistent and in alignment with domain knowledge."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tdesigns a new metric Concept Conformity to measure the quality of a concept which is demonstrated better than existing metric in three aspects.\n2.\tdiscusses the benefits of using k-means clustering to identify concepts."
                },
                "weaknesses": {
                    "value": "1.\tThe motivation is not strong enough: Why we need identify concept in hierarchical manner?\n2.\tThe representation need to be improved. \n\u2022\tThe algorithm is very unclear to know how to find concepts. \n\u2022\tMany typos and undefined symbols such as V_i, b, CONCOMP .\n\u2022\tUnclear description of the synthetic dataset. \n3.\tInsufficient baseline.  GLGExplainer (Global Logic-based GNN Explainer) [1] is a post-hoc concept-based explanation method as well.\n4.\tThe experiments do not show the advantage of hierarchical pooling which is the main motivation of this article.\n[1] Steve Azzolin, Antonio Longa, Pietro Barbiero, Pietro Lio, and Andrea Passerini. Global explainability of GNNs via logic combination of learned concepts. In The Eleventh International Conference on Learning Representations, 2023."
                },
                "questions": {
                    "value": "1.\tFor the synthetic dataset, you state \u201cThe class label is therefore given by (house, {triangle, house, fully connected pentagon})\u201d, could you explain it in detail? \n2.\tFor the synthetic dataset, what are intermediate nodes?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8164/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8164/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8164/Reviewer_zgh9"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8164/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698714237308,
            "cdate": 1698714237308,
            "tmdate": 1699637011910,
            "mdate": 1699637011910,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "frdRcjo2UW",
                "forum": "wrqAn3AJA1",
                "replyto": "8OCxGG2jeZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8164/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8164/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Response to Reviewer zgh9"
                    },
                    "comment": {
                        "value": "Thank you for the feedback on our paper. We have responded to your questions and concerns below.\n\n> Insufficient baseline. GLGExplainer (Global Logic-based GNN Explainer) [1] is a post-hoc concept-based explanation method as well\n\nIndeed, GLGExplainer is one of a variety of existing techniques for concept-based explainability on graphs. In contrast to HELP, it is a post-hoc method rather than an inherently interpretable architecture and it only delivers a set of concepts on the last layer, rather than insights into how concepts compose from the input to the final predictions.\nAs HELP is the first method at the intersection of hierarchical graph pooling and interpretability, we chose to cover a selection of both, uninterpretable hierarchical pooling approaches and non-hierarchical methods for explainability.\n\n> Why we need identify concept in hierarchical manner? [...] The experiments do not show the advantage of hierarchical pooling which is the main motivation of this article.\n\nHierarchies are ubiquitous in graph-structured data (and tasks). Identifying concepts in a more structured manner, allows for better explainability at different levels of granularity: From node-level concepts to concepts on the level of subgraphs which denote different motifs in the data. For instance, as shown in Figures 2a and 2b and explained in Section 5.2, the hierarchical pooling approach allows us to discover how concepts on later layers are composed of concepts from earlier layers. This yields significantly more detailed insights than only a single set of concepts after the final layer (as delivered by previous methods like GCExplainer or CEM (Magister et al. 2022)). Additionally, the hierarchical approach allows us to identify exactly which nodes belong to a concept, rather than just using k-hop neighborhoods. This significantly decreases the number of subgraphs a concept represents (see Figure 2), making it feasible to understand all subgraphs that make up the majority (the percentage is approximated by the concept conformity) of predictions, rather than only giving a few examples of the concept (like, for instance, GCExplainer and CEM).\n\n> The representation need to be improved. \u2022 The algorithm is very unclear to know how to find concepts. \u2022 Many typos and undefined symbols such as V_i, b, CONCOMP\n\nThank you for pointing this out. We have improved the notation in the revised version of the paper and added more detailed descriptions of the used symbols. $V_i$ denotes the set of nodes of the $i$th graph in the batch. Please let us know if anything remains unclear. As we were unable to locate the mentioned typos, we would also be grateful if you could clarify which parts you are referring to exactly, so we can address them appropriately.\n\n> For the synthetic dataset, you state \u201cThe class label is therefore given by (house, {triangle, house, fully connected pentagon})\u201d, could you explain it in detail? For the synthetic dataset, what are intermediate nodes?\n\nAs detailed in Section 4.1 and Appendix C.3.1, the synthetic hierarchical dataset is generated by first sampling a high-level motif (e.g. a house in Figure 4.1). Next, an intermediate node of a special color (node embedding) is inserted on each edge (please refer to Appendix C.3.1 for details on why this is required). Finally, a random low-level motif is sampled for each original node of the high-level motif (without the intermediate nodes). A graph\u2019s class is given by the combination of high-level motif and the set of low-level motifs. In Figure 4.1, the high-level motif is a house and the low-level motifs are two triangles, two fully connected pentagons and a house. The class is therefore given by the tuple (<high-level motif>, <set of low-level motifs>), which is (house, {triangle, house, fully connected pentagon}) in the case of Figure 4.1. In practice, we enumerate all possible classes and aim to predict the class I.D. as a one-hot encoding.\n\nWe have added a reference to Appendix C.3.1 in the revised paper.\n\nIf you have any further questions or concerns, we would be happy to discuss more!"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8164/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700601592352,
                "cdate": 1700601592352,
                "tmdate": 1700601592352,
                "mdate": 1700601592352,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ewztFGPYJa",
            "forum": "wrqAn3AJA1",
            "replyto": "wrqAn3AJA1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8164/Reviewer_VEwC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8164/Reviewer_VEwC"
            ],
            "content": {
                "summary": {
                    "value": "This paper achieved such progress:\n1) proposes a new non-spectral interpretable-by-design pooling method called \u201cHELP\u201d to demonstrate how concepts from different GNN layers interplay with each other and compose a new concept in later GNN layers. This method can give explanations to the model prediction in terms of concepts and the analysis of the hierarchical structure of graphs can be performed. \n2) proposes a novel metric called \u201cconcept conformity\u201d which measures the purity of a given concept to check if the discovered concepts by HELP are meaningful. \n3) demonstrate a method of GNN explainability via an interpretable GNN architecture design approach."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The motivation of this paper is clear, that is to find a GNN explainability method through neural network design and the writing style of this paper is also clear enough for readers to follow.\n2. This method offers some inspiration on how to deal with GNN explainability. By searching for high-level explainable concepts, this method can thus identify the relevant subgraphs in the model decision-making process.\n3. HELP uses K-Means as part of the algorithm, which is intrinsically more interpretable. Therefore, it can generate a more interpretable explanation of the model prediction compared to other black-box explainers."
                },
                "weaknesses": {
                    "value": "1. The paper lacks context in the introduction of the part 3.2 \u201cgradient flow\u201d, the readers find it hard to understand how this part is related to other parts in this paper. There is no background information about why it is necessary to introduce \u201cgradient flow\u201d in this part and how it relates to other parts of this paper.\n2. The explanation and description of how HELP works is insufficient. For instance, In part 3, this paper gives a limited description of how to implement \u201cpooling\u201d in this method (what is the exact way to apply a series of pooling blocks to the input graph, and how they are applied to different GNN layers?). Similarly, the description of Algorithm 1 is limited and readers might be confused about the purpose of each step in this algorithm (e.g., What is CONCOMP and why should we use it in this method?).\n3. Though focusing on explainability, the experiment result shows that HELP doesn\u2019t outperform other approaches in model accuracy, so the quality of this method in practice is questioned. The author needs to give more persuasive experiment results to show the feasibility of HELP.\n4. The metric concept conformity is not applicable for all methods, e.g., ASAP generates NA for this metric. This means that the applicability of concept conformity requires further exploration.\n5. This paper still needs to use other commonly used and standard metrics to measure the quality of generated concepts, instead of solely using two metrics."
                },
                "questions": {
                    "value": "1. Why the discovered concept-based explanations from HELP can give deeper insight compared to previous works? What makes these discovered concepts better compared to previous methods?\n2. How to ensure the process of converting graph embedding into a concept explainable enough after multiple layers of GNN? The concepts are generated after many layers of neural networks, so it\u2019s hard to demonstrate that the concepts are still interpretable enough to explain the model prediction.\n3. This paper states that \u201cour techniques preserve sparsity\u201d in \u201cpaper\u2019s contribution\u201d,  but there is none of any further explanation about this point. How is this statement validated by experiments or theories?\n4. The accuracy of HELP always lies in 1 standard deviation from the best approach. Does it necessarily mean that some implementation details in HELP can be further revised to make it perform better?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8164/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698754469501,
            "cdate": 1698754469501,
            "tmdate": 1699637011788,
            "mdate": 1699637011788,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Z00xc69zU7",
                "forum": "wrqAn3AJA1",
                "replyto": "ewztFGPYJa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8164/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8164/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer VEwC (1/2)"
                    },
                    "comment": {
                        "value": "Many thanks for your feedback. Below, we address your concerns and provide some clarifications.\n\n> The paper lacks context in the introduction of the part 3.2 \u201cgradient flow\u201d, the readers find it hard to understand how this part is related to other parts in this paper. There is no background information about why it is necessary to introduce \u201cgradient flow\u201d in this part and how it relates to other parts of this paper\n\nBy gradient flow, we simply refer to the fact that there exist well-defined gradients from the input to the predictions (which is required for backpropagation). This might not be immediately obvious as we utilize non-differentiable components like clustering. We have amended Section 3.2 to reflect this more clearly.\n\n> The explanation and description of how HELP works is insufficient. For instance, In part 3, this paper gives a limited description of how to implement \u201cpooling\u201d in this method (what is the exact way to apply a series of pooling blocks to the input graph, and how they are applied to different GNN layers?). Similarly, the description of Algorithm 1 is limited and readers might be confused about the purpose of each step in this algorithm (e.g., What is CONCOMP and why should we use it in this method?)\n\nWe have clarified our notation in the revised version. Please let us know in case there are any ambiguities left that you would like us to address.\n\n> Though focusing on explainability, the experiment result shows that HELP doesn\u2019t outperform other approaches in model accuracy, so the quality of this method in practice is questioned. \n\nAs you noted correctly, the goal of HELP is not to improve model accuracy, but to maintain comparable prediction quality to previous work while delivering insights into why predictions were made.\n\n> The metric concept conformity is not applicable for all methods, e.g., ASAP generates NA for this metric. This means that the applicability of concept conformity requires further exploration.\n\nConcept conformity is a metric designed to evaluate the quality of concepts that a method delivers to explain its predictions. Whereas ASAP is a popular hierarchical pooling approach, it does not deliver any explanations of its predictions. Therefore, there is no sensible way to define concept purity. The reason we use ASAP as a baseline, is to demonstrate that HELP performs comparable while delivering explanations for its predictions.\n\n> This paper still needs to use other commonly used and standard metrics to measure the quality of generated concepts, instead of solely using two metrics.\n\nUnfortunately, there are few commonly adapted metrics for this at the moment. The most popular one is concept completeness (which we report). Additionally, we report concept conformity, which measures the same objective as concept purity (proposed in GCExplainer), in a different way as justified in Section 4.2. In Table 5, we also give conformity scores using the k-hop neighborhood which makes them more similar to concept purity. Please let us know if there are any other metrics you had in mind.\n\n> Why the discovered concept-based explanations from HELP can give deeper insight compared to previous works? What makes these discovered concepts better compared to previous methods?\n\nAs we will detail in the next question, an important advantage of HELP is that it discovers a hierarchy of concepts, giving detailed insights over all GNN layers, rather than merely the result of the last layer (like, for example, GCExplainer). Additionally, comparing Figures 2a and 2b to Figure 2c clarifies the practical impact of the higher concept conformity. Concepts discovered by HELP represent one of a small set of subgraphs, making it easy to understand what a concept stands for. In contrast, concepts discovered by GCExplainer represent a significantly larger set of different subgraphs, making it almost impossible for a human to look at all of them and identify a common theme or meaning of the concept."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8164/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522332920,
                "cdate": 1700522332920,
                "tmdate": 1700522332920,
                "mdate": 1700522332920,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "daJYMle1hA",
                "forum": "wrqAn3AJA1",
                "replyto": "ewztFGPYJa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8164/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8164/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer VEwC (2/2)"
                    },
                    "comment": {
                        "value": "> How to ensure the process of converting graph embedding into a concept explainable enough after multiple layers of GNN? The concepts are generated after many layers of neural networks, so it\u2019s hard to demonstrate that the concepts are still interpretable enough to explain the model prediction.\n\nIndeed, you are  pointing out an important advantage of HELP. As you mention, existing, concept-based methods only generate a set of concepts after the last layer. In contrast, HELP generates a set of concepts after each pool block. As nodes generated from a similar concept/cluster, have a similar embedding\u00b9, we can view concepts from a given pool block as a set of (sub)graphs over concepts from the previous block (see Section 5.2). Note that in our experiments, there are only 2 GNN layers per pool block (see Table 3).\n\n> This paper states that \u201cour techniques preserve sparsity\u201d in \u201cpaper\u2019s contribution\u201d, but there is none of any further explanation about this point. How is this statement validated by experiments or theories?\n\nBy design, HELP only merges connected components and never creates any edges. It therefore preserves sparsity in the sense that a sparse input graph will not generally be fully connected after pooling, as it would be, for instance in DiffPool. \n\n> The accuracy of HELP always lies in 1 standard deviation from the best approach. Does it necessarily mean that some implementation details in HELP can be further revised to make it perform better?\n\nIndeed, it is possible that the performance of HELP could be improved by a thorough hyperparameter search, which is beyond the capacity of our resources. This seems particularly likely for the hyperplane gradient approximation as discussed in the Limitations in Section 5.3.\n\nWe would be happy to discuss more if you have any further questions or concerns!\n\n---------------------\n\u00b9the average over multiple nodes in the same cluster is expected to be close to the centroid"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8164/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522367283,
                "cdate": 1700522367283,
                "tmdate": 1700522510560,
                "mdate": 1700522510560,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SZYFYn90q6",
                "forum": "wrqAn3AJA1",
                "replyto": "daJYMle1hA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8164/Reviewer_VEwC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8164/Reviewer_VEwC"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thank you for your rebuttal. I have reviewed your response along with other reviews and rebuttals. I will keep my current score."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8164/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700722250290,
                "cdate": 1700722250290,
                "tmdate": 1700722250290,
                "mdate": 1700722250290,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "huTqE6iDa4",
            "forum": "wrqAn3AJA1",
            "replyto": "wrqAn3AJA1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8164/Reviewer_dvgz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8164/Reviewer_dvgz"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a hierarchical pooling procedure. At each step, the model processes multiple GNN layers at each step, performs clustering on representation, and merges connected components within the same cluster. By analyzing the relevant node mergers, we can gain insights into the model's decision-making process. In addition, this paper proposes a novel metric concept conformity to measure the noise level in the discovered concepts."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1) The proposed method takes into account the interactions between GNN layers, capturing the model's reasoning process from a hierarchical perspective, which refines the interpretability. In Section 3.1, the mentioned global clustering and merging clusters can enhance the effectiveness of clustering.\n\n2) The paper is well written and easy to understand.\n\n3) The paper studies an interesting problem that helps explain graphs."
                },
                "weaknesses": {
                    "value": "1) In the experimental section, a synthetic hierarchical dataset is used instead of the commonly used BA-Shapes and BA-Community datasets. Since conventional datasets do not exhibit a hierarchical structure, does this mean that the proposed method cannot be applied to these datasets and real-world datasets, and therefore has limitations? In Table 1, for the real-world dataset, HELP does not perform very well.\n\n2) The proposed synthetic hierarchical dataset is worth discussing. The accuracy of the model may be so high that the prediction of the dataset may be easier.\n\n3) Intuitively, as the number of layers in the model increases, the model will capture fine-grained information. However, the method proposed in this paper pools the input graph to a coarser representation, so does it ignore the fine-grained features of the nodes at high-level layer?\n\n4) For the metric Concept Conformity, i don't understand the formula, from the interpretation of the formula conf(c) should always be 1. In addition, will there be a case where two noise clusters are larger than the threshold t after merging, and then what should be done with these noise clusters?"
                },
                "questions": {
                    "value": "Please see the questions given in the weakness part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8164/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698754732662,
            "cdate": 1698754732662,
            "tmdate": 1699637011657,
            "mdate": 1699637011657,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "yM7iOosbOa",
                "forum": "wrqAn3AJA1",
                "replyto": "huTqE6iDa4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8164/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8164/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Response to Reviewer dvgz"
                    },
                    "comment": {
                        "value": "Thank you for your review and your supportive comments about our paper! We would like to address your questions and concerns below.\n> Since conventional datasets do not exhibit a hierarchical structure, does this mean that the proposed method cannot be applied to these datasets and real-world datasets, and therefore has limitations?\n\nWe would like to clarify that most real-world graphs are generally expected to exhibit hierarchical structure. For instance, molecular graphs like in BBBP or Mutagenicity can be seen as graphs over functional groups rather than atoms, as explained in Figure 1a. This is the underlying assumption of existing hierarchical pooling methods like ASAP and DiffPool and is supported by the concepts discovered by our method. The reason why we construct our hierarchical dataset in the given way is that in real-world datasets, the ground-truth hierarchies are unknown. This makes our synthetic dataset a useful sanity check to verify that HELP discovers the expected structures.\n\n> The proposed synthetic hierarchical dataset is worth discussing. The accuracy of the model may be so high that the prediction of the dataset may be easier.\n\nWe agree that our hierarchical synthetic dataset may be easier to learn than some of the real-world datasets. As mentioned above, its primary purpose is to verify the generated explanations in a scenario where the ground-truth structure is known, making it easy to recognize valid explanations.\n\n> Intuitively, as the number of layers in the model increases, the model will capture fine-grained information. However, the method proposed in this paper pools the input graph to a coarser representation, so does it ignore the fine-grained features of the nodes at high-level layer?\n\nIdeally, the parts of the fine-grained structure which are relevant for the prediction would get incorporated into the node embedding of the pooled node, making it available for the subsequent layers.\n\n> For the metric Concept Conformity, i don't understand the formula, from the interpretation of the formula conf(c) should always be 1. \n\nThank you for pointing this out. Indeed, we seem to have lost the crucial indicator function in the editing process which would make the conformity always 1 as you recognized correctly. We corrected the formula in the updated version.\n\n> Will there be a case where two noise clusters are larger than the threshold t after merging, and then what should be done with these noise clusters?\n\nWe assume you are referring to merging clusters as described in Section 3. First, we want to emphasize that the threshold $t$ is applied to the percentage of components mapped to a given cluster which were isomorphic, not to the size of the cluster compared to others. That said, if the percentage of occurrences of a particular component is below the threshold in two clusters ($\\frac ab < t$, $\\frac cd < t$), then it will also be below the threshold after merging those clusters ($\\frac{a+c}{b+d}<t$).\n\nWe are open and happy to discuss further if you have any more questions or concerns!"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8164/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522204333,
                "cdate": 1700522204333,
                "tmdate": 1700522204333,
                "mdate": 1700522204333,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "OkhJvE68ju",
            "forum": "wrqAn3AJA1",
            "replyto": "wrqAn3AJA1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8164/Reviewer_RY8e"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8164/Reviewer_RY8e"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces HELP (Hierarchical Explainable Latent Pooling), a new graph pooling method that enhances the interpretability of Graph Neural Networks (GNNs) by elucidating how concepts across different GNN layers combine to form complex representations. HELP is the first non-spectral, end-to-end learnable hierarchical graph pooling method that can handle a variable number of connected components and demonstrates competitive accuracy with standard GNNs. The method's efficacy is quantitatively validated using novel metrics like concept completeness and conformity and qualitatively through expert-aligned explanations in domains such as chemistry and social networks, marking a significant advancement in making GNNs more interpretable."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Addressing the Challenge of Explainability in Graph Neural Networks:\nThe paper tackles a pressing and highly relevant issue in the field of graph learning \u2013 the need for explainability. Explainability is crucial in deploying GNNs for real-world applications where understanding the model's decision-making process is as important as the accuracy of its predictions.\n\n2. Innovative Approach to Learning Hierarchical Structures:\nThe introduction of a hierarchical structure to improve explainability is a novel and compelling approach. Hierarchical interpretations of data are more aligned with human cognitive processes, making them a natural fit for explainability purposes."
                },
                "weaknesses": {
                    "value": "1. Inadequate Methodological Detail:\nThe paper falls short in providing essential details in the method section, notably omitting some crucial symbols and function definitions (See Question 1). This lack of clarity impedes the reader's ability to fully comprehend the proposed interpretative framework for graph neural networks.\n\n2. Insufficient Coverage of Related Works:\nAlthough the paper mentions the DiffPool method, it neglects to discuss other works in the domain of learnable pooling in GNNs. Specifically, the paper [1] also proposed a learnable clustering approach which is highly relevant to the context of the presented work.\n\n[1] Brain Network Transformer, NeurIPS 2022\n\n3. Over-simplification of Synthetic Datasets:\nThe nearly perfect classification accuracy on synthetic datasets raises concerns about the complexity and applicability of the test environment. Such high performance suggests that the synthetic dataset may be too simplistic to effectively challenge and evaluate the proposed model.\n\n4. Lack of Explicit Demonstration of Explainability Improvement:\nThe paper posits that high concept conformity leads to improved explainability but fails to demonstrate this relationship concretely. To substantiate such claims, the authors should provide empirical evidence or case studies that illustrate how explainability is enhanced as a direct result of increased concept conformity (See Question 3)."
                },
                "questions": {
                    "value": "1. In the Algorithm Section, please provide detailed definitions of used symbols and functions, for example, n_{blocks}, C, CONCOMP().\n2. Please enlarge the font size in Figure 2, and can you explain the X and Y axes in detail?\n3. Can you provide a case study to show which benefit the high Concept conformity can bring?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8164/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8164/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8164/Reviewer_RY8e"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8164/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699066123793,
            "cdate": 1699066123793,
            "tmdate": 1700748566069,
            "mdate": 1700748566069,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ULp1brPSVC",
                "forum": "wrqAn3AJA1",
                "replyto": "OkhJvE68ju",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8164/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8164/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Response to Reviewer RY8e"
                    },
                    "comment": {
                        "value": "Thank you for your feedback and time spent reviewing our work. Below, we address each of your comments and questions.\n\n> The paper falls short in providing essential details in the method section, notably omitting some crucial symbols and function definitions. [...]. In the Algorithm Section, please provide detailed definitions of used symbols and functions, for example, n_{blocks}, C, CONCOMP()\n\nThank you for pointing this out. We have added more detailed descriptions of the methods and variables in use. We hope these modifications address your concerns. \n\n> Insufficient Coverage of Related Works: [...] Specifically, the paper [1] also proposed a learnable clustering approach which is highly relevant to the context of the presented work.\n\nThank you for making us aware of this work. We have added it to the related work section.\n\n> Please enlarge the font size in Figure 2, and can you explain the X and Y axes in detail?\n\nWe will aim to improve readability of the figure in the final version. The y axis denotes a unique id of the cluster/concept. It therefore displays the numbers $0$ to $k-1$ (where $k$ is the number of clusters in the k-means clustering). For brevity, we only show a selection of these concepts in Figure 2 and refer to Appendix F.3 for plots that contain all concepts. The x axis denotes the number of nodes in the test set which were mapped to this particular concept. Nodes of the same color were mapped to the same component. For instance, all nodes that were pooled together in the same functional group would be mapped to the same color.\n\n> The paper posits that high concept conformity leads to improved explainability but fails to demonstrate this relationship concretely. To substantiate such claims, the authors should provide empirical evidence or case studies that illustrate how explainability is enhanced as a direct result of increased concept conformity [...]. Can you provide a case study to show which benefit the high Concept conformity can bring?\n\nIntuitively, concept conformity measures what percentage of the colored segments in a plot similar\u00b9 to Fig. 2 are bigger than some threshold. With a threshold of $t:=10%$ and the example of functional groups, a conformity of 100% implies that at most 10 (usually less) functional groups can be mapped to this concept, which makes it easy to understand by looking at the small number of functional groups it represents. 90% conformity would imply that 90% of the connected components mapped to this concept are functional groups that made up at least 10% of the total number of components. Therefore, 90% of the occurrences can be explained by at most 9 subgraphs. The rest could be a larger number of more rare subgraphs which might make it harder to individually consider all of them. A purity of 0% would imply that the concept can stand for many different subgraphs, making it hard to understand.\n\nWe are open to discuss further if you have any more questions or concerns!\n\n---------------------\n\u00b9The only difference is that the x axis would be the number of components rather than nodes, i.e. the size of each bar would be divided by the size of the component (e.g. 3 in a functional group with 3 atoms like NO2)"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8164/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700521989874,
                "cdate": 1700521989874,
                "tmdate": 1700521989874,
                "mdate": 1700521989874,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]