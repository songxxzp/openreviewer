[
    {
        "title": "SSL Framework for Causal Inconsistency between Structures and Representations"
    },
    {
        "review": {
            "id": "v8HyhY2URc",
            "forum": "SYPx4NukeB",
            "replyto": "SYPx4NukeB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission575/Reviewer_2DS3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission575/Reviewer_2DS3"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the author proposes a SSL framework to make the causal structure be the same as causal representation by regulating their strength set. The author further introduces a dialogue dataset which could serve as a potential benchmark."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The author showcases implementations under different frameworks. \n\n2. The dataset could be useful. \n\n3. The experimental results are promising."
                },
                "weaknesses": {
                    "value": "1. The presentation and the readability of the paper can be improved. \n\nThe author points out the inconsistency between causal structure and causal representation.  However, there is no formal definition of causal consistency in the paper.  In theory 1, the author gives the causal consistency condition as if it is equivalent under any intervention, these two causal models are consistent. But still, it is not a definition and there is a lack of intuition and motivation of why inconsistency is a problem to be solved. \n\n\n2. The hypothesis 2 is confusing. \n\nIn images or text, people project the original data into latent space, where each dimension does not have to be entangled. Even in the feature space, they do not have to be entangled. The pixel one may not relate to pixel two."
                },
                "questions": {
                    "value": "1. What is the causal inconsistency between causal representation and causal structure and why do we want to optimize it. \n\n\n2.  How do you adapt your method to other datasets where the intervention cannot be done, for example, celebA."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission575/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission575/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission575/Reviewer_2DS3"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission575/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698114824436,
            "cdate": 1698114824436,
            "tmdate": 1700320983140,
            "mdate": 1700320983140,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "N9Yrj9EWUJ",
                "forum": "SYPx4NukeB",
                "replyto": "v8HyhY2URc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission575/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission575/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer 2DS3"
                    },
                    "comment": {
                        "value": "Thank you for your careful review. We will address your concerns in turn with the following responses:\n\n1. About Causal Consistency: \n\nWe recognize that this is indeed a significant issue. Consequently, we have added a new PDF that elucidates: how to define causal representation, how to define causal consistency, and why Indefinite Data leads to such drastic inconsistency. Please refer to our Official Comment: \"We add a PDF file into Supplementary Material for some Major Revisions.\"\n\n2. About Hypothesis 2: \n\nWe fully agree with you, and in fact, we just wanted to illustrate a potential occurrence: the possibility of interconnections among pixels. Therefore, we believe it might be more suitable to revise our paper's statement to \"meaning that the representation is probably causally entangled over dimensions\". Additionally, Hypothesis 2 seeks to convey that we can grasp the information of Indefinite Data without sampling. For instance, if we want to understand the climate in Singapore, we need an adequate temperature sampling to learn about the weather characteristics, such as day-night temperature difference, or whether it's a tropical or subtropical climate. However, if we wanted to comprehend the meaning of a sentence, we would not need to collect many samples of this sentence. We could understand its semantics with just one \"sample\", as different dimensions in the multi-value representation could be causally entangled, thus containing sufficient information.\n\n3. About celebA: \n\nWe are delighted to discuss these issues with you. Intervention is determined based on how causal variables are identified. For example, if we believe that a particular part (like background) causes bias in the representation, then the 'background' should be a parent node of the representation. It should be removed in our framework (of course, the causal relationships cannot be observed with only these two variables). This is somewhat similar to finding shortcuts and causal patterns in XAI areas. Furthermore, if we think a person's recognition result is influenced by some people's face photos, we should sequentially intervene on different parent nodes (representations of other influential people) for different people. \n\nOnce again, thank you for your careful reading, and we apologize for the unclear areas in our previous manuscript. We look forward to your reply."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission575/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699683475303,
                "cdate": 1699683475303,
                "tmdate": 1699683475303,
                "mdate": 1699683475303,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Q5wC1Pco8a",
                "forum": "SYPx4NukeB",
                "replyto": "N9Yrj9EWUJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission575/Reviewer_2DS3"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission575/Reviewer_2DS3"
                ],
                "content": {
                    "comment": {
                        "value": "I think most of my concerns have been addressed or will be addressed in the revised version. Thank you for your reply."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission575/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700321083383,
                "cdate": 1700321083383,
                "tmdate": 1700321083383,
                "mdate": 1700321083383,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "fQ3AIhSKRO",
            "forum": "SYPx4NukeB",
            "replyto": "SYPx4NukeB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission575/Reviewer_cecZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission575/Reviewer_cecZ"
            ],
            "content": {
                "summary": {
                    "value": "The paper performs research on the intersection of deep learning and causal discovery. By so-called causal consistency, it proposes a self-supervised learning framework which provides potential support for the LLM. with some test results on a new dataset."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The idea is novel, and the viewpoint of consistency is important.\n2. The proposed new dataset may serve the community."
                },
                "weaknesses": {
                    "value": "1. Some definitions need to be more accurate.\n2. Experimental section can be improved."
                },
                "questions": {
                    "value": "1. The definition of \"non-statistical data\" forms like images, videos, and text is vague. These data still contains statistical information, and what do you mean by \"non-statistical\"?\n2. Definition 1 (Causal Data). I still think the definition of \"Indefinite Data\" \"Semi-definite\" based on D and M only is weak. How to quantify causal consistency is still an open question. This also applies to section 2.3.\n3. Def 3. The symbols looks slightly wired. \n4. Section 6. I am still puzzled that how you evaluate the \"causal graph\" and \"structure\" both. It seems that these two things basically align with the same aspect of the algorithm. Why not evaluate \"variance of learning results\" or \u201dscalability of the algorithm\u201c\uff1f"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission575/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698638436001,
            "cdate": 1698638436001,
            "tmdate": 1699635984784,
            "mdate": 1699635984784,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "RS9jNybZOu",
                "forum": "SYPx4NukeB",
                "replyto": "fQ3AIhSKRO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission575/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission575/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer cecZ"
                    },
                    "comment": {
                        "value": "Thank you for your meticulous review. We will answer your questions in order, hoping to eliminate your concerns:\n1. About Consistency: \n\nWe believe your question 2 and question 4 are pointing to the same issue: How to measure or define causal consistency? Indeed, in line with your thoughts and those of the other two reviewers, a few weeks ago, we also realized that the introduction to causal consistency in our paper was as unappetizing as garbage. Consequently, we uploaded a file that re-interprets what causal representation is, how to measure causal consistency, and why Indefinite Data would lead to such intense causal inconsistency. We hope these changes will make it more...\"delicious\" to you! Please refer to our Official Comment \"We add a PDF file into Supplementary Material for some Major Revisions.\" We trust that after understanding these supplements, you will see why our experiments need to revolve around causal graphs (causal structure) and causal representation. If there are still any doubts, please tell us.\n\n2. About \"non-statistical\": \n\nWe can see why you might have misunderstood, so we think it would be better to drop this adjective. In fact, what we wanted to express is that data like text, images, etc., are harder to exploit statistical characteristics (for example, we would not calculate high-order statistics between two sentences) compared to traditional causal domain data, but this is not important. In addition, if you want to understand more about the definition of Semi-Definite Data and Indefinite Data, you can refer to the review [1]. To make this definition strong enough, a lot of definitions and analyses must be introduced, such as \"Causal Variables and Causal Representation\", \"Single-value and Multi-value Variables,\" etc. Therefore, in this paper, we only hoped to explain Causal Consistency clearly. We would be very grateful if you could accept the definition of data paradigm as reasonable.\n\n3. The weird symbol: \n\nYou are likely referring to the index of the causal partial order $\\natural$ (music symbol). We will change it to $\\Xi$ (greek symbol).\n\nOnce again, thank you for your careful reading, and we apologize for the unclear areas in our previous manuscript. We look forward to your reply.\n\n[1]A Review and Roadmap of Deep Causal Model from Different Causal Structures and Representations. Arxiv2023."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission575/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699682031778,
                "cdate": 1699682031778,
                "tmdate": 1699682031778,
                "mdate": 1699682031778,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FT2XWMjat8",
                "forum": "SYPx4NukeB",
                "replyto": "RS9jNybZOu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission575/Reviewer_cecZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission575/Reviewer_cecZ"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "Thanks for the rebuttal. I would like to see more experimental results as raised in my Q4 before I raise my score."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission575/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700656822686,
                "cdate": 1700656822686,
                "tmdate": 1700656822686,
                "mdate": 1700656822686,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "3coeFMtolf",
            "forum": "SYPx4NukeB",
            "replyto": "SYPx4NukeB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission575/Reviewer_dzLx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission575/Reviewer_dzLx"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a causally motivated self supervised learning framework. In particular, the paper focuses on indefinite data, which refers to data that requires deep networks to represent them like text, videos, images etc. The authors show that current methods do not learn consistent structure and representations from a causal perspective, while their proposed method based on causal consistency outperforms existing SOTA methods on different benchmarks"
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The idea of considering consistency between representation and structure as a way of learning causal relations in an unsupervised manner is interesting."
                },
                "weaknesses": {
                    "value": "I feel the paper is poorly written. Without the Appendix, the technical contributions of the paper is very difficult to understand. Ideally, the paper should be complete with the Appendix dedicated to extra information that complements the contents of the paper. The experimental setup is not clearly explained which makes appreciating them difficult. More details in questions."
                },
                "questions": {
                    "value": "1. The paper studies the inconsistency problem between causal structure and representation. However, what is structure and representation is never formally defined in the paper. I understand from Definition 1, structure refers to the graph and representation is simply the output of a deep network operating on the data, like word embeddings of text. However, the authors consider two causal models one with the representation and one with the structure, which is confusing. A concrete example with the same data, but the two different U and V causal models for the structure and the representation would go a long way in making the presentation more clear.\n\n2. Hypothesis 2 is not clear. What does the notation E(\\hat{x}_{s,m,n}) = x_{s,m,n} mean? The E operator has not been defined, is it the expectation? If so, what is the expectation over?\n\n3. Section 2.2 is incomprehensible. What is causal consistency has not been defined so far, What is been plotted in Figure 1. The caption says it is the MSE between similarity matrices of representation and structure. What are these similarity matrices? Appendix A.3 does not give these details. What is the reconstruction loss the authors are referring to here? For example, lines 130-133, the authors say in the M > 1 or D > 1 case, the optimization of causal strength f changes to a weighted linear combination of f_m for the different M structures. However, this optimization problem has never been defined. Numerous such issues plague the readability of the paper.\n\n4. Eq 3 is unclear. What is L_k, what is being optimized? I understand at a high level we have 2 causal models, we intervene on both of them, and then have a way of checking the consistency of the two models. But beyond this high-level details, exact specifics of how the authors carry out the interventions and check for consistency is not present in the paper. \n\n5. The authors propose a Causalogue dataset for causal discovery. However, it is not clear how this dataset was construcuted. The appendix gives some details. However, the authors handcraft 10 causal structures. It is not clear how GPT-4 was prompted to respect this causal structure while generating the utterances. \n\nI think the entire paper needs significant restructuring to make the presentation clear and allow readers to understand the main contributions and needs more details to reproduce the results."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission575/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699257990185,
            "cdate": 1699257990185,
            "tmdate": 1699635984706,
            "mdate": 1699635984706,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Qm8dYItArj",
                "forum": "SYPx4NukeB",
                "replyto": "3coeFMtolf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission575/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission575/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dzLx"
                    },
                    "comment": {
                        "value": "Thank you for your attention to our paper. Simultaneously, we understand that under the situation of a heavy review load, it is inevitable that some key points might be overlooked when faced with our lengthy manuscript. Therefore, we hope that through our discussion, we can reach a pleasant consensus. I will reply to your questions one by one:\n\n1. More Information about Causal Inconsistency: \n\nWe completely agree with you. There, we added content to explain how causal consistency is measured and definitions of causal representation, etc. Please refer to our Official Comment: \"We add a PDF file into Supplementary Material for some Major Revisions.\"\n\n2. Question about Hypothesis 2: \n\nYes, $E$ stands for expectation. $E(\\hat{x_{s,m,n}}) \\doteq x_{s,m,n}$ means that if there are many identically distributed samples of the causal representation $\\hat{x_{s,m,n}}$, their expectation could equally reflect the corresponding causal variable $x_{s,m,n}$. This is the same as what we said in the lines 110-111: \"For instance, any sentence is enough to express its semantics, a single image can be read for its content.\" For example, for the sentence \"good morning\", if we collect different causal representations of this sentence from different models, given a large enough number, its expected representation represents the semantics of the sentence itself (therefore, we didn't use $=$ but $\\doteq$).\n\n3. Why Causal Inconsistency Arises: \n\nWe have revised Section 2.2, please refer to our Official Comment for details. Moreover, because everyone regards the generation process of causal representation as a general generation model, reconstruction loss, and optimization would emerge. For instance, section VI a) in the authoritative paper \"Towards Causal Representation Learning\".\n\n4. About Eqn3: \n\nThere was a typo here, it should not be $\\mathcal{L}_{k}$ but $\\mathcal{L}$ because the correct optimization function should not contain parameters unique to the intervention $k$. The optimization aim is the entire self-supervision process, so it involves output and parameters. Additionally, you perhaps overlooked that we proposed two implementations in Section 4.2 to assist readers in understanding our SSL framework, the details of these two implementations are in Appendix C.\n\n5. About Causalogue Dataset: \n\nWe do not primarily rely on prompts to satisfy causal structures. We set up \"system\" and \"role\" so that GPT will respect our causal structures. Please note that we are not using the window chat version, i.e., we use GPT-4 instead of ChatGPT. The details are shown in Appendix D.2 (Creation Process). \n\nHope these explanation could solve your questions. We look forward to hear your responses. Thank you for your concerning again!"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission575/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699679060404,
                "cdate": 1699679060404,
                "tmdate": 1699679060404,
                "mdate": 1699679060404,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]