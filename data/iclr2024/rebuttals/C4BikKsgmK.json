[
    {
        "title": "Str2Str: A Score-based Framework for Zero-shot Protein Conformation Sampling"
    },
    {
        "review": {
            "id": "gQuOUhh1HA",
            "forum": "C4BikKsgmK",
            "replyto": "C4BikKsgmK",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3973/Reviewer_6bVL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3973/Reviewer_6bVL"
            ],
            "content": {
                "summary": {
                    "value": "This paper aims to capture the dynamic protein structures and obtain various protein conformations. Instead of the resource-demanding MD and MC methods, the authors take inspiration from simulated annealing and propose a structure-to-structure translation framework for zero-shot conformation sampling. Roto-translation equivariance is appropriately guaranteed. Experiments on the 12 proteins in a newly established benchmark confirm the validity, fidelity, and diversity of the produced conformations. Ablation analysis and case study are provided for readers to have a deeper understanding of this paper. The problem under study is significant and this proposed idea is interesting."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Strucutre-to-structure translation seems a novel way to sample various conformations of a target protein. It requires less computational resources than MD and MC. \n- The experiments are described in details, which is very helpful for the readers the understand the proposed method.\n- The paper is well-written and easy to follow. More explanation about the formulas would further increase readability."
                },
                "weaknesses": {
                    "value": "- Although the overall structure-to-structure translation for protein conformation sampling is novel, there may not be adequate points to support the whole paper. The forward-backward process is most similar to a diffusion process, where the forward process adds noise (or heating) to data distribution and the backward process denoise (or annealing). The learning objective is similar to DenoisingIPA, except the minor edge translation layer.\n- Proper discussion of MC and MD-based related studies for protein conformation sampling could give readers a more thorough picture of where this paper is located.\n- Also, I'd like to see MC and MD-based baselines in the experiments. Though they are slow, I'm wondering how they perform in terms of validity, fidelity and diversity."
                },
                "questions": {
                    "value": "- What is the total number (or dimension) of variables T, R, v, X? Does this have something to do with the number of residues in each protein?\n- The score matching objective is the supervision signal. That is, the model is required to approximate the distribution of atom positions/angles of a target protein. I'm wondering how the proposed method encourages diversity of the sampled conformations. \n- Please properly use the term dynamics. Not sure if the authors properly interpret this term. To the best of my understanding, the concept of dynamics should have something to do with time and is usually used to indicate a temporally changing variable. Here in this paper, I do not see the conformation of a target protein changes with time. Instead, this paper cares more about different candidates of stable conformations. The proposed forward-backward process seems like a dynamics but essentially is a process of heating-then-simulated-annealing, which is different from the dynamics of protein conformation. Please properly modify some statements, especially those regarding dynamics.\n- How similar are the 12 proteins in the benchmark to the training protein data? Need to ensure zero-shot by quantifying the dissimilarity of train/test proteins at sequence and structure levels."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3973/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698498901547,
            "cdate": 1698498901547,
            "tmdate": 1699636358572,
            "mdate": 1699636358572,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qLXb2OsVvu",
                "forum": "C4BikKsgmK",
                "replyto": "gQuOUhh1HA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 6bVL: Part 1"
                    },
                    "comment": {
                        "value": "Firstly, we sincerely thank the reviewer for providing helpful suggestions to improve our manuscripts. Specifically, we want to address the above concerns as follows:\n\n**Weakness:**\n\n**Seemingly \u201cincremental\u201d to previous methods.**\n- Thanks for raising this point. We want to humbly argue in the following aspects: \n  - Firstly, the focus of this research paper is to present a zero-shot framework for the task of conformation sampling w/o expensive simulation data. As far as we are concerned, Str2str is the first-in-class example that can sample protein-level conformations in the zero-shot manner. \n  - One of our main contributions is the successful experimental demonstration that **it is able to transfer the generative models pretrained on PDB with score matching objective to the downstream task of conformation sampling**, even in a zero-shot manner. This distinguishes our work from those directly applying well-known methods such as diffusion to new data in an old task framework, and thus should not be criticized.\n  - Lastly, we are not aiming at proposing new generative methods extending SGM/diffusion [1] or introducing a new structure decoder on top of IPA as in AlphaFold2 [2]. Correspondingly, beyond Diffusion and IPA, our framework can flexibly accommodate other counterparts, such as LDM[3], flow matching[4] or SE(3)-transformers[5], etc, and these can be future work.\n\n\n**More related works for MC/MD methods.**\n- Thanks for this valuable suggestion. To better contextualize, we have carefully reviewed the related MC/MD literatures and complemented the relevant discussion in the Appendix G.1. \n\n**Baselines of MC and MD.**\n- Firstly, we note that the MD baseline, obtained from D.E. Shaw Research [4], were already shown in our main results. These simulations are among the most authentic and well-recognized studies in the MD domain, and unique in the simulation time scale. \n- Secondly, for MC, their validity should be comparable to MD since both of them involved force fields. Since MC is not mainstream in the MD domain (since it is not scaling well), there are very few works studying the protein dynamics using MC in recent decades. \n  - Evaluating MC methods on fidelity/diversity requires sampled trajectories, which are not accessible. Running any MC or MD in the same time scale as [5] from scratch is computationally intractable for us. The estimated simulation time for all benchmark systems far exceeded >10,000 GPU days, which is comparable to LLM pre-training such as Llama[7]. The most relevant work [8] conducted a MC-based study using a 100-fold larger timestep (x100 acceleration), it still requires ~100 GPU days and their data is not open-sourced.\n\nReferences:\n\n[1] Song, Yang, et al. \"Score-Based Generative Modeling through Stochastic Differential Equations.\" International Conference on Learning Representations. 2020.\n\n[2] Jumper, John, et al. \"Highly accurate protein structure prediction with AlphaFold.\" Nature 596.7873 (2021): 583-589.\n\n[3] Rombach, Robin, et al. \"High-resolution image synthesis with latent diffusion models.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022.\n\n[4] Lipman, Yaron, et al. \"Flow matching for generative modeling.\" arXiv preprint arXiv:2210.02747 (2022).\n\n[5] Fuchs, Fabian, et al. \"Se (3)-transformers: 3d roto-translation equivariant attention networks.\" Advances in neural information processing systems 33 (2020): 1970-1981.\n\n[6] Lindorff-Larsen, Kresten, et al. \"How fast-folding proteins fold.\" Science 334.6055 (2011): 517-520.\n\n[7] Touvron, Hugo, et al. \"Llama: Open and efficient foundation language models.\" arXiv preprint arXiv:2302.13971 (2023).\n\n[8] Heilmann, Nana, et al. \"Sampling of the conformational landscape of small proteins with Monte Carlo methods.\" Scientific reports 10.1 (2020): 18211."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3973/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700287845492,
                "cdate": 1700287845492,
                "tmdate": 1700287845492,
                "mdate": 1700287845492,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rZP8icAVXK",
                "forum": "C4BikKsgmK",
                "replyto": "gQuOUhh1HA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 6bVL: Part 2"
                    },
                    "comment": {
                        "value": "**Questions:**\n\n**Shape of the mentioned variables.**\n- They are dependent on the number of residues: the shape of respective variables for a single protein are: T = (N_residue, ); R = (N_residue, 3, 3); v = (N_residue, 3); x = (N_residue, 37, 3). \n\n**Explanation of the sampling diversity.**\n- Thanks for asking this question. We want to clarify that the proposed Str2str is in a transfer learning setting which does not require distribution data of the test system for training. During sampling, the perturbation (forward) process enforces exploration (say diversity) and the amortized learned score network will anneal (exploit) the perturbed sample to a candidate conformation. Overall, the forward-backward process achieves good balance between exploration and exploitation. \n\n**Explanation of the term \u201cdynamics\u201d in Section 3.2.**\n- Explanation: The semantic meaning of \u201cdynamics\u201d used in the forward-backward dynamics originates from the Langevin dynamics \u2014 which the backward process of diffusion/SGMs can belong to. We agree that \u201cdynamics\u201d comes with a time, while the time indicates here the time index of the diffusion process. According to your suggestion, we have altered the writing by using \u201cprocess\u201d in replace of \u201cdynamics\u201d in the Section 3.2. We hope this could address your concern.\n\n**Whether to ensure dissimilarity between train-test sets.**\n- Thanks for asking this question. In case there may be the least misunderstanding, we want to humbly clarify that such a process is not necessary: (1) amino-acid sequence information is neither used as input nor output; (2) The resulting evaluation is conducted based on the distribution metrics instead of the accuracy for a single structure. In other words, the setting is unsupervised w.r.t. the conformation sampling task; (3) The sampling for each test system corresponds to a new task during inference, and not a single data point belongs to that task is present during training. It is by definition zero-shot learning; (4) From the ML point of view, the usual train-test dissimilarity is enforced to avoid data leakage from supervision, which can make the \u201cgeneralization\u201d non-sense. This does not happen in our case. \n- Therefore, we preprocessed the training data by excluding the PDB entries to contain no a single conformation of all test systems.\n\n\n\nWe sincerely hope our response can address your concerns. If you have other questions, we are very glad to discuss them during the rebuttal."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3973/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700288254222,
                "cdate": 1700288254222,
                "tmdate": 1700288254222,
                "mdate": 1700288254222,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lvcz2EPRgG",
                "forum": "C4BikKsgmK",
                "replyto": "gQuOUhh1HA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Look forward to further feedbacks during the reviewer-author discussion period"
                    },
                    "comment": {
                        "value": "Dear Reviewer 6bVL,\n\nThank you for your helpful suggestions for improving our manuscripts. We sincerely appreciate your feedback and have carefully responded to each question point-by-point.\n\nThis is a kind reminder that as the reviewer-author discussion period is ending soon, we look forward to hearing from you about your feedback to our response. (Unlike previous years, there will be no second stage of reviewer-author discussion this year)\n\nIn particular, we have complemented related discussions and improved the clarification of writing, according to your advice.\n\nThank you again for your precious time and effort!\n\nBest regards,\n\nAuthors #3973"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3973/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700605585145,
                "cdate": 1700605585145,
                "tmdate": 1700605585145,
                "mdate": 1700605585145,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1lbTmuAeAW",
            "forum": "C4BikKsgmK",
            "replyto": "C4BikKsgmK",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3973/Reviewer_Fe1f"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3973/Reviewer_Fe1f"
            ],
            "content": {
                "summary": {
                    "value": "The authors present Str2Str, a score model for protein conformation sampling. The model is trained on crystal structures from the PDB and could generate diverse conformations for unseen protein systems. Unlike previous mothods (e.g., EigenFold), Str2Str is sequence-agnostic. The model learns protein conformation distribution without knowing the amino acid residue sequence. Through the proposed forward-backward dynamics, which is similar in vein to simulated annealing, the model is able to effectively explore different potential energy minima without suffering from rare event sampling problems.\n\nI find this manuscript well-written and provides promising results towards solving the protein conformation sampling challenge. Please see some of my main concerns below."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The major contribution of this work is the proposed forward-backward dynamics using a structure-based score model trained on the PDB dataset. From Fig. 5 and Fig. S3, it is clear that Str2Str outperforms other existing protein conformation sampling methods."
                },
                "weaknesses": {
                    "value": "See questions."
                },
                "questions": {
                    "value": "- What is the difference between the proposed Str2Str pipeline and applying forward-backward dynamics using a pretrained FrameDiff?\n\n- Is it possible to provide an additional ablation study on a few fast-folding proteins, where only alpha-Carbon coordinates are modeled? Maybe you can just turn off the rotation loss. I am curious whether frames are essential for accurate protein conformation sampling.\n\n- From Appendix >> Inference Stage on page 22, the ensemble structures is obtained by merging samples from each perturbation scale, in total 1,000 conformations for fast-folding proteins. It is surprising that metrics such as JS-PwD/MAE-TM remains so small even though $T_{\\delta}$ can be as large as 0.7. I expect that many samples are quite different from the starting conformation, especially for large $T_{\\delta}$. Could you please explain this behavior?\n\n- Since the model is sequence-agnostic, the model should sample many \"outlier\" conformations, which is not accessible from the given protein sequence. In Fig. S5, are most of the shown structures valid conformations for each protein system?\n\n- Page 18, I do not understand why reweighting could not help improve relevant distributional metrics. Does that mean the model likelihood estimation is not accurate, or model diversity originates from model uncertainty? Quick check, if we manually make $\\log p_{X}$ a constant value across all samples, would it improve the metrics?\n\n- Would you mind showing model performance on the apo/holo dataset for a fair comparison with EigenFold?\n\n- Could you please (1) provide the source code in supplementary materials; (2) make the benchmark data open-access for reproducibility?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3973/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3973/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3973/Reviewer_Fe1f"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3973/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698695903559,
            "cdate": 1698695903559,
            "tmdate": 1700614431238,
            "mdate": 1700614431238,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "QGXNQgmyWu",
                "forum": "C4BikKsgmK",
                "replyto": "1lbTmuAeAW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Fe1f: Part 1"
                    },
                    "comment": {
                        "value": "We appreciate the insightful questions and helpful suggestions for improving our manuscript. We have appended the related experiments in the updated PDF. Our response to each question is as follows:\n\n**Questions:**\n\n**Difference between Str2str and Framediff + Forward-backward (FB) dynamics.**\n- Firstly, according to our experimental results in the paper, the amortized conformation sampling can be competent by a backbone generative model trained on PDB. Intuitively, our framework is ready to accommodate all backbone design methods [1,2,3,4] including FrameDiff [4] in a plug-and-play manner, by simply applying the FB dynamics. Among them, FrameDiff that consists of the Riemannian diffusion on $SE(3)^n$ and the IPA module of AF2[5] was acknowledged by us as a very effective score model to follow. \n- Secondly, we argue that Str2str is targeting a totally different task, based on an existing model Framediff: Framediff (and its counterpart [1,2,3]) aims to unconditionally sample novel and designable backbones; Str2str aims to approximate the underlying conformation distribution similar to MD. The model architecture coincidence comes from (as our main contributions) how we designed the zero-shot sampling pipeline and demonstrated the effectiveness of transfer learning and thus should not be criticized. \n- Specific implementation differences: (i) the ideal frame geometry (idealized bond lengths and angles) used during training and inference is sequence-specific instead of all alanine;  (2) the training data is set to be in length between 10 and 512. (that of framediff is >60, which is larger than most test systems), etc.\n\n**Ablation on orientation (rotation matrix) modeling.**\n- The original purpose of using \u201cframes\u201d is to be able to generate all heavy atom coordinates plus the packing module, where the orientation can be important. According to this suggestion, we newly conducted the training w/o rotation and compared it with the previous checkpoint trained w/ rotation. Given the limited time of rebuttal, both checkpoints are aligned to be 300,000 steps for fair comparison. As shown in Appendix C.4, modeling the orientations can be important for the zero-shot conformation sampling.\n\n**Explain the difference between high $T_\\delta$ sample and initial sample.**\n- An increased perturbation scale encourages structural diversity and the samples can be different from the starting conformation. Such phenomenon does not contradict with the resulting small JS-PwD/MAE-TM, because these metrics are compared with long reference MD: JS = JS(p_pred||p_MD); MAE = |diversity(pred) - diversity(MD) |. After sufficiently long simulation, MD trajectory also discovers the conformation states that are quite distant from the starting one. The \u201csmall\u201d resulting metrics demonstrate the model can mainly agree with the MD with small discrepancy (JS, MAE). \n\n\nReferences:\n\n[1] Watson, Joseph L., et al. \"De novo design of protein structure and function with RFdiffusion.\" Nature 620.7976 (2023): 1089-1100.\n\n[2] Ingraham, John, et al. \"Illuminating protein space with a programmable generative model.\" BioRxiv (2022): 2022-12.\n\n[3] Lin, Yeqing, and Mohammed AlQuraishi. \"Generating novel, designable, and diverse protein structures by equivariantly diffusing oriented residue clouds.\" arXiv preprint arXiv:2301.12485 (2023).\n\n[4] Yim, Jason, et al. \"SE (3) diffusion model with application to protein backbone generation.\" arXiv preprint arXiv:2302.02277 (2023).\n\n[5] Jumper, John, et al. \"Highly accurate protein structure prediction with AlphaFold.\" Nature 596.7873 (2021): 583-589."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3973/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700286985616,
                "cdate": 1700286985616,
                "tmdate": 1700286985616,
                "mdate": 1700286985616,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5ey2RS2lsF",
                "forum": "C4BikKsgmK",
                "replyto": "1lbTmuAeAW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Fe1f: Part 2"
                    },
                    "comment": {
                        "value": "**Questions (continued):**\n\n**Discussion on the possible sampling of outlier.**\n- Since there is no criterion defining \u201cvalid\u201d conformation, let us denote \u201cvalid\u201d as local minima belonging to the underlying distribution. For fast folding proteins, we can infer from the results in [6] that distant (if compared with a folded start) yet valid conformations are transient unfolded states. In Figure S6, large $T_\\delta$ tends to destroy the original fold, while keeping some local secondary structures. Especially in the case of WW domain (we complement a Figure S8), the main components become coil (loop) and loosened for large $T_\\delta$ . \n- On the other hand, using three JS divergences instead of simply comparing the diversity takes the outlier into consideration during evaluation. The \u201cdiversity\u201d roughly reflects the radial of the space coverage while the \u201cJS\u201d penalizes the mistakes by sampling outliers in the wrong direction. The current gap between Str2str and MD reference represents one can still improve this imperfection in the future. In our humble view, even conditioning on sequence can neither guarantee the sampling of \u201cvalid\u201d conformation, if without enough training data. \n- Lastly, as a typical \u201cinvalid\u201d or \u201coutlier\u201d example, the idpGAN [7] has a strong tendency to sample coil components, which can belong to the \u201coutlier\u201d for most structural proteins. Therefore, the used fidelity metrics differentiate and penalize them based on the MD reference. \n\n**Investigation of reweighting (importance sampling).**\n- According to your suggestion, we have re-evaluated the ensemble w/ logp(X)=Constant (i.e. only use the FF to reweight). The JS-divergence results are [JS-PwD=0.471; JS-TIC=0.448; JS-Rg=0.487], which is still worse than that w/o reweighting. We dived into the details and have the following preliminary analysis:               \n  - We noticed the minimized energy for the generated ensembles has much larger standard deviations (~100 kcal/mol) than that in normal MD simulation (<10 kcal/mol) after equilibration. Since the energy is mainly contributed by the side chains, we probe our packing module (FASPR) by re-packing a batch of equilibrated conformation. The minimized energy of the repacked conformations is 50-100 kcal/mol higher than the pre-packed energy. Such results show that, even given perfect backbones, it still fails to generate low-energy side-chain conformation within the minimization steps. Therefore, the importance weight is not stable or accurate, which causes large variance to the estimation. As illustration, energy difference in 5 kcal/mol under 300K will lead to weight $w \\approx 4414$. The distribution will be sharply biased toward very few samples, making the estimation much worse by using only 1000 samples. In practice, a more robust packing module can be used to perform effective energy reweighting.\n\n**Apo/holo dataset.**\n- According to your suggestion, we have added the apo/holo benchmark in comparison with EigenFold by strictly following their settings, which is updated in Appendix F.4. \n\n**Code / reproducibility.**\n- We are currently refactoring the codebase into a more user-friendly version. As stated in the Reproducibility Statement paragraph, we promised all source codes, scripts, training data, necessary artifacts and experimental environments (settings) will be released upon the acceptance of this work. The benchmark MD trajectories are obtained from the original authors in D.E. Shaw Research (DESRES, https://www.deshawresearch.com/index.html). According to the DESRES License 3(e), \u201cLicensee shall not\u2026disclose, without DESRES's prior written approval, the Datasets, whether in whole or in part, other than as expressly authorized hereunder\u2026\u201d. It is thus illegal to put them on OpenReview during the double-blind review. For both reproducibility and legal purposes, we will  sincerely ask DESRES whether it is proper/how to share the benchmark data upon acceptance.\n\nReferences:\n\n[6] Lindorff-Larsen, Kresten, et al. \"How fast-folding proteins fold.\" Science 334.6055 (2011): 517-520.\n\n[7] Janson, Giacomo, et al. \"Direct generation of protein conformational ensembles via machine learning.\" Nature Communications 14.1 (2023): 774.\n\n\nWe sincerely hope our response can address your concerns. If you have other questions, we are very glad to discuss them during the rebuttal."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3973/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700287264738,
                "cdate": 1700287264738,
                "tmdate": 1700287264738,
                "mdate": 1700287264738,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KZJKPwsBi0",
                "forum": "C4BikKsgmK",
                "replyto": "1lbTmuAeAW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Look forward to further feedbacks during the reviewer-author discussion period"
                    },
                    "comment": {
                        "value": "Dear Reviewer Fe1f,\n\nThank you for your helpful suggestions and the recognition of the contribution of our paper. We sincerely appreciate your feedback and have carefully responded to each question point-by-point.\n\nThis is a kind reminder that as the reviewer-author discussion period is ending soon, we look forward to hearing from you about your feedback to our response. (Unlike previous years, there will be no second stage of reviewer-author discussion this year)\n\nIn particular, we have added more experimental results and related discussion per your advice. If you need any clarification, please feel free to contact us and we are very glad to discuss with you.\n\nThank you again for your precious time and effort !\n\nBest regards,\n\nAuthors #3973"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3973/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700605292173,
                "cdate": 1700605292173,
                "tmdate": 1700605292173,
                "mdate": 1700605292173,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zwXJF82KlF",
                "forum": "C4BikKsgmK",
                "replyto": "1lbTmuAeAW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3973/Reviewer_Fe1f"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3973/Reviewer_Fe1f"
                ],
                "content": {
                    "title": {
                        "value": "Response to author rebuttal"
                    },
                    "comment": {
                        "value": "Dear authors,\n\nThank you for your response, which addressed most of my concerns. My evaluation has been updated accordingly.\nLastly, would you mind showing the TM$_\\mathrm{ens}$ plot (EigenFold Fig 5) in the appendix?"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3973/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700614415882,
                "cdate": 1700614415882,
                "tmdate": 1700614595628,
                "mdate": 1700614595628,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "tobho058JE",
            "forum": "C4BikKsgmK",
            "replyto": "C4BikKsgmK",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3973/Reviewer_dLpk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3973/Reviewer_dLpk"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose STR2STR, a structure-to-structure framework to perform conditional conformation sampling of protein structures. The goal of conformation sampling is to sample new stable, energetically favorable structures from an initial protein structure. DIirecting atomistic modeling of protein structure is often intractable due to the size and high degrees of the system. Rather than sampling the entire structure at once, the authors reformulate the task into multiple conditional sampling tasks. The backbone is generated conditioned on a ground truth conformation. The backbone and ground truth conformation are used to then generate the side chains and carbonyl oxygen on the backbone. The authors present an updated implementation of the invariant point attention from AlphaFold and show that their confirmation sampling process is SE(3) equivariant. Compared to recent deep learning methods, STR2STR has comparable validity while improving fidelity and diversity of generated conformations."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The authors present a novel representation decomposition for protein structures to enable structure-to-structure translation using a diffusion model.\n* The amortized learning objective which uses only pre-confromed data and does not require new simulated sets is significant and can reduce the cost of training future models.\n* The improved diversity and fidelity of the model while not relying on simulated conformations is also significant. Improvements over EigenFold, a similar diffusion model is interesting."
                },
                "weaknesses": {
                    "value": "* The benchmarks set is small and make it difficult to judge the results provided. \n* Some presentation issues (refer to clarifications)"
                },
                "questions": {
                    "value": "* \u201cWe notice that the ensemble diversity is not the higher the better and depends on the characteristics of the target system\u201d\nCould you please elaborate more on this?\n* Is there a reason run times are provided only for a single target protein rather than all 12 (other than the high cost of sampling)?\n* Any particular reason why 100ns MD simulation runtimes are not compared with STR2STR runtimes?\n    * According to Table 1, smaller trajectories sometimes outperform the proposed model. Having all the data allows the reader to have a more complete understanding of the capabilities of the proposed model"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3973/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3973/Reviewer_dLpk",
                        "ICLR.cc/2024/Conference/Submission3973/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3973/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698952480611,
            "cdate": 1698952480611,
            "tmdate": 1700502517363,
            "mdate": 1700502517363,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "irQ3mC5R3T",
                "forum": "C4BikKsgmK",
                "replyto": "tobho058JE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dLpk"
                    },
                    "comment": {
                        "value": "We sincerely thanks for your questions and helpful suggestions for improving our manuscript. We put our response to your concerns accordingly as follows:\n\n**Weakness:**\n\n**The size of the benchmark/test set.**\n- First we understand this concern. In fact, the authentic protein trajectory data (long enough) is very limited in the MD domain. Most previous MD research works did not make their data disclosed. The 12 fast folding protein trajectories run by the DEShaw Research are one of the most well-recognized. Though N=12 seems far fewer than common ML benchmarking practice, it is still one of the largest scales for test systems. For example, one related work [1] only chose a subset (N=5) out of these 12 to evaluate their performance. \n\n**General presentation issue.**\n- Thanks for your suggestions. Several clarification issues suggested by other reviewers are addressed by us. Meanwhile, we will pay attention to the overall writing of this manuscript.\n\n\n\n**Questions:**\n\n**Why is not diversity \u201cthe higher the better\u201d?**\n- This observation comes from the structural characteristics of different proteins. (i) Some proteins can show very deterministic structure, an extreme example is the cyclic peptides. In this case, the motions in the protein dynamics are limited, and thus with small ensemble diversity from MD simulations; (ii) On the other hand, other proteins show more dynamic behaviors like distinguishably different states. They can have relatively larger diversity, which can be loyally reflected in the long MD simulations. For example, the SARS-Cov-2 spike protein was found to have transitions between its open and closed states [2]. So it is reasonable to compare with a MD-reference diversity rather than claiming it is \u201cthe higher the better\u201d.\n\n**Time profiling is shown in Table 2 for one system only.**\n- The runtime profiling on one target is enough to demonstrate the efficiency of the proposed Str2str as (1) the runtime scale is significantly smaller; (2) different systems can share a similar maginitude of simulation time. To better illustrate, we profiled for 100us MD the smallest system (Chignolin) which takes ~95.2 GPU days, and the largest system (A3D) which takes ~200.8 GPU days. \n\n**The reason to profile 100us MD but not for 100ns.**\n- In MD domain practice, running for a scale between 100us (0.1ms) and 1ms is considered to be a typical \u201clong\u201d simulation to discover natural dynamic characteristics. For example, in [3,4], all the systems are simulated for at least 100us, up to 1ms. Thus, we see 100us as a doorsill to become \u201clong\u201d. Since longer simulation is considered to uniformly \u201cbetter\u201d reflect the real dynamics than the shorter one, we thus omit the shorter cases. Also to illustrate, 100ns MD simulation in the GTT case (in explicit solvent) on a single V100 still takes ~3.87 hrs to finish, let alone 100ns is generally considered \u201cnot enough\u201d in standard practice. \n\n\nReferences:\n\n[1] Arts, Marloes, et al. \"Two for one: Diffusion models and force fields for coarse-grained molecular dynamics.\" Journal of Chemical Theory and Computation 19.18 (2023): 6151-6159.\n\n[2] Gur, Mert, et al. \"Conformational transition of SARS-CoV-2 spike glycoprotein between its closed and open states.\" The Journal of chemical physics 153.7 (2020).\n\n[3] Shaw, David E., et al. \"Atomic-level characterization of the structural dynamics of proteins.\" Science 330.6002 (2010): 341-346.\n\n[4] Lindorff-Larsen, Kresten, et al. \"How fast-folding proteins fold.\" Science 334.6055 (2011): 517-520.\n\n\nWe sincerely hope our responses can address your concerns. If you have other questions, we are very glad to discuss them during the rebuttal."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3973/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700286537540,
                "cdate": 1700286537540,
                "tmdate": 1700286537540,
                "mdate": 1700286537540,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LK054EBG9q",
                "forum": "C4BikKsgmK",
                "replyto": "tobho058JE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Look forward to further feedbacks during the reviewer-author discussion period"
                    },
                    "comment": {
                        "value": "Dear Reviewer dLpk,\n\nThank you for your helpful suggestions and the recognition of the soundness and contribution of our paper. We sincerely appreciate your feedback and have carefully responded to each question point-by-point.\n\nUnlike previous years, there will be no second stage of reviewer-author discussion this year. If you have other question or need any clarification during this period, please feel free to contact us and we are very glad to answer.\n\nThank you again for your precious time and effort !\n\nBest regards,\n\nAuthors #3973"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3973/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700605887063,
                "cdate": 1700605887063,
                "tmdate": 1700605887063,
                "mdate": 1700605887063,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vAld5YuYyu",
                "forum": "C4BikKsgmK",
                "replyto": "irQ3mC5R3T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3973/Reviewer_dLpk"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3973/Reviewer_dLpk"
                ],
                "content": {
                    "title": {
                        "value": "Most of the concerns addressed"
                    },
                    "comment": {
                        "value": "Thank you for your detailed responses and for answering the concerns. \n\n> This observation comes from the structural characteristics of different proteins. (i) Some proteins can show very deterministic structure, an extreme example is the cyclic peptides. In this case, the motions in the protein dynamics are limited, and thus with small ensemble diversity from MD simulations; (ii) On the other hand, other proteins show more dynamic behaviors like distinguishably different states. They can have relatively larger diversity, which can be loyally reflected in the long MD simulations. For example, the SARS-Cov-2 spike protein was found to have transitions between its open and closed states [2]. So it is reasonable to compare with a MD-reference diversity rather than claiming it is \u201cthe higher the better\u201d\n\nThis is a reasonable observation. I believe the manuscript would benefit from clarifying this point when introducing the metric."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3973/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687302266,
                "cdate": 1700687302266,
                "tmdate": 1700687302266,
                "mdate": 1700687302266,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vnnmTdgJ5S",
            "forum": "C4BikKsgmK",
            "replyto": "C4BikKsgmK",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3973/Reviewer_BVKt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3973/Reviewer_BVKt"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a technique for sampling equilibrium distributions of proteins, eliminating the dependency on costly Molecular Dynamic simulations. The suggested technique utilizes the ESMFold protein embeddings and trains an equivariant denoising diffusion model using samples from the Protein Data Bank, predominantly featuring single folded states (i.e., absolute minima of the equilibrium distribution). During the testing phase, the model diffuses to a specified noise level, partially erasing the protein structure but not entirely, and then it denoises it again, resulting in a different protein conformation. This translation from one structure to another is employed to sample different conformations, starting from the folded structure. The method's effectiveness is assessed using various metrics such as validity (defined as the non-clash) fidelity (defined as the JS between reference and samples TICA distributions) and Diversity. The method seems to outperform previous works."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The motivation and goals of this work are very relevant. Being able to sample protein equilibrium distributions without need of computing expensive molecular dynamics can have a high impact in the sampling community.\n- The metrics used in the paper to assess the quality of the equilibrium distributions show the proposed method outperforms previous works.\n- The paper contains many metrics assessing different aspects of the generated distributions."
                },
                "weaknesses": {
                    "value": "1)\nA more thorough review of prior studies could be beneficial. For instance, EigenFold (Jin et al, 2023) is a diffusion model trained solely on PDB samples with the same aim to generalize to protein distributions. It would be highly useful for readers to have a more detailed comparison between the proposed method and EigenFold, specially considering the apparent superior performance of the proposed method.\n\n1.1 What is novel in the proposed method w.r.t. EigenFold?\n1.2 Is the performance gap between EigenFold and the proposed method attributed to a difference in the conceptual approach or is it due to a more technical element such as the use of ESMFold in place of OmegaFold embeddings?\n\nI think answering these questions can really benefit future works when trying to spot the key aspects of the model without need to dig into the codebase.\n\n\n\n2) \nThe validity metrics analyze the non-clash ratio, but it would also be as relevant to examine the distributions of bonds and ensure no bonds are breaking when categorizing a sample as valid. Have the authors conducted this analysis?"
                },
                "questions": {
                    "value": "1)\nThe core part of the proposal of this method is described in 3.2 (forward-backward Dynamcis) where I think a more elaborate explanation could be done here.\n\nFor example, when sampling a conformation T ~ p(T | x_0), is x_0 consistently the initiating folded structure, or could it be a T derived from a preceding sampling step?  This is not clear to me from the text. I imagine that if setting it always to the folded structure it would bias the distribution to the minima. Could the authors provide a more precise description of this in the method section?\n\n2)\nIn section 3.1, could the authors provide more details, or cite relevant literature, explaining how the side chain atoms are derived from the backbone atoms?\n\n3)\nIn the following sentence \"Empirically, increasing T_delta leads to enhanced diversity yet it may hurt exploitation by demanding more reverse steps\".\n\nIs this true for any T_delta value? I would suspect that if T_delta goes to a large enough amount of noise (reaching the gaussian distribution), the result would be equivalent sampling from the trained PDB distribution, resulting again in sampling from the folded minima instead of a diverse equilibrium dataset.\n\n4) In section 3.2 (Score Network architecture), the authors indicate that there have been minor modifications to IPA to include pair representations with edge layers. Could the authors provide more context as to why this is necessary and not arbitrary?\n\n5) In Appenix B, Algorithm 2\nHow is the algorithm returning x_0? Based on the paper wasn't x_0 the starting point?\n\n6) Better interpretation on why the method works:\nGiven that the model is optimized on the PDB dataset, we would expect it to only learn the PDB landscape. However when degenerating the process with the proposed approach it actually learns to generate samples close to the equilibrium distribution. Because it never had access to a Force Field and only to the folded state it is quite surprising it is able to \"make up\" that information. Could it be this is only possible because of the ESMFold embeddings? I.e. do these embeddings contain information about the protein landscape beyond the folded structure, and then are you recovering that information present in the ESMFold embeddings with the proposed method? It would be interesting to know the authors interpretation about this."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3973/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699462237037,
            "cdate": 1699462237037,
            "tmdate": 1699636358250,
            "mdate": 1699636358250,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "RrMhvNh6Z6",
                "forum": "C4BikKsgmK",
                "replyto": "vnnmTdgJ5S",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer BVKt: Part 1"
                    },
                    "comment": {
                        "value": "We firstly appreciate the insightful questions and suggestions for improving our manuscript. We have added corresponding experiments and discussion in the updated PDF. Our responses to the specific concerns are listed below:\n\n**Weakness:**\n\n**Review and contextualize str2str based on prior studies.**\n- We appreciate this suggestion and have appended a thorough review by contextualizing the prior works, especially the EigenFold in Appendix G.2. To answer the questions:\n   - Similarity: both models leverage PDB for training with a denoising score matching objective. Difference: the EigenFold modeled a mapping from the sequence-encoded latent space (OmegaFold embedding ) to the structure space, while the Str2str delineated solely the structure space and sampled conformations in an amortized manner. During inference, EigenFold performs classic conditional generation while Str2str transforms the unconditional distribution into a translation proposal, from which it samples diverse conformation.\n  - We note that Str2str does not use ESMFold [1] embedding but only the output structure, which is different from EigenFold. We reckon the performance gap is due to the fact that Eigenfold handles a more challenging conditional generative task, where the embedding condition ($s_i, z_{ij}$) is far more complicated than a scalar label (for example in [2]). Without enough training data for each condition, the resulting diversity is thus limited to a large extent. In contrast, Str2str learns the structure landscape from which the conformations are sampled and can perform better.\n\n**Examine bond breaking as validity.**\n- Thanks for raising this great point! We sincerely adopt this suggestion and investigate the bond-breaking ratio for each model. In specific, we have defined and evaluated a new validity metric (\u201dVal-Bond\u201d) showing the ratio of samples w/o violating a statistical upper bound for adjacent Ca-Ca atoms. Relevant contents are updated in Section 4.1, Appendix E & Table [1, S3-7], and the results show that conformations sampled by Str2str are nearly all valid w.r.t. both clash and bonding.\n\n[1] Lin, Zeming, et al. \"Evolutionary-scale prediction of atomic-level protein structure with a language model.\" Science 379.6637 (2023): 1123-1130.\n\n[2] Song, Yang, et al. \"Score-Based Generative Modeling through Stochastic Differential Equations.\" International Conference on Learning Representations. 2020."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3973/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700285444959,
                "cdate": 1700285444959,
                "tmdate": 1700285444959,
                "mdate": 1700285444959,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JsD9asAWkj",
                "forum": "C4BikKsgmK",
                "replyto": "vnnmTdgJ5S",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer BVKt: Part 2"
                    },
                    "comment": {
                        "value": "**Questions**\n\n**Clarification of the Forward-backward dynamics.**\n- Firstly, we clarify that the condition is consistently the input across experiments. Here, we only use $p(T|T_0; \\theta)$ as a proposal distribution to obtain i.i.d. samples for each test system. A very natural extension echoing this question is that, we can craft a MCMC sampling pipeline by altering the starting point at each MCMC step $i$ and perform sample using $p(x^{[i+1]}|x^{[i]}; \\theta)$ where condition $x^{[i]}$ is the sample from the step $i-1$. According to your suggestion, we provide a description of this in the method section (page 4).\n\n**Description of side chain packing.**\n- We are sorry for not making it clear. In section 3.1, the sampling is conceptual and any form of the side-chain modeling can be used. The key idea is to sample atoms step-wise, from backbone to side-chains. In practice, as introduced in Section 3.2,  we used the packing module FASPR [3] which performs a rotamer-library search. Other packing methods can also be used, such as Diffpack [4] that predicts the torsion angles and use them to recover the corresponding atoms similar to what is done in AF2 [5].\n\n**The effect of $T_\\delta$ on ensemble diversity.**\n- Thanks for bringing up this question. To investigate this behavior, we additionally investigated the ensemble diversity versus different $T_\\delta$ in Appendix F.3 / Figure S7. Indeed, the diversity tends to plateau after $T_\\delta$=0.8 for PF and SDE, which shows the enhancement of diversity does not apply to all $T_\\delta$. We appreciate this empirical finding and have left a remark accordingly in the paper. Moreoever, from a theoretical view, the forward diffusion will not reach the Gaussian even for T=1.0; it only approximates the Gaussian when $t$ goes up and it is not strictly equivalent to sampling from a gaussian noise.\n\n**The motivation of using edge layers.**\n- We here justify the rationale: the DenoisingIPA can be viewed as a variant of the StructureModule (SM) in AF2 that translates frames to frames. The original SM only updates the single representation $s_i$, frames $T_i$ but not pair representation $z_{ij}$. Since the $z_{ij}$ there is the output of a strong encoder model called Evoformer. We can anticipate very informative $z_{ij}$ even without any updating inside the SM. However in our case, the initial $z_{ij}$ is as simple as the input embedding (time, position). So it is better to update the pair representation along inside $s_i, T_i$ in the model.\n\n\n**Typo in algorithm 2.**\n- Thanks for pointing this out. We have refined the notation in Algorithm 2. Also, we note that a change of variable is applied for the backward time domain $[T_\\delta, 2T_\\delta]$ so that we can conveniently leverage the prior discretization of time.\n\n**Interpretation on why str2str works.**\n- Thank you for starting us off with this insightful question. \n  - Firstly, we summarize that Str2str learns the vector fields, i.e. score, pointing towards a data-like stuff in the whole structure space (protein landscape). Thus, the trained model can (be expected to) push arbitrary perturbed structure to a nearby data-like minima. Str2str demonstrates a typical transfer learning setting by pretraining on PDB dataset, which enables it to do zero-shot conformation sampling for unseen proteins. Unlike EigenFold, str2str does not rely on sequence embedding but only an initial geometric frame during inference. \n  - \u201cThe reason why the model works\u201d can lie in our key assumption that: the dynamic patterns among conformations can be partially shared with the patterns between different structures in the PDB. That is to say, the common inter-protein structure differences in the training set can be distilled in the score network, which is \u201cunlocked\u201d during sampling to infer the inter-conformation deviation within a specific protein system. This agrees with the fundamental motivation of \u201cgeneralization\u201d in deep learning.\n\nReferences:\n\n[3] Huang, Xiaoqiang, Robin Pearce, and Yang Zhang. \"FASPR: an open-source tool for fast and accurate protein side-chain packing.\" Bioinformatics 36.12 (2020): 3758-3765.\n\n[4] Zhan, Yangtian, et al. \"DiffPack: A Torsional Diffusion Model for Autoregressive Protein Side-Chain Packing.\" arXiv preprint arXiv:2306.01794 (2023).\n\n[5] Jumper, John, et al. \"Highly accurate protein structure prediction with AlphaFold.\" Nature 596.7873 (2021): 583-589.\n\nWe really hope the above responses and revisions can address your concerns. Please kindly let us know if you have any other questions. We\u2019re always happy to have further discussion and improve the quality of the manuscript."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3973/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700286078537,
                "cdate": 1700286078537,
                "tmdate": 1700286078537,
                "mdate": 1700286078537,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wVYcHkeng3",
                "forum": "C4BikKsgmK",
                "replyto": "vnnmTdgJ5S",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3973/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Look forward to further feedback during the reviewer-author discussion period"
                    },
                    "comment": {
                        "value": "Dear Reviewer BVKt,\n\nThank you for your helpful suggestions and the recognition of the soundness and contribution of our paper. We sincerely appreciate your feedback and have carefully responded to each question point-by-point.\n\nThis is a kind reminder that as the reviewer-author discussion period is ending soon, we look forward to hearing from you about your feedback to our response. (Unlike previous years, there will be no second stage of reviewer-author discussion this year)\n\nIn particular, we have added more experimental results and discussions per your advice. Please refer to our posted point-to-point response and we are glad to discuss with you.\n\nThank you again for your precious time and effort !\n\nBest regards,\n\nAuthors #3973"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3973/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700605015181,
                "cdate": 1700605015181,
                "tmdate": 1700605015181,
                "mdate": 1700605015181,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]