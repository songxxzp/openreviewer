[
    {
        "title": "On Using Admissible Bounds for Learning Forward Search Heuristics"
    },
    {
        "review": {
            "id": "640LCsu4PO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5741/Reviewer_j4wF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5741/Reviewer_j4wF"
            ],
            "forum": "K6iBe17Y16",
            "replyto": "K6iBe17Y16",
            "content": {
                "summary": {
                    "value": "This paper proposes to learn planning heuristics for forward search algorithms. The authors propose using truncated Gaussians to model the distribution of the learned heuristics. This modeling change results in a different loss function from the standard MSE loss. Empirical evaluations are provided in three classical planning domains."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. I found the exposition interesting: connecting the MSE loss with the assumption that the empirical distribution is a Gaussian distribution with a fixed variance motivates the proposed method well. \n\n2. Employing existing knowledge to obtain lower bounds to further constrain the estimated distribution is a simple and elegant method to make the predictions more informative. The empirical evidence shows such an additional constraint improves the search efficiency."
                },
                "weaknesses": {
                    "value": "1. The choice of using Greedy Best-first Search (GBFS) needs more justification as it is not guaranteed to find optimal solutions. Can the authors explain why they did not choose to experiment with A*?\n\n2. Overall the empirical results are quite weak. While the negative log-likelihood (NLL) and MSE losses improve, the downstream search performance, i.e., the average number of node evaluations, compared to baselines (either the non-truncated Gaussian or using $h^{FF}$ directly) is not convincing. \n\n3. A popular direction for evaluating the effectiveness of a learned heuristic is to test how well it generalizes to larger instances of a class of problems. The current evaluations focus only on problems generated with the same set of parameters. Adding this kind of generalization experiment would demonstrate the practical value of the proposed approach better.\n\n4. The three classical planning problems should have sufficiently detailed descriptions."
                },
                "questions": {
                    "value": "Please see the above section for my question regarding the choice of the search algorithm.\n\nAdditionally, can the authors add the standard deviation numbers for the average number of node evaluations to Table 2?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5741/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5741/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5741/Reviewer_j4wF"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5741/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697408905418,
            "cdate": 1697408905418,
            "tmdate": 1700680920026,
            "mdate": 1700680920026,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Ww1ZDuxRP3",
                "forum": "K6iBe17Y16",
                "replyto": "640LCsu4PO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5741/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5741/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for your valuable feedback and questions.\nWe are pleased to know you believe our method is well-motivated,\n_\"simple\"_ and _\"elegant\"_.\nWe now answer the questions and concerns you have raised.\n\n> The choice of using Greedy Best-first Search (GBFS) needs more justification as it is not guaranteed to find optimal solutions. Can the authors explain why they did not choose to experiment with A*?\n\nThe reason for choosing GBFS over A\\* is that the learned heuristic $\\hat{h}$\nis not guaranteed to be **admissible**, regardless of the ML method employed\n(NLM, LR or HGN) and how the heuristic is modelled ($\\mathcal{N}$ vs $\\mathcal{TN}$).\nAn admissible heuristic is one that never exceeds the optimal plan cost\n$h^*$ for any state: $\\forall s \\in S, \\hat{h}(s) \\leq h^*(s)$.\nUnlike symbolic algorithms, machine learning methods (e.g., neural networks) do not provide such guarantees in general.\nIt is important to note that this issue is not particular to our approach since, to the best of our knowledge, **all heuristics learned by ML methods lack admissibility**.\n\nThe A\\* algorithm is guaranteed to return an optimal plan *only when* the heuristic used to guide the search is admissible (Russell and Norvig, 2010, pp. 94-95). Since $\\hat{h}$ is inadmissible, we cannot guarantee solution optimality regardless of the search algorithm employed (A\\* or GBFS).\nTherefore, we disregard plan length altogether and evaluate search performance as the number of node evaluations needed to find a solution, i.e.,\nfocus on satisficing planning.\n\nIn satisficing planning, A\\* is known to often be slower than WA\\* and GBFS (corresponding to WA\\* with $W\\rightarrow\\infty$) because it needs to explore all the nodes below the best current $f=g+h$ value, while WA\\* and GBFS do not.\nThis is the main reason why our work and many others in the heuristic learning literature (Ferber et al., 2022; Gehring et al., 2022; Yoon et al., 2008) employ GBFS instead of A*. **A* is not an appropriate baseline for the satisficing setting.**\n\n> Overall the empirical results are quite weak. While the negative log-likelihood (NLL) and MSE losses improve, the downstream search performance, i.e., the average number of node evaluations, compared to baselines (either the non-truncated Gaussian or using directly) is not convincing.\n\nWe address this concern in the common answer to all reviewers (additional tiebreaking experiments).\n\n> A popular direction for evaluating the effectiveness of a learned heuristic is to test how well it generalizes to larger instances of a class of problems. The current evaluations focus only on problems generated with the same set of parameters. Adding this kind of generalization experiment would demonstrate the practical value of the proposed approach better.\n\nWe have performed new experiments where we test the generalization abilities of the learned heuristics on larger problems. An overall analysis of the results obtained can be found in the common answer to all reviewers.\n\n> The three classical planning problems should have sufficiently detailed descriptions.\n\nWe have added detailed descriptions for the three domains (blocksworld, logistics and satellite) used in our paper, along with their PDDL encodings.\nThis information can now be found in Appendix I.\n\n> Can the authors add the standard deviation numbers for the average number of node evaluations to Table 2?\n\nWe have added the std of node evaluations, as requested.\nThis new information can be found in Appendix F.\n\nWe hope to have successfully addressed all your questions and concerns with our answers and paper additions."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5741/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700354559460,
                "cdate": 1700354559460,
                "tmdate": 1700679547424,
                "mdate": 1700679547424,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sQgSaKM4fy",
                "forum": "K6iBe17Y16",
                "replyto": "640LCsu4PO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5741/Reviewer_j4wF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5741/Reviewer_j4wF"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "I want to thank the authors for their detailed responses to my questions. I am glad to see the new tie-break strategy helps improve the results. However, I still have concerns with the empirical results. The generalization results in the Appendix only concern the NLL and MSE without planning results. Combined with the fact the three planning tasks are quite artificial, I think the overall evaluation could be strengthened. I will raise my score to 5."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5741/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700680902531,
                "cdate": 1700680902531,
                "tmdate": 1700680931271,
                "mdate": 1700680931271,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "TYXrT52SLC",
            "forum": "K6iBe17Y16",
            "replyto": "K6iBe17Y16",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5741/Reviewer_hjVN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5741/Reviewer_hjVN"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies heuristic learning by utilizing the information provided from admissible heuristics as informative bounds. To this end, instead of the traditional approach of minimizing mean square errors, the authors propose to model the learned heuristic as a truncated gaussian and subsequently minimize the loss function resulted from such a statistical/distributional assumption. As such, the authors claim to provide some theoretical understanding which is often lacking in the past work. Experiments are conducted and they show that the proposed method does contain certain merits."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The presentation is very clear and overall, the paper is easy to follow and digest. The proposed method also makes intuitive sense. Given that there are additional information available, it makes sense to utilize them in the modeling instead of going with the traditional gaussian case. The experiments also, to certain extent, verify the founding."
                },
                "weaknesses": {
                    "value": "The contributions of this paper may seem weak and limited. For example, the connection among MLE, Gaussian, MSE is well-known and Section 3 seems to be elementary. If admissible bounds are available, it seems straightforward/natural to refine the distributional assumption. Overall, I think this paper contains a good practical study but it doesn't seem to be innovative enough to justify the acceptance."
                },
                "questions": {
                    "value": "Could the authors provide some discussions on how certain assumptions in the current manuscript would change the result/model? For example, \"In this paper, we assume unit-cost: \u2200a \u2208 A; COST(a) = 1;\" \"In this work, we focus on the scenario where an admissible heuristic is provided along with the optimal solution cost h\u2217 for each state, leaving other settings for future work.\""
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5741/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697577566096,
            "cdate": 1697577566096,
            "tmdate": 1699636601507,
            "mdate": 1699636601507,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bHpofNs1xq",
                "forum": "K6iBe17Y16",
                "replyto": "TYXrT52SLC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5741/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5741/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for your valuable feedback and comments.\nWe are glad you found our paper _\"easy to follow\"_ and believe\nour approach _\"makes intuitive sense\"_.\nWe now answer the questions and concerns you have raised.\n\n> the connection among MLE, Gaussian, MSE is well-known and Section 3 seems to be elementary.\n\nThat is correct, since the aim of Section 3 is providing an extended background rather than explaining our contributions. This background is intended to serve as context for researchers who may not be familiar with this statistical knowledge (e.g., from the AI planning community).\nSection 4 builds upon this background to present what is the **main contribution** of our paper: using admissible heuristics as lower bounds of a $\\mathcal{TN}$ distribution modelling the learned heuristic."
                    },
                    "title": {
                        "value": "General reply"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5741/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700354359050,
                "cdate": 1700354359050,
                "tmdate": 1700359578374,
                "mdate": 1700359578374,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "86SIAfMWfZ",
                "forum": "K6iBe17Y16",
                "replyto": "TYXrT52SLC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5741/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5741/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Discussion about novelty"
                    },
                    "comment": {
                        "value": "> it seems straightforward/natural ...\n\nUsing admissible heuristics as lower bounds of a $\\mathcal{TN}$ distribution may appear trivial in the hindsight, but it is not straightforward nor obvious.\n\nWhile there exist several works that leverage $\\mathcal{TN}$ for machine learning,\ntheir usage is most often discussed in the context of safety-aware planning.\nFor example,\n(Murray et. al, 2023) uses a $\\mathcal{TN}$ to model a Simple Temporal Network with Uncertainty (STNU) which can model a distribution of time within a specific start time / deadline.\n(Eisen et al, 2019) uses a $\\mathcal{TN}$ to optimize wireless device allocations, where the truncation encodes the minimum (0) and maximum signal power output.\nIn robotics, it is common to use $\\mathcal{TN}$ for exploration (Chen et al, 2018) or\nto limit the measurement uncertainty of acceleration, velocity, positions (Kamran et al, 2018).\nIn all cases, upper/lower bounds are treated as a **static** and **arbitrary** constraint imposed by the environment or by a human operator.\n\nIn contrast,\nadmissible heuristics used as lower bounds in our work\nare **formal bounds automatically derived** by symbolic algorithms\nand are **dynamic**, as their value depend on each particular state\nexplored by a search algorithm (e.g., A\\*).\nFor example, Landmark-cut heuristic (Helmert, Domshlak, 2009) is computed by\nderiving a so-called landmark graph, then\niteratively reduces the edge costs in this graph on the edges that constitute a cut of the graph.\n\nTo our knowledge, **our work is first to show that such symbolic, dynamic, formally derived bounds can be combined with a $\\mathcal{TN}$ in order to aid training.**\n\nIn applications of machine learning to Operations Research problems (Vehicle routing problem, TSP),\nmost of the existing work tries to learn to solve the problems from the scratch without the help of heuristics (e.g., Nazari et al, 2018).\nAlthough some work (Liang et al, 2021) uses the optimal solution obtained by traditional methods (e.g. Concorde) for training and\ncombines it with existing admissible heuristics (LKH heuristic) during testing,\nit does not use the heuristic for training nor as the lower-bound of a truncated Gaussian distribution.\n\nIn the context of heuristic learning for planning,\nthe only role proposed so far for symbolically-derived heuristics\nis as a training target (which, as discussed in Section 4, is not a good approach)\nor as a basis for residual learning (Yoon et al, 2009).\nThe situation is similar in the Reinforcement Learning literature.\nWhile there exist works that help value/Q-function learning through reward shaping,\nwhich is theoretically equivalent to residual learning (Ng, Harada, Russel, 1999),\nand its extension (Ching-An et. al., 2021, HuRL) which utilizes domain-specific hand-crafted heuristics,\nnone has leveraged heuristics as lower/upper bounds for improving learning so far.\nChing-An et. al. also discussed the relation of pessimistic and admissible heuristics\nas desirable properties of RL and planning heuristics,\nbut their method does not explicitly use the upper/lower bound property for training.\n\nFinally, the novelty of our work is also supported by the comments of Reviewers LPcd and 795y, the latter claiming that our paper _successfully challenges the accepted wisdom of using MSE when learning heuristics_.\n\n* Helmert, Malte, and Carmel Domshlak. \"Landmarks, critical paths and abstractions: what's the difference anyway?.\" Proceedings of the International Conference on Automated Planning and Scheduling. Vol. 19. 2009.\n* Murray, Andrew, et al. \"A column generation approach to correlated simple temporal networks.\" Proceedings of the International Conference on Automated Planning and Scheduling. Vol. 33. No. 1. 2023.\n* Eisen, Mark, et al. \"Learning optimal resource allocations in wireless systems.\" IEEE Transactions on Signal Processing 67.10 (2019): 2775-2790.\n* Chen, Tao, Saurabh Gupta, and Abhinav Gupta. \"Learning Exploration Policies for Navigation.\" International Conference on Learning Representations. 2018.\n* Kamran, Danial, et al. \"Minimizing safety interference for safe and comfortable automated driving with distributional reinforcement learning.\" 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2021.\n* Nazari, Mohammadreza, et al. \"Reinforcement learning for solving the vehicle routing problem.\" Advances in neural information processing systems 31 (2018).\n* Xin, Liang, et al. \"NeuroLKH: Combining deep learning model with Lin-Kernighan-Helsgaun heuristic for solving the traveling salesman problem.\" Advances in Neural Information Processing Systems 34 (2021).\n* Ng, Andrew Y., Daishi Harada, and Stuart Russell. \"Policy invariance under reward transformations: Theory and application to reward shaping.\" Icml. Vol. 99. 1999.\n* Cheng, Ching-An, Andrey Kolobov, and Adith Swaminathan. \"Heuristic-guided reinforcement learning.\" Advances in Neural Information Processing Systems 34 (2021)."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5741/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700359619986,
                "cdate": 1700359619986,
                "tmdate": 1700361567573,
                "mdate": 1700361567573,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RROzqQWp2O",
                "forum": "K6iBe17Y16",
                "replyto": "TYXrT52SLC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5741/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5741/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Effects of our assumptions on our approach and obtained results"
                    },
                    "comment": {
                        "value": "> \"In this paper, we assume unit-cost: \u2200a \u2208 A; COST(a) = 1;\"\n\nThis assumption does not affect our work in any way,\nas our method is completely agnostic to it.\nWe assumed unitary costs because most _PDDL_ domains only contain unitary-cost actions.\nOur training method only requires training data (i.e., $h^*$, $l$ and heuristic values for residual learning) to be represented as real numbers,\nand is indifferent to whether it originates from unitary or variable cost domains.\n\n> \"we focus on the scenario where an admissible heuristic is provided along with the optimal solution cost $h^\u2217$\"\n\nIn this work, we have focused on the case where both $l$ and $h^*$ are available, since this is the most common scenario in the cost-to-go learning literature (i.e., having a dataset with optimal costs and being able to compute domain-independent, admissible heuristics).\nThis case also includes the scenario where $l$ is not available but only $h^*$, since we can always use $l=h^{blind}$ or $l=0$.\n\nOther scenarios have been left out as future work (see Section 7, Paragraph 3).\nOne such scenario is when the upper bound $u$ is available in addition to $lb$. Our approach is perfectly compatible with this scenario and no modifications would be needed. Regarding results, we would expect an increase in performance due to the tighter interval for $\\mathcal{TN}$ provided by both $l$ and $u$ when compared to only $l$.\nAnother interesting scenario is when $h^*$ is not available. We are working on tackling this setting by using _Variational Inference_ and treating $h^*$ as a hidden variable. This would require some modifications to our method, such as the number of ML models trained and the loss function to optimize (now corresponding to the _ELBO_ instead of the _NLL_)."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5741/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700359642142,
                "cdate": 1700359642142,
                "tmdate": 1700362543931,
                "mdate": 1700362543931,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "p8cKf0CCBH",
            "forum": "K6iBe17Y16",
            "replyto": "K6iBe17Y16",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5741/Reviewer_795y"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5741/Reviewer_795y"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a new loss function for learning admissible heuristics in AI\nsearch. The authors argue that the widely-used MSE does not accurately model\nwhat we intend to optimize, describe their new loss function, and evaluate it\nempirically."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "The paper is well-written, the presented argument is convincing, and the\nempirical results further support it. This is a great paper that successfully\nchallenges the accepted wisdom of using MSE when learning heuristics."
                },
                "weaknesses": {
                    "value": "I have no concerns or questions regarding the work."
                },
                "questions": {
                    "value": "I have no concerns or questions regarding the work."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5741/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698689500805,
            "cdate": 1698689500805,
            "tmdate": 1699636601398,
            "mdate": 1699636601398,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TOjf8cmef9",
                "forum": "K6iBe17Y16",
                "replyto": "p8cKf0CCBH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5741/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5741/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for your encouraging words and valuable feedback.\nWe are deeply pleased to know you have enjoyed our paper and found it _\"well-written\"_, _\"convincing\"_ and note that _\"the empirical results further support it\"_.\nWe are delighted with your statement that _\"this is a great paper that successfully challenges the accepted wisdom of using MSE when learning heuristics\"_."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5741/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700354193129,
                "cdate": 1700354193129,
                "tmdate": 1700354193129,
                "mdate": 1700354193129,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "RuPIQebFQf",
            "forum": "K6iBe17Y16",
            "replyto": "K6iBe17Y16",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5741/Reviewer_LPcd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5741/Reviewer_LPcd"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a new approach for learning heuristic for forward search (specifically, for greedy best-first search) that can make use of admissible heuristics. The proposed approach is based on modelling the learned heuristic using truncated Gaussian and use the admissible estimates as lower bound for the distribution. The best approach that consists of using truncated Gaussian, learned $\\sigma$, and residual learning (based on the popular h^FF heuristic) significantly outperform other learning-based configurations in terms of accuracy and number of solved instances."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Strengths:\n- Novel approach for learning heuristics that makes principled use of admissible estimates.\n- The approach is compatible with residual heuristic learning and is agnostic of the neural architecture.\n- Experiments show increased accuracy and a larger number of planning instances solved under 10^4 evaluations."
                },
                "weaknesses": {
                    "value": "Weaknesses:\n- Missing state-of-the-art recent baseline: [Chrestien et al., 2022] is an alternative approach that also argues against using MSE and proposes an alternative approach. This baseline should be compared to the proposed approach for learning heuristics.\n- In the experiments, it looks that the standard h^FF baseline outperforms the proposed approach in terms of problem solved in two out of the three domains.\n- There is no analysis of performance vs. problem size. It would be very useful to see if the patterns depend on problem size.\n\nMinor point: in Section 3, the description of learning heuristic ignores the goal, the learning of heuristics is conditioned on the goal state since the same state will have different estimate conditioned on different states."
                },
                "questions": {
                    "value": "I would appreciate the authors' response to the weaknesses listed above. In particular, did you compare to [Chrestien et al., 2022] or other state-of-the-art approaches for learning heuristics?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5741/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698794562057,
            "cdate": 1698794562057,
            "tmdate": 1699636601290,
            "mdate": 1699636601290,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "c6eJKT3ZX6",
                "forum": "K6iBe17Y16",
                "replyto": "RuPIQebFQf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5741/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5741/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for your valuable feedback and insightful comments.\nWe are pleased to know you found our method _\"novel\"_ and _\"principled\"_.\nWe address your comments and concerns below.\n\n> a new approach for learning heuristic for forward search (specifically, for greedy best-first search)\n\nJust a small clarification. The heuristic learned with our method is not tailored to any specific search algorithm (e.g., GBFS) and can in principle be applied to other algorithms such as A\\*. We use GBFS in our experiments because the heuristic learned with our approach (or any other ML method) is never guaranteed to be admissible and, thus, regardless of the search algorithm plan optimality is not guaranteed. Therefore, we disregard plan length altogether and focus on satisficing planning, i.e., finding a solution with as few node evaluations as possible. In satisficing search, A\\* is slower than WA\\* and GBFS (which corresponds to WA* with $W\\rightarrow\\infty$) because A\\* must explore all nodes below the current best $f=g+h$ value.\n\n> Missing comparison with (Chrestien et al., 2022)\n\nThank you for highlighting this interesting work. We would like to note that (Chrestien et al., 2022) follows the learning-to-rank approach initiated by (Garrett et al., 2016) which learns the relative quality between states, with an additional loss for enforcing heuristic monotonicity. We believe the method proposed in (Chrestien et al., 2022) corresponds to a learning-to-rank approach because the proposed L\\* loss function tries to rank the states expanded by A\\* before those which are not (as well as ranking them according to monotonicity), modeling the learning task as a binary classification rather than a regression as in our work.\n\nWe want to emphasize that **learning-to-rank methods deviate significantly from the cost-to-go learning literature** (which our work belongs to), both empirically and theoretically, as they pursue a different goal (correct node ordering vs correct cost-to-go estimation) and, thus, are significantly outside the scope of our work.\nOur paper aims at addresssing the lack of formal understanding in the cost-to-go learning literature and, in section 3, paragraph 8, we explicitly state that our goal is to learn the cost-to-go $p^*(x|s)$.\n\nLearning-to-rank methods directly optimize search performance by learning the node ordering. On the other hand, cost-to-go approaches learn to estimate the distance from some particular state to the goal, a unique capability missing from ranking-based methods. Being able to estimate the cost-to-go is useful in many practical applications, e.g., knowing the estimated travel time to destination in a mobile navigation app (e.g., Google Maps), as opposed to just\nknowing which direction to go at every intersection (equivalent to ranking the directions).\n\nApplying our theoretical intuition from $\\mathcal{TN}$ to the learning-to-rank approach\nis an interesting direction for future work.\n\n> In the experiments, it looks that the standard $h^{FF}$ baseline outperforms the proposed approach in terms of problem solved in two out of the three domains.\n\nWe address this concern in the common answer to all reviewers (new tiebreaking experiments).\n\n> There is no analysis of performance vs. problem size. It would be very useful to see if the patterns depend on problem size.\n\nWe have performed new experiments where we test the generalization abilities of the learned heuristics on larger problems. An overall analysis of the results obtained can be found in the common answer to all reviewers.\n\n> in Section 3, the description of learning heuristic ignores the goal\n\nThank you for bringing this oversight to our attention. It has now been corrected in the revision, by stating that heuristics depend on both states and goals."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5741/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700354149620,
                "cdate": 1700354149620,
                "tmdate": 1700360302803,
                "mdate": 1700360302803,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nnJJshv0zN",
                "forum": "K6iBe17Y16",
                "replyto": "c6eJKT3ZX6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5741/Reviewer_LPcd"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5741/Reviewer_LPcd"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "Thank your for your response.\n\n- My comment on GBFS is indeed due to the lack of admissibility of the learned heuristics.\n\n- Regarding (Chrestien et al., 2022): it is true that the setting of the two papers is different, however ultimately the goal of learning heuristics is to use them for planning. Given that the proposed approach is not learning admissible heuristic and is evaluated primarily in GBFS based on coverage, it is not clear to me why it should not be compared with (Chrestien et al., 2022) or other approaches that are focused on learning heuristics that achieve better coverage (for example, (Chrestien et al., 2022) did compare with L2 loss). If there is an inherent benefit for learning cost-to-go (in terms of planning performance) it should be demonstrated.\n\n- Results on large instances are encouraging, although it seems that h^FF still outperforms the proposed approach in terms of coverage in two of the domains. I think the new results about tie-breaking are interesting, but are not entirely convincing. It seems that you are creating many ties and then use h^FF to break ties and in the end achieve similar coverage to h^FF. If we consider a simple baseline that just predict a constant value and break ties using h^FF it will be able to get similar coverage to h^FF - therefore it is difficult to really observe the benefit of the proposed approach in terms of planning performance based on this experiment.\n\nOverall, I remain positive about the paper."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5741/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700706507562,
                "cdate": 1700706507562,
                "tmdate": 1700706507562,
                "mdate": 1700706507562,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "HrBy62BYwN",
            "forum": "K6iBe17Y16",
            "replyto": "K6iBe17Y16",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5741/Reviewer_63nm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5741/Reviewer_63nm"
            ],
            "content": {
                "summary": {
                    "value": "This paper discusses the use of modern machine learning techniques to learn heuristic functions for forward search algorithms. It highlights the lack of theoretical understanding regarding what these heuristics should learn, how to train them, and why they are trained in the first place, leading to a variety of training targets and loss functions in the literature. The authors argue that learning from admissible heuristics using mean square errors (MSE) as the loss function is not the correct approach because it results in a noisy, inadmissible heuristic. Instead, they propose modeling the learned heuristic as a truncated Gaussian, with admissible heuristics used as lower bounds. This approach results in a different loss function than MSE, leading to faster training convergence and better heuristics, with a 40 percent lower average MSE."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is enjoyable to read and fairly well organized by raising three core questions (what, how and why). The problem of choice of training target and loss function is also well-motivated. \n\n2. The experiments are relatively comprehensive and the results are pleasing."
                },
                "weaknesses": {
                    "value": "1. In my view, one of the main contributions of this paper is to use the NLL as their training loss instead of MSE, and NLL adds the prediction of $\\sigma$ (the variance) where MSE uses the fixed $\\sigma$. However, in my opinion, this technique will improve the performance very trivially since the model will predict better with more parameters.\n\n2. The authors explain the reason for using Gaussian distribution by giving the principle of maximum entropy, but the reason for using Truncated Gaussian seems missing and \nunconvincing."
                },
                "questions": {
                    "value": "In section 3, the authors claim that the importance of using NLL loss function instead of MSE. However, from the experiment results, the authors can only claim that $\\mathcal{T} \\mathcal{N}$ obtains around 40 percent lower MSE than $\\mathcal{N}$ +clip on (geometric) average, so does this truncated Gaussian technique play the major role of the outstanding performance of the experiment instead of the choice of loss function? And what is the statistical intuition behind it?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5741/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5741/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5741/Reviewer_63nm"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5741/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699162265186,
            "cdate": 1699162265186,
            "tmdate": 1699636601162,
            "mdate": 1699636601162,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4NHIoFVbth",
                "forum": "K6iBe17Y16",
                "replyto": "HrBy62BYwN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5741/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5741/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for your valuable feedback and comments.\nWe are glad you enjoyed reading our work.\nWe now answer the questions and concerns you have raised.\n\n### Re: Question 1\n\nFirstly, we would like to clarify a point of a slight confusion.\nYour comment mentions as follows:\n\n> In my view, ... to use the NLL as their training loss **instead of** MSE, ...\n\n> In section 3 ... the importance of using NLL loss function **instead of** MSE.\n\nLet us clarify that \"use NLL **instead of** MSE\" involves a slight misnomer,\nas the MSE is indeed a NLL for $\\mathcal{N}(\\mu, \\sigma=1/\\sqrt{2})$.\nIn our paper, we wrote:\n\n> [Main paper, Section 2, Paragraph 5] We emphasize that the choice of the distribution determines the loss.\n\nThis means that there is a 1-to-1 correspondence between the distribution used and the loss to minimize, i.e.,\nthey are **_two sides of the same coin_**.\nTherefore, as to the question\n\n> ... does this truncated Gaussian technique play the major role ... instead of the choice of loss function?\n\nWe answer that _the choice of our loss function is a direct consequence of choosing the truncated Gaussian distribution_,\ntherefore it is not possible to choose them separately.\nFor example, using a truncated Gaussian while minimizing a standard MSE loss\nis impossible/contradicting\n(minimizing MSE implies using $\\mathcal{N}(\\mu, \\sigma=1/\\sqrt{2})$).\n\nLikewise, switching modelling assumptions during training and evaluation\n(e.g., train the model with $\\mathcal{N}(\\mu, \\sigma)$, then reuse the network for $\\mathcal{TN}(\\mu, \\sigma, l, \\infty)$) is highly ad-hoc and should not be done.\n\n\nIn addition, regarding this comment:\n\n> the authors can only claim that $\\mathcal{TN}$ obtains around 40 percent lower MSE than $\\mathcal{N}+clip$ on (geometric) average, ...\n\nwe would like to mention that predictions from the $\\mathcal{N}+clip$ model are never worse than those of $\\mathcal{N}$, since $\\mathcal{N}+clip$ prevents incorrect\nheuristic predictions that are smaller than the admissible heuristic.\nTherefore, we can not only claim that $\\mathcal{TN}$ is better than $\\mathcal{N}+clip$, but also claim that it is better than $\\mathcal{N}$ too.\n\n### Re: Question 2\n\nNext, regarding the question\n\n> And what is the statistical intuition behind it?\n\nand a related weakness comment:\n\n> ... the reason for using Gaussian distribution by giving the principle of maximum entropy, but the reason for using Truncated Gaussian seems missing and unconvincing.\n\nWe emphasize that, as explained in Section 4 of our paper, $\\mathcal{N}$ and $\\mathcal{TN}$ are both maximum entropy (max-ent) distributions, but for different sets of initial constraints/assumptions (Dowson & Wragg, 1973). They both assume a finite mean and variance, but $\\mathcal{N}$ assumes its support is $\\mathbb{R}$ whereas $\\mathcal{TN}$ assumes it is an interval $(l, u)$.\n\nWe know that the value of the optimal heuristic $h^{\\ast}$ is always larger or equal to that of an admissible heuristic $h^{\\downarrow}$. Therefore, according to the max-ent principle, $h^{\\ast}$ should **not** be modelled as a $\\mathcal{N}$, but as a $\\mathcal{TN}$ with lower bound $l=h^{\\downarrow}$.\nThis modelling choice results in significantly better heuristics (see Tables 1 and 2).\n\n\n### Re: Weaknesses: More parameters?\n\n> NLL adds the prediction of $\\sigma$ ... the model will predict better with more parameters.\n\nOur improvement is not due to an increase in the number of parameters.\nIn order to predict $\\sigma$, the neural network (NLM) needs to have two outputs, but this only affects the size of the last linear layer of the network, which is negligible compared to the size and parameters of the entire network.\nMoreover, in our preliminary experiments, doubling the total number of model parameters (NLM width) did not significantly affect the performance.\n\nThe reason why our NLL loss outperforms the standard MSE is due to the underlying modelling assumptions:\nstandard MSE models $h^*$ as $\\mathcal{N}(\\mu,1/\\sqrt{2})$, which is bad;\nthe \"MSE with learned sigma\" models it as $\\mathcal{N}(\\mu,\\sigma)$, which is better but still bad;\nfinally, our NLL models it as $\\mathcal{TN}(\\mu,\\sigma,lb=h^{\\downarrow},\\infty)$, which is the best model both empirically and theoretically (max-ent distribution).\nThis is easy to check by looking at Table 1 in our main paper. It can be observed that $\\mathcal{TN}$ for the _fixed/none_ and _fixed/_ $h^{FF}$ configurations obtains better accuracy (_MSE_ rows) than $\\mathcal{N}$ for _learn/none_ and _learn/_ $h^{FF}$.\nThis means that an ML model that only predicts $\\mu$ (_fixed_ configurations) and is trained with our custom NLL outperforms another model that predicts both $\\mu$ and $\\sigma$ (_learn_ configurations) but is trained with the standard MSE.\n\nWe believe our answers address all your questions and concerns."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5741/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700353977482,
                "cdate": 1700353977482,
                "tmdate": 1700361249847,
                "mdate": 1700361249847,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]