[
    {
        "title": "Output-Domain Focused Inductive Bias on Latent Feature Clusters in Visual Classification"
    },
    {
        "review": {
            "id": "QremWk6V53",
            "forum": "cH3oufN8Pl",
            "replyto": "cH3oufN8Pl",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2285/Reviewer_7b4C"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2285/Reviewer_7b4C"
            ],
            "content": {
                "summary": {
                    "value": "The paper shows that neural networks tend to focus on input-domain-related information, such as visual similarities, which can conflict with unseen relations determined by human labeling in the output domain. This conflict limits the generalization of models. To address this problem, the authors propose a training strategy called Output-Domain focused Biasing (ODB), which emphasizes inductive biases based on output labels. ODB consists of four steps: learning intermediate latent object features, decoupling visual dependencies, capturing structured features optimized for classification, and integrating these features for prediction."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper aims to create inductive biases based on output labels, in order to avoid the dominance of input-domain focused bias. The motivation is relatively novel.\n2. The paper is well-structured and written in an accessible manner."
                },
                "weaknesses": {
                    "value": "1. The experimental improvements over the baselines are relatively modest, suggesting that the significance of Output-Domain focused Biasing (ODB) may be limited."
                },
                "questions": {
                    "value": "Is it possible for the authors to validate the efficacy of ODB in the context of domain adaptation? Is there a meaningful application of ODB in addressing input-domain bias when dealing with diverse visual domains?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2285/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2285/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2285/Reviewer_7b4C"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2285/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698680066559,
            "cdate": 1698680066559,
            "tmdate": 1700746929902,
            "mdate": 1700746929902,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Z7M4K778I9",
                "forum": "cH3oufN8Pl",
                "replyto": "QremWk6V53",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2285/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2285/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your comments!"
                    },
                    "comment": {
                        "value": "Thank you for all your efforts and detailed comments. \n\n> Weakness1. The experimental improvements over the baselines are relatively modest, suggesting that the significance of Output-Domain focused Biasing (ODB) may be limited.\n\nOur results show consistent and statistically significant improvement. We hope that the contribution on raising a new problem and its generality are more considered rather than the significance of performance gain determined by an unclear threshold. \n\n> Question1. Is it possible for the authors to validate the efficacy of ODB in the context of domain adaptation? \n\nWe can validate the efficacy in domain adaptation, but it requires more study, because domain adaptation allows not only tasks using the shared world knowledge, but also task-specific knowledge. \nWe hope that the knowledge of ODB is sufficiently general to work in even target domains for adaptation, but the conflict of task-specific knowledge may dominate the validation results. Unfortunately, recognizing which knowledge causes the conflict in neural networks is still challenging as far as we know. \n\n> Question2. Is there a meaningful application of ODB in addressing input-domain bias when dealing with diverse visual domains?\n\nWe think that potential applications of ODB are most supervised learning in visual domains where labeling may rely on some implicit knowledge of humans. Particularly, if a domain uses an input containing many latent objects to determine its label, it can be a more suitable application of ODB."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2285/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700208864776,
                "cdate": 1700208864776,
                "tmdate": 1700209100251,
                "mdate": 1700209100251,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "q9jq3ctI5a",
            "forum": "cH3oufN8Pl",
            "replyto": "cH3oufN8Pl",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2285/Reviewer_CuBT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2285/Reviewer_CuBT"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses the issue where vision neural networks learn latent features which are (naturally) too focused on the exact pixels that are part of the training dataset -- since this is all they see, ignorant of the real-world relationships between objects (as illustrated by how ignorant a neural network can be of the distance between a mop and a komondor dog). To remedy this, the authors propose a novel method (ODB) where an auxiliary loss is introduced in order to enforce diversity in the latent vectors across classes. This loss term is disconnected from the regular discriminative visual features, so as to not pollute it. The authors show across 5 random seeds that they achieve better results on ImageNet1K than well-known baselines."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The ODB approach does not use additional pre-training with large datasets and/or regularization such as MixUp or CutMix\n* The performance of the approach is inspected thoroughly both quantitatively and qualitatively.\n* The authors include transparent results on how they selected their hyperparameters in the appendix."
                },
                "weaknesses": {
                    "value": "* The term of output-domain knowledge is very vague/difficult to interpret. At one point in the introduction you instead write 'undescribed world knowledge', which I think refers to the same thing, and is more clear to me. Would it make sense to use another name than ODB? Specifically to change the OD to something else. This would make the paper clearer. Output domain is the domain where you test, which I think does not really do the job here.\n\n* In the related work, a knowledge graph is mentioned briefly while describing the method of one work. However, I miss a small section about the general idea of including hierarchical information or knowledge-graph representations into visual representations, which these authors are not the first to explore. For that reason, it becomes a bit difficult to buy when the authors claim they are the first to raise the issue of the implicit 'output-domain' knowledge missing during training, and a more complete related work section here would make the paper stronger (see for example the related work of Pan et al.)\n\n* The conclusion and future work section does not really contain recommendations for future work."
                },
                "questions": {
                    "value": "### Detailed comments\n\n* In A.1, you refer to Tables 7a and 7c although I believe you mean Figure 7 and 7c.\n* Conclusion: the phrasing \"harbors unseen knowledge from human labeling\" was difficult to parse and ambiguous.\n* Conclusion: \"on vision transformer architecture\" >> \"on the Vision transformer architecture\"\n* Conclusion: \"in qualitative and quantitative analysis on its results\" >> \"through qualitative and quantitative analysis of its results\"\n* Table 2: Why not show the standard deviation if in effect these results were run using 5 random seeds? It seems relevant in your comparison to the baseline which is quite close (84.80 vs. 84.40). You cannot use the term 'significant' in the Ablation study section of Section 5.1 if you do not show these standard deviations.\n* Table 2: explain what w/o Pos. stands for in table caption, even if you also say it in the text (if somebody glances quickly at the table.)\n* Formatting of references generally needed, use {} around text which should be case-sensitive in the .bib-file. (e.g., \"mixup\" >> \"MixUp\" for Zhang et al.)\n* In the end of Section 5.2, it would be great to specify either in the text or in the figure caption which classes numbers 1173 and 1813 correspond to. Are they the quill and paperknife or other visually similar classes?\n* 5.1 title: quantiTative*\n* Section 4: \"doesn\u2019t\" >> \"does not\" (too informal)\n* Section 4: \"provide series of analysis the impact\" >> \"provide a series of analysEs OF the impact\"\n* The second paragraph of the related work contains a duplicate sentence \"Lemesle et al...\". Should be removed.\n* Fig. 3 is a nice figure. Howeve,r it currently says \"L_diveristy\"  whereas I think you want to say \"L_diversity\"."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2285/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698775313247,
            "cdate": 1698775313247,
            "tmdate": 1699636161216,
            "mdate": 1699636161216,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "IHgHnCAwUN",
                "forum": "cH3oufN8Pl",
                "replyto": "q9jq3ctI5a",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2285/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2285/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your comments!"
                    },
                    "comment": {
                        "value": "Thank you for all your efforts and constructive comments. We have highlighted the revisions in our paper with purple text color based on the recommendation.\n\n> Weakness1. The term of output-domain knowledge is very vague/difficult to interpret. At one point in the introduction you instead write 'undescribed world knowledge', which I think refers to the same thing, and is more clear to me. Would it make sense to use another name than ODB? Specifically to change the OD to something else. This would make the paper clearer. Output domain is the domain where you test, which I think does not really do the job here.\n\nWe agree that the term  \u2018output-domain knowledge\u2019 does not intuitively align with our paper's interest. We revised terminology to avoid using 'OD' as follows\n\nLabel-focused inductive bias is the inductive bias determined by categorization of latent objects based on only labels, while undescribed world knowledge indicates all unexpressed world knowledge on the objects in human labeling. We use the term \u2018UWK\u2019 for \u2018Undescribed World Knowledge over latent objects in human labeling\u2019 \n\nWe revised related sentences (including titles) to use the terminologies, too. \n1)  \u2018Output-domain focused inductive biasing\u2019 (the method) -> Label-focused Latent-object Biasing (LLB)\u2019 \n2) \u2018output-domain focused inductive bias\u2019 -> label-focused inductive bias\n3) implicit relations over latent objects used for  human labeling(output-domain) -> undescribed world knowledge\n\n> Weakness2. In the related work, a knowledge graph is mentioned briefly while describing the method of one work. However, I miss a small section about the general idea of including hierarchical information or knowledge-graph representations into visual representations, which these authors are not the first to explore. For that reason, it becomes a bit difficult to buy when the authors claim they are the first to raise the issue of the implicit 'output-domain' knowledge missing during training, and a more complete related work section here would make the paper stronger (see for example the related work of Pan et al.)\n\nWe appreciate your valuable suggestion, as it notably helps to strengthen our proposal.\nWe added a paragraph and revised other paragraphs in the related work. In the second paragraph (Conflict Reduction via Knowledge Graph) in the related work section, we discuss previous works of using structured information such as knowledge graph in order to reduce input-domain focused bias.  It discusses the following references as follows. \n* Kenneth Marino, Ruslan Salakhutdinov, and Abhinav Gupta. The more you know: Using knowledge graphs for image classification. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2673\u20132681, 2017.\n* Xiaolong Wang, Yufei Ye, and Abhinav Gupta. Zero-shot recognition via semantic embeddings and knowledge graphs. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 6857\u20136866, 2018.\n* Michael Kampffmeyer, Yinbo Chen, Xiaodan Liang, Hao Wang, Yujia Zhang, and Eric P Xing. Rethinking knowledge graph propagation for zero-shot learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 11487\u201311496, 2019.\n* Lewei Yao, Jianhua Han, Youpeng Wen, Xiaodan Liang, Dan Xu, Wei Zhang, Zhenguo Li, Chunjing Xu, and Hang Xu. Detclip: Dictionary-enriched visual-concept paralleled pre-training for open-world detection. Advances in Neural Information Processing Systems, 35:9125\u20139138, 2022\n* Chenchen Zhu, Fangyi Chen, Uzair Ahmed, Zhiqiang Shen, and Marios Savvides. Semantic relation reasoning for shot-stable few-shot object detection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 8782\u20138791, 2021.\n\nTo the best of our knowledge, previous works focus on the effective use of external knowledge, while undescribed world knowledge over latent objects in human labeling of target training data has not been utilized and even recognized. Please check the related work section for more detailed discussions.\n\n> Weakness3. The conclusion and future work section does not really contain recommendations for future work.\n\nIn the conclusion of our paper's revised edition, we implemented the following revisions:\nBeyond using the plug-in model, effectively harmonizing the undescribed world knowledge with input-domain focused bias on a simple network still remains an open question. Also, we hope that our approach will evoke further research on diverse visual domains."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2285/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700208771668,
                "cdate": 1700208771668,
                "tmdate": 1700208799236,
                "mdate": 1700208799236,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "xoCUMeJGtz",
            "forum": "cH3oufN8Pl",
            "replyto": "cH3oufN8Pl",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2285/Reviewer_9BG9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2285/Reviewer_9BG9"
            ],
            "content": {
                "summary": {
                    "value": "This paper analyzes the inductive bias problem in existing methods and proposes Output-Domain focused Biasing (ODB) training strategy to overcome this limitation without external resources. The authors implemented ODB on  a vision transformer architecture and achieved improvements on image classification benchmarks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This paper raises the interesting issue of inductive bias in existing methods."
                },
                "weaknesses": {
                    "value": "1.Humans benefit from world information being able to avoid input domain bias. This actually benefits from humans having more prior information and being able to build better semantic relationships between classes. While Output-Domain focused Biasing (ODB) is more like a feature enhancement method, which improves performance through decoupling and enhancement of features.\n\n2.Figure 2 shows that the class centroids between some semantically unrelated classes are close to each other. Using triplet loss or contrast loss can also achieve the effect of widening the class centroids distance. It is recommended to add comparative experiments with this type of method.\n\n3.The paper is not easy to follow, especially the descriptions of Visual Dependency Disconnection and Non-visual Feature Structuring need more details.\n\n4.The proposed method has limited improvement in performance."
                },
                "questions": {
                    "value": "1.Is the ODB method equally effective in convolutional networks?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2285/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2285/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2285/Reviewer_9BG9"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2285/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699004303990,
            "cdate": 1699004303990,
            "tmdate": 1700731001817,
            "mdate": 1700731001817,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qKhOObkefk",
                "forum": "cH3oufN8Pl",
                "replyto": "xoCUMeJGtz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2285/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2285/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your comments!"
                    },
                    "comment": {
                        "value": "Thank you for all your efforts and thoughtful comments. We have highlighted the revisions in our paper with brown text color based on the recommendation.\n\n> Weakness1. Humans benefit from world information being able to avoid input domain bias. This actually benefits from humans having more prior information and being able to build better semantic relationships between classes. While Output-Domain focused Biasing (ODB) is more like a feature enhancement method, which improves performance through decoupling and enhancement of features. \n\nWe totally agree with the benefit of human knowledge. However, we hold a differing view that the absence of human knowledge is a weakness. because this paper aimed to improve neural networks and actually intended not to use external resources. This is one of the common goals of AI literature to reduce human efforts in building better AI for the last decades. \n\n> Weakness2. Figure 2 shows that the class centroids between some semantically unrelated classes are close to each other. Using triplet loss or contrast loss can also achieve the effect of widening the class centroids distance. It is recommended to add comparative experiments with this type of method. \n\nThanks for your suggestions.\n\nWe would like to emphasize that decoupling is one of the phenomena induced by ODB(revised to LLB). The primary distinction between ODB and traditional contrastive learning resides in the suppression of cluster positioning based on similarity within the input domain. This effect does not occur in methods simply oriented to decoupling representations. \nFor example, final representations generated from visually similar objects should be located in adjacent clusters even if the clusters are decoupled as shown in Figure 4. (In (c),  class 0-1 are very close, even overlapped, compared to 0-2. However, in (d), class 2 completely separates class 0 and class 1.) \nFor this reason, ODB more aptly aligns with a method aimed at inducing a bias relatively insensitive to input-domain features, as opposed to a method solely focused on decoupling.\n\nAs the reviewer\u2019s recommendation, we added the qualitative analysis of models using contrastive learning on the same data in Section 3.1. Figure 11d shows that the visually similar cluster centroids are not detached as ODB does. \nThe results are briefly shown as follows. \nUsing contrastive learning, the centroids are slightly decoupled compared to supervised learning. However, contrastive learning still fails to widen the gap between \u2019462: Broom\u2019 and \u2019746: Puck\u2019, where two class labels are visually similar in stick parts, but semantically distinguished between brush and puck. This observation shows that contrastive learning on CNN can reduce the input-domain focused bias, but still fails in some cases.\nPlease check Section C.2 in Appendix for figures and more details. \n\nPlus, the reason why we do not consider contrastive learning is that SOTA models on ViT do not include explicit loss based contrastive learning.\n\n> Weakness3. The paper is not easy to follow, especially the descriptions of Visual Dependency Disconnection and Non-visual Feature Structuring need more details. \n\nTo improve the readability, we revised Section 3.2 including  \u2018Visually Dependency Disconnection\u2019 and \u2018Non-visual Feature Structuring\u2019  paragraphs. \n\nThe revisions are briefly shown as follows. \n\n1) Notation definition of visual and non-visual features\nWe revised the notation for \u2018visual features\u2019 in Section 3.1 and \u2018non-visual features\u2019 in Section 3.2.\n\n2) Section 3.2 Visually Dependency Disconnection\nFor clear readability, we defined a notation for the output of the disconnect network as patch-wise non-visual features in the third paragraph of Section 3.2. Also, we added explanations of each notation in Equation (3).\n\n3) Emphasized points\nTo improve the clarity, we generally clarified the emphasized points in Section 3.2. We updated details at main components in our implementation.\n\nPlease check Section 3.1 and Section 3.2 for more details. \n\n> Weakness4. The proposed method has limited improvement in performance.\n\nOur results show consistent and statistically significant improvement. We hope that the contribution on raising a new problem and its generality are more considered rather than the significance of performance gain determined by an unclear threshold."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2285/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700208225201,
                "cdate": 1700208225201,
                "tmdate": 1700208319933,
                "mdate": 1700208319933,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sAubYXnaPW",
                "forum": "cH3oufN8Pl",
                "replyto": "xoCUMeJGtz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2285/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2285/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your comments!"
                    },
                    "comment": {
                        "value": "> Question1. Is the ODB method equally effective in convolutional networks?\n\nThe effect of the ODB (revised to LLB) method is basically not relying on specific architecture if its representations are directly affected by loss, so we think it is also effective in convolutional networks. The only reason why we selected ViT is because of its wide use and state-of-the-art performance.\nTo provide more insights, as in Section 3.1 preliminaries, we visualized the distribution of centroids of all output features in each class of ImageNet, extracted from ResNet50 as shown in Section C.1  in Appendix. We found that adjacent classes from Figure 2b, which are visually similar but semantically unrelated, were also closely positioned in CNN (Broom, Puck, Crutch, Mop) (Figure 11c) . We think that the dominance of the input-domain focused bias also exists in CNNs, and therefore ODB can be effective in CNNs. Check Section C.1 in Appendix for more details."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2285/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700208259920,
                "cdate": 1700208259920,
                "tmdate": 1700208341599,
                "mdate": 1700208341599,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mfDG1vrzvG",
                "forum": "cH3oufN8Pl",
                "replyto": "qKhOObkefk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2285/Reviewer_9BG9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2285/Reviewer_9BG9"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for authors' efforts to address my concerns. I raise my score from 5 to 6, and I hope authors can add these additional atoms into final version."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2285/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700730964475,
                "cdate": 1700730964475,
                "tmdate": 1700730964475,
                "mdate": 1700730964475,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Lw1ZleIJR4",
            "forum": "cH3oufN8Pl",
            "replyto": "cH3oufN8Pl",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2285/Reviewer_CuBT"
            ],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2285/Reviewer_CuBT"
            ],
            "content": {
                "title": {
                    "value": "Maintain my accept score (8)"
                },
                "comment": {
                    "value": "Thank you to the authors for your thorough replies in this rebuttal process. The paper has only improved in clarity since the submission, and I maintain my score at 8. I don't see the weaknesses listed by my fellow reviewers as strong enough reasons for rejection."
                }
            },
            "number": 7,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2285/-/Official_Comment"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1700690909287,
            "cdate": 1700690909287,
            "tmdate": 1700690909287,
            "mdate": 1700690909287,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]