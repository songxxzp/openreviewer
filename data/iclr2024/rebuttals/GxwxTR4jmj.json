[
    {
        "title": "Adapting Cross-View Localization to New Areas without Ground Truth Positions"
    },
    {
        "review": {
            "id": "OVjQYZ3tiN",
            "forum": "GxwxTR4jmj",
            "replyto": "GxwxTR4jmj",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1341/Reviewer_8CJA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1341/Reviewer_8CJA"
            ],
            "content": {
                "summary": {
                    "value": "This paper deals with the cross-view localization problem and considers the domain transfer issue for new areas. It proposes a teacher-student pipeline to improve the generation ability of existing works. This work assumes that the images of the target area are available, but there is no label. The experiments are conducted on VIGOR and KITTI dataset."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ Generalization is very important for the localization system and the work is well-motivated.\n+ The proposed method is evaluated on two widely used datasets with detailed evaluation metrics.\n+ The writing is easy to follow.\n+ The qualitative results look good. The ablation study and analysis are also well presented."
                },
                "weaknesses": {
                    "value": "-\tThe proposed method is more like semi-supervised learning rather than weakly-supervised learning, as it generates pseudo labels for training on the target area. Both knowledge distillation and domain adaptation have studied similar problems.\n-\tThe experimental setting could be improved to better support the motivation, i.e. generalization on new areas. The current setting seems to split the images of the target area into several parts. Although the label is not provided, the ground-truth pairs still exist in the training set of the target area, which is not the case for real-world applications. It is very common that some query images may not be covered by the reference images in the target areas. In other words, some images may not have the correct match in the training set of the target area. \n\n-\tThe performance improvement is limited, especially on KITTI dataset.\n\n-\tThe computation cost of the proposed method is not discussed. Given that previous methods have achieved high accuracy on these datasets and the proposed method introduces additional computational cost, It is important to discuss the trade-off between the performance improvement and the additional computational cost."
                },
                "questions": {
                    "value": "See the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1341/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698635881921,
            "cdate": 1698635881921,
            "tmdate": 1699636061321,
            "mdate": 1699636061321,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PdO94X2hei",
                "forum": "GxwxTR4jmj",
                "replyto": "OVjQYZ3tiN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1341/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1341/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate your feedback. Hereby, we address some concerns.\n\n**Reviewer**: \u201c*The experimental setting could be improved to better support the motivation, i.e. generalization on new areas. The current setting seems to split the images of the target area into several parts. Although the label is not provided, the ground-truth pairs still exist in the training set of the target area, which is not the case for real-world applications. It is very common that some query images may not be covered by the reference images in the target areas. In other words, some images may not have the correct match in the training set of the target area*\u201d: \n\n**Author response**: We agree that experimental settings should support the motivation, i.e. generalization to new areas. Because of this, we do not use ground truth position for the training in the target area. As motivated in the task setting (please refer to our reply to Reviewer Tcvm), a coarse GNSS prior is often available, also for the inference time in real world settings, such as autonomous driving and outdoor robotics. Hence, the task of fine-grained cross-view localization do assume the ground-aerial image pairs are known.  \n\n \n\n**Reviewer**: \u201c*The proposed method is more like semi-supervised learning rather than weakly-supervised learning, as it generates pseudo labels for training on the target area. Both knowledge distillation and domain adaptation have studied similar problems*\u201d: \n\n**Author response**: We use the term \u201cweakly-supervised learning\u201d since the task of fine-grained cross-view localization does provide ground-aerial image pairs. There exists a rough localization prior of the ground image. The term \u201cweakly\u201d indicates the existence of the rough localization prior. \n\nThe term \u201csemi-supervised\u201d would instead imply we have localization labels for some locations, and no labels for others. We see generating pseudo labels for training as a form of *self-supervised learning*. However, since self-supervised learning does not imply we know the ground-aerial image pairs, we find \u201cweakly-supervised learning\u201d is more appropriate."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1341/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699886876075,
                "cdate": 1699886876075,
                "tmdate": 1699886876075,
                "mdate": 1699886876075,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "skwxEIPwUV",
            "forum": "GxwxTR4jmj",
            "replyto": "GxwxTR4jmj",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1341/Reviewer_Tcvm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1341/Reviewer_Tcvm"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors propose a weakly-supervised learning approach using knowledge self-distillation to improve the cross-view localization performance in new target areas without accurate ground truth positions. However, the paper is flawed in terms of writing, innovations, and experiments."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "+ This article presents a self-distillation framework to enhance the performance of models across domains."
                },
                "weaknesses": {
                    "value": "- There is a lack of mathematical analysis as to why self-distillation frameworks are able to improve the fine-grained localization by only using coarse labels from target domain. Intuitive explanations and visualisation diagrams alone are not convincing enough.\n- The ablation experiments are insufficient. Lacking of comparison with domain adaption methods, and enhancements over baseline methods do not entirely come from pseudo label supervision by the teacher.\n- The test results are insufficient. Lack of indicators of the success rate of matching between ground and aerial images e.g. R@1, R@5, Hit Rate. A direct comparison of metre-level localization accuracy in the absence of a matching success rate is meaningless."
                },
                "questions": {
                    "value": "1.\tThe proposed introduces the coarse-grained labels from target domain so it is considered a domain adaptation approach. Is the boost due to having seen the distribution of target domains, or is it due to the weak supervision of the pseudo-labels? The addition of ablation experiments to compare other domain adaptation methods is recommended.\n2.\tWhy the poor model (the teacher) can lead good model (the student) in a good direction? Hopefully the authors will give solid mathematical derivations rather than intuitive descriptions and visualisations. This is because visualised heatmaps may simply come from success cases, which cannot be controlled at the time of review.\n3.\tFor the self-distillation approach, it is necessary to maintain the teacher model and the student model in the memory, which is not too demanding in terms of computational resources? I am concerned about the ease of reproducing the method proposed in this paper and suggest that the computational cost be given.\n4.\tLacking of indicators of the success rate of matching between ground and aerial images e.g. R@1, R@5, Hit Rate. A direct comparison of metre-level localization accuracy in the absence of a matching success rate is meaningless.\n5.\tAs the most important general framework diagram, the font size in Figure 2 is too small and the overall flow is not clear and concise. It is recommended that it be redrawn."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "I do not have the Ethics Concerns."
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1341/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698710254357,
            "cdate": 1698710254357,
            "tmdate": 1699636061249,
            "mdate": 1699636061249,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "WCtgk2G9V4",
                "forum": "GxwxTR4jmj",
                "replyto": "skwxEIPwUV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1341/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1341/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your valuable feedback. \n\nFirst of all, we would like to clarify our task setting and then address some related concerns. \n\n**Task setting**: \n\nOur paper focuses on fine-grained cross-view localization [Xia et al., 2022; Shi & Li, 2022; Lentsch et al., 2023; Fervers et al., 2023; Xia et al., 2023; Shi et al., 2023], a newly emerging task distinct from cross-view image retrieval-based localization. This task assumes a rough localization prior (e.g., noisy GNSS positioning or temporal filtering) is already available, which is realistic for real-world applications like autonomous driving. The localization prior can identify an aerial image that covers local surroundings. Therefore, the task in our submission and these previous works aims to precisely locate the ground camera within a known aerial image, and *does not*  concern retrieving corresponding aerial images. \n\n\n**Reply to the concerns**: Weakness \u201c*The test results are insufficient. Lack of indicators of the success rate of matching between ground and aerial images e.g. R@1, R@5, Hit Rate. A direct comparison of metre-level localization accuracy in the absence of a matching success rate is meaningless.*\u201d and the question \u201c*Lacking of indicators of the success rate of matching between ground and aerial images e.g. R@1, R@5, Hit Rate. A direct comparison of metre-level localization accuracy in the absence of a matching success rate is meaningless*\u201d: \n\nAs we clarified in our task setting, since the ground-aerial image pairs are known, recall *cannot be used* as an evaluation metric. Instead, localization error in meters is the key metric that measures how close the estimated location is to the ground truth location. Note that, prior work in this domain [Xia et al., 2022; Shi & Li, 2022; Lentsch et al., 2023; Fervers et al., 2023; Xia et al., 2023; Shi et al., 2023] also measures localization error in meters instead of ground-aerial image retrieval hit rate."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1341/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699886069836,
                "cdate": 1699886069836,
                "tmdate": 1699886069836,
                "mdate": 1699886069836,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]