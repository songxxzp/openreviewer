[
    {
        "title": "Computing Low-Entropy Couplings for Large-Support Distributions"
    },
    {
        "review": {
            "id": "RZ5MQ86XEk",
            "forum": "Tpk0p9QBM6",
            "replyto": "Tpk0p9QBM6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4090/Reviewer_n51E"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4090/Reviewer_n51E"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses the challenge of computing minimum-entropy couplings (MEC) for large-support distributions. \nMEC aims to find a joint distribution with the least joint entropy given two specific marginal distributions.\nExisting algorithms that find provable approximations for such couplings are unsuitable for very large-support distributions. \nCurrent heuristic methods, called Iterative Minimum-Entropy Coupling (IMEC), have limitations in handling these distributions.\n\nContributions:\n* Unified IMEC Algorithms: The authors provide a unified framework for IMEC algorithms using sets of partitions.\n* ARIMEC Introduction: Leveraging the unified view, a new method, ARIMEC, is introduced. It computes low-entropy couplings for any large-support distribution. Efficiency improvements, like lazy updates and entropy bounds, are incorporated.\n* Empirical Results: ARIMEC's effectiveness is showcased in Markov coding games and steganography, resulting in improved communication rates.\n\nThe paper presents a novel approach, ARIMEC, to compute low-entropy couplings for large-support distributions and validates its utility with real-world applications. \nThe authors promise to share their codebase with the community."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "As the author states, this paper has three contributions. Let's discuss the strengths of each in order.\n\n1. Unified IMEC Algorithms\nThe key strength of the unified IMEC framework, based on the description, seems to lie in its flexibility through the use of partitions. \nDepending on how these partitions are selected, different algorithms or strategies can be realized. \n\n2. ARIMEC Introduction\nThe proposed ARIMEC algorithm falls into the unified IMEC framework. \nIn the framework, irrespective of the specific autoregressive structure or the particularities of the marginal \\mu, \nthe algorithm can always satisfy the three conditions: Condition 3.1, 3.2 and 3.3. \nThis capability is significant because it allows ARIMEC to be applied to a wide range of problems or datasets \nthat have an autoregressive nature without the need for tweaking the algorithm for each specific case.\n\n3. Empirical Results\nilding on the work of Sokota et al. (2022), the authors explore an application of ARIMEC in the communication of messages \nthrough Markov decision processes. It's a unique application that hasn't been frequently touched upon in literature."
                },
                "weaknesses": {
                    "value": "* The experiments seem to be heavily centered around specific domains like Markov coding games and steganography. \n  While these are valuable explorations, they might not give a complete picture of ARIMEC's versatility across other potential domains or applications.\n  I'd like a bit more discussion on the potential applications of ARIMEC."
                },
                "questions": {
                    "value": "* In Section 3, a unified view of IMEC is proposed, but are there any existing algorithms to be unified other than TIMEC and FIMEC?\n* Figure 3, why do you compare Token-wise Error Rate?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4090/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698550852620,
            "cdate": 1698550852620,
            "tmdate": 1699636373589,
            "mdate": 1699636373589,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "J0QQx19xiC",
                "forum": "Tpk0p9QBM6",
                "replyto": "RZ5MQ86XEk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4090/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4090/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer n51E"
                    },
                    "comment": {
                        "value": "Thanks for the insightful feedback. It has helped us improve the submission, and we've submitted an updated version.\n\n> The experiments seem to be heavily centered around specific domains like Markov coding games and steganography. While these are valuable explorations, they might not give a complete picture of ARIMEC's versatility across other potential domains or applications. I'd like a bit more discussion on the potential applications of ARIMEC.\n\n\nWe agree that such a discussion is warranted. To address this concern, we added the following paragraph about additional potential applications for ARIMEC to the conclusion: \n\n\"For future work, there are a few application directions in which it would be interesting to push further with ARIMEC. First is unencrypted steganography. This direction is exciting because ARIMEC can achieve high throughput rates, as we observed in Figure 5, and because minimum-entropy coupling's usage for steganography was only recognized recently Schroeder de Witt et al. (2023). Thus, there may be real-world settings in which it is applicable, especially since unencrypted steganography requires no key exchange. Second, because ARIMEC is the first IMEC algorithm capable of handling arbitrary discrete distributions, it opens the door to using large support distributions for classical minimum-entropy coupling applications in which the distributions may be non-factorable, such as entropic causal inference, random number generation, functional representations, and dimensionality reduction.\"\n\n> In Section 3, a unified view of IMEC is proposed, but are there any existing algorithms to be unified other than TIMEC and FIMEC?\n\nNo, other than ARIMEC later in the submission.\n\n> Figure 3, why do you compare Token-wise Error Rate?\n\nWe are trying to measure the error rate at which the language model text is decoded properly, as this is the metric of interest in the steganography use case of minimum-entropy coupling. This error rate is related to joint entropy, but not exactly the same, so it requires separate treatment.\n\n---\n\nWe thank the reviewer again for their feedback. Please let us know if you have any further suggestions for the revised text."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4090/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700199486099,
                "cdate": 1700199486099,
                "tmdate": 1700199486099,
                "mdate": 1700199486099,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "FTl9scqE2B",
            "forum": "Tpk0p9QBM6",
            "replyto": "Tpk0p9QBM6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4090/Reviewer_dCYg"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4090/Reviewer_dCYg"
            ],
            "content": {
                "summary": {
                    "value": "The paper provides an efficient algorithm for min-entropy coupling that the authors call ARIMEC. The best previously known algorithm required one of the distributions to be  factorable into blocks with small supports, while their algorithm doesn't require that."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The result is new and seems to be strong. It answers an open question from Sokota et al. (2022). The paper is easy to read, the main result is clear and its comparison with the state of the art is explained. The idea is nice and simple."
                },
                "weaknesses": {
                    "value": "Even though I like the idea, the approach is not very sophisticated, it combines some standard (but non-trivial) combinatorial techniques with the results of prior works.\n\nAlso, even though the paper is easy to read, there are no rigorous formulations of the results in the main part of the paper, and some statements are not very precise (e.g. I find usage of terms like \"small\" in formal conditions not very nice)."
                },
                "questions": {
                    "value": "I do not have any specific questions, since the paper basically solves the problem as it was stated in Sokota et al. (2022). Maybe just a high-level question: Did you think of any potential future directions where your approach could be useful?\n\nSuggestions: As I said before, I would also write conditions in more formal manner (e.g. I recommend to replace \"small\" by something concrete and formal, and then add a high-level explanation below or above the formal definition). I also recommend to write your results as theorems (and keep current high-level explanations close to the formal statements)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4090/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4090/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4090/Reviewer_dCYg"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4090/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698766939105,
            "cdate": 1698766939105,
            "tmdate": 1699636373516,
            "mdate": 1699636373516,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MPkbni1w5z",
                "forum": "Tpk0p9QBM6",
                "replyto": "FTl9scqE2B",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4090/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4090/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dCYg"
                    },
                    "comment": {
                        "value": "Thanks to the reviewer for the helpful review and comments. The feedback really improved our work, and we've uploaded a new version.\n\n> there are no rigorous formulations of the results in the main part of the paper, and some statements are not very precise (e.g. I find usage of terms like \"small\" in formal conditions not very nice) ... Suggestions: As I said before, I would also write conditions in more formal manner (e.g. I recommend to replace \"small\" by something concrete and formal, and then add a high-level explanation below or above the formal definition). I also recommend to write your results as theorems (and keep current high-level explanations close to the formal statements).\n\nWe completely agree with the reviewer's criticism of the submission. To help address this, we removed the informal conditions and added runtime complexity statements for each of the algorithms (and their proofs in the Appendix).\n\n> Maybe just a high-level question: Did you think of any potential future directions where your approach could be useful?\n\nWe are excited about further exploring of further developing unencrypted steganography, as its literature is relatively less developed and minimum-entropy coupling may facilitate high information throughput. We are also interested in looking into applications of ARIMEC in entropic causal inference, random number generation, functional representations, and dimensionality reduction, as these are all areas where approximate minimum-entropy coupling algorithms have proved useful. We added a discussion on this to the end of the conclusion in the revised version of the submission.\n\n---\n\nWe thank the reviewer again for their feedback. Please let us know if you have any further suggestions for the revised text."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4090/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700199418644,
                "cdate": 1700199418644,
                "tmdate": 1700199418644,
                "mdate": 1700199418644,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Hipawiet6o",
                "forum": "Tpk0p9QBM6",
                "replyto": "MPkbni1w5z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4090/Reviewer_dCYg"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4090/Reviewer_dCYg"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Authors,\n\nThank you very much for your response! The score remains unchanged."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4090/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700733073035,
                "cdate": 1700733073035,
                "tmdate": 1700733073035,
                "mdate": 1700733073035,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "lXqtTvvdsn",
            "forum": "Tpk0p9QBM6",
            "replyto": "Tpk0p9QBM6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4090/Reviewer_caMu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4090/Reviewer_caMu"
            ],
            "content": {
                "summary": {
                    "value": "Minimum entropy coupling (MEC) is the following problem. Given marginal distributions of two finitely supported random variables X and Y, find a joint distribution \\gamma on X and Y (called a \u201ccoupling\u201d of X and Y) s.t. the entropy of \\gamma is as small as possible. In addition to being a natural problem from a theoretical point of view, MEC also has various practical applications, including steganography (the art of hiding secret messages in plain sight).\n\nThe authors propose a unified framework that captures previous approaches to MEC and propose a novel *heuristic* algorithm for MEC called ARIMEC. That is, their method does not have provable guarantees regarding the entropy achieved by the output coupling. The reason for this is that MEC is NP-hard (where the instance size is defined to be the support size of X and Y) and provable approximation algorithms for MEC run in O(N log N) time, where N is the support size. In many interesting practical applications, the support size N is often extremely large so even linear-in-N time is considered too slow. Thus, the authors turn to heuristic algorithms and argue for the utility of their approach via empirical evaluation."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The unifying framework using collections of partitions is relatively simple and nicely captures previous approaches, though its exposition could be improved. In addition, the application to steganography is interesting. Heuristic MEC algorithms, despite their lack of rigorous guarantees, could lead to interesting future work on steganography using large language models (LLMs) since for LLMs we have full access to the generating distribution."
                },
                "weaknesses": {
                    "value": "The paper's failure to address several important issues, in addition to the numerous ambiguities in the exposition, diminishes the paper's overall quality. Therefore, I am inclined to reject the current version of the paper. My concerns include the following.\n\n- **Basic MEC setup is unclear.** Throughout the paper, the authors seem to *implicitly* assume that X, Y are both vectors (or strings). In fact, the prefix tree in Section 4 does not even make sense unless elements of X are strings. This implicit vector assumption is also used in Section 2.3, Algorithm 1 and 2. However, this assumption on the structure of X and Y doesn\u2019t seem to be stated explicitly anywhere in the paper.\n    \n    Also, what kind of access do we have to the marginals of X and Y? Do we get black-box queries to the probability mass evaluations? Is it a sampling oracle?\n    \n- **Notion of efficiency is never formally defined.** The main reason for using heuristic MEC algorithms instead of the provable approximation algorithms is to avoid the log-linear-in-N run time. Computational efficiency, at least in CS, is always be defined relative to some problem instance size (i.e., it is an asymptotic notion). If N is \u201ctoo big\u201d, then what is the right index for the instance size for MEC? This would make sense if one explicitly assumed that X is supported on {0,1}^n and Y is supported on {0,1}^m, and we call any quantity \u201ctoo large\u201d or \u201cintractably large\u201d if it grows superpolynomially in n or m.\n\n- **Small support size of conditional distributions does not imply efficient sampleability (Condition 4.6).** Suppose X is a random vector in {0,1}^n defined as the output distribution of a pseudorandom generator (PRG), i.e., the pushforward of the uniform distribution over {0,1}^s through the PRG. Clearly, each conditional distribution arising in the autoregressive form of this distribution is supported on {0,1}, which is of size 2. However, these conditional distributions are not even efficiently computable (since they are given by a PRG).\n\n- **Missing run-time analysis of subroutines.** In Algorithm 3 (IMEC), is it clear that the optimization over the collection of partitions U can be implemented efficiently?\n\n- **Motivation for ARIMEC.** In what sense is ARIMEC better than previous approaches? In the regimes where TIMEC and FIMEC performs well, is it expected that ARIMEC performs not worse than these two approaches? Also, what is the motivation behind using partitions defined using the prefix tree?\n\n- **Missing details on the steganography task.** Details of the steganography experiment are missing (even including Appendix D), which makes it hard to understand what experiment is exactly being conducted here. Could the authors please expand on the last paragraph of Section 5?"
                },
                "questions": {
                    "value": "- What kind of access do we have to the marginals of X and Y? Do we get black-box queries to the probability mass evaluations? Is it a sampling oracle?\n- In Condition 2.5, what qualifies as \u201csmall\u201d support size and what quantifies as \u201cintractably large\u201d?\n- In Algorithm 3 (IMEC), is it clear that the optimization over the collection of partitions U can be implemented efficiently?\n- If the encoding is perfectly secure (i.e., encoding of ciphertext X into stegotext S is deterministic) and the distribution of stegotext S and covertext C is the same, doesn\u2019t this mean that one can \u201challucinate\u201d secret messages from innocuous text?\n\n**Editorial comments**\n\n- The NP-hard reference is rather misleading. For the NP-hardness result, the instances are indexed by N, the support size. Even if MEC were in P, this would not suffice for the setting this paper is interested in.\n- In the Algorithm boxes, the subscript 1:j-1 doesn\u2019t make sense for j = 1."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4090/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699399662335,
            "cdate": 1699399662335,
            "tmdate": 1699636373450,
            "mdate": 1699636373450,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MXmOIOGsD1",
                "forum": "Tpk0p9QBM6",
                "replyto": "lXqtTvvdsn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4090/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4090/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer caMu"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their engaged review and helpful comments. We feel that the reviewer's feedback has helped us significantly improve the submission, of which we have uploaded a revised copy.\n\n> Basic MEC setup is unclear. Throughout the paper, the authors seem to implicitly assume that X, Y are both vectors (or strings). In fact, the prefix tree in Section 4 does not even make sense unless elements of X are strings. This implicit vector assumption is also used in Section 2.3, Algorithm 1 and 2. However, this assumption on the structure of X and Y doesn\u2019t seem to be stated explicitly anywhere in the paper.\n\nWe would like to clarify that the original submission *did explicitly state this assumption*. Specifically:\n- In Condition 2.5, it states \"Y = (Y_1, . . . , Y_m) is a random vector\".\n- In Condition 2.6, it states \"X = (X_1, . . . , X_n) is a random vector\".\n- In Condition 4.6, it states \"X = (X_1, . . . , X_n) is a random vector\"\n\nHowever, in order to address the reviewers other comments, we have removed the conditions from the submission. Thus, to make this point clear, we added explicit mention of random vectors to Section 1, Section 2.2, and Section 2.4:\n- These algorithms work by iteratively coupling components of random vectors using provable MEC approximation algorithms in such a way that guarantees the aggregate joint distribution is a coupling.\n- In some settings, it is desirable to (non-provably) approximate minimum-entropy couplings where one random vector assumes such a large number of possible outcomes that the approaches described in Section 2.2 are inapplicable. Sokota et al. (2022) propose an iterative approach to such settings, which we call TIMEC, that assumes the random vector is autoregressively specified.\n- Sokota et al. (2022) also proposed a second approach, which we call FIMEC, in which $X$ is also assumed to be a random variable\n- $X=(X_1, \\dots, X_n)$ is a random vector such that $X_i$ and $X_j$ are independently distributed for $i \\neq j$.\n\nPlease let us know if there are other points in the submission where the reviewer feels it would be informative to add clarification about the status of $X$ and $Y$ as random vectors.\n\n> Also, what kind of access do we have to the marginals of X and Y? Do we get black-box queries to the probability mass evaluations? Is it a sampling oracle?\n\nWe get access to probability mass evaluations. We have added the text below to the introduction to make this more explicit: \"The problem of computing a coupling with the minimum amount of joint entropy among all feasible couplings, given access to probability mass evaluations of the marginals, is called minimum-entropy coupling (Kovacevic et al., 2015).\"\n\n> Formal Notion of Efficiency / Clarity of Conditions / Runtime Analysis\n\nWe thank the reviewer for this feedback. We agree that the way we were presenting the material previously was lacking formality. We attempted to address the reviewer's concerns in the revised version of the submission. To summarize:\n- We now describe algorithm runtime using big-O analysis.\n- We removed all of the \"conditions\" from our presentation of the material (including but not limited to those mentioned as of concern by the reviewer).\n- Regarding Algorithm 3 in its generic form, it is *not* the case that optimization over the collection of partitions U can be implemented efficiently. To make this more clear, we have added the text: \"Note that whether Algorithm 3 can be implemented efficiently depends on the distribution $\\nu$ and the set of partitions $\\mathfrak{U}$.\"\n- Following up on the previous point:\n    1. For TIMEC, optimization over the collection of partitions can be implemented efficiently (the finest partition will always have maximum entropy). \n    2. For FIMEC, optimization over the collection partitions can be implemented efficiently under the assumption that the distribution is factorable.\n    3. For ARIMEC, it is less obvious that optimization over the collection of partitions can be implemented efficiently. To address this issue, we introduced a pruning technique (which was in the appendix of the original submission) that can prove large parts of the prefix partition tree cannot induce a maximum-entropy partition. While we do not show a polynomial time guarantee for this pruning procedure, we found that, for all of the distributions that we have tried in the experiments, it only required checking a small number of partitions (on the order of 1) on average in order to find a provably maximum-entropy partition."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4090/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700199173692,
                "cdate": 1700199173692,
                "tmdate": 1700199173692,
                "mdate": 1700199173692,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "o0BMHay10C",
                "forum": "Tpk0p9QBM6",
                "replyto": "lXqtTvvdsn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4090/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4090/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer caMu (Part 2)"
                    },
                    "comment": {
                        "value": "> Motivation for ARIMEC\n\nWe attempt to make the motivation clear in the abstract: \"We derive a new IMEC instance from this formalism, which we call ARIMEC, that, unlike existing IMEC algorithms, can be applied in practice to arbitrary discrete distributions, and introduce associated operations that make ARIMEC efficient in practice.\" To state in different words, ARIMEC is the first algorithm that can produce couplings of large support distributions of arbitrary structure in practice. This contrasts with FIMEC, which requires one of the two distributions to be factorable. Please let us know if there is a better way we can characterize this motivation.\n\n> Missing details on the steganography task. Details of the steganography experiment are missing (even including Appendix D), which makes it hard to understand what experiment is exactly being conducted here. Could the authors please expand on the last paragraph of Section 5?\n\nWe apologize that the details here were unclear. To clarify:\n1. For the information-theoretic steganography experiments, the task is to perform a coupling between uniformly randomly distributed byte strings and the distribution over 100 tokens induced by GPT-2. The error rate is the proportion of the time that the MAP byte string is not equal to the true byte string. Symbolically $E_{X} E_{Y \\sim \\gamma(Y \\mid X)} I[X \\neq \\arg \\max_{x} \\gamma(x \\mid Y)]$. We have added this clarification about error rate to the main text.\n2. For unencrypted steganography, the task is to perform a coupling between the distribution over 100 tokens induced by GPT-2 conditioned on two different prompts. Error rate is defined the same way.\n\nPlease let us know if there is any additional detail that would be helpful to add.\n\n> If the encoding is perfectly secure (i.e., encoding of ciphertext X into stegotext S is deterministic) and the distribution of stegotext S and covertext C is the same, doesn\u2019t this mean that one can \u201challucinate\u201d secret messages from innocuous text?\n\nNaively, yes, if the receiver is expecting a message when no message is actually being sent, this is exactly what will occur. However, in practice, one can mitigate this possibility using standard error detection techniques. For this reason, the information-theoretic steganography model introduced by Cachin (1998), which we used in the submission, is common in steganography literature.\n\n> In the Algorithm boxes, the subscript 1:j-1 doesn\u2019t make sense for j = 1.\n\nWe use upper bound inclusive indexing, so 1:j-1 for j=1 (i.e., 1:0) means the empty array (as intended). We added this note to the submission to clarify this point: \"Note that we use upper-bound-inclusive indexing, so $Y_{1:0}=()$, $Y_{1:1}=(Y_1)$, $Y_{1:2}=(Y_1, Y_2)$, etc.\"\n\n---\n\nWe thank the reviewer again for their feedback. Please let us know if you have any further suggestions for the revised text."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4090/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700199336717,
                "cdate": 1700199336717,
                "tmdate": 1700199336717,
                "mdate": 1700199336717,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ABA3mFzSWU",
                "forum": "Tpk0p9QBM6",
                "replyto": "lXqtTvvdsn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4090/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4090/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow up"
                    },
                    "comment": {
                        "value": "Hello Reviewer caMu, we would be grateful if you can confirm whether our revision has addressed your concerns, and let us know if any issues remain. To recap, we:\n- Revised our discussion of efficiency and provided runtime analysis\n- Clarified concerns regards assumptions & motivation\n- Answered additional questions\n\nWe hope the reviewer will be able to respond before the end of the discussion (November 22nd)."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4090/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700632454774,
                "cdate": 1700632454774,
                "tmdate": 1700632562517,
                "mdate": 1700632562517,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7YujGeQAIx",
                "forum": "Tpk0p9QBM6",
                "replyto": "lXqtTvvdsn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4090/Reviewer_caMu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4090/Reviewer_caMu"
                ],
                "content": {
                    "comment": {
                        "value": "I greatly appreciate the responsiveness of the authors. The revisions, especially their new run-time analysis, have clarified the setup and motivation of the proposed approach. However, the run-time analysis for ARIMEC is still missing a few important details, and could benefit from further investigation.\n\n- **Computing the entropy for prefix tree partitions.** Apart from taking the maximum over the collection of partitions $\\mathfrak{U}$, Is it clear that for **each** prefix tree partition $P_v$ the entropy of the conditional distribution $B_v \\mid y_{1:j-1}$ can be efficiently computed? This seems to require **additional conditions on the marginal $\\mu$ of $X$**. I would assume that $\\mu$ should be able to efficiently compute the (conditional) probability mass of any subtree in $\\mathbb{X}$. This is satisfied if $\\mu$ is a product distribution (Assumption 2.4), but it\u2019s not clear what weaker assumptions on $\\mu$ would ensure this.\n- **Conditions on the marginal $\\nu$ of $Y$.** This is similar to the issue mentioned above. All heuristic coupling algorithms presented here require efficient computation of the conditional distributions $\\nu(Y_j \\mid Y_{1:j-1})$ for any j. The implicit assumption seems to be that $\\nu(Y_1,\u2026,Y_{j-1})$ is efficiently computable. The issue here is that $Y_1,\u2026,Y_{j-1}$ are not elements of $\\mathbb{Y}$. They are prefixes (i.e., subsets) whose cardinality (in terms of elements of $\\mathbb{Y}$) may be exponentially large in m. Thus, the sentence \u201cgiven access to the probability mass evaluations of the marginals\u201d in p.1 needs further specification. Viewing $\\nu$ (and also $\\mu$) as an oracle, what queries are allowed in the paper\u2019s setup?\n- **The number of nodes visited in the prefix tree (Z).** The current run-time analysis of ARIMEC (Proposition 4.1) could be investigated further. The introduction of the parameter Z, the number of nodes visited in the prefix tree, is rather ad hoc. This is understandable given the rebuttal time constraints, but it glances away from potentially important details of ARIMEC."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4090/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700704109964,
                "cdate": 1700704109964,
                "tmdate": 1700704109964,
                "mdate": 1700704109964,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "9lSzN8wL60",
                "forum": "Tpk0p9QBM6",
                "replyto": "lXqtTvvdsn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4090/Reviewer_caMu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4090/Reviewer_caMu"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarification. It's not immediately clear to me how Proposition B.1 explains the posterior update procedure. Let's consider a simple example where $\\mathbb{X} = \\\\{0,1\\\\}^n$ and $\\mathbb{Y}=\\\\{0,1\\\\}^m$. Suppose in iteration $j=1$, the partition used is $\\Pi_1 = \\\\{\\\\{0^n\\\\},\\mathbb{X}\\setminus\\\\{0^n\\\\}\\\\}$. At the beginning of iteration 2, what is the measure of $\\gamma(0*\\mid Y_1=0)$ (i.e, set of all strings with prefix $X_1 = 0$) in terms of $\\\\{\\gamma(B,Y_1)\\mid B \\in \\Pi_1\\\\}$ and $\\mu$?\n\nMore explanation on the posterior update, possibly using simple examples like this, would be helpful.\n\nOn the other hand, the assumption on the marginal $\\nu$ of $Y$ is clear now. A minor nitpick is whether \"random vector is autoregressively specified\" is a standard way of describing such measures. I would instead write \"the measure $\\nu$ efficiently computes prefix queries\" or \"measures of cylinder sets\", but I acknowledge that different communities might describe it differently."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4090/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700719006237,
                "cdate": 1700719006237,
                "tmdate": 1700719006237,
                "mdate": 1700719006237,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PxlHZsZ9YE",
                "forum": "Tpk0p9QBM6",
                "replyto": "lXqtTvvdsn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4090/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4090/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Clarification of Posterior Update Procedure"
                    },
                    "comment": {
                        "value": "Proposition B.1 shows how, given the posterior associated to a partition $P_v$, the partition associated to a partition $P_u$ can be computed, where $u$ and $v$ are neighbors in the prefix tree. In the example you describe, $\\emptyset$ and $0^n$ are $n$ edges away from one another in the prefix tree, so computing the posterior over $\\gamma(0^{\\ast} \\mid Y_1 = 0)=\\gamma(\\mathbb{B}_{\\sqsubset 0} \\mid Y_1=0)$ would require performing $n$ updates as dictated by Proposition B.1. \n\nTo give intuition, Proposition B.1 shows that the posteriors of adjacent nodes are related by up-weighting or down-weighting the value of the appropriate edge. For example, if we perform a coupling on the partition $P_{00}$ and the posterior \n\n$\\gamma(\\mathbb{B}_{\\not \\sqsubset 00} \\mid Y_1)$ \n\nis higher than the prior \n\n$\\gamma(\\mathbb{B}_{\\not\\sqsubset 00})$\n\nthen the posterior associated with $P_0$ given $Y_1$ is a re-weighting of the prior where the probability \n$\\gamma(\\mathbb{B}_{\\sqsubset 00} \\mid Y_1)$ is shifted downward and the probability of all other blocks are shifted upward (as per Proposition B.1).\n\nWe will add detailed examples on this point to the text. Please let us know if any other details would be helpful. We also commit to release well-documented code for all of the algorithms discussed in the paper (so these procedures will also be given explicitly)."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4090/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700723604086,
                "cdate": 1700723604086,
                "tmdate": 1700723665432,
                "mdate": 1700723665432,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]