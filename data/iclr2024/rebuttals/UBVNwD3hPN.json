[
    {
        "title": "CivRealm: A Learning and Reasoning Odyssey for Decision-Making Agents"
    },
    {
        "review": {
            "id": "csYGUgxyvN",
            "forum": "UBVNwD3hPN",
            "replyto": "UBVNwD3hPN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1285/Reviewer_XJ4N"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1285/Reviewer_XJ4N"
            ],
            "content": {
                "summary": {
                    "value": "The primary contribution of this paper is the introduction of the CivRealm environment, which is built on Civilization VI, a complex and popular video game. This environment offers a platform to study long-term planning, multi-agent interactions, and intricate decision-making etc."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper doesn't just introduce an environment but also provides benchmark tasks and baseline.\n- The API provides a comprehensive log of game state and actions.\n- It allows AI agents to interact at both high (strategic) and low (tactical) levels.\n- It focus on long-term planning which is crucial to agents"
                },
                "weaknesses": {
                    "value": "As a work in the area of datasets and benchmarks, I think a lot of the details are in the code, and I don't have good confirmation of those details just by virtue of the text in the paper. This environment is based on an open-source game http://freeciv.org/. I don't know how different is the open-source game and the environment introduced by the authors. It would be excellent if authors could give reviewers an early release of code to review."
                },
                "questions": {
                    "value": "This environment is based on an open-source game http://freeciv.org/. From the development aspects, what is the main modifications/effort has been done upon the open-source game?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1285/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1285/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1285/Reviewer_XJ4N"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1285/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698647481729,
            "cdate": 1698647481729,
            "tmdate": 1700682673315,
            "mdate": 1700682673315,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UFhLs4awFM",
                "forum": "UBVNwD3hPN",
                "replyto": "csYGUgxyvN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1285/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1285/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Point-to-Point Response to Reviewer XJ4N"
                    },
                    "comment": {
                        "value": "We thank reviewer 8arZ for the valuable time and constructive feedback.\n\n#### **Q1: As a work in the area of datasets and benchmarks, I think a lot of the details are in the code, and I don't have good confirmation of those details just by virtue of the text in the paper. This environment is based on an open-source game <http://freeciv.org/>. I don't know how different is the open-source game and the environment introduced by the authors. It would be excellent if authors could give reviewers an early release of code to review.**\n\n**A1:**\nThat is an excellent question. We have released our code on GitHub at an anonymous account for review purposes: <https://github.com/civrealm>. and you can also access our documentation at: <https://civrealm.github.io/civrealm/>. This GitHub account hosts four distinct repositories <https://github.com/civrealm?tab=repositories>:\n   - `civrealm`: this repository contains the core code of the CivRealm environment, encompassing both tensor-based and language-based APIs, along with comprehensive documentation.\n   - `civrealm-sav`: this repository contains the code responsible for creating the mini-games, which also enables users to customize their own games and generate new maps.\n   - `civrealm-tensor-baseline`: this repository provides the code for our baseline tensor-based RL agents.\n   - `civrealm-llm-baseline`: this repository hosts the code for our LLM agents, including BaseLang and Mastaba. \n\nIn the following, we would like to explain the relationship between Civrealm and the Freeciv game. To put it briefly, it is analogous to the relationship between pysc2 ([link](https://github.com/google-deepmind/pysc2)) [ref1] and the Starcraft game. \n\nSpecifically, Freeciv is a game that supports graphical interfaces for human players. However, this interface type is **not** designed for RL or language agents, i.e., accessing states and executing actions through tensor or language. To expose Freeciv as a research environment, we have developed CivRealm with an OpenAI Gym-style API to facilitate interaction between AI agents and Freeciv. In other words, Civrealm implements a proxy API that enables programmatic control of Freeciv. Through this API, AI agents can start/join a game, obtain game states, perform actions, and capture screenshots to generate game replays.\n\nTo implement the API, we conducted an in-depth exploration of the internal workings of Freeciv. This involved:\\\n(1) delving into the process of parsing game states and issuing action commands through communication packets, \\\n(2) building concurrent communication flows and thoroughly testing the environment to ensure smooth training and testing processes, \\\n(3) configuring server settings for diverse game modes, \\\n(4) developing infrastructure for parallel training, and \\\n(5) incorporating various other supporting features for research with the game, including quantitative metrics.\n\nIn summary, we have constructed a comprehensive infrastructure that encompasses various controller, state, and action classes designed for multifaceted game control, thus facilitating interaction with the Freeciv server. \n\nAdditionally, we have added support for tensor-based and LLM-based agents and have created a new game mode: \"mini-game ([doc link](https://civrealm.github.io/civrealm/advanced_materials/minigame.html))\". For more detailed documentation of our implementation, please refer to: <https://civrealm.github.io/civrealm/>.\n\nWe sincerely appreciate your thoughtful review, and we hope we have addressed your concerns. Please do not hesitate to reach out if you require any further information.\n\n---\n[ref1] Samvelyan, Mikayel, et al. \"The starcraft multi-agent challenge.\", 2019."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1285/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700338530284,
                "cdate": 1700338530284,
                "tmdate": 1700542029128,
                "mdate": 1700542029128,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "03FegBcNPK",
                "forum": "UBVNwD3hPN",
                "replyto": "csYGUgxyvN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1285/Reviewer_XJ4N"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1285/Reviewer_XJ4N"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your explanation! Hope you can understand that it is important for reviewer to have codes to review for these kinds of paper. I am happy to raise your score. :)\n\nAnother question:\nIn the table one, why Dota is not regarded as a stochastic game? I think the monster in the wild and the items drop from them are random. Why it is not multi-goal game? One may argue that the goal is single -- win the game, but I guess CivRealm is also to \"win the game\"."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1285/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700682659392,
                "cdate": 1700682659392,
                "tmdate": 1700682659392,
                "mdate": 1700682659392,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hpFxQl449O",
            "forum": "UBVNwD3hPN",
            "replyto": "UBVNwD3hPN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1285/Reviewer_4Csd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1285/Reviewer_4Csd"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a novel testbed environment inspired by the Civilization game, called *CivRealm*, which is a multi-agent multi-goal long-horizon challenging environment. The authors also implement RL and LLM baseline agents and show that they struggle to make substantial progress in the full game."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The authors present a novel and challenging testbed for agent studies, which is a big contribution.\n2. The experiments on the proposed agents also set up baselines that follow-up works can improve upon.\n3. The environment also has mini-games that can benefit the (multi-agent) RL community.\n4. The paper is clearly written and easy to follow."
                },
                "weaknesses": {
                    "value": "1. Some details are not clear enough. As this is a multi-agent environment, what are the baseline RL and LLM agents play against? I didn't seem to find such details in the description.\n2. The proposed baselines are not working in the (full game) environment. Maybe it is better to also set different difficulty levels (e.g. by different task horizons) for the full game so that later research can more easily be evaluated on the benchmark.\n3.  Is Figure 2 the real situation that the LLM agents discover or the expected situation? If it is what the LLM agents discover, why does Tit still behave poorly?\n4. The text in Figure 4 is too small to view."
                },
                "questions": {
                    "value": "1. Why the success rate of the RL agent in some mini-games (e.g., SettlerBuildCity) is higher for the hard setting than for the easier settings?\n2. Can the authors comment on the reason for instability and the sudden drop in performance in Figure 9?\n3. It would be great if the authors could provide videos of the experiments or visualization ways in the future code repo."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1285/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698734719154,
            "cdate": 1698734719154,
            "tmdate": 1699636055437,
            "mdate": 1699636055437,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7v22uGVR9T",
                "forum": "UBVNwD3hPN",
                "replyto": "hpFxQl449O",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1285/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1285/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Point-to-Point Response to Reviewer 4Csd"
                    },
                    "comment": {
                        "value": "We thank reviewer 8arZ for the valuable time and constructive feedback.\n\n#### **Q1: Some details are not clear enough. As this is a multi-agent environment, what are the baseline RL and LLM agents play against? I didn't seem to find such details in the description.**\n\n**A1:**\nThank you very much for bringing this to our attention. The opponent players that our baseline methods play against are built-in AIs implemented by the original Freeciv team. We have added this detail in Appendix A.1 of the revision.\n\n#### **Q2: The proposed baselines are not working in the (full game) environment. Maybe it is better to also set different difficulty levels (e.g. by different task horizons) for the full game so that later research can more easily be evaluated on the benchmark.**\n\n**A2:**\nThank you for the suggestion! We will be adding APIs to allow users to configure the length of a full game. This will enable later research projects to evaluate themselves on full games with varying time horizons.\n\nThe current full game is also highly customizable in several ways:\n\n- The number of opponents and the map size can be adjusted.\n- The level of resources on the map can be customized.\n- It offers different levels of difficulty in terms of the built-in AI opponents.\n\n\n#### **Q3: Is Figure 2 the real situation that the LLM agents discover or the expected situation? If it is what the LLM agents discover, why does Tit still behave poorly?**\n\n**A3:**\nThank you for bringing this confusing part to our attention. This is an expected situation simulated by our built-in rule-based AI, which we utilize to illustrate the complexity of the Freeciv game. Figure 8 displays what the LLM agents have discovered.\n\n#### **Q4: The text in Figure 4 is too small to view.**\n\n**A4:**\nThank you for the reminder. We have updated Figure 4 in the revised paper.\n\n#### **Q5: Why the success rate of the RL agent in some mini-games (e.g., SettlerBuildCity) is higher for the hard setting than for the easier settings?**\n\n**A5:**\nWe have also observed this interesting phenomenon. This counterintuitive situation arises from a *shortcut strategy* discovered by the RL agent. Specifically, as outlined in Appendix A.2 of the paper and detailed at <https://civrealm.github.io/civrealm/advanced_materials/minigame.html>, the winning condition for the hard mode of the SettlerBuildCity task is determined by averaging the potential city positions on the minigame map. In the harder mode, the land terrain is considerably less favorable, with an abundance of deserts, tundra, and swamps, resulting in lower tile production values for food, production, and trade. Consequently, the winning score is lower due to the averaging across these poorer terrains, resulting in a ranking of minimal winning scores as follows: easy > normal > hard.\n\nOriginally, the goal of the hard mode was to locate and settle in a resource-rich land area (e.g., forests or rivers) amidst these challenging terrains. However, sea and ocean tiles always offer more resources compared to the widely distributed poor land terrains. We have observed that tensor-based agents tend to exploit this unique scenario and learn a shortcut strategy of exclusively building coastal cities. This approach easily results in above-average production values for inland terrain, meeting the winning criteria for settlerBuildCity[hard].\n\n#### **Q6: Can the authors comment on the reason for instability and the sudden drop in performance in Figure 9?**\n\n**A6:**\nThe sudden drop is attributed to the player encountering opponents or a pirate invasion, which could trigger when the player has reached a certain development stage. Our method, Mastaba, has outpaced the development of BaseLang; therefore, Mastaba encountered pirate invasions and was defeated at an earlier stage. It is worth noting that in the game, defending against pirate invasions is challenging, even for human players, as the pirates' technology, attack strength, and other factors are typically set to a high difficulty level.\n\n#### **Q7: It would be great if the authors could provide videos of the experiments or visualization ways in the future code repo.**\n\n**A7:**\nWe included two videos in the supplementary materials: \"Mastaba\" and \"BaseLang,\" each showcasing a complete game. In terms of visualization, our codebase offers users two functionalities: 1) the ability to visually observe the agent playing the game and 2) the option to automatically record screenshots of the game. We also customized the [FCIV-NET](https://github.com/fciv-net/fciv-net) version of the game for users, which provides a 3D visualization (shown in Fig 1).\n\n\nWe appreciate again your thoughtful review and we hope we addressed your concerns. Please let us know if you'd like any further information."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1285/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700338015161,
                "cdate": 1700338015161,
                "tmdate": 1700585846967,
                "mdate": 1700585846967,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "owFUKtt6Zs",
                "forum": "UBVNwD3hPN",
                "replyto": "7v22uGVR9T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1285/Reviewer_4Csd"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1285/Reviewer_4Csd"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "I am satisfied with the authors' response. I will keep my original score."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1285/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700632105164,
                "cdate": 1700632105164,
                "tmdate": 1700632105164,
                "mdate": 1700632105164,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "JelbU9YL6v",
            "forum": "UBVNwD3hPN",
            "replyto": "UBVNwD3hPN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1285/Reviewer_3D5Q"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1285/Reviewer_3D5Q"
            ],
            "content": {
                "summary": {
                    "value": "This is a dataset and benchmark paper that introduces the CivRealm environment. It supports a number of game features based on the Civilization game, including an agent-agnostic framework, a friendly interface, and a tensor-based agent interface, supporting a variety of custom tasks with custom goal definitions, etc. This is a very exhaustive benchmark for a long-horizon strategy-based game. The paper also discusses the performance of three methods (one tensor-based and one LLM-based)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This dataset and associated framework is very useful and will support a lot of research for multi-agent settings involving various kinds of agents. \n2. The whole framework is very novel."
                },
                "weaknesses": {
                    "value": "I'm not sure how robust the client-server architecture used in the framework is. There are no comments on the robustness of this."
                },
                "questions": {
                    "value": "1. How robust is the server-client architecture? Did you do any experiments to test it?\n2. Is there support for designing custom games? I see Lua script being mentioned to specify the reward structure, new goals, etc. Is there also a support for new maps?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1285/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1285/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1285/Reviewer_3D5Q"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1285/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699029167063,
            "cdate": 1699029167063,
            "tmdate": 1699636055338,
            "mdate": 1699636055338,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mCSQE67OVh",
                "forum": "UBVNwD3hPN",
                "replyto": "JelbU9YL6v",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1285/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1285/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Point-to-Point Response to Reviewer 3D5Q"
                    },
                    "comment": {
                        "value": "We thank reviewer 3D5Q for the valuable time and constructive feedback.\n\n#### **Q1: How robust is the server-client architecture? Did you do any experiments to test it?**\n\n**A1:**\nThat is an excellent question! During the development of CivRealm, we adhered to the test-driven development practice. We created unit tests, integration tests, and end-to-end tests to verify the reliability of various game operations and the training environment. Additionally, we conducted testing on multiple platforms, including Linux, Mac OS, and Windows, to ensure smooth gameplay for our agents to the best of our efforts. Most of the test code is available in the [civrealm/tests](https://github.com/civrealm/civrealm/tree/main/tests) folder within the released `civrealm` repository for your reference.\n\n#### **Q2: Is there support for designing custom games? I see Lua script being mentioned to specify the reward structure, new goals, etc. Is there also a support for new maps?**\n\n**A2:**\nYes, we have uploaded a `civrealm-sav` repository in our released code. This repository enables users to customize new games and generate new maps. For a detailed tutorial, please refer to the 'Create new Mini-Game' content at: <https://civrealm.github.io/civrealm/advanced_materials/minigame.html>.\n\nWe sincerely appreciate your thoughtful review, and we hope we have addressed your concerns. Please let us know if you would like any further information."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1285/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700337910459,
                "cdate": 1700337910459,
                "tmdate": 1700542067365,
                "mdate": 1700542067365,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7WjpEBo3yW",
                "forum": "UBVNwD3hPN",
                "replyto": "mCSQE67OVh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1285/Reviewer_3D5Q"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1285/Reviewer_3D5Q"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for clarification"
                    },
                    "comment": {
                        "value": "I read the rebuttal carefully and I thank the authors for their response and their work."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1285/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700493713786,
                "cdate": 1700493713786,
                "tmdate": 1700493713786,
                "mdate": 1700493713786,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tvS6qGzngG",
                "forum": "UBVNwD3hPN",
                "replyto": "JelbU9YL6v",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1285/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1285/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your response"
                    },
                    "comment": {
                        "value": "Thank you for your prompt response. We are genuinely grateful for your thoughtful feedback, which further improves the clarity of our paper. \n\nBest,\n\nAuthors"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1285/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700584927904,
                "cdate": 1700584927904,
                "tmdate": 1700584972004,
                "mdate": 1700584972004,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]