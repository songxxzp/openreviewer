[
    {
        "title": "On the Markov Property of Neural Algorithmic Reasoning: Analyses and Methods"
    },
    {
        "review": {
            "id": "JHQ2XfG9zE",
            "forum": "Kn7tWhuetn",
            "replyto": "Kn7tWhuetn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5854/Reviewer_QaJ5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5854/Reviewer_QaJ5"
            ],
            "content": {
                "summary": {
                    "value": "The paper points out that most algorithmic tasks should have Markov property and thus the optimal model should not rely on historical embeddings. The paper then proposes ForgeNet and GForgerNet which doesn't use or only limitedly use historical embeddings."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. There is a novelty in observing the Markov property of many algorithmic tasks and proposing an architecture that aligns with this property.\n2. The overall performance seems to be better than all compared baselines.\n3. The paper is quite well-written and easy to follow."
                },
                "weaknesses": {
                    "value": "The authors claimed that the gating value should decrease because  \"As training progresses and the model starts predicting more reliable intermediate predictions\". But if there are no regularisation terms on the gating variable, why should the gating value decrease if there is still useful information in the historical embeddings?  The authors do show a plot of the gating variable trajectory as training progresses, but the gating value only decreases slightly and never to 0. Are there any cases where the gating variable decreases to 0? If not, why is this the case since the model can just simply ignore the historical embedding after training stabilizes?"
                },
                "questions": {
                    "value": "See weakness,"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5854/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697915735778,
            "cdate": 1697915735778,
            "tmdate": 1699636619774,
            "mdate": 1699636619774,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9nKLexZumk",
                "forum": "Kn7tWhuetn",
                "replyto": "JHQ2XfG9zE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5854/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5854/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reponse to Reviewer QaJ5"
                    },
                    "comment": {
                        "value": "Dear reviewer QaJ5, thank you for your valuable comments. Below are our responses to your concerns.\n\n> If there are no regularization terms on the gating variable, why should the gating value decrease if there is still useful information in the historical embeddings?\n\nMotivated by this comment, we have added a regularization term to G-ForgetNet and demonstrated its superb effectiveness for enforcing the Markov property in G-ForgetNet and improving model performance. We refer the reviewer to Section 4.2 and Section 5 to see the details of this new regularization term as well as an analysis of its performance and behavior. However, without this penalty term, we still observe that the gating value in G-ForgetNet decreases. As motivated by the Markov property and empirically shown in ForgetNet, the historical embeddings do not contain useful information, which is why we still observe that the gating value in G-ForgetNet decrease, allthough not to 0 as it does with the added penalty. \n\n> The authors do show a plot of the gating variable trajectory as training progresses, but the gating value only decreases slightly and never to 0. Are there any cases where the gating variable decreases to 0?\n\nWithout the added loss penalty, the gating value generally will not converge exactly to 0, allthough it does get close for many algorithms. However, when we add the penalty to G-ForgetNet, we see that the gating value *does* converge to 0. We analyze the behavior of the penalized gate in Section 5 and in Appendix A.2, and we have included an in-depth comparison of G-ForgetNet with and without this penalty in Appendix A.3 in order to address these questions. \n\nFinally, we would like to thank the reviewer for the insightful points they raised"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700515519821,
                "cdate": 1700515519821,
                "tmdate": 1700515519821,
                "mdate": 1700515519821,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "lesoG3MWWC",
            "forum": "Kn7tWhuetn",
            "replyto": "Kn7tWhuetn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5854/Reviewer_gWrY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5854/Reviewer_gWrY"
            ],
            "content": {
                "summary": {
                    "value": "This paper aims to reconsider the Markov property of neural algorithmic reasoning. While classical algorithms inherently possess the Markov property, existing neural algorithmic reasoning approaches learn to execute algorithms using historical embeddings, which contradicts this property. Building on this observation, this paper proposes ForgetNet, a method that eliminates the reliance on historical embeddings to reintroduce the Markov nature. Additionally, the paper introduces G-ForgetNet, which adaptively integrates historical embeddings."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This paper focuses on an emerging and interesting research topic: neural algorithmic reasoning.\n2. This paper is well-written. Figures and formulas clearly illustrate the background and proposed method.\n3. The motivation for aligning current algorithms with their Markov nature is well stated. Additionally, this paper complements a crucial concept in the context of neural algorithmic reasoning.\n4. Experiments show that the proposed method can outperform baselines in most of the tasks (algorithms)."
                },
                "weaknesses": {
                    "value": "1. Although ForgetNet perfectly possesses the Markov property of algorithm execution, the newly proposed G-ForgetNet still utilizes historical embeddings but outperforms ForgetNet. Is there an inherent drawback of neural algorithmic reasoning in possessing the Markov property?\n2. For certain tasks, G-ForgetNet performs worse than ForgetNet, or ForgetNet performs worse than the baseline. Some task-specific explanations regarding this should be discussed."
                },
                "questions": {
                    "value": "Please see the weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5854/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5854/Reviewer_gWrY",
                        "ICLR.cc/2024/Conference/Submission5854/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5854/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698657359940,
            "cdate": 1698657359940,
            "tmdate": 1700615916365,
            "mdate": 1700615916365,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tatsnA2xQE",
                "forum": "Kn7tWhuetn",
                "replyto": "lesoG3MWWC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5854/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5854/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer gWrY"
                    },
                    "comment": {
                        "value": "Dear reviewer gWrY, thank you for your valuable comments. Below are our responses to your concerns.\n\n> W1.  Although ForgetNet perfectly possesses the Markov property of algorithm execution, the newly proposed G-ForgetNet still utilizes historical embeddings but outperforms ForgetNet. Is there an inherent drawback of neural algorithmic reasoning in possessing the Markov property?\n\nThe drawback of ForgetNet is not due to the Markov property, in fact, the Markov property is ForgetNet's biggest strength. The drawback of ForgetNet is the training difficulties that stem from removing the connections between layers. We have tried to clarify this point in Sections 4.1 and 4.2 of our revised manuscript. Additionally, motivated by comments from reviewers, we added a loss penalty to G-ForgetNet which better aligns G-ForgetNet with the Markov property. We demonstrate that, with the new loss penalty, the gate norm goes to 0 during training, *i.e.,* the gate becomes entirely closed. We observe that enforcing the gate to be closed significantly improves the performance of G-ForgetNet, as it now outperforms the baseline on all 30/30 algorithms. As such, we further show the power of aligning neural algorithmic reasoners with the important Markov property. We refer the reviewer to the revised Section 5 to see these new results. \n> W2. For certain tasks, G-ForgetNet performs worse than ForgetNet, or ForgetNet performs worse than the baseline. Some task-specific explanations regarding this should be discussed\n\nGenerally ForgetNet struggles on algorithms where the $\\texttt{hints}$ time series is very long, such as Jarvis' March, Articulation Points, or Heapsort, where the training time series lengths are 204, 163, and 91, respectively. This aligns with our expectations as it is incredibly difficult for the model to backpropagate signals through 100+ sequentially applied processor layers when the predictions early in the time series are inaccurate. We believe that ForgetNet underperforms on algorithms such as Naive String Matcher or Floyd-Warshall because the update step between consecutive $\\texttt{hints}$ is non-trivial. E.g. in Floyd-Warshall, each step requires the model to simulate a double-nested for-loop, which is generally difficult to learn, and these difficulties are then compounded by the previously discussed training issues in ForgetNet. \n\nConversely, ForgetNet performs best on algorithms with very simple update steps between hints such as in DFS."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700515080969,
                "cdate": 1700515080969,
                "tmdate": 1700515080969,
                "mdate": 1700515080969,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2tlvLtOkbc",
                "forum": "Kn7tWhuetn",
                "replyto": "tatsnA2xQE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5854/Reviewer_gWrY"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5854/Reviewer_gWrY"
                ],
                "content": {
                    "comment": {
                        "value": "Dear authors,\n\nThanks for your response, but I'm afraid you have misunderstood my question. I'm asking if there is an inherent drawback of **neural algorithmic reasoning** in possessing the Markov property, rather than your proposed method. Could you provide any insights into this?"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522770795,
                "cdate": 1700522770795,
                "tmdate": 1700522770795,
                "mdate": 1700522770795,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FdLhF0xCiD",
                "forum": "Kn7tWhuetn",
                "replyto": "lesoG3MWWC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5854/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5854/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer gWrY"
                    },
                    "comment": {
                        "value": "Dear reviewer gWrY,\n\nWe apologize for any confusion. To the best of our knowledge, there are *not* any inherent drawbacks of neural algorithmic reasoning in possessing the Markov property. When the algorithmic reasoning task is Markov, neural algorithmic reasoners are able to learn single-step execution, *i.e.,* learning transitions between subsequent states or $\\texttt{hints}$. As formalized in [1], intuitively, it is easier for neural networks to learn these simpler computations, and the removal of such Markov property would needlessly increase the complexity of the underlying task. \n\nAdditionally, prior works such as [2] have shown that using the $\\texttt{hints}$ time series significantly increases the performance of neural algorithmic reasoning models compared to directly learning to map from the algorithm input to the final output. They do not analyze this in the context of the Markov property, however, based on the analysis in our work, we can see that the removal of such hints removes the Markov property from the neural algorithmic reasoning task, which explains observed the performance degradation. \n\n[1] Keyulu Xu, Jingling Li, Mozhi Zhang, Simon S Du, Ken-ichi Kawarabayashi, and Stefanie Jegelka. What can neural networks reason about? In International Conference on Learning Representations, 2020.\n\n[2] Beatrice Bevilacqua, Kyriacos Nikiforou, Borja Ibarz, Ioana Bica, Michela Paganini, Charles Blundell, Jovana Mitrovic, and Petar Veli\u010dkovi\u0107. Neural algorithmic reasoning with causal regularisation. In International Conference on Machine Learning, pp. 2272\u20132288. PMLR, 2023."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700549127230,
                "cdate": 1700549127230,
                "tmdate": 1700549158279,
                "mdate": 1700549158279,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wUGtGmh9fu",
                "forum": "Kn7tWhuetn",
                "replyto": "FdLhF0xCiD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5854/Reviewer_gWrY"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5854/Reviewer_gWrY"
                ],
                "content": {
                    "comment": {
                        "value": "Dear authors,\n\nThanks for your clarification. Given your response and acknowledging my unfamiliarness with this area, I maintained my score and decreased my confidence."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700615902222,
                "cdate": 1700615902222,
                "tmdate": 1700615902222,
                "mdate": 1700615902222,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Iyzl3h1WjB",
            "forum": "Kn7tWhuetn",
            "replyto": "Kn7tWhuetn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5854/Reviewer_fqct"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5854/Reviewer_fqct"
            ],
            "content": {
                "summary": {
                    "value": "This work studies a gap in the existing GNN literature -- while encoder-processor-decoder architectures typically have hidden states passed between calls to the processor, this work investigates the best way to handle those connections in the setting of algorithmic reasoning."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The work is original to my knowledge. In fact, I went through related work looking for experiments, claims, and ablation studies relevant to this paper. I expected to see some justification or discussion of the hidden states and the way they are used in other GNN architectures. I could not find a sufficient example and so I think question the architecture and showing that omitting hidden states all together or otherwise limiting the information flow through those connections is a valuable addition to the literature.  \n2. The quality of the writing is good. I think the paper is well motivated and clearly written.\n3. The conclusions are significant. The fact is that on a 30-problem benchmark suite, the two architectural changes proposed in this work generally improve performance."
                },
                "weaknesses": {
                    "value": "1. The discussion of the Markov nature of algorithms could use some nuance. If it is the case that these algorithms, when processing entire graphs, therefore having some history in the 'state' are Markov, then the historical information in the hidden features shouldn't help. In fact, this work shows that a gated layer is better than no connection for passing information with the hidden states. Thus, I think the story arc is a bit confusing. It actually took me several readings to really piece together the fact that the treatment of the hidden state is under discussed in the literature and the two options presented in this paper are better than the existing approaches as a result of the confusing Markov narrative. This is perhaps a small point, and I'm only one reader -- if the Markov framework helps convey the story to others this is my weakness, and not the paper's but I though it was worth mentioning here."
                },
                "questions": {
                    "value": "1. In most algorithms ForgetNet beats the baseline (Figure 3). Is there any intuition or hypothesis around which particular algorithms the baseline is better? For example, for Naive String Matcher the baseline looks considerably better. Why might that be?\n2. I really like the visualization with bars in Figure 1, I think adding G-ForgetNet to that graphic or otherwise including a plot with the G-ForgetNet results would help. Can the authors provide such a visualization?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5854/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698777716055,
            "cdate": 1698777716055,
            "tmdate": 1699636619540,
            "mdate": 1699636619540,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9vrgpVHhpv",
                "forum": "Kn7tWhuetn",
                "replyto": "Iyzl3h1WjB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5854/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5854/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer fqct"
                    },
                    "comment": {
                        "value": "Dear reviewer fpct, thank you for your valuable comments. Below are our responses to your concerns.\n\n> The discussion of the Markov nature of algorithms could use some nuance. If it is the case that these algorithms, when processing entire graphs, therefore having some history in the 'state' are Markov, then the historical information in the hidden features shouldn't help\n\nIn our revised manuscript we have clarified our motivations for the G-ForgetNet model. The core motivation for the proposed G-ForgetNet is that, while inclusion of information from previous layers does not inherently align with the desired Markov nature, it can provide helpful support, especially during the early stage of training, where it can mitigate the effects of inaccurate intermediate predictions and facilitate higher quality backpropagation signals. *I.e.* the connection between layers in G-ForgetNet is beneficial not because the model is making use of historical information about the algorithm, but rather because of the important computational pathways it provides. We refer the reviewer to Section 4.1 and 4.2 for more elaboration. Additionally, we further introduce a loss penalty for G-ForgetNet and show that enforcing the gate to be closed further boosts performance, which aligns with our intuitions about the importance of obeying the Markov property. We hope that this new penalized G-ForgetNet model helps to clarify the story arc. \n\n> Q1.  In most algorithms ForgetNet beats the baseline (Figure 3). Is there any intuition or hypothesis around which particular algorithms the baseline is better? For example, for Naive String Matcher the baseline looks considerably better. Why might that be?\n\nGenerally ForgetNet struggles on algorithms where the $\\texttt{hints}$ time series is very long, such as Jarvis' March, Articulation Points, or Heapsort, where the training time series lengths are 204, 163, and 91, respectively. This aligns with our expectations as it is incredibly difficult for the model to backpropagate signals through 100+ sequentially applied processor layers when the predictions early in the time series are inaccurate. We believe that ForgetNet underperforms on algorithms such as Naive String Matcher or Floyd-Warshall because the update step between consecutive $\\texttt{hints}$ is non-trivial. E.g. in Floyd-Warshall, each step requires the model to simulate a double-nested for-loop, which is generally difficult to learn, and these difficulties are then compounded by the previously discussed training issues in ForgetNet. \n\n> Q2.  I really like the visualization with bars in Figure 1, I think adding G-ForgetNet to that graphic or otherwise including a plot with the G-ForgetNet results would help. Can the authors provide such a visualization?\n\nWe have added this visualization as Figure 6 in Appendix A.1."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700514956629,
                "cdate": 1700514956629,
                "tmdate": 1700514956629,
                "mdate": 1700514956629,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XoLgq1u5M4",
                "forum": "Kn7tWhuetn",
                "replyto": "9vrgpVHhpv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5854/Reviewer_fqct"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5854/Reviewer_fqct"
                ],
                "content": {
                    "title": {
                        "value": "Reply from Reviewer fqct"
                    },
                    "comment": {
                        "value": "Thank you for these additions. The paper is strong, and I advocate that it be accepted."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700586764655,
                "cdate": 1700586764655,
                "tmdate": 1700586764655,
                "mdate": 1700586764655,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "F65jrk035V",
            "forum": "Kn7tWhuetn",
            "replyto": "Kn7tWhuetn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5854/Reviewer_PbVk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5854/Reviewer_PbVk"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes ForgetNet, a GNN that enforces Markov structure across algorithmic reasoning steps.\n- Motivation: algorithmic tasks (e.g. sorting) can be modeled by transitioning through states which is Markov in nature, whereas existing methods use the history.\n- Solution: ForgetNet enforces such Markov structure by updating the representation at each step usingfeatures at the current step only.\n    - i.e. the hidden states at time $t$ is updated as $\\{h_i^{(t)}\\} = f_{\\text{GNN}}(\\{x_i^{(t)}\\}, \\{e_{ij}^{t}\\}, g^{(t)})$, for node features $x$, edge features $e$, and global feature $g$.\n- Further challenge: empirical results suggest that such Markov structure may cause training instability issues at early stage of training, likely because the intermediate steps are too unconstrained (note that supervision is provided only on the final state).\n- Solution: G-ForgetNet, which selectively and adaptively keeps some history using a gating mechanism."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Another way to state the results is that\n1. for better generalization, the authors proposed to restrict the function class by excluding non-Markov solutions, leading to the proposed ForgetNet.\n2. the restricted function class raises optimization challenges. To address these challenges, the author incorporates a gating mechanism that selectively incorporate the history.\n\nBoth these changes are natural/simple yet effective: the proposed G-ForgetNet outperforms baselines in most tasks in the CLRS-30 benchmark."
                },
                "weaknesses": {
                    "value": "- The discussion about the motivation could be improved.\n- About the motivation that \"algorithmic reasoning tasks are Markov\": it should be clarified that this work is about algorithmic reasoning tasks that can be modeled by finite-state automata. In general, whether the process is Markov or not depends the definition of the state space.\n- Even though the Markov observation motivates to remove history information, history information proves to be important for stabilizing training (hence the proposal of G-ForgetNet). This is similar to the effect of residual links, which can be discussed more in the paper."
                },
                "questions": {
                    "value": "- Fig 4 (b): what are execution steps, and how are the labels acquired? Since there are labels to compute the per-step loss, can we also compare with per-step teacher forcing?\n- Fig 5: for better comparison, could you also provide the norm of the residual branch in the baseline?\n- I wonder if one can anneal the gating, i.e. gradually reducing the amount of the history (e.g. by controlling the gating value).\n    - One motivation is that in Table 1, when G-ForgetNet is not better than the baseline, its performance is very close to the baseline. This suggests that G-ForgetNet falls back to the baseline in these cases, hence ensuring the history embeddings are actually not being used may help with performance.\n    - Another reason is that according Fig 5, the gate value is ~0.38 even at the end of training. This means the history embeddings are still helpful, which weakens the claim that the task should be Markov, unless the history embeddings are effectively removed."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5854/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5854/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5854/Reviewer_PbVk"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5854/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698817837039,
            "cdate": 1698817837039,
            "tmdate": 1700628475400,
            "mdate": 1700628475400,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "OqQVd3UMh3",
                "forum": "Kn7tWhuetn",
                "replyto": "F65jrk035V",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5854/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5854/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer PbVk 1/2"
                    },
                    "comment": {
                        "value": "Dear reviewer PbVk,\n\nWe thank you for your insightful comments. We have addressed your comments in the revised manuscript.\n\n>  The discussion about the motivation could be improved.\n\nPrior works such as [1] have shown the importance of aligning the computational graph of neural networks with the structure of the underlying task. This motivates us to restructure the computational graph of neural algorithmic reasoners to be better aligned with the Markov nature of the algorithms in the CLRS-30 benchmark. In our revised manuscript we have clarified the motivation for our G-ForgetNet model. We refer the reviewer to Sections 4.1 and 4.2 to see our refined motivation for G-ForgetNet, including the mentioned connections with residual links.\n\n>  It should be clarified that this work is about algorithmic reasoning tasks that can be modeled by finite-state automata. In general, whether the process is Markov or not depends the definition of the state space.\n\nFirstly, thank you for raising an interesting perspective on finite-state automata, which may broaden this direction in the future. Indeed, the algorithms in the CLRS-30 *can* be modeled by finite automata under a slightly irregular definition of the state space because the graphs used for training and testing are of fixed size. We leave further theoretical analysis of algorithmic reasoning in the context of finite automata or other models of computation to future work.\n\n>  Even though the Markov observation motivates to remove history information, history information proves to be important for stabilizing training (hence the proposal of G-ForgetNet). This is similar to the effect of residual links, which can be discussed more in the paper.  \n\nWe appreciate the insightful comments about the similarities with residual links. We have added some discussion on these similarities in Section 4.1.\n\n> Fig 4 (b): what are execution steps, and how are the labels acquired? Since there are labels to compute the per-step loss, can we also compare with per-step teacher forcing?\n\nThis part of Figure 4 was moved to Appendix B.2 in our updated manuscript in order to make room for the rest of our updates. However, the execution steps in this figure are the time series of $\\texttt{hints}$ for each intermediate step in the algorithm process. Per your suggestion, we evaluated ForgetNet with 100% teacher forcing. Allthough the losses for ForgetNet with teacher forcing are incredibly low, the model fails to generalize to the test data for most algorithms. The figure with the training losses for ForgetNet trained with teacher forcing on the Floyd-Warshall algorithm can be sound in the Supplementary Material, and the performance for ForgetNet with teacher forcing on each algorithm can be found below. Allthough the overall average performance of ForgetNet with teacher forcing is significantly below the baseline, it outperforms our best model, G-ForgetNet, on several algorithms, including na\u00efve string matcher, where it achieves a remarkable 100% test accuracy. We believe teacher forcing shows significant potential for future works, however further study is outside the scope of our paper.\n\n> Fig 5: for better comparison, could you also provide the norm of the residual branch in the baseline?\n\nYes, per your suggestion, we have included the norm of the residual branch in the baseline in Figure 5 as well as in Figure 7 in Appendix A.2. In order to provide a fair comparison between G-ForgetNet and the baseline, we now report the norm of the gated hidden states instead of the norm of the gate itself. \n\n[1] Keyulu Xu, Jingling Li, Mozhi Zhang, Simon S Du, Ken-ichi Kawarabayashi, and Stefanie Jegelka. What can neural networks reason about? In  International Conference on Learning Representations,  2020."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700514662414,
                "cdate": 1700514662414,
                "tmdate": 1700514662414,
                "mdate": 1700514662414,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1rX7hSBUQr",
                "forum": "Kn7tWhuetn",
                "replyto": "VzcXiL8JOa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5854/Reviewer_PbVk"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5854/Reviewer_PbVk"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for the clarification and additional results!\nI maintain my score and recommend acceptance."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700627952764,
                "cdate": 1700627952764,
                "tmdate": 1700627952764,
                "mdate": 1700627952764,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rhw5JSG3p0",
            "forum": "Kn7tWhuetn",
            "replyto": "Kn7tWhuetn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5854/Reviewer_VNPs"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5854/Reviewer_VNPs"
            ],
            "content": {
                "summary": {
                    "value": "The paper focuses on the Markov property of neural algorithmic reasoning. More specifically, neural networks that learn to imitate algorithmic execution have thus far used as additional inputs data from the algorithmic traces at previous execution steps, not just the current step. The paper emphasises that, as the studied algorithms are Markovian, a better alignment between the neural network and the task should mean not using data from previous execution steps, which are named historical embeddings in the paper. This work uses an established architecture as the baseline, and with the removal of the historical embeddings proposes ForgetNet. Further, G-ForgetNet is obtained by using a gating mechanism to learn how much to use the historical embeddings within the baseline. The proposed changes outperform the studied baselines, and a simple ablation study on the gating mechanism shows the importance of using historical embeddings early on in training, when accumulating errors can be more harmful for final performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well motivated and clear. The proposed changes are supported by the empirical evaluation on the CLRS-30, outperforming the baseline in most algorithms."
                },
                "weaknesses": {
                    "value": "The initial hypothesis \u2014 that better alignment with the markovian property should result in better performance \u2014 is strong. However, there are trainability issues (e.g. accumulating errors early in training) that can be addressed in different ways. The paper proposes one solution, gating, but some questions remain \u2014 why is gating better than the NN more generally learning how to combine historical and current embeddings, as in the baseline? Moreover, what are other solutions, possibly not involving learning?\n\nLastly, the TripletGMPNN includes a gating layer in the single-task setup. A discussion on how this differs from the gating in G-ForgetNet should be included."
                },
                "questions": {
                    "value": "Please see above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5854/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5854/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5854/Reviewer_VNPs"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5854/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699579587739,
            "cdate": 1699579587739,
            "tmdate": 1699636619296,
            "mdate": 1699636619296,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7yTg4WMwu3",
                "forum": "Kn7tWhuetn",
                "replyto": "rhw5JSG3p0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5854/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5854/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer VNPs"
                    },
                    "comment": {
                        "value": "Dear reviewer VNPs, thank you for your valuable comments. Below are our responses to your concerns.\n\n>  Why is gating better than the NN more generally learning how to combine historical and current embeddings, as in the baseline?\n\nIn response to your comments and those of other reviewers, we have added a regularization term to the loss function which penalizes the magnitude of the gate norm, ensuring that the gate is aligned with the Markov property as desired. However, to answer your original question, the G-ForgetNet model *without* this penalty performs better than the baseline because, while it still may fit some historical noise, it is less reliant on historical embeddings than the baseline model, and therefore closer aligned with the Markov property. We further analyze your question in Appendix A.3 of our revised manuscript.\n\n>  Lastly, the TripletGMPNN includes a gating layer in the single-task setup. A discussion on how this differs from the gating in G-ForgetNet should be included.\n\nThe gate in Triplet-GMPNN is placed ahead of the decoder and is meant to bias the model towards only updating a subset of the hidden states at each step, while the remaining hidden states are left unchanged. Our gate is placed ahead of the processor and is meant to bias the model towards not including *any* hidden states at all, which we further enforce using a loss penalty. We have added further clarification about the difference between our gates in Section 5 of the revised manuscript.\n\n> Moreover, what are other solutions, possibly not involving learning?\n\nWe previously tried to use a manual annealing schedule for the gate in which the gate is initially fully open, and is linearly decayed until the end of training, where it would be entirely closed, thus explicitly enforcing the Markov property. However, we found that this did not significantly improve the performance over the baseline. The results of this experiment for each algorithm are given in the table below. \n\nResults outperforming G-ForgetNet are highlighted in bold\n\n|Algorithm | Manual Annealing |\n|--|--|\n| Activity Selector | 95.99\u00b11.02% |\n| Articulation Points | 94.37\u00b10.84% |\n| Bellman-Ford | 98.71\u00b10.08% |\n|BFS |  99.95\u00b10.02% |\n|Binary Search | 71.40\u00b12.22% |\n| Bridges | 96.25\u00b11.41% |\n| Bubble Sort | 77.53\u00b13.20% |\n| DAG Shortest Paths | 98.45\u00b10.17% |\n| DFS |  62.23\u00b17.53% |\n| Dijkstra | 98.23\u00b10.06% |\n| Find Max. Subarray | 42.89\u00b10.98% |\n| Floyd-Warshal | 33.77\u00b11.15% |\n| Graham Scan | 92.17\u00b11.41% |\n| Heapsort | 37.26\u00b13.89% |\n| Insertion Sort | 87.52\u00b10.93% |\n| Jarvis' March | 82.45\u00b11.45% |\n| Knuth-Morris-Pratt | **23.79\u00b12.96%** |\n| LCS Length |  84.49\u00b10.60% |\n| Matrix Chain Order | 92.94\u00b11.08% |\n| Minimum | 97.73\u00b10.40% |\n| MST-Kruskal | 85.73\u00b10.72% |\n| MST-Prim | 92.75\u00b10.53% |\n| Na\u00efve String Matcher | 27.32\u00b11.39% |\n| Optimal BST | 78.52\u00b10.73% |\n| Quickselect | 3.54\u00b10.90% |\n| Quicksort | 49.56\u00b15.09% |\n| Segments Intersect | 98.47\u00b10.06% |\n| SCC | 41.90\u00b12.54% |\n| Task Scheduling | 81.05\u00b10.44% |\n| Topological Sort | 91.48\u00b13.68% |\n| Overall Average | 73.95\u00b11.58% |"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700514295584,
                "cdate": 1700514295584,
                "tmdate": 1700514295584,
                "mdate": 1700514295584,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8hfDp4Gcfe",
                "forum": "Kn7tWhuetn",
                "replyto": "7yTg4WMwu3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5854/Reviewer_VNPs"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5854/Reviewer_VNPs"
                ],
                "content": {
                    "comment": {
                        "value": "I would like to thank the authors for their response. I will maintain my score, recommending acceptance of the paper."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700739861782,
                "cdate": 1700739861782,
                "tmdate": 1700739861782,
                "mdate": 1700739861782,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]