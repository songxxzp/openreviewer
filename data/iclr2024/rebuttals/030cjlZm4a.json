[
    {
        "title": "Learning Predictive Checklists with Probabilistic Logic Programming"
    },
    {
        "review": {
            "id": "6z8d0fHka1",
            "forum": "030cjlZm4a",
            "replyto": "030cjlZm4a",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9267/Reviewer_SxKf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9267/Reviewer_SxKf"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a new framework for learning predictive checklists. The method is able to process time series, images, tabular features, etc. The use of techniques enabling sparse representations of the inputs and the use of a fairness metric lead to checklists that would have interpretable features and that promote fairness toward sensible variables."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "-The \u00ab\u00a0related works\u00a0\u00bb  analysis is thorough and seems up-to-date.\n-I found the experiment subsection 5.1 truly compelling. Many metrics are reported, which I think is not done often enough.\n-The approach is well-explained and flexible."
                },
                "weaknesses": {
                    "value": "**Major**\n\n1 \u2013 Most how the points I would like to raise concern interpretability. (See also the points in the Question section on that matter.)\n\n1.1 - Interpretability is directly impacted by the complexity of the model itself, but the fact that the algorithm is in itself a black box makes it such that understanding why the model is what it is is unreachable.\n\n1.2 \u2013 As discussed in [1], p.17, when it comes to logical rules, the more digits there are to take into account, the less the rule is interpretable. One could argue that the checks from Figure 4 aren\u2019t that interpretable. When it comes to the features themselves: what does it really mean to have an \u00ab\u00a0sd\u00a0\u00bb of FiO2 above 0.035? It is normal? Is it higher than the average? Is it higher than a certain minimum threshold? Such questions arrises with every check.\n\n1.3 \u2013 The interpretation made of the checks from MNIST Images task is questionable. It\u2019s been known for a long time now that saliency maps, especially the vanilla approach of looking at the gradient map, can easily lead to false conclusions, especially when those conclusions match what a person is seeking [2]. Interpretability is needed in the context where explainability (e.g. saliency maps) is not trustworthy.\n\n1.4 \u2013 Finally, the interpretation of the features is made in an example where the relationship between the inputs of a problem and the labels is known. The procedure given in order to make sense of the feature extract wouldn\u2019t work if this knowledge was unknown.\n\n2.1 \u2013 It is shown that the use of the fairness regularizer works in order to minimize both FNR and FPR, but it is not discussed whether or not the constraint impacts the performances of the checklist, so there is no way to truly understand if its usage is really beneficial.\n\n2.2 \u2013 The second contribution states \u00ab\u00a0We investigate the impact of different schemes for improving the interpretability of the concepts learnt as the basis of the checklist. We employ regularization techniques to encourage the concepts to be distinct, so they can span the entire input vector and be specialized, i.e. ignore the noise in the signal and learn sparse representations. We also investigate the impact of incorporating fairness constraints into our architecture.\u00a0\u00bb But since (as discussed in 2.1) there lacks evidence of the soundness of the fairness regularizer, combined with the fact that there is no evidence demonstrating that \u00ab\u00a0regularization techniques encourage the concepts to be distinct, so they can span the entire input vector and be specialized\u00a0\u00bb (as discussed in 1.4), or at least that the \u00ab\u00a0different schemes for improving the interpretability of the concepts learned\u00a0\u00bb truly are responsible for such observations, the soundness of all Contribution 2 can be questioned.\n\n[1]\u00a0: Rudin, C., Chen, C., Chen, Z., Huang, H., Semenova, L., & Zhong, C. (2021). Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges. ArXiv. /abs/2103.11251\n\n[2]\u00a0: Julius Adebayo, Justin Gilmer, Michael Muelly, Ian J. Goodfellow, Moritz Hardt, and Been Kim. 2018. Sanity Checks for Saliency Maps. In NeurIPS. 9525\u20139536.\n\n**Minor**\n\n1 \u2013 Typos. There are several of them... \n\n1.1 - \u00ab\u00a0Figure 1: Example checklist **learnt** by our architecture. Three **of** more checks [\u2026].\u00a0\u00bb\n\n1.2 - \u00ab\u00a0Clinical practice is **an** highly stressful [...]\u00a0\u00bb\n\n1.3 - \u00ab\u00a0[\u2026] programming and thus exhibits much faster **?** times and [...]\u00a0\u00bb (a word is missing; \u00ab\u00a0computation\u00a0\u00bb, \u00ab\u00a0training\u00a0\u00bb?)\n\n1.4 - \u00ab\u00a0[\u2026] we can write the **probabality** of query q as follows.\u00a0\u00bb\n\n1.5 - \u00ab\u00a0We **additional** introduce a regularization [...]\u00a0\u00bb\n\n1.6 - \u00ab\u00a0We investigate the performance **?** ProbChecklist along [...]\u00a0\u00bb\n\n1.7 - \u00ab\u00a0We create **a We** briefly describe the MNIST [...]\u00a0\u00bb\n\n1.8 - \u00ab\u00a0focus on the image\u2019s upper half and **centre**\u00a0\u00bb\n\n1.9 - \u00ab\u00a0we visualize **? learnt** by ProbChecklist in one of the experiments\u00a0\u00bb\n\n1.10 - \u00ab\u00a0Detailed complexity analysis can be found in the **?** B.\u00a0\u00bb\n\n1.11 - \u00ab\u00a0[\u2026] interpretable such as decision trees) **)** and posthoc [...]\u00a0\u00bb\n\n2 - \u00ab\u00a0ProbChecklist\u00a0\u00bb is named one time (the first time) before being properly introduced (the second time it is mentioned).\n\n3 \u2013 The first citation \u00ab\u00a0Learning Predictive and Interpretable Timeseries Summaries from ICU Data, volume 1, 2021.\u00a0\u00bb doesn\u2019t respect the template. It should be something like \u00ab\u00a0Johnson N, Parbhoo S, Ross AS, Doshi-Velez F. Learning Predictive and Interpretable Timeseries Summaries from ICU Data. AMIA Annu Symp Proc. 2022 Feb 21;2021:581-590. PMID: 35309006; PMCID: PMC8861716.\u00a0\u00bb\n\n4 \u2013 The fourth chapter\u2019s title should be isolated from the previous paragraph.\n\n5 \u2013 Using a single letter (with the same calligraphy) for two different usages (\u2018d\u2019, both overall dimension and error criterion) is not desirable.\n\n6 \u2013 Constraints are not respected concerning the configuration of the table (Table 1): \u00ab\u00a0number and title always appear before the table\u00a0\u00bb (ICLR24 template and instructions).\n\n7 \u2013 In Table 1: why is there no number bolded for some dataset / metric? Why are there two bolded results for MIMIC III \u2013 Accuracy?"
                },
                "questions": {
                    "value": "1 - Interpretability is not inherent to a family of models. For example, a checklist whose features aren\u2019t interpretable or a checklist with too many \u00ab\u00a0checks\u00a0\u00bb to look at (as with linear models) isn\u2019t interpretable either, for the simple knowledge is drowned in the quantity of information to manipulate. Therefore: how is it made sure that the model, concerning those two criteria, remains interpretable?\n\n2 \u2013 It is argued that decision trees could be of lesser interest when it comes to medical applications. But, the interpretation of a model is part of how the features interact with each other in order to generate a given response. When it comes to checklists, no interaction is presented whatsoever; in the case of decision trees, it is inherent what features need to be looked at carefully given the value of some other feature. Wouldn\u2019t that be more appropriate in the context of medical tasks?\n\n3 \u2013 It has been briefly discussed that there is an exponential memory complexity intrinsic to the model. Was that a limitation to the experiments that have been run?  \n\n4 - How did it impact the training time? Was that training time similar to the compared approaches? How many hyperpameters are there in total, and when compared to the baselines?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Other reasons (please specify below)"
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "This is not a huge \"ethical issue\", but the ICLR24 .tex template was modified, most probably in order to save space (no space before and/or after headings in some places, for example, the titles for Sections 4, 5.3, 6; or table titles, see Table 1)."
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9267/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9267/Reviewer_SxKf",
                        "ICLR.cc/2024/Conference/Submission9267/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9267/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698683826765,
            "cdate": 1698683826765,
            "tmdate": 1700488544114,
            "mdate": 1700488544114,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "II3sUyugh9",
                "forum": "030cjlZm4a",
                "replyto": "6z8d0fHka1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9267/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9267/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors (1/3)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their valuable comments and insights.\n\n```1 - Interpretability is not inherent to a family of models. For example, a checklist whose features aren\u2019t interpretable or a checklist with too many \u00ab checks \u00bb to look at (as with linear models) isn\u2019t interpretable either, for the simple knowledge is drowned in the quantity of information to manipulate. Therefore: how is it made sure that the model, concerning those two criteria, remains interpretable?```\n\n**Checklist with many items:** \n\nHyperparameters $d_k, \\ T and \\ M$ represent the structure/compactness of the checklist. Domain experts will be more equipped to choose these values based on their knowledge of the features. For example, if we are recording a time series feature known to stay stable (not fluctuate much), then low $d_k$ is sufficient. The value of $d_k$ also depends on the number of observations (most blood tests aren\u2019t performed hourly, but heart rate and oxygen saturation are monitored continuously). We encourage the users to select the minimum possible value for $d_k$ to effectively capture all the information. We have performed sensitivity analysis to study the relation between $d_k$ and performance. Figure 3a suggests that the performance saturates after a certain point. This point can be determined experimentally for different modalities. M, total concepts in the checklist, is obtained by pruning concepts that are true for insignificant samples.\n\n**Interpretable Concepts:**\n\nWe refer the reviewer to read the discussion on interpretability of concepts in the global response. We would be happy to answer any further questions. \n\n```2) It is argued that decision trees could be of lesser interest when it comes to medical applications. But, the interpretation of a model is part of how the features interact with each other in order to generate a given response. When it comes to checklists, no interaction is presented whatsoever; in the case of decision trees, it is inherent what features need to be looked at carefully given the value of some other feature. Wouldn\u2019t that be more appropriate in the context of medical tasks?```\n\nDecision trees and checklists are interpretable and widely used in the clinical domain. These models offer different forms of interpretability: checklists provide limited feature interaction, while each path in a decision tree represents a separate checklist.  The main goal of using such models is to automate certain stages of diagnosis/treatment and reduce the burden on the clinicians.\nChecklists, recognized for their robustness, appear as an ideal choice in emergency rooms or scenarios where doctors manage a high volume of patients simultaneously. Their robustness is intrinsically linked to interpretability and can help anticipate hard samples. This avoids poor performance on corner cases, thereby validating the model. We direct the reviewer to Section D of the appendix where we argue the tradeoffs in interpretability between  checklists and decision trees.\n\n```3 \u2013 It has been briefly discussed that there is an exponential memory complexity intrinsic to the model. Was that a limitation to the experiments that have been run?```\n\nWe have provided detailed complexity analysis and training details in the appendix (Section B). Yes, the exponential complexity is the primary reason for performing feature selection and limiting the modalities to 10 and learning up to 3 features per modality. A fruitful future direction would be to study approximations to explore a smaller set of combinations.\n\n```4 - How did it impact the training time? Was that training time similar to the compared approaches? How many hyperpameters are there in total, and when compared to the baselines?```\n\nWe thank the reviewer for this suggestion. We have added a comparison of training times with the MIP checklist method on the PhysioNet Tabular dataset to evaluate the extent of this limitation (Section B of the appendix). It's crucial to highlight that while MIP Checklist performs effectively with tabular data, successfully uncovering the optimal solution, its performance is poor when applied to MNIST synthetic setup. Even when we set the runtime for Gurobi solver as 1 hour, it struggles to achieve optimal solutions for many cases. On the other hand, ProbChecklist stands out as more reliable, capable of performing end-to-end training and successfully learning the optimal solution."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700476159199,
                "cdate": 1700476159199,
                "tmdate": 1700476159199,
                "mdate": 1700476159199,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "eBg8cZrrpF",
                "forum": "030cjlZm4a",
                "replyto": "6z8d0fHka1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9267/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9267/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors (2/3)"
                    },
                    "comment": {
                        "value": "```5) Most how the points I would like to raise concern interpretability. (See also the points in the Question section on that matter.)```\n\n```5.1 - Interpretability is directly impacted by the complexity of the model itself, but the fact that the algorithm is in itself a black box makes it such that understanding why the model is what it is is unreachable.```\n\nWe refer the reviewer to our discussion on the interpretability of checklist structure and interpretability of learnt concepts in the global response. \n\n```5.2 \u2013 As discussed in [1], p.17, when it comes to logical rules, the more digits there are to take into account, the less the rule is interpretable. One could argue that the checks from Figure 4 aren\u2019t that interpretable. When it comes to the features themselves: what does it really mean to have an \u00ab sd \u00bb of FiO2 above 0.035? It is normal? Is it higher than the average? Is it higher than a certain minimum threshold? Such questions arrises with every check.```\n\nWe transformed the PhysioNet time series dataset (which contains hourly data) into a tabular format by manually extracting features like mean, standard deviation, and final values. This method of feature extraction is extensively employed in clinical machine learning and is acknowledged as one of the most dependable and interpretable techniques in this domain. The standard deviation is particularly effective in capturing fluctuations in a patient's vital signs, with abrupt changes indicating the necessity for specialized care. We also want to clarify that these concepts are probabilistic i.e. \u2018FiO2 > 0.035 with probability 0.5'. We can optimize this probability threshold based on whether the objective is to obtain higher accuracy, AUC-ROC, or F1-Score. We performed experiments by changing the objective, which can be found in Section E.7 of the supplementary material.\n\n```5.3 \u2013 Finally, the interpretation of the features is made in an example where the relationship between the inputs of a problem and the labels is known. The procedure given in order to make sense of the feature extract wouldn\u2019t work if this knowledge was unknown.```\n\nWe direct the reviewer to Figure 1 of the paper, which illustrates the checklist learnt from the medical abstract classification task. As previously explained in the global response, understanding results for NLP tasks is significantly simpler due to the comprehensibility of tokens. We have now included a description of the technique used for generating this checklist in the main paper. While experiments involving the TANGOS regularizer on time series datasets have been conducted, we have presented them in the supplementary section. This decision was made as these results require assessment by domain experts to discern patterns effectively.  Instead, our focus has shifted to the synthetic MNIST dataset, as its known ground truth concepts make it easier to validate our approach. We also discuss the results of the PhysioNet Tabular dataset.\n\n```6) It is shown that the use of the fairness regularizer works in order to minimize both FNR and FPR, but it is not discussed whether or not the constraint impacts the performances of the checklist, so there is no way to truly understand if its usage is really beneficial.```\n\nWe agree with the reviewers assessment that only the difference in FNR/FPR error rates for pairs of sensitive groups is insufficient to gauge the fairness regularizer's effectiveness. It is crucial to ensure that the performance of the majority sensitive group does not deteriorate while the minority groups experience improvements. We have reported the FNR/FPR for each sensitive group before and after the regularizer is applied in Section G of the supplementary material. Most minority subgroups benefit\nfrom this regularization; however, FNR increases for both the Female (minority) and Male (majority)\nsubgroups after regularization. We believe that comparing FNR/FPR for individual subgroups is more apt in this setting and provides more fine-grained/thorough evaluation. We have now included additional results on how the model performance varies after the fairness regularizer is applied."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700476403483,
                "cdate": 1700476403483,
                "tmdate": 1700476703648,
                "mdate": 1700476703648,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6gzBsOeYO7",
                "forum": "030cjlZm4a",
                "replyto": "6z8d0fHka1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9267/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9267/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors (3/3)"
                    },
                    "comment": {
                        "value": "```7) The second contribution states \u00ab We investigate the impact of different schemes for improving the interpretability of the concepts learnt as the basis of the checklist. We employ regularization techniques to encourage the concepts to be distinct, so they can span the entire input vector and be specialized, i.e. ignore the noise in the signal and learn sparse representations. We also investigate the impact of incorporating fairness constraints into our architecture. \u00bb But since (as discussed in 2.1) there lacks evidence of the soundness of the fairness regularizer, combined with the fact that there is no evidence demonstrating that \u00ab regularization techniques encourage the concepts to be distinct, so they can span the entire input vector and be specialized \u00bb (as discussed in 1.4), or at least that the \u00ab different schemes for improving the interpretability of the concepts learned \u00bb truly are responsible for such observations, the soundness of all Contribution 2 can be questioned.```\n\n**Fairness Regularizer:** \n\nBased on the reviewer\u2019s suggestion, we have provided additional results in the supplementary comparing model performance before and after the fairness regularizer is applied. Previously, we had only presented the FNR/FPR values for each subgroup to show the performance of the majority sensitive group doesn\u2019t deteriorate as a result of the regularization. These results can be found in Section G of the supplementary. We also refer the reviewer to our previous answer discussing the efficacy of the fairness regularizer for more details.\n\n**TANGOS Regularizer:** \n\nThe interpretability of the feature space in deep learning problems can be approached from various angles. The notion of interpretability we have focussed on is that the concepts are distinct and specialized and also span the entire input vector. TANGOS regularization assisted us in achieving this by quantifying the contribution of each input dimension to a particular concept. We examine the gradient of each concept obtained from the concept extractors with respect to the input signal. The TANGOS loss consists of two components: The first component enforces sparsity, emphasizing a concentrated subset of the input vector for each concept. The second component promotes uniqueness, minimizing the overlap between the input subsets from which each concept is derived. Sparsity is achieved by taking the L1-norm of the concept gradient attributions with respect to the input vector. To promote decorrelation of signals learned in each concept, the loss is augmented by incorporating the inner product of the gradient attributions for all pairs of concepts. Additional details about the mathematical formulation of TANGOS have been provided in Section F.1 of the appendix. The desired level of interpretability can be adjusted by varying the relative weights of these terms with respect to the probabilistic checklist objective. In Section F.2, we show how the model performance varies in terms of accuracy, precision and recall by tweaking these weights. The section elegantly captures the trade-off between interpretability and model performance. Furthermore, we plot the images and corresponding gradient attributions heat maps for seven input samples of the Image 2 modality of the MNIST dataset for different combinations of sparsity and correlation regularization terms. This plot can be found in Section F.2 (Figure 5). Similar analysis has also been done for MIMIC Clinical Time Series (Section F.3, Figure 8). It is evident from both these plots that the gradient attributions for both the concepts was identical when TANGOS regularization is not used (i.e \\lambda_sparity = 0 and \\lambda_correlation = 0). As the regularization weights are gradually increased, the gradient attributions start to diverge, yielding distinct concepts. We agree with the reviewer that this assessment relies on visual inspection because it\u2019s hard to quantify interpretability. Nevertheless, a significant advantage of our approach lies in its flexibility, enabling users to experiment with other notions of interpretability tailored to different applications. \n\nWe also found it easier to interpret our results on NLP Medical Abstract classification without the need of TANGOS regularizer. We represented our learnt checklist in Figure 1. This is because the building blocks of text are tokens which are inherently human understandable, on the other hand it\u2019s much harder to comprehend pixel-level RGB intensities.\n\n```Typos: ```\n\nWe thank the reviewer for spotting the typing mistakes. We have proofread the paper carefully and resolved the listed issues."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700476655765,
                "cdate": 1700476655765,
                "tmdate": 1700476895937,
                "mdate": 1700476895937,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qxo8ESe809",
                "forum": "030cjlZm4a",
                "replyto": "6gzBsOeYO7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9267/Reviewer_SxKf"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9267/Reviewer_SxKf"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their exhaustive response. I am globally satisfied with the answers to my concerns. However, I still think  gradient attributions is insufficient for interpreting the concepts, as said before, for it is one explainability technique that is far from being reliable. Therefore, I see this work relevant in areas where the inputs of the problems are intrinsically interpretable. And even though the scope, from this perspective, is more restrained, the probabilistic approach and the fairness constraints are in themselves valuable contributions; I will raise thus my score. Thank you."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700488521707,
                "cdate": 1700488521707,
                "tmdate": 1700488521707,
                "mdate": 1700488521707,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "NpCjpCtarH",
            "forum": "030cjlZm4a",
            "replyto": "030cjlZm4a",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9267/Reviewer_Ucnh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9267/Reviewer_Ucnh"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a novel method based on probabilistic logic programming to learn predictive checklists from diverse data modalities including images and time series. The proposed approach was validated using several public benchmark datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Originality: The paper demonstrates originality in creative combinations of existing ideas and approaches to the target problem\n- Clarity: Problem formulations and related works are clearly described and cited. The paper is well-organized with most components including limitations.\n- Significance: Classification performances are reported with multiple metrics and confidence intervals"
                },
                "weaknesses": {
                    "value": "1. One weakness is the results discussion using MNIST data only, which is not so intuitive in the checklist concept motivated by healthcare examples in the introduction part. And the paper has results from clinical data of PhysioNet and MIMIC III in the supplementary materials, which should be much better than the MNIST story. The necessity of using checklist, instead of other benchmark methods, on the experiment data tasks (especially non-healthcare MNIST data) is another question not explained.  \n2. Model comparison in Table 1 would be better to also be illustrated in graph and plots for easy visualization.\n3. Concepts learned from images seem not human-interpretable if looking at the example in Figure 3. The two concepts might still look like visual patterns that could be only differentiable by machines or algorithms. It will be hard in practice to create human-understandable checklist out of the concepts illustrated, especially in clinical domain. \n4. Concepts learned from other data modality is not illustrated in the main paper, especially time series and text, which weakens the claim of interpretation utility of the proposed algorithm in different modality.\n5. Several typos in the paper, e.g. (683, 2021) on page 6, not sure whether it's citation or time series specification; and also \"We create a We briefly\" in line #2 on page 7. The paper needs some proofreading."
                },
                "questions": {
                    "value": "1. Same in weakness. If the checklist concept learned from the data is not easy for human to understand and annotate, what's the potential utility of the proposed method?\n2. How does the proposed method compared to other benchmark method without using checklist? a.k.a. Why using checklist to identify MNIST or predict sepsis or mortality? Is the performance better than other methods in the literature?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9267/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698794126465,
            "cdate": 1698794126465,
            "tmdate": 1699637167426,
            "mdate": 1699637167426,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kRDsBsnMG5",
                "forum": "030cjlZm4a",
                "replyto": "NpCjpCtarH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9267/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9267/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their valuable comments and insights.\n\n``` 1) Model comparison in Table 1 would be better to also be illustrated in graph and plots for easy visualization. ```\n\nWe thank the reviewer for this suggestion. We have added this plot to Section I of the appendix to help the readers.\n\n``` 2) Concepts learned from other data modality are not illustrated in the main paper, especially time series and text, which weakens the claim of interpretation utility of the proposed algorithm in different modality.```\n\nWe direct the reviewer to Figure 1 of the paper, which illustrates the checklist learnt from the medical abstract classification task. As previously explained in the global response, understanding results for NLP tasks is significantly simpler due to the comprehensibility of tokens. We have now included a description of the technique used for generating this checklist in the main paper. While experiments involving the TANGOS regularizer on time series datasets have been conducted, we have presented them in the supplementary section. This decision was made as these results require assessment by domain experts to discern patterns effectively.  Instead, our focus has shifted to the synthetic MNIST dataset, as its known ground truth concepts make it easier to validate our approach. We also discuss the results of the PhysioNet Tabular dataset.\n\n``` 3) Same in weakness. If the checklist concept learned from the data is not easy for human to understand and annotate, what's the potential utility of the proposed method? ```\n\nWe direct the reviewer to our discussion on interpretability of concepts and utility of the method in the global response.\n\n``` 4) How does the proposed method compared to other benchmark method without using checklist? a.k.a. Why using checklist to identify MNIST or predict sepsis or mortality? Is the performance better than other methods in the literature?```\n\nWe have included the following baselines in Table 1:\n- **ML (non-checklist) baselines:** LSTM/CNN/BERT + MLP (for 10 selected features and all features in the dataset), LSTM/CNN/BERT + LR. \n- **Checklist baselines:** Unit weighting, ILP mean thresholds, MIP Checklist.\n\nThe CNN/LSTM + MLP for MIMIC which is trained on all the features in the dataset acts as an upper baseline to quantify the performance loss incurred by switching to an interpretable checklist classifier.\n\nThrough these experiments, we aim to showcase that ProbChecklist surpasses existing checklist methods and achieves comparable performance to MLP (non-interpretable) methods. It\u2019s important to note that a checklist, due to its binary weights, has a strictly lower capacity and is less expressive than deep learning but possesses a more practical and interpretable structure. Despite this, it exhibits similar performance to an MLP.\n\n```5) One weakness is the results discussion using MNIST data only, which is not so intuitive in the checklist concept motivated by healthcare examples in the introduction part. And the paper has results from clinical data of PhysioNet and MIMIC III in the supplementary materials, which should be much better than the MNIST story. The necessity of using checklist, instead of other benchmark methods, on the experiment data tasks (especially non-healthcare MNIST data) is another question not explained.```\n\nWe direct the reviewer to the global response 1 and answers to questions 1 and 4 above. \n\n``` 6) Several typos in the paper, e.g. (683, 2021) on page 6, not sure whether it's citation or time series specification; and also \"We create a We briefly\" in line #2 on page 7. ```\n\nThe paper needs some proofreading. We thank the reviewer for spotting the typing mistakes. We have proofread the paper carefully and resolved these issues."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700475814319,
                "cdate": 1700475814319,
                "tmdate": 1700735217999,
                "mdate": 1700735217999,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XwvhcTJeFd",
                "forum": "030cjlZm4a",
                "replyto": "NpCjpCtarH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9267/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9267/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We are available to answer any further comments."
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you again for reviewing our paper and for your encouraging feedback!\n\nHave all the concerns you raised been adequately addressed? We are glad to provide you with complementary responses.\n\nThank you very much.\n\nBest Regards,\nThe authors"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700679754269,
                "cdate": 1700679754269,
                "tmdate": 1700679754269,
                "mdate": 1700679754269,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZHqzASP0nX",
            "forum": "030cjlZm4a",
            "replyto": "030cjlZm4a",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9267/Reviewer_eMqU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9267/Reviewer_eMqU"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a method for learning checklist models for diverse data modalities, such as images, time series, and text. Checklists are a type of interpretable models that are widely used in clinical settings. A checklist model consists of a set of concepts, each of which is assigned an integer weight (always +1 in this paper). The prediction is made by summing the weights of the concepts that are present in the input and comparing the sum to a threshold $T$. Existing methods for learning checklist models are limited to tabular data. To learn checklists from these raw data modalities, the authors propose to train neural networks using a probabilistic logic programming (PLP) framework. Basically, the neural network maps the input signals to a fixed number of logits, each of which is regarded as the log probability of the presence of a concept. One can then use the logits to compute the likelihood of the positive/negative label based on the definition of the checklist model. The likelihood of the positive label is the probability of the event that at least $T$ concepts are present in the input. The model is then trained with the cross-entropy loss. The authors also propose to add several regularization terms to encourage interpretability and fairness. In the experiments, the proposed model is compared to integer programming and deep learning baselines."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Originality: This work extends checklist learning to data modalities other than tabular data and combines the power of deep learning with the interpretability of checklist models. The proposed method is interesting.\n- Clarity & Quality: The background and methodology are clearly presented. The paper is easy to follow.\n- Significance: The proposed method seems to be a practical solution to the problem of learning checklist models from raw data modalities. Such models, if learned successfully, may be used in many real-world applications, such as clinical decision support."
                },
                "weaknesses": {
                    "value": "- There are too many hyperparameters in the proposed method, including the weight of the regularization terms, the number of concepts, and the threshold $T$, in addition to the architecture details of the neural networks. The authors should provide some guidance on how to choose these hyperparameters.\n- The learned \"concept\"s are hard to interpret from my point of view. The authors suggest that the concepts can be sensed by using post hoc attribution methods. However, it is well-known that the attribution methods are not perfect and may not be reliable.\n- Missing related work: I believe this work should be connected to the literature on concept-based explanation and learning, such as [1], [2], and the references therein. The authors should discuss the connections and differences.\n- The computational cost of the proposed loss function scales exponentially with the number of concepts.\n- Typos: \"LSTMS\" -> \"LSTMs\", \"TANGOS\" -> \"TANGOs\"\n\n[1] Amirata Ghorbani, et al. Towards Automatic Concept-based Explanations. NeurIPS 2019\n[2] Pang Wei Koh, et al. Concept Bottleneck Models. ICML 2020"
                },
                "questions": {
                    "value": "- Is it possible to extend the proposed method to learn checklist models with integer weights that are not necessarily +1? This may be useful in many applications."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9267/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9267/Reviewer_eMqU",
                        "ICLR.cc/2024/Conference/Submission9267/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9267/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698839690002,
            "cdate": 1698839690002,
            "tmdate": 1700668054185,
            "mdate": 1700668054185,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CsUTv7ngW6",
                "forum": "030cjlZm4a",
                "replyto": "ZHqzASP0nX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9267/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9267/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their valuable comments and insights.\n\n```1) There are too many hyperparameters in the proposed method, including the weight of the regularization terms, the number of concepts, and the threshold, in addition to the architecture details of the neural networks. The authors should provide some guidance on how to choose these hyperparameters. ```\n\nWe thank the reviewer for this suggestion. We had included a section on hyperparameter tuning in the appendix (Section C). We have now added a reference to it in the main paper for the interested readers. \n\nThe ProbChecklist framework allows experts to design user-centric checklists. Hyperparameters $d_k, \\ T and \\ M$ represent the structure/compactness of the checklist but alone aren\u2019t sufficient to garner information about the checklist\u2019s performance. Different $d_k$ are tried for each modality in an increasing fashion to find the one that performs best. Sensitivity analysis to study the relation between $d_k$ and performance (Figure 3a) suggests that the performance saturates after a certain point. This point can be determined experimentally for different modalities. M, total concepts in the checklist, is obtained by pruning concepts that are true for insignificant samples. Our experiments showed that pruning was not required since all the concepts were true for a significant fraction of samples. This indicates the superior quality of the concepts. \n\nWe try different values of T in the range [M/4, M/2] (total items M) to find the most performant model. However, this hyperparameter tuning doesn\u2019t contribute to the computational cost. For $d_k$, we only only 2-3 values, and use the same value for all the features. Domain experts will be more equipped to choose these values based on their knowledge of the features. For example, if we are recording a time series feature known to stay stable (not fluctuate much), then low $d_k$ is sufficient. The value of $d_k$ also depends on the number of observations (most blood tests aren\u2019t performed hourly, but heart rate and oxygen saturation are monitored continuously).\n\n```2) The learned \"concept\"s are hard to interpret from my point of view. The authors suggest that the concepts can be sensed by using post hoc attribution methods. However, it is well-known that the attribution methods are not perfect and may not be reliable. ```\n\nWe direct the reviewer to our discussion on interpretability of concepts in the global response.\n\n``` 3) Missing related work: I believe this work should be connected to the literature on concept-based explanation and learning, such as [1], [2], and the references therein. The authors should discuss the connections and differences. [1] Amirata Ghorbani, et al. Towards Automatic Concept-based Explanations. NeurIPS 2019 [2] Pang Wei Koh, et al. Concept Bottleneck Models. ICML 2020  ```\n\nWe thank the reviewer for recommending these papers. Concept Bottleneck Model (CBM) is an approach to make deep learning architectures more interpretable by adding a concept layer before the last fully connected layer. Each neuron in this layer represents a human understandable concept. One major limitation of this technique is that annotated data for predefined concepts is required which is expensive to collect. We have included these papers in our related works section. \n\n``` 4) The computational cost of the proposed loss function scales exponentially with the number of concepts.```\n\nWe offer a comparison of training times with the MIP checklist method on the PhysioNet Tabular dataset to evaluate the extent of this limitation (Section B of the appendix). It's crucial to highlight that while MIP Checklist performs effectively with tabular data, successfully uncovering the optimal solution, its performance is poor when applied to MNIST synthetic setup. Even when we set the runtime for Gurobi solver as 1 hour, it struggles to achieve optimal solutions for many cases. On the other hand, ProbChecklist stands out as more reliable, capable of performing end-to-end training and successfully learning the optimal solution."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700474127658,
                "cdate": 1700474127658,
                "tmdate": 1700474127658,
                "mdate": 1700474127658,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "OpByayJO6e",
                "forum": "030cjlZm4a",
                "replyto": "ZHqzASP0nX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9267/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9267/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors (2/2)"
                    },
                    "comment": {
                        "value": "``` 5) Is it possible to extend the proposed method to learn checklist models with integer weights that are not necessarily +1? This may be useful in many applications. ```\n\nWe warmly thank the reviewer for this very valuable suggestion. Before we formulate a method to achieve this, it is important to note that this would make it harder to interpret the checklist. More specifically, the meaning of the checklist threshold used for classification of samples would now change. Previously, it represented the minimum number of true concepts for a positive classification. Now it signifies a score - the minimum value of the weighted sum of concept probabilities for a positive classification.\n\nWe propose the following extension to allow for integer weights larger than 1. Given K data modalities as the input for sample i, we train K concept learners to obtain the vector of probabilistic concepts  of each modality $\\mathbf{p_i^k} \\in [0,1]^{d'}$. Next, we concatenate the full concepts probabilities ($\\mathbf{p_i}$) for sample i. At this point, we can introduce a trainable weight vector $W \\in [0,1]^{d'}$ (with $\\sum_{i=1}^{d\u2019}w_i = 1$) of the same dimension as $p_i$ (concept probabilities) which will capture the relative importance of the features. Element-wise product ($\\circledcirc$) of $p_i$ and W represents the weighted concept probabilities and can be denoted with $Wp_i$. This vector can be normalized by dividing each element with the maximum entry (L0 norm). While training it i For training the concept learners, we pass $Wp_i$ through the probabilistic logic module. After training, the integer weights corresponding to each concept in the checklist can be obtained by converting the W to a percentage: $W_{int}$. At inference time, we discretize $\\mathbf{C_i}$ to construct a complete predictive checklist. Next, compute the score $W_{int}^T C_i$ and compare it against the checklist threshold, $M$, to classify the sample.\n\nWe appreciate the reviewer's suggestion and concur that this extension of our method could be valuable for users. As a result, we have incorporated a figure and a concise description of the approach in the appendix (Section H).\n\n\n``` 6) Typos```\n\nWe thank the reviewer for spotting the typing mistakes. We have proofread the paper carefully and resolved them."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700474331396,
                "cdate": 1700474331396,
                "tmdate": 1700474656002,
                "mdate": 1700474656002,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "AZP6NDzbdb",
                "forum": "030cjlZm4a",
                "replyto": "OpByayJO6e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9267/Reviewer_eMqU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9267/Reviewer_eMqU"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your detailed response. I will update my rating to borderline accept. Please recheck the notation consistency in the revised submission. For example, I think the $d_k$ in Figure 3a should be $d'_k$ in Section 4.3. Proofreading is needed."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700668024699,
                "cdate": 1700668024699,
                "tmdate": 1700668024699,
                "mdate": 1700668024699,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]