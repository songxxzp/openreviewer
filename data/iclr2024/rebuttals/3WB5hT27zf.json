[
    {
        "title": "Partial Optimal Transport for Open-set Semi-supervised Learning"
    },
    {
        "review": {
            "id": "QyZ4bJTnaN",
            "forum": "3WB5hT27zf",
            "replyto": "3WB5hT27zf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1549/Reviewer_uAiP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1549/Reviewer_uAiP"
            ],
            "content": {
                "summary": {
                    "value": "The paper considers an open-set semi-supervised learning where there potentially are \u201coutliers\u201d in the unlabeled data distribution. The paper provides a novel loss function inspired by Partial optimal transport to handle OOD detection and demonstrates the effectiveness and robustness of the proposed method on multiple datasets."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1. Strong empirical performance\n2. Various ablations suggest that the method is robust and has a lower computation time and other baselines.\n3. A connection to optimal transport is intuitive"
                },
                "weaknesses": {
                    "value": "1. Lack of clarity in writing.  I found it hard to understand what is the main idea of the paper up until page 6. The author mentions in the abstract/ introduction that a mass score function (MSF) to measure the likelihood of unlabeled samples being outliers, yet I did not mention how this is related to OT/POT and it\u2019s not clear to me how OT is beneficial to the OSSL task. The following sentence is helpful for me to understand the idea,  \u201cwe can utilize the transport mass as a reliable OOD score, where a sample with a smaller value of mass score function tends to be an OOD sample\u201d. However, it is mentioned on page 6. It would be nice if one could provide something like this earlier in the paper and provide a clear problem setting early on.\n\n\n2. Many definitions and acronyms are used before being defined (see questions)\n\n3. The definition of distribution in equation 8) is not mathematically valid? By adding a factor of k, the sum of the probability mass is greater than 1 and therefore is not a valid probability distribution.\n\nI am willing to increase the score if these issues are addressed."
                },
                "questions": {
                    "value": "1. OSR is not defined, MSR is mentioned before it is defined in section 2.2.\n2. Section 4.1, the distribution L and U are not defined.\n3. Section 4.1, \u201cthe features of these d-dimensional samples\u201d, do you mean the features or samples that has d-dimensional ?\n4. Notation in equation 7) is not clear. Does this means T1_{\\mathcal{L}} \\leq \\mathcal{L} point-wise less than or equal to ?\n5. In algoirthm3, L_x and L_u is not defined in the main text ?\n6. What is the number 50, 100, 500 for in Table 5 ?\n7. \u201cmagnituWde\u201d -> \u201cmagnitude\u201d ?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1549/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1549/Reviewer_uAiP",
                        "ICLR.cc/2024/Conference/Submission1549/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1549/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698698984496,
            "cdate": 1698698984496,
            "tmdate": 1700610115285,
            "mdate": 1700610115285,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hTZVyajhZk",
                "forum": "3WB5hT27zf",
                "replyto": "QyZ4bJTnaN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1549/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1549/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer uAiP"
                    },
                    "comment": {
                        "value": "Thanks for your valuable comments, which help us improve the manuscript.\n\n__W1:The clarity of writing.__\n  \nWe will reinforce the connection between MSF and OT in the introduction and provide an explanation on how the MSF is computed. Additionally, in the introduction, we will add following descriptions about MSF to improve the presentation. \n\n\n\"MSF is calculated through the optimal transport plan of partial optimal transport, where the MSF for an unlabeled sample is determined by the sum of its mass transport to the labeled distribution. Samples with higher scores are more likely to be identified as ID samples.\"\n\n\n__W2: Many definitions and acronyms are used before being defined.__\n  \nQ1. The OSR means open-set recognition. We will revise the presentation in an updated manuscript. \n  \nQ2. The formal definitions of $\\mathcal{L}$ and $\\mathcal{U}$ are shown in Equation 8. We should have made it appear earlier in Sec 4.1. \n  \nQ3. Yes. We should say \"The feature of each sample is of d-dimensions\". \n  \nQ4. Yes. All inequalities in Eq.7 mean point-wise less than or equal to.\n  \nQ5. The definitions of L_x and L_u can be found in Section A.1. We will add corresponding descriptions in Algo3.\n  \nQ6. The number (50/100/400) denotes the number of labeled samples for each class. We will explain it in the head of Table 5.\n  \nQ7. Yes, it is a typo.\n\n__W3: The distribution in Eq.8 is not mathematically valid.__\n\nWe acknowledge that defining $\\mathcal{U}$ as a distribution is inappropriate; rather, it is the k-fold of a distribution. In our paper, focusing on modeling OOD detection in OSSL, this definition remains valid within our technical framework. In the revised version, the terminology will be modified to use \"K-fold unlabeled distribution\" instead of \"unlabeled distribution\" to describe $\\mathcal{U}$."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700036752453,
                "cdate": 1700036752453,
                "tmdate": 1700036752453,
                "mdate": 1700036752453,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "U3RK1o7NP1",
                "forum": "3WB5hT27zf",
                "replyto": "hTZVyajhZk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1549/Reviewer_uAiP"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1549/Reviewer_uAiP"
                ],
                "content": {
                    "comment": {
                        "value": "The author has addressed my concern and I will be increasing my score."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700610149118,
                "cdate": 1700610149118,
                "tmdate": 1700610149118,
                "mdate": 1700610149118,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "2J0WNilOsE",
            "forum": "3WB5hT27zf",
            "replyto": "3WB5hT27zf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1549/Reviewer_2Syu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1549/Reviewer_2Syu"
            ],
            "content": {
                "summary": {
                    "value": "The paper tackles the open-set semi-supervised learning (OSSL) challenge, specifically aiming to frame the treatment of out-of-distribution data (OOD) as a partial optimal transport (POT) problem. It introduces a mass score function (MSF) designed to evaluate the likelihood of a sample being an outlier during training. Additionally, the paper presents an OOD loss, allowing conventional semi-supervised learning methods to be adapted for OSSL scenarios via end-to-end training. The authors compare their proposed method against MTCF, T2T, and OpenMatch, on CIFAR10, CIFAR100, and Imagenet-30, showing superior performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* Semi-supervised learning is a significant area of research in machine learning, aiming to enhance performance by effectively utilizing both labeled and unlabeled data. \n\n* The OOD angle used in the paper makes it interesting to a broader audience.\n\n* Incorporating (partial) optimal transport as a framework is a novel and innovative aspect of this work."
                },
                "weaknesses": {
                    "value": "* Respectfully, the novelty of the method is limited and the paper overclaims novelty.\n   *  For instance, one main contribution of this paper is the introduction of the \"novel\" MSF score. The score function essentially corresponds to what is commonly referred to as \"barycentric projection,\" a concept well-documented in both classical and contemporary optimal transport (OT) theory literature (for reference, please see sources such as [Ambrosio et al.](https://link.springer.com/book/10.1007/b137080)). In this context, it is more appropriate to state that the paper utilizes classical concepts from OT theory to address new application challenges. The sentence \u201cwe devise a new score function\u201d is more or less misleading.\n\n* The parameter $k$, which deals with the amount of redundancy, plays a crucial role in the methodology presented in the paper. Varying the value of k leads to significant variations in the outcomes of ODD detection. It would enhance the paper's quality if it delves into the process of determining this value. Specifically, the paper could explore methods for assessing the amount of data that should be classified as outliers before initiating the algorithms. \n\n* Some implementation details and important ablation studies are missing from the paper. For instance, the utilized batch size and the effect of having a small batch size (which presumably reduces the performance of the proposed method) are missing from the paper. \n\n* The rationale behind the decision to use (10) instead of the original constraint (7), i.e., enforcing all mass from $\\mathcal{L}$ to be transported to a subset of $\\mathcal{U}$, is not well presented. Couldn't the unsupervised data be missing an entire class? In that case, the missing classes in $\\mathcal{L}$ must be destroyed, i.e., not transported, and the constraints in (7) would allow that. I believe this can easily happen in minibatch training. \n\n* Some of the very relevant references are missing from the paper: \n   * Rizve, M.N., Kardan, N. and Shah, M., 2022, October. Towards realistic semi-supervised learning. In European Conference on Computer Vision (pp. 437-455). Cham: Springer Nature Switzerland.\n   * Xu, R., Liu, P., Zhang, Y., Cai, F., Wang, J., Liang, S., Ying, H. and Yin, J., 2020. Joint Partial Optimal Transport for Open Set Domain Adaptation. In IJCAI (pp. 2540-2546).\n   * Yang, Yucheng, Xiang Gu, and Jian Sun. \"Prototypical Partial Optimal Transport for Universal Domain Adaptation.\" (2023)."
                },
                "questions": {
                    "value": "* For Algorithm 2, in the line of OOD score, shouldn't the formula be $Score_\\{\\mathcal{U}\\}=\\mathbf{T}^T\\mathbf{1}_n$?\n\n* The transportation cost is set to \"Cosine distance.\" The definition  \"d(x,y)=1-Cosine(x,y)\"  is only a true metric if $x,y\\in \\mathbb{S}^{d-1}$, i.e., $x$ and $y$ are unit vectors. Is your backbone returning unit vectors? Even if that is the case, and for the sake of mathematical rigor, I suggest adhering to the Euclidean distance, which is equivalent to the cosine distance when $x$ and $y$ are unit vectors and is still sensible when they are not!"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1549/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698777366796,
            "cdate": 1698777366796,
            "tmdate": 1699636083325,
            "mdate": 1699636083325,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kkFcPz0zCr",
                "forum": "3WB5hT27zf",
                "replyto": "2J0WNilOsE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1549/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1549/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 2Syu"
                    },
                    "comment": {
                        "value": "Thanks for your thoughtful and constructive feedback. \n\n__W1: The novelty of the method is limited and the paper overclaims novelty.__\n\nWe acknowledge that barycentric projection is a concept in the OT literature, and we recognize that the functionality of the proposed mass score function could be mathematically interpretated through barycentric projection.\n\nHaving clarified this, we would like to emphasize that we did not claim the ownership of the concept. Our primary contribution lies in modeling the OOD detection problem under the OSSL setting as a POT problem, and in training it within the SSL setting in an end-to-end manner. The Mass Score Function (MSF) is just one facet of the contributions of this paper, aiding in assessing the likelihood of a test input being an OOD sample. \n\nIn summary, our claim is that the proposal of the problem modeling and its associated techniques are novel in OOD detection under OSSL settings. We value your suggestions, and we agree that utilizing the concept of barycentric projection for explaining the proposed score function would enhance mathematical rigor, clarify intuitions, and improve presentation.\n \n__W2: The issue regarding the parameter k.__\n\nIn the ablation study, we have reported the result of the performance on different k. \nOur findings reveal the robustness of the hyperparameter k in our algorithm. Consequently, we maintain a consistent setting of k=2 across all experiments in Table 1 to Table 3, consistently achieving excellent results despite varying proportions of ID samples. To further assess the robustness of parameter k, additional experiments were conducted with k set to 5 and k set to 10.\n\n|k|1.5|2.0|2.5|5.0|10.0|\n|-|-|-|-|-|-|\n| Acc|92.3|92.3|90.1|92.1|92.0|\n| AUROC|98.8|99.6|99.0|97.8|97.7|\n\nThe results demonstrate that the value of k has good robustness  over a wider range.\n\n__W3: Implementation details Ablation study on batch size.__\n\nIn the revised version, we will include a description of the experiment settings.\n\nOur experimental setup is shown below\uff1a\n\nThe batch-size B = 64.\n  \nThe relative size of batch-size for unlabeled data \u00b5 = 2 in all experiments for fair comparison. \n  \nIterations per epoch are 1024 and the total number of epochs is 512.\n  \nOptimizer: SGD with nesterov momentum = 0.9.\n  \nLearning rate \u03b7 = 0.03 and use cosine annealing learning rate schedules.\n\nThe batch size we use is 64 and the relative size of batch size for unlabeled data \u00b5 is 2, which is a relatively small batch size in semi-supervised learning.\n\nWe compare our method with other SSL and OSSL methods on smaller batch size on CIFAR100 dataset.\n\n|Batch size|64||32||16||\n|-|-|-|-|-|-|-|\n||Acc|AUROC| Acc|AUROC|ACC|AUROC|\n|FixMatch|__78.2__|57.3|75.7|58.2|71.8|64.0|\n|OpenMatch|72.3|87.0|69.8|85.0| 66.2 |__84.7__|\n|POT|77.6|__87.5__|__77.0__|__86.5__ |__73.4__|78.0|\n\nFor a detailed analysis of the experimental results, please refer to W4.\n\n__W4: Label missing problem in minibatch training.__\n\nThe situation you've highlighted is indeed a reality. In small batch sizes, $\\mathcal{L}$ and $\\mathcal{U}$ may not sufficiently cover all classes, posing challenges for OOD detection. However, semi-supervised learning has undergone several iterations, and the occasional subpar detection performance in certain mini-batches has minimal impact on the overall performance.\n\nNotably, with a batch size of 32, our method shows a slight decline in OOD detection performance but outperforms FixMatch in close-set accuracy. Conversely, with a batch size of 16, there is a noticeable drop in OOD detection, yet our method resiliently maintains commendable close-set accuracy.\n\n__W5\uff1aRelevant references are missing.__\n\nIn Related Work section, we will incorporate a discussion on relevant papers.\n\nReferences [2-3] address Open Set Domain Adaptation problems using POT. Reference [2] uses the mean cost of transport to control the proportion of POT. Reference [3] providing an approximate estimation of the transport ratio in POT. Compared to existing POT-based methods [2-3], our method stands out by not necessitating prior knowledge about the ratio of POT. Reference [1] proposed a novel pseudo-label based approach to tackle SSL in an open-world setting. TRSSL aims to assign labels for outliers at test time, which is a different semi-supervised setting.\n\n__Q1: The formula of score function.__\n\nThanks for pointing it out. We agree it should be $\\textbf{T}^\\top \\mathbf{1}_{n}$. We will address them in the revised version.\n\n__Q2: The use of cosine distance.__\n\nIn our experiment, we normalize the vector before calculating the cosine distance. However, our method is also applicable when the OT cost is represented by the Euclidean distance. We conducted experiments on CIFAR10 using Euclidean distances, with 50 labeled samples for each class.\n\n||Euclidean|Cosine|\n|-|-|-|\n|Acc|92.5|92.3|\n|AUROC|99.6|99.6|\n\nThe results indicate that our proposed method is a universal approach, effective across different metrics."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700052804502,
                "cdate": 1700052804502,
                "tmdate": 1700052804502,
                "mdate": 1700052804502,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aEtgRemm67",
                "forum": "3WB5hT27zf",
                "replyto": "2J0WNilOsE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1549/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1549/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A gentle reminder for the closing rebuttal window"
                    },
                    "comment": {
                        "value": "We would like to express our sincere appreciation for your valuable comments on our manuscript. We have carefully considered each of your suggestions and provided detailed responses. As the deadline for the rebuttal is approaching, we want to ensure if our responses adequately address your concerns. We are open to any further discussion. \n\nThank you again for your time and consideration."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700656005085,
                "cdate": 1700656005085,
                "tmdate": 1700656005085,
                "mdate": 1700656005085,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "alMliCTXK5",
                "forum": "3WB5hT27zf",
                "replyto": "aEtgRemm67",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1549/Reviewer_2Syu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1549/Reviewer_2Syu"
                ],
                "content": {
                    "title": {
                        "value": "Acknowledging Authors' Rebuttal"
                    },
                    "comment": {
                        "value": "I thank the authors for their rebuttal and for addressing my comments. Respectfully, I find the response to W4 to be insufficient, since it lacks a logical explanation for transitioning from a broader formulation Eq. (7) addressing the issue to a more restricted or narrower approach, Eq. (10), which suffers from the raised issue. Conducting an ablation study on this aspect would have been beneficial. Additionally, if the performance of the method is better using approach (10) compared to (7), then providing intuition on why this is the case could help the reader. Lastly, while the provided experiment on the parameter $k$ is absolutely needed, it still partially shows the effect of this parameter, as presumably for larger or smaller batch sizes different parameters should be used. \n\nOverall, I think the paper has merit, but many design choices still seem ad-hoc without a strong rationale behind them. Hence, I adhere to my original evaluation of the paper."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700702150823,
                "cdate": 1700702150823,
                "tmdate": 1700702150823,
                "mdate": 1700702150823,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "PR4Db9ZtDW",
            "forum": "3WB5hT27zf",
            "replyto": "3WB5hT27zf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1549/Reviewer_RKEQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1549/Reviewer_RKEQ"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on studying the problem of Open-Set Semi-Supervised Learning (OSSL). The authors present a novel framework that transforms the OSSL problem into the Partial Optimal Transport (POT) problem. The authors aim to leverage the benefits of POT to detect the OOD samples. Empirically, POT achieves competitive performance on various benchmarks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "-\tThis paper is straightforward and well-written. It is quite easy to follow.\n-\tThe paper solves Open-Set Semi-Supervised Learning (OSSL), an important ML problem in practice.\n-\tEmpirical results demonstrate that POT can achieve SOTA results on several benchmarks."
                },
                "weaknesses": {
                    "value": "-\tBased on the description provided, it is possible that the article's approach could be categorized as an auxiliary OOD classifier approach, similar to methods such as MTCF, T2T, and OpenMatch. What is the difference between the proposed method and them? A more detailed discussion may be required.\n-\tThe author's explanation for why POT is more effective at detecting OOD is not adequately provided.\n-\tIn similar settings, Partial Optimal Transport (POT) has also found applications, such as in Open-set Domain Adaptation and Positive-Unlabeled Learning. The authors should consider discussing the connections and distinctions between their work [1-3] and the research presented in these articles. And what are the strengths of POT for Open-Set Semi-Supervised Learning? Are there some special designs for Open-Set Semi-Supervised Learning compared with other tasks, such as PU leanring, Open Set Domain Adaptation?\n-\tThe authors should offer an explanation for why Fixmatch algorithm yields better results compared to certain Open-Set Semi-Supervised Learning (OSSL) methods.\n-\tThere lack of many experiment details in the paper, such as the specific parameter settings for Fixmatch and the implementation specifics of the T2T algorithm.\n-\tTable 3 lacks some of the comparative algorithms present in Table 1.\n-\tThere is an inconsistency in the notation of the k in Algorithm 3.\n-\tOn page 8 in the experimental section, $L_{ood}$ --> $\\lambda_{ood}$\n-  What is \"graph\" in the last of Subsection 2.2?\n\n[1] Partial Optimal Transport with Applications on Positive-Unlabeled Learning, NeurIPS 2020.\n\n[2] Joint Partial Optimal Transport for Open Set Domain Adaptation, IJCAI 2020.\n\n[3] Prototypical Partial Optimal Transport for Universal Domain Adaptation, AAAI 2023."
                },
                "questions": {
                    "value": "Please see the weakness for details."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1549/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698813130006,
            "cdate": 1698813130006,
            "tmdate": 1699636083256,
            "mdate": 1699636083256,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "j9mbxilAjb",
                "forum": "3WB5hT27zf",
                "replyto": "PR4Db9ZtDW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1549/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1549/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer RKEQ"
                    },
                    "comment": {
                        "value": "Thanks for your insightful comments, which help us improve the manuscript.\n\n__W1:Difference with other OSSL methods.__\n\nOur approach focuses on directly utilizing the distribution information. Specifically, we use POT between labeled and unlabeled samples to train a binary OOD classifier, and we treat OSSL as a multi-task learning problem.\n\nIn contrast, T2T and OpenMatch build their OOD classifiers using b (where b is the number of classes) one-vs-all classifiers, relying on labeled data and incorporating unlabeled data to improve the classifier performance. However, these methods exhibit a noticeable performance decline, especially when dealing with a large number of classification categories.\n\nSimilar to our methodology, MTCF employs a binary OOD classifier but utilizes a curriculum learning framework for model training. MTCF applies Otsu thresholding to select unlabeled samples, potentially leading to error accumulation that may impact the overall model performance.\n\nWe will add corresponding discussions to the manuscript in a revised version.\n\n__W2: Why POT is more effective at detecting OOD is not adequately provided.__\n\nIn the third paragraph of Sec 4.3, we explored the effectiveness of POT. To complement our methodology, we incorporate the following details into the Methods section. \n\nIn the OSSL context, we propose that ID samples in the unlabeled dataset and labeled samples are drawn from a latent ID distribution, while OOD samples in the unlabeled dataset are drawn from a latent OOD distribution. In this setting, the optimal transport cost tends to be low between ID samples in unlabeled dataset and labeled samples.\n\nThe cost of transporting unit mass between ID samples (including labeled samples and ID samples in unlabeled dataset) is small. In POT, only a fraction of the mass in the unlabeled distribution can be transported.  To minimize the overall transport cost, ID samples in unlabeled dataset obtain larger transport mass. This characteristic aids in identifying OOD samples based on the transport mass of each individual sample.\n\n__W3: Discussion about relevant references.__\n\nReference [1] proposes a partial optimal transport method for positive-unlabeled learning. The proportion of positive samples $\\pi$ in the unlabeled set is necessary, which is often unavailable in real open-set scenario. \nReferences [2-3] address Open Set Domain Adaptation problems using partial optimal transport. Reference [2] uses mean cost of transport to control the proportion of partial optimal transport, which is not robust in real world. Reference [3] providing an approximate estimation of the transport ratio in partial optimal transport.\n\n__Strengths of POT for OSSL__: As outlined in W1, our method presents a simpler and more effective approach to detect outliers in OSSL using POT.\n\n__Special designs for OSSL__: Existing POT-based methods [1-3], rely on the estimation of the transport ratio. However, in the context of OSSL, it is impractical to estimate the transport ratio for each mini-batch. To address this challenge, we introduce redundant mass for partial optimal transport as a robust parameter. This approach ensures that there is no need to estimate the transport ratio in every iteration, enhancing the stability and efficiency of OOD detection.\n\n__W4: Why Fixmatch algorithm yields better results.__\n\nIn the OSSL scenario, while FixMatch may not generate accurate pseudo-labels for OOD unlabeled samples, it nonetheless retains the capability to generate high-quality pseudo-labels for ID unlabeled samples. Consequently, the close-set accuracy remains minimally affected by the presence of OOD samples.\n  \n__W5: Lack of many experiment details.__\n\nIn the revised version, we will include a description of the experiment settings.\n\nFollowing the same parameter settings of original paper, we reproduce our baselines using their official codes. For a fair comparison, we unified the parameters of semi-supervised learning as follows.\n\nEach experiment is done with a single NVIDIA A100 GPU.\n\nThe batch-size B = 64.\n\nThe relative size of batch-size for unlabeled data \u00b5 = 2 in all experiments for fair comparison. \n\nIterations per epoch are 1024 and the total number of epochs is 512.\n\nOptimizer: SGD with nesterov momentum = 0.9.\n\nLearning rate \u03b7 = 0.03 and use cosine annealing learning rate schedules.\n\n__W6: Baseline on Imagenet30.__\n\nWe supplemented additional experiments and obtained the following results.\n\n| |     $\\  \\  \\  \\  $SSL   ||    |   OSSL   |    |\n|:-----:|:--------:|:----:|:----:|:---------:|:----:|\n|       | FixMatch | MTCF |  T2T | OpenMatch |  POT |\n|  Acc  |    91.7   | 86.4 | 88.8 |    89.6   | __90.3__ |\n| AUROC |    45.1   | 93.8 | 55.7 |    96.4   | __97.4__ |\n\nCompared to OSSL methods, POT achieves the SOTA performance on the Imagenet30 dataset in terms of inlier accuracy and AUROC.\n\n__W7-W9: Issues in the paper.__\n\nThank you very much for pointing out the issues. We will address them in the revised version."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700048521857,
                "cdate": 1700048521857,
                "tmdate": 1700048521857,
                "mdate": 1700048521857,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MahyugLV1Z",
                "forum": "3WB5hT27zf",
                "replyto": "j9mbxilAjb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1549/Reviewer_RKEQ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1549/Reviewer_RKEQ"
                ],
                "content": {
                    "title": {
                        "value": "Read the comments"
                    },
                    "comment": {
                        "value": "The authors partly answer my questions. I'll keep my rating."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700205210828,
                "cdate": 1700205210828,
                "tmdate": 1700205210828,
                "mdate": 1700205210828,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]