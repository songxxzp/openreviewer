[
    {
        "title": "Lewis's Signaling Game as beta-VAE For Natural Word Lengths and Segments"
    },
    {
        "review": {
            "id": "Wu1rcCkTX5",
            "forum": "HC0msxE3sf",
            "replyto": "HC0msxE3sf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1551/Reviewer_TgUR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1551/Reviewer_TgUR"
            ],
            "content": {
                "summary": {
                    "value": "The authors discuss connections between classic emergent communication in Lewis signalling games and Beta-VAEs.\n\nIn some traditional EC works, a speaker and listener must coordinate such that the listener can reconstruction a speaker's \"target\" observation, given communication. In many ways, this mirrors classic reconstruction training. Prior works have often found that the resulting communication from such training is often \"unhumanlike\" in several ways, including ZLA and HAS metrics. This work argues that such undesireable properties are likely a result of implicit priors that most EC works encode. \n\nBy connecting EC to Beta-VAE methods, the authors uncover theoretical interpretations of different terms in EC and open up the important directions for experiments (such as varying prior distributions or Beta).\n\nIn experiments, the authors show that, by using a learnable prior in training agents, they appear to achieve greater separation of EC into \"word-like\" units."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "## Originality\nI'm am somewhat torn about the originality of this work. On the one hand, I think connection EC literature to other theoretically-rich approaches like beta-VAE is a very good idea. On the other hand, the authors note that some prior literature appears to have considered a generalization of this problem (\"Section 6: Tucker et al. defined a communication game... based on VIB, which is known as a generalization of beta-VAE.\"), which makes me think this work is not proposing novel ideas.\n\n## Quality\nOverall, the work seems quite careful and sound in discussing the mathematical underpinnings of many EC methods.\n\n## Clarity\nSome aspects of this paper were quite clear (in particular, the introduction and conclusion are very good), but I found other aspects harder to read. I suspect this is somewhat due to having a fair amount of notation is not immediately interpretable without remembering definitions from earlier pages (e.g., \"monkey typing model\" or n_bou).\n\n## Significance\nI think this work falls within an important (and significant) field of connecting EC to other training methods and objects. I remain somewhat confused about the relationship to prior art, however, so I am unsure of the significance of this individual work."
                },
                "weaknesses": {
                    "value": "Overall, I like aspects of this work, but there are a few important unresolved questions or weaknesses that I would want to see addressed before accepting, in particular about relations to prior art.\n\n## Relation to prior art\nThe authors do a good job noting related prior literature, but I remain somewhat confused by the position of this paper relative to such literature. In particular, the authors write that:\n\n> Moreover, Resnick et al. (2020) explicitly formulated the objective as ELBO, though it is not directly applicable to this paper...\n\n> Tucker et al. (2022) defined a communication game called VQ-VIB, based on Variational Information Bottleneck (VIB, Alemi et al., 2017) which is known as a generalization of beta-VAE. Also, Chaabouni et al. (2021) formalized a color naming game with a similar motivation.\n\nIf prior art has used the same formulation and considered a generalization of the problem this paper is considering, what are the contributions of this paper? Honestly, I suspect there are many unique contributions made in this paper, but the contrast relative to prior art should be made much more obvious. Even just adding a sentence at the end of each related works section saying, e.g., \"While Tucker et al., Alemi et al., and Chaabouni et al. consider similar frameworks to us, we introduce novel metrics and results\" or something to that effect would help a lot. Ideally, the authors would run experiments comparing to Resnick's method.\n\n## Presentation of results\nI found the results somewhat difficult to read. Figure 2 contains the main results, and with enough flipping between pages, I could eventually figure out how to interpret them, but generally I encourage authors to make figures more self-contained. For example, listing a baseline as BL1 is not as informative as using a name/label that actually describes characteristics of the baseline (e.g., conventional + entropy).\n\n## Why did segments become more meaningful.\n\nThe analysis in this section, while addressing a very important question, is slightly unsatisfying. First, parts of the writing are very casual (e.g., The receiver must be surprised several times...\"), whereas in reality the receiver just needs to receive, over multiple timesteps, enough bits to reconstruct the input. It is unclear what it means to \"be surprised\" as a binary term.\n\nSecond, I question the fundamental conclusion of this paragraph. The authors appear to suggest that the competing terms for entropy and reconstruction are what give rise to word boundaries. In other words, communication wants to often be predictable (because of the entropy term), which creates word-like clumps. However, as the authors note, the speaker needs to communicate some information in at least some timesteps to convey the meaning to the listener. Is there any mathematical basis, given the training terms used, for why that information should be concentrated in just a few timesteps (which would match word-like clumps) as opposed to evenly distributed across time? For example, in a simple four-timestep case conveying 4 bits, is there any advantage (as measured by decreased loss) to transmitting [2 bits, 0 bits, 2 bits, 0 bits] vs. [1 bit, 1 bit, 1 bit, 1 bit]?\n\n## Minor:\nAppendix D would greatly benefit from a little bit more text explaining what the graphs present. There are also some sentences that need editing (e.g., \"threshold is set to 0.25.\")"
                },
                "questions": {
                    "value": "1. In the Weaknesses section, I raised questions about why an entropy term would actually increase word segmentation. To repeat it here: is there any mathematical reason that the losses used during training should concentrate surprisal in just a few timesteps (which would induce word-like clumps) instead of spreading the surprisal loss more evenly across time?\n\n2. I struggled to understand Figure 5. What is it depicting? What do the legend entries/different lines correspond to?\n\n3. Just a clarifying question about the results for Criterion C3: the authors' proposed method is worse than baselines, correct? I recognize that topsim values for the proposed method improved generally, but for the narrow metric of the difference between topsim values, there is a decrease, right?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1551/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698420061826,
            "cdate": 1698420061826,
            "tmdate": 1699636083659,
            "mdate": 1699636083659,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "96ozEHk0Nj",
                "forum": "HC0msxE3sf",
                "replyto": "Wu1rcCkTX5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1551/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1551/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer TgUR (Comment 1-2)"
                    },
                    "comment": {
                        "value": "Thank you very much for your detailed and thoughtful reviews.\nWe have extensively revised our paper in light of the feedback received.\nThese revisions aim to clarify the paper's positioning and enhance the readability of our experimental results.\n\n## Reviewer's Comment 1\n> The authors do a good job noting related prior literature, but I remain somewhat confused by the position of this paper relative to such literature. ...\n\nThank you for point it out.\nWe added the positioning of our paper, compared to the related studies Resnick et al. (2020); Chaabouni et al. (2021); Tucker et al. (2022).\n\nPerhaps another problem was the beginning of Sec 3: `The main proposal of this paper is redefine the objective of signaling game as (beta-)VAE's`.\nWe modified the beginning of Sec 3 too.\n\nMoreover, we made the table to clarify our positioning, which is put to Appendix F in the revised version.\n\n## Revision for Comment 1\nAt Paragraph \"EC as Representation Learning\" in Sec 6 \"Related Work\", we added:\n> (***Revision***) Resnick et al. (2020) formulated the objective as ELBO. However, they defined messages as fixed-length binaries and agents as non-autoregressive models, which is not applicable to our variable-length setting. Moreover, they do not discuss the prior distribution choice; they seem to have adopted Bernoulli purely for computational convenience. In contrast, we indicated that their choice influences the structure of emergent languages.\n\nAt Pragraph \"VIB\" in Sec 6 \"Related Work\", we added:\n> (***Revision***) Note that messages are defined as single symbols in their settings. In contrast, messages are of variable length in our setting to discuss the structure of emergent languages such as ZLA and HAS.\n\nIn Sec 3, we modified the first few sentences:\n> (***Revision***) ~~The main proposal of this paper is to redefine the objective of signaling games as (beta-)VAE's, i.e., the evidence lower bound (ELBO) with an additional KL weighting hyperparameter $\\beta$.~~\n> In this section, we first redefine the objective of signaling games as (beta-)VAE's, i.e., the evidence lower bound (ELBO) with a KL weighting hyperparameter $\\beta$. Next, we show several reasons supporting our ELBO-based formulation.\n\nIn Appendix F, we added the table to clarify our positioning.\nThe table shows the characteristics of the studies in terms of:\n- whether their formulation is based on a generative perspective such VAE and VIB,\n- whether message length in their settings is variable,\n- whether they study the compositionality of emergent languages,\n- whether they investigate if emergent languages follow ZLA,\n- whether they investigate if emergent languages follow HAS, and\n- whether they are aware of the existence of prior distributions and carefully choose an appropriate one.\n\nEach related study stasfies some of them, while it does not satisfy the others.\nIn contrast, our paper satisfies all of them.\n\n## Reviewer's Comment 2\n> I found the results somewhat difficult to read. Figure 2 contains the main results, and with enough flipping between pages, I could eventually figure out how to interpret them, but generally I encourage authors to make figures moreself-contained. For example, listing a baseline as BL1 is not as informative as using a name/label that actually describescharacteristics of the baseline (e.g., conventional + entropy).\n> ...\n> ...\n> Appendix D would greatly benefit from a little bit more text explaining what the graphs present. There are also some sentences that need editing (e.g., \"threshold is set to 0.25.\")\n\nThank you for this feedback.\n\n## Revision for Comment 2\nTo make Figure 2; 3; 4 more readable and self-contained, we added more information to the legend and included the explanation on the evaluation metrics and the baseline methods in the captions.\nAs a result, the caption (in Figure 2) became as follows:\n> (***Revision***) Results for $n_{\\textrm{bou}}$ (C1), $n_{\\textrm{seg}}$ (C2), $\\Delta_{w,c}$ (C3), C-TopSim (C3), and W-TopSim (C3) are shown in order from the left. The x-axis represents $(n_{\\textrm{att}},n_{\\textrm{val}})$ while the y-axis represents the values of each metric. The shaded regions and error bars represent the standard error of mean. The threshold parameter is set to $0$. The blue plots represent the results for our ELBO-based objective $\\mathop{\\mathcal{J}}\\nolimits_{\\textrm{ours}}$, the orange ones for (BL1) the conventional objective $\\mathop{\\mathcal{J}}\\nolimits_{\\textrm{conv}}$ plus the entropy regularizer, and the grey ones for (BL2) the ELBO-based objective whose prior is $P_{\\alpha}^{\\textrm{prior}}$.\n> ...... (*For the rest part of the revised caption, see our response to Comment 6*)"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1551/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700189799978,
                "cdate": 1700189799978,
                "tmdate": 1700189799978,
                "mdate": 1700189799978,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "53FtXSkbja",
                "forum": "HC0msxE3sf",
                "replyto": "X8zfeqCNjL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1551/Reviewer_TgUR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1551/Reviewer_TgUR"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your extensive comments (here and elsewhere).\n\nI am glad that we seem to agree about comment 4 (that there is no fundamental reason for increasing HAS). Weakening the statements as you have proposed addresses this concern, but I feel like this fact weakens the strength of the paper overall. In other words, given that the authors appear to state that there is not theoretical reason that their reframing should increase HAS, such effects are unmotivated/purely empirical. That is fine but undercuts the main point of the paper as a theoretical re-framing of EC as Beta-VAE."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1551/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700662715340,
                "cdate": 1700662715340,
                "tmdate": 1700662715340,
                "mdate": 1700662715340,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "SwkBBeNfyL",
            "forum": "HC0msxE3sf",
            "replyto": "HC0msxE3sf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1551/Reviewer_E7HT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1551/Reviewer_E7HT"
            ],
            "content": {
                "summary": {
                    "value": "This paper reanalyzes an emergent communication-signalling game in terms of\na VAE.  Within this analysis, the optimization of a signalling game is using an\n\"implicit prior\" which leads to statistical properties of the emerging language\nwhich do not match human languages.  Introducing linguistically-inspired priors\ninto signalling game by way of the VAE framework improves the resulting\nemergent languages' statistical properties (i.e., adhering Zipf's Law of\nAbbreviation and Harris's Articulation Scheme more closely)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- (major) The paper aims at re-analyzing a common EC setting in a more\n  formalized way, yielding the potential for theoretical insights that would\n  not otherwise be possible.\n- (major) Furthermore, I think this analysis is largely in the correct\n  direction with analyzing the signalling game as a VAE, looking at inductive\n  biases, and tying in linguistic concepts like Zipf's Law of Abbreviation and\n  Harris's Articulation Scheme (although this wide scope is also a bit of\n  concern; cf. \"Weaknesses\").\n- (minor) The experiments partially satisfy HAS which is known to hold for\n  human languages."
                },
                "weaknesses": {
                    "value": "- (major) A critical part of the paper is the \"prior\" within a VAE or\n  signalling game, but I did not get a concrete sense of what this prior\n  actually is in the context of a signalling game with neural network-based\n  agents (I expand on this in \"Questions\").  As a result, it makes me unsure\n  how well the theoretical claims actually apply to a real setup.\n- (major) The paper, I think, tried to do too much, and ends up not spending\n  enough time on the core claims, namely, the signalling game can be\n  re-analyzed as a VAE.  I think the paper would benefit greatly from cutting\n  away all but the essential claims and going through those more slowly and\n  thoroughly.\n    - For example, this shows up in the experiments which seem more concerned\n      with evaluating the existence of ZLA/HAS in the newly proposed setting\n      rather than establishing empirically that the signalling game behaves\n      like a VAE.\n- (minor) The notation and the proofs are not very clear, and it made it\n  slow/difficult to work through the equations."
                },
                "questions": {
                    "value": "- What exactly is the \"prior\" in the emergent language game?  I understand that\n  it is implicit, but does that mean that is embedded in the objective function\n  (i.e., the $D_\\text{KL}$ term is constant)?  Or is it instead the case that\n  the sender's architectural biases represent the prior?\n- In addition to the theoretical analysis, what else can the authors point to\n  to support the claim that an EC signalling game is analogous to a VAE?\n\n\n### Other comments\n\n- If the authors are assuming a REINFORCE objective for the signalling game,\n  that should be mentioned earlier than Sec 4.1.\n- What is $A_t$ in Eq 3?\n- In Sec 2.2, I do not think the section compositionality is relevant or\n  important; it should removed, in that case.\n- Before Eq 5, what is $\\mathcal A^*$?  Is it supposed to be a Kleene star?\n- What exactly is the uniform prior?  Is it just a constant probability mass\n  over every possible sequence?  If so, how do we know that is the \"implicit\n  prior\" and not something like a uniform _unigram_ prior instead, for example.\n\n\n- Sec 3.1: It is not clear to me how (9) is derived from (2).  I looked at Section\n  B.1, but it was very unclear what was happening because rather than starting\n  with (2) and going to (9), it talks about \"transforming\" different sides of\n  the equation.\n  - It would also be helpful to give an indication of what from Schulman et al.\n    (2015) is being applied (i.e., the what the \"stochastic computation\n    approach\" is).\n  - As a result, I'm not convinced that the reconstruction game, absent\n    modifications to the traditional object (e.g., length penalty), assumes\n    a uniform prior of messages.\n  - It seems like the $P(m) = \\mathbb E_{x\\sim{}P_\\text{obj}}[S(m|x)]$ should be the\n    prior over messages.  I very well might be misunderstanding something here\n    due to terminology.  Am I conflating here that \"prior\" as the distribution\n    of messages the receiver produces given the distribution over inputs with\n    \"prior\" in the sense of our objective function which we are optimizing\n    against (in which case \"prior\" does not refer to anything concrete in the\n    EC environment but rather only to the optimization process by analogy to\n    a VAE's optimization)?\n- Sec 3.2: what is a \"heuristic variant of [a] VAE\"?\n- Sec 3.4:\n  - The very first paragraph of this section, I think, is glossing over\n    critical question in the paper: what is the connection between the \"prior\"\n    and the actual EC setup.  I understand that the EC setup is analogous to\n    a VAE, but what exactly is the analog of the VAE's prior?\n  - I think the use of \"approximately\" is dangerous when trying to make\n    theoretical claims; I understand that it is unavoidable in something as\n    messy as EC, but it still needs to be accompanied by some justification in\n    order to keep the theoretical claims strong.\n\n\n### Minor notes\n\n- \"they are not\" reproduced emergent lanuaguages   has awkward phrasing\n- Right after Eq. (1), it should be $\\log(|\\mathcal A| - 1)\\ge0$ in the case\n  that $|\\mathcal A| = 2$.\n- Sec 3.3:\n  - what is $\\mathcal M$ -- the set of all messages? \n  - What is $\\mathcal A$, again?\n  - Eq 15 limit notation here would be more appropriate"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1551/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1551/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1551/Reviewer_E7HT"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1551/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698505789101,
            "cdate": 1698505789101,
            "tmdate": 1700604944014,
            "mdate": 1700604944014,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "j9OmFJSrDd",
                "forum": "HC0msxE3sf",
                "replyto": "SwkBBeNfyL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1551/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1551/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer E7HT (Comment 1-4)"
                    },
                    "comment": {
                        "value": "Thank you for your thorough and insightful review.\nIn response to the comments provided, we have diligently revised our paper.\nYour constructive feedback has been instrumental in enhancing the readability and academic value of our work.\n\n## Reviewer's Comment 1\n> (major) A critical part of the paper is the \"prior\" within a VAE or signalling game, but I did not get a concrete sense of what this prior actually is in the context of a signalling game with neural network-based agents (I expand on this in \"Questions\"). As a result, it makes me unsure how well the theoretical claims actually apply to a real setup.\n\nWe greatly appreciate your feedback regarding the prior in the context of EC signalling game.\n(Please see our response to Comment 3; 9; 10; 11; 12)\n\n## Reviewer's Comment 2\n> (major) The paper, I think, tried to do too much, and ends up not spending enough time on the core claims, namely, the signalling game can be re-analyzed as a VAE. I think the paper would benefit greatly from cutting away all but the essential claims and going through those more slowly and thoroughly.\n\nWe value your suggestion to focus more on the core claims of our paper.\nIn the revised version, we have taken the reviewers' comments into consideration and made efforts to improve the quality of the paper.\nWe have removed unnecessary text and moved some parts to the appendix to focus more on the essential aspects.\nWe hope you will find the revised version more satisfactory.\n\nRoughly speaking, our core claims are made of two components, which are (somewhat philosophically) of mutual dependence.\n\nOur core claims are:\n1. The conventional EC signaling game is analogous to (beta-)VAE.\n2. By explicitly re-defining EC signaling game as (beta-)VAE, the structure of emergent languages improves.\n\nThanks to the 2nd claim,\n- the 1st claim becomes more than a mere theoretical result.\n\nThanks to the 1st claim,\n- the 2nd claim becomes more than an arbitrary \"hack\" of the evaluation criteria (The arbitrary hack might be a questionable practice as a simulation of language emergence, in a scientific sense).\n\nFor a more detailed decomposition of our claims, please refer to our response to Comment 4.\n\n## Reviewer's Comment 3\n> What exactly is the \"prior\" in the emergent language game? I understand that it is implicit, but does that mean that is embedded in the objective function (i.e., the term is constant)? Or is it instead the case that the sender's architectural biases represent the prior?\n\nWe appreciate your question regarding what exactly the prior is.\nThis is an important point to clarify our storytelling.\n\nIn terms of the conventional EC signaling game, yes, the prior is constant.\nSpecifically, it is a uniform distribution over a message space.\n\n(In contrast, we regard it as a language model)\n(See also our response to Comment 9; 10; 11; 12).\n\n## Reviewer's Comment 4\n> In addition to the theoretical analysis, what else can the authors point to to support the claim that an EC signalling game is analogous to a VAE?\n\nThank you for questioning that point.\nOur contribution is indeed more than the theoretical analysis of the game, including e.g.,\n- a new idea for EC setting (i.e., prior as a language model),\n- empirical results (for ZLA and HAS), and\n- relationship to the linguistic concept (i.e., surprisal theory).\n\nOur overall claims are as follows:\n\nFirst, as you mentioned,\n- ***As an interesting math problem***, EC signaling game is similar to (beta-)VAE (Sec 3.1; 3.2).\n\nImportantly,\n- By interpreting EC signaling game as (beta-)VAE, ***we can reveal the existence of implicit prior*** (Sec 3.1).\n\nFurthermore, by having revealed the existence of implicit prior,\n- We can appropriately re-define the prior distribution to have a ***good influence on the structure of emergent languages***, namely ZLA/HAS (Sec 3.3; 3.4; Sec 4).\n- We can naturally introduce a ***language model (=prior distribution) explicitly in the simulation of language emergence*** (Sec 3.4).\n\nMoreover, by regarding the prior as a language model,\n- We'll be somewhat ***satisfied in a scientific sense*** to notice that ***the prior coincides with surprisal, a concept from psycho-linguistics*** (Sec 3.5).\n\nThey are also shown in \"Recipe for Supporting Our ELBO-based Formulations\" in Sec 3."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1551/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700187854470,
                "cdate": 1700187854470,
                "tmdate": 1700187854470,
                "mdate": 1700187854470,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Yhjxz8XhO8",
                "forum": "HC0msxE3sf",
                "replyto": "SwkBBeNfyL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1551/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1551/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer E7HT (Comment 11-13)"
                    },
                    "comment": {
                        "value": "## Reviewer's Comment 11 (about Sec 3.1; Appendix B.1)\n> It would also be helpful to give an indication of what from Schulman et al. (2015) is being applied (i.e., the what the \"stochastic computation approach\" is).\n> As a result, I'm not convinced that the reconstruction game, absent modifications to the traditional object (e.g., length penalty), assumes a uniform prior of messages.\n\nThank you for pointing it out.\n\nApart from the standard VAE, we adopted the REINFORCE-like optimization but the \"reward\" (reconstruction term) is differentiable (w.r.t the receiver $\\theta$).\nThe differentiability of the \"reward\" hinders the direct application of REINFORCE.\nThat is why, instead of Williams (1992), we mentioned Schulman et al. (2015), who proposed some sort of the generalization of REINFORCE.\nAs you pointed out, our proof would become clearer by explicitly explaining how to utilize the result of Schulman et al. (2015).\n\n## Revision for Comment 11\nTo clarify the proof, we added two lemmas (Lemma 1; 2) in Appendix B.1 to support the proof description (The lemmas can be seen as a special case of Schulman (2015) and/or REINFORCE).\n\n## Reviewer's Comment 12 (about Sec 3.1; Appendix B.1)\n> It seems like the $P(m)\\sim\\mathop{\\mathbb{E}}\\nolimits_{x\\sim P_{obj}}[S(m|x)]$ should be the prior over messages.\n\nWe understand your concern, but this is not the case.\nWe hope that the above revision made our proof persuasive enough to regard the uniform distribution as the prior.\n\nLet us explain why the average sender is not the prior in the conventional EC signaling game, using some equations.\nFirst, let us decompose Eq. 9 as follows:\n\n$$\n\\begin{aligned}\n\\nabla_{\\phi,\\theta}\\mathop{\\underbrace{\\mathop{\\mathbb{E}}\\nolimits_{P_{\\textrm{obj}}(x),S_{\\phi}(m|x)}[\\log R_{\\theta}(x|m)]}}\\limits_{\\text{conventional objective}}\n&\\mathop{\\underbrace{=}}\\limits_{\\text{proof target}}\n\\nabla_{\\phi,\\theta}\\mathop{\\mathbb{E}}\\nolimits_{P_{\\textrm{obj}}(x),S_{\\phi}(m|x)}[\\log R_{\\theta}(x|m)+\\log P_{\\textrm{unif}}^{\\textrm{prior}}(m)]\n\\\\\\\\\n&=\n\\mathop{\\underbrace{\\nabla_{\\phi,\\theta}\\mathop{\\mathbb{E}}\\nolimits_{P_{\\textrm{obj}}(x),S_{\\phi}(m|x)}[\\log R_{\\theta}(x|m)]}}\\limits_{\\text{same as the left-hand side.}}\n+\\mathop{\\underbrace{\\nabla_{\\phi,\\theta}\\mathop{\\mathbb{E}}\\nolimits_{P_{\\textrm{obj}}(x),S_{\\phi}(m|x)}[\\log P_{\\textrm{unif}}^{\\textrm{prior}}(m)].}}\\limits_{\\text{should be proven $=0.$}}\n\\end{aligned}\n$$\n\nBased on this decomposition, what we have to prove essentially is: $\\nabla_{\\phi,\\theta}\\mathop{\\mathbb{E}}\\nolimits_{P_{\\textrm{obj}}(x),S_{\\phi}(m|x)}[\\log P_{\\textrm{unif}}^{\\textrm{prior}}(m)]=0$.\nAccording to Lemma 1 (which is added in the revised version), it can be further transformed as follows:\n\n$$\n\\begin{aligned}\n\\nabla_{\\phi,\\theta}\\mathop{\\mathbb{E}}\\nolimits_{P_{\\textrm{obj}}(x),S_{\\phi}(m|x)}[\\log P_{\\textrm{unif}}^{\\textrm{prior}}(m)]\n&\\mathop{\\underbrace{=}}\\limits_{\\text{From Lemma 1.}}\n\\mathop{\\mathbb{E}}\\nolimits_{P_{\\textrm{obj}}(x),S_{\\phi}(m|x)}[\\nabla_{\\phi,\\theta}\\log P_{\\textrm{unif}}^{\\textrm{prior}}(m)+(\\log P_{\\textrm{unif}}^{\\textrm{prior}}(m))\\nabla_{\\phi,\\theta}\\log S_{\\phi}(m|x)].\n\\\\\\\\\n&=\n\\mathop{\\underbrace{\\mathop{\\mathbb{E}}\\nolimits_{P_{\\textrm{obj}}(x),S_{\\phi}(m|x)}[\\nabla_{\\phi,\\theta}\\log P_{\\textrm{unif}}^{\\textrm{prior}}(m)]}}\\limits_{(\\dagger)}\n+\\mathop{\\underbrace{\\mathop{\\mathbb{E}}\\nolimits_{P_{\\textrm{obj}}(x),S_{\\phi}(m|x)}[(\\log P_{\\textrm{unif}}^{\\textrm{prior}}(m))\\nabla_{\\phi,\\theta}\\log S_{\\phi}(m|x)]}}\\limits_{(\\ddagger)}.\n\\end{aligned}\n$$\n\nHere,\n- Term $(\\dagger)$ would be $0$ if $\\nabla_{\\phi,\\theta}\\log P_{\\textrm{unif}}^{\\textrm{prior}}(m)=0$.\n- Term $(\\ddagger)$ would be $0$ if $\\log P_{\\textrm{unif}}^{\\textrm{prior}}(m)$ is constant w.r.t $m$ (See Lemma 2, which is added in the revised version).\n\nThus, we should define $P_{\\textrm{unif}}^{\\textrm{prior}}(m)$ as a uniform distribution, i.e., $P_{\\textrm{unif}}^{\\textrm{prior}}(m)=\\frac{1}{|\\mathcal{M}|}$.\n\nNow, let us assume a prior distribution to be $S_{\\phi}(m):=\\mathop{\\mathbb{E}}\\nolimits_{x\\sim P_{\\textrm{obj}}}[S_{\\phi}(m|x)]$ as you suggested.\nThen, what we have to check (prove/disprove) is whether $\\nabla_{\\phi,\\theta}\\mathop{\\mathbb{E}}\\nolimits_{P_{\\textrm{obj}}(x),S_{\\phi}(m|x)}[\\log S_{\\phi}(m)]=0$.\nBut the gradient is not zero in general, since\n$$\\mathop{\\mathbb{E}}\\nolimits_{P_{\\textrm{obj}}(x),S_{\\phi}(m|x)}[\\log S_{\\phi}(m)]=-\\mathop{\\mathbb{E}}\\nolimits_{S_{\\phi}(m)}[-\\log S_{\\phi}(m)]=-\\mathcal{H}(S_{\\phi}(M)).$$\n\n## Reviewer's Comment 13 (about Sec 3.2)\n> Sec 3.2: what is a \"heuristic variant of [a] VAE\"?\n\nWe just meant by that phrase that the conventional EC signaling game is similar to VAE.\nIndeed, it might be an awkward phrase as you imply.\n## Revision for Comment 13\nWe rephrased the phrase as follows:\n> (***Revision***) In this sense, the conventional signaling game is similar to VAE."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1551/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700188963707,
                "cdate": 1700188963707,
                "tmdate": 1700196080716,
                "mdate": 1700196080716,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xHxKwuc9OO",
                "forum": "HC0msxE3sf",
                "replyto": "p0T6HjGlvr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1551/Reviewer_E7HT"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1551/Reviewer_E7HT"
                ],
                "content": {
                    "title": {
                        "value": "Studied problem does have an audience"
                    },
                    "comment": {
                        "value": "I would explicitly disagree with Weakness (3) given by Reviewer unmd. I think theoretical analysis of emergent communication games is much needed in the field as a whole.  For the most part, EC works lean towards \"engineering\" approaches (e.g., tinkering with empirical evaluation) instead of theoretical analysis that allows for principled predictions before empirical evaluation (even if they turn out to be wrong).  This allows for iterative development of theoretical models as they produce predictions which are subsequently tested and point to revisions needed in the theoretical model.  For this reason, I definitely think that the overall direction of this paper is important."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1551/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700603900149,
                "cdate": 1700603900149,
                "tmdate": 1700603900149,
                "mdate": 1700603900149,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ClDBdQZzVm",
                "forum": "HC0msxE3sf",
                "replyto": "Yhjxz8XhO8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1551/Reviewer_E7HT"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1551/Reviewer_E7HT"
                ],
                "content": {
                    "title": {
                        "value": "Revised evaluation in light of rebuttal"
                    },
                    "comment": {
                        "value": "I believe that the rebuttal and revisions of the paper have addressed the weaknesses stated in my review and bolstered the strengths.\nSpecifically, I will change the following ratings in review:\n\n- Soundness: 2 -> 3\n- Presentation: 2 -> 3\n- Rating: 5 -> 8\n\nThe reason that I am willing to change my rating significantly is that (1) I was already convinced of the importance of approaching EC theoretically before immediately jumping to empirical evaluation as well (expanded upon in my reply to Reviewer unmd) as the particular analysis of the signalling game as an VAE (I think it is an almost obvious analogy but one that has lacked substantial analysis in the extant literature).\n(2) And my main concerns had to do with the clarity and the exact nature of one of the central claims (i.e., the \"prior\" of the signalling game/VAE).\nSince the clarity issue was resolved adequately, I feel that the strength of the approach can shine through, and that the theoretical analyses can be of use to practitioners down the road.\n\nI acknowledge the weaknesses given by Reviewer TgUR, and I think they have been sufficiently ameliorated by the revisions, even if not completely resolved.\nThe weaknesses given by Reviewer unmd are not substantive and do not impact my evaluation significantly."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1551/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700604923212,
                "cdate": 1700604923212,
                "tmdate": 1700604923212,
                "mdate": 1700604923212,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "iqUWRUGLzG",
            "forum": "HC0msxE3sf",
            "replyto": "HC0msxE3sf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1551/Reviewer_knBD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1551/Reviewer_knBD"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a new perspective on Lewis\u2019s signaling game as beta-VAE and reformulates the game\u2019s objective as ELBO. Based on this modification, it analyzes the influence of the implicit prior function on the properties of word lengths and segmentation of the emergent languages. It also shows that a learned prior distribution of the emergent languages can help evolve a language following Zipf\u2019s law and Harris\u2019s articulation scheme while the previous conventional objectives do not encourage meaningful segments."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1. The originality of this paper is good. The authors propose a generative point of view of the signaling game and analyze the possible causing factors of the current problems of the emerging less meaningful linguistic properties using the conventional objectives. This can provide a fresh study framework for emergent communication. The rigorous formalization and mathematical equations can integrate previous designs of regularizers and help with future objective design, offering a valuable contribution to the field.\n\n2. The quality of the experiments and analysis is good. They compare different baselines controlling different priors of the objectives. The properties of word lengths, segments, and compositionality are carefully checked. \n\n3. This paper is of good clarity. It is easy to follow the argument of this paper."
                },
                "weaknesses": {
                    "value": "No obvious weaknesses."
                },
                "questions": {
                    "value": "Based on the current formulation, it seems that the distractors on the receiver\u2019s side are not considered. How would you incorporate the context of the distractors and their corresponding influences [1,2] into the prior design? \n\n[1] Lazaridou, Angeliki, Alexander Peysakhovich, and Marco Baroni. \"Multi-agent cooperation and the emergence of (natural) language.\" arXiv preprint arXiv:1612.07182 (2016).\n\n[2] Evtimova, Katrina, et al. \"Emergent communication in a multi-modal, multi-step referential game.\" arXiv preprint arXiv:1705.10369 (2017)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1551/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1551/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1551/Reviewer_knBD"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1551/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698624222969,
            "cdate": 1698624222969,
            "tmdate": 1699636083495,
            "mdate": 1699636083495,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oz7bWAZ3iA",
                "forum": "HC0msxE3sf",
                "replyto": "iqUWRUGLzG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1551/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1551/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer knBD"
                    },
                    "comment": {
                        "value": "We greatly appreciate your positive feedback on our research!\n\n> Based on the current formulation, it seems that the distractors on the receiver\u2019s side are not considered.\n> How would you incorporate the context of the distractors and their corresponding influences into the prior design?\n\nThis is an important point. Thank you for highlighting it.\n\nSimilar to Lewis's signaling (reconstruction) game, Lewis's discrimination (referential) game has also been a significant model in EC.\nDue to the generative nature of our storytelling, we have focused on the reconstruction game in this study.\nWe plan to extend our study to include the discrimination game in our future work."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1551/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700190541725,
                "cdate": 1700190541725,
                "tmdate": 1700190541725,
                "mdate": 1700190541725,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "p0T6HjGlvr",
            "forum": "HC0msxE3sf",
            "replyto": "HC0msxE3sf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1551/Reviewer_unmd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1551/Reviewer_unmd"
            ],
            "content": {
                "summary": {
                    "value": "The paper attempts to reframe the conventional Lewis's signaling game within the context of beta-VAE and ELBO, with a focus on the impact of prior distributions on emergent languages. The authors argue that selecting appropriate prior distributions can lead to the emergence of more natural language segments, while the conventional prior may hinder adherence to linguistic properties like Zipf's law of abbreviation (ZLA) and Harris's articulation scheme (HAS).\n\nThe weak points of this paper include:\n(1) The paper is hard to read. The theoretical section includes symbols and equations without full explanation.\n(2) The experiments are weak. The compared methods lack descriptions, and the performance improvement is not well explained.\n(3) The studied problem lacks of enough audience."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The author well introduces the problem, which is well motivated.\n2. The authors provide a deteailed proof in supplementary material."
                },
                "weaknesses": {
                    "value": "(1) The paper is hard to read. The theoretical section includes symbols and equations without full explanation.\n(2) The experiments are weak. The compared methods lack descriptions, and the performance improvement is not well explained.\n(3) The studied problem lacks audience in the community."
                },
                "questions": {
                    "value": "I suggest the authors address my concerns mentioned in Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1551/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699122831107,
            "cdate": 1699122831107,
            "tmdate": 1699636083372,
            "mdate": 1699636083372,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KdYiqKj6rp",
                "forum": "HC0msxE3sf",
                "replyto": "p0T6HjGlvr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1551/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1551/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer unmd"
                    },
                    "comment": {
                        "value": "Thank you for reviewing our paper.\n\n## Reviewer's Comment 1\n> The paper is hard to read. The theoretical section includes symbols and equations without full explanation.\n\nThank you for pointing out the need for clearer explanations in the theoretical section.\nTaking all the reviewers' comments into consideration, we have now added explanations for symbols and equations.\n\nIf you have any other specific problems or comments, please do not hesitate to mention them.\n\n## Reviewer's Comment 2\n> The experiments are weak. The compared methods lack descriptions, and the performance improvement is not well explained.\n\nWe appreciate your feedback regarding the experimental section.\n\nWe believe we have adequately addressed the important aspects of the theoretical contribution through mathematical proof. Regarding word length and segmentation, we are confident that the experimental results we have obtained support the main claims of our contribution.\n\nHowever, it is possible that we may have overlooked some points that the reviewer has noticed. If you believe there is a lack of experiments in terms of supporting specific hypotheses, we would greatly appreciate your feedback.\n\n## Reviewer's Comment 3\n> The studied problem lacks of enough audience.\n\nWe are afraid that you may be underestimating the growing interest in Emergent Communication (EC) and Representation Learning.\nBoth of them are increasingly being recognized as important in recent years, as evidenced by the significant number of papers published in major machine leaning conferences.\nOur paper bridges these two areas by demonstrating how EC signaling game can be re-interpreted as representation learning in generative models, namely beta-VAE."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1551/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700190770761,
                "cdate": 1700190770761,
                "tmdate": 1700190770761,
                "mdate": 1700190770761,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]