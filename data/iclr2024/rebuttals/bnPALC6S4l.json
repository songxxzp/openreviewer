[
    {
        "title": "Towards general neural surrogate PDE solvers with specialized neural accelerators"
    },
    {
        "review": {
            "id": "BaFf982TCF",
            "forum": "bnPALC6S4l",
            "replyto": "bnPALC6S4l",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4225/Reviewer_PJmS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4225/Reviewer_PJmS"
            ],
            "content": {
                "summary": {
                    "value": "Neural networks can be used to learn the solution operators for PDEs. The more complex the PDE problem (in terms of initial data etc.) the harder it is to learn solution operators applicable to a wide class of problem instances. The authors propose to combine the ideas of domain decomposition methods with that of Fourier neural operators. They demonstrate how to successfully learn the solution operator for smaller sub-domains for problems that can be solved by iterating on a domain decomposition by updating the boundary condition based on neighboring solutions. The authors demonstrate that their learned neural operators can solve example problems in electromagnetics (magnetic field wave equation) and fluid mechanics (incompressible Navier-Stokes equation) via domain decomposed iteration. To successfully learn the solution operator the authors propose to add residual connections and a self-modulation mechanism to the Fourier neural operator architecture from the literature and demonstrate their usefulness in ablation experiments. Due to the iterated nature of the author\u2019s proposed solution approach the solution is not one-shot and the computational cost increases in a non-trivial way as a function of problem size. Overall, it is not clear that using the proposed SNAP-DDM approach outperforms a conventional finite difference frequency domain solver."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- The authors present an original idea of applying the neural operator approach to domain decompositions which should be easier to learn systematically due to keeping them to a smaller sub-domain which should hopefully contain less complexity.\n- The authors contribute architectural improvements to FNOs and demonstrate the usefulness to the example problems that they consider. These ideas seem likely to be useful to other applications of the FNO architecture as well."
                },
                "weaknesses": {
                    "value": "- The evaluation setup is not very clear to me in terms of what was done on training data and what was done on evaluation data. For example, the 99% accuracy made in the introduction seems to be on training data (Table 1)? It makes sense to me that we want to understand how well in general the architecture can fit a neural operator if the training data for that specific problem instance is provided, but that does not tell me anything about how well the approach generalizes. My understanding is that Section 3.2 uses the previously trained neural operators on a held out problem instance (Figure 4). I think this distinction and implications about generalization need to be discussed more clearly. Especially, I'm wondering how dissimilar the instances can become and still converge or how does out-of-domain-ness impact convergence speed.\n- Related work and background of how the contribution ties into the field is explained only on a surface level (in the introduction). Literature cited is mostly from numerical simulation publication venues and not machine learning. Lots of terminology that is used without definition will not be familiar to the broader ICLR audience, e.g. TE and TM polarization not necessarily familiar to non-physics audience, Bloch phase, finite difference frequence domain solvers. Furthermore, the insights gained in the paper are mostly useful to the numerical simulation community in a specific application area. Not sure how generally useful the contribution is to machine learning field because no new machine learning concept are introduced. So I am not sure the broader ICLR audience is the right one for this paper."
                },
                "questions": {
                    "value": "- Since neural operators are approximations whose approximation error is hard to bound in advance, how is it possible how useful they will be for a given problem instance? Is there some way of combining them or using them to warm-start or speed up a traditional numerical solver with theoretical convergence guarantees (more like a pre-conditioner)?\n- When can DDM methods be applied in principle / how general are they? Do they only lend themselves to the type of PDEs considered in the paper or are they much broader?\n- Is the setup used in the paper (2D 960x960 grid) relevant to praciticioners? Can useful real-world problems be solved at that resolution?\n- c1 and c2 be set to 1 for \"simplicity\" -> is this based on any sort of hyper param experiment? Technically, you also only need one of these hyper params, since the other one is implicit in alpha.\n- For the time complexity measurements: Mean absolute accuracy of 15% seems like far from convergend (less than first 16 iterations in Figure 4), why was this chosen?\n- Nit: I was a bit confused by the use of \"pixels\" terminology in a paper about PDE solutions"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4225/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698659817600,
            "cdate": 1698659817600,
            "tmdate": 1699636389577,
            "mdate": 1699636389577,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pn5sTn2QjH",
                "forum": "bnPALC6S4l",
                "replyto": "BaFf982TCF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4225/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4225/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your review!"
                    },
                    "comment": {
                        "value": ">4.1. The evaluation setup is not very clear to me in terms of what was done on training data and what was done on evaluation data. For example, the 99% accuracy made in the introduction seems to be on training data (Table 1)? It makes sense to me that we want to understand how well in general the architecture can fit a neural operator if the training data for that specific problem instance is provided, but that does not tell me anything about how well the approach generalizes. My understanding is that Section 3.2 uses the previously trained neural operators on a held out problem instance (Figure 4). I think this distinction and implications about generalization need to be discussed more clearly. Especially, I'm wondering how dissimilar the instances can become and still converge or how does out-of-domain-ness impact convergence speed.\n\nAll the table and plot data are conducted on 10k newly generated unseen test data. We have also added text in section 3.1 as well as in the titles of Tables 1 and 2. We have also added the dataset split and training details in section 3.1.\n\nWe expect the performance of the model will deteriorate as the test data drift away from the training data distribution. For example for material dielectric constant outside of the range considered (epsilon = 1 to 16), or with different Reynolds numbers. The claim of our method emphasizes more on how to create random dataset (detailed in Appendix A) to enable model solving a broad range of problems within its distribution that\u2019s sufficient for practical applications (shown in Figure 4), and we don\u2019t claim that the method would extrapolate perfectly to unseen distributions.\n\n>4.2. Related work and background of how the contribution ties into the field is explained only on a surface level (in the introduction). Literature cited is mostly from numerical simulation publication venues and not machine learning. Lots of terminology that is used without definition will not be familiar to the broader ICLR audience, e.g. TE and TM polarization not necessarily familiar to non-physics audience, Bloch phase, finite difference frequence domain solvers. Furthermore, the insights gained in the paper are mostly useful to the numerical simulation community in a specific application area. Not sure how generally useful the contribution is to machine learning field because no new machine learning concept are introduced. So I am not sure the broader ICLR audience is the right one for this paper.\n\nWe understand this work covers a broad range of topics and that there is some technical electromagnetic jargon in the manuscript, which we have attempted to limit with additional edits throughout.  The point of this manuscript is to simply use electromagnetics as a testbed for solving PDEs with neural networks, which itself is of interest to the machine learning community (the original FNO and PINNs papers already have thousands of citations from the applied mathematics and machine learning communities).  In this context, we push back on the idea that \u201cno new machine learning concept is introduced.\u201d  We introduce improvements to the FNO architecture (again, the initial paper is cited 1000+ times largely by machine learning specialists) that can enable improved solving of PDEs, show that FNO subdomain solvers can be utilized in a DDM framework, and we provide data generation schemes and physics-augmented training schemes that enable subdomain solvers operating with near unity accuracy.  All of these insights are not limited to electromagnetics or fluids but to any steady state PDE problem, making our insights in machine learning of broad interest to members in the computational, physical sciences, and data science communities.\n\n\n>4.3. Since neural operators are approximations whose approximation error is hard to bound in advance, how is it possible how useful they will be for a given problem instance? Is there some way of combining them or using them to warm-start or speed up a traditional numerical solver with theoretical convergence guarantees (more like a pre-conditioner)?\n\nPart of what we wanted to explore was whether we could solve PDE problems using only neural networks.  PDE solutions that > 90% accurate, which is what we have with SNAP-DDM, are sufficient for performing inverse design and optimization in fields such as nanophotonics. [1,2]  With that said, we agree that the idea of using neural operators as a means to find better initial guess or to be used as pre-conditioner to accelerate traditional solvers with theoretical convergence guarantees is a promising avenue for future research. \n\n\n\n[1] Zhelyeznyakov, Maksym, et al. \"Large area optimization of meta-lens via data-free machine learning.\" Communications Engineering 2.1 (2023): 60. \n\n[2] Chen, Mingkun, et al. \"WaveY-Net: physics-augmented deep-learning for high-speed electromagnetic simulation and optimization.\" High Contrast Metastructures XI. Vol. 12011. SPIE, 2022."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4225/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700724899038,
                "cdate": 1700724899038,
                "tmdate": 1700724927002,
                "mdate": 1700724927002,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "NIXHsSRWf3",
            "forum": "bnPALC6S4l",
            "replyto": "bnPALC6S4l",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4225/Reviewer_scWL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4225/Reviewer_scWL"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes SNAP-DDM, a method that utilizes deep learning in the context of domain decomposition methods. Each subdomain inside a given DDM framework is separately solved with a neural network-based solver and stitched together using appropriate boundary conditions. Depending on the contents of each subdomain, specialized neural operators are used. The main contribution of this work are modifications to the FNO architecture, in the form of residual connections inspired by the ResNet architecture and self-modulating connections inspired by transformers. The authors evaluate the proposed method on an electromagnetic and a fluid flow problem."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "I see two main strengths of this paper, mainly in terms of originality and significance:\n\nFirst, to me the application of established PDE deep learning methods to DDM appears to be an original and promising direction, even though I am not an expert in the domain that this paper targets. Nevertheless, I am still unsure if this paper would not be a better fit in a physics journal, as especially Section 2 heavy relies on physical details in the current version of this work.\n\nSecond, if the modifications to FNO hold in a more general setting, the proposed residual and self-modulating connections would be a valuable addition to the neural operator toolbox. Especially so, considering the success of ResNets and transformers compared to previous network architectures in the vision and language modeling domains.\n\nFurthermore, source code is provided alongside this submission, which should help to improve the reproducibility of the shown results. However, I did not run or investigate the source code."
                },
                "weaknesses": {
                    "value": "This paper appears to be unfinished in various aspects, and several presentation issues and lacking details make it difficult to clearly understand the methodology and judge the presented empirical results.\n\n### Presentation\n\n**P1:**\nEven though there are a range of references in the introduction, in my opinion this paper would clearly benefit from a dedicated related work section and a more generic introduction. Otherwise connections relative to prior work are difficult to draw, especially for non-experts on the overlap area of DDMs, neural operators, and machine learning like myself. \n\n**P2:**\nThere are statements throughout the paper that are vague, need further explanation, or require citations. Some examples are the following, but this is not an exhaustive list:\n- *\"but the are largely limited to systems featuring predetermined problem sites or fixed PDE parameters\u201d* (abstract)\n- the spectral bias issues of PINNs (end of second paragraph in section 1)\n- the problems of current neural operator methods *\u201cWhile much progress have been made\u2026 resource consuming and undesirable.\u201d* (at the bottom of page 1 / the top of page 2)\n- *\u201cFurthermore, the training of separate networks\u2026 without loss of generality.\u201d* (at the top of page 4)\n\n**P3:**\nThe overall structure of the paper and especially the presentation of the methodology should be improved. It is not clear how exactly the network is used or what its outputs are, even at the end of the methodology section. Furthermore, the methodology section is not written in generic terms of the method, but simply as an example description on the electromagnetic experiment. For instance, it is not discussed how to choose networks in the generic case, or how SNAP-DDM works on the fluid flow problem.\n\n**P4:**\nThe paper generally lacks polishing and contains a range of smaller issues and typos, for example:\n- Number of abbreviations is relatively large and can easily become confusing\n- Fig. 3/4/6: In my opinion, it is not ideal to show ground truth field and error in same colormap\n- Fig. 4: Colorbars are missing\n- Fig. 4/6/7: Subfigures are plotted inconsistently\n- Fig. 7: What are the differently colored lines here? To me that was not clear from the description. Furthermore, the fontsize is too small\n- Section 1, paragraph 2: \u201cansartz\u201d\n- Abstract: \u201cnear unity accuracy\u201d (unclear and unusual formulation)\n- Top of page 3: \u201cYee formalism (cite)\u201d\n- Begin of Section 4: \u201cwith L the being number of layers\u201d\n\n\n### Evaluations\n**E1:**\nThe proposed changes in this work are first and foremost improvements to FNOs and not DDM. It is not clear why they are only tested on the DDM case, which makes things unnecessarily complicated. Instead, a direct comparison against FNOs and other baselines on full-sized PDE problems would be much more logical as a first step. With the current scope it is unclear if the observed improvements hold more generally.\n\n**E2:**\nIt would be nice to have a comparison to a non-DDM model as a baseline, to get an idea of the achieved performance level. For example, a direct prediction via a fully convolutional neural network trained on different domain sizes comes to mind.\n\n**E3:**\nThe physical problems are relatively limited, especially the fluid flow problem (where it is even unclear how SNAP-DDM works, as mentioned in P3 above). An interesting case would be a more complex fluid problem, like an unsteady flow. This would requires multiple time iterations (in addition to the solver iterations), but show that DDM is robust to temporal rollouts, which is a highly desirable property.\n\n**E4:**\nIt is not mentioned how the data sets are split. This is especially relevant for Tab. 1 and 2, as it is unclear what is actually shown here, training loss, validation, or test performance? Furthermore, it would be interesting to see how SNAP-DDM performs for more complex evaluation tasks (slightly) outside of the training domain, for example different Reynolds numbers in the flow experiment. Or boundaries created by a fundamentally different generation method.\n\n**E5:**\nTab 1 shows that more training data substantially improves model performance. Why are the other baselines not evaluated with the same amount of data for a fair comparison at the computational limit that would be used in practice as well?\n\n**E6:**\nTraining details of the baselines are missing, and the appendix only contains a very rough overview of some parameters of each baseline. Furthermore, how are the most important hyperparameters for the baselines chosen?\n\n**E7:**\nWhile the proposed changes are promising compared to FNOs, it seems that other simpler architectures like Unet can achieve similar performance. Especially with recent Unet modernizations commonly used for diffusion models, even better results might be possible (see *\u201cDenoising diffusion probabilistic models\u201d* by Ho et al., NeurIPS 2020, or *\u201cDiffusion models beat GANs on image synthesis\u201d* by Dhariwal and Nichol, NeurIPS 2021).\n\n### Summary\nOverall, this work feels unfinished and in my opinion needs a larger revision in terms of presentation and more rigorous evaluations. Due to the chosen problem setup inside a DDM solver, it is also difficult to tell if the improvements to the FNO architecture actually hold in a more general setting. This leads to my overall recommendation of reject for the current state of this paper.\n\n### Update after Author Response\nWith the improved presentation and additional results, the insights from combining DDM with FNOs are certainly an interesting direction. Nevertheless, I think this paper would clearly benefit from further improving the presentation and investigating the strengths of the other baseline variants, especially U-Net in more detail. Finally, showing the benefits of the proposed improvements to FNOs in a more general setting would be a useful addition. As a result, I reconsidered my original evaluation of this work and updated my original review with the following changes:\n- Soundness Score: increased from *2 fair* to *3 good*\n- Presentation Score: increased from *1 poor* to *2 fair*\n- Overall Score: increased from *3 reject* to *6 marginally above the acceptance threshold*"
                },
                "questions": {
                    "value": "**Q1:**\nHow can the data error computed via an L1 loss in Fig. 3/6 be negative? According to equation 4 it is just a sum over the absolute difference which should always be positive?\n\n**Q2:**\nWhat are the results when evaluating the best baseline (i.e. Unet) in the same way as shown for SNAP-DDM in Fig. 4/6b?\n\n**Q3:**\nI did not fully understand the choice for the ablation study models in Tab. 3, especially w.r.t. changing the architecture at the same time as the model sizes $L$ and $C$. The current presentation makes it unclear if the differences are due to architectural changes or the model size.\n\n**Q4:**\nOn a rather abstract level, the iterative refinement approach of the solver has some interesting connections to diffusion models, that also iteratively refine an initial prediction. What are your thoughts on the usage of diffusion models within DDMs: Do you see some potential to map the solver iterations to an iterative model training schedule, achieving a physical diffusion-style DDM framework?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4225/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4225/Reviewer_scWL",
                        "ICLR.cc/2024/Conference/Submission4225/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4225/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698756561245,
            "cdate": 1698756561245,
            "tmdate": 1700755351829,
            "mdate": 1700755351829,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "OedNtQpkBr",
                "forum": "bnPALC6S4l",
                "replyto": "NIXHsSRWf3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4225/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4225/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your review!"
                    },
                    "comment": {
                        "value": ">3.1. Even though there are a range of references in the introduction, in my opinion this paper would clearly benefit from a dedicated related work section and a more generic introduction. Otherwise connections relative to prior work are difficult to draw, especially for non-experts on the overlap area of DDMs, neural operators, and machine learning like myself.\n\nWe have rewritten parts of the introduction in an attempt to add clarity to the current state-of-the-art in PDE solving and to further highlight our contributions.  With the page limit and the addition of other content to the main text, we were not able to add too much more text but hope that the additional cited references can further help an interest non-specialist learn more about these non-trivial subjects.\n\n>3.2. There are statements throughout the paper that are vague, need further explanation, or require citations. Some examples are the following, but this is not an exhaustive list:\n1. but the are largely limited to systems featuring predetermined problem sites or fixed PDE parameters\u201d (abstract)\n2. the spectral bias issues of PINNs (end of second paragraph in section 1)\n3. the problems of current neural operator methods \u201cWhile much progress have been made\u2026 resource consuming and undesirable.\u201d (at the bottom of page 1 / the top of page 2)\n4. \u201cFurthermore, the training of separate networks\u2026 without loss of generality.\u201d (at the top of page 4)\n\nWe have edited the entire document to modify statements that are vague or that require further explanation, and we have specifically addressed the examples cited.\n\n>3.3. The overall structure of the paper and especially the presentation of the methodology should be improved. It is not clear how exactly the network is used or what its outputs are, even at the end of the methodology section. Furthermore, the methodology section is not written in generic terms of the method, but simply as an example description on the electromagnetic experiment. For instance, it is not discussed how to choose networks in the generic case, or how SNAP-DDM works on the fluid flow problem.\n\nWe have updated Figure 1 to indicate more clearly the inputs and outputs of each subdomain model and how these inputs and outputs work synergistically in the DDM framework.  We also have a dedicated section on boundary value update that visualizes how boundaries within a subdomain are extracted and used to update the boundary value of the nearest neighbors.  While this example and flow chart is indeed focused on an electromagnetics problem, we believe it is now posed in a sufficiently generic manner as to be readily adapted to other types of physics problems.  We have also updated the caption of Figure 1 to indicate that the same principle (boundary models, source models and material models) could be applied to general PDE problems, including fluid problems. \n\n>3.4. The paper generally lacks polishing and contains a range of smaller issues and typos, for example: \u2026\n\nWe have fixed the typos and added full clarified abbreviations."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4225/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700724268042,
                "cdate": 1700724268042,
                "tmdate": 1700724268042,
                "mdate": 1700724268042,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vrwv6wcqr1",
            "forum": "bnPALC6S4l",
            "replyto": "bnPALC6S4l",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4225/Reviewer_mta4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4225/Reviewer_mta4"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a method that employs domain decomposition techniques to help solve steady-state partial differential equations PDEs, for which known physical prior information is available. The model operates by mapping the parameter functions of the equation to its steady-state solution. This is achieved through the division of the entire domain into multiple subdomains. Notably, the surrogate models are exclusively trained using data from the subdomains' results and boundary conditions. The PDE is then solved iteratively, incorporating a physical loss, and updating the boundary conditions for each subdomain. The results of the proposed model are promising."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper investigates the utilization of an existing physical model to streamline the solving of partial differential equations (PDEs) by spatially decomposing the domain. This approach reduces the complexity of the required model for each subdomain. This offers insights into incorporating additional physical priors to enhance the scalability of current neural PDE surrogate models.\n- The method is evaluated on various electromagnetic systems with diverse domain shapes. The modular design of the model makes it applicable for solving the same PDE in different settings."
                },
                "weaknesses": {
                    "value": "- In terms of presentation quality, I recommend enhancing the overall structure of the paper by providing a more visible and distinct description of the model, including a concise definition of the input and the output. Additionally, it would be beneficial to separate and clarify the sections for the model, training, and evaluation processes. Currently, understanding the entire training pipeline is challenging as it is intertwined with the model description, the existing algorithm, and the experimental results. Furthermore, I suggest reorganizing the presentation of experimental results with a clearer structure, dedicating specific sections to data preparation, technical details, and result analysis.\n- Baselines comparison: While the model is currently benchmarked against baseline architectures for subdomain training, it is essential to consider a broader comparison with physics-informed baselines such as PINNs and PINOs/PiDeepONet on the entire domain. This extended evaluation would provide a more comprehensive understanding of how the proposed method compares to established DL-based physics-informed techniques.\n- Regarding terminology: I was somewhat surprised when I noticed that the authors introduced an additional residual connection alongside the one that already existed. (Please note that point-wise convolution is equivalent to applying a linear layer to each pixel and is a conventional implementation of residual connections when the input and output channel counts do not match.) Have the authors considered replacing the point-wise convolution with a simple identity addition?"
                },
                "questions": {
                    "value": "- It's quite unexpected that the original FNO struggles to predict the outputs of not-so-complex subdomains accurately. It would be valuable if the authors could provide additional insights into the specific challenges or limitations the original FNO faces when applied to these cases.\n- In Figure 7, it's intriguing to observe the solver's convergence with iterations, especially considering that the subdomain models are trained solely with the ground truth subdomain boundary conditions. To gain a deeper understanding of this convergence behavior, it would be beneficial to include a more detailed graph that provides further insights into the solver's performance throughout the entire testing process. The current figures show data from only five selected points, but a more precise graph could shed light on the solver's convergence across the entire testing period."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4225/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698841520119,
            "cdate": 1698841520119,
            "tmdate": 1699636389410,
            "mdate": 1699636389410,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qh7DPozg8M",
                "forum": "bnPALC6S4l",
                "replyto": "vrwv6wcqr1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4225/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4225/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your review."
                    },
                    "comment": {
                        "value": ">2.1 In terms of presentation quality, I recommend enhancing the overall structure of the paper by providing a more visible and distinct description of the model, including a concise definition of the input and the output. Additionally, it would be beneficial to separate and clarify the sections for the model, training, and evaluation processes. Currently, understanding the entire training pipeline is challenging as it is intertwined with the model description, the existing algorithm, and the experimental results. Furthermore, I suggest reorganizing the presentation of experimental results with a clearer structure, dedicating specific sections to data preparation, technical details, and result analysis.\n\nWe thank the reviewer for the critical suggestions on presentation. \n- We have updated Figure 1 with much clearer indication of inputs and output of each subdomain model, and we have a dedicated section on boundary value update that visualizes how boundaries are extracted, and update to overlapping nearest neighbors.\n- Due to the page limit, we have left details of data generation in Appendix A.\n- We added training details in section 3.1.\n\n>2.2 Baselines comparison: While the model is currently benchmarked against baseline architectures for subdomain training, it is essential to consider a broader comparison with physics-informed baselines such as PINNs and PINOs/PiDeepONet on the entire domain. This extended evaluation would provide a more comprehensive understanding of how the proposed method compares to established DL-based physics-informed techniques.\n\nWe agree it is necessary to show the comparison on the entire domain. We have added two experiments in the SI:\n- We have conducted extensive architecture, activation function, and parameter search for multiple PINN models applied to simulation problems of varying domain sizes with heterogeneous material simulation domains, with material refractive index spanning from air to silicon. We provide extensive discussion in Section D (Domain-Specific Physics-Informed Neural Networks) in the SI.  We find that it remains challenging to scale current strategies to large domain sizes and heterogeneous material with high dielectric index.  This observation is consistent with other works in the literature.  \n- We also report in the SI the findings for training a neural operator on a large scale domain (960 by 960 pixels). We observe that the model size, data required for generalization, and the number of Fourier modes required quickly becomes intractable with larger domains. We also note that even if enough resources and time make such large scale training possible, it still remains non-trivial to have a scheme work for arbitrary domain sizes, which is one key benefit of our DDM-based approach.\n\n>2.3. Regarding terminology: I was somewhat surprised when I noticed that the authors introduced an additional residual connection alongside the one that already existed. (Please note that point-wise convolution is equivalent to applying a linear layer to each pixel and is a conventional implementation of residual connections when the input and output channel counts do not match.) Have the authors considered replacing the point-wise convolution with a simple identity addition?\n\nAs discussed in point 1.4 above, we have indeed verified that initializing the W matrix with identity matrix (plus a kaiming initialization), is equivalent to the default kaiming initialization plus a residual connection. We have added text in the manuscript to clarify this point.  \n\n>2.4. It's quite unexpected that the original FNO struggles to predict the outputs of not-so-complex subdomains accurately. It would be valuable if the authors could provide additional insights into the specific challenges or limitations the original FNO faces when applied to these cases.\n\nWe certainly agree that the subdomain size (64 by 64 pixels) and square shape are simple, but we also emphasize that the modeling of the highly heterogeneous and high contrast media (epsilon ranging from 1 to 16), together with our consideration of arbitrary boundary conditions, makes our problem very challenging to learn for any FNO.  To add further clarification, we have made the following modifications (all in Figure 3 and Table 1):\n- We applied the correct initialization for the original FNO model, which now performs better and makes for a fairer comparison.\n- We added a subdomain benchmark with 1M total data size and show that due to the heterogeneous grayscale material distribution and arbitrary robin boundary conditions, our dataset is indeed complex enough that large training data size is required for generalization.\n- We also include a benchmark against a recently improved FNO named \u201cFactorized FNO\u201d (which we cited in the first version) to strengthen our argument that input-dependent modulation is crucial in learning complex heterogeneous dataset."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4225/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700723913989,
                "cdate": 1700723913989,
                "tmdate": 1700723913989,
                "mdate": 1700723913989,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5wDCvsRbSk",
            "forum": "bnPALC6S4l",
            "replyto": "bnPALC6S4l",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4225/Reviewer_RuAk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4225/Reviewer_RuAk"
            ],
            "content": {
                "summary": {
                    "value": "# Initial comment\nIn this paper, the authors try to extend the current learning-based PDE surrogate solvers to handle problems with larger scale, more complicated boundaries, and varying parameters, by integrating domain decomposition methods. In each subdomain, the problem is solved by neural operators with extra residual connection and modulation encoders. Experiments on electromagnetic and fluidic flow problems are performed to demonstrate the effectiveness of the proposed model, compared with FNO, UNet, and Swin Transformer.\n\n# After author-reviewer rebuttal\nOverall, thanks very much for your detailed response, enhanced experiments, and modification of the manuscript.\n\n- Thanks for confirming some of the points I provided in the previous review.\n- Thanks for the clarification on how the boundary information is handled in the proposed method.\n\nWith all the factors considered, as well as the fact that a positive score is already given, I decide to remain my original score for now."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- This is one of the earlist works to combine Neural Operators and DDM.\n- The motivation is clear and reasonable, as described at the end of the third paragraph in the Introduction Section."
                },
                "weaknesses": {
                    "value": "- The proposed method will perform self-consistent iterations, introducing extra complexity and convergence issues.\n- The scale and shape of the PDE problems considered in this paper are not complicated enough to be fully convincing to me.\n- The design is relatively straightforward and inflexible, resulting in limitations such as fixed subdomain size and shape."
                },
                "questions": {
                    "value": "- One contribution the paper claimed is that extra residual connection is added to the FNO module. But the original FNO block already contains a parameterized residual connection. From the description in the paper, I understand that it is validated by experiments. But what is the benefit of such design in principle? Specifically speaking, if the W matrix in FNO is initialized as an identity matrix, will there be any difference?\n- I am still not very clear about how the boundary information is fed into SNAP-DDM. A bit more explanation will be appreciated."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4225/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4225/Reviewer_RuAk",
                        "ICLR.cc/2024/Conference/Submission4225/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4225/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699519447375,
            "cdate": 1699519447375,
            "tmdate": 1700747907620,
            "mdate": 1700747907620,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "EERdR6oh14",
                "forum": "bnPALC6S4l",
                "replyto": "5wDCvsRbSk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4225/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4225/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your comment"
                    },
                    "comment": {
                        "value": "Thank you for your review.\n\n>1.1. The proposed method will perform self-consistent iterations, introducing extra complexity and convergence issues.\n\nThe reviewer\u2019s comment on convergence on self-consistent iterations is well-taken. DDM methods are mature iterative methods for solving large scale PDEs, especially elliptical PDEs, and are the basis for parallelizing the solving of PDEs on CPU servers. While there remain theoretical research questions pertaining to the convergence stability of DDM with Maxwell\u2019s Equations, especially in the highly heterogeneous dielectric case, we do ultimately demonstrate stable performance with our method, as demonstrated in Figures 4 and 7 with large scale high dielectric contrast problems.  This type of performance is unprecedented for neural network-based PDE solving.\n\n>1.2.  The scale and shape of the PDE problems considered in this paper are not complicated enough to be fully convincing to me.\n\nWe agree that the size (64 by 64 pixels) and square shape of our targeted subdomains are simple, but our targeted subdomain PDE problem is nonetheless complex and non-trivial because it is highly heterogeneous, contains dielectric constant media (epsilon = 16), and contains fully arbitrary boundary conditions.  Very few demonstrations in the literature involving domains of any size capture this level of complexity. We emphasize that while DDM is well known in the mathematics community, the utilization of a surrogate subdomain solver together with DDM has not been possible until this work due to the accuracy limitations in prior FNO algorithms.  We also make the following modifications to further elucidate the quality of our result (all in Figure 3 and Table 1):\n- We applied the correct initialization for the original FNO model, which now performs better and makes a fairer comparison.\n- We add a subdomain benchmark with 1M total data size, to show that due to the heterogeneous grayscale material distribution and arbitrary Robin boundary conditions, our dataset is indeed complex enough that large training data size is required for generalization.\n- We also include a benchmark against a recently improved FNO named \u201cFactorized FNO\u201d (which we cited in the first version) to strengthen our argument that input-dependent modulation is crucial in learning a complex heterogeneous dataset.\n\n>1.3. The design is relatively straightforward and inflexible, resulting in limitations such as fixed subdomain size and shape.\n\nWe fully note that the subdomain problem size is fixed.  However, the whole point of SNAP-DDM is that we can ultimately tile these subdomain solvers in arbitrary ways to solve large scale problems of arbitrary size, as demonstrated in Figure 4.  This flexibility is a feature of SNAP-DDM and it exceeds the flexibility of all previous neural network surrogate solvers.\n\n>1.4. One contribution the paper claimed is that extra residual connection is added to the FNO module. But the original FNO block already contains a parameterized residual connection. From the description in the paper, I understand that it is validated by experiments. But what is the benefit of such design in principle? Specifically speaking, if the W matrix in FNO is initialized as an identity matrix, will there be any difference?\n\nWe have verified that mathematically, and from our experiments, initializing the W matrix with identity matrix (plus a kaiming initialization), is equivalent to the default kaiming initialization plus a residual connection. We still decide to keep the residual connection in Figure 2 for clarity and we add the following text in Section 2: \u201cWe note that the residual connection is equivalent to initializing the 1x1 convolutional layer W using identity plus Kaiming or Xavier initialization, but we keep the residual connection in Figure 2 for clarity and ease of implementation.\u201d We also updated Figure 3 and Table 1 to have this better initialization for the original FNO benchmark, which makes for a much fairer comparison. We leave the less ideal initialization in the ablation study to show that explicit residual connection (or initialization) is necessary to reliably train deep networks.\n\n>1.5. I am still not very clear about how the boundary information is fed into SNAP-DDM. A bit more explanation will be appreciated.\n\nThe Robin boundary values are inputted into the subdomain models as images with 64x64 pixel dimensions that match the subdomain size.  Boundary values are located at the perimeter of the image and the rest of the pixels interior to the image are set to zero.  We have updated Figure 1 with much clearer indication of inputs and output of each subdomain model, and we have a dedicated section on boundary value update that visualizes how boundaries are extracted, and update to overlapping nearest neighbors.\n\n[1] Li, Zongyi, et al. \"Fourier neural operator with learned deformations for pdes on general geometries.\" arXiv preprint arXiv:2207.05209 (2022)."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4225/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700723554228,
                "cdate": 1700723554228,
                "tmdate": 1700723554228,
                "mdate": 1700723554228,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]