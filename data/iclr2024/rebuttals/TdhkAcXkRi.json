[
    {
        "title": "Momentum Benefits Non-iid Federated Learning Simply and Provably"
    },
    {
        "review": {
            "id": "S0MAhdHonl",
            "forum": "TdhkAcXkRi",
            "replyto": "TdhkAcXkRi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1089/Reviewer_W4SM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1089/Reviewer_W4SM"
            ],
            "content": {
                "summary": {
                    "value": "Under the federated learning paradigm, this work tries to validate the effectiveness of adding a momentum item to local client updating. Specifically, in each communication round, the proposed method will require the center server to broadcast the global gradient information to all clients (along with the updated model parameters). Then, the local clients embed the global gradient information into the local updating steps as a momentum item.\n\nThe strategy is simple and straightforward, just as the title highlighted. Particularly, this work gives detailed proof to validate the effectiveness of the simple strategy, which is appreciated (but with some mistakes). This work also empirically shows the effectiveness of the proposed method through some easy experiments."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The presentation is clear and logically consistent.\nFurthermore, the proposed method, momentum acceleration by transiting the global gradient information to local clients, should be empirically useful and improve practical performance."
                },
                "weaknesses": {
                    "value": "1.\tThe same algorithm has been proposed by multiple works [1,2]. FedCM in [1] is exactly the same as the proposed method, and [1] also gives theoretical guarantees under general convex or non-convex smooth assumptions, it is not the case as this work claimed: \u201cHowever, whether momentum can offer theoretical benefits to FL remains underexplored\u201d.\n\n2.\tThere are mistakes with the proof of the main result (Theorem 1) and implicitly using of extra assumptions, so the correctness of the main results is doubtful. Please check the following Questions 2 and 4.\n\n3.\tThe problem complexity is studied over the convergence rate under the same fixed hardware budget, such as communication cost or memory consumption. However, this work forgets to mention the extra requirement over the communication budget or the local storage.\n(a)\tFirstly, the costs of the downlink communication may be two times more expensive than other methods since the proposed method requires the broadcast of the extra averaged gradient information from the center server to each client, together with the new model parameters.\n(b)\tIf the algorithm tries to maintain the same communication cost, then it can only broadcast the averaged gradient information. But it will require the local client to save a copy of the initial parameters of (r-1)-step, i.e., transferring the global updating step to local clients.\n\n4.\tDespite the doubt about proof, the method itself is not novel. Embedding local or global momentum seems straightforward. Meanwhile, considering the broad application scenarios of FL, the experiment is too simple, which is not valid to show the effectiveness of the method. However, if the proof can be validated, those shortages can be largely mitigated.\n\n[1] Xu J, Wang S, Wang L, et al. Fedcm: Federated learning with client-level momentum[J]. arXiv preprint arXiv:2106.10874, 2021.\n[2] Kim, Geeho, Jinkyu Kim, and Bohyung Han. \"Communication-efficient federated learning with acceleration of global momentum.\" arXiv preprint arXiv:2201.03172 (2022)."
                },
                "questions": {
                    "value": "1.\tI am totally not sure how to build the relationship between \u2207fi(x) and \u2207f(x) without the bounded data heterogeneity assumption. I.e., without the popular bounded data heterogeneity assumption, how the local gradient information contribute to the global convergence? Can you briefly explain it?\n\n2.\tThe second question is independent but may be correlated with the first one. I checked the proof of Theorem 1 (Theorem 11 in the Appendix), and the building of the above relation can track the source back to Lemma 5. However, the very second inequality of the proof of Lemma 5 (Page-14), which builds the above relationship, seems to be wrong to me. Considering the updating step is x^{r+1} = x^{r} \u2013 \u03b3g^{r+1}, the item \u2212\u03b3||\u2207f(x^{r})||2 comes out from nowhere, and the sign of the item \u03b3\u27e8\u2207f(x^{r}),g^{r+1}\u27e9 should be negative, and it is the real descent item.\nThen, without Lemma 5, the most important result in this work, Theorem 1, may be wrong.\n\n3.\tThis work uses Young\u2019s inequality four times (Page 14, 17, 22 and 25), but actually, I am not really sure how to get the derived inequality by applying Young\u2019s inequality each time. Please elaborate on each one.\n\n4.\tThis question is correlated with the Question 1 and 3. Basically, each time when you use the Young\u2019s inequality, you will use the relation, E||x^{r} \u2013 x{r\u22121}||^2 <= \u03b3^{2}E(\u03be_{r-1} + E||\u2207f(x^{r-1})||^{2}) in next step, for example, it has been used to derive the second inequality in Page 22.\nIt is not true to me without any assumptions. Basically, you are saying the averaged gradient can be bounded by the true gradient with some error, this is basically a (new) variant assumption of the assumption you claim you have abandoned (bounded data heterogeneity assumption). I believe you should not abandon the more standard bounded data heterogeneity assumption.\n\n5.\tI checked the mentioned work VRL-SGD that can handle unbounded data heterogeneity. It is not published, and the soundness of the proof is being doubted in the previously peer-reviewing stage. You should be careful to present the conclusions of VRL-SGD as formal results in your work."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1089/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1089/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1089/Reviewer_W4SM"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1089/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698451280208,
            "cdate": 1698451280208,
            "tmdate": 1700600191720,
            "mdate": 1700600191720,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YIVNai2oWt",
                "forum": "TdhkAcXkRi",
                "replyto": "S0MAhdHonl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1089/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1089/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors: Part I"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the comments. All questions have been clarified. We are glad to address any further comments or questions.\n\n\n\n**1. Comparison with FedCM**\n\n\nThanks for pointing this out and bringing FedCM [R1] to our attention. It is indeed the same as our FedAvg-M. We will remove the statements like \"resulting in the new algorithm FedAvg-M\" from our paper. Please note that the main novelty of our paper does not lie in the algorithm development, but in **clarifying the theoretical improvements brought by momentum**. The FedCM paper cannot justify the theoretical benefits by incorporating momentum. \n\nTo resolve the reviewer's concern, we added a detailed comparison with FedCM in the revised paper, see the highlighted paragraph in Page 6. For reviewer's convenience, we repeat the highlighted paragraph as follows:\n\n*FEDAVG-M coincides with the FEDCM algorithm proposed by Xu et al. (2021b). However, our results outperform that of Xu et al. (2021b) in several aspects. First, our convergence only utilizes the standard smoothness of objectives and gradient stochasticity while Xu et al. (2021b) additionally require bounded data heterogeneity and bounded gradients which are rarely valid in practice, suggesting the limitation of their analysis. Second, the convergence established by Xu et al. (2021b) is significantly weaker than ours and cannot even asymptotically approach the ideal rate $O(1/ \\sqrt{NKR})$ in non-convex FL, as demonstrated by the results stated in Table 1.*\n\n\nThe rate comparison established in FedCM and ours are as follows:\n\nFedCM: $\\left(\\frac{L\\Delta ({\\sigma^2}+NK{G}^2)}{NKR}\\right)^{1/2}+\\left(\\frac{L\\Delta ({\\sigma}/{\\sqrt{K}}+G)}{R}\\right)^{2/3}$.\n\nFedAvg-M: $\\left(\\frac{L\\Delta \\sigma^2}{NKR}\\right)^{1/2}+\\frac{L\\Delta}{R}$.\n\nIt is observed that the rate established by FedCM is much weaker than FedAvg-M. \n\n**2. Mistakes in the proof**\n\nPlease check the detailed responses to questions below.\n\n**3. The extra requirement over the communication budget or the local storage**\n\n\nFirst, it is generally true that downlink bandwidth is substantially larger than uplink bandwidth in most practical systems. This significant asymmetry between downlink and uplink capacities suggests that heavier downlink loads may be less problematic compared to lighter uplink loads.\n\nSecond, our FedAvg-M does not incur additional downlink load compared to FedAvg when more memory is available. For practical implementation of FedAvg-M, the server does not need to communicate both $x^{r+1}$ and $g^{r+1}$ simultaneously to clients. If clients can store a model copy $x^r$ locally, by only broadcasting the latest server model $x^{r+1}$ from the server to all clients, clients are able to recover the momentum direction through $g^{r+1}=(x^{r+1}-x^r)/\\gamma$. By employing the equivalent implementation, FedAvg-M does not suffer from a double in downlink communication. \n\nMoreover, we would like to remark that the doubling in local storage is customary for advanced FL algorithms beyond FedAvg, see, e.g., Scaffold [R2], Mime [R3]. In fact, as long as the local update rule is not the vanilla SGD, the double local storage can be inevitable to store optimizer states, e.g., momentum state.  \n\nTo resolve the reviewer's concern, we added comment in Section 3 of the revised paper. The comment is *\"Notably, no extra downlink commmunication cost is needed if clients store the last iterate model $x^r$ so that momentum $g^{r+1}$ can recovered through $(x^{r+1}-x^r)/\\gamma$.\"*\n\n\n**4. The method is not novel and the experiment is too simple**\n\nWe respectively disagree with the reviewer on this point. The main novelty in our paper lies in **proving the theoretical improvements brought by momentum**, not in proposing new momentum variants of FL algorithms. While momentum has been widely used in federated learning empirically, it is still unknown in literature how momentum can benefit federated learning theoretically. Our paper focused on this open question and proved two novel results:\n\n- **Momentum can remove the influence of data heterogeneity**. When all clients participate in FL, momentum enables FedAvg to get rid of the restrictive data heterogeneity assumption without any impractical algorithmic structure. \n\n- **Momentum can theoretically speed up FL algorithm**. We have shown that FedAvg, Scaffold, and their variance-reduced variants with momentum achieve faster convergence rate than without momentum. In fact, all achieved results are state-of-the-art compared to existing algorithms. \n\nWith the above two contributions, we are the **first**, to our best knowledge, to validate the usage of momentum in federated learning in theory, which we believe is a novel and important contribution to the community."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1089/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700454306127,
                "cdate": 1700454306127,
                "tmdate": 1700455259521,
                "mdate": 1700455259521,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oHmSYqEtNW",
                "forum": "TdhkAcXkRi",
                "replyto": "S0MAhdHonl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1089/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1089/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors: Part II"
                    },
                    "comment": {
                        "value": "As for experiments, we have added a new experiment with $N=100$ clients with MNIST dataset in the appendix of the revision, see Figure 5 and 6. The results show that FedAvg-M and Scaffold-M outperform FedAvg and Scaffold by an evident margin when $N=100$, which is closer to the pratical FL setups.\n\nAlso, since FedAvg-M coincides with FedCM. The superior performance of FedCM reported in FedCM paper is also an evidence that momentum can bring significant benefits, which aligns well with our theory. \n\nFinally, we would like to emphasize that the main contribution of our paper is to clarify the theoretical benefits brought by momentum. We hope the reviewer can find our empirical studies have well justified all our theoretical findings. \n### Questions\n`Q1`: How to build the relationship between $\\nabla f_i(x)$ and $\\nabla f(x)$ without the bounded data heterogeneity assumption?\n\nA: We briefly present the high-level idea of FedAvg-M in the full participation setting. Note that when the local learning rate $\\eta\\to 0$ and global learning rate $\\gamma$ is fixed, FedAvg will reduce to minibatch SGD over all the clients, i.e., SGD over $f(x)$ with batch size $NK$. In this case, the heterogeneity assumption $\\zeta$ is known to be unnecessary. Intuitively, in FedAvg-M, our strategy is also to show that the local iterates will not drift too far away from the initialization in each communication round (Lemma 9) if $\\eta$ is properly small with the help of momentum.\n\n`Q2`: Lemma 5 seems incorrect.\n\nA: As pointed out and confirmed by reviewer ELLH in the part of \"Typos\", the second line in Lemma 5 is merely a typo and **does not affect the overall validity**. The correction should be\n$$\nf(x^{r+1})\\leq f(x^r)+\\langle \\nabla f(x^r),x^{r+1}-x^r\\rangle +\\frac{L}{2}\\\\|x^{r+1}-x^r\\\\|^2 = f(x^r)-\\gamma  \\\\|\\nabla f(x^r)\\\\|^2+\\gamma  \\langle \\nabla f(x^r),\\nabla f(x^r)-g^{r+1}\\rangle+\\frac{L\\gamma^2}{2}\\\\|g^{r+1}\\\\|^2.\n$$\nWe have addressed this in our revision.\n\n`Q3`: How to use Young inequality?\n\nA: In page 14, $\\gamma  \\langle \\nabla f(x^r),\\nabla f(x^r)-g^{r+1}\\rangle \\leq \\frac{\\gamma }{2}\\\\|\\nabla f(x^r)\\\\|^2+\\frac{\\gamma }{2} \\\\|\\nabla f(x^r)-g^{r+1}\\\\|^2$. \n\nIn page 17 and 22, $\\mathbb{E} [\\\\|\\nabla f_i(x^r)\\\\|^2] \\leq (1+q)\\mathbb{E}[\\\\|\\nabla f_i(x^{r-1})\\\\|^2]+(1+q^{-1})\\\\| \\nabla f_i(x^r)-\\nabla f_i(x^{r-1})\\\\|^2 \\leq (1+q)\\mathbb{E}[\\\\|\\nabla f_i(x^{r-1})\\\\|^2]+(1+q^{-1})L^2\\mathbb{E}[\\\\|x^r-x^{r-1}\\\\|^2]$.\n\nIn page 25, $\\left(1-\\frac{S}{N}\\right)\\frac{1}{N}\\sum_{i=1}^N\\mathbb{E}[\\\\|c_i^r-\\nabla f_i(x^r)\\\\|^2]\\leq \\left(1-\\frac{S}{N}\\right)\\frac{1}{N}\\sum_{i=1}^N\\mathbb{E}\\left[\\left(1+\\frac{S}{2N}\\right)\\\\|c_i^r-\\nabla f_i(x^{r-1})\\\\|^2+\\left(1+\\frac{2N}{S}\\right)\\\\| \\nabla f_i(x^r)-\\nabla f_i(x^{r-1})\\\\|^2\\right]$ and $\\\\| \\nabla f_i(x^r)-\\nabla f_i(x^{r-1})\\\\|^2 \\leq L^2\\\\|x^r-x^{r-1}\\\\|^2$.\n\n`Q4`: About the second inequality in page 22 $\\mathbb{E}||x^{r} \u2013 x^{r\u22121}||^2 \\leq 2\\gamma^{2}\\mathbb{E}(\\mathcal{E}_{r-1} + \\mathbb{E}||\\nabla f(x^{r-1})||^{2})$.\n\nA: First, we would like to emphasize that **we did not use any additional assumption**. Note that by the definition of $\\mathcal{E}_{r-1}$ in the beginning of Appendix A, we have \n\n$\\mathbb{E}\\\\|x^r-x^{r-1}\\\\|^2 = \\gamma^2\\mathbb{E}\\\\|g^r\\\\|^2 \\leq 2\\gamma^2 \\mathbb{E}(\\\\|g^r-\\nabla f(x^{r-1})\\\\|^2 + \\\\|\\nabla f(x^{r-1})\\\\|^2) = 2\\gamma^2 (\\mathcal{E}_{r-1}+\\mathbb{E}[\\\\|\\nabla f(x^{r-1})\\\\|^2])$.\n\nAnd we derive a recursive bound for $\\mathcal{E}_{r-1}$ in Lemma 8. Therefore, we do not need the bounded heterogeneity assumption.\n\n`Q5`: About VRL-SGD.\n\nA: Thanks for pointing this out and we have made additional comments on the work in our revision, as highlighted in the red color in Table 1. For reviewer's convenience, we repeat the comments as follows: \n*The works have not been published in peer-reviewed venues.*\n\nWe hope the above clarification can relieve the reviewer's concern. We believe our paper makes a novel and important contribution to the community on understanding the theoretical benefits of momentum in federated learning, which has never been clarified before. We are happy to address any further questions or commmens from the reviewer.\n\n[R1] Xu, Jing, et al. \u2018Fedcm: Federated Learning with Client-Level Momentum\u2019. arXiv Preprint arXiv:2106. 10874, 2021.\n\n[R2] Karimireddy, Sai Praneeth, Satyen Kale, et al. \u2018Scaffold: Stochastic Controlled Averaging for Federated Learning\u2019. International Conference on Machine Learning, PMLR, 2020, pp. 5132\u20135143.\n\n[R3] Karimireddy, Sai Praneeth, Martin Jaggi, et al. \u2018Mime: Mimicking Centralized Stochastic Algorithms in Federated Learning\u2019. arXiv Preprint arXiv:2008. 03606, 2020."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1089/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700454792491,
                "cdate": 1700454792491,
                "tmdate": 1700455288035,
                "mdate": 1700455288035,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kobecsSX9b",
                "forum": "TdhkAcXkRi",
                "replyto": "3iQ4nYYyET",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1089/Reviewer_W4SM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1089/Reviewer_W4SM"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for rebuttal"
                    },
                    "comment": {
                        "value": "Dear authors, \n\nThank you for the detailed rebuttal and it did resolve some of my concerns, and I would like to raise my score. However, I have some follow-up comments still.\n\nGiven the definition $\\xi_{r}: = \\mathbb{E}[|| \\nabla f(x^{r}) - g^{r+1} ||^{2}]$ in your proof and your replying, I believe it is a formal assumption instead of an \u201cauxiliary variables to facilitate proofs\u201d.\n\nFor example, the very commonly used assumption bounded variance $\\mathbb{E}[||g - \\nabla f(x)||^{2}] \\leq \\sigma^{2}$, which is the key in the convergence analysis since it builds the relationship between stochastic gradient and ground-truth gradient. Your current definition potentially implies a similar assumption that the difference between stochastic gradient and ground-truth gradient is upper-bounded.\n\nA quick question: does the result still hold when $\\xi = \\infty$?\nI think your result does not hold when $\\xi = \\infty$, such as Lemma 8, so you are assuming a \u201cbounded variance\u201d assumption, which is basically similar to the standard one, bounded data heterogeneity."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1089/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700600124392,
                "cdate": 1700600124392,
                "tmdate": 1700600124392,
                "mdate": 1700600124392,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dJL9ebq120",
                "forum": "TdhkAcXkRi",
                "replyto": "S0MAhdHonl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1089/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1089/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the follow-up question. We use $\\xi$ to denote the random data sampled per iteration within each client and use  $\\mathcal{E}_r = \\mathbb{E}[\\|\\nabla f(x^r) - g^{r+1}\\|^2]$ throughout the manuscript. We believe the reviewer meant to ask for the clarification regarding the latter one. \n\n\nThe reviewer has misunderstood the term $\\mathcal{E}_r = \\mathbb{E}[\\\\|\\nabla f(x^r) - g^{r+1}\\\\|^2]$. **This term is NOT an assumption**. We do not need to assume the boundedness of $\\mathbb{E}[\\\\|\\nabla f(x^r) - g^{r+1}\\\\|^2]$. Instead, **its boundedness can be derived rigorously** buildng upon the standard objective smoothness (i.e., Assumption 1) and stochastic gradients (i.e., Assumption 3). Specifically, we have shown in the proof of Theorem 11 that \n\n$$\n\\sum_{r=0}^{R-1}\\mathcal{E}\\_r\\leq \\frac{9}{7\\beta }\\mathcal{E}\\_{-1} + \\frac{2}{7}\\mathbb{E} [\\sum_{r=-1}^{R-2}\\\\|\\nabla f(x^{r})\\\\|^2] + \\frac{144}{7}(e\\beta \\eta KL)^2G_0 R+ \\frac{36\\beta \\sigma^2}{7NK}R\n$$\n\nwhere $G_0=\\sum_{i=1}^N\\\\|\\nabla f_i(x^0)\\\\|^2/N$ and $\\mathcal{E}_{-1} = \\\\|\\nabla f(x^0) - g^{0}\\\\|^2$ are all constants by definition. By combining this with Lemma 5, we have \n\n$$\\frac{1}{7} \\sum_{r=0}^{R-1} \\mathbb{E}\\left[\\left\\\\|\\nabla f\\left(x^r\\right)\\right\\\\|^2\\right] \\leq \\frac{1}{\\gamma} \\mathbb{E}\\left[f\\left(x^0\\right)-f^\\star\\right] +\\frac{39}{56 \\beta} \\mathcal{E}_{-1}+\\frac{78}{7}(e \\beta \\eta K L)^2 G_0 R+\\frac{39 \\beta \\sigma^2}{14 N K} R,$$\n\nwhich reveals that $\\mathbb{E} [\\sum_{r=-1}^{R-2}\\\\|\\nabla f(x^{r})\\\\|^2]/R$ is bounded provided with properly small  $\\eta$ and $\\beta$. This, in turn, reveals that $\\sum_{r=0}^{R-1}\\mathcal{E}_r/R$ is bounded is the averaged sense, which is sufficient to attain the ultimate convergence rate. **It is guaranteed that $\\mathcal{E}_r$ cannot go to $+\\infty$, in the averaged sense**.\n\n\nAgain, We would also like to emphasize that no additional assumption regarding the *data heterogeneity*, i.e., $\\sup_x \\frac{1}{N}\\sum_{i=1}^N\\\\|\\nabla f_i(x)-\\nabla f(x)\\\\|^2$, is needed in our paper due to the usage of momentum, which is a non-trival contribution to the community. \n\nWe hope this can address your concern. We are glad to have further discussion on this point."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1089/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700634682013,
                "cdate": 1700634682013,
                "tmdate": 1700654789953,
                "mdate": 1700654789953,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7kDdQ79Z2p",
            "forum": "TdhkAcXkRi",
            "replyto": "TdhkAcXkRi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1089/Reviewer_CZuh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1089/Reviewer_CZuh"
            ],
            "content": {
                "summary": {
                    "value": "This paper explores the application of momentum to enhance the performance of FEDAVG and SCAFFOLD, two leading federated learning algorithms. It achieves a faster convergence without relying on the bounded data heterogeneity assumptions and introduces new variance-reduced extensions, exhibiting state-of-the-art convergence rates."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This paper is easy to follow.\n2. The incorporation of momentum enhances the convergence rates of both FedAvg and SCAFFOLD. And this improvement has been substantiated through both theoretical analysis and experimental validation."
                },
                "weaknesses": {
                    "value": "1. The final convergence rate achieved by the authors does not sufficiently account for the impact of the momentum coefficient. Please clarify this issue.\n2. In fact, FedDyn [1] demonstrates a faster convergence rate compared to the authors' findings in this paper, which is also without the need of clients\u2019 variance assumptions. This observation may highlight the potential limitations in the author's theoretical contributions.\n3. The authors' work seriously lacks comparative experiments, including comparison with various momentum-based federated algorithms [2].\n4. The author's experimental work lacks a comprehensive discussion of a key hyperparameter, momentum coefficient.\n\n[1] Acar, Durmus Alp Emre, et al. \"Federated learning based on dynamic regularization.\"  ICLR, 2021.\n\n[2] Reddi, Sashank, et al. \"Adaptive federated optimization.\" ICLR, 2021."
                },
                "questions": {
                    "value": "This paper lacks a comprehensive discussion regarding the limitations of the proposed algorithms. It is evident, for instance, that SCAFFOLD exhibits a suboptimal performance at very low sampling rates [2], leaving uncertainty regarding the extent to which the authors' improved algorithm can address this issue.\n\nPost-rebuttal Comments:\nI would like to thank the authors for their responses. Many of my concerns have been addressed, including both the theoretical and experimental analyses of the hyperparameter $\\beta$. But I may still be a little concerned with the authors' claims on their theoretical contributions of the convergence, which is particularly defeated by the faster convergence rate achieved by FedDyn (though FedDyn requires a clients\u2019 solution optimizer). Overall, I would raise my score to 5."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1089/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1089/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1089/Reviewer_CZuh"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1089/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698810553939,
            "cdate": 1698810553939,
            "tmdate": 1701056419220,
            "mdate": 1701056419220,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dAQZiGzTuy",
                "forum": "TdhkAcXkRi",
                "replyto": "7kDdQ79Z2p",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1089/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1089/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the comments. All questions have been clarified. We are glad to address any further comments or questions.\n\n**1. Influence of momentum coefficient**\n\nThe momentum coefficient does not appear in the final convergence rate because we have **set up a concrete and proper value for $\\beta$** when deriving the convergence rate. For example, when establishing the convergence of FedAvg-M in Theorem 11 in the appendix, we first prove that\n\n$$\\frac{1}{R}\\sum_{r=0}^{R-1}\\mathbb{E}\\|\\nabla f(x^r)\\|^2 = O\\left(\\frac{L\\Delta}{R} + \\frac{L\\Delta}{\\beta R} + \\frac{\\beta \\sigma^2}{NK} + (\\beta \\eta K L)^2 G_0\\right)$$\n\nwhich reflects how $\\beta$ would influence the convergence rate. When we set $\\beta = O(\\sqrt{\\frac{NKL\\Delta}{\\sigma^2 R}})$ and let $\\eta \\beta L$ be sufficiently small (see Theorem 11 for the value of $\\eta \\beta L$), we can simplify the convergence rate as\n\n$$\\frac{1}{R}\\sum_{r=0}^{R-1}\\mathbb{E}\\|\\nabla f(x^r)\\|^2 = O\\left(\\sqrt{\\frac{L \\Delta \\sigma^2}{NKR}} + \\frac{L\\Delta}{R}\\right)$$\n\nwhich is the SOTA convergence rate. Notably, we remark the above annealing $\\beta$ is mainly set for theory purpose. \n\nIn practice, we found a proper constant value (e.g., $\\beta=0.5, 0.2$) is also capable to attain substantial improvement, as demonstrated by our experiments.\n\n**2. FedDyn and our algorithms are not comparable**\n\nWe respectively disagree with the comments that FedDyn demonstrates faster convergence rate than our proposed algorithms. **FedDyn and our algorithm belong to different algorithm families, and they are using different oracles in local updates.** Our algorithm use the standard stochastic gradient oracle in local updates, while FedDyn relies on the black-box oracle that gives the exact solutions to local optimization problems (see line 5 in Algorithm 1 of FedDyn). Note that the local optimization problem is generally intractable (particularly for non-convex functions) and thus the oracle required by FedDyn is usually impractical, which outweighs its benefits in convergence if any. If the local optimization problem is not solved exactly, it is not known whether the current rate in FedDyn still hold. For this reason, we believe FedDyn and our algorithms are not comparable. The convergence rate of FedDyn does not hurt our theoretical contribution.\n\n**3. Empirical comparison with federated adaptive algorithms**\n\nWe thank the reviewer for bringing up the federated adaptive algorithms. However, the main contribution in our paper is to clarify the theoretical improvements brought by introducing momentum to FL algorithms. This goal, to our knowledge, has not been achieved by [R1] or any other literature.\n\nAgain, we are not aiming to develop adaptive algorithms that can outperform any federated adaptive algorithms in [R1] empirically. All of our experiments are conducted to validate our theoretical findings, i.e., momentum can help remove the influence of data heterogeneity and enhance the convergence rate. Whether our algorithms can outperform [R1] or not does not provide direct evidence to our theoretical findings. We hope the reviewer can understand that the comparison between our algorithms and adaptive algorithms in [R1] is not necessary and beyond the scope of our paper. \n\n**4. Experiments on different $\\beta$**\n\nAs illustrated in the descriptions of algorithms, when $\\beta=1$, ours will reduce to vanilla FedAvg or Scaffold. And in the experiments, we have shown the difference between $\\beta=1$ and other constants, i.e. between the non-momentum variant and the momentum variant. Also, we supplement an ablation study on different choices of $\\beta\\in (0, 1)$ in the appendix of revision. The results suggest that stronger momentum can lead to better practical performance, see Figures 7 and 8 in Section D.5 in the appendix.\n\n**5. Scaffold with low sampling rate**\n\nWe thank the reviewer for the sharp observation. When the number of sampled clients $S$ is far less than the number of all clients $N$, i.e., $S \\ll N$, all federated learning algorithms listed in Table 2 will suffer from slower convergence, see their rates in Table 2. It implies that slow convergence in the scenario with a low client-sampling ratio is a common issue in federated learning. \n\nHowever, incorporating momentum does bring some benefits. For example, incorporating momentum has improved Scaffold's convergence rate from $O(\\sqrt{\\frac{L \\Delta \\sigma^2}{S K R}} + \\frac{L \\Delta}{R}(N/S)^{2/3})$ to $O(\\sqrt{\\frac{L \\Delta \\sigma^2}{S K R}} + \\frac{L \\Delta}{R}(N^{2/3}/S))$, which quantitively illustrates that momentum indeed accelerates the rate. \n\nWe hope the above clarification can relieve the reviewer's concerns. We believe our paper makes a novel and important contribution to the community on understanding the theoretical benefits of momentum in federated learning, which has never been clarified before. \n\n[R1] Reddi, Sashank, et al. \u2018Adaptive Federated Optimization\u2019. arXiv Preprint arXiv:2003. 00295, 2020."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1089/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700454149232,
                "cdate": 1700454149232,
                "tmdate": 1700454149232,
                "mdate": 1700454149232,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "g45b1bQZcN",
            "forum": "TdhkAcXkRi",
            "replyto": "TdhkAcXkRi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1089/Reviewer_ELLH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1089/Reviewer_ELLH"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the impact of adding a simple momentum term to standard Federated Learning algorithms (namely, FedAVG and SCAFFOLD) to mitigate client drift by \"anchoring\" local gradients closer to an estimate of the gradient of the global function computed at the server side. State-of-the-art convergence rates are obtained in the non-convex and smooth setting, without relying on the common assumption of bounded data heterogeneity. Variance-reduced extensions of the algorithms are also studied. Baseline empirical evaluations of the methods are provided with a three-layer MLP and a ResNet18 on CIFAR-10, hinting that the introduced momentum term does indeed help generalizing on test data."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* **SOTA CV rates:** State-of-the-art convergence rates are obtained for the introduced methods.\n* **No data heterogeneity assumption**: The proof technique gets rid of the bounded data heterogeneity assumption, improving theoretical convergence rates and hinting that the method mitigates the impact of arbitrary data heterogeneity.\n* **No additional uplink load**: The introduced momentum term is simple, its effect is intuitive to understand, and does not lead to any additional client to server communication.\n* **Constant step-size:** If the training is sufficiently long ($R$ sufficiently high), the theoretical analysis allows for a constant step size for the stochastic gradients (contrary to vanishing ones standard in the literature).\n* **VR variants:** Variance-reduced variants of the methods are presented and analyzed."
                },
                "weaknesses": {
                    "value": "* **Algorithm not new**: Contrary to what is claimed in section 3.1 (*\"resulting in the new algorithm FEDAVG-M\"*), the added momentum is not new: FedCM [[1]](https://arxiv.org/pdf/2106.10874.pdf) is exactly the same algorithm as FedAVG-M, although their theoretical analysis does use the bounded heterogeneity assumptions. Comparison with FedCM rates is lacking in Table 1.\n* **Surprising rates for the VR variants**: [[2]](https://link.springer.com/article/10.1007/s10107-022-01822-7) states that *\"every randomized algorithm requires $\\mathcal O \\left( \\frac{\\Delta L \\sigma}{\\epsilon^3} + \\frac{\\Delta L}{\\epsilon^2} + \\frac{\\sigma^2}{\\epsilon^2} \\right)$  oracle queries\"*, however, the rate reported in Table 1 and Theorem 2 for FedAVG-M-VR seems to improve on this lower bound as a it leads to an oracle complexity of $\\mathcal O \\left( \\frac{\\Delta L \\sigma}{NK \\epsilon^3} + \\frac{\\Delta L}{\\epsilon^2} \\right)$. Setting aside the variance-reduction effect of running a distributed algorithm (leading to the $NK$ term), is it normal to get rid of the $\\frac{\\sigma^2}{\\epsilon^2}$ term or am I wrongly worried ? (This question also holds for the VR version of SCAFFOLD-M)\n* **Experiments seem light:** A value of $N=10$ is pretty low for the standards of the literature in Federated Learning (see, e.g., experiments in [1] where a value of $N=100$ is used), especially since a different behavior for the optimization algorithms can be expected at scale in the partial participation setting (see, e.g. [[3]](https://arxiv.org/abs/2102.02079 ) ). Are the runs averaged over several random seeds ?\n* **Additional downlink load**: Although no additional client-to-server communication is necessary, the server-to-client communications are doubled in size with the addition of the momentum for FedAVG-M.\n* **Lacking discussion on link between $R$ and $\\beta$**: While a constant step-size can be considered for sufficiently high values of $R$, the direct corollary is that, before that regime arrives, Theorem 1 sets a value of $\\beta=1$, meaning that the theory seems to predict that the momentum could only be used for sufficiently long training. However, experiments in Fig. 2 seem to show that using a momentum would help even if the training stopped early.\n\n\n\n[1] Jing Xu and Sen Wang and Liwei Wang and Andrew Chi-Chih Yao, *FedCM: Federated Learning with Client-level Momentum*, ArXiv eprint 2106.10874, 2021.\n\n[2] Arjevani, Yossi, Carmon, Yair, Duchi, John C., Foster, Dylan J., Srebro, Nathan and Woodworth, Blake. *Lower bounds for non-convex stochastic optimization*, Mathematical Programming, 2023.\n\n[3] Li, Qinbin and Diao, Yiqun and Chen, Quan and He, Bingsheng. *Federated Learning on Non-IID Data Silos: An Experimental Study*, 2022 IEEE 38th International Conference on Data Engineering (ICDE)."
                },
                "questions": {
                    "value": "* Does the performances of adding a momentum scales to settings with greater values of $N$ ? (Or does scaling leads to a collapses as could be observed for SCAFFOLD, see Fig.10 of [[3]](https://arxiv.org/abs/2102.02079 ) )? \n* Although the last sentence of section 1.2 states *\"The analysis presented in this work distinguishes from [[4]](https://arxiv.org/abs/2305.15155)\"*, [[4]](https://arxiv.org/abs/2305.15155) state in their paper that *\"We also hope that our proof techniques can be useful to establish linear speedup for other classes of distributed methods, e.g, algorithms based on local training such as SCAFFOLD and ProxSkip without relying on data similarity assumptions.\"* Thus, it raises the question: how different is your analysis from [[4]](https://arxiv.org/abs/2305.15155) ?\n\n**Typos:**\n\n* after equation (1): *\"represents a~n~ global gradient\"*.\n* Second line of the proof of Lemma 5: the scalar product seems to be missing a term, shouldn't it rather read $\\gamma \\langle \\nabla f(x^r), \\nabla f(x^r) - g^{r+1} \\rangle$  ? (this does not impact the following lines)\n\n\n**Final comment:**\n\nI recognize the interest of the theoretical contributions of this paper, thus, I am ready to increase my score if my concerns concerning the convergence rates and the experiments are correctly addressed.\n\n[4] Ilyas Fatkhullin and Alexander Tyurin and Peter Richt\u00e1rik. *Momentum Provably Improves Error Feedback!* ArXiv eprint 2305.15155, 2023.\n\n=== **After Rebuttal** ===\n\nMy concerns and questions were correctly addressed by the authors, I subsequently raise my score and recommend to accept this paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1089/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1089/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1089/Reviewer_ELLH"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1089/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698820821668,
            "cdate": 1698820821668,
            "tmdate": 1700513973533,
            "mdate": 1700513973533,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ihHc8umKrd",
                "forum": "TdhkAcXkRi",
                "replyto": "g45b1bQZcN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1089/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1089/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors: Part I"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the detailed comments. All questions have been clarified. We are glad to address any further comments or questions.\n\n**1. Comparison with FedCM**\n\nThanks for bringing FedCM to our attention. It is indeed the same as our FedAvg-M. We will remove the statements like \"resulting in the new algorithm FedAvg-M\" from our paper. Please note that the main novelty of our paper does not lie in the algorithm development, but in **clarifying the theoretical improvements brought by momentum**. The FedCM paper cannot justify the theoretical benefits by incorporating momentum. \n\nTo resolve the reviewer's concern, we added a detailed comparison with FedCM in the revised paper, see the highlighted paragraph in Page 6. For reviewer's convenience, we repeat the highlighted paragraph as follows:\n\n*FEDAVG-M coincides with the FEDCM algorithm proposed by Xu et al. (2021b). However, our results outperform that of Xu et al. (2021b) in several aspects. First, our convergence only utilizes the standard smoothness of objectives and gradient stochasticity while Xu et al. (2021b) additionally require bounded data heterogeneity and bounded gradients which are rarely valid in practice, suggesting the limitation of their analysis. Second, the convergence established by Xu et al. (2021b) is significantly weaker than ours and cannot even asymptotically approach the ideal rate $O(1/ \\sqrt{NKR})$ in non-convex FL, as demonstrated by the results stated in Table 1.*\n\n\nThe rate comparison established in FedCM and ours are as follows:\n\nFedCM: $\\left(\\frac{L\\Delta ({\\sigma^2}+NK{G}^2)}{NKR}\\right)^{1/2}+\\left(\\frac{L\\Delta ({\\sigma}/{\\sqrt{K}}+G)}{R}\\right)^{2/3}$.\n\nFedAvg-M: $\\left(\\frac{L\\Delta \\sigma^2}{NKR}\\right)^{1/2}+\\frac{L\\Delta}{R}$.\n\nIt is observed that the rate established by FedCM is much weaker than FedAvg-M. \n\n**2. VR rates**\n\nThanks for the sharp observation. **There is no mismatch between our rate and that in [R1]. The difference lies in the number of data batches used in the initialization stage** (i.e., the the number of data batches in the very first iteration). In the paper we set initial number of batches $B$ as $\\Theta\\left((NKR)^{1/3}(\\frac{\\sigma^2}{L\\Delta})^{4/3}\\right)$ for simplicity so we can get rid of the additional $\\sigma^2/\\epsilon^2$ term. On the other hand, if we set initial batch size as $\\Theta(NKR)$ as constrained by the setup in [R1], our rate will match the lower bound stated in [R1]. \n\nTo resolve the reviewer's concern, we also considered the setting with initial batch size $\\Theta(NKR)$ and derived the convergence rate, see Theorem 15 and Theorem 22 in the revised paper. We also list the new convergence rate in Table 1. For reviewer's convenience, we put the comparison in FedAvg-M-VR as follows:\n\n\nFor initial batchsize $B=\\Theta\\left((NKR)^{1/3}(\\frac{\\sigma^2}{L\\Delta})^{4/3}\\right)$, the rate is $\\left(\\frac{L\\Delta \\sigma}{NKR}\\right)^{2/3}+\\frac{L\\Delta}{R}$.\nFor initial batchsize $B=\\Theta(NKR)$, the rate is $\\left(\\frac{L\\Delta \\sigma}{NKR}\\right)^{2/3}+ \\frac{\\sigma^2}{NKR}+\\frac{L\\Delta}{R}$.\n\n\n**3. More experiments**\n\nThanks for the advice. Due to the hardware resource limitation and tight rebuttal deadline, we cannot afford an experiment with $N=100$ with Cifar-10 dataset at this stage. Instead, we have conducted experiments with $N=100$ clients with MNIST dataset in the appendix of the revision, see Figure 5 and 6. The results show that FedAvg-M and Scaffold-M outperform FedAvg and Scaffold by an evident margin when $N=100$. \n\nAlso, since FedAvg-M coincides with FedCM. The superior performance of FedCM reported in FedCM paper is also an evidence that momentum can bring significant benefits, which aligns well with our theory. Finally, we would like to emphasize that the main contribution of our paper is to clarify the theoretical benefits brought by momentum. The empirical studies are mainly to confirm our theoretical findings."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1089/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700453733607,
                "cdate": 1700453733607,
                "tmdate": 1700455226686,
                "mdate": 1700455226686,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MmBups0jB3",
                "forum": "TdhkAcXkRi",
                "replyto": "g45b1bQZcN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1089/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1089/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors: Part II"
                    },
                    "comment": {
                        "value": "**4. Downlink load**\n\nFirst, it is generally true that downlink bandwidth is substantially larger than uplink bandwidth in most practical systems. This significant asymmetry between downlink and uplink capacities suggests that heavier downlink loads may be less problematic compared to lighter uplink loads.\n\nSecond, our FedAvg-M does not incur additional downlink load compared to FedAvg when more memory is available. For practical implementation of FedAvg-M, the server does not need to communicate both $x^{r+1}$ and $g^{r+1}$ simultaneously to clients. If clients can store a model copy $x^r$ locally, by only broadcasting the latest server model $x^{r+1}$ from the server to all clients, clients are able to recover the momentum direction through $g^{r+1}=(x^{r+1}-x^r)/\\gamma$. By employing the equivalent implementation, FedAvg-M does not suffer from a double in downlink communication.\n\nTo resolve the reviewer's concern, we added comment in Section 3 of the revised paper. The comment is *\"Notably, no extra downlink commmunication cost is needed if clients store the last iterate model $x^r$ so that momentum $g^{r+1}$ can recovered through $(x^{r+1}-x^r)/\\gamma$.\"* \n\n**5. Link between $R$ and $\\beta$**\n\nIn Theorem 1 we set $\\beta=1$ when $R$ is small for simplicity. However, we remark that $\\beta$, in principle, can be any $\\Theta(1)$ constant that is less than $1$ instead of being exactly $1$. The convergence rates will not affected by this choice, which can be easily derived with very minor modifications to the proof.\n\nTo resolve the reviewer's concern, we have revised the choise of $\\beta$ in Theorems 1, 11, 15, 19 and 22. \n\n**6. Momentum scales with more clients**\n\nThanks for raising this very interesting question. Based on our theories, the incorporation of momentum (once properly tuned) scales well when more clients participate in FL with the linear speedup term $O(1/\\sqrt{NKR})$. With our new experiments with $N=100$, we do not observe the collapse of Scaffold-M. Once we have more computational recourse and allowed time, we will conduct more expereiments to examine it. \n\n\n**7. Difference from [R4]**\n\n[R4] focuses on communication compression in distributed optimization and does not involve any fundamental characteristic of FL, i.e. local updates and partial participation. Therefore, our analysis is fundamentally different from [R4]. On the other hand, we propose momentum to handle the effect of client drift in local iterations, which is beyond the scope of [R4]. We don't think there is a direct connection between our analysis and [R4] except for the usage of momentum in algorithmic development. \n\n**8. References**\n\nWe thank the reviewer for bringing various relevant references to our attention. We have cited them properly and added corresponding discussions in the revised paper.\n\n\n[R1] Arjevani, Yossi, Carmon, Yair, Duchi, John C., Foster, Dylan J., Srebro, Nathan and Woodworth, Blake. Lower bounds for non-convex stochastic optimization, Mathematical Programming, 2023.\n\n[R2] Karimireddy, Sai Praneeth, Satyen Kale, et al. \u2018Scaffold: Stochastic Controlled Averaging for Federated Learning\u2019. International Conference on Machine Learning, PMLR, 2020, pp. 5132\u20135143.\n\n[R3] Karimireddy, Sai Praneeth, Martin Jaggi, et al. \u2018Mime: Mimicking Centralized Stochastic Algorithms in Federated Learning\u2019. arXiv Preprint arXiv:2008. 03606, 2020.\n\n[R4] Fatkhullin, Ilyas, et al. \u2018Momentum Provably Improves Error Feedback!\u2019 arXiv Preprint arXiv:2305. 15155, 2023.\n\nWe thank the reviewer again for the careful and valuable comments. We hope these response can clarify the reviewer's questions. We are looking forward to the follow-up discussion, and more than happy to address any further comments or questions."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1089/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700453779330,
                "cdate": 1700453779330,
                "tmdate": 1700455240356,
                "mdate": 1700455240356,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lWdsPT6LTK",
                "forum": "TdhkAcXkRi",
                "replyto": "g45b1bQZcN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1089/Reviewer_ELLH"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1089/Reviewer_ELLH"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their detailed answers.\n\nGiven that:\n* They recognized the existence of FedCM and added a comparison of convergence rates in Table 1, as well as added a discussion paragraph in their main paper,\n* They clarified my concern about their convergence rate of the VR versions, and added those clarifications in the paper,\n* They added more experiments to show that FedAVG-M is indeed helping at scale,\n* They corrected my statement by remarking that no additional downlink communications are needed for a small memory overhead on the clients' part,\n* They clarified my concern about the use of momentum for low training rounds $R$,\n* The fact that, upon a second quick check of the proof of their Theorem 1, I did not see any blatant error in their derivations, making me confident about the validity of their result,\n\nand, most importantly, given that the theoretical contributions of this paper on showing the ability of a simple momentum term to provably help federated optimization without relying on the bounded heterogeneity assumption seems to be of high interest for the community,\n\nI subsequently raise my score and support fully the acceptance of the paper.\n\nI would, however, point out that more experiments on CIFAR-10 with ResNets to discuss the scaling properties of the momentum versions of the algorithms as well as the proper tuning of it when scaling in less of a \"toy scenario\" would strengthen the paper."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1089/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700513982709,
                "cdate": 1700513982709,
                "tmdate": 1700514127194,
                "mdate": 1700514127194,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ib2oHVna9s",
            "forum": "TdhkAcXkRi",
            "replyto": "TdhkAcXkRi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1089/Reviewer_XBW2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1089/Reviewer_XBW2"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on the FedAvg and SCAFFOLD algorithm in federated learning. In literature, many works that analyze the performance of these two algorithms have to rely on bounded heterogeneity assumptions, which is unrealistic. In this works, momentum methods is employed to solve the data heterogeneity issue in federated learning. Without any other modification on Fedavg and SCAFFOLD, plain SGD with momentum updates can achieve similar convergence rate as literature. Furthermore, this work show that in the setting of partial client participation, momentum update can accelerate convergence."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This work overcomes one of the most common problem in FL analysis, the data heterogeneity issue. Although a lot of works in literature analyzes the convergence result of the two algorithm, most of the works have bounded heterogeneity assumptions. This is the most basic problem in FL analysis. This work utilizes momentum method to overcome the difficulty.\n2. The experiment result is encouraging and directly validate the theory."
                },
                "weaknesses": {
                    "value": "The major concern is novelty. FedAvg and SCALFFOLD are well-known methods in FL. Momentum method is also a popular optimization algorithm. Thus the algorithm design lacks novelty. Further, some work has analyzed the performance of FedAvg with Adam update, e.g, Reddi, Sashank, et al. \"Adaptive federated optimization.\" arXiv preprint arXiv:2003.00295 (2020). Adam algorithm is closely related to SGD with momentum, thus the proposed analysis lacks novelty."
                },
                "questions": {
                    "value": "What is the major difference or difficulty of SGD momentum analysis compared to Adam algorithm? Reddi, Sashank, et al. \"Adaptive federated optimization.\" arXiv preprint arXiv:2003.00295 (2020)"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1089/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699412235359,
            "cdate": 1699412235359,
            "tmdate": 1699636035016,
            "mdate": 1699636035016,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vl3SF6L7m0",
                "forum": "TdhkAcXkRi",
                "replyto": "ib2oHVna9s",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1089/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1089/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the comments. All questions have been clarified. We are glad to address any further comments or questions.\n\n**1. Novelty**\n\nThe main novelty in our paper lies in **proving the theoretical improvements brought by momentum**, not in proposing new momentum variants of FL algorithms. While momentum has been widely used in federated learning empirically, it is still unknown in literature how momentum can benefit federated learning theoretically. Our paper focused on this open question and proved two novel results:\n\n- **Momentum can remove the influence of data heterogeneity**. When all clients participate in FL, momentum enables FedAvg to get rid of the restrictive data heterogeneity assumption without any impractical algorithmic structure. \n\n- **Momentum can theoretically speed up FL algorithm**. We have shown that FedAvg, Scaffold, and their variance-reduced variants with momentum achieve faster convergence rate than without momentum. In fact, all achieved results are state-of-the-art compared to existing algorithms. \n\nWith the above two contributions, we are the **first**, to our best knowledge, to validate the usage of momentum in federated learning in theory, which we believe is a novel and important contribution to the community. \n\n\n**2. Comparison with federated ADAM**\n\nReference [R1] is a great and influential paper. However, **it does not provide sufficient theoretical justification for the benefits brought by momentum**. [R1] primarily focuses on proving convergence guarantees, but does not clearly explicate the advantages of using momentum and adaptability. Its analysis is limited in that it does not clarify whether and how momentum can relax restrictive assumptions or improve convergence rates. The major novelty in our analysis is to utilize new analytical techniques to clarify that momentum can relieve data heterogeneity assumption and speed up  convergence theoretically. \n\nThere are also several important technical differences between [R1] and our paper.  First, the analysis in [R1] relies on the impractical and restrictive assumptions of bounded gradient and bounded client variance, which can significantly simplify their analysis. In our analysis, we have relaxed all these assumptions. Second, the algorithm in [R1] use vanilla SGD in local updates (see Algorithm 2 in [R1]), while our paper incorporates momentum in local updates, which also cause significant difference in analysis.\n\nWe hope the above clarification can relieve the reviewer's concern on the novelty. We believe our paper makes a novel and important contribution to the community on understanding the theoretical benefits of momentum in federated learning, which has never been clarified before. \n\n[R1] Reddi, Sashank, et al. \u2018Adaptive Federated Optimization\u2019. arXiv Preprint arXiv:2003. 00295, 2020."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1089/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700453445544,
                "cdate": 1700453445544,
                "tmdate": 1700453445544,
                "mdate": 1700453445544,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "L1R3jxgly0",
                "forum": "TdhkAcXkRi",
                "replyto": "vl3SF6L7m0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1089/Reviewer_XBW2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1089/Reviewer_XBW2"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Authors"
                    },
                    "comment": {
                        "value": "Thanks to the authors for the answers and clarification. I agree with the authors that momentum methods can speed up the convergence, but this is commonly known. However, I do not see any benefit specific to FL setting. (Momentum can benefit centralized training, and it benefits FL in similar way.) Further, momentum can 'smoothen' the optimization landscape, which is also well studied in literature. The idea behind this is that it can close the gap between the gradients, which is also the goal of algorithm design when data is heterogeneous in FL. Although it is proved in the paper that momentum methods enable the convergence without data heterogeneity, theoretically it still remains unclear how momentum brings the benefit. If the goal of the paper is to justify the benefit of momentum, I would suggest quantify and add more details to the \"Intuition on the effectiveness of momentum\" part."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1089/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700679504500,
                "cdate": 1700679504500,
                "tmdate": 1700679504500,
                "mdate": 1700679504500,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]