[
    {
        "title": "DeepSPF: Spherical SO(3)-Equivariant Patches for Scan-to-CAD Estimation"
    },
    {
        "review": {
            "id": "aMbJEPyd5S",
            "forum": "Dnc3paMqDE",
            "replyto": "Dnc3paMqDE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3419/Reviewer_T7zb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3419/Reviewer_T7zb"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents an integrable backbone for SO(3)-equivariant point-cloud learning, called Learnable Spherical Patch Fields (DeepSPF).\nThe proposed method is based on a patch-wise representation obtained using spheres, introduced as Spherical Patch Fields. \nThe method aims at seamlessly integrating local and global contextual information, adaptively extracted by the presented Patch Gaussian Layer. The experimental validation of the proposed model focuses on Scan-to-CAD (S2C) \u2014 a sub-task of reconstructing indoor environments, including point cloud registration, retrieval, and completion \u2014 and provides a considerable improvement over the baseline models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "S1. The provided illustrations are neat and facilitate the reader\u2019s understanding of the method. \n\nS2. The proposed DeepSPF successfully tackles an important problem of equivariant local and global feature extraction, by enabling multiple-layer learning of the spherical representations. \n\nS3. The effectiveness of the proposed DeepSPF backbone is demonstrated on various point cloud tasks with clear improvement over the baselines, both quantitatively and qualitatively."
                },
                "weaknesses": {
                    "value": "W1. Unclear presentation. \nThe manuscript relies heavily upon the related and prior work, which makes in particular Section 3 hard to follow for readers less familiar those works. The important components from the related work, e.g., Vogel (1979), Wang et al. (2018), and Salihu & Steinbach (2023), could be presented in more detail in the Appendix.\n\nW2. SO(3)-equivariance is at the heart of the paper, as the title, Abstract, and Introduction imply. However, the method section is missing the crucial part of the equivariance discussion, which is instead placed in the Appendix.\n\nW3. A more detailed complexity analysis is required (see the Questions), as the brief mention in the conclusion does not suffice."
                },
                "questions": {
                    "value": "Q1. Section 3\n\n\u2022\tafter equation 1: Was $v \\in \\mathcal{S}^3$ meant to be $v \\in \\mathcal{R}^3$ or $v \\in \\mathcal{S}^2$? \n\n\u2022\tafter equation 7: since we are in 3D, why is the sphere $\\mathcal{S}^3$ and not $\\mathcal{S}^2$?\n\nQ2. Section 3.2: \n\n\u2022\tWhich \u201cprevious work\u201d is meant in the second line in the first paragraph and the first line of page 5?\n\nQ3. Is the proposed method SPF also equivariant to reflections? I.e., is the entire O(3) group covered?\n\nQ4. Can the proposed method generalize to dimensions higher than 3?\n\nQ5. How sensitive is the model with respect to the number of spheres |v|?\n\nQ6. It would be useful if the authors summarized all the learnable parameters of SPF.\n\nQ7. What is the total number of parameters of the DeepSPF models used in the experiments?\nHow does this compare to the baselines?\n\nQ8. What is the computational complexity of the DeepSPF compared to the baselines? \nCould the authors provide a speed comparison?\n\nMinor:\n\n\u2022\tEquation 4: Should $l$ be $i$ in the {} under the max?\n\n\u2022\tPunctuation between the equations is missing, e.g., 9 and 10. \n\n\u2022\tEquation 12 is a part of equation 11.\n\n\nIn the rebuttal, my questions were addressed appropriately, thus the assessment is updated."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3419/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3419/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3419/Reviewer_T7zb"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3419/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698654486075,
            "cdate": 1698654486075,
            "tmdate": 1700813997901,
            "mdate": 1700813997901,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GCkw5tZDdl",
                "forum": "Dnc3paMqDE",
                "replyto": "aMbJEPyd5S",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3419/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3419/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to T7zb"
                    },
                    "comment": {
                        "value": "First of all, we would like to thank the reviewer for the thorough evaluation of our work and their valid criticism, which has already led to major improvements in our work. Due to character limitations, we refer to the revised manuscript.\n\n**1) Related Work in Appendix**\n\nWe append the information regarding the previous work in the appendix, as requested.\nWe focused on three works the reviewer addressed and added another critical previous work to this description.\n\n**2) SO(3)-equivariance - Paper structure**\n\nWe thank the reviewer for suggestions on the structure of the paper.\nWe hoped it would improve the readability of the overall methodology, but as the reviewer correctly noticed, we have to add this to the main part of the work. \nWe have changed the structure and replaced part of the evaluation (qualitative results of point cloud completion) with the SO(3) equivariance analysis.\n\n**3) Complexity analysis**\n\nWe hope the extended analysis of complexity is sufficient for the reviewer and that all questions have been answered (see below for in-depth question-by-question explanations).\nWe would happily improve the work further if more information is needed!\n\n**4) Q1 - Typo**\n\nThis is a typo, and we have now fixed both to $\\boldsymbol{\\nu}\\in \\mathcal{S}^2$.\nWe apologize for the simple mistake and thank the reviewer for noticing it.\n\n**5) Q2 - Unclearity with previous work**\n\nWe acknowledge that this might have been unclear and needs to be explicitly addressed this point in the manuscript.\nThe prior work we refer to [2].\n\n**6) Q3 - Equivariance to Reflections - O(3) Group**\n\nIn the context of scan-to-CAD, point cloud registration, and retrieval, we typically steer clear of the O(3) group. \nThis avoidance is primarily because the ground truth labels do not represent reflections.\n\nWe evaluated our method and Vector Neurons [3] on the O(3)-group and found that both of them are actually O(3)-equivariant.\nThis can be explained by the fact that reflections are essentially rotation matrices, and therefore, the theories that demonstrate equivariance are the same.\nHowever, due to the ground truth labels mentioned above, we deliberately restrict the estimation process for the scan-to-CAD task and, therefore, do not consider reflections.\nThe restriction is made in the singular value decomposition. \nFor more information, we refer to the work of Umeyama [4] or the supplementary material of DeepGMR [5].\n\n**7) Q4 - Generalization to higher dimensions**\n\nWe assume that this is the case, but the benefits would probably be reduced as the SPF essentially depends on E$(\\boldsymbol{\\nu}, \\boldsymbol{p})$, and if we consider higher dimensions, this distance graph needs to be adjusted to work sufficiently.\n\n**8) Q5 - Sensitivity to $|\\mathbf{\\nu}|$**\n\nWe have extended the appendix with an evaluation on different values of $|\\boldsymbol{\\nu}| = f_{\\text{no}} \\times C$.\nTo evaluate different $|\\boldsymbol{\\nu}|$, we provide Table 9 and Table 10.\n\n**9) Q6 - Learnable parameters**\n\nThe learnable parameters of SPF are:\n- From E$(\\boldsymbol{\\nu}, \\boldsymbol{p})$ we have $\\theta$ and $\\phi$.\n- From $\\text{U}(P(\\boldsymbol{\\nu}, \\boldsymbol{p}))$ we have the fully connected layer $f_\\psi$.\n- From $\\text{V}(r)$ we have the radius $r$.\n\n**10) Q7 - What is the total number of parameters of the DeepSPF models used in the experiments? How does this compare to the baselines?**\n\nWe extensively evaluate all model parameters in the appendix in Table 11.\n\n**11) Q8 - Could the authors provide a speed comparison?**\n\nAs some of our models run on different servers with varying loads (utilizing the same GPU but different CPUs), we are currently consolidating all computations onto a single independent device. This is to ensure a fair speed comparison across the board.\nWe aim to update the manuscript by the end of this week.\n\n**12) Minor Issues**\n\nWe thank the reviewer for finding all minor issues. We have addressed them all in the manuscript.\n\n**13) References**\n\n[1] Helmut Vogel. A better way to construct the sunflower head. Bellman Prize in Mathematical\nBiosciences, 44:179\u2013189, 1979.\n\n[2] Driton Salihu and Eckehard Steinbach. Sgpcr: Spherical gaussian point cloud representation and\nits application to object registration and retrieval. In The 2023 IEEE/CVF Winter Conference on\nApplications of Computer Vision (WACV 2023), Waikoloa, Hawaii USA, Jan 2023.\n\n[3] Congyue Deng, Or Litany, Yueqi Duan, Adrien Poulenard, Andrea Tagliasacchi, and Leonidas J.\nGuibas. Vector neurons: A general framework for so(3)-equivariant networks. 2021 IEEE/CVF\nInternational Conference on Computer Vision (ICCV), pp. 12180\u201312189, 2021.\n\n[4] Shinji Umeyama. Least-squares estimation of transformation parameters between two point patterns. IEEE Trans. Pattern Anal. Mach. Intell., 13:376\u2013380, 1991.\n\n[5] Wentao Yuan, Benjamin Eckart, Kihwan Kim, V. Jampani, Dieter Fox, and Jan Kautz. Deepgmr:\nLearning latent gaussian mixture models for registration. In ECCV, 2020."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3419/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700068804390,
                "cdate": 1700068804390,
                "tmdate": 1700068804390,
                "mdate": 1700068804390,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DYwzXoScKX",
                "forum": "Dnc3paMqDE",
                "replyto": "GCkw5tZDdl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3419/Reviewer_T7zb"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3419/Reviewer_T7zb"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarifications in the rebuttal. Note however that reflections are not rotations. Indeed, a rotation is the concatenation of two reflections!"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3419/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700161325142,
                "cdate": 1700161325142,
                "tmdate": 1700161325142,
                "mdate": 1700161325142,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "AJyBQX8g6m",
            "forum": "Dnc3paMqDE",
            "replyto": "Dnc3paMqDE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3419/Reviewer_73te"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3419/Reviewer_73te"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose Spherical Patch Fields (SPF), a point cloud representation based on Spherical Gaussian (SG) to generate many spherical patches to obtain local and global information, and proposed PG-Layer to improve the learnable SPF representation using low-frequency information and adaptive patches. Besides, the authors verified its effectiveness on three public datasets and their proposed method achieved competitive results."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The idea is somehow novel and interesting. The writing of the entire paper is fine in general, and the paper is easy to read."
                },
                "weaknesses": {
                    "value": "1. More recent related works should be compared, such as Section 4.4, which does not compare with the latest rotation-invariant method: Rotation-invariant transformer for point cloud matching[1]. Section 4.6 does not compare the state-of-the-art point cloud completion methods: Diverse point cloud completion with Geometry-Aware Transformers[2].\n\n[1] Yu, Hao, et al. \"Rotation-invariant transformer for point cloud matching.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n[2] Yu, Xumin, et al. \"Pointr: Diverse point cloud completion with geometry-aware transformers.\" Proceedings of the IEEE/CVF international conference on computer vision. 2021.\n\n2. In Table 3, the proposed method does not perform well in some classes and reasons should be analyzed and discussed.\n \n3. Some sentences are not clear. For example, the red arrow in Figure 1 is ambiguous, and the lower-right circle in the SPF part lacks an arrow. In Section 5, typo: ``resizeable'' \u21d2 ``resizable''."
                },
                "questions": {
                    "value": "See above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3419/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698813189755,
            "cdate": 1698813189755,
            "tmdate": 1699636293285,
            "mdate": 1699636293285,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "in4YOjmSIb",
                "forum": "Dnc3paMqDE",
                "replyto": "AJyBQX8g6m",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3419/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3419/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to 73te"
                    },
                    "comment": {
                        "value": "**1) Related Work - Rotation-Invariant Methods [1]**\n\nAs suggested by the reviewer, we have appended the evaluation of [1] for point cloud registration on ModelNet40 using zero-intersection noise.\nWe show the final results here:\n\n| Model                       | RRMSE | RMSE(t)   |\n|-----------------------------|-------|-----------|\n| Hao et al. [1]              | 81.14 | 0.1353    |\n| Ours (*E*)                  | 7.45  | 0.0031    |\n| Ours (*E*+*U*)              | 6.49  | 0.0029    |\n| Ours (*E*+*U*+*V*)          | **5.17** | **0.0022** |\n\nTo obtain rotation and translation values from [1], we followed the official code to train and obtain features and correspondences.\nWe then used the evaluation script of [1] to subsequently obtain the rotation matrix and translation vector.\nNoticeably, the result is significantly worse. \nThus, using [1] on 3D instance point clouds with no point-to-point correspondences leads to a large reduction in alignment quality.\n\n\n**2) Related Work - Point Cloud Completion [2]**\n\nOur main contribution is the proposed learning of SO(3)-equivariant representation by considering local and global structures. \nWe use the example of point cloud completion to evaluate between one non-equivariant encoder (PointNet [3]) and one SO(3)-equivariant encoder (VN-based PointNet [4]).\nAs such, we wanted to have a structure that is as simple as possible (such as PCN [5]) so that we and the reader can have an easier time understanding the differences/improvements that are possible from our encoder.\n\n[2] considered a more extensive pipeline for the point cloud completion process with a high number of processing steps.\nIn contrast, we proposed an encoder that can be used in many different architectures to improve the point cloud completion pipeline.\nAs such, we decided not to compare with [2].\nTo illustrate this, we have added [2] as an outlook for future work that could be improved by a comprehensive evaluation of the joint combination of our method with [2].\nIf the reviewer insists, we can add the evaluation.\n\n**3) Table 3 - Performance of certain classes**\n\nWe thank the reviewer for the valuable criticism and correct assessment that this experiment needs more analysis. \nWe conducted two additional studies to enhance the analysis of this experiment, and the details have been included in the appendix.\nDue to the character limit in the response, we refer to the appendix for the explanation.\n\n**4) Unclear Figure 1 and Typos**\n\nWe thank the reviewer for the comment. As multiple reviewers mentioned the issue with Figure 1. we have improved the structure and hopefully reduced ambiguity.\nWe also thank the reviewer for finding the typo.\n\n\n**5) References**\n\n[1] Yu, Hao, et al. \"Rotation-invariant transformer for point cloud matching.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023. \n\n[2] Yu, Xumin, et al. \"Pointr: Diverse point cloud completion with geometry-aware transformers.\" Proceedings of the IEEE/CVF international conference on computer vision. 2021.\n\n[3] C. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. Pointnet: Deep learning on point sets for 3d\nclassification and segmentation. 2017 IEEE Conference on Computer Vision and Pattern Recog-\nnition (CVPR), pp. 77\u201385, 2016.\n\n[4] Congyue Deng, Or Litany, Yueqi Duan, Adrien Poulenard, Andrea Tagliasacchi, and Leonidas J.\nGuibas. Vector neurons: A general framework for so(3)-equivariant networks. 2021 IEEE/CVF\nInternational Conference on Computer Vision (ICCV), pp. 12180\u201312189, 2021.\n\n[5] Wentao Yuan, Tejas Khot, David Held, Christoph Mertz, and Martial Hebert. Pcn: Point completion\nnetwork. 2018 International Conference on 3D Vision (3DV), pp. 728\u2013737, 2018\n\n[6] C. Qi, Or Litany, Kaiming He, and Leonidas J. Guibas. Deep hough voting for 3d object detection in point clouds. 2019 IEEE/CVF International Conference on Computer Vision (ICCV), pp. 9276\u2013\n9285, 2019."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3419/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700068831707,
                "cdate": 1700068831707,
                "tmdate": 1700068831707,
                "mdate": 1700068831707,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "aY444zDASU",
            "forum": "Dnc3paMqDE",
            "replyto": "Dnc3paMqDE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3419/Reviewer_bCvD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3419/Reviewer_bCvD"
            ],
            "content": {
                "summary": {
                    "value": "The paper suggests a network design aiming at providing SE(3) equivariant features consisting of local and global spatial neighborhoods. The neighborhoods are modeled using spherical Gaussian representations.  The size of the patches is adjustable by learnable elements in the proposed network.\nThe method is mainly evaluated on 3D scan2cad tasks: registration, retrieval, and completion."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The work tackles the challenging goal of learning the correct spatial receptive field for features.\n\nI appreciate the effort to evaluate the method on three different tasks. In addition qualitative results are also provided."
                },
                "weaknesses": {
                    "value": "The main weaknesses of the paper are related to its exposition and readability qualities.\nIn particular, the authors should strive to reduce the level of technical detail in the main text and aim for a clearer presentation of the key concepts. Furthermore, the paper could benefit from the inclusion of more intuitive explanations. \n\nSome examples:\ni)  \u201c conventional SO(3)-equivariant methods do not sufficiently investigate the correlation between global and local structures\u201d. Is it specifically true for equivariant methods? SO(3) symmetries? \nii) Figure 1 is unclear. It is unclear how the caption relates to elements in the figure itself.\niii) There is no clear analysis provided (proposition, theorem, etc.) that supports the claim that the proposed network is equivariant. \niv) Some equations are not clear, e.g. it is not clear what is z in eq. (3).\n\nIn summary, it seems the writing quality is such that the paper is not ready yet for publication."
                },
                "questions": {
                    "value": "No specific questions. I would appreciate a response with respect to the weaknesses stated above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "none"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3419/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698869683674,
            "cdate": 1698869683674,
            "tmdate": 1699636293202,
            "mdate": 1699636293202,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vBCUSWVLKh",
                "forum": "Dnc3paMqDE",
                "replyto": "aY444zDASU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3419/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3419/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to bCvD"
                    },
                    "comment": {
                        "value": "**1) Is it specifically true for equivariant methods? SO(3) symmetries?**\n\nThank you for your feedback. We have rephrased the sentence to provide a more precise explanation of the issue:\n\"These methods often treat the issues of local and global SO(3)-equivariance separately, leading to an insufficient investigation of SO(3)-equivariance between global and local structures.\"\nThese methods refer to the SO(3)-equivariant methods we name and cite directly beforehand. \nFollowing Vector Neurons [1], we avoid a more extensive explanation of how SO(3) is defined.\nWe would gladly provide a more detailed explanation in the appendix if needed.\n\n**2) Figure 1 is unclear**\n\nWe improved the figure and caption and hope the caption now relates better to the figure itself.\nAdditional details regarding these changes can be found in the general response section of our reply, as another reviewer highlighted concerns related to this figure.\n\n**3) No analysis regarding equivariance**\n\nWe realize that having the proposition and theorem in the appendix might not have been the correct decision.\nAs such, we have replaced parts of the evaluation with the analysis of equivariance to improve the manuscript. \n\n**4) Unclear equations or variables**\n\nWe realize that the previous sentence structure made it hard to see the definition of the latent vector $\\boldsymbol{z}$ (in front of Eq.(3)). Thus, we have improved the sentence structure and added the latent vector $\\boldsymbol{z}$ also as output to SPF($\\boldsymbol{p}$) in Eq.(3) to make it more readable.\nWe tried to find more variables where such an issue might have happened and would be happy for any further issues found.\n\n**5) General Readability**\n\nWe thank the reviewer for the open criticism of our manuscript.\nWe understand that we included a lot of equations and technical details.\nWe simplified and improved the readability of the main section.\nWe hope this extended rebuttal has clarified our intention to enhance our work, and we would appreciate any suggestions or improvements you may have.\n\n**6) References**\n\n[1] Congyue Deng, Or Litany, Yueqi Duan, Adrien Poulenard, Andrea Tagliasacchi, and Leonidas J.\nGuibas. Vector neurons: A general framework for so(3)-equivariant networks. 2021 IEEE/CVF\nInternational Conference on Computer Vision (ICCV), pp. 12180\u201312189, 2021."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3419/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700068828608,
                "cdate": 1700068828608,
                "tmdate": 1700068828608,
                "mdate": 1700068828608,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]