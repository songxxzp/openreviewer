[
    {
        "title": "Sequential Bayesian Continual Learning with Meta-Learned Neural Networks"
    },
    {
        "review": {
            "id": "1eAyiCy71T",
            "forum": "6r0BOIb771",
            "replyto": "6r0BOIb771",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4775/Reviewer_awoT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4775/Reviewer_awoT"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a new general MCL framework, SB-MCL, by considering exponential family posterior distributions for efficient sequential Bayesian updates, and employing a neural network to learn the parameters in the variational prior. The model demonstrates improved performance compared to multiple benchmark datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper shows extensive empirical comparisons with various benchmark datasets and on multiple tasks, which demonstrates the advantage of the SB-MCL framework."
                },
                "weaknesses": {
                    "value": "The contribution of the paper lies in replacing the inner update rules of MCL with sequential Bayesian updates using exponential family distributions. However, both the idea of Bayesian updates and using exponential family distribution as variational posterior is not new. This paper combines several existing ideas and demonstrates superior performance of the method, but the novelty is somewhat lacking."
                },
                "questions": {
                    "value": "While the paper states a general results for exponential family distributions, the main results are shown with factorized Gaussian. How does this affect the result? Does different exponential family distributions yield different performances?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4775/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4775/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4775/Reviewer_awoT"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4775/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698724441008,
            "cdate": 1698724441008,
            "tmdate": 1699636459621,
            "mdate": 1699636459621,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xmTWnElUay",
                "forum": "6r0BOIb771",
                "replyto": "1eAyiCy71T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4775/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4775/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We greatly appreciate the time and effort to review our paper. We hope our following response will resolve most of the concerns.\n\n## Novelty\n\nWhile SGD-based approaches are dominating the current CL literature, it is important to note that updating a model with SGD does not come with any theoretical guarantees on performance in CL settings. On the contrary, we highlight a critical aspect of exponential family posteriors, which has been overlooked in the CL community: *they are the only type of posteriors that can theoretically guarantee learning without forgetting while maintaining a constant memory size*. Therefore, we introduce a general MCL framework that leverages the perfect CL ability of statistical models with exponential family posteriors. We effectively address their weak representational power by combining meta-learned neural networks; as a result, we can achieve SOTA performance on a variety of classification, regression, and generation benchmarks. We believe our work provides a fresh perspective on CL, and the other two reviewers also pointed out the novelty as a strength of our approach.\n\n\n\n## The Choice of Gaussian\n\nWhile the Fisher-Darmois-Koopman-Pitman theorem is applied to every exponential family distribution, Gaussian distributions are particularly easy to integrate with neural networks thanks to the reparameterization trick [1]. Discrete distributions, such as Bernoulli or categorical distributions, require more sophisticated techniques, such as Gumbel softmax [2]. We also conjecture that the choice of the posterior may not be crucial as long as the meta-learned neural network components are flexible enough. Nonetheless, there may be some cases that can benefit from different types of posteriors, and we leave thorough exploration of them as future work.\n\n\n---\n\n[1] Kingma and Welling, Auto-Encoding Variational Bayes. ICLR 2014.\n\n[2] Jang et al., Categorical Reparameterization with Gumbel-Softmax. ICLR 2017."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4775/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700400050269,
                "cdate": 1700400050269,
                "tmdate": 1700539804458,
                "mdate": 1700539804458,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "UNEY0HbkK2",
            "forum": "6r0BOIb771",
            "replyto": "6r0BOIb771",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4775/Reviewer_y1kN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4775/Reviewer_y1kN"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a new approach to Meta-Continual Learning (MCL) with the aim to mitigate forgetting in nonstationary streams of data. The novel method, called Sequential Bayesian Meta-Continual Learning (SB-MCL) is presented as a combination of meta-learned neural networks and sequential Bayesian updating. The assumption is that for each CL episode, composed of multiple tasks, a single multidimensional latent variable exists and governs the entire episode. Along the episode, the posterior distribution of latent variable conditional on observations is updated step by step with Bayesian updating to accumulate the entire knowledge of the past. The authors propose the use of the Fisher-Darmois-Koopman-Pitman theorem to show that using distributions from the exponential family enables an update that is resistant to forgetting, while not increasing in time the number of required parameters.  On the opposite, using distributions outside the exponential family in a fixed memory scenario, forgetting becomes inevitable. \n\nThe full method uses a neural network encoder (called \u201clearner\u201d) to encode the input as the parameters of an assumed distribution that is used to update the distribution of the latent variable. The posterior distribution is then sampled and another neural network (called \u201cmodel\u201d) produces an output conditioned on the input and the samples from the posterior. \n\nThe encoder and the model are meta-learned across various CL episodes. CL in the inner loop is performed only by Bayesian updating in the latent space, not requiring any gradient computation, enabling to process the stream of data also non-sequentially with the same result. Moreover, this is a way to remove the requirement of computing second-order gradients. The objective of the meta-training optimization is to maximize the log-likelihood of the test set after continually learning from the training stream. Due to the latent variable this function is intractable. The authors introduce a variational distribution of the latent variable (a gaussian distribution) and obtain variational lower bounds both for supervised and unsupervised problems.  \n\nSB-MCL generates a family of models that is tested against other MCL competitors in various settings showing the capabilities of the proposal to mitigate catastrophic forgetting."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is well written and proposes an innovative and interesting approach to Meta-CL. The proposed idea shifts the focus of the memorization of past experiences from the weight distribution to the latent distribution, removing completely the need of computing gradients during CL phase. The reasons for this choice are well explained and the use of the Fisher-Darmois-Koopman-Pitman theorem enriches the work with a theoretical grounding on how the exponential family can be of fundamental importance to accumulate knowledge in a memory-constrained environment. \n\nThe derivation of the variational lower bounds used for continual meta-optimization is also clearly done, overcoming the limitations of previous derivations. \n\nThe proposal is tested in a wide range of different tasks, from classification to regression, from generation to image rotation prediction. This confirms the robustness of the idea in different scenarios, improving its significance for the MCL literature. \n\nThe proposed method has also a clear and probably impactful improvement from the computational point of view with respect to other models: the possibility to feed the examples in parallel to the learner and the removal of second-order gradients make the method  quite interesting also from a practical point of view."
                },
                "weaknesses": {
                    "value": "One of the main ideas of the paper is the use of distributions from the exponential family to accumulate knowledge from the past without increasing the parameters need. The Fisher-Darmois-Koopman-Pitman theorem implies that distributions from the non-exponential family need sufficient statistics of unbounded dimensions to fully capture the information of the data. While the authors acknowledge that models only based on exponential family update are often too simple, they do not address directly what are the consequences of this simplification in their proposal. Probably the use of a strongly nonlinear model (as a neural network) is sufficient to obtain the same learning power as a model that is not limited to exponential family distribution. In any case it would be interesting to directly address this point. \n\nIn a similar way, the sequential Bayesian update with the exponential family has results completely equivalent to having all examples available at the same time. This would solve \u201cby definition\u201d the problem of forgetting. The idea is very interesting, but it should be specified that this is possible due to a simplification assumption on the distribution, and exploring what the consequences of this assumption are. Claiming that this method transforms a CL problem in a underfitting problem should be verified empirically by varying the number of parameters of the neural networks and/or the dimension of the latent space, showing how the memorization ability changes. More importantly this claim is somehow in contradiction with the \u201closslessness\u201d of the exponential family sequential update, implying that, with the increase of tasks, the number of parameters should increase.\n\nOn a higher level, the approach (like any other meta-continual learning framework, in fairness) shifts the forgetting problem from the task to the meta task. Else said, the approach assumes that all meta non-stationarieties are represented at meta-training time. If the meta-test phase characterizes by substantial non-stationarieties the method is bound to fail as it cannot adapt (without incurring once again in catastrophic forgetting at meta level)."
                },
                "questions": {
                    "value": "Q1) While the experiments cover a wide array of tasks, it is not clear why the proposed model is not tested in all cases. It would be useful for additional clarity to have the same models tested in all possible cases. If the claim is that the proposed model is the generator of a family of specific models known in the literature, it should be tested anyway, showing if its generality can make an improvement. Is there any technical reason why the proposed general model is not tested in all scenarios?\n\nQ2) As a very small note, the plots with the results are not extremely clear to read, with some lines outside the bounds and some others with similar colours and many overlaps."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4775/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698768474893,
            "cdate": 1698768474893,
            "tmdate": 1699636459511,
            "mdate": 1699636459511,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "J0jh3r0Q25",
                "forum": "6r0BOIb771",
                "replyto": "UNEY0HbkK2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4775/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4775/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We deeply appreciate the insightful comments. The questions delve into the fundamental aspects of our approach, leading to valuable insights. We provide our answers in the following.\n\n## The Price of Lossless CL with Exponential Family Posteriors\n\nCompliant with the \"no free lunch\" theorem, we do pay a price for harnessing the power of exponential family posteriors: the necessity of meta-training. Due to the simplicity of the exponential family, meta-learned neural networks are vital for handling complex and high-dimensional problems. On the other hand, SGD can be applied to standard CL scenarios, although it requires additional techniques to mitigate forgetting. We made this clear in the second paragraph of section 3.3 in the updated draft.\n\nHowever, as we mentioned in the introduction, MCL is a promising direction toward solving CL. Once we embrace the MCL setting, SB-MCL arises as an attractive solution with minimal downsides. In theory, limiting the inner loop updates to the exponential family posterior should not have a significant impact on the representational capacity, as long as the meta-learned neural networks fulfill their duty as universal function approximators. Our experiments also empirically verify that the meta-learned neural networks are sufficient for SB-MCL to outperform SGD-based MCL approaches.\n\n\n\n## Underfitting and the Lossless Sequential Update\n\nAs neatly summarized in the review, our framework \"by definition\" produces the same results regardless of how the training data is provided. Our claim about forgetting vs. underfitting was to highlight this fundamental property of our approach, not as an empirical observation. Even in standard multi-task learning settings where all tasks are available throughout training, the performance can degrade as the number of tasks increases, which is often described as underfitting. Since SB-MCL\u2019s performance drop in a CL setting is exactly the same as the performance drop in the corresponding multi-task learning setting with the same tasks, we referred to it as underfitting. More specifically, the sequential Bayesian update is indeed lossless; however, information loss can occur (i) when the learner transforms the raw data to the variational likelihood and (ii) when the model forwards $x$ and $z$. Therefore, underfitting and lossless sequential updates do not contradict each other.\n\nFrom this perspective, it becomes evident that there would be a positive correlation between the model size and the performance up to a certain point. If we reduce the number of parameters, the performance will surely drop. However, naively increasing the number of parameters does not necessarily lead to a better performance, which is why people do not use a gigantic multi-layer perceptron to solve all kinds of problems. We do need a clever architectural design to further improve the performance, and it would be an exciting topic for future research.\n\n\n\n## MCL as a Data-Driven Approach to CL\n\nIt is true that MCL frameworks transform the challenge of designing a good CL algorithm into the challenge of building a good meta-training set. The meta-training set should be large and diverse enough to cover the meta-test distribution. But is this really a weakness of MCL?\n\nAs we mentioned in the introduction, it has been proved that CL is fundamentally an NP-hard problem (Knoblauch et al. 2020). This theoretical result entails a profound message to the CL literature: no matter how meticulously a CL algorithm is designed, there are CL problems that it cannot solve efficiently. This is why we think MCL is a promising direction. Instead of manually designing domain-specific CL algorithms, we can design a general MCL algorithm and collect meta-training datasets for target domains. In this sense, MCL is also better aligned with [The Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html) by Rich Sutton. It is an argument that general learning algorithms, which leverage more computation and data, have always won over complicated algorithms relying on domain-specific human knowledge in the long run. Therefore, we believe the data-driven aspect of MCL can be considered a strength, rather than a weakness."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4775/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700399945361,
                "cdate": 1700399945361,
                "tmdate": 1700399945361,
                "mdate": 1700399945361,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Trwr50vadZ",
                "forum": "6r0BOIb771",
                "replyto": "TlUuAOZhOw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4775/Reviewer_y1kN"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4775/Reviewer_y1kN"
                ],
                "content": {
                    "title": {
                        "value": "Response to rebuttal"
                    },
                    "comment": {
                        "value": "First of all, I appreciate the response touch on all points of the review. Please find below some further considerations.\n\n**The Price of Lossless CL with Exponential Family Posteriors**\n\nI find the answer quite convincing. The simplification in the latent space should be theoretically compensated by a well-functioning meta-learned neural network that should recover all the representation capabilities. This is similar to what happens in a VAE using a member of the exponential family in the latent space. At the same time, VAE with different distributions exist. Considering that the distributional choice is fundamental to this paper, I would find interesting to direct address the implication of choosing a distribution instead of another for the latent space from the model capabilities perspective. In the end, the reason why the Bayesian update is lossless in the exponential case is exactly the simplicity of these distributions. Are we losing something by choosing this family to accumulate past knowledge?\n\n**Underfitting and the Lossless Sequential Update**\n\nIn this case, I find the answer only partially solving the issue. Again, the assumption about a single gaussian latent variable that governs the entire episode is an important one and solves the forgetting \u201cby definition\u201d. I agree that the update in the latent space is indeed lossless and that the loss of information can happen at the weights level. Given that this loss of information does not happen in time probably can be called underfitting instead of forgetting. I would still appreciate an empirical validation of this claim due to the important implications it can have on CL: by choosing a large enough model is really possible to solve the CL problem?\n\n**Improved Experiments**\n\nI really appreciate the improvements in the section. Now the experiments are more clear and readable.\n\nTo conclude, I am not arguing against MCL. Just commenting on the fact that the risk is that of shifting the issue from the model to the meta-model. Thanks again for your response. I will take this into consideration in the reviewers' discussion and in determining the score."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4775/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700668664577,
                "cdate": 1700668664577,
                "tmdate": 1700668664577,
                "mdate": 1700668664577,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "iyYGC0Pmnb",
            "forum": "6r0BOIb771",
            "replyto": "6r0BOIb771",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4775/Reviewer_DFZf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4775/Reviewer_DFZf"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new framework for meta-continual learning. The authors propose leveraging the Bayesian learning and specific properties of Gaussian distribution in order to bypass the need for storing large amounts of replay data and use a meta-learned neural network to make the final predictions based on the samples drawn from an episode-specific Gaussian distribution. The authors evaluated their method on a variety of meta learning datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well-organized and structured up to the experiment section. Mathematical derivations are sound and the authors have gone through enough details in order to convey their message. \n\nThe idea of leveraging Bayesian learning in the context of continual learning is both interesting and novel. \n\nFigure 1 and 2 nicely describe the whole framework."
                },
                "weaknesses": {
                    "value": "**Using a frozen meta-learned model:** I believe one of the main shortcomings of the proposed method is the fact that the authors propose to freeze the meta-learned network to perform the meta-test.  Freezing the weights extremely limits the plasticity of the framework and I believe Bayesian learning by itself is not enough to address the \"different enough\" tasks. Also, Using a frozen meta-learned network is analogous to using a pertained model which usually defies the purpose of CL. The end goal of CL is to put the network in scenarios in which truly unseen data are encountered and the network should learn to **adapt** to the new environment while maintaining its previously learned knowledge. I believe freezing is not a good way of maintaining the knowledge and Bayesian learning is not expressive enough to be plastic as it is evident in the qualitative result. The VAE reconstruction results look blurry even for nist-type images.  \n\n**Motivation:** I am having a hard time finding a realistic scenario to deploy such a framework. For instance, it seems too restrictive to train VAEs continually while only seeing the data once. At least in the context of generative models, we usually do not operate in such restrictive scenarios. \n\n**Evaluations:** This is tightly related to the first issue. The meta-training tasks are very similar to the meta-testing ones. I believe it is necessary to evaluate the expressiveness of the Bayesian learning approach on more diverse tasks. \n\n**plots:** There are too many plots in Figure 3. Not all of them are informative and some should definitely be moved to the appendix. The message would be better conveyed if we had more tables in the main body instead of a large number of plots in just one figure. The legends are better to be close to the actual plot. It is not easy to match the colors in the top rows to the legend in the bottom row. Also, some of the gray trends (denoted by \"standard\" in the legend), are out of the plot frame. Especially the one in the bottom right."
                },
                "questions": {
                    "value": "**Q1:** Have the authors tried deploying their framework on more diverse sets of tasks? I am curious to see the limits of expressivity of the Bayesian methods to add plasticity."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4775/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4775/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4775/Reviewer_DFZf"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4775/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699179773677,
            "cdate": 1699179773677,
            "tmdate": 1699636459441,
            "mdate": 1699636459441,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "G5YJWOT43Z",
                "forum": "6r0BOIb771",
                "replyto": "iyYGC0Pmnb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4775/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4775/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the constructive feedback and for recognizing various strengths in our work. We find that most of the raised concerns are not confined solely to our framework but rather extend to broader meta-learning and MCL settings. In the subsequent discussion, we provide a more comprehensive context within the meta-learning and MCL literature, with the hope of addressing these concerns. In addition, we significantly revised the experiments section following the suggestions.\n\n\n### Frozen Meta-Learned Components\n\nFreezing some meta-learned components in the inner loop is a well-established technique in both meta-learning and MCL [1, 2, 3, 4, 5, 6, 7]. Moreover, the most important trait of OML [3], our primary SGD-based MCL baseline, is freezing the model\u2019s encoder while training only the two topmost layers in the inner loop. If the encoder is not frozen, OML becomes equivalent to MAML naively applied in MCL settings. The experiments in the original OML paper and our work confirm that the naive MAML performs much worse than OML. This suggests that it is crucial to prevent excessive plasticity, especially in MCL settings, which is contrary to the reviewer\u2019s concern. Even if the subject of inner updates is dramatically simplified, as in the cases of OML and SB-MCL, the meta-learned neural networks are strong enough to compensate for the simplification, demonstrating neural networks\u2019 capabilities as universal function approximators.\n\nIn the review, VAE\u2019s blurry reconstructions in the qualitative results were pointed out as evidence for a lack of expressivity in Bayesian learning. However, this is a misinterpretation of the results. Blurry output is a well-known trait of VAE [8], which is orthogonal to Bayesian learning. Our VAE reconstruction results are blurry regardless of the MCL methods (OML, OML-Reptile, and SB-MCL), while the DDPM trained by our SB-MCL can produce incredibly crisp images, which are hard to distinguish from real images.\n\nLastly, we emphasize that updating neural networks is not the ultimate goal of CL but one possible solution for CL, which is not necessarily ideal. It is straightforward to extend our framework to perform SGD updates of neural networks concurrently in the inner loop. However, updating the neural networks in the inner loop will bring up the forgetting issue, which has been eliminated by our framework, and degrade performance.\n\n\n\n### Potential Applications of MCL with Generative Models\n\nThe integration of MCL with deep generative models holds tremendous potential, unlocking possibilities for various applications that are currently beyond reach. Consider, for instance, text-to-image applications like OpenAI's DALL-E, Adobe's Firefly, or Midjourney that are based on the diffusion model. They significantly expedite the artistic design processes and are already creating substantial economic values. Combining MCL can take this further; artists can supply a few examples of desired results to get a rapidly adapted personalized model. Since the design process often involves gradually adding new assets (e.g., characters, scenes, and objects when creating an animation) built upon the existing assets, continually and rapidly adapting the model to the current project would be especially beneficial.\n\n\n\n### Meta-Learning Evaluations\n\nAs the review pointed out, our meta-training tasks are similar to the meta-testing ones. However, it is one of the most fundamental assumptions of meta-learning [1, 5, 7, 9] and MCL [2, 3, 4], not confined to our approach. In essence, it represents a broader principle applicable to all machine learning paradigms: the training set should cover the test distribution. Even in standard learning scenarios, we generally do not expect a learned model to magically generalize beyond its training set; for example, if we train an image classifier on the images of cats and dogs, it would not perform well on the images of cars or airplanes. This challenge may be related to other topics like open-set classification or out-of-distribution generalization, which are orthogonal to meta-learning and MCL.\n\n\n### Updated Presentation of the Results\n\nWe greatly appreciate the feedback on the plots. The original plot was indeed overly crowded, as we crammed too many results into a small area. We largely updated the experiments section as suggested in the review.\n\n- We added a table in the main text that summarizes the key results.\n- The number of plots is significantly reduced.\n- For each plot, we compare only three methods, which are necessary to deliver our key message: Standard, OML, and SB-MCL.\n- To reduce confusion, the special cases of SB-MCL (PN, GeMCL, and ALPaCA) are now compared under the name SB-MCL, along with the generic SB-MCL architectures for supervised and unsupervised settings.\n\nWe believe the updated section is far more concise and clearly conveys the essence of the results."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4775/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700399768415,
                "cdate": 1700399768415,
                "tmdate": 1700399768415,
                "mdate": 1700399768415,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ReiigG3jCu",
                "forum": "6r0BOIb771",
                "replyto": "iyYGC0Pmnb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4775/Reviewer_DFZf"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4775/Reviewer_DFZf"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "I have read the author's answers and I thank the authors for addressing my concerns and modifying the experiment section. The authors significantly improved their experiment section and explanation of their evaluation settings. I appreciate the removal of excessive figures and the addition of an informative table.\n\nHowever, I need to clarify some of my previous statements because I believe there is a misunderstanding, especially regarding the task similarities. To me, having similar but challenging tasks is acceptable but when the tasks are too simple to solve (data existing on a low dimensional manifold) like in the NIST-type tasks, and at the same time they are very much similar to each other, then there is a problem since the plasticity and the expressivity of the model cannot be properly tested. With the proposed experiments I cannot really conclude that the exponential models are better than having MLP heads in general or it is just because of the fact that the tasks are trivial. Maybe in some more challenging benchmarks, it would be beneficial to use more complex plastic components. If a proposed method is simple, it should be shown that the simplicity is enough. \n\nMoreover, I encourage the authors to compare their approach with more recent MCL baselines. The only tested baseline is OML which is for 2019. \n\nI thank the authors for pointing out some of the potential applications of their framework however, I believe they are far reached and continual learning is not needed in those applications. The fact that the generative model must generate in an order is different from the fact that it needs to learn all those new design concepts gradually. I still struggle to see the applicability of the framework in real-world problems. \n\nDue to the above-mentioned reasons, I will keep my initial score."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4775/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700677539475,
                "cdate": 1700677539475,
                "tmdate": 1700677564869,
                "mdate": 1700677564869,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]