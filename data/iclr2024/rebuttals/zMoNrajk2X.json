[
    {
        "title": "CADS: Unleashing the Diversity of Diffusion Models through Condition-Annealed Sampling"
    },
    {
        "review": {
            "id": "BcCTf3siqF",
            "forum": "zMoNrajk2X",
            "replyto": "zMoNrajk2X",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2574/Reviewer_Djqj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2574/Reviewer_Djqj"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, conditional-annealed diffusion sampler (CADS) is proposed to address the limited diversity of diffusion models with a high classifier-free guidance scale or when trained on small datasets. Specifically, during early inference, the conditional signal is perturbed largely and then restored gradually  during late inference. The proposed method is simple and effective, amplifying the diversity of the generated samples. Besides, it requires minimal computational overhead and easy to implement. In addition, this paper provides extensive experiments on various tasks and ablation studies, validating the effectiveness and novelty of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "+ The proposed method is simple but effective. It is easy to implement and validated with various experiments. Besides, it outperforms a naive and intuitive approach, termed as adaptive CFG, confirming its technical contributions.\n+ To validate the proposed method, this paper provides extensive experiments on various tasks and ablation studies. Thus, it is a solid paper."
                },
                "weaknesses": {
                    "value": "- In Appendix G, this paper provides sampling and evaluation details, shown in Table 12. The sampling hyperparameters is set deliberately for these experiments. To my knowledge, the training setting is mostly fixed for the same dataset even though it is an ablation study. But, as shown in Table 12, this rule is broken. For example, the setting of ImageNet 256 in Table 1 is different from the setting of ImageNet 256 in Table 6a. How do you set the sampling hyperparameters? \n- As shown in Table 2, there is a missing comparison. The authors should provide the result of DiT-XL/2 with CADS($w_{CFG=1.5}$) or the result of DiT-XL/2 ($w_{CFG=2}$), alleviating the effects of different cfgs."
                },
                "questions": {
                    "value": "- Empirically, with high guidance weights, the diffusion sampler can produce unnatural images and sometimes even diverges. There is a concern about the proposed method: is it easy to produce bad images?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2574/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2574/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2574/Reviewer_Djqj"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2574/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698679453444,
            "cdate": 1698679453444,
            "tmdate": 1700631251641,
            "mdate": 1700631251641,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SqhbYIAdZq",
                "forum": "zMoNrajk2X",
                "replyto": "BcCTf3siqF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2574/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2574/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Response to Reviewer Djqj"
                    },
                    "comment": {
                        "value": "### **Ablations and hyperparameter selection**\n\nThe reviewer\u2019s question brings up an interesting point about the hyperparameter settings in the present work.  The settings described in our paper were determined heuristically based on experimentation with the individual datasets.  It is important to note that, as our method is a *sampling* method, no hyperparameter choices need to be made at training time, and experimentation to help select hyperparameter settings is relatively inexpensive.  We also found that our method is quite robust to a range of settings.  When performing an ablation study on individual hyperparameters, the other hyperparameters must be kept fixed at predetermined values.  These values were selected to best illustrate the effects of exploring the range of the *ablated* hyperparameters, which in some cases differ from the settings used elsewhere in the paper.  However, we agree with the reviewer about the importance of maintaining a direct comparison between experiments, and we report below additional ablations with the fixed hyperparameters chosen to match those in Table 1.  These results comport with the conclusions of the original ablation study while, we hope, better connecting with the earlier experiments.\n\n**New ablation on $\\tau_1$**\n\n| **$\\tau_1$** | **FID** | **Recall** |\n| :---: | :---: | :---: |\n| 0.2 | 47.21 | 0.81 |\n| 0.5 | 9.47 | 0.62 |\n| 0.9 | 20.64 | 0.33 |\n\n**New ablation on $\\psi$**\n\n| $\\psi$ | FID | Recall |\n| :---: | :---: | :---: |\n| 0.0 | 111.39 | 0.81 |\n| 0.5 | 11.55 | 0.60 |\n| 1.0 | 9.47 | 0.62 |\n\n\n**New ablation on $s$ with and without rescaling**\n\n| $s$ | FID ($\\psi=0$) | Recall ($\\psi=0$) | FID ($\\psi=1$) | Recall ($\\psi=1$) |\n| :---: | :---: | :---: | :---: | :---: |\n| 0.025 | 16.88 | 0.43 | 12.94 | 0.50 |\n| 0.05 | 14.96 | 0.48 | 12.69 | 0.52 |\n| 0.10 | 14.13 | 0.63 | 10.18 | 0.60 |\n| 0.15 | 111.39 | 0.81 | 9.47 | 0.62 |\n\n### **Missing comparisons in Table 2**\n\nWe thank the reviewer for pointing out the missing comparisons in Table 2. Please find the completed version below. We have added the metrics for regular CFG at guidance levels that produced best FID at both resolutions. This further confirms the fact that CADS allows the usage of higher guidance values without a significant drop in diversity/FID.\n\n| **ImageNet 256**|  |  |  |  |\n| --- | :---: | :---: | :---: | :---: |\n| **Sampler** | **FID** | **IS** | **Precision** | **Recall** |\n| DDPM ($w_{cfg}=1.5$) | 2.27 | 278.24 | 0.83 | 0.57 |\n| DDPM ($w_{cfg}=2.0$) | 5.82 | 379.39 | 0.89 | 0.48 |\n| CADS ($w_{cfg}=2.0$) | 1.70 | 268.77 | 0.78 | 0.64 |\n\n\n| **ImageNet 512**|  |  |  |  |\n| --- | :---: | :---: | :---: | :---: |\n| **Sampler** | **FID** | **IS** | **Precision** | **Recall** |\n| DDPM ($w_{cfg}=1.5$) | 3.04 | 240.82 | 0.84 | 0.54 |\n| DDPM ($w_{cfg}=2.5$) | 10.20 | 388.81 | 0.85 | 0.35 |\n| CADS ($w_{cfg}=2.5$) | 2.31 | 239.56 | 0.80 | 0.61 |\n\n### **High guidance values and producing bad images**\n\nThe short answer is that, within a wide range of settings, it is quite difficult to produce bad images using our method.  None of the images in our paper were cherry-picked or otherwise curated.  However, it is important to note that CADS was developed to solve the issue of limited image diversity when using high guidance scales and was not designed to protect against the deleterious effects of ultra-high guidance scales.  As our method is built on top of CFG, we suspect that it is similarly susceptible to these effects.  However, our method provides practitioners with a simple tool for avoiding the diversity limitations of CFG, which we argue increases the range of scales that can be used in practice versus standard methods."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2574/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700129647193,
                "cdate": 1700129647193,
                "tmdate": 1700129879617,
                "mdate": 1700129879617,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3AwpUgQZdM",
                "forum": "zMoNrajk2X",
                "replyto": "SqhbYIAdZq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2574/Reviewer_Djqj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2574/Reviewer_Djqj"
                ],
                "content": {
                    "comment": {
                        "value": "I have read authors\u2019 rebuttal. The authors solve my concerns. Thus, I prefer to raise my score to 8."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2574/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700631233497,
                "cdate": 1700631233497,
                "tmdate": 1700631233497,
                "mdate": 1700631233497,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "E8RsaZGlYy",
            "forum": "zMoNrajk2X",
            "replyto": "zMoNrajk2X",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2574/Reviewer_iK6t"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2574/Reviewer_iK6t"
            ],
            "content": {
                "summary": {
                    "value": "Although conditional Diffusion Models have shown impressive performance in good coverage of the real data distribution, it is still limited in covering all the modes of the complex real distribution. In this paper, the authors are proposing a simple but effective sampling method of pretrained Diffusion Models for sampling more diverse results without additional time cost. Comprehensive experiments demonstrate the performance improvements of the proposed method."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Good paper writing. Most parts of the paper is written understandable and reasonable. \n- Simple but effective method.\n- Performance improvement (w.r.t. diversity) in Pose-to-image generation is impressive.\n- Experiments are done comprehensively.\n- The proposed method is theoretically analyzed and also proven to be effective by toy dataset experiment. (in Appendix)"
                },
                "weaknesses": {
                    "value": "1. \u201cAdaptive\u201d may not be an appropriate term. To my knowledge, \u2018adaptive\u2019 is used for a method of which parameters are dynamically changed depending on a given input value [1]. Here, $z_t$ is the input I was expecting rather than $t$ since $t$ is a value within a fixed time window.\n\n2. There are a lot of sampling methods including DDIM [2] while only the original DDPM sampler is used to compare. Considering the fact that DDIM is a more widely used sampling method than the original DDPM sampling method, additional comparison with DDIM is needed.\n\n\n[1] Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization, ICCV\u201917\n[2] Denoising Diffusion Implicit Models, ICLR\u201921"
                },
                "questions": {
                    "value": "1. The definition of \u201cdiversity\u201d is provided right under Section 3. \nWhat is the meaning of \u201crandom seed\u201d? Does it mean the seed of the randomness (e.g., random.seed(1) in Python) or different $x_T$? To me, comparing samples from different seed is less clear than comparing different samples from the fixed seed.\nFor example, we have two $x_T$ sampled from the standard normal, i.e., $x_T^{(0)}$, $x_T^{(1)}$. Let\u2019s say the regular sampling method is $f$ (e.g., DDPM), the proposed sampling method is $g$, and an arbitrary metric of the semantic distance between two images is $h$.\nTo me, the effect of the proposed method would be understandable if $h(f(x_T^{(0)}), f(x_T^{(1)})) < h(g(x_T^{(0)}), g(x_T^{(1)}))$ because we can consider that more modes in the real distribution are covered by the standard gaussian. However, if the noise samples $x_T^{(0)}$, $x_T^{(1)}$ are sampled from different random seed respectively, maybe it's a trivial issue, but it sounds somehow unclear to me. Further clarifications on this point are needed.\n\n2. What is the justification for the higher IS of DDPM across most of $w_{\\text{CFG}}$ in Fig. 5?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2574/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698891986843,
            "cdate": 1698891986843,
            "tmdate": 1699636194261,
            "mdate": 1699636194261,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "U9SQ4SRtGN",
                "forum": "zMoNrajk2X",
                "replyto": "E8RsaZGlYy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2574/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2574/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Response to Reviewer iK6t"
                    },
                    "comment": {
                        "value": "### **Adaptive CFG terminology**\n\nWe thank the reviewer for pointing this out.\u00a0 We have changed the terminology to *dynamic* CFG to avoid confusion with adaptive normalization scenarios that are data dependent.\n\n### **More experiments with DDIM and other samplers**\n\nWe appreciate the reviewer\u2019s point regarding the samplers one has to choose from.\u00a0 Table 3 in our submission reports our experiments with other samplers based on the class-conditional ImageNet model. In our revised manuscript, we have added a section in the appendix that extends the experiments reported in Table 1 with additional samplers. Specifically, we compared our results on DDIM for both pose-to-image models and reported additional experiments using DPM++ [1] and PNDM [2] samplers with StableDiffusion. The table reporting these additional experiments is shown below.  In addition, our response to Reviewer fxon also includes an experiment of performance-versus-NFE based on DPM++ and DDIM samplers. We observed that across all tested scenarios and samplers, CADS consistently improves the diversity of output over that of the base sampler while maintaining image quality.\n\n| **Dataset** | **Sampler** | **FID** \u2193 | **Precision** \u2191 | **Recall** \u2191 | **MSS** \u2193 | **Vendi Score** \u2191 |\n|:---------|:---------|:---------:|:---------:|:---------:|:---------:|:---------:|\n| DeepFashion | DDIM | 14.60 | **0.93** | 0.02 | 0.80 | 1.03 |\n| | CADS (Ours) | **7.90** | 0.76 | **0.49** | **0.35** | **2.30** |\n| SHHQ | DDIM | 26.27 | **0.70** | 0.15 | 0.57 | 1.27 |\n| | CADS (Ours) | **15.14** | 0.61 | **0.46** | **0.36** | **2.06** |\n| StableDiffusion | DPM++ | 45.70 | **0.70** | 0.29 | 0.19 | 5.30 |\n| | CADS (Ours) | **40.35** | 0.65 | **0.42** | **0.13** | **6.93** |\n| | PNDM | 45.76 | **0.68** | 0.28 | 0.19 | 5.36 |\n| | CADS (Ours) | **41.37** | 0.65 | **0.38** | **0.13** | **6.83** |\n\n\n### **Confusion about the random seed**\n\nWe thank the reviewer for catching this ambiguous terminology. We have changed the term \u201crandom seed\u201d to \u201cinitial random sample\u201d in our working draft, and we will pay additional attention to this section to ensure clarity when finalizing the manuscript.\u00a0 The idea we wish to get across is that *low* diversity means that many different initial random samples are converted by the model to a small number of stereotyped outputs, while *high* diversity means that many different initial random samples are converted by the model to *just as many* distinct outputs.\u00a0 However, when comparing CADS versus non-CADS sampling, we do fix the *local* random seed to guarantee that each method sees the same set of initial random samples, $x_T$.\n\n### **Higher Inception Score (IS) values for DDPM**\n\nAs argued in [3], IS \u201cdoes not reward covering the whole distribution or capturing diversity within a class.\u201d\u00a0 Indeed, one can construct a pathological scenario in which a very small set of exemplar images (say, one or a few for each class) can maximize IS while minimizing diversity by design.\u00a0 Nevertheless, IS is still a popular measure of generative modeling output, which we included for completeness.\u00a0 As IS is also a reasonable measure of image quality, it is worth noting that it consistently *increases* with $w_{\\text{CFG}}$ in Figure 5.\u00a0 That it is somewhat below DDPM may speak more to the nuances of IS than to the quality of output when using CADS.\u00a0 Indeed, we report a similar phenomenon in Appendix F, where the IS value computed on *real* data from ImageNet was significantly lower than the values obtained for DDPM samples. As sampling with higher guidance tends to maximize the class probability $p(y|x)$, the IS of DDPM outputs is possibly artificially inflated. \n\n---\n**References**\n\n[1] Lu, Cheng, et al. \"Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models.\" *arXiv preprint arXiv:2211.01095* (2022).\n\n[2] Liu, Luping, et al. \"Pseudo Numerical Methods for Diffusion Models on Manifolds.\" *International Conference on Learning Representations*. 2022.\n\n[3] Dhariwal, Prafulla and Nichol, Alex. \u201cDiffusion models beat GANs on image synthesis.\u201d arXiv preprint arXiv:2105.05233v4 (2021)."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2574/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700128929158,
                "cdate": 1700128929158,
                "tmdate": 1700138279178,
                "mdate": 1700138279178,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8ndM5Vm7X4",
                "forum": "zMoNrajk2X",
                "replyto": "U9SQ4SRtGN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2574/Reviewer_iK6t"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2574/Reviewer_iK6t"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarifications.\nThe authors resolved all of my concerns.\n\nI will keep my initial rating."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2574/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700628536993,
                "cdate": 1700628536993,
                "tmdate": 1700628536993,
                "mdate": 1700628536993,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "a8rzVamHtp",
            "forum": "zMoNrajk2X",
            "replyto": "zMoNrajk2X",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2574/Reviewer_fxon"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2574/Reviewer_fxon"
            ],
            "content": {
                "summary": {
                    "value": "Although diffusion models are known for good mode coverage, the sample diversity of conditional diffusion models is still challenging when sampling at a high classifier-free guidance (CFG) scale. This work examines the conditional diffusion models and attributes this problem to how the conditional information should be mixed into the reverse diffusion process. \n\nTo tackle this problem, it introduces an annealed sampling scheme for conditional generation, Conditional Annealed Diffusion Sampler (CADS). The core principle of CADS is to gradually increase the strength of conditional information in the reverse time diffusion process, letting the unconditional score model explore better data modes in the early stage (noisy region) and guiding the sampling converge to the conditional distribution using the conditional information in the final stage (data region).\n\nThis work conducted detailed experiments on class-conditional generation, pose-to-image generation, identity-conditioned face generation, and text-to-image generation. CADS consistently improves the sample diversity of baseline conditional diffusion models without retraining."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This is a good paper for conditional diffusion models. Its merits span the following aspects:\n\n1. The proposed method is intuitive and does not require further finetuning on pretrained diffusion models. This allows for improving a wide range of models and samplers. The straightforward approach should be amenable to the broader audience of ICLR.\n2. This work also provides a theoretical explanation for CADS. I found this explanation helpful. It should be added to the main paper using the extra granted page after acceptance.\n3. Decent experimental results. The proposed sampler offers consistent improvements over the baseline diffusion models.\n4. Detailed ablation studies. The ablation studies clearly show the influence of hyperparameters introduced in this sampler.\n5. Writing clarity. This paper is well presented. The methods and experiment sections are well organized. Please move Appendix C. to the main article."
                },
                "weaknesses": {
                    "value": "While the paper possesses several strengths, there is room for enhancement in articulating the motivation behind the methodology. The issue of sample diversity has been clearly defined, yet the rationale for the solution could benefit from a stronger motivation. Ideally, the approach should be presented as a natural derivation from the first principle, rather than retroactively justified through theoretical exposition.\n\nThis critique should not be seen as a detriment to the overall quality of the work. It is, in essence, a good paper for improving the conditional information in diffusion models."
                },
                "questions": {
                    "value": "1. How does this work determine where to add noises to the conditional information? For example, CADS mostly injects noises into the embeddings. However, for the pose-to-image generation, this work adopts the noise injection to the pose image. Is there a guidance to choose the position for conditional noise injection? What if inject noises into the internal layers of the conditional information extractor? What if we also adopt the embeddings noise injection scheme for the face-to-image generation? In other words, how large can the influence of noise injection position be regarding different choices?\n2. Notably, the experiments in this work utilize relatively large sampling steps (>= 100 NFEs). Will the proposed sampler deteriorate at a limited number of function evaluations? How does the conditional generation under CADS change along different sampler steps/NFEs?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2574/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699259274340,
            "cdate": 1699259274340,
            "tmdate": 1699636194175,
            "mdate": 1699636194175,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6ISDEN6cBC",
                "forum": "zMoNrajk2X",
                "replyto": "a8rzVamHtp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2574/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2574/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Response to Reviewer fxon"
                    },
                    "comment": {
                        "value": "### **Motivating the method**\nWe appreciate the reviewer\u2019s suggestion to better motivate the method ahead of its introduction and to move some of the theoretical discussion from the appendix to the main paper.\u00a0 To the best of our knowledge, accepted papers at ICLR do not get an extra page allowance, so we have to assume for the moment that we are working with limited space.\u00a0 However, we agree with the reviewer that the placement of the method\u2019s motivation is important, so we have added a paragraph above Section 3.1 in our working draft to provide readers a better intuition behind the rationale of the solution before introducing the solution itself. Please find the corresponding paragraph below:\n\n> We conjecture that the low-diversity issue is due to a highly peaked conditional distribution, particularly at higher guidance scales, which leads the majority of samples toward certain modes during inference. One way to address this issue is by smoothing the conditional distribution with decreasing Gaussian noise, which breaks and then gradually restores the statistical dependency on the conditioning signal during inference. Next, we introduce a novel sampling technique that integrates this intuition into the inference process. The superiority of this method over the above approaches is depicted in Figure 2.c.\n\n\n### **Where to inject noise**\nMany conditional diffusion models have an embedding layer that provides the actual continuous conditioning signal to the input of the model. This can effectively be a look-up table in the class-conditional case or a continuous functional mapping, such as the CLIP network, for text-to-image generation. This continuous embedding space is ideal for injecting Gaussian noise, and for a more unified approach across various tasks, we injected noise into each condition\u2019s embedding. In some settings, however, such as the pose-to-image task, embedding layers aren\u2019t normally used, as the conditioning information is directly concatenated with the input to the diffusion model [1]. We decided to experiment with the noise injection directly on top of the pose image, since it is this representation that constitutes the conditioning signal in this case. Based on the reviewer\u2019s comment, we also tested a different pose-to-image model that does use an embedding layer and found that injecting noise to the pose embedding also successfully diversifies the model outputs. We saw a similar phenomenon for the face-ID setting, where adding noise either before or after the embedding layer in the diffusion model performed well.\u00a0 The takeaway seems to be that the technique is highly flexible and robust to this design choice, with the key requirement being initially breaking and then progressively restoring the model\u2019s dependence on the conditioning signal, which can be achieved at a number of places in the model.\n\n\n### **Behavior of CADS VS NFEs**\nThis is an excellent question. We have added a section to the appendix of the paper that explores the effectiveness of CADS with respect to different numbers of sampling steps (NFEs). The behavior of CADS vs NFEs is similar to the base sampler, and a consistent gap exists between sampling with and without condition annealing across different NFEs. Additionally, please note that as DDPM does not perform well when using low NFEs, we switched to DPM++ [2] and DDIM [3] to perform this comparison. Please find the results of this experiment in the tables below.\n\n|  | DPM++ w/ CADS | DPM++ w/ CADS | DPM++ | DPM++ |\n| --- | :---: | :---: | :---: | :---: |\n| **NFEs** | **FID** | **Recall** | **FID** | **Recall** |\n| 25 | 7.73 | 0.67 | 17.86 | 0.37 |\n| 50 | 8.56 | 0.64 | 18.64 | 0.36 |\n| 75 | 8.95 | 0.63 | 18.81 | 0.36 |\n| 100 | 9.63 | 0.61 | 18.90 | 0.36 |\n\n|  | DDIM w/ CADS | DDIM w/ CADS | DDIM | DDIM |\n| --- | :---: | :---: | :---: | :---: |\n| **NFEs** | **FID** | **Recall** | **FID** | **Recall** |\n| 25 | 8.45 | 0.64 | 18.67 | 0.36 |\n| 50 | 9.80 | 0.59 | 18.91 | 0.36 |\n| 75 | 10.08 | 0.57 | 18.92 | 0.35 |\n| 100 | 10.16 | 0.58 | 18.96 | 0.35 |\n\n---\n**References**\n\n[1] Saharia, Chitwan, et al. \"Image super-resolution via iterative refinement (2021).\"\u00a0*arXiv preprint arXiv:2104.07636*\u00a0(2021).\n\n[2] Lu, Cheng, et al. \"Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models.\"\u00a0*arXiv preprint arXiv:2211.01095*\u00a0(2022).\n\n[3] Song, Jiaming, Chenlin Meng, and Stefano Ermon. \"Denoising Diffusion Implicit Models.\"\u00a0*International Conference on Learning Representations*. 2021."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2574/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700128571337,
                "cdate": 1700128571337,
                "tmdate": 1700133477587,
                "mdate": 1700133477587,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hs3hp7s7v5",
                "forum": "zMoNrajk2X",
                "replyto": "6ISDEN6cBC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2574/Reviewer_fxon"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2574/Reviewer_fxon"
                ],
                "content": {
                    "comment": {
                        "value": "I really appreciate the author's timely response. This perfectly addressed my questions. Very interestingly, the proposed CADS works even better at small NFEs. \n\n- Could you please further reduce the NFEs? Given the current observations, I assume there will be a U curve regarding FIDs. \n\n- In addition, which dataset/setup was used for this table? (It would be better if this could be further verified using additional setups/models once authors have more time after acceptance. There's no rush to complete it now. Please take your time with this, considering the limited discussion time remaining.)\n\nIt is a great pleasure to review this paper. I have no concerns about this work and will be very happy to see the acceptance.\n\nThanks,\\\nReviewer fxon"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2574/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700454555110,
                "cdate": 1700454555110,
                "tmdate": 1700454555110,
                "mdate": 1700454555110,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]