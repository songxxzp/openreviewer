[
    {
        "title": "Federated Causal Discovery from Heterogeneous Data"
    },
    {
        "review": {
            "id": "G3ozj7k6O9",
            "forum": "m7tJxajC3G",
            "replyto": "m7tJxajC3G",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3985/Reviewer_VxyA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3985/Reviewer_VxyA"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on the problem of federated causal discovery from heterogeneous data, and proposes a novel constraint-based method called FedCDH, which can accommodate arbitrary causal models and heterogeneous data. It constructs the summary statistics to protect data privacy and further proposes federated conditional independence test (FCIT) and federated independent change principle (FICP) for skeleton discovery and direction determination. The experimental results on synthetic and real datasets show the efficacy of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper addresses the issue of heterogeneous data in federated causal discovery and relaxes the assumptions of causal models, which are critical problems.\n2. The paper proposes a novel constraint-based method for effectively conducting federated causal discovery from heterogeneous data.\n3. The paper provides detailed proofs for the presented theorems and lemmas. Extensive experiments demonstrate the effectiveness of the proposed method."
                },
                "weaknesses": {
                    "value": "1. The paper conducts numerous experiments; however, it should provide a more in-depth analysis of the underlying reasons behind the experimental results, rather than just stating the observations.\n2. The section of method overuses symbols, leading to difficulties in understanding.\n3. The presentation of this paper can be largely improved for clarification."
                },
                "questions": {
                    "value": "1. In the penultimate paragraph of page 2, the authors say \u2018Let k be the client index, and \u2127 be the domain index\u2019, what\u2019s the difference between client and domain?\n2. In the last paragraph of page 2, the authors say \u2018When the data is heterogeneous, there must be some causal models changing across different domains. The changes may be caused by the variation of causal strengths or noise variances.\u2019 The authors should better clarify what is the change of causal models.\n3. In the first paragraph of page 3, \u03c8(\u2127) and \u03b8i(\u2127) are functions of \u2127, and \u2127 is a positive integer from 1 to k. Actually, \u2127 is a value defined by the authors, and does it have an impact on the results when it takes different values?\n4. In the fourth paragraph of page 3, as indicated by the authors, \u2127 and Vi are connected by unobserved domain-changing variables \u03c8(\u2127) and \u03b8i(\u2127), so what does it mean of \u2018If there is an edge between surrogate variable \u2127 and observed variable Vi on Gaug\u2019?\n5. The authors should improve the presentation quality of the paper and fix typos. For example:\n(1) In the second paragraph of page 5, \u2018therefore, we would like to \u2026\u2019 -> \u2018Therefore, we would like to \u2026\u2019.\n(2) In the second paragraph of the Section of A6.4 Results of Computational Time, \u2018The results are exhibited in Table A3.\u2019 -> \u2018The results are exhibited in Table A1\u2019."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3985/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698482624910,
            "cdate": 1698482624910,
            "tmdate": 1699636360289,
            "mdate": 1699636360289,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wdSNGXjSLR",
                "forum": "m7tJxajC3G",
                "replyto": "G3ozj7k6O9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer VxyA (1/2)"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer for the time dedicated to reviewing our paper, constructive suggestions, and encouraging feedback. We have carefully **modified the manuscript** in light of your detailed suggestions. Particularly, in order to distinguish between different symbols and avoid confusion, we have **added a new notation table** in Appendix A1. Moreover, **a new set of experiments** is added to evaluate the impact on domain indices. Please find the responses to all your comments below.\n\n\n**Q1:** \"The paper conducts numerous experiments; however, it should provide a more in-depth analysis of the underlying reasons behind the experimental results, rather than just stating the observations.\"\n\n**A1**: Thanks a lot for the constructive suggestion. We would like to clarify that: due to the space limit in the main paper, we have provided some of the detailed analysis in the Appendix. For example, in Appendix A7.2, we concluded the observational results w.r.t. $F_1$ and SHD on synthetic datasets and then provided in-depth analysis on why those phenomena might happen (e.g., FedPC performed the worst, due to its strong assumptions on linear model and homogeneous data; FedDAG and NOTEARS-MLP-ADMM presented worse SHD results compared to our FedCDH, probably because both of them are continuous-optimization-based methods, which might suffer from various issues such as convergence and nonconvexity). \n\nCertainly, we are glad to incorporate your suggestion, to provide a more in-depth analysis for all other experiments. Therefore, we have updated our manuscript with a more detailed analysis, as you can see in Appendix A7.3, A7.4, A7.5, A8.1, and A8.2.  \n\n\n**Q2:** \"The section of method overuses symbols, leading to difficulties in understanding.\"\n\n**A2**: We are grateful for your straightforward and helpful comment. In order to improve readability and avoid symbol confusion, we have summarized and categorized the symbols throughout the paper and put them into the table in Appendix A1. Hopefully, this table can be helpful for the readers, especially when reading the equations and theorems.  \n\n\n**Q3:** \"The presentation of this paper can be largely improved for clarification.\"\n\n**A3**: Thank you so much for the comment. We have tried our best to improve the presentation based on your comments. Hopefully, our responses to your detailed question below from Q4 to Q8 and the accordingly modified manuscript can help to improve our presentation. If there are any other comments you have on the presentation, we would appreciate it if you could kindly let us know.\n\n\n**Q4:** \"In the penultimate paragraph of page 2, the authors say \u2018Let k be the client index, and $\\mho$ be the domain index\u2019, what\u2019s the difference between client and domain?\"\n\n**A4:** Thanks a lot for this great question. A client is a decentralized entity in federated learning, while a domain typically refers to a distinct category of data that share common features. Usually, when one set of data is heterogeneous, we say that the data distribution is changing across different domains. In our paper, we assume that one client corresponds to one unique domain. We have updated this detail in Section 2 of our manuscript.\n\n\n**Q5:** \"In the last paragraph of page 2, the authors say \u2018When the data is heterogeneous, there must be some causal models changing across different domains. The changes may be caused by the variation of causal strengths or noise variances.\u2019 The authors should better clarify what is the change in causal models.\n\n**A5:** Thanks for raising this great suggestion. By \"the change of causal model\", we intend to say that: the structural causal model (SCM) $V_i = f_i(PA_i, \\epsilon_i)$ is different/changing across different domains, that is, the function $f_i$ or the distribution of the noise $\\epsilon_i$ is different/changing across different domains. \n \nTaking a linear SCM as an example, more specifically, we have $V_i = \\sum_{j\\in PA_i} a_{ij} V_j + \\epsilon_i$, where $a_{ij}$ are the coefficients or causal strengths in the causal function and $\\epsilon_i$ is the noise term. When we say the causal models change, then either the causal strength $a_{ij}$ or the noise variance of $\\epsilon_i$ will change across domains.\n\nWe have included the discussion in Section 2 of the updated manuscript."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3985/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700250892552,
                "cdate": 1700250892552,
                "tmdate": 1700250892552,
                "mdate": 1700250892552,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "d5v3HRcHou",
                "forum": "m7tJxajC3G",
                "replyto": "NQVCk5SyXB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3985/Reviewer_VxyA"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3985/Reviewer_VxyA"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your clear response. Most of my concerns have been addressed and I have also read other comments and detailed responses. However, I still have concerns regarding the presentation of this paper."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3985/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700483362314,
                "cdate": 1700483362314,
                "tmdate": 1700483362314,
                "mdate": 1700483362314,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SCPlztKGc0",
                "forum": "m7tJxajC3G",
                "replyto": "G3ozj7k6O9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Could you please let us know more details about your concerns?"
                    },
                    "comment": {
                        "value": "Dear Reviewer VxyA:\n\nWe are very happy that most of your concerns have been well addressed. Thanks for letting us know that you still have concerns regarding the presentation. Could you please kindly let us know exactly what presentation issue you saw with the paper (e.g., which Section or which Figure), so that we can address them as soon as possible?\n\nSincerely,\n\nAuthors of Submission 3985."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3985/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700484050726,
                "cdate": 1700484050726,
                "tmdate": 1700508825101,
                "mdate": 1700508825101,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qOlfQTVfUz",
            "forum": "m7tJxajC3G",
            "replyto": "m7tJxajC3G",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3985/Reviewer_157B"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3985/Reviewer_157B"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors propose a novel FCD method attempting to accommodate arbitrary causal models and heterogeneous data. Specifically, they first utilize a surrogate variable corresponding to the client index to account for the data heterogeneity across different clients. Then they develop a federated conditional independence test (FCIT) for causal skeleton discovery and establish a federated independent change principle (FICP) to determine causal directions. These approaches involve constructing summary statistics\nas a proxy of the raw data to protect data privacy. Owing to the nonparametric properties, FCIT and FICP make no assumption about particular functional forms, thereby facilitating the handling of arbitrary causal models. Extensive experiments on synthetic and real datasets could show the efficacy of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper features a detailed theoretical analysis and addresses a highly challenging problem."
                },
                "weaknesses": {
                    "value": "This paper is relatively difficult to read, and it is not very comprehensible, making it not conducive for others to follow and reproduce the work. This paper presents a list of theorems, but I haven't seen a clear explanation of the specific challenging problem you have addressed. The relationship between these theorems and the contributions of the paper is quite ambiguous."
                },
                "questions": {
                    "value": "Please see the weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3985/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3985/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3985/Reviewer_157B"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3985/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698647855559,
            "cdate": 1698647855559,
            "tmdate": 1699636360210,
            "mdate": 1699636360210,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5dBEzzRLwv",
                "forum": "m7tJxajC3G",
                "replyto": "qOlfQTVfUz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer 157B (1/2)"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer for the time dedicated to reviewing our paper and constructive suggestions. In light of your valuable feedback, we have **updated our manuscript** in the first paragraph of Section 3. To improve the readability of our paper, we have **added a new notation table** in Appendix A1. Please find our responses to your concerns below.\n\n\n**Q1:** \"This paper is relatively difficult to read, and it is not very comprehensible, making it not conducive for others to follow and reproduce the work. This paper presents a list of theorems, but I haven't seen a clear explanation of the specific challenging problem you have addressed. The relationship between these theorems and the contributions of the paper is quite ambiguous.\"\n\n**A1:** Thanks for raising those concerns, which will help to improve the presentation of our manuscript. First of all, in order to improve the readability of our paper, we have summarized the symbols and put them in the table in Appendix A1. Then, to address your main concern, we would like to clarify two aspects: what the contributions of our paper are, and how those theorems and lemmas in the paper are related to each other. (The key theorems, in which our main contributions lie, are in **bold**.)\n\n**The main contributions and the challenging problem we have addressed:** \n- First, in this paper we proposed a novel constraint-based method for federated causal discovery (FCD), which can handle arbitrary functional causal models and heterogeneous data, demonstrating broader applicability compared to the existing FCD methods. \n- Specifically, we proposed two novel submodules, i.e., federated conditional independence test (FCIT; **Theorem 4 and Theorem 5**) and federated independent change principal (FICP; **Theorem 6**), for skeleton discovery and direction determination. Intuitively, they are the federated extensions of previous centralized conditional independent test (CIT) [1] and independent change principal (ICP) [2], respectively. To the best of our knowledge, we are the first work to propose the methods for federated CIT and federated ICP. \n    - In order to satisfy the demand that the raw data must not be directly shared across domains (to protect the data privacy), we proposed summary statistics (**Theorem 8**), consisting of total sample size and covariance tensor. Fortunately, our summary statistics are sufficient to represent all the statistics that appeared in FCIT and FICP.\n- Lastly, to evaluate the efficacy of our proposed method, we conducted extensive experiments on two synthetic datasets (i.e., linear Gaussian model and general functional model) and another two real-world datasets (i.e., fMRI Hippocampus dataset and HK stock market dataset). \n\n**The relationships among the theorems/lemmas:** \n\nIn short, Lemma 1 and 2 are the preliminaries for our method; Lemma 3 is an extension of Lemma 1; Theorem 4 and Theorem 5 are the core parts of FCIT whose proofs rely on Lemma 3; Theorem 6 is the core part of FICP which is based on Lemma 2; Lemma 7 shows the main rules to help derive Theorem 4, 5 and 6; And Theorem 8 concludes that what summary statistics are and how summary statistics are sufficient to achieve FCD. \n\n- Lemma 1 and Lemma 2 provide the fundamental characterizations for the centralized CIT and ICP, respectively. Based on those two lemmas, we try to extend them from centralized versions to the corresponding federated versions. \n- Lemma 3 is an extension of Lemma 1, presenting another characterization of conditional independence (CI). With Lemma 3, we can measure the CI using covariance matrices.\n- **Theorem 4** exhibits the core of our proposed FCIT, with the new test statistics and the asymptotic distribution.\n- **Theorem 5** shows how we can approximate the asymptotic distribution with a two-parameter Gamma distribution for the test, where the mean and the variance are displayed. \n- **Theorem 6** presents our proposed statistics for FICP. Fortunately, the test statistic in Theorem 4, the mean and variance in Theorem 5, and the dependence values in Theorem 6 are all represented in relation to the variance or covariance matrices, which are decomposable with respect to the samples. \n- Lemma 7 is the connection rule that builds the relationship between the kernel matrix and covariance matrix. The rules in Lemma 7 actually help to derive the proofs of Theorem 4, 5, and 6.\n- **Theorem 8** states the sufficiency of our proposed summary statistics. With merely these decomposable summary statistics, we can complete the whole FCD process. \n    \n\nWe sincerely thank you once again for the valuable and constructive suggestions. We hope you will find that our responses, along with updated manuscripts, have properly addressed your concerns. Please kindly let us know if there are any further questions or comments."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3985/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700250536604,
                "cdate": 1700250536604,
                "tmdate": 1700250576404,
                "mdate": 1700250576404,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6phWSiEDgX",
                "forum": "m7tJxajC3G",
                "replyto": "qOlfQTVfUz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Could you please kindly check whether our responses properly addressed your concerns?"
                    },
                    "comment": {
                        "value": "Dear Reviewer 157B:\n\nThank you for your time and efforts in reviewing our paper. We have provided responses and revised the paper according to your constructive comments.\n\nAs the rolling discussion period for our paper is coming to a close, we are still waiting for your feedback on our responses. Could you please kindly check whether our responses properly addressed your concerns? If there are any other concerns, please kindly let us know, so that we can address them as soon as possible. Thank you so much!\n\nSincerely,\nAuthors"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3985/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700654923317,
                "cdate": 1700654923317,
                "tmdate": 1700654923317,
                "mdate": 1700654923317,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8QJKenDJnR",
            "forum": "m7tJxajC3G",
            "replyto": "m7tJxajC3G",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3985/Reviewer_SgBE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3985/Reviewer_SgBE"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a constraint-based federated causal discovery method suitable for heterogeneous data. That is, the paper assumes different but related structural causal models at each client and seeks to discover the global structural causal model where local differences are modeled using domain-specific effective parameters for each variable and a set of domain-specific the pseudo-confounders. The paper proposes to use the Hilbert-Schmidt independence criterion and a (federated) independent change principle, based on the partial cross-covariance operator on a reproducing kernel Hilbert space, which captures non-linearities in the relationship of variables based on the chosen kernel. To make computations tractable, it approximates the kernel with random Fourier features. It shows that these criteria can be computed from summary statistics based on the kernel matrices."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- federated causal discovery is a relevant and interesting problem\n- the method is well motivated and theoretically sound\n- good empirical performance"
                },
                "weaknesses": {
                    "value": "- the method requires that the different domains are known in the application"
                },
                "questions": {
                    "value": "**Questions:**\n- why assume $L$ hidden confounders? How is L set in practice? Could we simply choose $d$ or $2^d$? In the theoretical evaluation, $L$ is assumed to be equal to the number of datapoints n which goes to infinity. Isn't that a problematic assumption, or did I misread the proof of Thm. 4?\n- How does sharing local kernel matrices affect privacy?\n\n**Detailed Comments:**\n- The notation with bold $\\mathbf{\\psi}$ and normal $\\psi$ is visually hard to distinguish.\n- The formulation with an underlying causal graph and an augmented causal graph is not clear to me. For me it made sense to either assume an underlying \"augmented\" graph that captures local differences, or to assume an underlying graph and local interventions - these interventions are then modeled via the augmented graph. If the latter is the case, this should be clarified.\n- Is it necessary to consider $\\mho$ an observable variable? In the experiments, some additional information is used to decide the domain, but in general this is rarely possible. E.g., in [1] the domain is infered. What happens if you assumed that every client has a different domain and $\\mho$ is the client index? \n\n\n[1] Mian, Osman, Michael Kamp, and Jilles Vreeken. \"Information-theoretic causal discovery and intervention detection over multiple environments.\" Proceedings of the AAAI Conference on Artificial Intelligence, AAAI-23. 2023."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3985/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698745807082,
            "cdate": 1698745807082,
            "tmdate": 1699636360115,
            "mdate": 1699636360115,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Ow3ddlg4UT",
                "forum": "m7tJxajC3G",
                "replyto": "8QJKenDJnR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer SgBE"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer for the time dedicated to reviewing our paper, constructive suggestions, and encouraging feedback. We have carefully **modified the manuscript** in light of your detailed suggestions. Particularly, in order to distinguish between different symbols and avoid confusion, we have **added a symbol table** in Appendix A1. Please find the responses to all your comments below.\n\n**Q1:** \"Why assume $L$ hidden confounders? How is $L$ set in practice? Could we simply choose $d$ or $2^d$? In the theoretical evaluation, $L$ is assumed to be equal to the number of datapoints $n$ which goes to infinity. Isn't that a problematic assumption, or did I misread the proof of Theorem 4?\"  \n\n**A1:** Thanks for raising this great question. In Section 2, we use $L$ to denote the number of hidden confounders, where $L$ can be varying. The minimum value for $L$ can be 0, meaning that there is no latent confounder in the graph, while the maximum value can be $C_d^2=\\frac{d(d+1)}{2}$ where $d$ is the number of observed variables, meaning that each pair of observed variables has a hidden confounder. Fortunately, we can directly work on the simplified augmented graph $\\mathcal{G}_{aug}$ with surrogate variable $\\mho$ as shown in Figure 1(b), where we have no need to specify the value of $L$. We have updated this discussion in Section 2 of our manuscript.\n\nHowever, $L$ in the proof of Theorem 4, has a different meaning, denoting the number of nonzero eigenvalues of the kernel matrices. We apologize for the double use of one symbol. We have replaced $L$ with $\\beta$, and updated the proof of Theorem 4 in our manuscript.  \n\nFurthermore, in order to improve the readability of our paper, we have summarized the most important symbols throughout the paper and added the notation table in Appendix A1. \n\n**Q2:** \"How does sharing local kernel matrices affect privacy?\"\n\n**A2:** Thanks for the question. We would like to clarify that: our method does not share the kernel matrices, instead, it shares our constructed covariance tensors. As we mentioned in Section 3.4, sharing the covariance tensor instead of the raw data can preserve data privacy to some extent. Moreover, if each client is required to not directly share the local covariance tensor, one can use some secure computation techniques such as secure multiparty computation [2], to further enhance the protection of data privacy. \n\n**Q3:** \"The notation with bold $\\boldsymbol{\\psi}$ and normal $\\psi$ is visually hard to distinguish.\"\n\n**A3:** Thanks for the great suggestions, which help improve the clarity of our manuscript. In order to distinguish between the two symbols, we have replaced the bold one $\\boldsymbol{\\psi}$ with $\\boldsymbol{\\tilde{\\psi}}$. We have updated the manuscript accordingly in Section 2. \n\n**Q4:** \"The formulation with an underlying causal graph and an augmented causal graph is not clear to me. For me it made sense to either assume an underlying \"augmented\" graph that captures local differences or to assume an underlying graph and local interventions - these interventions are then modeled via the augmented graph. If the latter is the case, this should be clarified.\" \n\n**A4:** Thanks for the constructive suggestion. We agree with the latter point that we assume an underlying graph and local interventions, which are then modeled via the augmented graph. In light of your suggestion, we have updated the manuscript accordingly.\n\n**Q5:** \"Is it necessary to consider $\\mho$ an observable variable? In the experiments, some additional information is used to $\\mho$ decide the domain, but in general this is rarely possible. E.g., in [1] the domain is inferred. What happens if you assume that every client has a different domain and $\\mho$ is the client index?\"\n\n**A5:** We appreciate your insightful comment. That is exactly our assumption\u2014each client has a different domain and $\\mho$ is the client/domain index (one client corresponds to one domain). Such an assumption is natural in the federated learning setting, because the data distribution may often be heterogenous across different clients/domains. Therefore, this client/domain index is an observable variable. We will append this detail in our revised manuscript.  \n\nThank you again for your constructive comments, which are really helpful in improving the quality of the manuscript. Meanwhile, thanks a lot for the appreciation of our work, and we are really encouraged by it. We hope our responses and the modified manuscript can adequately address the remaining concerns. Please let us know if there are any further questions.\n\n\n---\n**References:**\n\n[1] Mian, Kamp, and Vreeken. \"Information-theoretic causal discovery and intervention detection over multiple environments.\" AAAI, 2023.\n\n[2] Cramer, Damgard, et al. \"Secure multiparty computation.\" Cambridge University Press, 2015."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3985/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700250336298,
                "cdate": 1700250336298,
                "tmdate": 1700250336298,
                "mdate": 1700250336298,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "28ZUrMeTk2",
                "forum": "m7tJxajC3G",
                "replyto": "Ow3ddlg4UT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3985/Reviewer_SgBE"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3985/Reviewer_SgBE"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "Thank you for your detailed response. You have answered my concerns and I maintain my positive assessment. Out of curiosity: you encode the client index with $\\mho$ under the assumption that each client has a different domain. In practice, many clients might share the same domain, though. Wouldn't that lead to a large number of superfluous hidden confounders? Would it be possible to infer which domains are similar? Or maybe even which confounder variables essentially encode the same intervention?"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3985/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700579634508,
                "cdate": 1700579634508,
                "tmdate": 1700579634508,
                "mdate": 1700579634508,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "DHcyU86aAI",
            "forum": "m7tJxajC3G",
            "replyto": "m7tJxajC3G",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3985/Reviewer_j4X7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3985/Reviewer_j4X7"
            ],
            "content": {
                "summary": {
                    "value": "This work addresses the problem of federated causal discovery, where one wishes to recover the causal structure of some domain given datasets from multiple independent sources. The authors address this problem by proposing a procedure that leverages summary statistics, rather than individual observations, from each source. The work proposes KCIT, and in order to allow for the adaptation to the federated setting random fourier features are used for an approximation. The work also proposes a federated version of the individual change principle, also leveraging summary statistics. Empirical results are provided which show favorable performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper proposes a very sensible extension to existing work on conditional independence testing and the invariance condition to the federated learning setting. The authors lay out the proposed method well, and the approach is easy to follow and understand. In addition, the experimental results show nice performance in comparison to other methods."
                },
                "weaknesses": {
                    "value": "In my view the largest issue with this method is that there are a few places that lack sufficient specificity. The authors use the kernel conditional independence test as a basis, but don't appear to specify the necessary assumptions on the underlying functional forms, same for the invariance principle. It also isn't clear to me how we should expect the behavior of the federated approach to compare to its non-federate counterpart, e.g., what assumptions are necessary on the number of samples per domain? What is loss of power between the federate and non-federated tests? The authors appeal to random fourier features, which seems necessary (or at least some approximation appears to be necessary) but it isn't clear to me under which conditions we should expect this algorithm to not pay a price for this approximation. I certainly could be missing something, but the proofs provided appear to rely on large sample properties, but it's really unclear to me when those start to kick in, e.g. when should we expect the test to converge? How many samples before the summary statistics applied to the random Fourier features become a reliable representation of the underlying distribution for a given source?"
                },
                "questions": {
                    "value": "All of my questions are largely laid out above. In general, it would be good to get a sense of the finite sample behavior of the proposed method."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3985/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699296792902,
            "cdate": 1699296792902,
            "tmdate": 1699636360033,
            "mdate": 1699636360033,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dbzJq9lyvK",
                "forum": "m7tJxajC3G",
                "replyto": "DHcyU86aAI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer j4X7 (1/2)"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer for the time dedicated to reviewing our paper and constructive suggestions. With the help of this valuable feedback, we believe that our manuscript could be improved a lot. We have added **a new set of experiments** for evaluating the power of the test, and **updated our manuscript** according to your detailed suggestions. Please find the point-by-point responses below.\n\n**Q1**: \"The authors use the kernel conditional independence test as a basis, but don't appear to specify the necessary assumptions on the underlying functional forms, same for the invariance principle.\"\n\n**A1**: We appreciate this insightful comment. Fortunately, these kernel-based methods do not make restricted or specific assumptions on the underlying functional causal models due to the nonparametric properties, in other words, they can handle both linear or nonlinear functions, Gaussian or non-Gaussian data distributions well. \n\nHowever, once the Gaussian kernel is utilized, the kernel conditional independence test implicitly assumes smoothness for the relationship of continuous variables. Similarly, the smoothness assumption is also used for the invariance principle. We have included the details at the end of Section 2 of our manuscript.\n\n \n**Q2**: \u201cIt also isn't clear to me how we should expect the behavior of the federated approach to compare to its non-federate counterpart, e.g., what assumptions are necessary on the number of samples per domain? What is loss of power between the federate and non-federated tests?\u201c\n\n**A2**: Thanks a lot for the insightful questions. We would like to address your concerns one by one as follows.\n- Ideally speaking, the performance of our federated approach should be approaching that of its non-federated counterpart [1]. \n\n- Theoretically, the number of samples should be approaching infinity in order to satisfy the guarantee, e.g., Equation (31) in the proof of Theorem 4 in Appendix A4.2. However, in practice, based on Figure 3 and Figure 4, we found that at least 100 samples per domain can lead to a competitive performance. \n\n- Regarding the loss of power between the federated tests and non-federated tests, we have added the new experiment results in Appendix A7.8. Specifically, we found that the performance of the federated test is quite similar to that of the centralized test [1], and the loss of power is quite small.\n\n\n**Q3**: \"The authors appeal to random Fourier features, which seems necessary (or at least some approximation appears to be necessary) but it isn't clear to me under which conditions we should expect this algorithm to not pay a price for this approximation. \"\n\n**A3**: Thanks for raising this great point. The random Fourier features [2] have shown competitive performances to approximate the kernels using low-dimensional feature space. Theoretically, the more hidden features (or a larger $h$) we use, the better approximated performance the random feature should have. \n\nAs mentioned in Appendix A7.5, we conducted the hyperparameter study on varying $h$. The results show that: while $h$ increases, the performance of our method on the directed graph is getting better. Even though when $h$ is as small as 5, the performance is still good where the $F_1$ score is above 70%.  Furthermore, as we can see from Figure 3 and Figure A3 where $h$ is set to 5, the $F_1$ scores of our method in general outperform other baselines in various settings.\n\n**Q4**:  \"I certainly could be missing something, but the proofs provided appear to rely on large sample properties, but it's really unclear to me when those start to kick in, e.g. when should we expect the test to converge?\" \n\n**A4**:  Thanks for asking this question. Actually, the large sample properties start to be needed when deriving the asymptotic distribution of the test statistic $\\hat{T}$ in Theorem 4 (federated conditional independence test). Specifically, Equation (31) in Appendix A4.2 requires the assumption of large sample size, where we expect $\\hat{T}$ to converge in probability to $\\frac{1}{n^2} \\sum_{i,j=1}^{L} \\lambda_{{\\ddot{X}|Z},i} \\lambda_{Y|Z,j} \\alpha_{ij}^2$ as $L = n\\rightarrow \\infty$. Similarly, we need the large sample properties in Theorem 14 (federated unconditional independence test). We have included the discussions at the end of Section 2 of our updated manuscript."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3985/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700249720686,
                "cdate": 1700249720686,
                "tmdate": 1700252779640,
                "mdate": 1700252779640,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HzKb20P33y",
                "forum": "m7tJxajC3G",
                "replyto": "DHcyU86aAI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Could you please kindly check whether our responses properly addressed your concerns?"
                    },
                    "comment": {
                        "value": "Dear Reviewer j4X7:\n\nThank you for your time and efforts in reviewing our paper. We have provided responses and revised the paper according to your constructive comments.\n\nCould you please kindly check whether our responses properly addressed your concerns? If any explanations remain unclear, we will gladly provide further clarification.\n\nSincerely,\nAuthors"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3985/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700654126443,
                "cdate": 1700654126443,
                "tmdate": 1700654126443,
                "mdate": 1700654126443,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ppkl53uVGX",
            "forum": "m7tJxajC3G",
            "replyto": "m7tJxajC3G",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3985/Reviewer_71ck"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3985/Reviewer_71ck"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a novel constraint-based federated causal discovery method, FedCDH, specifically tailored for heterogenous data distributions mostly existent in FL. Novelty is twofold: Using summary statistics as a surrogate for skeleton discovery and introducing a surrogate variable to model distribution changes. The paper is very well written and shows promising results."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "(1) Topic is very relevant causal inference and ICLR communities. \n\n(2) Nicely written paper with lots of background material and well-documented code.\n\n(3) Federated causal discovery from heterogeneous data is challenging in theoretical and realistic experiment settings. \n\n(4) Ability to operate over general functional models."
                },
                "weaknesses": {
                    "value": "(1) Communication cost for small sample size.\n\n(2) Why have a maximum number of clients of 10?"
                },
                "questions": {
                    "value": "(1) Why the assumption \" We set the sample size of each client to be equal.\" is required? Data heterogeneity can come in number of samples, too. Having unequal samples across clients is realistic.\n\n(2) How the datasets are divided into clients is unclear to me."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3985/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699440214173,
            "cdate": 1699440214173,
            "tmdate": 1699636359965,
            "mdate": 1699636359965,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "m4NQawPqN1",
                "forum": "m7tJxajC3G",
                "replyto": "ppkl53uVGX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer 71ck"
                    },
                    "comment": {
                        "value": "We greatly appreciate the reviewer\u2019s time, encouraging comments, and constructive suggestions. We have carefully **modified the manuscript** according to your detailed suggestions. Please find the responses to all your comments below. Q1 and Q2 below correspond to the points in \u201cWeaknesses\u201d, while Q3 and Q4 correspond to the points in \u201cQuestions\u201d.\n\n**Q1**: \u201cCommunication cost for small sample size.\u201d\n\n**A1**: We sincerely appreciate your comment. As mentioned in the last Section \u201cDiscussion and Conclusion\u201d, we acknowledged that one of the limitations of our paper is that: the efficiency of our summary statistics in reducing communication costs may not be considerable when the sample size n is small, because the raw data is in dimension $\\mathbb{R}^{n{\\times}d'}$ while the constructed covariance tensor is in dimension $\\mathbb{R}^{d'\u00d7d'\u00d7h\u00d7h}$. However, even though the sample size is small, using our constructed covariance tensor could still enjoy other advantages, such as the preservation of data privacy, as mentioned in Section 3.4. \n\n**Q2**: \u201cWhy have a maximum number of clients of 10?\u201d\n\n**A2**: Thanks a lot for the question. We would like to clarify that: following previous work [1], the number of clients in our synthetic experiments include 2, 4, 8, 16, and 32; therefore, the maximum number of clients we considered is 32 instead of 10. Moreover, our method actually does not require constraint on the number of clients. In other words, the number of clients can be any positive number.\n\n\n**Q3**: \u201cWhy the assumption \u2018We set the sample size of each client to be equal\u2019 is required? Data heterogeneity can come in number of samples, too. Having unequal samples across clients is realistic.\u201d\n\n**A3**: Thank you so much for this insightful point. We would like to clarify that: following the setting of previous works such as [1, 2], we therefore set the sample size of each client to be equal. However, this setting is **not a required assumption** in our method. Actually, our method can handle both equal and unequal samples across clients. As we mentioned in the paper (the paragraph above Theorem 8), our constructed global covariance tensor $\\mathcal{C_T}$ is obtained by simply adding up the local ones $\\mathcal{C_{T_k}}$, i.e., $\\mathcal{C_T}=\\sum_{k=1}^K \\mathcal{C_{T_k}}$, which is not related to the local sample size here. Therefore, our method can work well no matter whether each client has an equal or unequal sample size. We have added those details to our manuscript. \n\n\n**Q4**: \u201cHow the datasets are divided into clients is unclear to me.\u201d\n\n**A4**: Thanks for the great question. In our experiments, regarding the generation of synthetic heterogeneous data, we separately generate the data for each domain with different causal models and then combine them together, instead of generating the data and subsequently dividing. We have included this detail in our manuscript. \n\n\nThank you again for all these constructive comments, which are really helpful in improving the quality of the manuscript. We hope our responses and the modified manuscript can adequately address the concerns. Please let us know if there are any further questions.\n\n\n***\n**References:** \n\n[1] Ng and Zhang. \"Towards federated bayesian network structure learning with continuous optimization.\" AISTATS, 2022.\n\n[2] Gao, Chen, et al. \"FedDAG: Federated dag structure learning.\" TMLR, 2022."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3985/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700248748698,
                "cdate": 1700248748698,
                "tmdate": 1700249931900,
                "mdate": 1700249931900,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bPNOUXC08n",
                "forum": "m7tJxajC3G",
                "replyto": "ppkl53uVGX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3985/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Could you please kindly check whether our responses properly addressed your concerns?"
                    },
                    "comment": {
                        "value": "Dear Reviewer 71ck:\n\nWe sincerely appreciate your valuable time, constructive suggestions, and encouragement. Given that the rolling discussion period is coming to an end, could you please kindly provide your feedback on our responses? If there is any other concern, could you please kindly let us know? Thank you very much!\n\nBest Regards, \n\nAuthors"
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3985/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700655753617,
                "cdate": 1700655753617,
                "tmdate": 1700655889670,
                "mdate": 1700655889670,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uJdZCYjCm7",
                "forum": "m7tJxajC3G",
                "replyto": "bPNOUXC08n",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3985/Reviewer_71ck"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3985/Reviewer_71ck"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "Dear authors, \n\nThanks for your contributions and for your detailed response. You have answered my concerns and I maintain my positive score."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3985/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700733435798,
                "cdate": 1700733435798,
                "tmdate": 1700733435798,
                "mdate": 1700733435798,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]