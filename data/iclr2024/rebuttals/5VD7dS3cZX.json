[
    {
        "title": "Rethinking the Solution to Curse of Dimensionality on Randomized Smoothing"
    },
    {
        "review": {
            "id": "XSgTinoUwt",
            "forum": "5VD7dS3cZX",
            "replyto": "5VD7dS3cZX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7661/Reviewer_FGgM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7661/Reviewer_FGgM"
            ],
            "content": {
                "summary": {
                    "value": "This work is a follow-up work of Li et al., Double sampling randomized smoothing, in ICML 2022. Compared to the original randomized smoothing, DSRS leverages another random smoothing distribution $Q$, which could improve the certified radius of randomized smoothing. The main novelty of this work is using the \"exponential general Gaussian\" (EGG) distribution as $Q$, which compared to standard Gaussian changes the exponent from 2 to $\\eta$. The authors claim that this can further improve the certified radius of DSRS."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "N/A"
                },
                "weaknesses": {
                    "value": "I recommend rejecting this submission, because (a) this submission in a very large part is essentially the same as Li et al. (2022); (b) there are fundamental errors in the theoretical analysis as well as the experiments. \n\n## (a) Comparing to Li et al. (2022)\nCompared to Li et al. published in ICML 2022, the only novelty of this submission seems to be the EGG distribution and related theoretical analysis and empirical verification. The theoretical part, however, is almost the same as Li et al. (2022). Specifically, Theorem 1 focuses on the case where $\\eta = 2$, and this statement is the exact same statement as Theorem 2 in Li et al. (2022). Note that the EGG distribution with $\\eta = 2$ is equivalent to the generalized Gaussian distribution used in Table 1 of Li et al. (2022). Although this submission does cite Li et al. (2022), its writing seems to claim that Theorem 1 is a novel result, which is definitely false. In fact, the proof of Theorem 1 is essentially the same as Li et al. (2022), Theorem 2:\n- Lemma C.1/C.2 (this work) = Proposition F.1 (Li et al.). The only difference is $\\eta$, which in my opinion adds almost no additional difficulty to the proof. \n- Lemma C.3 (this work) = Lemma F.2 (Li et al.). Only difference is $\\eta$.\n- Lemma C.4 (this work) = Lemma F.3 (Li et al.). Only difference is $\\eta$.\n- And so on.\n\nMoreover, Section 4.3 is almost the same as Section 5 in Li et al. (2022), except for $\\eta$.\n\nOverall, I don't see any significant difference between this submission before Section 5 and Li et al. (2022), except for $\\eta$. The proofs and the algorithms are all essentially the same.\n\n## (b) Does $\\eta$ really work? No.\nI have pointed out that the only novelty of this submission is $\\eta$, so does $\\eta$ really break the curse of dimensionality as the authors claim? I don't think so, and I think that there are two fundamental errors:\n\nTheoretically, in Theorem 4 the authors proved an $\\Omega(d^{1/\\eta})$ lower bound of the certified radius, and claim that this bound gets larger as $\\eta$ gets smaller. The problem is that when $\\eta$ becomes smaller, then the premise of this result also becomes stronger. Specifically, with the same $\\sigma$ and $p$, the $(\\sigma, p, \\eta)$-concentration assumption is stronger as $\\eta$ becomes smaller. So of course with a stronger assumption, the certified radius will become larger. And it seems to me that the authors are aware that $\\eta$ does not make the bound tighter, as they mentioned at the top of page 6 as well as in Eqn. (54) in Theorem 4. This even baffles me more why the authors would claim that EGG could lead to \"much tighter constant factors\" (in the first contributioin).\n\nEmpirically, Table 2, if it is correct, shows that EGG only with $\\eta = 8.0$ has a very marginal improvement over DSRS. However, before Theorem 1, the authors wrote \"all EGG with $\\eta \\in (0,2)$ have the potential to break the curse\", which is not verified by Table 2, and seems to contradict with $\\eta = 8.0$ in the experiments.\n\nIn conclusion, this work in a very large part is the same as a prior work, its claims are quite misleading, and it contains fundamental errors. Thus, I recommend rejection."
                },
                "questions": {
                    "value": "The authors need to do a very detailed comparison between this submission and Li et al. (2022), including comparison of the methods, the theoretical results and their proofs, the experiment settings and results, and the conclusions.\n\nAlso, Theorem 1 is the same as Theorem 2 in Li et al. (2022), so there is no need to write the proof again. The extension of that theorem to $\\eta \\neq 2$ is very straightforward and only requires a brief explanation. Please also see my comments in the ethics review section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "This submission, in a very large part before Section 5, is essentially the same as Li et al. (2022). It does raise some research integrity concern. I am not flagging for ethics review, only because it is possible that the first author is a junior student who just started doing research, and I want them to know that a submission with so much similarity with prior work but without proper reference is not acceptable. It is necessary and crucial to clearly label in the paper which results are from prior work, which results are new, and how the new things are different from prior work. For example, if Theorem 1 is exactly the same as a previous result up to paraphrasing, then this previous result must be clearly cited alongside Theorem 1, and the same proof should not be written again. If a theorem is a generalization or an extension of a previous result, then the difference between the two results should be elaborated."
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7661/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698176551499,
            "cdate": 1698176551499,
            "tmdate": 1699636932155,
            "mdate": 1699636932155,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "x15kad2wDK",
                "forum": "5VD7dS3cZX",
                "replyto": "XSgTinoUwt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7661/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7661/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We Thank but Disagree with the Reviewer"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the careful reading on the paper. However, according to reviews, our contributions are largely and comprehensively underesitmated. \n1. The first title of this paper is actually 'Effects of Exponential Gaussian Distributions on Double Sampling Randomized Smoothing'. The major concern of this paper, as the reviewer mentioned, is on how changing the exponent $\\eta$ influences the theoreical and practical results of certifications from (DS)RS. We emphasize that we are not trying to hide this intuition for the work.\n2. About our Theorem 1. The Theorem 1 is definitely novel, or at least, absolutely a generalization for the conlusion from Li et al. (2022). This is because $\\eta$ does not only appear in the concentration assumption, but also in the smoothing distributions. In other words, definition 2 and theorem 1 are distinctive things, where when $\\eta=2$, the definition 2 reduces to the same thing in Li et al. (2022) (their definition 3). But theorem 1 is far from a copy, it is describing the fact that under the same concentration assumption in Li et al. (2022), $\\eta \\in (0,2)$ provides tigher constant factors than $\\eta=2$, which is what we specifically describe in 'Study on the constant factor' in page 6. We maintain that this section should be more carefully read and understood. \n3. About Theorem 4. Different with Theorem 1, the existence of theorem 4 is to show that the exponent $\\eta$ can be formally introduced into the lower bound, rather than to prove the $\\Omega({\\sqrt{d}})$ once again. We have also learned the the concentration assumption here is stricter than that in theorem 1 (see Remark in page 24), and its fundamental equivalence to theorem 1 (top of page 6) or its logical naturalness. These are also why we put theorem 4 in the appendix instead of the text. However, we do not believe the equivalence of $\\sigma \\sqrt{d}$ to $\\sigma_s d^{\\frac{1}{\\eta}}$ is an obvious conclusion to the community without any clarification, or only showing Eqn. (62)-(64).\n4. The experimental results. Firstly, we don't understand why our method, that brings holistic improvements on extensive mainstream datasets and training methods to General Gaussian distribution is called 'margined'. Is it because the increment on CIFAR10 is not strong? If so, please also consider the ImageNet results. Overall, the contribution of our work is far beyond breaking the SOTA, because the deep and meticulous study on the smoothing distributions reveal the potenitial restrictions to the current solution the curse of dimensionality and the double-sampling method, and taking other $\\eta$ effectively alleviates the limitation of the origin method, both theoretically and pratically.\n5. The seemlingly contradictory conclusions for theories and experiments. Actually, we have deeply explored and explained this phenomenon in the text. In short, our theories tell that the smaller $\\eta$ the better, while the experiments tell that the larger $\\eta$ the better. One key insight of our paper is revealing that these findings are not incompatible, which comes from the concentration assumption. See the 2nd paragraph of analyses in page 9. Briefly, if the concentration assumption strictly holds (p=1), smaller $\\eta$ is better, otherwise (p<1) larger $\\eta$ is better. Our theory is based on the $p=1$ assumption, but the real classifiers can only satisfy $p<1$, which is the decisive reason of the seemingly opposite conclusions. Figure 10 further shows this extreme sensitivity to $p$ of the concentration assumption, that there is a large gap between effects of even $p=0.99999$ and $p=1$.\n6. Ethic concerns. Our theorem 1 is defintely not found by Li et al. (2022), and is in essence considering the generalization from 2 to real numbers for DSRS. As we have mentioned, definition 2 is indeed the concentration assumption in Li et al. (2022), but we have clarified this in the next paragragh of definition 2. In fact, we feel deeply astonished, confused, and discontented on the statement of so-called '(im)proper reference' and ' integrity concern'.\n\nFinally, the generalization from $\\eta=2$ to $\\eta\\in\\mathbb{N_+}$ is absolutely not a trivial improvement like deleting $2$ and press an another number on the keyboard to obtain the results. On the contrary, it needs thorough understanding on Li 2022, methods in Yang 2020 to figure out why we can improve the framework from the perspective of exponent of distribution. This perspective, as far as we are concerned, are never systematically investigated by the community. Moreover, contrary to what the reviewer said, there do exist difficulties for our derivation. In addition to the significant bar on mastering the precedent work, some core details for calculating the certified radius are blank on the Internet, especially on EGG and ESG distributions themselves. Furthermore, stepping into unknown fields for human beings, going deep and offering valuable insights inherently contains big challenges."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7661/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699686967449,
                "cdate": 1699686967449,
                "tmdate": 1699690747374,
                "mdate": 1699690747374,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CjLrZRv2rI",
                "forum": "5VD7dS3cZX",
                "replyto": "XSgTinoUwt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7661/Reviewer_FGgM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7661/Reviewer_FGgM"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "I thank the authors for their response.\n\n1. I would like to apologize for my earlier misunderstanding. Now I can see the difference between Theorem 1 in this work, and Theorem 2 in Li et al. (2022). However, given that the difference is so subtle, I would like to suggest the authors particularly highlight this difference before or after this result. It was not until the fifth time I read these two statements that I finally found the difference, especially given that they have the exact same bound. Also, I still think that Theorem 2 of Li et al. (2022) has not been properly cited in your Theorem 1. I would suggest you change the name of Theorem 1 to \"Generalization of Theorem 2 of Li et al. (2022)\". \n\n2. I would like to remove my comments of ethics concerns (openreview does not allow removing ethics comments though). But still, I think that the proof in your Appendix C is way too similar to the proof in Appendix F of Li et al. (2022). I don't know why there is a need to copy so many things from a previous paper. It would be sufficient for the authors to just describe how to extend Li et al.'s result from $\\eta = 2$ to other $\\eta$, for example using Yang et al.'s results, and I don't see why this has any significant technical difficulty.\n\n3. And still, I cannot see how your results give tighter constant factors. Theorem 1 has the exact same bound as Li et al. (2022). And as for Theorem 4, like I mentioned in my review, it requires a stronger assumption.\n\n4. Regarding the experiments and your fourth point: First, I do not understand why an improvement on CIFAR-10 from 57.4% to 57.6%, and sometimes even worse than DSRS, should be called anything other than \"marginal\" (by the way, reviewers Ba1f and 2qpb also call it \"marginal\"). And it is not surprising at all that EGG can be *better* than DSRS, because EGG with $\\eta =2$ is exactly DSRS so you can never be worse than DSRS, and by adding one degree of freedom in hyperparameter tuning EGG can get better results without doubt. My point is that this improvement, from any scientific lens, is not significant.\n\n5. Second, your theorem focused on $\\eta \\in (0,2)$, but your experiment shows that $\\eta = 8.0$ is the best, which is contradictory to your theoretical results. I cannot understand your analysis on this contradiction in page 9, as well as the fifth point in your response. Let me make my question really simple: This paper is proposing \"EGG\", your theory says that \"EGG with $\\eta \\in (0,2)$ is good\", but your experiments say that \"EGG with $\\eta \\in (0,2)$ is actually not good, but EGG with $\\eta = 8$ is good\". So what is exactly your proposal? EGG with $\\eta \\in (0,2)$ which is not verifiable in your experiments, or EGG with $\\eta = 8$ which is not justified by your theory? Or if you are proposing both, do you have a practical, implementable method of selecting this $\\eta$, other than testing over all $\\eta$ and hand-picking the best one? If I select $\\eta$ with a validation set, could I get the best $\\eta$? If this is the case, then you will need to show this with experimental results.\n\n6. Finally, I still recommend adding a detailed and careful comparison between your work and Li et al. (2022) given their great similarity, including a comparison on the theoretical results, their proofs and the experimental setups and results. This would definitely help anyone reading this work who is not extremely familiar with Li et al. (2022)."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7661/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699719493771,
                "cdate": 1699719493771,
                "tmdate": 1699721323246,
                "mdate": 1699721323246,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "AaB9QAZZy6",
                "forum": "5VD7dS3cZX",
                "replyto": "Vkv3QQygH3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7661/Reviewer_FGgM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7661/Reviewer_FGgM"
                ],
                "content": {
                    "title": {
                        "value": "Reviewer Response"
                    },
                    "comment": {
                        "value": "I thank the authors for their newest response.\n\n### 1. Tighter constant factor\nIf I understand it correctly, the authors are saying that the tightest $r$ that EGG with $\\eta$ can certify is given by $F(r; \\eta)> 0 $, and this $F$ is given by Eqn. (29). However, Eqn. (29) does not have a closed-form solution, so the authors use binary search to find the best $r$. I have not entirely grasped how this could work out, but this seems interesting. I have the following suggestion to the authors:\n- This discussion, especially Eqn. (29), should appear in the main body Theorem 1 because \"tighter constant factor\" is one of your main claims. It should not be the readers' job to delve so deep into the proof to find out why your main claim makes sense.\n- Binary search seems only a method of finding solution to Eqn. (29), and other solvers are also feasible. So \"binary search\" does not seem to be the main point here, but rather Eqn. (29) $F(r; \\eta)> 0 $ is what really makes your bound tighter. Right now \"binary search\" is confusing, especially after (4) where you wrote \"through binary searching on $\\lVert \\delta \\rVert_2$, we obtain the certified radius of example $x_0$\"; when I first read this, I had zero idea of how this binary searching would work.\n- It would be very helpful if the authors could provide some intuition on why a smaller $\\eta$ could lead to a tighter constant factor. Let's consider the extreme case $\\eta = 0$, then $G$ and $G_t$ become polynomially tailed distribution. The argument is basically: Suppose the base classifier is exponentially smooth (such that it satisfies the $(\\sigma, p, 2)$-concentration property), then using another polynomially tailed distribution to smoothify the base classifier could lead to a larger certified radius. Without having checked the proof very carefully, I have very little intuition how this could work out.\n\n### 2. Point 2 of general response\nIf I understand it correctly, what the authors are saying with the new table is that a larger $\\eta$ would not only help DSRS, but also the original NP certification. I have the following questions:\n- This would be very interesting if this is true. In this case, why do you choose to only focus on DSRS, instead of the more general and well-known original NP certification where probably the effect of $\\eta$ could be understand more easily? Why don't you just say that you improve the constant factor of NP certification?\n- \"If the concentration property strictly holds, then smaller $\\eta$ is better; if not, then larger $\\eta$ is better\":\n    - First, how could one verify whether the concentration property strictly holds or not in practice? I don't think this property is very easy to verify, because it requires a conditional probability to be strictly 1, which cannot be verified by simple Monte-Carlo.\n    - Second, can the authors give an example of a real dataset, where the concentration property strictly holds and a smaller $\\eta$ works better?\n    - Third, it is still hard for me to see why this argument makes sense. For example, suppose there is a base classifier $f$ such that the concentration property strictly holds. One can easily break this property by changing the value of $f$ in a very small neighborhood of $x_0$ with a very small measure. Then, according to the authors, it suddenly changes from \"a smaller $\\eta$ is better\" to \"a larger $\\eta$ is better\". I really cannot see why this is correct."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7661/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700405864865,
                "cdate": 1700405864865,
                "tmdate": 1700405864865,
                "mdate": 1700405864865,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "AnvzBIRyxp",
                "forum": "5VD7dS3cZX",
                "replyto": "XSgTinoUwt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7661/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7661/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response with Updated Paper"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the time spent on careful reading, deep thinking and writing the response on the paper.\n\n**The constant factor.**\n\nThis is the right understanding. Taking Eqn. (30) as the example, we let \n\n$F(r; \\eta)=\\mathbb{E}_u\\Psi(\\frac{T^2-(\\sigma_g(2u)^{\\frac{1}{\\eta}}-r)^2}{4r\\sigma_g(2u)^\\frac{1}{\\eta}})-\\frac{1}{2}$.\n\nThen, for a given $r$, if $F(r; \\eta) > 0$, $r$ is certified, else $r$ is not certified. For the points:\n\n$\\cdot$ We have reorganized page 6 in the latest version: adding details for Eqn. (30) as Eqn. (8), and moving Theorem 1 to the appendix.\n\n$\\cdot$ We are sorry for the ambiguous presentation, and have deleted the confusing \u2018binary search\u2019 in the text.\n\n$\\cdot$ About little $\\eta$. We have considered the mechanisms carefully on why small $\\eta$ provides better theoretical results, but find this is beyond our intuition at present. \n\n(1) One possible reason is that a concentration assumption becomes more and more strict for EGG when $\\eta$ gets smaller. For this, we can consider fixing a $T$ in Figure 5 (left). Then, for EGG with smaller $\\eta$, more mass of the distribution $(r<T)$ is contained by $T$ (meaning larger proportion of perturbed examples will be correctly classified on the base classifier). However, intuitively, the certified radius is not uniquely influenced by their PDF, it can also be affected by other geometric properties. We did not mention this in the text, since it is not systematic enough.\n\n(2) By introducing an additional distribution, it is rational that the NP certification can be improved. This is because the NP lemma is always considering the most conservative case and constructing the 'worst smoothed classifier' based on known information  (such as probabilities from MC sampling) of the given classifier. DSRS improves NP by bringing in extra information for the given classifier, and is capable of constructing a 'better worst smoothed classifier' to provide certification (as well as certified radius) for examples. The intuition to improve certification with additional information also appears in other papers. For instance, [1] and [2] improve the certifications by introducing gradient information of the base classifier.\n\n**Why focus on DSRS.**\n\nYes, from our experiments, increasing $\\eta$ in EGG improves the certification for both NP and DSRS. More specifically, our **theoretical analysis** sets $B=1$ (the concentration assumption is perfectly satisfied), finding smaller $\\eta$ in EGG provides tighter lower bounds **for DSRS**. Besides, our **experiments** on real datasets and real base classifiers ($B<1$, the concentration assumption is not perfectly satisfied) show larger $\\eta$ in EGG gives better certifications **for NP and DSRS**. In other words, $\\eta$ performs great for DSRS both theoretically and practically, but we do not include specialized theories on NP. This is why we take DSRS as the principle line.\n  \n**The concentration assumption.**\n\n$\\cdot$ On the verification and practical use of concentration assumption. At the current stage, the perfectly satisfied concentration assumption is an ideal case, that we may only realize it by numerical simulation, such as setting $B=1$ when computing. Therefore, it is beyond our ability to train a classifier that gives absolutely right predictions for a noised real dataset, even if the level of the noise is restricted.\n\n$\\cdot$ Why our conclusions make sense. \n\n(1) The large gap between 0.99 and 1 also appears in Li et al. (2022) (their figure 2a). In that figure, DSRS w/N = 1e7 is equal to B=0.9999993, DSRS w/N = 1e6 is equal to B=0.999993 in our paper (their probabilities was simulating the Clopper-Pearson lower bound, while we directly set them). As they showed, the large 'gap' between $B=0.99$ and $B=1.0$ exists, and the $B=1$ can provide very large certified radius, but DSRS w/N = 1e7 can only provide $r<3$.\n\n(2) The essential reason for the gap is our Lemma C.3 or Li et al. (2022)'s Lemma F.2. The key point here is, if the assumption holds at 0.99, then it only takes effect on the specified distribution (say, Gaussian). But if it holds at 1, then it takes effect for every distribution, because the specified distribution has positive density everywhere.\n\n(3) Our conclusions are based on rigor derivation and experiments, which are checked multiple times (codes included). We also want our results to look concise, but we must obey science and practice.\n\nRefs:\n\n[1] Mohapatra J et al. Higher-order certification for randomized smoothing[J]. NeurIPS, 2020, 33: 4501-4511.\n\n[2] Levine A et al. Tight second-order certificates for randomized smoothing[J]. arXiv preprint arXiv:2010.10549, 2020."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7661/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700553292925,
                "cdate": 1700553292925,
                "tmdate": 1700622655106,
                "mdate": 1700622655106,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Ul13DemUEv",
                "forum": "5VD7dS3cZX",
                "replyto": "AnvzBIRyxp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7661/Reviewer_FGgM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7661/Reviewer_FGgM"
                ],
                "content": {
                    "title": {
                        "value": "Reviewer Response"
                    },
                    "comment": {
                        "value": "I thank the authors for their discussion. I think I have sort of understood why the authors claim that $\\eta$ should be smaller when Eqn. (6) holds with probability 1, and $\\eta$ should be larger when Eqn. (6) holds with probability less than 1. Here is my understanding:\n1. When $\\eta$ is smaller, $Q$ becomes more polynomially tailed, that is it is less smooth; when $\\eta$ is larger, $Q$ is smoother.\n2. \"Eqn. (6) holds with probability 1\" is in fact a very strong assumption, because regardless of $\\eta > 0$, $S(\\sigma, \\eta)$ is always supported on the entire Euclidean space. Thus, Eqn. (6) is equivalent to $f(x) = y _0 \\text{ a.e. } \\lVert x - x _0 \\rVert _2 \\le T$. In other words, $f(x)$ is essentially a constant within a ball centered at $x _0$ with radius $T$.\n3. Under this very strong assumption, one can choose $Q$ to be a less smooth distribution, and get a large certified radius as long as this ball has a sufficiently large measure under probability measure $Q$. There is no point to use a large $\\eta$, because a larger $\\eta$ will make $Q$ more \"concentrated\" at $x _0$, but it is already assumed that $f$ is a constant within a ball so why bother using a concentrated distribution? In other words, a smaller $\\eta$ allows more \"exploration\" outside this ball.\n4. However, if Eqn. (6) holds with probability less than 1, then $f$ does not have this nice constant ball as a foundation. As a result, choosing $Q$ to be a less smooth distribution will not give a larger statistically certifiable radius. And if the probability Eqn. (6) is much lower than 1, then a more concentrated $Q$ (with a larger $\\eta$) could increase the ACR.\n\nBased on the above understanding, I have the following comments:\n1. It seems that Eqn. (6) is a very strong assumption, because it is equivalent to saying that $f$ is a.e. constant within a ball centered at $x _0$. However, if such a ball is **assumed**, then it naturally implies that the model is adversarially robust, so what is the point of certification at all? Thus, my feeling is that Definition 2 is not a reasonable assumption. To make it more reasonable, the probability of Eqn. (6) should be strictly less than 1, say 0.99.\n\n2. I think that \"using a larger $\\eta$ can lead to a larger certified radius for the original NP certification\" would be a super interesting and groundbreaking result if it could be proved. I am not sure if this has been proved in a prior work. If not and if the authors could prove this, then I would give a score of 10 without any doubt. I don't think this conjecture has anything to do with the specific formulation of DSRS. Basically this conjecture is saying: If the model is known to be smooth upon smoothifying with some distribution $P$, then using another smoother distribution $Q$ to smoothify the model could lead to a higher certified radius. This is a very pure and well-posed statistics question, and it is really such a result that could be \"going deep and offering valuable insights\".\n\n3. I don't think using a small $\\eta$ could be beneficial at all, under any reasonable assumptions. Indeed, the authors' experiments show that using a small $\\eta$ hurts the performance. Like I said in my earlier response, the extreme case of a small $\\eta$ is $\\eta = 0$, where $Q$ would become polynomially-tailed, and assuming that the model is only smooth w.r.t. an exponentially-tailed distribution, I couldn't see how this $Q$ would be helpful at all. Theorem 1 gives the illusion that a small $\\eta$ would help, only because it is based on a not very reasonable assumption (Definition 2), which by itself has already implied that the model is robust.\n\nTo sum up, I will still vote to reject this submission, because I believe that the main theoretical result (Theorem 1) which says that a smaller $\\eta$ could improve certification is not sound and potentially misleading. The core reason is that its foundation is a very strong assumption. The empirical evidence of my argument is the experimental results provided by the authors themselves. \n\nMy suggestion to the authors is to consider the following research question:\n- Suppose Eqn. (6) holds with probability strictly less than 1, say 0.99. Then, for the original NP certification, prove that using a larger $\\eta$ could provably lead to a larger certified radius. To prove this, one needs to show a lower bound of the CR for a large $\\eta$, and an upper bound for a small $\\eta$, and then show that the former is greater than the latter.\n\nIf such a result could be proved, then I would rate \"strong accept\" without any doubt, and I can assure the authors that any reviewer sufficiently familiar with this field would rate the same. I can imagine that proving this could be extremely hard, but given that the authors aspire to do deep research, this is a direction I would strongly recommend."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7661/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700629623181,
                "cdate": 1700629623181,
                "tmdate": 1700629623181,
                "mdate": 1700629623181,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EIphGLh3wS",
                "forum": "5VD7dS3cZX",
                "replyto": "XSgTinoUwt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7661/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7661/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "We thank the reviewer for replying again. Here we have the following points to clarify:\n\n1.Smoother smoothing distribution $\\nRightarrow$ smoother classifier or better certification\n\nThe word 'smooth distribution' looks ambiguous. From the context, we speculate it refers to differentiability of the PDF of distributions. If this is the case, then the smoothness of distribution has no direct correlation with the smoothness of the classifier, and also, does not guarantee greater certified accuracy. A simple example: Laplace (ESG, $\\eta=1$) is less smooth than Gaussian (ESG, $\\eta=2$), but they basically provide similar certifications (Table 3). Likewise, in DSRS, we do not think truncated general Gaussian is smoother than general Gaussian. In other words, the smoothness of a distribution is not a significant factor for choosing the supplementary distribution.\n\n2. The understanding of the mechanism is inaccurate.\n\n(1)  EGG with larger will not be more concentrated at $x_0$. Instead, it will be concentrated in a shell, at a distance from $x_0$ (which is the thin-shell phenomenon, Zhang et al. (2020)).\n\n(2) In our work, we emphasize the existence of a gap between $B=0.99$ and $B=1$, and the distinct performance of EGG under very similar settings. The reviewers' intuition on $B=1$, is very close to our tentative explanation, which we believe is insufficient for understanding the behavior of EGG under $B<1$.\n\n3. The concentration assumption.\nThe concentration assumption is actually an extrapolation for an observed phenomenon, rather than fabricated from the thin air. It originated from Li et al. (2022), which is essentially enlightened by the observation of some real robust classifiers. For this, we recommend the reviewer to their Figure 4 and their Appendix J.1. In that figure, each blue curve represents the performance of a test data from ImageNet perturbed by 1000 random Gaussian noise on a pre-trained robust classifier. For example, a point (190, 0.99) on a curve means the robust classifier has a 99% accuracy on 1000 perturbed points, and the $l_2$ length of perturbations can reach up to 190. In addition, there are abrupt downfalls in most blue curves, most of which begin to plunge after the green peak in the figure, which is where the Gaussian noises gather. The observations above are why the concentration assumption was proposed. Moreover, even if the concentration assumption strictly holds, it does not mean the classifier is robust, because this robustness is not only a local property, but also limited to specific inputs.\n\n4. We thank the reviewer for providing a prospective studying project for us, we will consider it in our future research.\n\nFinally, We remark that our contributions are underestimated, and are not fully understood by the reviewer. But we still thank the reviewer for the plenty of time spent on our work."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7661/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700722793237,
                "cdate": 1700722793237,
                "tmdate": 1700729120261,
                "mdate": 1700729120261,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5oSTVr6WyN",
            "forum": "5VD7dS3cZX",
            "replyto": "5VD7dS3cZX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7661/Reviewer_2qpb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7661/Reviewer_2qpb"
            ],
            "content": {
                "summary": {
                    "value": "The paper extends the DSRS framework to a family of distributions called the Exponential General Gaussian (EGG) distributions. Assuming Li et al.'s concentration condition, the authors show that the proposed framework is capable of producing better certified radii (in the constant factor). Furthermore, the authors show that for stronger concentration assumptions, the proposed method can produce polynomially better certified radii. The authors also provide a truncated version of the distributions for the additional distribution in the DSRS framework and give an algorithm to solve the optimization problem to compute the certified radii under the extended framework. Finally, the authors show the empirical advantage of the proposed method on real-life datasets, CIFAR10 and Imagenet."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The suggested framework extends the DSRS framework to a larger family of distributions that can provide theoretically better bounds (better in the constant multiplier) under Li et al.'s concentration assumption. The paper also proposes a more general concentration assumption under which the proposed distributions can polynomially better certified radii.\n- The proposed method is able to provide better certified accuracy than the current state-of-the-art method on both CIFAR10 and Imagenet datasets. At larger radii, the certified accuracy on Imagenet beats the current SOTA by 4-6%."
                },
                "weaknesses": {
                    "value": "- The empirical performance on the CIFAR10 dataset is only marginally better than the current SOTA. It is not clear why this happens."
                },
                "questions": {
                    "value": "Please check the weaknesses section.\n\nTypos\n- When introducing the PDFs, I think you wanna say \"We let $S(\\sigma, \\eta)$ and $G(\\sigma, \\eta, k)$ be the probability density functions (PDFs) of ESG and EGG, respectively\". Currently, the ordering is wrong.\n- Similarly for substitution variances, \"We let $\\sigma_s$ and $\\sigma_g$ be the substitution variances of ESG and EGG, respectively\""
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7661/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698794461776,
            "cdate": 1698794461776,
            "tmdate": 1699636932032,
            "mdate": 1699636932032,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "V71PcnYtwZ",
                "forum": "5VD7dS3cZX",
                "replyto": "5oSTVr6WyN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7661/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7661/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the time as well as the encouraging feedback. We would like to deal with the questions as follows.\n\n$\\cdot$ We have some additional materials for experiments on CIFAR10 in point 2 of the global response, please check it if necessary. In fact, the comparison between DSRS and EGG, $\\eta=8.0$ is not totally fair, because DSRS takes $\\mathcal{Q}\\neq$ TEGG when providing the baseline for CIFAR10. If we pay attention to EGG, $\\eta=2.0$, we can see the improvement brought by EGG, $\\eta=8.0$ is significant. \n\n$\\cdot$ We have corrected these typos accordingly.\n\nWe hope our response has resolved your concerns on the paper, and would welcome any further discussion."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7661/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700062175134,
                "cdate": 1700062175134,
                "tmdate": 1700062175134,
                "mdate": 1700062175134,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8Ig40bIOiC",
            "forum": "5VD7dS3cZX",
            "replyto": "5VD7dS3cZX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7661/Reviewer_Ba1f"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7661/Reviewer_Ba1f"
            ],
            "content": {
                "summary": {
                    "value": "This work conducted some theoretical study on the lower bound of $\\ell_2$ certified radius with a tighter constant, compared to the previous work DSRS. The experiments results verified the theory in some cases."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This work contains some theoretical finding and the corresponding empirical experiments to verify these finding.\n2. The paper is easy to follow."
                },
                "weaknesses": {
                    "value": "1. As the title already suggested, the paper is mainly to study the certified radius in high dimensional space. Therefore, making the constant tighter is not of significant interest for research purposes because the dominate term is always the dimension $d$. Making the order of $d$ smaller is definitely of interest.\n2. The author needs to include the variance for each experiments. By theory, EGG distribution should yield certified accuracy no smaller than DSRS. However, EGG has smaller certified accuracy in some cases in Table 2, which suggest there is a variance issue. So it's good to report variance.\n3. Marginal improvement: for most of the cases in Table 2, the improvement is no larger than 0.5%. This coincides with the intuition mentioned in weakness 1: making the constant tighter in high dimensional space will only yield incremental improvement."
                },
                "questions": {
                    "value": "Minor:\n1. It's better to write Neyman-Pearson Lemma instead of NP lemma, as NP can represent many terms.\n2. In theorem 1, \"let d be a sufficient(ly) large input dimension...\"\n3. In theorem 1, are the $\\eta$ in P and Q the same? It also seems surprised to me that the lower bound doesn't depend on $k$ and $\\eta$. This means any values of $k$ and $\\eta$ will lead to the same lower bound."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7661/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7661/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7661/Reviewer_Ba1f"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7661/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698809290848,
            "cdate": 1698809290848,
            "tmdate": 1699636931894,
            "mdate": 1699636931894,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MUoYBFmWhO",
                "forum": "5VD7dS3cZX",
                "replyto": "8Ig40bIOiC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7661/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7661/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "We provide thanks to the reviewer for the effort put into the review, and give our feedback as follows.\n\n**Weaknesses:**\n1. One of our initial motivations for the work, quite similar to what the reviewer mentioned, is to improve the order of $d$, and we did have the trial in our work (see the second paragraph on page 6). In our derivation, the exponent $\\eta$ can be introduced into the order of $d$ to form $\\Omega(d^{\\frac{1}{\\eta}})$. Despite it being proved an equivalent bound to $\\Omega(\\sqrt{d})$, our theorem shows EGG with $\\eta\\in(0,2)$ can improve the constant factors efficiently. We believe our theoretical results, though do not break the  $\\sqrt{d}$ order, can propel and enlighten future studies in this topic.\n\nIn fact, the initial title of this paper is 'Effects of Exponential General Gaussian on Double Sampling Randomized Smoothing'. That is to say, we emphasize a lot on thinking from the perspective of the exponent, and its effect on the (double sampling) randomized smoothing framework. In addition to the investigation on curse of dimensionality, our work also provide substantial insights on RS and DSRS including:\n\n$\\cdot$ Our experimental results for EGG show seemingly contrary rules with theoretical analysis. Specifically, our theorems reveal the lower bound improves as the $\\eta$ in EGG gets smaller, while our experiments on real-world datasets show larger $\\eta$ provides better certifications. However, this seemingly contrary phenomenon does not mean we made mistakes in the work. According to our further study, we find how $\\eta$ influences the certifications is largely decided by whether the concentration assumption strictly holds. That is, if the concentration assumption strictly holds (i.e. B=1 in Problem (4), which is the case of our theorem 1 and Figure 1(a)), the lower bound provided by DSRS improves as the $\\eta$ decreases. Otherwise, if the concentration assumption does not strictly hold (i.e. B<1 in Problem (4), which is the experimental case because no classifier perfectly satisfies the assumption), the certifications provided by EGG improves as the $\\eta$ increases. Our Figure 10 further clarifies this point by simulating the cases where $B$ is very close to 1. It is clear in the figure that if $B=1$, $\\eta=1$ performs better, but if $B<1$ (even if extremely close), $\\eta=2$ performs better.\n\n$\\cdot$ Our results for ESG demonstrates that a mainstream view in the randomized smoothing community can be augmented. Concretely, the mainstream view (for example, Yang et al. (2020)) believes Gaussian distribution is the best distribution to provide certification in the RS framework. However, our finding is that many members of the ESG distribution can provide certification as great as Gaussian (Gaussian is a special case of ESG when $\\eta=2.0$).\nWe would like to recommend reading point 1 in the global response for more information on backgrounds and motivations for this paper.\n\n2. It is a bit ambiguous for 'variance', here we talk about both the cases.\n\n$\\cdot$ If it refers to the variance of each distribution, such as $0.5, 1.0$. We can ensure that all variances in this work are aligned by keeping $\\mathbb{E}r^2$ a constant (the convention from Yang et al. (2020) and Li et al. (2022)). This is also why we have the substitution variance in Table 1.\n\n$\\cdot$ If it refers to the variance between repetitive experiments. In our work, we find the errors on certified accuracy caused by randomness of experiments usually range between 0.0%-0.3%. It will definitely be great to show results of multiple experiments, but its impact may be limited for the theme of this paper. Actually, though our results for $\\eta=8.0$ result does not significantly improve the DSRS baseline, the comparison is not fair. In Li et al. (2022), they reached the baseline by setting $\\mathcal{Q}\\neq TEGG$. If we consider a fair comparison, say comparing $\\eta=2.0$ with $\\eta=8.0$, then our improvement is significant.\n\n3. Please check point 2 in the global response. From our perspective, compared to $\\mathcal{P}=EGG, \\mathcal{Q}=TEGG, \\eta=2.0$,  the setting $\\mathcal{P}=EGG, \\mathcal{Q}=TEGG, \\eta=8.0$ provides holistic improvements, no matter which dataset (CIFAR10, ImageNet) and training method (standard, SmoothMix, Consistency) are used. Besides, our results can be further enhanced by letting $\\eta$ larger (16, 32). We do not show them in the paper because their errors are more difficult to control than $\\eta=8.0$.\n\n**Questions:**\n\n1, 2. We have improved these representations in the latest paper.\n\n3. Yes, $\\eta$ is the same for $\\mathcal{P}$ and $\\mathcal{Q}$. As for $\\eta, k$, they definitely influence the bound (please check Eqn (51). and Table 4). Theorem 1 only shows the same bound provided by General Gaussian (Li et al. (2022)) can also be provided by EGG, and the section 'study on the constant factor' (page 6) further shows the factor grows as $\\eta$ shrinks, for $d-2k$ except 1."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7661/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700061978394,
                "cdate": 1700061978394,
                "tmdate": 1700061978394,
                "mdate": 1700061978394,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "eoyx1Rwecc",
                "forum": "5VD7dS3cZX",
                "replyto": "MUoYBFmWhO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7661/Reviewer_Ba1f"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7661/Reviewer_Ba1f"
                ],
                "content": {
                    "comment": {
                        "value": "I would like to thank the authors for the response. I have read the response and would like to keep my original rating mainly based on weakness 1."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7661/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700433984893,
                "cdate": 1700433984893,
                "tmdate": 1700433984893,
                "mdate": 1700433984893,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "id7MoKHQSq",
            "forum": "5VD7dS3cZX",
            "replyto": "5VD7dS3cZX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7661/Reviewer_Dgzf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7661/Reviewer_Dgzf"
            ],
            "content": {
                "summary": {
                    "value": "This work extends double sampling randomized smoothing (DSRS) to smooth with exponential general Gaussian (EGG) and exponential standard Gaussian (ESG) distributions. The authors derive certified robust radii for their proposed methods, and experimentally show that the performance of their methods surpass that of standard DSRS on CIFAR-10 and ImageNet."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The Introduction is concise and motivates the problem well, and the contributions are clearly outlined.\n2. The Experiments are thorough.\n3. The Preliminaries section provides a nice concise introduction to the formalisms at hand.\n4. The theoretical results (namely, Theorems 1 and 2) appear to be novel.\n5. The proposed method's performance (in terms of certified radii) appears to meet/exceed prior state-of-the-art."
                },
                "weaknesses": {
                    "value": "1. What do you mean by \"point-to-point certified accuracy\" in the Abstract? This terminology may be unclear to the reader, so I suggest replacing it or clarifying what it means.\n2. \"We let $\\sigma_s$ and $\\sigma_g$ be the substitution variances of EGG and ESG, respectively.\" I think you mean \"...variances of ESG and EGG, respectfully.\"\n3. \"We let... be the probability density functions (PDFs) of EGG and ESG, respectively.\" I think you mean \"... of ESG and EGG, respectfully.\"\n4. \"...our theoretical analysis shows EGG distributions can be prospective in providing much tighter lower bounds...\" What do you mean by prospective? I think this sentence needs rewriting.\n5. Why is $\\eta$ restricted to be in a finite set in Theorem 1? Why is $d-2k$ restricted to be less than 30? I don't see where the number 30 appears in the proof of Lemma C.3 at all.\n6. When introducing DSRS in Section 3, the values of $A,B$ are somewhat glossed over, leaving the reader to wonder what they are and where they come from. You mention that you can estimate them through Monte Carlo sampling, but no formulas are given to perform those estimates. How are $A$ and $B$ defined mathematically? Also, you state \"In a nutshell, we find the maximum $\\lVert\\delta\\rVert_2$ that makes the worst probability...\". This is somewhat vague. Are you saying that you maximize over $\\delta$ in an \"outer-maximization\" after solving the minimization (4)? In other words, it would be good to clarify how exactly the certified radius of DSRS is defined mathematically, and how that definition relates to (4).\n7. It looks like your statement of Lemma C.3 should be \"at labeled example $(x_0,y_0)$\", not just \"at input $x_0$\".\n8. The way Theorem 2 is stated, it does not appear that you are solving the dual problem (8), but rather giving specific formulas for the objective and constraints based on specific EGG density functions. If this is indeed the case, then you should re-word your descriptions to be more accurate (i.e., do not call your result a closed-form solution to the optimization problem). How are you actually solving the dual in practice (for the dual variables $\\nu_1,\\nu_2$)? This should be made more clear to the reader.\n8. Overall, the paper is a bit hard to follow at times, as some of the language is cryptic or vague."
                },
                "questions": {
                    "value": "See my questions above in \"Weaknesses\"."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7661/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699320430159,
            "cdate": 1699320430159,
            "tmdate": 1699636931740,
            "mdate": 1699636931740,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0gD4Bde5Aq",
                "forum": "5VD7dS3cZX",
                "replyto": "id7MoKHQSq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7661/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7661/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the time and the consideration. Here we provide point-to-point explanations for the concerns.\n1. Using 'point-to-point certified accuracy', we were trying to describe our experimental results as better than the baselines at almost every certified radius $r$. For this, please check figures for EGG on page 46-49, where the curves of EGG,$\\eta=8$ envelop almost all their corresponing EGG,$\\eta=2$. To reduce ambiguity, we now use the term certified accuracy following the convention in the RS community.\n\n2,3. We have corrected these typos.\n\n4. Here we wanted to show EGG is a potential choice for providing better certification results, where the word 'prospective' is indeed inaccurate. Currently, this sentence in the text has been rewritten into 'Overall, theoretical analysis above shows taking EGG as the smoothing distribution in DSRS, we are likely to obtain much tighter lower bounds for the certified radius on base classifiers, ...'. We hope the current expression clarifies our intention.\n5. About $\\eta, d, k$. The EGG distributions, defined as $\\mathcal{G}(\\sigma, \\eta, k)$ in the paper, are all considered in discrete combinations of the parameters.\n\n$\\cdot$ The reason why $\\eta$ belongs to a finite set is that it appears as an argument in the gamma function (for example, Eqn. (12)). As far as we are concerned, it is currently intractable to analyze the continuous property of $\\eta$ considering the gamma function, which is also why Li et al. (2022) only considered discrete cases in their Proposition F.6.\n\n$\\cdot$ Yes, we do not need to add the restriction $d-2k\\in [1,30]\\cap \\mathbb{N}$ if we just want to prove Lemma C.3, since $d-2k \\geq 1$ can all satisfy Eqn. (24). The setting of 30 is following Li et al. (2022) (see their Proposition F.6), where they restricted $d - \\frac{k}{2} \\in$ {$0.5, 1.0, \\cdots, 15.0$}. As we mentioned, the analysis on continous property of EGG distributions is intractable, so only the discrete combinations of $d, k, \\eta$ is considered. Concretely, we show the proof for $(d-2k, \\eta) \\in$ {$1, 2, \\cdots, 30$} $\\times$ {$1, \\frac{1}{2}, \\frac{1}{3}, \\cdots, \\frac{1}{50}$}. For each combination of $d-2k$ and $\\eta$, Theorem 1 proves its ability to give the $0.02\\sigma\\sqrt{d}$ lower bound. Here we take  $d-2k = 2, \\eta=\\frac{1}{2}$ as an example. Specifically, we need to substitute $\\mu=0.02, d-2k=2$ and $\\eta=\\frac{1}{2}$ into Eqn. (52), and check if the value is greater than 0.5. By checking Table 4, we find the value is 0.782, then the $0.02\\sigma\\sqrt{d}$ lower bound is proved. To sum it up, Table 4 contains all the discrete combinations of parameters we study (i.e. different EGG distributions), where $d, k, \\eta$ appear simultaneously. $d, k, \\eta$ also exist in other equations such as Eqn. (51). They do not appear in Theorem 1, because all the limited combinations of $(d-2k, \\eta) \\in$ {$1, 2, \\cdots, 30$} $\\times$ {$1, \\frac{1}{2}, \\frac{1}{3}, \\cdots, \\frac{1}{50}$} have been proved capable of offering the $\\Omega(\\sqrt{d})$ lower bound.\n\n6. About Eqn. (4). \n\n$\\cdot$ A and B are both probabilities that the base classifier gives the right prediction for $x_0$, under different noise distributions.\n\n$\\cdot$ Just as the reviewer understands, there is an \u2018outer-maximization\u2019 after we obtain the best function $\\tilde{f}_{x_0}$. This \u2018outer-maximization\u2019 is quite simple so that we can solve it only by binary searching on $||\\delta||_2$.\n\nTo further clarify the definitions of $A,B$, we have rewritten the paragraph below Eqn. (4).\n\n7. We have improved the statement of Lemma C.3 accordingly.\n8. We agree with the review on 'closed-form', and now use 'integral form' to describe our theorem in the latest paper. To clarify the process of solving the DSRS problem, we have added Appendix F.2 in the latest paper, which is a short introduction considering the complete derivation is somewhat complicated and voluminous. For $\\nu_1, nu_2$, we get their values from the DualBinarySearch algorithm from Li et al. (2022).\n9. We are sorry for the confusion and puzzle. In fact, we have been trying to clarify the mechanisms in the paper as understandable as possible since we started to write this paper. This paper has been revised for more than 15 times before being submitted to the conference. However, limited to our writing skills, and the innate complexity of this work, sometimes it is still difficult to follow. We welcome further discussions on any confusion on or technical details of the paper, and promise we will carefully handle the questions at our best."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7661/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700061415926,
                "cdate": 1700061415926,
                "tmdate": 1700061415926,
                "mdate": 1700061415926,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pukGl8AXKA",
                "forum": "5VD7dS3cZX",
                "replyto": "0gD4Bde5Aq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7661/Reviewer_Dgzf"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7661/Reviewer_Dgzf"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their responses and their updates to the manuscript and its presentation. However, as the improvements over prior methods (Li et al., 2022) are marginal (Table 2) and the theoretical novelties also appear to be marginal based on my understandings of Reviewer FGgM's qualms, I maintain my original score."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7661/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700080575592,
                "cdate": 1700080575592,
                "tmdate": 1700080575592,
                "mdate": 1700080575592,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]