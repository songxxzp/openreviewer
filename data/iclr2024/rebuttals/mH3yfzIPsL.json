[
    {
        "title": "XTSFormer: Cross-Temporal-Scale Transformer for Irregular Time Event Prediction"
    },
    {
        "review": {
            "id": "KZPPCaHReq",
            "forum": "mH3yfzIPsL",
            "replyto": "mH3yfzIPsL",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6853/Reviewer_AZAP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6853/Reviewer_AZAP"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new model called XTSFormer for irregularly timed event data, and highlights its superior performance compared to baseline methods. The XTSFormer includes a unique Feature-based Cycle-aware Positional Encoding and a hierarchical multi-scale temporal attention mechanism to address these challenges."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed PCPE incorporates event type information. It is reasonable to use type information for better embedding.\n2. The proposed multi-scale attention is novel and useful.\n3. The use of Weibull distribution improves performance."
                },
                "weaknesses": {
                    "value": "1. The proposed FCPE seems to be Mercer time embedding [1] parameterized by event type. It would be great to present the comparison with Mercer time embedding.\n2. The ablation studies on the NLL/RMSE with FCPE, attention, and weibull distribution should be presented.\n3. The use of event type prediction somehow hinders the models from being a generative model. Can authors run experiments on using the event type prediction similar to ANHP[2]?\n\n[1] Self-attention with Functional Time Representation Learning, NeurIPS 2019.\n\n[2] Transformer Embeddings of Irregularly Spaced Events and Their Participants. ICLR 2022."
                },
                "questions": {
                    "value": "See weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6853/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6853/Reviewer_AZAP",
                        "ICLR.cc/2024/Conference/Submission6853/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6853/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698703340928,
            "cdate": 1698703340928,
            "tmdate": 1700677812265,
            "mdate": 1700677812265,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ahD6UrAgx2",
                "forum": "mH3yfzIPsL",
                "replyto": "KZPPCaHReq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer AZAP"
                    },
                    "comment": {
                        "value": "We appreciate the great comments and suggestions! We used **W** to represent the weaknesses listed.\n\n## 1. Comparison with Mercer Time Embedding (W1)\n\nThank you for bringing up this related work on Mercer Time Embedding [1]. This is a great insight. As suggested, we have added experimental comparisons.\n\nWe replaced the FCPE in XTSFormer with Mercer Time Embedding and conducted experiments on four datasets. The results in the following table show that our method has slightly better performance, which may be due to the event type feature-based encoding. \n\n|        | Medications |      | Providers |      | Financial |      | StackOverflow |      |\n|:------:|:-----------:|:----:|:---------:|:----:|:---------:|:----:|:-------------:|:----:|\n|        |   Accuracy (%)  | RMSE |  Accuracy (%) | RMSE |  Accuracy (%) | RMSE |    Accuracy (%)   | RMSE |\n| Mercer |     31.5    | 1.45 |    41.2   | 2.49 |    76.9   | 0.87 |      46.3     | 4.38 |\n|  FCPE  |     33.5    | 1.12 |    43.9   | 2.33 |    77.5   | 0.88 |      49.4     | 4.21 |\n\n\n[1] Self-attention with Functional Time Representation Learning, NeurIPS 2019.\n\n\n## 2. Ablation Studies on NLL/RMSE (W2)\n\nThis is a great point. We have conducted comprehensive ablation studies to fill in the missing details as below, and we will include these studies in our revised manuscript.\n\n### The NLL of ablation study results:\n\n|  PE  | Multi-scale | Distribution | Meications | Providers | Financial | StackOverflow |\n|:----:|:-----------:|:------------:|:----------:|:---------:|:---------:|:-------------:|\n| base |     w/o     |  Exponential |    3.48    |    2.21   |    2.10   |      2.88     |\n| FCPE |     w/o     |  Exponential |    2.99    |    2.15   |    2.07   |      2.41     |\n| base |      w/     |  Exponential |    2.47    |    1.92   |    1.60   |      2.42     |\n| FCPE |      w/     |  Exponential |    2.20    |    1.81   |    1.17   |      2.10     |\n| base |     w/o     |   Weilbull   |    2.59    |    2.30   |    2.35   |      2.31     |\n| FCPE |     w/o     |   Weilbull   |    2.34    |    2.10   |    2.11   |      2.09     |\n| base |      w/     |   Weilbull   |    2.31    |    1.89   |    1.59   |      2.02     |\n| FCPE |      w/     |   Weilbull   |    2.23    |    1.75   |    1.18   |      1.89     |\n\n### The RMSE of ablation study results:\n\n|  PE  | Multi-scale | Distribution | Meications | Providers | Financial | StackOverflow |\n|:----:|:-----------:|:------------:|:----------:|:---------:|:---------:|:-------------:|\n| base |     w/o     |  Exponential |    1.89    |    3.62   |    1.44   |      5.85     |\n| FCPE |     w/o     |  Exponential |    1.80    |    3.05   |    1.45   |      5.50     |\n| base |      w/     |  Exponential |    1.75    |    2.48   |    1.01   |      4.39     |\n| FCPE |      w/     |  Exponential |    1.15    |    2.40   |    0.92   |      4.22     |\n| base |     w/o     |   Weilbull   |    1.90    |    3.50   |    2.42   |      5.51     |\n| FCPE |     w/o     |   Weilbull   |    1.82    |    2.88   |    0.89   |      4.39     |\n| base |      w/     |   Weilbull   |    1.65    |    2.51   |    1.15   |      4.30     |\n| FCPE |      w/     |   Weilbull   |    1.12    |    2.33   |    0.88   |      4.21     |\n\nThe results from our ablation study demonstrate the robust performance of our Feature-based Cycle-aware Positional Encoding (FCPE), multi-scale attention, and Weibull distribution across various datasets. Notably, the integration of FCPE and multi-scale attention consistently yields lower RMSE values, underlining the efficacy of these components in our model. For example, in the 'Medications' dataset, the combination of FCPE with multi-scale attention and Weibull distribution significantly reduces RMSE to 1.12 from a base RMSE of 1.90. This trend is observed across all datasets, confirming the advantages of our approach as discussed in section 4.3 of our paper.\n\n## 3. Using ANHP Setup (W3)\nThis is a great point! We acknowledge that our current configuration is for next-event prediction. Due to the need for precomputing hierarchical clustering tree, it is not the best fit for event sequence generation, as in the ANHP [2] model. We will work on customizing our model for event sequence generation (autoregressive prediction). \n\n[2] Transformer Embeddings of Irregularly Spaced Events and Their Participants. ICLR 2022."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700210901483,
                "cdate": 1700210901483,
                "tmdate": 1700210901483,
                "mdate": 1700210901483,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xObxl4UQPo",
                "forum": "mH3yfzIPsL",
                "replyto": "ahD6UrAgx2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6853/Reviewer_AZAP"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6853/Reviewer_AZAP"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the reply. \n\nThe comparison between FCPE and Mercer and the results on NLL/RMSE are interesting. The authors have addressed most of my concerns. I raised my score.\n\nOverall, the proposed FCPE and hierarchical architecture is novel and useful. However, the non-autoregressive design still will be my biggest concern for the practicability of the proposed method in Irregular Time Series as the event prediction is only one part of Irregular Time Series processing."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700678052238,
                "cdate": 1700678052238,
                "tmdate": 1700678052238,
                "mdate": 1700678052238,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "TIuEsRrgct",
            "forum": "mH3yfzIPsL",
            "replyto": "mH3yfzIPsL",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6853/Reviewer_TWtn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6853/Reviewer_TWtn"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposed a method for predicting the time and type of future events based on a historical event sequence. The model has two main components:\n\u2022 A feature-based cycle-aware positional encoding (FCPE) that encodes both the cyclic and semantic information of event times into a vector representation.\n\u2022 A cross-temporal-scale transformer that captures the multi-scale temporal dependencies among events using a hierarchical clustering algorithm and a cross-scale attention mechanism."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper addresses an interesting issue of event prediction (time and type) using irregular and multi-scale temporal data.\nThe paper addresses a significant problem, namely event prediction and event timing in the presence of irregularities. This has not been addressed before, which is more challenging than a typical forecasting task.\nThe paper includes a comprehensive ablation study of each component, and the experiment was conducted on a set of real-world data."
                },
                "weaknesses": {
                    "value": "The model component lacks novelty, which can be seen as a limitation. Nonetheless, the paper's exploration of event prediction within irregular sequences is an interesting topic.\n\nThe paper never addresses state-of-the-art irregular models recently introduced, including ODE-based models [1-4], which is critical to be added as one of the baseline models.\nRecent models [2,3,4] can handle irregular time series more effectively without the need for data grouping based on temporal scale. A comparison with ODE-based models is essential.\n\nThe paper is generally well-written. However, the model component is difficult to understand; many details are in the appendix.\nThere are issues in the organization of Section 3, particularly in understanding the connection between different modules. For instance, Section 3.2.4, which outlines the overall model architecture, must be presented at the beginning of Section 3, followed by a breakdown of individual module components. The excessive use of subsubsections with limited content also hampers the paper's clarity. Structural improvements are needed to enhance the overall readability.\n\n\n[1] Chen, R.T., Rubanova, Y., Bettencourt, J. and Duvenaud, D.K., 2018. Neural ordinary differential equations. Advances in neural information processing systems, 31.\n[2] Kidger, P., Morrill, J., Foster, J. and Lyons, T., 2020. Neural controlled differential equations for irregular time series. Advances in Neural Information Processing Systems, 33, pp.6696-6707.\n[3] Rubanova, Y., Chen, R.T. and Duvenaud, D.K., 2019. Latent ordinary differential equations for irregularly-sampled time series. Advances in neural information processing systems, 32.\n[4] Weerakody, P.B., Wong, K.W., Wang, G. and Ela, W., 2021. A review of irregular time series data handling with gated recurrent neural networks. Neurocomputing, 441, pp.161-178."
                },
                "questions": {
                    "value": "There are notable issues with the clarity and novelty of the proposed model. Why has ODE based models not considered for comparison?\n\nWhy is the use of hierarchical classification needed? It raises concerns due to the data preprocessing required."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6853/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698927560690,
            "cdate": 1698927560690,
            "tmdate": 1699636794821,
            "mdate": 1699636794821,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oFBjiC8BTZ",
                "forum": "mH3yfzIPsL",
                "replyto": "TIuEsRrgct",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer TWtn"
                    },
                    "comment": {
                        "value": "Thank you for the insightful comments. Please see our responses below. We used **Q** and **W** to represent the questions and weaknesses listed, respectively.\n\n## 1. Comparison with ODE-based Models (Q1)\n\nWe recognize the importance of comparing our model against Neural ODE-based models. \n\nIt is true that Neural ODE-based models are popular methods in handling irregular time series [1,2,3,4]. However, its common version [1-4] captures random variables as a continuous-time function (e.g., temperature over a time period), which **cannot be directly applied to discrete event sequences** (as the events do not occur at every time point in the continuous time domain, unlike temperature variable). After a literature review, we found two papers that customized the neural ODE models for discrete event sequences: Neural Jump Stochastic Differential Equations (NJSDE) [6], which enhances the Neural ODE framework with a stochastic process on jumps between discrete events; and [7] that applies Neural ODE to compute the likelihood of Spatio-Temporal Point Processes (ODETPP). For a fair comparison, we modified ODETPP by removing its spatial component (only focusing on time). \n\nWe conducted an experimental comparison between our method and existing Neural ODE-based TPPs [6] and [7] on two public datasets. Our experimental results below demonstrate that XTSFormer has better prediction accuracy over neural ODE-based TPP on two public datasets.\n\n|           | Financial |          |      |      | StackOverflow |          |      |      |\n|:---------:|:---------:|:--------:|:----:|:----:|:-------------:|:--------:|:----:|:----:|\n|           |  Accuracy (%) | F1-score (%)| RMSE |  NLL |    Accuracy (%)   | F1-score (%)| RMSE |  NLL |\n|   NJSDE [6]  |    72.0   |   74.1   | 0.93 | 1.18 |      47.3     |   34.2   | 4.33 | 1.96 |\n|   ODETPP [7]  |    69.1   |   65.9   | 2.20 | 2.07 |      44.4     |   33.1   | 5.46 | 2.52 |\n| XTSFormer |    77.5   |   78.8   | 0.88 | 1.18 |      49.4     |   35.0   | 4.21 | 1.89 |\n\n[1] Chen, R.T., Rubanova, Y., Bettencourt, J. and Duvenaud, D.K. Neural ordinary differential equations. Advances in neural information processing systems, 2018. \n[2] Kidger, P., Morrill, J., Foster, J. and Lyons, T.. Neural controlled differential equations for irregular time series. Advances in Neural Information Processing Systems, 2020. \n[3] Rubanova, Y., Chen, R.T. and Duvenaud, D.K.. Latent ordinary differential equations for irregularly-sampled time series. Advances in neural information processing systems, 2019.\n[4] Weerakody, P.B., Wong, K.W., Wang, G. and Ela, W., 2021. A review of irregular time series data handling with gated recurrent neural networks. Neurocomputing, 441, pp.161-178.\n[5] Brillinger D R. Time series, point processes, and hybrids. Canadian Journal of Statistics, 1994.\n[6] Jia J, Benson A R. Neural jump stochastic differential equations. Advances in Neural Information Processing Systems, 2019.\n[7] Chen R T Q, Amos B, Nickel M. Neural Spatio-Temporal Point Processes. International Conference on Learning Representations, 2021.\n\n\n## 2. Why Hierarchical Clustering (Q2)\nThis is a great question. We use hierarchical clustering on irregular-time events in the time domain to capture the multi-scale temporal patterns on such event sequences. Such multi-scale temporal event patterns are motivated by real-world applications. For example, in the electronic health record (EHR) data we received from collaborators in a hospital, irregular time medication events for the same patient are multi-scale in nature. Medications intra-operation (in operating rooms) are often every few minutes (**fine granularity**) while medication events pre- or post-operations are often every few hours (**coarse granularity**). Our domain collaborator in clinical practice also highlights the importance of such multi-scale patterns. Thus, we propose a method to capture the multi-scale temporal patterns inherent in such real-world irregular-time event datasets. We will add such discussions as you suggested. Thank you for bringing this up!\n\nWe acknowledge that the idea poses preprocessing costs, and we are planning to explore an end-to-end learnable approach for hierarchical clustering for multi-scale temporal patterns. This will be explored in future work. \n\n## 3. Improvements in Clarity and Organization (W3)\n\nWe fully agree with the points regarding the presentation and organization issues. We believe these issues can be fixed. We are working on that now."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700210866992,
                "cdate": 1700210866992,
                "tmdate": 1700720840966,
                "mdate": 1700720840966,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wJjxSMaztM",
                "forum": "mH3yfzIPsL",
                "replyto": "TIuEsRrgct",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer TWtn,\n\nThanks for your suggestions. We have carefully addressed your comments on comparison with existing ODE-based models. We would greatly appreciate it if you could review our responses and consider if they might prompt an adjustment in your scoring.\n\nAdditionally, in response to your feedback on presentation and organization, we have restructured Section 3 to provide a clearer and more coherent introduction to the overall model architecture. We are committed to continuously revising the paper further to enhance its clarity and readability, following your insightful suggestions.\n\nYour feedback is very valuable to us, and we eagerly await any further insights you might offer."
                    },
                    "title": {
                        "value": "Reminder of Response to Author's Rebuttal"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685733760,
                "cdate": 1700685733760,
                "tmdate": 1700720985746,
                "mdate": 1700720985746,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wh1vR3p442",
                "forum": "mH3yfzIPsL",
                "replyto": "wJjxSMaztM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6853/Reviewer_TWtn"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6853/Reviewer_TWtn"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the additional experiments and detailed comments. Much appreciated. However, the experiment is incomplete as there are several newer ODE models. I stand by my score."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700728124860,
                "cdate": 1700728124860,
                "tmdate": 1700728124860,
                "mdate": 1700728124860,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "jju4GYhqZS",
            "forum": "mH3yfzIPsL",
            "replyto": "mH3yfzIPsL",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6853/Reviewer_cLDM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6853/Reviewer_cLDM"
            ],
            "content": {
                "summary": {
                    "value": "The cross-temporal-scale transformer (XTSFormer) is proposed as a solution for unevenly timed event data. The approach is built around two key components: a unique Feature-based Cycle-aware Positional Encoding (FCPE) that captures the cyclical character of time and a hierarchical multi-scale temporal attention mechanism. A bottom-up clustering technique determines these scales. Extensive testing on a variety of real-world datasets demonstrates that our XTSFormer exceeds various baseline methods in prediction performance."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "It is the first work to take into account multi-scale features in neural TPPs.\n\nThey introduce a novel time positional encoding, the Feature-based Cycle-aware Positional Encoding (FCPE), which incorporates both feature and cyclical information. This approach strengthens our model\u2019s capacity to capture complex temporal patterns.\n\nThey design a cross-scale attention operation within the multi-scale hierarchy and compare the time cost with default all-pair attention."
                },
                "weaknesses": {
                    "value": "(1) It is not so clear why multi-scale patterns are so important for event sequences. In introduction, there is no explanation about the benefits of multi-scale features.\n\n(2) Multi-scale temporal attention mechanism has been widely published in previous papers [1][2]. Cycle-aware Time Embedding has been proposed in [3]. Please describe the difference between your paper and these published papers. The novelty is limited.\n\n(3) Eq.6 and Eq. 7 are unnecessary. They are the commonsense of attention mechanism and MLP.\n\n(4) Section 3.2.3 is so simple. Please add more analysis about Flops and memory cost of your model.\n\n(5) Each equation should be followed of commas or full stop. Please clarify it.\n\n(6) Some formulas are not clearly defined, such as the missing definition of P(ti) in Eq. (5)\n\n(7) The writing of the paper can be improved as there are many typos.\n\n\n[1]Hu H, Dong S, Zhao Y, et al. Transrac: Encoding multi-scale temporal correlation with transformers for repetitive action counting[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 19013-19022.\n\n[2]Dai R, Das S, Kahatapitiya K, et al. MS-TCT: multi-scale temporal convtransformer for action detection[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 20041-20051.\n\n[3]Dikeoulias I, Amin S, Neumann G. Temporal knowledge graph reasoning with low-rank and model-agnostic representations[J]. arXiv preprint arXiv:2204.04783, 2022."
                },
                "questions": {
                    "value": "Please see weakness above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No."
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6853/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6853/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6853/Reviewer_cLDM"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6853/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699332592120,
            "cdate": 1699332592120,
            "tmdate": 1699636794664,
            "mdate": 1699636794664,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "juTEgubOxi",
                "forum": "mH3yfzIPsL",
                "replyto": "jju4GYhqZS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer cLDM (Part 1/2)"
                    },
                    "comment": {
                        "value": "Thank you for your constructive feedback and for recognizing the novel aspects of our XTSFormer model. We value your insights and are eager to address the concerns raised to enhance the clarity and impact of our work. We used **W** to represent the weaknesses listed.\n\n## 1. Importance of Multi-scale Patterns in Event Sequences (W1)\nThanks for the comment. Our idea of multi-scale temporal event patterns is motivated by rea-world applications. For example, in the electronic health record (EHR) data we received from collaborators in a hospital, irregular time medication events for the same patient are multi-scale in nature. Medications administered intra-operation (in operating rooms) are often every few minutes (fine granularity), while medication events pre- or post-operations are often every few hours (coarse granularity). Our domain collaborator in clinical practice also highlights the importance of such multi-scale patterns. Thus, we propose a method to capture the multi-scale temporal patterns inherent in such real-world irregular-time event datasets. We will add such explanations in the introduction as you suggested. \n\n## 2. Comparison with Multi-scale Temporal Attention and Cycle-aware Time Encoding (W2)\nThank you for the great suggestions to clarify novelty against existing works on multi-scale temporal attention and cycle-aware time embedding. We have now discussed these two aspects one by one. \n\nFirst, the two works on multi-scale temporal attention (e.g., **TransRAC [1]**, **MS-TCT [2]**) are designed for action detection in video data which are **regular time series**. For instance, MS-TCT uses temporal convolutional layers to process time series data, which cannot be directly applied to irregular time event data in our case. In contrast, our XTSFormer focuses on multi-scale temporal attention on **irregularly timed event data** in a neural temporal point process framework. We will cite these two papers in related work and add discussions on the differences in our draft.\n\nSecond, we carefully reviewed the existing cycle-aware time embedding paper [3] you suggested.  \nThe Multi-Recurrent Cycle-Aware (MRCA) encoding [3] decomposes time into multiple cycles like seasons, months, weeks, and days to capture recurring temporal patterns. However, we found several differences as summarized below:\n\nMRCA directly encodes the time into several **fixed cycles**, e.g., daily, weekly, monthly, which may not be sufficient for datasets where cycles are not well-defined. In contrast, our Feature-based Cycle-aware Positional Encoding (FCPE) has **learnable cycles representation**. It is specifically tailored for irregular temporal data. Although cycle-aware time positional encodings are not new (see [4,5] below), we added the idea of semantic-feature-based learnable cycles. Specifically, the learnable cycles in our FCPE depend on **event-specific semantic features**. This is motivated by real-world applications where different types of events may show different cyclic patterns. For example, some types of medications are taken every few minutes, while others may be every few hours or daily. Another difference is that the existing work of MRCA [3] lacks **time translation invariance**. This means it is unable to assure steady performance across the time domain, particularly when facing shifts in temporal features.\n\nWe also added experimental comparisons of our feature-based cycle-aware time positional encoding (FCPE) against existing basic cycle-aware time position encoding methods, including [4] (we call base below), and Mercer encoding [5] brought up by another reviewer (i.e., positional encoding without event feature parameterization). The results are as follows:\n\n\n|        | Medications |      | Providers |      | Financial |      | StackOverflow |      |\n|:------:|:-----------:|:----:|:---------:|:----:|:---------:|:----:|:-------------:|:----:|\n|        |   Accuracy (%) | RMSE |  Accuracy (%) | RMSE |  Accuracy (%) | RMSE |    Accuracy (%)   | RMSE |\n|  base  |     29.3    | 1.65 |    40.2   | 2.51 |    73.5   | 1.15 |      45.1     | 4.30 |\n| Mercer |     31.5    | 1.45 |    41.2   | 2.49 |    76.9   | 0.87 |      46.3     | 4.38 |\n|  FCPE  |     33.5    | 1.12 |    43.9   | 2.33 |    77.5   | 0.88 |      49.4     | 4.21 |\n\nThe results show that our FCPE has slightly better prediction accuracy.\n\n\n[1]Hu H, Dong S, Zhao Y, et al. Transrac: Encoding multi-scale temporal correlation with transformers for repetitive action counting. CVPR 2022. \n\n[2]Dai R, Das S, Kahatapitiya K, et al. MS-TCT: multi-scale temporal convtransformer for action detection. CVPR 2022. \n\n[3]Dikeoulias I, Amin S, Neumann G. Temporal knowledge graph reasoning with low-rank and model-agnostic representations.  Workshop on representation learning for NLP 2022.\n\n[4] Zuo, Simiao, et al. \"Transformer hawkes process.\" ICML 2020.\n\n[5] Self-attention with Functional Time Representation Learning, NeurIPS 2019."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700210787729,
                "cdate": 1700210787729,
                "tmdate": 1700210787729,
                "mdate": 1700210787729,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "79XkQ9Nyde",
                "forum": "mH3yfzIPsL",
                "replyto": "jju4GYhqZS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer cLDM (Part 2/2)"
                    },
                    "comment": {
                        "value": "## 3. Time and Memory Cost Analysis (W4)\n\nThank you for the suggestions. We have added a detailed analysis of our approach's time and memory costs as below. \n\n### Time cost analysis (FLOPs):\nAssume the number of input temporal points is $L$, the batch size is $B$, the number of heads is $h$, and the hidden dimensions are $d$. In our attention computation, the query matrix dimensions is represented by $Q \\in \\mathbb{R}^{B \\times h \\times L \\times d}$. For each query point $\\mathcal{Q}_i$  (where $1 \\leq i \\leq L$), its selective key set size is $M$ (dependent on the threshold in each level). Thus, the key matrix results from concatenating key sets of all query points, yielding a dimension of $\\mathbb{R}^{B \\times h \\times L \\times M \\times d}$. Consequently, the FLOPs of the attention computation with our approach is $B \\cdot h \\cdot L \\cdot M \\cdot d$, with the key set size $M$ scaling $O(log L)$. This results in a significantly more efficient attention computation Flops, specifically $B \\cdot h \\cdot L \\cdot \\log L \\cdot d$, compared to the vanilla transformer [6] computation of $B \\cdot h \\cdot L^2 \\cdot d$.  For example, when $B=64, h= 4, L=10000, d=256$, the Flops per attention layer = $2\\times 64 \\times 4 \\times 10000 \\times \\log 10000 \\times 256 \\approx 17.4$ billion FLOPs.\n\n### Memory cost analysis:\nWe analyze the memory costs of the model theoretically. We use the same math variable definition as above. We use $\\mathcal{K}_i$ to denote the key set for the $i$-th query point and key set size is $M$. The memory costs of our approach are dominated by the hierarchical attention layer, since we need to store the key set $\\mathcal{K}_i$ for $L$ query points, and each key set has the dimension $M \\cdot d$. Thus, the total memory cost is $O(B\\cdot h  \\cdot d \\cdot L \\cdot M)$ per layer, where $M=\\log L$.  Given $B=64, h= 4, L=10000, d=256$, with floating32 precision, the memory cost is  $64\\times 4\\times 256 \\times 10000 \\times log 10000 \\times 4 \\approx 32.4$ GB.\n\nAdditionally, to evaluate the efficiency of our method on long event sequences, we have conducted further computational experiments using a synthetic dataset. This dataset comprises $64$ event data sequences, each with a length of $100,000$ events. Each event in a sequence is a pair: an event type and its corresponding time point. The event type is a discrete variable ranging from ${0, 1, 2, \\dots, 9}$. Each event type exhibits a unique temporal occurrence pattern, modeled using a Poisson distribution. Given an event type $i$, the time point of its occurrence is sampled from an exponential distribution with rate parameter $\\lambda_i$. This is given by:$P(T = t | \\lambda_i) = \\lambda_i e^{-\\lambda_i t}$, where $T$ is the time between events. To introduce variability and simulate the irregularities observed in real-world event sequences, we perturb these time intervals by adding Gaussian noise $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$ where $\\sigma$ is a small standard deviation. Based on preliminary testing and to ensure that the perturbations were subtle yet meaningful, we set $\\sigma = 0.1\\times \\text{mean of the sampled time interval}$.\n\nIn our experiments, we set the batch size $B=1$ and the hidden dimension $d=32$. We progressively increased the sequence length and recorded the time cost (in seconds) per epoch. The results, which we plan to include in the final version of the paper, are as follows (OOM indicates 'out of memory'):\n\n|  Length of Sequence | 10,000 | 20,000 | 30,000 | 40,000 | 50,000 | 60,000 | 70,000 | 80,000 |\n|:-------------------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|\n| Vanilla Transformer [6] |   2.9  |   7.9  |  12.5  |  24.3  |  39.1  |  58.8  |  83.7  |   OOM  |\n|      XTSFormer      |   3.1  |   4.5  |   6.6  |  12.1  |  13.9  |  16.7  |  20.8  |  25.3  |\n\nThe experimental results clearly demonstrate that our XTSFormer model is more efficient than the Vanilla Transformer.\n\n[6] Vaswani, Ashish, et al. \"Attention is all you need.\" Advances in neural information processing systems 30 (2017).\n\n## 4. Improvements in Writing and Technical Presentation (W3, W5, W6, W7)\n\nThank you for the great catch on writing issues concerning equations and typos. We have fixed those in our revised draft."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700210818618,
                "cdate": 1700210818618,
                "tmdate": 1700210818618,
                "mdate": 1700210818618,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DunBDiVl6D",
                "forum": "mH3yfzIPsL",
                "replyto": "79XkQ9Nyde",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6853/Reviewer_cLDM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6853/Reviewer_cLDM"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "Thank you for your response. I still have concerns about the novelty of this paper. The main framework (called Cross-Temporal-Scale Transformer) can be easily found in other published papers. As the author says, the regular time series and irregularly timed event data have great difference, but I disagree with the argument that the distribution of data has impact on the framework. Your framework will be better if you can tackle with both regular and irregular conditions."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700537349622,
                "cdate": 1700537349622,
                "tmdate": 1700537349622,
                "mdate": 1700537349622,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Ys9zgLLTwY",
                "forum": "mH3yfzIPsL",
                "replyto": "jju4GYhqZS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer view that distribution of data has no impact on the framework"
                    },
                    "comment": {
                        "value": "We acknowledge that a model that can tackle both regular and irregular conditions will be ideal. Technically, we can of course run the framework on both regular and irregular sequences as long as the input format looks similar.  \nWe disagree with the reviewer, however, on the view that the distribution of data has no impact on the framework. We urge the reviewer to be careful to draw such a conclusion since there is a rich literature highlighting the difference in framework for time series forecasting and temporal point process. Statistically, they are different stochastic processes. In fact, not all regular-time series transformers are applicable to our irregular-time event sequence problems (including the two methods recommended by the reviewer). As said in [6], **Temporal point processes (TPPs)** are principled mathematical tools for the modeling and learning of asynchronous event sequences, which capture the instantaneous happening rate of the events and the temporal dependency between historical and current events. So **TPPs are the dominant paradigm for modeling sequences of events happening at irregular intervals [18]**. Our model proposed a neural TPP method. In fact, there is rich literature from major machine learning and AI conferences (e.g., AAAI, ICLR, ICML) highlighting that **there is a big gap between regular data (like time series) and irregular data (like even data, TPPs)**. For example, as stated in [1], \"Unlike other sequential data such as time series, event sequences tend to be asynchronous, which means time intervals between events are just as important as the order of them to describe their dynamics\". Furthermore, as claimed in [2], compared with regularly-spaced time series, TPPs are different since they are irregularly-spaced time sequences. As stated in [3], the time series and event data (TPPs) are different domains. As claimed in [4], the true distribution of events is never known and the performance depends on the design of the stochastic process. As claimed in [5], the irregularity and asynchronicity of event sequences pose a challenge. Similar arguments can also be found in [6-20].\n\nIn addition, can you reviewer provide evidence that the same \u201cframework (called Cross-Temporal-Scale Transformer) can be easily found in other published papers\u201d? Please kindly show us an example of paper that has exactly the same method and we will make sure we compare with them. \n\nCould the reviewer comment on our response to your concern about time complexity and cost analysis?\n\nReferences:\n[1] Zuo, Simiao, et al. \"Transformer Hawkes Process\". ICML 2020.\n\n[2] Bae, Wonho, et al. \"Meta Temporal Point Processes\". ICLR 2023.\n\n[3] Ding, Fangyu, et al. \"c-NTPP: Learning Cluster-Aware Neural Temporal Point Process\". AAAI 2023.\n\n[4] Pan, Zhen, et al. \"A Variational Point Process Model for Social Event Sequences\". AAAI 2020.\n\n[5] Zhang, Qiao, et al. \"Self-Attentive Hawkes Process\". ICML 2020.\n\n[6] Yan, Junchi, et al. \"Modeling and Applications for Temporal Point Processes\". KDD 2019.\n\n[6] Li, Shuang, et al. \"Learning Temporal Point Processes via Reinforcement Learning\". NeurIPS 2018.\n\n[7] Shou, Xiao, et al. \"Influence-Aware Attention for Multivariate Temporal Point Processes\". CLeaR 2023\n\n[8] Boyd, Alex, et al. \"Probabilistic Querying of Continuous-Time Event Sequences\". AISTATS 2023.\n\n[9] Gracious, Tony, et al. \"Dynamic Representation Learning with Temporal Point Processes for Higher-Order Interaction Forecasting\". AAAI 2023.\n\n[10] Wang, Qingmei, et al. \"Hierarchical Contrastive Learning for Temporal Point Processes\". AAAI 2023.\n\n[11] Yang, Chenghao, et al. \"Transformer Embeddings of Irregularly Spaced Events and Their Participants\". ICLR 2022.\n\n[12] Yuan, Yuan, et al. \"Spatio-temporal Diffusion Point Processes\". KDD 2023.\n\n[13] Chen, T. Q. , et al. \"Neural Spatio-Temporal Point Processes\".  ICLR 2021.\n\n[14] Zhang, Yunhao, et al. \"Learning Mixture of Neural Temporal Point Processes for Multi-dimensional Event Sequence Clustering\". IJCAI 2022.\n\n[15] Du, Nan, et al. \"Recurrent Marked Temporal Point Processes: Embedding Event History to Vector\". KDD 2016.\n\n[16] Mei, Hongyuan, et al. \"The Neural Hawkes Process: A Neurally Self-Modulating Multivariate Point Process\". NeurIPS 2017.\n\n[17] Omi, Takahiro, et al. \"Fully Neural Network based Model for General Temporal Point Processes\". NeuIPS 2019.\n\n[18] Shchur, Oleksandr, et al. \"Intensity-Free Learning of Temporal Point Processes\". ICLR 2020.\n\n[19] Shchur, Oleksandr, et al. \"Neural Temporal Point Processes: A Review\". IJCAI 2021.\n\n[20] Upadhyay, Utkarsh , et al. \"Deep Reinforcement Learning of Marked Temporal Point Processes\". NeurIPS 2018."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700577582805,
                "cdate": 1700577582805,
                "tmdate": 1700720645274,
                "mdate": 1700720645274,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6DWVAaCrso",
                "forum": "mH3yfzIPsL",
                "replyto": "Ys9zgLLTwY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6853/Reviewer_cLDM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6853/Reviewer_cLDM"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "Thanks for your response. The novelty of \"cross-scale transfromer\" has been published in ICCV 2021 [1], and this paper has been cited for many times. I think you just modified the structure of transformer in temporal dimension and deploy it into Irregular Time Event Prediction. Therefore, I still have concerns about the novelty of this paper.\n\nI don't mean that the distribution of data has no impact on the framework. I just give a suggestion that your framework can perform well in more generalized condition.\n\n\n[1] Chen C F R, Fan Q, Panda R. Crossvit: Cross-attention multi-scale vision transformer for image classification[C]//Proceedings of the IEEE/CVF international conference on computer vision. 2021: 357-366."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700639557929,
                "cdate": 1700639557929,
                "tmdate": 1700639557929,
                "mdate": 1700639557929,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KWaYorUfXw",
                "forum": "mH3yfzIPsL",
                "replyto": "jju4GYhqZS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer cLDM,\n\nThank you for your elaboration. We carefully read the related work [1] (ICCV 2021) you brought up. We agree with you that the general philosophy shares some similarity in that both methods address efficiency through coarse-scale and fine-scale attention.  Saying that, we still see some differences that can be important.\n\nSpecifically, Cross-ViT in paper [1] uses two attention branches (one for **small patches**, and the other for **coarse patches**) within a regular image grid. Because of the **regular grid**, different patch-scales are naturally **pre-existing (well-defined)**. This is similar to other multi-scale attention for time series data (e.g., Pyraformer in our references). In contrast, in our irregular time event sequence, the scales are often **implicit and need to be established**, by preprocessing with hierarchical time clustering (our current approach) or more importantly by learning such multi-scale temporal structure (that we plan to explore in future works). Therefore, we did not just modified the structure from [1]. We can add these discussion in a revised version.\n\nWe have spent quite some time in addressing your comments, including time complexity analysis and FLOPs and experimental results. Could you consider raising your score?\n\nFor your suggestion of a general method for different scenarios, we agree that it is a good to be general. It is just that most event prediction problems are irregular time in nature. But thank you for bringing this up."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687173881,
                "cdate": 1700687173881,
                "tmdate": 1700720723961,
                "mdate": 1700720723961,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "oyp5KCGWuK",
            "forum": "mH3yfzIPsL",
            "replyto": "mH3yfzIPsL",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6853/Reviewer_XqYU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6853/Reviewer_XqYU"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a natural extension of the Temporal Point Process framework. The idea is to use data split to improve the learning. In particular, the authors propose a specific way to cluster event sequences and calculate modified attention based on such a clustering."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Interesting idea and delivered algorithm\n- Reasonable number of datasets in the comparison\n- Time cost analysis performed. It shows the superiority of the considered approach for long sequences."
                },
                "weaknesses": {
                    "value": "- The proposed approach can limit the performance for complex long-range dependencies\n- Most alternative approaches consider a different structure for event type and intensity prediction, which makes a comparison not 100% fair (while I consider it not a big problem)\n- No comparison to other clustering approaches for TPP [1]. However, it is also tolerable, given that the paper came out in 2023. Also lack of comparison with clustering based on embeddings of tokes from NLP\n\n1. Ding, Fangyu, Junchi Yan, and Haiyang Wang. \"c-NTPP: learning cluster-aware neural temporal point process.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 37. No. 6. 2023."
                },
                "questions": {
                    "value": "- Can you compare your approach to c-NTPP?\n- Can you compare to other Efficient transformers based on grouping tokens into clusters [2, 3]?\n\n2. Vyas, Apoorv, Angelos Katharopoulos, and Fran\u00e7ois Fleuret. \"Fast transformers with clustered attention.\" Advances in Neural Information Processing Systems 33 (2020): 21665-21674. \n3. Wang, Ningning, et al. \"Clusterformer: Neural clustering attention for efficient and effective transformer.\" Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2022."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6853/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699508924160,
            "cdate": 1699508924160,
            "tmdate": 1699636794563,
            "mdate": 1699636794563,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "WBLphG7MFe",
                "forum": "mH3yfzIPsL",
                "replyto": "oyp5KCGWuK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer XqYU"
                    },
                    "comment": {
                        "value": "Thank you for the great suggestions on additional comparisons. We used **Q** and **W** to represent the questions and weaknesses listed, respectively.\n\n## 1. Comparison with c-NTPP (Q1, W2, W3)\nThank you for bringing up the recent work on c-NTPP (Cluster-Aware Neural Temporal Point Process), published in AAAI 2023. We compared it with our XTSFormer as you suggested. \n\nThe c-NTPP model is different from our method: c-NTPP utilizes a sequential variational autoencoder framework to identify clusters in latent feature embeddings (in latent feature space), while our XTSFormer framework conducts hierarchical clustering in the time domain in order to capture the complex multi-scale patterns in time domain from real-world data. \n\nWe also conducted experiments for comparison on two public datasets. The results are as follows:\n\n|           | Financial |          |      |      | StackOverflow |          |      |      |\n|:---------:|:---------:|:--------:|:----:|:----:|:-------------:|:--------:|:----:|:----:|\n|           | Accuracy (%)| F1-score (%) | RMSE |  NLL |   Accuracy (%) | F1-score (%) | RMSE |  NLL |\n|  c-NTPP [1]|    62.6   |   63.9   | 1.17 | 1.25 |      43.8     |   33.7   | 8.50 | 2.55 |\n| XTSformer |    77.5   |   78.8   | 0.88 | 1.18 |      49.4     |   35.0   | 4.21 | 1.89 |\n\nFrom the results, we can see that XTSFormer performed better in accuracy over c-NTPP on these two datasets (e.g., with a ~15% increase in accuracy on event type prediction on Financial dataset). This may be due to the importance of capturing multi-scale clustering patterns in the time domain. \n\n[1] Ding, Fangyu, Junchi Yan, and Haiyang Wang. \"c-NTPP: learning cluster-aware neural temporal point process.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 37. No. 6. 2023.\n\n\n## 2. Comparison with Other Grouping-based Transformers (Q2, W3)\nThank you for the suggestion. We added comparisons of our XTSFormer model with the efficient transformer models based on grouping tokens into clusters, i.e., Fast Transformers with Clustered Attention [2] and ClusterFormer [3].\n\nAfter reviewing these two papers in detail, we found that these two works are similar to ours in the sense that they also conduct efficient attention based on clustering. The main difference is that both works conduct clustering in the latent token embeddings (latent feature space), while our method conducts hierarchical clustering in the time domain (to capture the multiple temporal scale patterns). We added experimental comparisons, as you suggested, on the same two public datasets. Please note that we had to recast these two methods into neural temporal point process framework for irregular time event predictions. We maintained consistent hyper-parameters across all models for a fair comparison (details in Appendix A.2.1). The results are listed below.\n\nWe can see that while the models by [2] and [3] have better time efficiency, they fall short in prediction accuracy. The results may be due to the importance of capturing multi-scale clustering in time domain (our approach).\n\n|                   |   Financial  |              |      |      |                 | StackOverflow |              |       |      |                 |\n|:-----------------:|:------------:|:------------:|:----:|:----:|:---------------:|:-------------:|:------------:|:-----:|:----:|:---------------:|\n|                   | Accuracy (%) | F1-score (%) | RMSE |  NLL | Time Cost (min) |  Accuracy (%) | F1-score (%) |  RMSE |  NLL | Time Cost (min) |\n| Fast Transformers [2]|     71.6     |     69.2     | 1.57 | 1.44 |       6.9       |      43.5     |     32.8     |  5.17 | 3.04 |       12.4      |\n|   ClusterFormer [3]  |     65.0     |     51.8     | 1.93 | 1.87 |       5.0       |      40.5     |     27.1     | 10.15 | 5.66 |       9.8       |\n|     XTSformer     |     77.5     |     78.8     | 0.88 | 1.18 |       8.4       |      49.4     |     35.0     |  4.21 | 1.89 |       14.3      |\n\n\n[2] Vyas, Apoorv, Angelos Katharopoulos, and Fran\u00e7ois Fleuret. \"Fast transformers with clustered attention.\" Advances in Neural Information Processing Systems 33 (2020): 21665-21674.\n[3] Wang, Ningning, et al. \"Clusterformer: Neural clustering attention for efficient and effective transformer.\" Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2022.\n\n## 3. Long-range Dependencies (W1)\n\nThank you for the point. Can you please further elaborate on your concern about our approach's limiting the performance of complex long-range dependencies?"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700210719147,
                "cdate": 1700210719147,
                "tmdate": 1700237221878,
                "mdate": 1700237221878,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vDdvsfxhS6",
                "forum": "mH3yfzIPsL",
                "replyto": "oyp5KCGWuK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6853/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reminder of Response to Author's Rebuttal"
                    },
                    "comment": {
                        "value": "Dear Reviewer XqYU,\n\nWe have thoroughly reviewed each point you raised and have provided detailed responses to address them. We would be grateful if you could kindly review our responses and let us know if they satisfactorily address your concerns. If so, we hope you might consider revising your score accordingly.\n\nYour feedback is immensely valuable to us, and we look forward to any further suggestions you might have."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685430962,
                "cdate": 1700685430962,
                "tmdate": 1700720964893,
                "mdate": 1700720964893,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]