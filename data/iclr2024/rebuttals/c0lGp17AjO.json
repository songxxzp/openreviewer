[
    {
        "title": "A Wasserstein-2 Distance for Efficient Reconstruction of Stochastic Differential Equations"
    },
    {
        "review": {
            "id": "aIl8KBLZuz",
            "forum": "c0lGp17AjO",
            "replyto": "c0lGp17AjO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission276/Reviewer_2Kjt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission276/Reviewer_2Kjt"
            ],
            "content": {
                "summary": {
                    "value": "The paper derives Wasserstein distance between two probability distributions associated with two stochastic differential equations."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper tries to learn a SDE by bounding the W2 distance."
                },
                "weaknesses": {
                    "value": "There are no generalization bounds."
                },
                "questions": {
                    "value": "Can we prove some finite sample generalization bounds?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission276/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698556732314,
            "cdate": 1698556732314,
            "tmdate": 1699635952960,
            "mdate": 1699635952960,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "h0BBmq1jeA",
                "forum": "c0lGp17AjO",
                "replyto": "aIl8KBLZuz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal responses to Reviewer 2Kjt"
                    },
                    "comment": {
                        "value": "Thank you for your careful reading and valuable suggestions.  We\nbelieve that there could some misunderstanding on the ``generalization\nbound\".\n\nTo summarize, to the best of our knowledge, there are very few\npublished methods for general SDE reconstruction.  We propose the\nfirst general framework that can be readily used to reconstruct\ngeneral SDEs based on the Wasserstein distance. It provides a simple\nand efficient (compared to recent Wasserstein generative adversarial\nmethod and MMD loss method) way to reconstruct SDEs.  We applied our\nnew Wasserstein-distance-based SDE reconstruction method noisy\ntrajectories that arise in many biological and biophysical\nsettings. We show some of our preliminary results here\nhttps://drive.google.com/file/d/1HW5CBjx7g37DFx3s3A-sNDK0aoG6zqbT/view?usp=drive_link.\nWe will submit more extensive results on arXiv soon.\n\nGiven the novelty and potentially broad applicability of our method\ntowards uncertainty quantification and analyzing time series data, we\nhope you will kindly consider reevaluating the revised manuscript and\nupdate your score in light of our responses:\n\nQ1 \\& W1. Thank you for your question, and we appreciate the opportunity to\nclarify our approach in addressing your question on ``generalization\nbounds\".\n\nOur Theorem 2 provides a time-discretization error bound for the difference\nbetween the Wasserstein\ndistance of solutions to two distinct SDEs given the same initial condition and the Wasserstein distance\nof finite-time-point observations of the solutions to those two SDEs.\n\nThe\nstochastic nature of the Stochastic Differential Equation (SDE) we aim\nto reconstruct inherently complicates the straightforward extension of\n\"generalization bounds\" defined for deterministic systems. Thus, in Examples\n2, 3, and 4, we evaluate the performance of SDE reconstruction using\nthe metrics $|f-\\hat{f}|$ and $|\\sigma-\\hat{\\sigma}|$, representing\nthe errors in reconstructing the drift and diffusion terms of the SDE,\nrespectively. This choice aligns with our method's objective of\nreconstructing general unknown SDEs from data.\n\n\nIt would be nice to obtain ``finite sample generalization\nbounds\". Even though a theoretical derivation of such bounds is quite nontrivial\nchallenging, we have conducted a sensitivity analysis in Examples 2,\n3, and 4 to investigate how the number of samples impacts the\nreconstruction of $f$ and $\\sigma$ (refer to Figs. 2, 3, and 4). Our preliminary results\nindicate that more samples lead to better accuracy and smaller $|f-\\hat{f}|$ and $|\\sigma-\\hat{\\sigma}|$.\n\nAnalyzing the error bound between the empirical Wasserstein distance\nand the genuine Wasserstein distance is complicated and depends on\nboth the number of samples and the dimensionality of the SDE. This is\nbeyond the scope of our paper, as our focus was to introduce and\ndevelop a novel and practical (see our examples and additional applications)\nWasserstein-distance-based SDE reconstruction method as well as\nprovide insight into its efficacy.\n\n\nIn theory, there is also a theorem for analyzing the errors between the\nempirical Wasserstein distance with finite samples and the genuine\nWasserstein distance, see, \\textit{e.g.}\n\nRef [1]. Fournier, Nicolas, and Arnaud Guillin, On the rate of\nconvergence in Wasserstein distance of the empirical measure,\n$\\textbf{Probability theory and related fields}$, 162(3-4): 707-738,\n(2015).\n\nCurrently, our ongoing efforts involve both theoretical analysis of\nour Wasserstein-distance SDE reconstruction method and practical\napplications in reconstructing multiple SDEs with noisy dynamics in\nbiology. We have\ncited Ref [1] in our Example 4 to clearly state that more analysis is\nneeded on the number of samples and dimensionality in our future work.\n\nWe hope that these clarifications effectively address your concerns\nand we are open to further discussion or inquiries about our new\nWasserstein-distance-based loss function and SDE inference approach."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700110508414,
                "cdate": 1700110508414,
                "tmdate": 1700280389248,
                "mdate": 1700280389248,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EU3uYOofAD",
                "forum": "c0lGp17AjO",
                "replyto": "aIl8KBLZuz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer 2Kjt, \n\nWe are grateful for the time and expertise you dedicated to reviewing our paper. \nIn light of the clarifications we have made in response to your comments, we would be immensely appreciative if you could take a moment to review our responses. We hope that our clarifications and responses have satisfactorily addressed your questions and concerns and we would greatly appreciate it if our responses could warrant your reevaluation of our work. Thank you once again for your invaluable contribution and for sharing your expertise with us! \n\nWith sincere gratitude, \n\nAuthors"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700543385522,
                "cdate": 1700543385522,
                "tmdate": 1700543385522,
                "mdate": 1700543385522,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "saMpITj8By",
            "forum": "c0lGp17AjO",
            "replyto": "c0lGp17AjO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission276/Reviewer_ioMy"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission276/Reviewer_ioMy"
            ],
            "content": {
                "summary": {
                    "value": "The paper analyzes the Wasserstein 2 distance (WD) between solutions of two stochastic differential equations of form $d X(t) = f(X(t),t) d t + \\sigma(X(t),t) d B(t)$ as distributions over continuous function space. The main result shows that under certain mild assumptions, the WD is upper bounded by differences over $f$ and $\\sigma$, which establishes the relation between estimation of $f,\\sigma$ and the resulting reconstruction. Furthermore, when only a finite dimensional distribution is observed, the WD between the finite projections and the original WD are shown to be close to each other. An approximator of the finite projected WD is also proposed, using which various examples are implemented."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is overall well written and presented, and the the ideas are original to the knowledge of the reviewer. Some strengths:\n1. The bound in Theorem 1 seems interesting and novel, which establishes how the solution to SDE evolves as the parameters change. This provides evidence that WD is a valid loss function for SDE reconstruction. Moreover, an analysis of WD over Banach space (continuous function space) seems interesting.\n2. The proposed finitely projected WD loss seems simple to compute, and the examples illustrate that it is suitable for various reconstruction tasks."
                },
                "weaknesses": {
                    "value": "1. Theorem 1 is an interesting bound, but it is unclear how this gives a full characterization of what happens when using WD as a loss for reconstruction. In fact, a reverse of the inequality would also be needed to show that when minimizing the WD, the functions $f,\\sigma$ are both well approximated, as it is usually the WD that we can observe, rather than gaps for $f,\\sigma$.\n2. A major concern is the tightness of equation (17). As a simple example, if $f,\\sigma$ are both only function of $t$ not $x$, then the finite projections will be jointly Gaussian, the WD between which is not likely to be just sum of WD between marginal. Thus it is hard to assess how good the approximation is, even if it seems to work well in the provided examples."
                },
                "questions": {
                    "value": "Please see above (section Weaknesses) for details. The major question is how tight the approximation (17) is, as it was extensively used in the examples, and is claimed to be an approximation of the original WD. It is hard to assess how well the reconstruction is from the current contents of the paper, as it does not seem to properly 'interpolate' between discrete time steps if only local information is used, and continuity of the construction is provided by the continuity of the neural network estimators. Alternatively the paper can also provide theoretical guarantees specifically for this loss."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission276/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission276/Reviewer_ioMy",
                        "ICLR.cc/2024/Conference/Submission276/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission276/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698813355943,
            "cdate": 1698813355943,
            "tmdate": 1700605620653,
            "mdate": 1700605620653,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "d1gB38pJ3q",
                "forum": "c0lGp17AjO",
                "replyto": "saMpITj8By",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal responses to Reviewer ioMy part I"
                    },
                    "comment": {
                        "value": "Thank you for your careful reading and valuable suggestions.  We have\nrevised our manuscript based on your comments.\n\nTo summarize, to the best of our knowledge, there are very few\npublished methods for general SDE reconstruction.  We propose the\nfirst general framework that can be readily used to reconstruct\ngeneral SDEs based on the Wasserstein distance. It provides a simple\nand efficient (compared to recent Wasserstein generative adversarial\nmethod and MMD loss method) way to reconstruct SDEs.  We applied our\nnew Wasserstein-distance-based SDE reconstruction method noisy\ntrajectories that arise in many biological and biophysical\nsettings. We show some of our preliminary results here\nhttps://drive.google.com/file/d/1HW5CBjx7g37DFx3s3A-sNDK0aoG6zqbT/view?usp=drive_link.\nWe will submit more extensive results on arXiv soon.\n\nGiven the novelty and potentially broad applicability of our method\ntowards uncertainty quantification and analyzing time series data, we\nhope you will kindly consider reevaluating the revised manuscript and\nupdate your score in light of our responses:\n\nW1. Thank you for your insightful\nobservation. We would like to first clarify how Theorem 1 contributes\nto a comprehensive understanding of how to use the Wasserstein\ndistance (WD) as a loss for SDE reconstruction. Theorem 1 provides an\ninteresting upper bound for the Wasserstein distance concerning the\ndiscrepancies $|f-\\hat{f}|$ and $|\\sigma-\\hat{\\sigma}|$. This upper\nbound points to the necessity of minimizing the WD for the successful\nreconstruction of both $f$ and $\\sigma$. We have explicitly\nhighlighted this point on Page 3.\n\nIt is nontrivial to show a lower bound on the WD \nas a function of the errors in the drift and diffusion terms\n$f-\\hat{f}$ and $\\sigma-\\hat{\\sigma}$. The challenge lies in\nthe definition of the Wasserstein distance (Definition 2.1), which\ninvolves taking the infimum over all admissible couplings $\\pi(\\mu,\n\\hat{\\mu})$. Finding a lower bound for WD would probably require\nconstructing a specific coupling $\\pi^*(\\mu, \\hat{\\mu})$ to establish\n$W_2(\\mu, \\hat{\\mu})\\approx \\mbox{E}_{(\\boldsymbol{X}, \\hat{\\boldsymbol{X}})\\sim\n  \\pi^*(\\boldsymbol{X}, \\hat{\\boldsymbol{X}})}[\\lVert\\boldsymbol{X}-\\hat{\\boldsymbol{X}}\\rVert^2]$, which can\nbe analytically challenging.  In essence, the squared Wasserstein\ndistance $W_2^2$ serves as a measure of \"error\". Typically, we can\nonly derive upper bounds on this error.\n\nMost of the literature analyzes Wasserstein distances applied to SDEs,\nsuch as\n\nRef [1]. Wang Jian, $L^p$-Wasserstein distance for stochastic differential\nequations driven by L\\'evy processes, $\\textbf{Bernoulli}$, (2016):\n1598-1616.\n\nRef [2]. Sanz-Serna, Jesus Maria, and Konstantinos C. Zygalakis,\nWasserstein distance estimates for the distributions of numerical\napproximations to ergodic stochastic differential equations,\n$\\textbf{The Journal of Machine Learning Research}$, 22.1 (2021):\n11006-11042.\n\nThese works obtained only an upper bound for the Wasserstein distance\nand found no lower bounds.  To the best of our knowledge, we do not\nknow any literature on how to derive effective lower bounds for the WD\nunless one imposes some restrictions on the coupling $\\pi$, such as in\n\nRef [3]. M\\'emoli, Facundo, A spectral notion of Gromov\u2013Wasserstein\ndistance and related method, $\\textbf{Applied and Computational\n  Harmonic Analysis}$, 30.3: 363-401, (2011).\n\nand other papers that study some regularized Wasserstein\ndistances.\n\nWhile the feasibility of establishing a lower bound for WD remains\nuncertain, our numerical examples demonstrate the efficacy of training\nwith WD. Undoubtedly, the exploration of deriving a lower bound for WD\nin the context of solutions to two SDEs warrants further\ninvestigation. We are committed to addressing this gap in our future\nwork and will make our findings public once we find meaningful\nresults."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700110304127,
                "cdate": 1700110304127,
                "tmdate": 1700280354543,
                "mdate": 1700280354543,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "L31t84HKnL",
                "forum": "c0lGp17AjO",
                "replyto": "saMpITj8By",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal responses to Reviewer ioMy part II"
                    },
                    "comment": {
                        "value": "W2. We appreciate your thoughtful\nconsideration of Eq. (17) and your concern regarding its tightness.\n\nEq. (17) is an approximation to Eq. (16), and it is helpful to\nevaluate how it approximates Eq. (16) in general cases.  One rationale\nbehind employing Eq. (17) in our examples is its advantageous\nsimplification for univariate SDEs. In such cases, Eq. (17) reduces to\nEq. (3), allowing for analytical calculations and a clear statistical\ninterpretation. Specifically, Eq. (17) aims to match the distribution\nof reconstructed trajectories with the ground truth trajectories at\ndifferent time points.\n\nIn Example 4, we also directly minimized Eq. (16) (the blue line) as\nthe loss function. Our result shows that minimizing Eq. (16) performs\nworse than minimizing Eq. (17). To provide further insight, we\nincorporated a visualization of the loss functions concerning training\nepochs in Example 4, demonstrating the superior numerical efficiency\nof minimizing Eq. (17) relative to minimizing Eq. (16).\n\nIn theory, numerically calculating Eq. (16) could be less accurate\nespecially when the number of samples is limited, as the bound of the\ndiscrepancy between the empirical Wasserstein distance and the genuine\nWasserstein distance deteriorates when the dimensionality increases.\nIn using Eq. (16), the dimensionality is $Nd$, where $N$ is the number\nof timesteps and $d$ is the dimensionality of the SDE. See,\n\\textit{e.g.},\n\nRef [4]. Nicolas Fournier and Arnaud Guillin, On the rate of convergence in\nWasserstein distance of the empirical measure, $\\textbf{Probability\n  Theory and Related Fields}$, 162.3-4: 707-738, (2015).\n\nA comprehensive comparison between\nEq. (16) and the sum of Wasserstein distances between marginals\n(Eq. 17) requires further discussion, especially when dealing with\nmultidimensional SDEs, which we outlined in Example 4. This intricate analysis goes beyond the scope\nof our current manuscript, which primarily introduces the novel\nWD-based SDE reconstruction method and provides preliminary insight\ninto its efficacy.\n\nAs applications, we have successfully applied Eq. (17) as a loss\nfunction for reconstructing multiple multivariate SDEs.  Currently, we\nare working on analyzing WD for multidimensional SDEs and exploring\nwhether there are more suitable loss functions than Eq. (17).\n\nWe hope that our responses can satisfactorily address your questions\nand concerns and that you may better appreciate the new,\n  practical, and efficient Wasserstein-distance-based SDE\n  reconstruction approach that we developed."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700110339161,
                "cdate": 1700110339161,
                "tmdate": 1700280362539,
                "mdate": 1700280362539,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "eKhV7XKl8a",
                "forum": "c0lGp17AjO",
                "replyto": "L31t84HKnL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Reviewer_ioMy"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Reviewer_ioMy"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "I thank the authors for the response, which addresses most of my questions. Regarding (17) I'm still not fully convinced that the proposed method is a principled substitute of (16), as it seems all the causality across different time are lost, even if (17) performs better empirically. I will thus still leave my score unchanged."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700519400118,
                "cdate": 1700519400118,
                "tmdate": 1700519400118,
                "mdate": 1700519400118,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "AASyE3SoJa",
                "forum": "c0lGp17AjO",
                "replyto": "pwoB6xn1S7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Reviewer_ioMy"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Reviewer_ioMy"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "I thank again the authors for the response.\n\nHere are some clarification of my previous question: I acknowledge that the proposed (17) is rather easy to implement and performs well as illustrated. However, it seems the theoretical guarantees (e.g. Thm 2) are all for (16). The $\\approx$ in (17) suggests that they are strongly related, but there are plenty of examples where (16) and (17) differs substantially. Thus it seems there's a noticeable gap between the theoretical guarantee part of the paper and the implementation part. The reviewer expects at least some direct justification is provided for (17), rather than simply stating \"If one disregards the temporal correlations of values at different times within a single trajectory...\". For the current form of the paper, it seems the soundness of (17) is only supported heuristically.\n\nThe reviewer understands that this is additional work, so here are some alternative improvements: either to provide a bound or discussion for why the \"$\\approx$\" in (17) makes sense, or simply stating (17) as a practically motivated quantity that is inspired by (16). In either case the reviewer suggests to add discussion on tightness or gap on the approximation argument $\\approx$ in (17).\n\nOne side note: reconstructing based on marginals (17) have appeared in a related context of Wasserstein splines [1,2,3]. Introducing this to inferring SDE coefficients indeed seems interesting, so the reviewer increases the rating to 6. (Personally the reviewer thinks it's possible to extend Thm 2 to (17) by smoothness assumptions of $f,\\sigma$, which would greatly strengthen the theoretical merit of the paper.)\n\n[1] Chen, Yongxin, Giovanni Conforti, and Tryphon T. Georgiou. \"Measure-valued spline curves: An optimal transport viewpoint.\" SIAM Journal on Mathematical Analysis 50.6 (2018): 5947-5968.\n[2] Benamou, Jean-David, Thomas O. Gallou\u00ebt, and Fran\u00e7ois-Xavier Vialard. \"Second-order models for optimal transport and cubic splines on the Wasserstein space.\" Foundations of Computational Mathematics 19 (2019): 1113-1143.\n[3] Chewi, Sinho, et al. \"Fast and smooth interpolation on Wasserstein space.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2021."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700605602380,
                "cdate": 1700605602380,
                "tmdate": 1700605602380,
                "mdate": 1700605602380,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xjQdSxK7sA",
                "forum": "c0lGp17AjO",
                "replyto": "saMpITj8By",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your suggestions! & Revisions based on your advice"
                    },
                    "comment": {
                        "value": "Dear Reviewer ioMy,\n\nWe really appreciate your feedback and your reevaluation! \nWe are grateful for your constructive suggestions. Our previous statement that ``Eq. (17) is an approximation to Eq. (16)\" was not very precise. Actually, Eq. (17) is smaller than or equal to Eq. (16) due to a relaxation on the constraint of the coupling \\pi(\\mu, \\hat{\\mu}). We have made this point clear and revised the manuscript accordingly (Page 5). Since Eq. (17)\\leq Eq. (16), minimizing Eq. (17) is also necessary to have a small reconstruction error $f-\\hat{f}$ and $\\sigma-\\hat{\\sigma}$ owing to Theorems 1 & 2, and we have also made this point clear in the manuscript (Page 5).\n\nWe have added an additional section (Appendix J) to carry out an additional numerical experiment in response to your question on the gap between Eq. (16) and Eq. (17). Interestingly, when minimizing Eq.(16), the gap between Eq. (16) and Eq. (17) is relatively large. However, when minimizing Eq. (17), the gap is small and both Eq.(16) and Eq.(17) are kept small. We believe that this is worth further investigation. \n\nFurthermore, in Appendix J, we have extended Thm 2 to Eq. (17) and explicitly showed that Eq. (17) is an approximation to the summation of time-decoupled squared W2\ndistances \n\\begin{equation}\n\\sum_{i=1}^{N-1}W_2^2(\\mu_i, {\\hat{\\mu_i}})\n\\end{equation}\n in the $N\\rightarrow \\infty$ limit, where $\\mu_i, \\hat{\\mu_i}$ are the two probability distributions associated with $\\boldsymbol{X}(t), t\\in[t_i, t_{i+1})$ and $\\hat{\\boldsymbol{X}}(t), t\\in[t_i, t_{i+1})$. This is our preliminary result on the theoretical aspect of the loss function Eq. (17). Please see our updated manuscripts for those revisions.\n\nYour references on the Wasserstein splines are greatly appreciated, and we have cited Ref. [3] which seems to be related to our time-decoupled W2 loss. We are working on further analyzing the squared $W_2$ distance, and will post our findings on arXiv once we reach some interesting results. We believe that our proposed simple and efficient W2-distance-based SDE reconstruction method could become a potential benchmark method in this specific SDE reconstruction field. We would greatly appreciate it if you found our work interesting and potentially useful.\n\n\nSincerely,\n\nAuthors"
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700679749731,
                "cdate": 1700679749731,
                "tmdate": 1700679999704,
                "mdate": 1700679999704,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7wDaBwIA4V",
            "forum": "c0lGp17AjO",
            "replyto": "c0lGp17AjO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission276/Reviewer_fb1D"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission276/Reviewer_fb1D"
            ],
            "content": {
                "summary": {
                    "value": "This paper delved into the poblem of reconstructing SDEs (using Neural Networks) with Wasserstein-2 loss ($W_2$). The authors introduced a new bound on the $W_2^2$ loss of 2 probability measures constructed on 2 random process. In addition, the authors also provided an estimation of the $W_2^2$ that can be carried out numerically. Finally, the authors conducted empirical experiments testing the perfomance of reconstructing SDEs using Neural Networks with this $W_2^2$ loss."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper is written clearly with detailed explanation.\n\n2. The authors provided an upper bound on the $W_2^2$ distance that can be approximated numerically.\n\n3. The empirical performance of the new loss out-performs traditional MSE and KL loss."
                },
                "weaknesses": {
                    "value": "I am not very familiar with this topic. There seems to be no major flaw in this paper, but I think it would be better if there are some more detailed comparisons with prior works and other losses, as the authors only provided some intuitive comparison with MSE and KL divergence losses in Appendix B."
                },
                "questions": {
                    "value": "1. What kind of noise can the $W_2^2$ loss deal with?\n\n2. Can the authors provide some intuition about why $W_2^2$ loss is more robust to noise?\n\n3. Is eq(10) purely of intellectual interest or thers are some methods to estimate this expectation? It seems Theorem 2 didn't use this upper bound to construct an estimation of the $W_2^2$ loss.\n\n4. Finally, I am curious what method did the authors use to minimize the $W_2^2$ loss?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission276/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698819168066,
            "cdate": 1698819168066,
            "tmdate": 1699635952792,
            "mdate": 1699635952792,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GUovmk6GHm",
                "forum": "c0lGp17AjO",
                "replyto": "7wDaBwIA4V",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal responses to Reviewer fb1D"
                    },
                    "comment": {
                        "value": "Thank you for your careful reading and valuable suggestions. \n\nTo summarize, to the best of our knowledge, there are very few\npublished methods for general SDE reconstruction.  We propose the\nfirst general framework that can be readily used to reconstruct\ngeneral SDEs based on the Wasserstein distance. It provides a simple\nand efficient way (compared to recent Wasserstein generative\nadversarial method and MMD loss method) to reconstruct SDEs.  We\napplied our new Wasserstein-distance-based SDE reconstruction method\nto noisy trajectories that arise in many biological and biophysical\nsettings. We show some of our preliminary results here\nhttps://drive.google.com/file/d/1HW5CBjx7g37DFx3s3A-sNDK0aoG6zqbT/view?usp=drive_link.\nWe will submit more extensive results on arXiv soon.\n\nGiven the novelty and potentially broad applicability of our method\ntowards uncertainty quantification and analyzing time series data, we\nhope you will kindly consider reevaluating the revised manuscript and\nupdate your score in light of our specific responses:\n\nW1. Indeed in Appendix B we explained in theory why the MSE and KL\ndivergence is not as good as the Wasserstein distance for the purpose\nof SDE reconstruction. Moreover, in Examples 1 and 2, we numerically\ncompared our Wasserstein-distance based SDE reconstruction approach\nwith MSE, maximal log likelihood, and Mean$^2$+Var approaches. Our\nWasserstein distance loss gives the best reconstructed trajectories\n(Example 1) and smallest errors $f-\\hat{f}$ and $\\sigma-\\hat{\\sigma}$\n(Example 2). In Examples 3 and 4, we compare our approach with\nrecently proposed machine learning methods such as a Wasserstein\nGenerative Adversarial Network (WGAN) approach and a Maximum Mean\nDiscrepancy (MMD) loss. Once again, our Wasserstein distance method\noutperforms the WGAN and MMD approaches in both accuracy and\nefficiency.  We hope that these numerical experiments and comparisons\nwith other methods convince you of the advantages of our new method.\n\nQ1. In principle, the $W_2^2$ loss can can\nbe calculated for a stochastic process obeying many kinds of noise.\nFor example, the Wasserstein distance between different\n  solutions associated with different initial conditions of a general L\\'evy process has been computed\n, \\textit{e.g.},.\n\nRef [1]. Jian Wang, $L^p$-Wasserstein distance for stochastic differential equations driven by L\\'evy processes, $\\textbf{Bernoulli}$, 1598-1616, (2016).\n\nIn our work, we minimize a Wasserstein loss to\nreconstruct the SDE from data, and restrict ourselves to Brownian\nnoise processes.\n\n\nQ2. The\nrobustness of the $W_2^2$ loss to noise can be attributed to its\nnature as a distribution-based loss function, as exemplified by\nEq. (3). This type of loss is designed to quantify the difference\nbetween the targeted distribution and the approximated distribution,\nmaking it particularly well-suited for reconstructing the distribution\nof trajectories. Compared to the MSE, $W_2^2$ captures the variation and compared to the Mean$^2$+Var , $W_2^2$ is able to capture more features such as multiple peaks, \nas illustrated in Example 1.\n\nIn Example 1, we also demonstrated the suitability of the $W_2^2$ loss for\nreconstructing distributions. An additional advantage lies in the\nflexibility of the $W_2^2$ loss. Unlike other commonly used loss\nfunctions, such as Mean$^2$+Var or maximal log likelihood, the $W_2^2$\nloss does not necessitate an assumption of a Gaussian\ndistribution. This characteristic enhances its robustness to various\ntypes of noise, as it does not rely on specific distributional\nassumptions.\n\nQ3. Eq. (10) is for Theorem 1. It is\na rather technical condition such that if satisfied, then\nthe $W_2^2$ distance between the solutions to two SDEs converges\nuniformly to 0 as $\\hat{f}\\rightarrow f, \\hat{\\sigma}\\rightarrow\n\\sigma$, as we explain on Page 4.\n\nAs a simple case, if $f, \\sigma, \\partial_x f, \\partial_x \\sigma$ are\nuniformly bounded, then Eq. (10) is also uniformly bounded, and all\nassumptions of Theorem 1 are satisfied.\n\nQ4. As described\non Page 6, training details are given in Appendix E. For all examples,\nthe AdamW stochastic optimization method is used for minimizing the\n$W_2^2$ loss. The code implementation is available in the\nsupplementary files provided with the manuscript.\n\nWe hope that our responses satisfactorily address your questions and\nconcerns and that you will better appreciate the new\nWasserstein-distance-based SDE reconstruction method we have\ndeveloped."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700110052042,
                "cdate": 1700110052042,
                "tmdate": 1700280330651,
                "mdate": 1700280330651,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7POljijm0Z",
                "forum": "c0lGp17AjO",
                "replyto": "7wDaBwIA4V",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer fb1D,\n\nWe are grateful for the time and expertise you dedicated to reviewing our paper. \nIn light of the changes and clarifications we have made in response to your comments, we would be immensely appreciative if you could take a moment to review our responses. Your confirmation on whether our responses have adequately addressed your concerns would be greatly valued. We hope that our clarifications and responses have satisfactorily addressed your questions and concerns and we would greatly appreciate it if our responses could warrant your reevaluation of our work.\nThank you once again for your invaluable contribution and for sharing your expertise with us!\n\nWith sincere gratitude,\n\nAuthors"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700543186282,
                "cdate": 1700543186282,
                "tmdate": 1700543219248,
                "mdate": 1700543219248,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aYn9IKofCc",
                "forum": "c0lGp17AjO",
                "replyto": "GUovmk6GHm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Reviewer_fb1D"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Reviewer_fb1D"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their detailed response. I would like to keep my ratings unchanged."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700588835765,
                "cdate": 1700588835765,
                "tmdate": 1700588835765,
                "mdate": 1700588835765,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kE10SosXY6",
                "forum": "c0lGp17AjO",
                "replyto": "7wDaBwIA4V",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer fb1D,\n\nWe really appreciate your time in reading our responses and your feedback! \n\nExtracting SDEs from noisy time series data has been an important topic in uncertainty quantification for biological and physical applications. However, there exist very few methods for SDE reconstruction. Using the W2 distance as a loss function to reconstruct SDEs is quite easy to implement and easy to understand. Furthermore, it outperforms traditional methods and recent machine learning methods we have known so far in both efficiency and accuracy. Thus, we believe that our proposed simple W2-distance-based SDE reconstruction could become a potential benchmark method in this specific SDE reconstruction field. We would greatly appreciate it if you found our work interesting and potentially useful.\n\nSincerely,\n\nAuthors"
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700679867702,
                "cdate": 1700679867702,
                "tmdate": 1700679983251,
                "mdate": 1700679983251,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "l8xxOet8Io",
            "forum": "c0lGp17AjO",
            "replyto": "c0lGp17AjO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission276/Reviewer_NdWD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission276/Reviewer_NdWD"
            ],
            "content": {
                "summary": {
                    "value": "Optimal transport (OT) metrics, aka Wasserstein distances, are ubiquitous in comparing probability measures since they capture the underlying geometric of the objects at hand. This paper introduces the Wasserstein distance between two probability distributions associated with two solutions of stochastic differential equations (SDE). The author(s) investigate the squared Wasserstein distance to reconstruct the drift and the diffusion components of an SDE through a neural SDE."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Investigating the 2-Wasserstein distance between two probability distributions associated with two solutions.\n- Theoretical guarantees of the 2-Wasserstein distance.\n- Reconstruction of the drift and the diffusions component of SDE through a neural SDE where the 2-Wasserstein distance serves as the loss training.\n- Numerical experiments of univariate and bivariate SDE for CIR, OU, and 2D geometric Brownian models."
                },
                "weaknesses": {
                    "value": "- I suggest that the result in Theorem 1 should be highlighted in the case of **univariate** SDE ($d=1$), since in Definition 1, the Wasserstein distance is defined for $d$-dimensional processes. \n- In Remark 1, the author(s) mentioned that the upper bound could be generalized for $d$-dimensional case under mild assumptions. I think it is important to write this result and get some consistent presentation in the manuscript since Theorem 2 is valid for multivariate case.\n- Again with Remark 1, do the drifts $(f_i)$ and the diffusions components $(\\sigma_i)$ satisfy the same assumptions in Theorem 1?\n- In Equations (16) and (17),  the vectors  $\\boldsymbol{X}(t_i)$ and $\\hat{\\boldsymbol{X}(}t_i)$ are $d$-dimensional then the squared  $(\\boldsymbol{X}(t_i) -\\hat{\\boldsymbol{X}(}t_i))^2$ must be a squared-$L_2$ norm.\n\n- For the rotated  $W_2$, I couldn't understand the intuition behind this application of rotations. I think there is an \"embedding\"-like of the origin components $X_1$ and $X_2$ of the SDE, hence it seems that we have changed the origin SDE, by changing its drift and diffusions components. So, the rotated $W_2$ is it an upper or a lower bound for the origin one?\n- Does the rotated squared $W_2$ verify the same upper and lower bounds as in Theroems 1 and 2?\n- In the definition of the rotated Wasserstein, does $m$ the number of rotations? If yes, so in Tables 6 and 7 $N_{rotate}$ should be replaced by $m$.\n- According to Figure 4, I would prefer the reconstruction of $f$ and $\\sigma$ using Eq. 16 and Eq. 17 than the rotated $W_2$. Indeed, according to their definitions on Page 17,  they are acting on the empirical observations of the process in the time partition $(t_i)$. However, the rotated $W_2$ is acting on an embedding of the origin process, which might induce some loss of data information.\n\n- Tables 6 and 7 could be more readable if they were represented as plots."
                },
                "questions": {
                    "value": "### Minor comments\n- Page 2: \"regularized W distance\", add the reference (Cuturi 2013, NIPS'13).\n- Page 2: \"reconstructingmultidimensional\"  -->  reconstructing multidimensional.\n- Page 4: \"MSE-based\": the acronym MSE is not defined.\n- Page 6: \"torchsde package (Lie tal, 2020) in Python\" --> \"torchsde Python package (Lie tal, 2020).\n- Page 7: \"Cox-Ingersoll-Ross\" --> \"Cox-Ingersoll-Ross (CIR)\".\n- Page 8: \"Python Optimal Transport package\": add its reference Flamary et al. JMLR'21.\n- Page 8, Caption Figure 4: \"the vectors $f(X_1, X_2) \\hat f(X_1, X_2)$\" --> add a comma $f(X_1, X_2), \\hat f(X_1, X_2)$.\n- Page 12: Equation (25): there is not a norm, it is only an absolute value. \n- Page 14: \"where $||X||^2$: $X$ would be in bold.\n- Page 14: $| \\cdot |$ is the $l^2$ norm: this is a little bit confusing because this notation is used before for the absolute value.\n- Page 14: In Equation (34), $\\ell$ is not defined.\n- Page 16: \"two vectors $(x_1(t_i), X_2(t_i)$: missing closed parenthesis.\n- Page 21: Caption of Table 7: \"This indicates the correlation .... in the drift term\", I think the correlation in the drift is more difficult to distinguish than the correlation in the diffusion because the relative error in $\\sigma$ gets much smaller."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission276/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission276/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission276/Reviewer_NdWD"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission276/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698873972051,
            "cdate": 1698873972051,
            "tmdate": 1700567255271,
            "mdate": 1700567255271,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tTXZGdOV5j",
                "forum": "c0lGp17AjO",
                "replyto": "l8xxOet8Io",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal responses to Reviewer NdWD part I"
                    },
                    "comment": {
                        "value": "Thank you for your careful reading and valuable suggestions.  We have\nrevised our manuscript based on your comments.\n\nTo summarize, to the best of our knowledge, there are very few\npublished methods for general SDE reconstruction.  We propose the\nfirst general framework that can be readily used to reconstruct\ngeneral SDEs based on the Wasserstein distance. It provides a simple\nand efficient (compared to recent Wasserstein generative adversarial\nmethod and MMD loss method) way to reconstruct SDEs.  We applied our\nnew Wasserstein-distance-based SDE reconstruction method noisy\ntrajectories that arise in many biological and biophysical\nsettings. We show some of our preliminary results here\nhttps://drive.google.com/file/d/1HW5CBjx7g37DFx3s3A-sNDK0aoG6zqbT/view?usp=drive_link.\nWe will submit\nmore extensive results on arXiv soon.\n\nGiven the novelty and potentially broad applicability of our method\ntowards uncertainty quantification and analyzing time series data, we\nhope you will kindly consider reevaluating the revised manuscript and\nupdate your score in light of our responses:\n\nW1. We have added a sentence in Theorem 1 to indicate that it\napplies to the 1D SDE case.\n\nW2. We concur that presenting $d$-dimensional version of Theorem 1 \n  is beneficial.  As we\nhave shown in the remark, Theorem 1 can be straightforwardly extended \nto $d$-dimensional SDEs in the trivial case where $f_i, \\sigma_i$\ndepend only on $X_i$ (the $i^{\\text{th}}$ component of the vector\n${\\boldsymbol X}$). We are currently working on generalizing Theorem 1 to\ncoupled multidimensional SDEs and have revised our remark accordingly\nto state that multivariate cases is quite nontrivial.\n\nEven though we have not yet been able to obtain theoretical results\nthat generalize Theorem 1 to multidimensional SDEs, Eq. (17)\nnonetheless works well as a loss function for reconstructing\nmultidimensional SDEs, as is shown in our Example 4 and the additional\nexamples we provide. \n\nIn summary, while we await proofs of the generalization of Theorem 1\nto multidimensional SDEs, we have highlighted the practical success of\nour approach in reconstructing multidimensional stochastic systems. We\nremain committed to sharing any theoretical advancements in subsequent\nwork, ensuring transparency and clarity in our contributions.\n\nW3. If each $f_i, \\sigma_i$ depend only on $X_i, t$ and satisfy the conditions in\nTheorem 1, then Theorem 1 can be generalized to multivariate cases. We\nare still working on extending Theorem 1 to interacting\nmultidimensional SDEs, which appears quite nontrivial.\n\nW4. We have revised\nthe $\\ell^2$ vector norm notation $|\\cdot|^2$ to $|\\cdot|^2_2$ to avoid confusion.\n\nW5.  We\n  appreciate your inquiry regarding the intuition behind the\n  application of rotations in the rotated $W_2$ method. The rotated\n  $W_2$ serves as a lower bound of the true $W_2$ distance. In higher\n  dimensions, an analytical evaluation of the $W_2$ distances is\n  challenging. Our approach approximates the $W_2$ distance in two\n  ways: the decoupled $W_2$ and the rotated $W_2$.\n\n  The primary method, which we refer to as the decoupled $W_2$\ndistance, involves projecting the 2D distribution in two orthogonal\ndirections and summing the $W_2$ distances between $1 \\mathrm{D}$\nprojections of the true and reconstructed data. This method yields a\nlower bound of the true $W_2$ distance and is exact (equal to the true\n$W_2$) if the 1D projections $X_1$ and $X_2$ are mutually independent.\n\nHowever, this approach may not effectively handle skewed (correlated)\ndistributions. We address this by applying a suitable rotation, as\nillustrated in the figure https://drive.google.com/file/d/1wJdYAzZQhNEEOsQ-80Ne1GvWsuxxX0D-/view?usp=drive_link.\n\nPractically, the\noptimal rotation matrix is unknown, necessitating an average over\nvarious rotations. Since each rotation is isometric, rotation \ndoes not change the true $W_2$ distance, and thus each decoupled\n$W_2$ distance post-rotation remains a lower bound of the true $W_2$\ndistance. Therefore, the averaged $W_2$ distance after rotation also\nconstitutes a lower bound of the true $W_2$ distance.\n\nWe discuss the rotated $W_2$ distance in more detail in Appendix D of the revised manuscript \nas well as in the response to Comment 8 below.\n\n\nW6. The rotated squared $W_2$ is a lower bound\nof the true $W_2$ distance and aims to approximate the true $W_2$\ndistance for the empirical distributions on the time partition\n$\\left(t_i\\right)$.  Consequently, upper bounds for $W_2$ distances\nassociated with the time partition $\\left(t_i\\right)$ hold for the\nrotated squared $W_2$ distance as well.  We have further clarified the\ndefinition of the rotated squared $W_2$ loss in Appendix D of the\nrevised manuscript.\n\nW7. Yes, $m$ is the number of rotations. We\nhave revised the notation in Tables 6 and 7 (now Fig. S1 and Fig. S2)\naccordingly."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700109646378,
                "cdate": 1700109646378,
                "tmdate": 1700280214418,
                "mdate": 1700280214418,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YgWccQv5zE",
                "forum": "c0lGp17AjO",
                "replyto": "l8xxOet8Io",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal responses to Reviewer NdWD part II"
                    },
                    "comment": {
                        "value": "W8. To clarify, the rotation itself does not introduce additional\nloss of information, as the rotation is an isometric linear\ntransformation. From an abstract perspective, the true\nhigh-dimensional dynamics is not changed by a change of coordinates.\nFrom another perspective, the original SDE of $\\boldsymbol{X}_t$ and\nthe rotated SDE of $\\boldsymbol{Y}_t \\coloneqq\n\\boldsymbol{R}\\boldsymbol{X}_t$, where $\\boldsymbol{R}$ is a rotation\nmatrix, are related by\n\\begin{equation}\n\\mathrm{d} {\\boldsymbol{Y}} = \\boldsymbol{R}\n\\boldsymbol{f}\\big(\\boldsymbol{R}^{-1} (\\boldsymbol{Y})\\big)\n\\mathrm{d} t + \\boldsymbol{R} \\boldsymbol{\\sigma} \\big(\\boldsymbol{R}^{-1}\n(\\boldsymbol{Y})\\big)\\mathrm{d} \\boldsymbol{W}_t.\n\\end{equation}\n Once knowing the\nrotated SDE, we can recover the original SDE by applying the inverse\ntransform $\\boldsymbol{R}^{-1}$.\nDespite this, averaging over different rotations and projecting in\ndifferent directions can lead to some loss of information. \n\nLastly, we plug the decoupled and rotated $W_2$ distances into Eq. 17\nas approximations to the true $W_2$ distance at each time point. \nWhile these methods provide analytical approximations to\nthe true $W_2$ distance, our manuscript also explores numerical\noptimization procedures for a numerical approximation of the $W_2$\ndistance. The purpose is to compare the performance and computational \ncosts of these methods. We discuss these\naspects in further detail in Example 4 of the revised manuscript.\n\n\nW9. We have replaced Tables 6 and 7 with Figs. S1\nand S2 in the revised manuscript.\n\n$\\textrm{\\textbf{Minor comments:}}$\n\nWe really appreciate your careful reading and we have made revisions\nbased on your minor comments and cited the references you\nsuggested. Here are our responses to some of your questions in the\nminor comments.\n\n\n\nQ11. In Equation (34), $\\ell$ is was added by mistake.\n  We have removed it in the revised manuscript.\n\nQ13. Thank you for your observation regarding the correlation in the drift\nterm. We apologize for any confusion caused by our initial\nexplanation. In the revised manuscript, we have clarified the\ncomparison between the two scenarios outlined in Tables 6 and 7 (now\nFig. S1 and S2). In Table 6 (now Fig. S1), the ground truth SDE is\ndefined by Eq. 22, where the drift terms have no correlation across\ndifferent components. In Table 7 (now Fig. S2), the ground truth SDE\nis defined by Eq. 48, where the drift terms are correlated across\ndifferent components. In both cases, the diffusion terms are\ncorrelated across different components.\n\nLooking at the relative errors in drift terms $\\boldsymbol{f}$, they all\nhover around 0.1 for both cases and all values of rotation number $m$.\nComparison between Tables 6 and 7 (now Fig. S1 and S2) shows that\ncorrelation in drift terms \\textit{does not} significantly affect\nthe reconstruction of drift terms.\n\nBy contrast, increasing the rotation number $m$ from 1 to 10\nsignificantly improves the reconstruction of diffusion terms\n$\\boldsymbol{\\sigma}$ when they are correlated across different\ncomponents (Table 7, now Fig. S2).\n\nIn conclusion, the rotated $W_2$\ndistance ($m \\geq 2$) performs better than the decoupled $W_2$\ndistance ($m = 1$) in reconstructing correlated diffusion terms, while\nit does not significantly contribute to the reconstruction of drift\nterms. On the other hand, the existence of correlation in diffusion terms\nconfounds the reconstruction by the decoupled $W_2$ distance, while correlation\nin drift terms does not. This suggests that the existence of correlation in diffusion terms is indeed more\ndifficult to distinguish than the existence of correlation in drift terms in our example. In reconstructing general multivariate SDEs,\nit remains to explore whether the correlation in the drift is more difficult than the correlation in the diffusion\nto distinguish or not.\n\nWe have revised the paragraph following Table 7 (now Fig. S2) to\nclarify this point.\n\nWe hope that our responses satisfactorily address your questions and\nconcerns and that you will better appreciate the new\nWasserstein-distance-based SDE reconstruction method we have\ndeveloped."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700109859771,
                "cdate": 1700109859771,
                "tmdate": 1700280271786,
                "mdate": 1700280271786,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YX7DUCiYse",
                "forum": "c0lGp17AjO",
                "replyto": "l8xxOet8Io",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer NdWD,\n\nWe are extremely grateful for the time and expertise you dedicated to reviewing our paper. Your suggestions and feedback greatly helped us improve our work. We deeply value your support and guidance in this process.\nIn light of the changes we have made in response to your comments, we would be immensely appreciative if you could take a moment to review our revisions. We would be greatly appreciating it if our responses have satisfactorily addressed your concerns and warrant your reevaluation.\nThank you once again for your invaluable contribution and for sharing your expertise with us!\n\nWith sincere gratitude,\n\nAuthors"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700542809339,
                "cdate": 1700542809339,
                "tmdate": 1700543230690,
                "mdate": 1700543230690,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hBS4edaSzK",
            "forum": "c0lGp17AjO",
            "replyto": "c0lGp17AjO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission276/Reviewer_pb7V"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission276/Reviewer_pb7V"
            ],
            "content": {
                "summary": {
                    "value": "Given SDE of form (2), expressions for optimal transportation between the two such process is provided. An upper bound on the objective is shown in theorem1, which guarantees that when both deterministic and stochastic functions in the SDE are close, then the objective is close to zero. Then a time-discretised version (16) is presented, which by theorem2 convergence to the true objective as time-step becomes infinitesimally small.\n\nThe optimal objective is then employed as a loss to learn/estimate an SDE. Simulations on simple SDEs are presented."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. SDE estimation using optimal transport seems interesting. I feel this is not so well-understood from a learning perspective and perhaps deserves more attention."
                },
                "weaknesses": {
                    "value": "1. The presentation can be improved to make it easily readable. Currently, I found it hard to understand what is happening. Brevity and notation compound the difficulty.\n\n2. Since the bound (7) is not elegant, perhaps it could be simplified appropriately to preserve the point about convergence. \n\n3. Some training set details for simulations seem missing like what was the step-size, time-horizon, number of samples etc ?\n\n4. There seem to be prior works which perhaps present a more comprehensive analysis of SDE wrt. optimal transport e.g., [1*], [2*], [3*], [4*]. It would be insightful if these are discussed in detailed in related work and perhaps appropriately compared with. I feel this is a major weakness of the work.\n\n[1*] https://arxiv.org/pdf/1902.08567.pdf\n[2*] https://arxiv.org/pdf/1603.05484.pdf\n[3*] https://arxiv.org/abs/1209.0576\n[4*] https://www.jmlr.org/papers/volume22/21-0453/21-0453.pdf"
                },
                "questions": {
                    "value": "1. What do the measures \\mu,\\hat{\\mu} represent? It seems they are measures corresponding to X(t) and \\hat{X}(t) . If so, should not there be a \\mu(t), \\hat(\\mu}(t) ? In which case, they cannot be used in the LHS of 5 as the RHS is integrated over time. I think the RHS is a generalization of optimal transport to SDEs, but the optimal objective need not be a wasserstein distance (LHS). Am I correct ?\n\n2. why are different sets of baselines used in the various simulation examples ?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission276/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission276/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission276/Reviewer_pb7V"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission276/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699032533519,
            "cdate": 1699032533519,
            "tmdate": 1700632314026,
            "mdate": 1700632314026,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Fz1wr7nvek",
                "forum": "c0lGp17AjO",
                "replyto": "hBS4edaSzK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal responses to Reviewer pb7V part I"
                    },
                    "comment": {
                        "value": "Thank you for your valuable comments.  We have revised our manuscript\nbased on your suggestions.  \n\nTo summarize, to the best of our\nknowledge, there are very few published methods for general SDE\nreconstruction.  Addressing this gap, we introduce a novel framework\nthat uses the Wasserstein distance and that exhibits efficiency in\nreconstructing general SDEs across a number of applications. Our\napproach offers a straightforward and efficient alternative relative\nto recent methods such as Wasserstein generative adversarial and MMD\nloss methods for SDE reconstruction.\n\nTo demonstrate its practical applicability we have used our new\nWasserstein-distance-based SDE reconstruction method to reconstruct\nSDEs from noisy trajectories arising in some biological and biophysics\nsettings. We present some of our preliminary results here https://drive.google.com/file/d/1HW5CBjx7g37DFx3s3A-sNDK0aoG6zqbT/view?usp=drive_link, with\nmore extensive results posted on arXiv soon. Given the novelty and\npotentially broad applicability of our method towards uncertainty\nquantification and analyzing time series data, we hope you will\nkindly reevaluate the revised manuscript\nand score it in light of our responses:\n\nW1. We have taken your comments into\nconsideration and made improvements to enhance the readability of our\npaper. Specifically, we have reorganized subsection 1.2, focusing on\nclearly presenting the structure of our paper and emphasizing the\nnovelty of our contributions. We believe that the roles of Theorem 1\nand Theorem 2 in the analysis and development of our\nWasserstein-distance SDE reconstruction method, along with key aspects\nof our numerical experiments, are now more clearly introduced. We hope\nthat our revisions could satisfactorily address your concern.\n\nW2.  In Appendix A, we provide a detailed proof of Theorem 1, outlining each\nintermediate step and the Cauchy inequalities employed to derive the\nerror bound. While the current form of Eq. (7) may not be the most\nelegant, it effectively communicates how the Wasserstein distance\n$W_2(\\mu, \\hat{\\mu})$ is bounded by multiples of the differences in\nthe drift and diffusion terms, $f-\\hat{f}$ and $\\sigma-\\hat{\\sigma}$,\nbetween two SDEs. Eq. (7) serves to illustrate the necessity of\nminimizing $W_2(\\mu, \\hat{\\mu})$ for SDE reconstruction, aiming to\nreduce the errors $f-\\hat{f}$ and $\\sigma-\\hat{\\sigma}$ between the\nground truth and reconstructed SDEs.\n\nWe acknowledge the potential for further refinement by imposing\ntighter inequalities in Appendix A to enhance the error bound.  What\nis more interesting and nontrivial is to extend the error bound\nEq. (7) to solutions between two multidimensional SDEs.  We are\ncurrently working on multidimensional SDEs but the analysis is\nnontrivial, as described in Remark 1.\n\nW3.  At the beginning of Section 3, we have written that training\ndetails for all examples such as the step-size, the number of samples,\nthe learning rate, etc, are given in Appendix E. The time-horizon is\ngiven separately in each example (Eqs. (18), (20), (21), (23))."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700109161674,
                "cdate": 1700109161674,
                "tmdate": 1700280122162,
                "mdate": 1700280122162,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zLcT10Grwn",
                "forum": "c0lGp17AjO",
                "replyto": "hBS4edaSzK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "W4. We appreciate your providing these\nreferences.  We were aware of some of these and had cited Reference\n[2] from your list in our manuscript. However, these previous works do\nnot directly address the specific task of approximating an SDE by\nanother SDE or SDE reconstruction. Moreover, the references you\nprovided primarily focus on the Wasserstein distance between solutions\nto the same SDE with different initial conditions or other specific\nscenarios, such as stochastic contraction and numerical solutions;\nthey do not directly address the SDE reconstruction problems that our\nproposed method aims to solve. We summarize them here:\n\n (1) Reference [1] analyzes the Wasserstein distance between\n  solutions to the same SDE with different initial conditions, which\n  is called stochastic contraction. It is not directly applicable to\n  approximating an SDE by another SDE.\n\n (2) Reference [2] studies the Wasserstein distance between solutions\n  to the same L\\'evy process \\& potential jumps with different initial\n  conditions as well as coupling. It is not directly applicable to\n  approximating an SDE by another SDE or SDE reconstruction problems\n  either.\n\n (3) Reference [3] investigates the Wasserstein distance between the\n  solution to an SDE and its Euler scheme approximation.  Yet, the results\n  cannot be directly applied \n  for SDE reconstruction, which requires analyzing the Wasserstein distance\n  between solutions to two SDEs.\n\n (4) Reference [4] studies the Wasserstein distance between the\n  solution to an ergodic SDE and its numerical solution. It mainly\n  discusses how to appropriately obtain the numerical solutions to\n  SDEs of some specific form.  This paper does not mention how to\n  reconstruction SDEs.  Yet, the Langevin equations it analyzes could\n  be helpful if we wish to apply the Wasserstein distance to construct\n  processes other then SDEs. We have cited this paper in our revised\n  literature review.\n\nIn our Appendix F, we also carried out a numerical experiment showing\nhow the uncertainty in the initial condition affects the\nreconstruction of an SDE. Of course, it would be helpful to carry out\nmore theoretical analysis on this, as was done in the references you\nkindly provided to us.\n\nAs you and Reviewer 4 suggest, there seems to be no simple method\nso far that exploits the Wasserstein distance for SDE\nreconstruction. Thus, our method is not only new but it also appears\nto be quite efficient in applications we explored. The most recent and\nrelated work that directly tackles general SDE reconstruction or using\none SDE to approximate another unknown SDE are the WGAN-SDE method and\nits extensions (Neural SDEs as infinite-dimensional GANs) and the MMD\nmethod (Generative moment matching networks). We compared our\nWasserstein-2-distance-based SDE reconstruction method with two\nmethods in Example 3 and found our method was more\nefficient and accurate. Furthermore, minimization of the Wasserstein-distance loss\nfunction (Eqs. 16, 17) used in our method is much easier to implement than\nthe aforementioned WGAN and MMD methods.\n\nQ1. The measures $\\mu, \\hat{\\mu}$ are two probability measures associated with\nthe entire infinite dimensional temporal trajectories $\\boldsymbol{X}(t), t\\in[0, T]$ and $\\hat{\\boldsymbol{X}}(t),  t\\in[0, T]$\nrather than specific probabilities for $\\boldsymbol{X}(t), \\hat{\\boldsymbol{X}}(t)$ at a fixed time point $t$. Therefore, we would not\nuse the notation $\\mu(t), \\hat{\\mu}(t)$.\nThe distance between two trajectories is thus defined as the temporal integration $\\lVert\\boldsymbol{X}\\rVert\\coloneqq\n\\big(\\int_0^T \\sum_{i=1}^d |X_i(t)|^2\\text{d} t\\big)^{\\frac{1}{2}}$. In this context, we can define \nthe Wasserstein-2 distance between the two measures $W_2(\\mu, \\hat{\\mu})$ as Eq. (5).\n\nQ2. In Examples 1 and 2, we compare our method with several classical uncertainty quantification (UQ) methods. \nWe find that the Wasserstein distance could indeed be better in reconstructing SDEs' trajectories and drift as well as diffusion terms than those classical UQ loss functions in statistics.\nIn Examples 3 and 4, for simplicity, we do not compare with those classical statistical UQ methods again. Instead, we focus on comparing with two most recent machine-learning-based SDE reconstruction methods (WGAN and MMD). We find that our method could also outperform these two methods in SDE reconstruction.\n\nWe hope that our responses satisfactorily address your questions and\nconcerns and that you will better appreciate the new\nWasserstein-distance-based SDE reconstruction method we have\ndeveloped."
                    },
                    "title": {
                        "value": "Rebuttal responses to Reviewer pb7V part II"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700109436948,
                "cdate": 1700109436948,
                "tmdate": 1700280156272,
                "mdate": 1700280156272,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rDaBLdjxL7",
                "forum": "c0lGp17AjO",
                "replyto": "hBS4edaSzK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer pb7V,\n\nWe are grateful for the time and expertise you dedicated to reviewing our paper. Your insightful feedback has been instrumental in guiding us to improve our work. We deeply value your support and guidance in this process.\nIn light of the changes and clarifications we have made in response to your comments, we would be immensely appreciative if you could take a moment to review our revisions. Your confirmation on whether our responses have adequately addressed your concerns would be greatly valued.\nThank you once again for your invaluable contribution and for sharing your expertise with us! We would greatly appreciate it if our revisions and changes warrant your reevaluation of our work.\n\nWith sincere gratitude,\n\nAuthors"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700542642119,
                "cdate": 1700542642119,
                "tmdate": 1700543292080,
                "mdate": 1700543292080,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BYafIzxC5s",
                "forum": "c0lGp17AjO",
                "replyto": "rDaBLdjxL7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Reviewer_pb7V"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Reviewer_pb7V"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their detailed response. Since my concerns are addressed, I am increasing the score."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700632295720,
                "cdate": 1700632295720,
                "tmdate": 1700632295720,
                "mdate": 1700632295720,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "JZq9JTHcKr",
            "forum": "c0lGp17AjO",
            "replyto": "c0lGp17AjO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission276/Reviewer_NdWD"
            ],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission276/Reviewer_NdWD"
            ],
            "content": {
                "comment": {
                    "value": "I thank the authors for their detailed answers to my concerns, in particular for clarifying the rotated 2-Wasserstein. I decided to raise my score to 6. Furthermore, I think the reconstruction of the 5-dimensional SDE model of circadian clocks, given in the rebuttal, highlights the proposed approach in a real data application. I encourage the authors to add this and the figure for the explanation of the rotation (given also in the rebuttal) to the appendices."
                }
            },
            "number": 20,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1700567221779,
            "cdate": 1700567221779,
            "tmdate": 1700567221779,
            "mdate": 1700567221779,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8TOlf1Evih",
                "forum": "c0lGp17AjO",
                "replyto": "JZq9JTHcKr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission276/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your suggestions! & Revisions based on your comments"
                    },
                    "comment": {
                        "value": "Dear Reviewer NdWD,\n\nWe really appreciate your feedback and your reevaluation! \n\nWe are grateful for your constructive suggestions. Based on your suggestions, we have added the figure for illustrating the rotated W2 distance in Appendix D as well as added a new appendix section (Appendix K) detailing the reconstruction of the 5D circadian SDE model. The 5D circadian SDE model is still our ongoing work and we will post more details of it along with the application of our novel W2 distance SDE reconstruction method into other biological problems on arXiv soon. Please see our updated manuscript for the revisions.\n\nExtracting SDEs from noisy time series data has been an important topic in uncertainty quantification for biological and physical applications. However, there exist very few methods for SDE reconstruction. Using the W2 distance as a loss function to reconstruct SDEs is quite easy to implement and easy to understand. Furthermore, it outperforms traditional methods and machine learning methods we have known so far (the WGAN-SDE and the MMD method) in both efficiency and accuracy. Thus, we believe that our proposed simple W2-distance-based loss functions for reconstructing SDEs could become a potential benchmark method in this specific SDE reconstruction field. We would greatly appreciate it if you found our work interesting and potentially useful.\n\nSincerely,\n\nAuthors"
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission276/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700679208385,
                "cdate": 1700679208385,
                "tmdate": 1700679208385,
                "mdate": 1700679208385,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]