[
    {
        "title": "AutoCast++: Enhancing World Event Prediction with Zero-shot Ranking-based Context Retrieval"
    },
    {
        "review": {
            "id": "ZcKP5GhjJo",
            "forum": "COYDmKkQH4",
            "replyto": "COYDmKkQH4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission459/Reviewer_vd8q"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission459/Reviewer_vd8q"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a zero-shot ranking-based retriever-reader model for event forecasting. The model can generate the effective answers by the proposed task-aligned retrieval module and enhanced neural article reader. Experimental results on a public dataset verify the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.The logic of the paper is sound.  \n2.The description of the methodology is relatively clear."
                },
                "weaknesses": {
                    "value": "1.The writing of the paper needs to be further improved and all the symbols need to be interpreted.  \n2.The work focuses on a single textual modality, so why mention multiple data sources, multiple modalities in the introduction section?  \n3.N_q is a subset of D. Why are the elements in N_q n and not d?  \n4.The dataset used is too small and results on more as well as larger datasets are needed to be validated."
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission459/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission459/Reviewer_vd8q",
                        "ICLR.cc/2024/Conference/Submission459/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission459/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697703989433,
            "cdate": 1697703989433,
            "tmdate": 1700728789283,
            "mdate": 1700728789283,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "W5EmIn5oEA",
                "forum": "COYDmKkQH4",
                "replyto": "ZcKP5GhjJo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission459/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission459/Authors"
                ],
                "content": {
                    "comment": {
                        "value": ">**Q1: The writing of the paper needs to be further improved and all the symbols need to be interpreted.** \n\nThank you for your comment. We have updated the notation explanations in the PDF to enhance clarity.\n\n>**Q2: The work focuses on a single textual modality, so why mention multiple data sources, multiple modalities in the introduction section?**\n\nThank you for your feedback. In response, we have adjusted our text to more explicitly state our objective of exploring data modalities that are more complex than traditional structured time-series data. The revised sentence is presented below for reference:\n\n*However, as the demand for more accurate forecasts in diverse domains has grown, the need to integrate data from **beyond the structured time-series modality** has become apparent.*\n\n\n>**Q3: N_q is a subset of D. Why are the elements in N_q n and not d?**\n\nThank you for pointing out this inconsistency. We have updated our notation to use $n$ instead of $d$ to represent each news article, with $n$ serving as an abbreviation for 'news'. Our text has been revised accordingly to reflect this change.\n\n>**Q4: The dataset used is too small and results on more as well as larger datasets are needed to be validated.**\n\nThank you for your feedback. The Autocast dataset [1] comprises approximately 5700 questions, including both training and testing sets. In comparison, the most similar dataset, ForecastQA [2], contains slightly over 10,000 questions in total. However, we contend that the quantity of questions should not be the primary criterion for assessing the actual scope of such datasets.\n\nWhile Autocast has fewer questions, it offers a significantly larger context retrieval space. ForecastQA's questions are limited to the time span from January 11, 2019, to November 12, 2019, all within the year 2019. In contrast, Autocast's questions span from 2016 to 2022, necessitating the retrieval and reader module to potentially handle more intricate information that encompasses greater long-term unpredictability.\n\nFurthermore, as highlighted in the Autocast paper [1], the closest benchmark dataset, ForecastQA, has certain limitations in its data. We quote from [1] as follows:\n\n> ForecastQA's questions were authored by crowdworkers without any forecasting experience. Consequently, these questions often lack coherence or clarity due to the absence of additional context, as exemplified by queries like \"To how many people will the Representative of an internet speak to by September 2019?\" or \"In July 2019, will an article say there were no volunteers in 2016?\"\n\nWe believe that exploring our methodology on additional datasets is a promising avenue for future research, and we are committed to pursuing this in our future work.\n\nRef:\\\n[1] Forecasting future world events with neural networks. NeurIPS 2022.\\\n[2] FORECASTQA: A Question Answering Challenge for Event Forecasting with Temporal Text Data. ACL 2021."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission459/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700629090573,
                "cdate": 1700629090573,
                "tmdate": 1700629090573,
                "mdate": 1700629090573,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LFbArFfhmz",
                "forum": "COYDmKkQH4",
                "replyto": "uqINce4Dzn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission459/Reviewer_vd8q"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission459/Reviewer_vd8q"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors' rebuttal"
                    },
                    "comment": {
                        "value": "Thanks to the authors for the detailed response. My confusions have been answered and I am willing to revise my rating to \"marginally above the acceptance threshold\"."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission459/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700728935639,
                "cdate": 1700728935639,
                "tmdate": 1700728935639,
                "mdate": 1700728935639,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "h15e7sIRvW",
            "forum": "COYDmKkQH4",
            "replyto": "COYDmKkQH4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission459/Reviewer_mh89"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission459/Reviewer_mh89"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces AutoCast++, an event prediction system designed to address forecasting questions by analyzing news documents. AutoCast++ comprises three key components: the Task-Aligned Retrieval Module, which re-ranks news documents based on relevance (using GPT-3 in a zero-shot manner) and recency; the Enhanced Neural Article Reader, which summarizes pertinent news content; and the Human-Aligned Loss Function, aligning system confidence with human forecaster accuracy. These components collectively led to improvements in addressing various forecasting question types in the AutoCast dataset, notably achieving a 48% enhancement in handling multiple-choice questions."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Ablation study is done to evaluate the effectiveness of different components of the system.\n\n- Their proposed system achieved 48% improvement on multiple choice forecasting questions, which is significant.\n\n- Even the smaller version of their proposed system (with 0.2 and 0.8 billion parameters) outperforms larger baselines (with 2.8 billion parameters)."
                },
                "weaknesses": {
                    "value": "- Limited reproducibility: The source code associated with the research paper is unavailable, so it is not possible to reproduce the results.\n\n- In ablation study, no specific experiment has been conducted to demonstrate the isolated effectiveness of the Alignment Loss component."
                },
                "questions": {
                    "value": "Please see the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission459/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698587483577,
            "cdate": 1698587483577,
            "tmdate": 1699635972091,
            "mdate": 1699635972091,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TmKIvYb2V0",
                "forum": "COYDmKkQH4",
                "replyto": "h15e7sIRvW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission459/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission459/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are thankful for the reviewer's valuable feedback.\n>**Q1. Limited reproducibility.**\n\nWe acknowledge the reviewer's concern regarding reproducibility. In our study, a significant finding is the contribution of pre-trained GPT-3 in enhancing event prediction by performing relevance re-ranking and text summarization. This is conducted on the original datasets that consist of prediction questions and a large number of news articles. During our implementation, these preliminary steps are executed before the training phase. We then save these enhanced retrieval results and integrate them into our dataloader for training the model. To achieve full reproducibility, it is indeed necessary to share the re-ranking results generated by GPT-3, which essentially constitute our modified training data. However, the substantial size of this data exceeds typical file size limitations. As a commitment to transparency and reproducibility, we plan to make these materials publicly available following the acceptance of our paper.\n\n>**Q2. The isolated effectiveness of the Alignment Loss component.**\n\nPlease kindly refer to Table 3 in our paper, where we present ablation studies focused on the impact of disabling the alignment loss in our model. \n\nAdditionally, in this rebuttal, we trained the FiD Static baseline with additional alignment loss. The summarized results of these experiments, specifically for the 0.2B model sizes, are detailed in the table below.\n\n| Model                             | Retriever (GPT)   | Retriever (non-GPT) | Reader (GPT)  | Reader (non-GPT)  | Reader (non-GPT) | T/F$\\\\uparrow$ | MCQ$\\\\uparrow$ | Num$\\\\downarrow$ |\n|-----------------------------------|-------------------|---------------------|---------------|-------------------|------------------|----------------|----------------|------------------|\n|                                   | Relevance Re-rank | Recency Re-rank     | Summarization | Numerical Binning | Alignment Loss   |                |                |                  |\n|             FiD Static            | No                | No                  | No            | No                | No               | 62.0           | 29.6           | 24.5             |\n|       FiD Static + alignment      | No                | No                  | No            | No                |          **Yes** | 62.5           | 31.2           | 23.5             |\n| FiD Static + GPT3| **Yes**           | No                  | **Yes**       | No                |               No | 65.5           | 42.1           | 21.3             |\n| Autocast++ without alignment loss | Yes               | Yes                 | Yes           | Yes               | **No**           | 66.7           | 43.5           | 19.9             |\n| Autocast++ (ours)                 | Yes               | Yes                 | Yes           | Yes               | Yes              | 66.7           | 43.8           | 19.8             |\n\nThis alignment loss is beneficial for the plain FiD Static baseline, which lacks any LLM-enhanced components. However, in the full Autocast++ model, where relevance re-ranking and text summarization are employed, the alignment loss appears to have a diminished role in enhancing performance.\n\nIn our additional experiment `FiD Static + GPT3`, we demonstrate that the baseline performance can be significantly enhanced by using the pretrained GPT3-enabled techniques. We acknowledge that the effect of alignment loss is relatively minor when compared to using pretrained LLM in the retriever and reader."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission459/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700629085805,
                "cdate": 1700629085805,
                "tmdate": 1700629403646,
                "mdate": 1700629403646,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "xm3mXRDzCn",
            "forum": "COYDmKkQH4",
            "replyto": "COYDmKkQH4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission459/Reviewer_KQUb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission459/Reviewer_KQUb"
            ],
            "content": {
                "summary": {
                    "value": "The authors present AutoCast++, a system for world event prediction relying on three components: a task-aligned retrieval module; a news summarisation module (text summarisation on retrieved news); a fusion-in-decoder model that is aligned to perform the event predictions.\nThey evaluate the system on the AutoCast dataset by grouping the tasks in numerical, multiple choice and true/false; considering as baselines a collection of methodologies suggested by the benchmark.\nThe results show that the proposed system is able to outperform the considered baselines considering different model sizes."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The proposed system shows remarkable performance presenting a limited impact from the model size.\nThe only tasks where it does not excel are the numerical ones, but it's anyway a close call with a baseline that is almost two times larger."
                },
                "weaknesses": {
                    "value": "While the exclusion of baselines relying on new LLMs including data post mid 2021 is understandable, the ablation studies seem to suggest that relying on LLM for retrieval reranking and summarisation play a huge role in the performance of the system.\nWhat would be convincing is to build/revamp the baselines considered using the GPT3 pre-trained version that the authors leverage in their experiments.\nThis would surely make the submission much stronger and convincing."
                },
                "questions": {
                    "value": "Which GPT3 version was considered in the work?\nWhat is the impact of binning numerical questions? Is the binning applicable also to the baselines? If yes how would results change?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Discrimination / bias / fairness concerns",
                        "Yes, Privacy, security and safety"
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "Relying on LLM-powered systems for world event forecasting using a pre-trained model with no safeguards can be very dangerous in practice. It would be useful to have this discussed in the paper."
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission459/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission459/Reviewer_KQUb",
                        "ICLR.cc/2024/Conference/Submission459/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission459/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698768681490,
            "cdate": 1698768681490,
            "tmdate": 1700644526161,
            "mdate": 1700644526161,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "beqrjiduZV",
                "forum": "COYDmKkQH4",
                "replyto": "xm3mXRDzCn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission459/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission459/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are grateful for the insightful feedback provided by the reviewer. Below, we address the reviewer's queries and have also updated our manuscript accordingly, with the changes highlighted in blue in the PDF.\n\n>**Q1: revamp the baselines considered using the GPT3.**\n\nWe have expanded our experimental results to include the FiD Static (0.2B model size) baseline, now enhanced with retrieval re-ranking and summarization using GPT-3.\n\n| Model                         | Retriever (GPT)   | Retriever (non-GPT) | Reader (GPT)  | Reader (non-GPT)  | Reader (non-GPT) | T/F$\\\\uparrow$ | MCQ$\\\\uparrow$ | Num$\\\\downarrow$ |\n|-------------------------------|-------------------|---------------------|---------------|-------------------|------------------|----------------|----------------|------------------|\n|                               | Relevance Re-rank | Recency Re-rank     | Summarization | Numerical Binning | Alignment Loss   |                |                |                  |\n|           FiD Static          | No                | No                  | No            | No                | No               | 62.0           | 29.6           | 24.5             |\n| FiD Static + GPT3| **Yes**           | No                  | **Yes**       | No                |               No | 65.5           | 42.1           | 21.3             |\n| Autocast++             | **Yes**           | Yes                 | **Yes**       | Yes               | Yes              | 66.7           | 43.8           | 19.8             |\n\nOur findings demonstrate a notable improvement in the FiD Static model when incorporating GPT-3 enhancements in the retriever and reader stages. With these enhancements, the FiD Static baseline now exhibits performance much closer to our model.\n\nIt's important to note that the UnifiedQA and T5 baselines are not reliant on retrieval processes (as they do not utilize context from news articles), and thus, are not impacted by this modification. \n\nRegarding the FiD Temporal baseline, it uniquely utilizes daily news articles as context. Given that the average question in the Autocast dataset spans approximately 130 days, this would necessitate processing a volume of articles about 130 times greater than our current setup using the pretrained GPT-3. While this presents an intriguing direction for future research, it was beyond our capacity to fully explore within the limited time frame allocated for this rebuttal.\n\n>**Q2: Which GPT3 version was considered in the work?**\n\nIn our experiments, we utilized the gpt-3.5-turbo-0613 API version of GPT-3.\n\n>**Q3: impact of binning numerical questions and results on the baselines?**\n\nOur approach is based on the T5 transformer model [2], and this enables the easy integration of our numerical question binning method with the FiD Static baseline, which is also based on T5. We conducted comparative ablation studies regarding the binning on both the FiD Static and our Autocast++ models, each with a 0.2B model size.\n\n| Model                         | Retriever (GPT)   | Retriever (non-GPT) | Reader (GPT)  | Reader (non-GPT)  | Reader (non-GPT) | T/F$\\\\uparrow$ | MCQ$\\\\uparrow$ | Num$\\\\downarrow$ |\n|-------------------------------|-------------------|---------------------|---------------|-------------------|------------------|----------------|----------------|------------------|\n|                               | Relevance Re-rank | Recency Re-rank     | Summarization | Numerical Binning | Alignment Loss   |                |                |                  |\n|           FiD Static          | No                | No                  | No            | No                | No               | 62.0           | 29.6           | 24.5             |\n|      FiD Static + Binning     | No                | No                  | No            | **Yes**           | No               | 62.1           | 29.6           | 23.2             |\n| Autocast++ without binning    | Yes           | Yes                 | Yes       | **No**                | Yes              | 66.7           | 43.6           | 21.0             |\n| Autocast++ (ours)             | Yes           | Yes                 | Yes       | **Yes**               | Yes              | 66.7           | 43.8           | 19.8             |\n\nThis modification transforms the numerical question prediction from a regression task to a classification one, aligning it with the loss used for T/F and MCQ. Our empirical findings show that this adjustment consistently enhances the accuracy of numerical predictions and does not significantly impact T/F and MCQ performance.\n\nRef:\\\n[1] Forecasting future world events with neural networks. NeurIPS 2022.\\\n[2] Exploring the limits of transfer learning with a unified text-to-text transformer. JMLR 2020."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission459/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700629080986,
                "cdate": 1700629080986,
                "tmdate": 1700629080986,
                "mdate": 1700629080986,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uIZchnDRYc",
                "forum": "COYDmKkQH4",
                "replyto": "beqrjiduZV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission459/Reviewer_KQUb"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission459/Reviewer_KQUb"
                ],
                "content": {
                    "title": {
                        "value": "Response to author rebuttal"
                    },
                    "comment": {
                        "value": "I would like to thank the authors for addressing most of my comments and conducting experiements that I believe are improving the quality and the soundness of their work.\nThe experiments show that the framework presented is outperforming the baselines even when equipped with components that are making them more competitive with the presented approach.\nThe only part that I believe deserves to be tackled in an accepted submission is the concerns with the respect to ethics and security and potential strategies to have guardrails in place when predicting events.\nI'm happy to update my score based on the authors' response."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission459/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700644489855,
                "cdate": 1700644489855,
                "tmdate": 1700644489855,
                "mdate": 1700644489855,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]