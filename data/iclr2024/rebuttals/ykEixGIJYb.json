[
    {
        "title": "Incentivized Truthful Communication for Federated Bandits"
    },
    {
        "review": {
            "id": "quekXUhdk1",
            "forum": "ykEixGIJYb",
            "replyto": "ykEixGIJYb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5786/Reviewer_Jfq6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5786/Reviewer_Jfq6"
            ],
            "content": {
                "summary": {
                    "value": "This paper extends the recent work on incentivized linear federated bandits (Wei et al. 2023) to one where the clients\u2019 communication costs are unknown, and the server must devise a mechanism for payments that is incentive-compatible. The authors use ideas from mechanism design to design such a scheme while keeping the total payments small."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Novel setting that combines multi-armed bandits with mechanism design \n- Theoretical results seem correct and non-trivial \n- I appreciate the numerical simulations that were conducted to corroborate theory"
                },
                "weaknesses": {
                    "value": "I find the main weakness of this paper to be the model. It is a very complex model that combines many different aspects (linear bandits, multiple clients, communication cost, incentivizing payments, truthfulness). The paper did not provide any motivating application for studying this complex model.\n\nRegarding the motivation for the model, one of my main points of confusion is in how the reward/regret of the bandit algorithm can be compared to the incentive payment paid out by the server. Relatedly, what incentive does the server have, to pay the clients (out of pocket) to get them to participate? From my understanding, it is each client that is performing some action, and hence it is in the client\u2019s best interest that the bandit algorithm chooses the best actions. Now, federated learning will improve the learning algorithm since more data is collected, so it is in the agent\u2019s best interest to participate in federated learning. If the \u201ccommunication cost\u201d is higher than the benefits of participating in federated learning, then the agent can simply choose not to participate. In this paper, the server will pay such a client to participate - but what benefit does the server get when the agent participates? What if the true \u201ccommunication costs\u201d are exorbitant (e.g. $1M per communication)? The algorithm in this paper still makes the server pay, regardless of the scale of these costs. \n\nIf one is considering the problem in this paper purely for theoretical interest, the fact that the model was so complex makes it difficult to identify how the results contribute to the theory of multi-armed bandits. Most of the paper was about mechanism design, but it took a long time for me to understand the underlying federated linear bandit model - and it wasn\u2019t clear to me which parts of the underlying bandit model were crucial and which were not."
                },
                "questions": {
                    "value": "- A client\u2019s utility, $u_{it}$ was not defined, so truthfulness (definition 1) is not well defined. Does a client\u2019s utility involve both the regret as well as the payment? If so, how are these combined?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5786/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5786/Reviewer_Jfq6",
                        "ICLR.cc/2024/Conference/Submission5786/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5786/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698326525050,
            "cdate": 1698326525050,
            "tmdate": 1700662427063,
            "mdate": 1700662427063,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "zkHZsXwAwf",
                "forum": "ykEixGIJYb",
                "replyto": "quekXUhdk1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Jfq6 [Part 1/2]"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the constructive comments. First of all, we would like to make a fundamental clarification on the misunderstanding on the objective of **federated bandt learning**, which has caused the reviewer\u2019s most confusions about the motivation (Q1), model behavior (Q2), and our contribution (Q3) in the context of federated bandit learning.\n\nAs detailed in the general responses [CA1, CA2], in this line of research, the server\u2019s goal is **NOT** to game or bargain with the clients. **Instead, it is the server\u2019s desire/duty to minimize the overall regret across all clients, as achieving a near-optimal regret is in its best interest**. Imagine a distributed recommender system, where the central server\u2019s goal is to make sure all clients\u2019 recommendation quality is satisfactory. Using the reviewer\u2019s language in Q2, the lower the overall regrets are, the higher the \"incentives\" for the server. Moreover, we note that the main research interest and challenge in \u201cincentivized federated bandits\u201d lies in incentive mechanism design, as explained in [CA3]. A detailed discussion of our contribution to the theory of bandit learning is presented in [CA4].\n\nPlease let us know if you have any further questions, and we are more than happy to incorporate any additional suggestions that could further enhance our work and lead to a more favorable evaluation of our work.\n\n\n\n**[Q1]**: The paper did not provide any motivating application for studying this complex model. \n\n**[A1]**: The line of research on federated bandit learning has been motivated by many real-world sequential decision applications where recommender systems is a representative one. For instance, a recommendation platform (server) wants its mobile app users (clients) to opt in its new recommendation service, which switches previous on-device local bandit algorithm to a federated bandit algorithm. Although the new service is expected to improve the overall recommendation quality for all clients (minimizing the overall regret), particular clients may not be willing to participate in this collaborative learning, as the expected gain for them might not compensate their locally increased cost (e.g., communication bandwidth, added computation, lost control of their data, and etc). \n\nTherefore, a proper incentive mechanism is required to facilitate the federated learning process, as explained in [CA3]. Following this direction, our work focuses on a more realistic scenario that aims to design a truthful incentive mechanism, ensuring clients won't exploit the server\u2019s commitment by misreporting their data sharing cost.\n\n**[Q2]**: How can the reward/regret of the bandit algorithm be compared to the incentive payment paid out by the server. Relatedly, what incentive does the server have, to pay the clients (out of pocket) to get them to participate? What benefit does the server get when the agent participates? What if the true \u201ccommunication costs\u201d are exorbitant (e.g. $1M per communication)? The algorithm in this paper still makes the server pay, regardless of the scale of these costs. \n\n**[A2]**: As explained in [A1], the server is obligated to reduce regret for all clients. **Therefore, the server\u2019s goal is not to trade off between regret and incentive payment, but to motivate client\u2019s participation for nearly optimal regret**. Note that this obligated server is practical in many real-world scenarios (e.g., distributed users/edge devices on a shared learning platform, different departments within the same company, etc.), where the server/platform/company's best interest is to improve the overall learning across all clients.\n\nWith that being said, since Wei et al. (2023) recently opened up an interesting direction in this line of research, we absolutely agree that exploring the non-obligated server setting is a timely and important future work. The interactions between the server and clients can be modeled variously according to real-world applications. For instance, in addition to incentivizing clients for participation, the server can even charge some clients for receiving data from the server."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700203528777,
                "cdate": 1700203528777,
                "tmdate": 1700203528777,
                "mdate": 1700203528777,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "c6ypLRMoOB",
                "forum": "ykEixGIJYb",
                "replyto": "quekXUhdk1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Jfq6 [Part 2/2]"
                    },
                    "comment": {
                        "value": "**[Q3]**: If one is considering the problem in this paper purely for theoretical interest, the fact that the model was so complex makes it difficult to identify how the results contribute to the theory of multi-armed bandits. Most of the paper was about mechanism design, but it took a long time for me to understand the underlying federated linear bandit model - and it wasn\u2019t clear to me which parts of the underlying bandit model were crucial and which were not.\n\n**[A3]**: Thanks for pointing out the place that could lead to unnecessary confusion. We have provided a detailed discussion on the basics objectives and challenges of federated bandits learning in [CA2].\n\nTypically, the communication scheme (i.e., arm selection strategy, communication event trigger) is a crucial part for federated bandit learning. **However, in the context of incentivized federated bandits, the main interest is on designing the incentive mechanism**, and both Wei et al (2023) [R1] and our work adopt the standard communication scheme, as we explained in [CA3].\n\nFor a detailed discussion of our contribution to the theory of bandit learning, please refer to our response in [CA4].\n\n**[Q4]**: A client\u2019s utility $u_{i,t}$,  was not defined, so truthfulness (definition 1) is not well defined. Does a client\u2019s utility involve both the regret as well as the payment? If so, how are these combined?\n\n**[A4]**: Following Wei et al. (2023) [R1], our problem considers \u201cindividual rational\u201d clients, meaning that client $i$ only participates in data sharing if the incentive mechanism provides a non-negative utility (see Definition 1 of Individual Rationality in [R1]), where utility is defined as the difference between incentive and true cost of client $i$ , i.e., $u_{i,t} = \\mathcal I_{i,t} - D_{i,t}$, as is standard in economic analysis [R2]. We have made this notation clearer in our revised manuscript (Section 3).\n\nNonetheless, we agree that it is also an interesting alternative to include the regret-related term as a factor in the client\u2019s utility design. And we\u2019d like to share some thoughts on it:\n- Under the obligated server setting, the server will help every client regardless of whether the clients share their local data or not. As the server always guarantees a nearly optimal regret in each communication round, thus there is no significant difference in such a regret-related utility term across all clients, as everyone can utilize the same amount of aggregated data shared by the server for regret reduction. Therefore, it is less meaningful to take the regret-related term in the utility design. \n- In contrast, for the non-obligated server setting, each client may receive different subsets of the aggregated data and thus obtain different levels of regret reduction. In this case, it becomes more reasonable to include the regret-related term in the utility design, which we believe is an interesting direction to explore combined with the non-obligated setting, as we discussed in [A2].\n\n**References**\n\n[R1]. Zhepei Wei, Chuanhao Li, Haifeng Xu, and Hongning Wang. Incentivized Communication for Federated Bandits. NeurIPS 2023.\n\n[R2]. Roger B Myerson and Mark A Satterthwaite. Efficient mechanisms for bilateral trading. Journal of economic theory, 29(2):265\u2013281, 1983."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700203753792,
                "cdate": 1700203753792,
                "tmdate": 1700245370412,
                "mdate": 1700245370412,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QVV5ZrNxOq",
                "forum": "ykEixGIJYb",
                "replyto": "c6ypLRMoOB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_Jfq6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_Jfq6"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you to the authors for the detailed answers. The questions I asked in my review have been clarified. I am still not convinced that this is a practical setting - in the recommendation platform example, is it actually practical that a platform pays its user for each communication round, and it pays each user differently according to their true costs? I don't mean to nitpick on this point, but I still think of this setting as mainly driven by theoretical interest. I also agree with reviewer 1gFC that the exposition of the paper is poor (which was the source of all of my questions/confusion) and hence the paper should be significantly re-written for clarity. I will maintain my score."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700500402019,
                "cdate": 1700500402019,
                "tmdate": 1700500402019,
                "mdate": 1700500402019,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MdsvUAWzr9",
                "forum": "ykEixGIJYb",
                "replyto": "londXlPL1f",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_Jfq6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_Jfq6"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you to the authors again for the detailed responses. Though I still feel the exposition can be improved, I acknowledge the space constraints as well as the existing literature on federated bandits. I have increased my score."
                    }
                },
                "number": 38,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700662409724,
                "cdate": 1700662409724,
                "tmdate": 1700662409724,
                "mdate": 1700662409724,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "q6BiaW5yKs",
            "forum": "ykEixGIJYb",
            "replyto": "ykEixGIJYb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5786/Reviewer_3EFN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5786/Reviewer_3EFN"
            ],
            "content": {
                "summary": {
                    "value": "The work builds on, as an extension of Wei et al. (2023), to incentivize the truthful participation of clients to improve overall utility for each client. The authors show the developed communication protocol TRUTH-FEDBAN enjoys near-optimal theoretical guarantees on regret and communication costs."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This work presents a mechanism design to ensure the truthful participation of clients, where the client's only beneficial strategy is to share their true costs in a federated bandit learning setting. The incentive-compatible communication protocol offers near-optimal theoretical guarantees on regret and communication costs. Numerical evaluations validate the method's efficacy."
                },
                "weaknesses": {
                    "value": "1. I am a bit unsure of the contribution and the motivation for the developed solution of this work, particularly considering how this work is built (as an extension) on Wei et al. (2023); hence, the claim for making this work a first attempt in mechanism design for federated bandit learning seems incorrect? Also, for the method developed, several recent works on federated settings, such as FL, tackle such issues for truthful and fair participation, employing economic tools. Contract Theory-based methods or Auction-based methods have been \"extensively\" employed in mechanism design for truthful interaction between the clients and the server. For instance, [R1, R2]. \n\n[R1] Karimireddy, Sai Praneeth, Wenshuo Guo, and Michael I. Jordan. \"Mechanisms that incentivize data sharing in federated learning.\" arXiv preprint arXiv:2207.04557 (2022).\n[R1] T. H. Thi Le et al., \"An Incentive Mechanism for Federated Learning in Wireless Cellular Networks: An Auction Approach,\" in IEEE Transactions on Wireless Communications, vol. 20, no. 8, pp. 4874-4887, Aug. 2021, doi: 10.1109/TWC.2021.3062708\n\nIn that reference, I am not sure relaxing the data sharing cost with a valuation function, commonly used in standard economic analysis, is a sufficient contribution to this work. Can you explain more about the missing guarantees on the social cost of Wei et al. (2023)? Later, after Def. 2, you mentioned the definition of social cost in this work is different than theirs.\n\n2. Following my earlier comment, the setup and the interaction procedure is unclear to establish the contribution, again, as compared to Wei et. al., 2023. The preliminary model is not rigorous to that end. For instance, what exactly is pulling the arm characterised in Section 3 in a federated bandit setting? How to interpret y_t following it? what is w in footnote 1? and so on. This can be significantly improved.\n\n3. Can the authors support the claim that \"more frequent communication leads to lower regret\"? (and the line that follows in pg. 3) It is understandable in terms of the communication overhead, but this is also the fact that you gain in training efficiency. This leads back to my earlier confusion regarding how \"regret\" is quantified.\n\n4. Is the critical value defined in Def. 4 unique?\n5. I must admit the proof of monotonicity has not been conveyed clearly in its current form; can you provide a discussion on this?\n6. Simulations:\n- The methods build on Wei et. al. 2023 but didn't use it as a baseline.\n- What about the time-complexity analysis and the overall learning performance following the proposed approach? Also, how well the method scales.\n- The general setup with \"sequential interaction\" is limiting in itself, in my understanding."
                },
                "questions": {
                    "value": "Please consider the questions raised in the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5786/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5786/Reviewer_3EFN",
                        "ICLR.cc/2024/Conference/Submission5786/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5786/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698595340835,
            "cdate": 1698595340835,
            "tmdate": 1700637894762,
            "mdate": 1700637894762,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VDcft6J7pi",
                "forum": "ykEixGIJYb",
                "replyto": "q6BiaW5yKs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 3EFN [Part 1/3]"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the constructive comments. **Unfortunately, it appears that there are some critical confusions regarding our studied problem (e.g., as in [Q2, Q5, Q10]), thus leading to a misunderstanding of our contribution (e.g., as in [Q1, Q4])**. We should first clarify that our focus is on incentive mechanism design for **federated bandit learning**, where \u201csequential interaction\u201d features the core nature of this online learning problem, as opposed to the general federated learning that operates on a fixed offline dataset. Please refer to our general response [CA1] for detailed clarification on this. Moreover, the standard communication scheme (discussed in [CA3]) used in our work is **NOT** our claimed contribution. Please see a detailed discussion on our contribution in [CA4].\n\nPlease let us know if you have any further questions, and we are more than happy to incorporate any additional suggestions that could further enhance our work and lead to a more favorable evaluation of our work.\n\n**[Q1]**: I am a bit unsure of the contribution and the motivation for the developed solution of this work, particularly considering how this work is built (as an extension) on Wei et al. (2023); hence, the claim for making this work a first attempt in mechanism design for federated bandit learning seems incorrect? \n\n**[A1]**: Thanks for pointing out the place that could lead to unnecessary confusions. The truthfulness guarantee is a crucial property in mechanism design, especially in the context of **federated bandit learning** (see definition in [CA1]). Motivated by this practical demand, our work provides the first solution that simultaneously ensures both truthfulness and nearly optimal learning performance. Please also refer to the motivating example in our response to [Q1 of Reviewer Jfq6].\n\nWe acknowledge that Wei et al. (2023) [R6] is the first work to investigate mechanism design in the incentivized federated bandits. Indeed, in our introduction section, we only claim to present \"**the first incentive-compatible (i.e., truthful)** communication protocol\", signifying that our work is the first solution to achieve nearly optimal performance without relying on the truthfulness assumption in the incentivized federated bandit problem.\n\nPlease refer to our general responses for a detailed comparison on the commonality (i.e., using the same communication scheme, see [CA3]) and differences (i.e., our unique contribution, see [CA4]).\n\n**[Q2]**: Also, for the method developed, several recent works on federated settings, such as FL, tackle such issues for truthful and fair participation, employing economic tools. Contract Theory-based methods or Auction-based methods have been \"extensively\" employed in mechanism design for truthful interaction between the clients and the server. For instance, [R1, R2]. In that reference, I am not sure relaxing the data sharing cost with a valuation function, commonly used in standard economic analysis, is a sufficient contribution to this work.\n\n**[A2]**: Thanks for bringing up the related works. Indeed, there has been growing research effort in exploring incentivized data sharing protocols in federated learning [R3, R4]. However, most of them, including [R1, R2], only focused on the supervised offline learning setting. **As we discussed in [CA1], none of these solutions can be applied to the federated bandit learning problem**. Wei et al. (2023) [R6] is the only notable exception, but however, it still relies on the unrealistic truthfulness assumption as we explained above. For a detailed discussion on the contributions of our work, please refer to our response [CA4].\n\nRegarding the relaxation on data sharing cost $D_{i,t} = f(\\Delta V_{i,t})$, we would like to clarify that the intended purpose is to generalize our solution to any form of data sharing cost, rather than restricting it to a constant value as in Wei et al. (2023) [R6]. In fact, none of our analysis relies on the specific form of $D_{i,t} = f(\\Delta V_{i,t})$ - all that matters is that client $i$ has  value $D_{i,t}$ for its data at time step $t$, and we do not impose any conditions on the function $f$. Please see also our response to [Q3 of Reviewer 1gFC] for further clarification on this aspect."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700201725909,
                "cdate": 1700201725909,
                "tmdate": 1700201725909,
                "mdate": 1700201725909,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "eUKArydvhZ",
                "forum": "ykEixGIJYb",
                "replyto": "q6BiaW5yKs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 3EFN [Part 2/3]"
                    },
                    "comment": {
                        "value": "**[Q3]**:  Can you explain more about the missing guarantees on the social cost of Wei et al. (2023)? Later, after Def. 2, you mentioned the definition of social cost in this work is different than theirs. \n\n**[A3]**: In the remarks following Definition 2, we stated that the social cost defined in our work is different from the incentive cost studied in Wei et al. (2023) [R6]. Specifically,\n- **Social Cost**: the total actual costs incurred by all participating clients in the incentivized client set $S_t$, i.e., $\\sum_{i \\in S_t} D_{i,t}$.\n- **Incentive Cost**: the total payment (monetary incentive) the server made to all participating clients in the incentivized client set $S_t$, i.e., $\\sum_{i \\in S_t} \\mathcal I_{i,t}$.\n\nAs truthfulness is assumed in their setting, the server simply pays the participating client\u2019s claimed cost, i.e., $\\mathcal I_{i,t} = D_{i,t}$. In contrast, we do not assume truthfulness in our setting. To ensure truthfulness, the server needs to pay the calculated critical value to the participating client, which is guaranteed to be no less than their true cost (see Theorem 8), i.e., $\\mathcal I_{i,t} \\geq D_{i,t}$. Therefore, in our setting, these two costs are completely different concepts.\n\nRegarding the missing guarantee on the social cost in Wei et al. (2023) [R6], even under the truthfulness assumption, their proposed incentive mechanism (Algorithm 3 in their paper) only satisfies the constraint of the optimization problem defined in Eq. (1), while providing no guarantee on the objective. **In other words, their method aims solely to find a feasible set of clients to collect data so as to achieve near-optimal regret, without ensuring the optimality of cost from the selected set** -  ideally, the optimal set should satisfy the constraint while yielding the lowest social cost.\n\n**[Q4]**: Following my earlier comment, the setup and the interaction procedure is unclear to establish the contribution, again, as compared to Wei et. al., 2023. The preliminary model is not rigorous to that end. For instance, what exactly is pulling the arm characterised in Section 3 in a federated bandit setting? How to interpret y_t following it? what is w in footnote 1? \n\n**[A4]**: In the context of federated bandits (introduced in Section 3 of our paper), there are $N$ clients interacting with the environment to learn the unknown parameter, coordinated by a central server. At each time step $t$, an arbitrary client becomes active to pull an arm $x_t$, and receives the corresponding reward $y_t$ from the environment. A vivid illustration of the interaction procedure can be found in Figure 1(a) of [R5].\n\nAs is standard in federated bandit learning, we use the upper confidence bound (UCB)-based arm selection strategy to guide the client\u2019s interaction with the environment, where the collected data $(x_t, y_t)$ is used for model estimation, as detailed in [CA2]. Regarding the communication scheme between the server and clients under the incentivized setting, please see our response [CA3].\n\nThe notation $w$ in footnote 1 represents how much client $i$ weighs its data collection cost $\\det(\\Delta V_{i,t})$ in its data-sharing cost function $D_{i,t} = f(\\Delta V_{i,t})$. However, as we clarified in [A2] and in our response to Q3 of Reviewer 1gFC, the specific form is trivial and will be removed from our final version to avoid further confusion.\n\n**[Q5]**: Can the authors support the claim that \"more frequent communication leads to lower regret\"? (and the line that follows in pg. 3). It is understandable in terms of the communication overhead, but this is also the fact that you gain in training efficiency. This leads back to my earlier confusion regarding how \"regret\" is quantified.\n\n**[A5]**: As in line with the established common ground and convention of this line of research, our claim that \"more frequent communication leads to lower regret\" and the definition of \u201cregret\u201d are the standard consensus/terminology shared by federated bandits literature. Please refer to our response [CA2] for a detailed clarification.\n\n**[Q6]**: Is the critical value defined in Def. 4 unique?\n\n**[A6]**: Yes. Suppose $c_{i,t}^{1}$ and $c_{i,t}^{2}$ are two distinct critical values for client $i$ at time step $t$. When client $i$ claims its data sharing cost as $\\widehat D_{i,t} = (c_{i,t}^{1} + c_{i,t}^{2}) / 2$, then client $i \\in S_t$ and $i \\notin S_t$ will simultaneously hold true according to Definition 4, which is clearly a contradiction. Therefore, by Definition 4, the critical value for each client $i$ is unique."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700202405106,
                "cdate": 1700202405106,
                "tmdate": 1700203159095,
                "mdate": 1700203159095,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QXCrz1WWny",
                "forum": "ykEixGIJYb",
                "replyto": "q6BiaW5yKs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 3EFN [Part 3/3]"
                    },
                    "comment": {
                        "value": "**[Q7]**: I must admit the proof of monotonicity has not been conveyed clearly in its current form; can you provide a discussion on this?\n\n**[A7]**: As defined in Definition 3, Algorithm 1 is monotone if for any selected participating client $i$ with a reported data sharing cost $\\widehat D_{i,t}$, it will remain selected by Algorithm 1 whenever it reports a lower value, i.e., $\\widehat D^\\prime_{i,t} \\leq \\widehat D_{i,t}$.\n\nNote that Algorithm 1 searches for the participating set $S_t$ by starting from a minimal budget (Line 2) and repeatedly increases the budget (Line 4) until the resulting client set found by Algorithm 2 satisfies the specified condition (Line 3). Therefore, decreasing a client's reported cost $\\widehat D_{i,t} \\rightarrow \\widehat D^\\prime_{i,t}$ can cause a different output by Algorithm 2 and, consequently, terminate the search process of Algorithm 1 at a different budget $b \\rightarrow b'$ with a potentially different selection of the participant set ${S_t} \\rightarrow {S^\\prime_t}$.\n\n**As a result, to prove monotonicity, we need to show that given $i \\in S_t$ when client $i$ reports $\\widehat D_{i,t}$, the proposition $i \\in S^\\prime_t$ always holds true when $\\widehat D^\\prime_{i,t} \\leq \\widehat D_{i,t}$**. This is done by demonstrating that the resulting objective value $g_t({S_t})$ from Algorithm 2 is non-decreasing with respect to its input budget $b$, as we proved in Lemma 12. In other words, it becomes impossible for $b' > b$ because otherwise the search process in Algorithm 1 would have stopped at $b$. Since decreasing client $i$'s claimed cost will increase its chance of getting selected by Algorithm 2 (Line 3), we can show that $i \\in S'_t$ always holds true for all $b' \\leq b$, as explained in Appendix A. This finishes the proof.\n\n**[Q8]**: The methods build on Wei et. al. 2023 but didn't use it as a baseline in simulation\n\n**[A8]**: We have to clarify that despite achieving the same results on regret and communication cost, our incentive mechanism is completely different from that of Wei et al. (2023) [R6], and **these two are not comparable as their method builds on the truthfulness assumption, which is absent in our setting**. Please find a detailed comparison in our general response [CA4].\n\n**[Q9]**: What about the time-complexity analysis and the overall learning performance following the proposed approach? Also, how well the method scales.\n\n**[A9]**: As detailed in the response to [Q4 of Reviewer 1gFC], the proposed method holds a polynomial time complexity of $O\\left(\\left\\lceil \\log_{1+\\epsilon}\\left(\\sum_{i=1}^{N} \\frac{\\widehat{D}{i,t}}{b_0}\\right)\\right \\rceil \\cdot N^2\\right)$, where $b_0 = \\min_{i \\in \\widetilde S} \\widehat D_{i,t}$, scaling quadratically with the number of clients $N$.\n\nOur method archives nearly-optimal overall learning performance with $O(d\\sqrt{T} \\log T)$ regret and $O(N^{2} d^3\\log T)$ communication cost, which is confirmed by our empirical study in Section 5. For example, as Figure 1(a) shows, the regret curve of our proposed method converges after ~1000 iterations, indicating that the algorithm already learned an accurate estimation of the unknown parameter and can consistently choose the best arm, thus incurring no regret.\n\n**[Q10]**: The general setup with \"sequential interaction\" is limiting in itself, in my understanding.\n\n**[A10]** : We should clarify that our studied problem is **federated bandit learning**, which is an important research field with a wide range of real-world applications featuring sequential decision-making processes, as discussed in [CA1]. Therefore, investigating the incentive design with this setup holds significant value both in research and practical applications.\n\n**References**\n\n\n[R1]. Karimireddy, Sai Praneeth, Wenshuo Guo, and Michael I. Jordan. \"Mechanisms that incentivize data sharing in federated learning.\" arXiv preprint arXiv:2207.04557 (2022). \n\n[R2]. T. H. Thi Le et al., \"An Incentive Mechanism for Federated Learning in Wireless Cellular Networks: An Auction Approach,\" in IEEE Transactions on Wireless Communications, vol. 20, no. 8, pp. 4874-4887, Aug. 2021, doi: 10.1109/TWC.2021.3062708\n\n[R3]. Jian Pei. A survey on data pricing: from economics to data science. IEEE Transactions on knowledge and Data Engineering, 34(10):4586\u20134608, 2020.\n\n[R4]. Xuezhen Tu, Kun Zhu, Nguyen Cong Luong, Dusit Niyato, Yang Zhang, and Juan Li. Incentive mechanisms for federated learning: From economic and game theoretic perspective. IEEE Transactions on Cognitive Communications and Networking, 2022.\n\n[R5]. Chuanhao Li, and Hongning Wang. Asynchronous Upper Confidence Bound Algorithms for Federated Linear Bandits. AISTATS 2022.\n\n[R6]. Zhepei Wei, Chuanhao Li, Haifeng Xu, and Hongning Wang. Incentivized Communication for Federated Bandits. NeurIPS 2023."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700203086338,
                "cdate": 1700203086338,
                "tmdate": 1700203116933,
                "mdate": 1700203116933,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "63glEB6j2v",
                "forum": "ykEixGIJYb",
                "replyto": "QXCrz1WWny",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_3EFN"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_3EFN"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks to the authors for a detailed response. I agree with some of the concerns raised by, particularly Reviewer 1gFC, and others regarding the contribution of this work compared to Wei et al. (2023) while acknowledging the distinction made by authors in [CA4]. It might be correct, the claim being the first one to simultaneously achieve IC and optimal regret in federated bandit learning (pls. note I am aware of the distinction between federated learning and federated bandit learning), but the authors should discuss several existing methods employing contract-theory/auction mechanism to enforce truthful participation in such a setting (collaborative learning/FL) to position their arguments better. This can be improved in my understanding. Further, following your responses, \n- the authors mentioned their method can generalize for any form of valuation function $f(\\cdot)$. Can the authors justify this claim? \n- you mentioned \"all the client's secret lies in $\\Delta b_{i,t}$\" and revealing $\\Delta V_{i,t}$ won't compromise the client's \"data privacy\". I believe this needs further discussion/clarification.\n- and I wonder, isn't this one of the limiting criteria that all clients need to participate and report $\\Delta V_{i,t}$?"
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700409482875,
                "cdate": 1700409482875,
                "tmdate": 1700409482875,
                "mdate": 1700409482875,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cdb08JONhp",
                "forum": "ykEixGIJYb",
                "replyto": "PC6euKfABb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_3EFN"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_3EFN"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their diligent efforts in clarifying potential confusion during the rebuttal period. The topic is certainly of great interest. While I have some reservations about the organization of the work (improvements required in positioning the problem, the interaction setting, and their contributions - as raised by other reviewers as well), most of my comments have been addressed. Following your revisions (incl. Table 1) and responses to the other reviewer's comments, I think the merit and contributions of this work stand out well; thus, I am raising my scores. All the best!"
                    }
                },
                "number": 34,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700637744094,
                "cdate": 1700637744094,
                "tmdate": 1700637744094,
                "mdate": 1700637744094,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "XkkO8FeGbm",
            "forum": "ykEixGIJYb",
            "replyto": "ykEixGIJYb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5786/Reviewer_ihns"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5786/Reviewer_ihns"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies a federated learning problem with N strategic, individually rational agents that repeatedly interact with an environment over T rounds to receive rewards. Every agent faces the same environment characterized by a common latent parameter and stochastic rewards that are linear in the action with additive zero mean sub-Gaussian noise. Each agent wants to minimize her regret over the T rounds of interaction, subject to communication costs. The authors propose a truthful mechanism that incentivizes agents via payments (by a central server) to communicate and report their true participation costs, and simultaneously guarantees $\\tilde{\\mathcal{O}}\\left( \\sqrt{T} \\right)$ individual regret."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The main contribution, in my assessment, is an improvement over Wei et al. (2023) in proposing a truthful incentive mechanism (for reporting participation costs) that simultaneously guarantees $\\tilde{\\mathcal{O}}\\left( \\sqrt{T} \\right)$ near-optimal learning loss."
                },
                "weaknesses": {
                    "value": "Given that this work is based off of the model of Wei et al. (2023) who essentially formulate all of the problem setting and the optimization problem being solved, the contributions could run the risk of being seen as incremental. \n\nHowever, I believe this paper provides an improved and richer solution concept in comparison to that proposed in Wei et al. (2023) by factoring in regret, social cost and as well as the incentives involved in reporting participation costs."
                },
                "questions": {
                    "value": "Is the bi-criteria approximation in Theorem 9 best possible or it can possibly be improved to $[1+\\epsilon, 1-\\delta(\\epsilon)]$, where $\\delta(\\epsilon)$ decreases in $\\epsilon$ with $\\delta(\\infty) = 0$. Also, is $\\delta(0) = \\frac{1}{e}$ best possible?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5786/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698816579089,
            "cdate": 1698816579089,
            "tmdate": 1699636608723,
            "mdate": 1699636608723,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6J0UQ2lUqE",
                "forum": "ykEixGIJYb",
                "replyto": "XkkO8FeGbm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ihns"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the appreciation of our work. Please let us know if you have any further questions, and we are more than happy to incorporate any additional suggestions that could further enhance our work and lead to a more favorable evaluation of our work.\n\n**[Q1]**: The contributions of this work could run the risk of being seen as incremental to Wei et al. (2023). However, I believe this paper provides an improved and richer solution concept in comparison to that proposed in Wei et al. (2023) by factoring in regret, social cost and as well as the incentives involved in reporting participation costs.\n\n**[A1]**: Despite achieving the same results on regret and communication cost as Wei et al. (2023), our solution is completely different from theirs, with fewer assumptions yet richer property guarantees. Please see a detailed discussion on our contribution in [CA4].\n\n\n**[Q2]**: Is the bi-criteria approximation in Theorem 9 best possible or it can possibly be improved to $[1+\\epsilon, 1-\\delta(\\epsilon)]$ , where $\\delta(\\epsilon)$ decreases in $\\epsilon$ with $\\delta(\\infty) = 0$. Also, is $\\delta(0) = \\frac{1}{e}$ best possible?\n \n**[A2]**: The approximation factor of $1-e^{-1}$ on the constraint in Theorem 9 stems from the approximation factor of the solution to the sub-problem defined in Line 5 of Algorithm 1, which is an NP-hard submodular optimization problem. In our method, we resort to the greedy algorithm (Algorithm 2) that holds the approximation factor of $1-e^{-1}$. This performance guarantee is known as best possible for this sub-problem [R1]. \n\nRegarding the objective approximation factor, our result of $(1+\\epsilon)$ is the best possible in terms of order-wise analysis, as the positive constant $\\epsilon > 0$ can be arbitrarily small. For constant-wise analysis, this is still an open question in the field of submodular optimization to the best of our knowledge. With that being said, **any possible constant-wise change in our bi-criterion approximation will not impact our upper bound analysis or the truthfulness guarantee of our proposed method**.\n\n**Reference**\n\n[R1]. Maxim Sviridenko. A note on maximizing a submodular set function subject to a knapsack constraint. Operations Research Letters, 32(1):41\u201343, 2004."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700200516299,
                "cdate": 1700200516299,
                "tmdate": 1700200516299,
                "mdate": 1700200516299,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rsTL1nYR1D",
                "forum": "ykEixGIJYb",
                "replyto": "6J0UQ2lUqE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_ihns"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_ihns"
                ],
                "content": {
                    "title": {
                        "value": "Keeping my score"
                    },
                    "comment": {
                        "value": "I thank the authors for answering my queries and for providing a very comprehensive overall rebuttal. Upon examining the points that were raised, I do concur that the paper could substantially benefit from being rewritten in a way that precisely distills out contributions vis-a-vis Wei et al. (2023). Personally, I found this paper hard to review as I was not aware of Wei et al. (2023) before, and current exposition implicitly assumes reader's familiarity with prior work. That said, I'd imagine this wouldn't be an issue for many as well. I'll therefore maintain my score."
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700523931481,
                "cdate": 1700523931481,
                "tmdate": 1700523931481,
                "mdate": 1700523931481,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Q7cjk3BiZE",
            "forum": "ykEixGIJYb",
            "replyto": "ykEixGIJYb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5786/Reviewer_1gFC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5786/Reviewer_1gFC"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the problem of learning the unknown parameter in linear parametric bandits via federated/distributed learning (FL) with a central server and multiple clients, when each client must be incentivised to participate in the learning task. More specifically, each client possesses an intrinsic participation cost (e.g., amount of local computational resources at the client required to execute its share of the FL task), and participates only when its incentive for participation exceeds its participation cost. The paper studies the interesting and practically relevant setting when each client may potentially misreport its participation cost (in the interest of exploiting the system or maximising its utility), a setting that is not studied in the prior works. The authors borrow the ideas of *truthfulness* and *social cost* (popular in economics) to design an FL algorithm in which each client can maximise its utility only if it reports the true participating cost. For such an algorithm, the authors obtain bounds on the communication cost and pseudo-regret for FL with incentivised communication, while also demonstrating that the optimal social cost may be achieved up to scaling factors."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper studies the interesting and practically relevant setting when each client may potentially misreport its participation cost (in the interest of exploiting the system or maximising its utility), a setting that is not studied in the prior works. For the problem of FL with incentivisation studied in the prior work of Wei et al. (2023), the paper brings in the ideas of *truthfulness* and *social cost* from economics to quantify the performance of a regret-minimisation algorithm. A formal demonstration of the monotonicity of Algorithm 1 is one of the key contributions of the paper; a similar result is missing in the prior works on FL. The experimental valuations are adequate and insightful."
                },
                "weaknesses": {
                    "value": "1. The regret analysis seems to follow quite straightforwardly from Wei et al. (2023) with slight modifications in the hyper-parameter values (as indeed noted on page 17 of the supplementary material, in the description trailing Lemma 18). Therefore, it appears that there is not much novelty in the regret analysis, leaving the novelty to the demonstration of truthfulness and near-optimality of social cost. \n\n2. In continuation to the last sentence of the previous point, there appears to be no motivation to study the criterion delineated in (1). The authors simply proceed to analyse the objective function in (1), simply because it appears in Wei et al. (2023). No further explanation of the criterion in (1) or of its relevance to FL is provided in the paper.\n\n3. The authors consider a very specific form for the valuation function $f(\\Delta V_{i,t})$ without motivating the same. Has a similar valuation function been studied in the context of FL? More generally, what conditions must $f$ satisfy for the analyses to go through? These are not discussed in the paper. \n\n4. On the algorithmic side, the authors prove in Lemma 6 that if the selection rule (a rule for selecting a set $S_t$ of clients that would participate in the FL task at time $t$) can be computed in polynomial time, then so can the critical value associated with the selection rule. However, no explicit result stating how much time is taken by Algorithm 1/2 to compute the selection rule is provided in the paper. While the authors provide an explicit scheme to compute the critical value, the authors do not explicitly prove that their Algorithm 1/2 computes the selection rule in polynomial time. \n\n5. The statement of Lemma 7 appears to be contradictory to one of the statements made in its proof (presented in Appendix D). In the proof, the authors identify that $\\left(1+\\frac{t L^2}{\\lambda d} \\right)^{-d}$ is a lower bound on a certain ratio of determinants, and further note that \"if the hyper-parameter $\\beta$ is **greater** than the (preceding) lower bound, it is guaranteed that no client can be essential\". However, Lemma 7 states the contrary. Furthermore, the constants $L$ and $\\lambda$ appearing in the statement of Lemma 7 are not defined in the main text.\n\n6. There are no comments on the tightness of the bounds on the communication cost and pseudo-regret in relation to the bounds appearing in the work of Wei et al. (2023) (the key piece of work the current paper seems to be based upon). In the process of achieving near-optimal social cost, what is the impact on the communication cost / number of rounds of communication and regret? A formal comparison along these lines with Wei et al. (2023) is missing.\n\n7. Immediately following the statement of Lemma 18 in Appendix E, the authors state that \"In each communication round, **all** the clients upload $O(d^2)$ scalars to the server and then download $O(d^2)$ scalars.\" Why do **all** the clients participate in the communication and not just the ones from the selection set $S_t$ at the communication time instant $t$? This is a little confusing, and not discussed elsewhere in the paper.\n\nThe writing of the paper can be significantly improved. \n\n1. The *incentive* $\\mathcal{I}_{i,t}$ introduced in (2) does not appear to be used elsewhere in the paper. \n2. In Definition 4: $c\\_{i}(\\mathcal{M}, \\widehat{D}\\_{-i, t}) \\to c\\_{i, t}(\\mathcal{M}, \\widehat{D}\\_{-i, t})$.\n3. In the paragraph before Lemma 6: \"Lemma 5\" should be replaced with \"Proposition 5\".\n4. In the proof of Theorem 8: $i \\notin S\\_t \\to i \\notin S\\_t^\\prime$.\n5. The notion of \"communication threshold\" in Theorem 10 is not explained in the paper.\n\nThe paper is generally missing the overall feel of an FL paper (no details about the communication protocol, which set of clients participate in communication, what information is communicated from the clients to the server), and seems to only build upon the setting and results of Wei et al. (2023) on the social cost and truthfulness aspects."
                },
                "questions": {
                    "value": "I have discussed the questions under \"Weaknesses\"."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5786/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5786/Reviewer_1gFC",
                        "ICLR.cc/2024/Conference/Submission5786/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5786/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699431937925,
            "cdate": 1699431937925,
            "tmdate": 1700628805237,
            "mdate": 1700628805237,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xI0UQlwNa6",
                "forum": "ykEixGIJYb",
                "replyto": "Q7cjk3BiZE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1gFC [Part 1/3]"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the careful review and valuable suggestions to clarify our contribution in comparison with previous works. But we have to first clarify that our focused problem is **federated bandit learning**, not the general federated learning (FL) as the reviewer kept referring to in the review. **We are worried that this might cause most of the reviewer\u2019s misunderstandings about our work (e.g., regarding our model behavior [Q2, Q7, Q9] and novelty [Q1, Q10])**. We ask the reviewer to kindly refer to our general response [CA1] for a detailed discussion on the uniqueness of federated bandit problem, which directly determines how data should be valued in this particular context. More detailed discussions on this aspect are provided in our following responses [A2] and [A3]. \n\nPlease let us know if you have any further questions, and we are more than happy to incorporate any additional suggestions that could further enhance our work and lead to a more favorable evaluation of our work.\n\n**[Q1]**: It appears that there is not much novelty in the regret analysis, leaving the novelty to the demonstration of truthfulness and near-optimality of social cost. \n\n**[A1]**: As we discussed in the general response [CA4], our method achieves the **same order of regret** as previous works that count on strong assumptions (e.g., the willingness assumption in DisLinUCB [R2], the truthfulness assumption in Inc-FedUCB [R4] as illustrated in the table presented in [CA4]), while we drop all those assumptions. We truly believe our finding that one can achieve the same level of regret while being free from these strong assumptions is already a non-trivial contribution to the community.\n\nWe should emphasize that our focus is on devising the incentive mechanism that ensures truthfulness and near-optimal social cost, without compromising the guarantees in regret and communication cost. Moreover, as the previous work has shown the obtained regret and communication upper bounds are already tight [R5], there is little room to develop new regret analysis techniques to improve the results. \n\n\n**[Q2]**:  There appears to be no motivation to study the criterion delineated in (1). No further explanation of the criterion in (1) or of its relevance to FL is provided in the paper.\n\n\n**[A2]**: In our concerned federated bandit problem, optimizing the determinant ratio directly corresponds to the reduction of regret [R4], which is a well-established standard metric in the literature [R1, R2, R3]. Therefore, any feasible solution to Eq. (1) that satisfies the determinant ratio constraint immediately guarantees the near-optimal regret. A more detailed explanation of this criterion is provided in Sections 4.1 and 4.2 in Wei et al. (2023) [R4].\n\nWe want to clarify that in our work, using Eq. (1) as our optimization problem is not an assumption but a design choice to achieve our goal. We acknowledge the possibility of other forms of optimization problems that, when solved, can yield similar results with proper proofs.\n\n**[Q3]**: The authors consider a very specific form for the valuation function $f(\\Delta V_{i,t})$ without motivating the same. Has a similar valuation function been studied in the context of FL? More generally, what conditions must $f$ satisfy for the analyses to go through? These are not discussed in the paper. \n\n**[A3]**: By the notation $D_{i,t} = f(\\Delta V_{i,t})$, we meant to express that our work generalizes the constant setting of data sharing cost, i.e., $D_{i,t} = C_i \\cdot \\mathbb{I}(\\Delta V_{i,t} \\neq \\mathbf{0})$ as adopted in Wei et al. (2023) [R4].\n\nIn fact, none of our analysis across the paper depends on the specific form of $D_{i,t}$ - all that matters is that client $i$ has a value $D_{i,t}$ for its data at time step $t$, and **we do not require any conditions for the function $f$ to satisfy**. To eliminate potential confusion, we will remove the $f(\\Delta V_{i,t})$ notation in our final version."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700199061337,
                "cdate": 1700199061337,
                "tmdate": 1700260493370,
                "mdate": 1700260493370,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0O8scJShy8",
                "forum": "ykEixGIJYb",
                "replyto": "Q7cjk3BiZE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1gFC [Part 2/3]"
                    },
                    "comment": {
                        "value": "**[Q4]**: No explicit result stating how much time is taken by Algorithm 1/2 to compute the selection rule is provided in the paper. While the authors provide an explicit scheme to compute the critical value, the authors do not explicitly prove that their Algorithm 1/2 computes the selection rule in polynomial time.\n\n**[A4]**: For Algorithm 2, the worst-case time complexity of the while loop is $O(N)$. The operation inside the while loop involves finding the maximum element in a set, which takes $O(N)$ time. Therefore, the time complexity of Algorithm 2 is $O(N^2)$.\n\nLet $M$ be the number of iterations of the while loop in Algorithm 1. Hence, the time complexity of Algorithm 1 is $O(M \\cdot N^2)$. Specifically, the worst case is to consistently increase the budget $b$ until it reaches the sum of $\\widehat D_{i,t}, \\forall i \\in \\widetilde{S}$. Therefore, we can upper bound $M$ by considering the loop-breaking case: $b_0 \\cdot (1 + \\epsilon)^M \\geq \\sum_{i=1}^{N} \\widehat D_{i,t}$, i.e., $M \\leq \\left\\lceil \\log_{1+\\epsilon}\\left(\\sum_{i=1}^{N} \\frac{\\widehat D_{i,t}}{b_0}\\right)\\right \\rceil$, where $b_0 = \\min_{i \\in  \\widetilde S} \\widehat{D}_{i,t}$.\n\nAs a result, the overall time complexity of Algorithm 1 is $O( \\left\\lceil \\log_{1+\\epsilon}\\left(\\sum_{i=1}^{N} \\frac{\\widehat D_{i,t}}{b_0}\\right)\\right \\rceil \\cdot N^2)$, which is a polynomial time complexity.\n\n**[Q5]**: A typo in the proof of Lemma 7 (presented in Appendix D). Furthermore, the constants $L$ and $\\lambda$ appearing in the statement of Lemma 7 are not defined in the main text.\n\n\n**[A5]**: Thanks for pointing out this typo. We have corrected it (and other typos pointed out by the reviewer) in our updated manuscript. To follow the convention in the bandit literature and reduce the barrier of access, we choose the standard notations $L$ and $\\lambda$ to represent the regularization parameters, in line with previous works [R1,R2, R3, R4]. Due to the space limit, we left these standard technical details to the appendix, please refer to the definitions in Lemma 15 and Eq. (12).\n\n\n**[Q6]**: There are no comments on the tightness of the bounds on the communication cost and pseudo-regret in relation to the bounds appearing in the work of Wei et al. (2023). In the process of achieving near-optimal social cost, what is the impact on the communication cost / number of rounds of communication and regret? A formal comparison along these lines with Wei et al. (2023) is missing.\n\n\n**[A6]**: As clarified in [A1], our results on the communication costs and regret are essentially in the same order as those in Wei et al. (2023) [R4], which are already tight order wise. Please see a detailed comparison in the general response [CA4].\n\nAs analyzed in our Section 4.3, to achieve a near-optimal social cost, our method needs to slightly relax the determinant ratio constraint by a small constant factor of $(1 - e^{-1})$. Technically, our method guarantees the determinant ratio $\\frac{\\det(V_{g,t}(S_{t}))}{\\det(V_{g,t}(\\widetilde{S}))} \\geq \\beta^{1-e^{-1}}$, while their method guarantees $\\frac{\\det(V_{g,t}(S_{t}))}{\\det(V_{g,t}(\\widetilde{S}))} \\geq \\beta$. Correspondingly, we need to set a lower communication threshold $D_c = \\frac{T}{N^2d\\log T} - (1-e^{-1}) \\sqrt{\\frac{T^2}{N^2dR\\log T} }\\log \\beta$ compared to $D_c = \\frac{T}{N^2d\\log T} - \\sqrt{\\frac{T^2}{N^2dR\\log T} }\\log \\beta$ in Wei et al. (2023).\n\nDespite these trivial constant gaps, **there is no impact on the order of communication cost and regret**, as we presented in the table of [CA4] and proved in Appendix E."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700199986708,
                "cdate": 1700199986708,
                "tmdate": 1700200103306,
                "mdate": 1700200103306,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZKpToCKWZj",
                "forum": "ykEixGIJYb",
                "replyto": "Q7cjk3BiZE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1gFC [Part 3/3]"
                    },
                    "comment": {
                        "value": "**[Q7]**: Why do all the clients participate in the communication and not just the ones from the selection set $S_t$ at the communication time instant $t$? This is a little confusing, and not discussed elsewhere in the paper.\n\n**[A7]**: To facilitate the data valuation of clients' local updates at time step $t$, all clients need to first upload $\\Delta V_{i,t}$ to the server, and only those who decide to participate will subsequently upload the corresponding $\\Delta b_{i,t}$. Please refer to [CA3] for a detailed clarification on the communication scheme.\n\n**[Q8]**: The incentive $\\mathcal{I}_{i,t}$ introduced in (2) does not appear to be used elsewhere in the paper. \n\n**[A8]**: In the incentivized communication setting, any individual rational client only participates in data sharing if the incentive provided by the server is no less than the client's intrinsic data sharing cost, i.e., $\\mathcal I_{i,t} \\geq D_{i,t}$. This property is formally introduced in Definition 1 of Wei et al. (2023) [R4], and we have made this notation clearer in our revised manuscript (see Section 3).\n\n**[Q9]**: The notion of \"communication threshold\" in Theorem 10 is not explained in the paper.\n\n**[A9]**: We have made this notation clearer in our revised manuscript (see Theorem 10). The communication threshold $D_c$ is a hyperparameter of the standard communication event trigger, which is used to control the communication frequency, as defined in the communication protocol (Line 9 of Algorithm 6).  \n\n**[Q10]**: The paper is generally missing the overall feel of an FL paper (no details about the communication protocol, which set of clients participate in communication, what information is communicated from the clients to the server), and seems to only build upon the setting and results of Wei et al. (2023) [R4] on the social cost and truthfulness aspects.\n\n**[A10]**: We should clarify that our focus is on mechanism design for incentive compatibility in **federated bandit learning**, instead of the general FL. Please find our detailed clarifications in [CA1] and [CA2].\n\nDue to space limit, we leave the details of the standard communication scheme to Appendix F, where the communication protocol is presented in Algorithm 6. Please see also our general response [CA3].\n\nAs we clarified in the general response [CA4], our incentive mechanism design (Algorithm 1) is completely different from Wei et al. (2023) [R4] (Algorithm 3 in their paper), as their design builds on the strong truthfulness assumption. **Note that despite achieving the same results on regret and communication cost bounds, our method requires fewer assumptions but enjoys richer guarantees**.\n\n**References**\n\n[R1]. Yasin Abbasi-Yadkori, D\u00e1vid P\u00e1l, and Csaba Szepesv\u00e1ri. Improved algorithms for linear stochastic bandits. NeurIPS 2011.\n\n[R2]. Yuanhao Wang, Jiachen Hu, Xiaoyu Chen, and Liwei Wang. Distributed bandit learning: Near-optimal regret with efficient communication. ICLR 2020.\n\n[R3]. Chuanhao Li, and Hongning Wang. Asynchronous Upper Confidence Bound Algorithms for Federated Linear Bandits. AISTATS 2022.\n\n[R4]. Zhepei Wei, Chuanhao Li, Haifeng Xu, and Hongning Wang. Incentivized Communication for Federated Bandits. NeurIPS 2023.\n\n[R5]. Jiafan He, Tianhao Wang, Yifei Min, Quanquan Gu. A Simple and Provably Efficient Algorithm for Asynchronous Federated Contextual Linear Bandits. NeurIPS 2022."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700200295806,
                "cdate": 1700200295806,
                "tmdate": 1700244798678,
                "mdate": 1700244798678,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3flk0KUTfY",
                "forum": "ykEixGIJYb",
                "replyto": "Q7cjk3BiZE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_1gFC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_1gFC"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors' rebuttal (Round 1)"
                    },
                    "comment": {
                        "value": "I thank the authors for their meticulous and comprehensive response. I acknowledge that I erroneously employed the term \"federated learning\" in my review comments, leading to potential confusion, and I extend my apologies for any misunderstanding. I also wish to acknowledge that I am fully aware of the difference between federated bandit learning and federated learning.\n\nUpon a thorough examination of the authors' detailed rebuttal, I feel that the substantial merit inherent in the paper may not be readily apparent upon initial reading. The key concepts within the paper appear either dispersed or, alternatively, necessitate readers to delve into the specifics of Wei et al.'s (2023) work to fully comprehend the results. I am afraid the reader might miss seeing the paper's significant contributions, primarily due to the writing style.\n\n1. Given that this is a paper on federated bandit leaning, it is certainly important to mention what rule is followed for communication between the server and the clients, even if this means reproducing a portion of the content from prior works; this is in the interest of making the problem description clear. In their common response [CA3], the authors state that whenever a communication event is triggered, each client uploads $\\Delta V_{i,t}$ and, only when incentivised, participates in uploading $\\Delta b_{i,t}$. This is an important fact pertaining to the problem setting, and a description of this is missing in Section 3. Even the fact that the communication between the clients and the server takes place on a threshold-based trigger is not made explicit in Section 3. In my opinion, it would be unfair to ask the readers to refer to Appendix F or be aware of the work of Wei et al. (2023) merely to understand this part. It is my humble submission that Section 3 can be rewritten to make the above facts explicit.\n\n2. Instead of mentioning \"Wei et al. (2023) pinpointed the core optimization problem in incentivized communication as follows...\" in Section 3 (just before (1)), the authors should perhaps mention that (1) is a \"design choice\" which they use to model incentivised communication in their work, and that they borrow this from the work of Wei et al. (2023). Again, this is my suggestion to the authors towards improving the writing of the paper to set the objectives clearly in the paper.\n\n3. I am afraid that the notations $D\\_{i,t}$ (true participating cost of client $i$ at time $t$) and $\\widehat{D}\\_{i,t}$ (the actual reported cost of client $i$ at time $t$) may lead to confusions in understanding the main objective of the paper. The authors state that it is of interest to minimise the social cost which is equal to $\\sum_{i \\in S_t} D_{i,t}$, whereas the bounds presented in Theorem 9 are for the quantity $\\sum\\_{i \\in S_t} \\widehat{D}\\_{i,t}$. I think it will be more clearer to the reader if there is an explicit mention that $D\\_{i,t}$ is used only in the analysis. Algorithm 6 in Appendix F (the author's algorithm for communication between clients and server), the definition of incentive $\\mathcal{I}\\_{i,t}$, Eq. (3), and the result in Theorem 9 are all based on the reported cost $\\widehat{D}\\_{i,t}$ only. It is best to not leave the reader wondering where $D\\_{i,t}$ is being used in the paper.\n\nIn the interest of saving space, I wish to refrain from pointing out more specifics along the above lines. While I find that the setting and the contributions of the paper are indeed quite interesting (especially regarding the aspects of untruthfulness of clients and social cost, given how important these aspects are from a practical standpoint) and am therefore willing to increase my score to 5 (borderline reject), I find that the writing of the paper can (and perhaps should) be significantly improved. I humbly submit that it would be appropriate for the authors to do a full and thorough rewriting of the paper to delineate the problem description, the important aspects of communication protocol, incentivised communication, and social cost minimisation clearly in their paper, and bring out the contributions more cogently. Also, an inclusion of the table from the common response (comparing the results of the prior works with those of the current paper) in the main text would be apt in my opinion. \n\n**While I am divided between the choice to accept the paper with an essential rewriting for more clarity, and rejecting the paper in the interest of recognising that the authors have very limited time (to do a thorough rewriting) at this stage of the review process, I am inclined to stay with the latter decision**."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700490997138,
                "cdate": 1700490997138,
                "tmdate": 1700629247839,
                "mdate": 1700629247839,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bXdGm0edoQ",
                "forum": "ykEixGIJYb",
                "replyto": "Q7cjk3BiZE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1gFC [Round 2, Part 1/3]"
                    },
                    "comment": {
                        "value": "Thank you for the response and acknowledgment of our work's technical contributions. We are particularly glad to find that the reviewer recognizes *\u201cthe setting and the contributions of the paper are indeed quite interesting (especially regarding the aspects of untruthfulness of clients and social cost, given how important these aspects are from a practical standpoint)\u201d*. \n\nHowever, we respectfully disagree with the reviewer\u2019s criticism that \u201cit would be unfair to ask the readers to refer to Appendix F\u201d for a detailed description of the standard communication protocol. Given the strict page limit, we have to make a choice between the details of our technical contributions in this work versus the general background of this line of work. In Section 3 of our original submission, the paragraph below Eq. (1), we explicitly explained that *\u201cA detailed description of this communication protocol is provided in Appendix F\u201d*. And in Appendix F, we carefully described every step in this communication protocol in Algorithm 6 with particular highlights on the uploading and downloading steps (Line 10, 13, 18). Moreover, we have to stress that this communication protocol is quite **standard for federated bandit learning**, almost employed by every work in federated bandits [R4, R5, R6, R7, R8, R9]; and it was actually first introduced in Wang et al. (2020) [R4] paper, not Wei et al. (2023) [R5].\n\n**Given all necessary technical details and background have been presented in our paper and the reviewers found our technical contributions strong, it will be very frustrating to find our paper got rejected, simply because such content was not presented earlier due to space limit**. Moreover, we firmly believe there is no need to rewrite the paper, as all the suggested \u201cconfusing notations\u201d and \u201cmissing descriptions\u201d have also been explained clearly in the paper. Please refer to the following itemized responses for a detailed justification.\n\nWith that being said, from the perspective of disseminating a paper with heavy technical details like ours, we agree it would be more favorable to present the contribution in a way that readers with different backgrounds can grasp it at first glance. To this end, we have included the table in [CA4] in our latest manuscript.\n\nPlease let us know if you have any further questions, and we look forward to the possibility of your updated evaluation of our work.\n\n**[Round2-Q1]**: The key concepts within the paper appear either dispersed or, alternatively, necessitate readers to delve into the specifics of Wei et al.'s (2023) work to fully comprehend the results.\n\n**[Round2-A1]**: As we concluded at **the second paragraph in Section 1** of our original submission, our focus is on *\u201cdesign a truthful incentive mechanism for federated bandits that prevents misreporting while still preserving the nearly optimal regret and communication cost\u201d*, which has clearly stated the expected results and contribution of this work. We have consistently tried to emphasize this in the response to the reviewer\u2019s previous misunderstandings about our contribution in [Q1]. \n\nTherefore, we believe we have provided necessary descriptions for the readers to comprehend our results and contributions and there is very little requirement for them to delve into previous works, unless the readers are curious/skeptical about our claim or the general background as in the reviewer\u2019s previous question regarding the optimization problem in [Q2]. What\u2019s more, the discussions regarding those related work have been carefully addressed in our related work section."
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700546538965,
                "cdate": 1700546538965,
                "tmdate": 1700548627940,
                "mdate": 1700548627940,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Y9NYq5BiRd",
                "forum": "ykEixGIJYb",
                "replyto": "Q7cjk3BiZE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1gFC [Round 2, Part 3/3]"
                    },
                    "comment": {
                        "value": "**[Round2-Q4]**: I am afraid that the notations $D_{i,t}$ and $\\widehat D_{i,t}$ may lead to confusions in understanding the main objective of the paper. The authors state that it is of interest to minimise the social cost which is equal to $\\sum_{i \\in S_t} D_{i,t}$, whereas the bounds presented in Theorem 9 are for the quantity $\\sum_{i \\in S_t} \\widehat D_{i,t}$. I think it will be more clearer to the reader if there is an explicit mention that $\u200b\u200bD_{i,t}$ is used only in the analysis. \n\n**[Round2-A4]**: We should seriously clarify that the true data sharing cost $D_{i,t}$ of any client $i$ is **NOT** used in any part of our analysis. The reason is simple: the true data sharing costs are private to the clients themselves and are not revealed to the server or any other clients at all, as is standard in truthful mechanism design [R1, R2, R3].\n\nNote that both the notations for social cost (i.e., $\\sum_{i \\in S_t} D_{i,t}$) and the bound ($\\sum_{i \\in S_t} \\widehat D_{i,t}$) presented in Theorem 9 are **in their intended format**. This is because our Theorem 9 (and other theorems) is narrated from the server\u2019s perspective, and the server only has access to the reported cost $\\widehat D_{i,t}$ rather than the true cost $D_{i,t}$. Therefore, it would be incorrect to use the notation $D_{i,t}$ in Theorem 9, as it suggests the server knew the true costs of the clients.\n\nThis explains why we need a truthful mechanism to guarantee that clients report $\\widehat D_{i,t} = D_{i,t}$; otherwise, the notations would be conflicting with each other. More importantly, with the truthful mechanism design, we can directly minimize the social costs without accessing the private true cost of each client, which is one of the key technical contributions of our work.\n\n**References**\n\n[R1]. Karimireddy, Sai Praneeth, Wenshuo Guo, and Michael I. Jordan. Mechanisms that incentivize data sharing in federated learning. arXiv preprint arXiv:2207.04557 (2022). \n\n[R2]. T. H. Thi Le et al. An Incentive Mechanism for Federated Learning in Wireless Cellular Networks: An Auction Approach. in IEEE Transactions on Wireless Communications, vol. 20, no. 8, pp. 4874-4887, Aug. 2021, doi: 10.1109/TWC.2021.3062708\n\n[R3]. Mu'Alem, Ahuva, and Noam Nisan. Truthful approximation mechanisms for restricted combinatorial auctions. Games and Economic Behavior 64.2 (2008): 612-631.\n\n[R4]. Yuanhao Wang, Jiachen Hu, Xiaoyu Chen, and Liwei Wang. Distributed bandit learning: Near-optimal regret with efficient communication. ICLR 2020.\n\n[R5]. Zhepei Wei, Chuanhao Li, Haifeng Xu, and Hongning Wang. Incentivized Communication for Federated Bandits. NeurIPS 2023.\n\n[R6]. Dubey, Abhimanyu, and AlexSandy Pentland. Differentially-private federated linear bandits. NeurIPS 2020.\n\n[R7]. Chuanhao Li, Huazheng Wang, Mengdi Wang, and Hongning Wang. Communication efficient distributed learning for kernelized contextual bandits. NeurIPS 2022.\n\n[R8]. Chuanhao Li, and Hongning Wang. Asynchronous upper confidence bound algorithms for federated linear bandits. AISTATS 2022.\n\n[R9]. Chuanhao Li, and Hongning Wang. Communication efficient federated learning for generalized linear bandits. NeurIPS 2022."
                    }
                },
                "number": 28,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700546850157,
                "cdate": 1700546850157,
                "tmdate": 1700549551092,
                "mdate": 1700549551092,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MH0Hr6GYqZ",
                "forum": "ykEixGIJYb",
                "replyto": "Q7cjk3BiZE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_1gFC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_1gFC"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors' rebuttal (Round 2)"
                    },
                    "comment": {
                        "value": "I thank the authors for their detailed responses and counter-arguments to my questions. The more I engage with the authors in discussions, the more I am convinced of the soundness of the contributions. That it took so much of explanation from the authors to help me (and perhaps the other reviewers) see the contributions of the paper (in comparison to those of the existing works) more clearly and thereby arrive at a positive evaluation of the paper is of little concern to me. I am only suggesting that the paper be written more carefully so that the key ideas do not remain dispersed all throughout the paper, but are clearly evident in the main text. Somehow, because of the writing style, I feel that the key ideas of the paper and the contributions are dispersed throughout the paper and not explicit in one go, a single reading. Noting that the authors have put in significant efforts to revise their paper heeding to my suggestions and the suggestions of the other reviewers, I am willing to increase my score further. Before I do so, I would like the authors to provide clarifications on the following.\n\n1. Can the authors clarify if their statement of Lemma 7 is correct? Should $\\beta$ be lesser than or greater than the threshold mentioned there for the statement of the Lemma to make sense? The proof of Lemma 7 seems to state the contrary. I believe that $\\beta \\leq \\ldots$ in Lemma 7 should be changed to $\\beta \\geq \\ldots$.\n\n2. In my understanding, the proposed algorithm guarantees that $\\sum_{i \\in S_t} \\widehat{D}\\_{i,t} = \\sum_{i \\in S_t} D\\_{i,t}$ for each time $t$, as the proposed algorithm is shown to satisfy the truthfulness property. Can the authors clarify if my understanding is correct? If so, it may be good to include a statement to this effect after Theorem 9. This would help the reader  correlate the implication of Theorem 9 with the definition of social cost, and thereby reinforce the near-optimality of the social cost achieved by the algorithm. The reason I am nitpicking on this point is because while the algorithm is shown to have a near-optimal value of $\\sum_{i \\in S_t} \\widehat{D}\\_{i,t}$ (up to a factor of $1+\\epsilon$), it would be incorrect to refer to $\\sum_{i \\in S_t} \\widehat{D}\\_{i,t}$ as the social cost, though the Theorem may be stated from the server's perspective.\n\nThe authors can perhaps include a sentence immediately after Lemma 6 explicitly stating that their algorithm indeed satisfies the desired polynomial time complexity, and provide a short proof of this in the appendix along the lines of the proof delineated in round 1 of their response."
                    }
                },
                "number": 31,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700555981288,
                "cdate": 1700555981288,
                "tmdate": 1700556893848,
                "mdate": 1700556893848,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fnrPoWGkRC",
                "forum": "ykEixGIJYb",
                "replyto": "ajGEiIkYxJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_1gFC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_1gFC"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors' rebuttal (Round 3)"
                    },
                    "comment": {
                        "value": "I thank the authors for their responses. I think my questions are addressed satisfactorily. I appreciate the authors' effort to revise their manuscript to include the suggestions provided by me and the other authors. I am hereby increasing my score to 8, while also duly recognising that there is room for further improving the writing of the paper to make the contributions stand out better and easily comprehensible in a first reading of the paper."
                    }
                },
                "number": 33,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700628742513,
                "cdate": 1700628742513,
                "tmdate": 1700628742513,
                "mdate": 1700628742513,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]