[
    {
        "title": "Learning Personalized Causally Invariant Representations for Heterogeneous Federated Clients"
    },
    {
        "review": {
            "id": "3k6Q6iCEsx",
            "forum": "8FHWkY0SwF",
            "replyto": "8FHWkY0SwF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7234/Reviewer_Qvuh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7234/Reviewer_Qvuh"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a novel approach to mitigating shortcut learning in personalized federated learning, which is a challenging problem in real-world settings. The proposed method, FedSDR, utilizes structural causal models to discover and remove shortcuts while preserving personalization knowledge."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This paper provides extensive background information, offering readers significant convenience in understanding the topic.\n\n2. The authors conducted extensive experiments on some real-world datasets, validating the excellent performance of the proposed method."
                },
                "weaknesses": {
                    "value": "1. I believe the main issue with this paper is that the research motivation seems weak. The paper claims to primarily address the scenario where training sets are Non-IID among clients, and where within each client, the training and test sets are also Non-IID. However, I think existing Robust Federated Learning and Federated Domain Generalization methods are capable of handling the aforementioned scenario. Although these two methods primarily focus on the issue of Non-IID training and test sets within each client.\n\n2. The paper states, \"To the best of our knowledge, we are the first to consider the shortcut trap problem in personalized federated learning and analyze it by formulating the structural causal models for heterogeneous clients.\" While it's true that this paper is indeed the first to study the use of PFL+SCM to address the shortcut trap problem, existing Robust Federated Learning and Federated Domain Generalization methods can also address the shortcut trap problem. Therefore, the contribution of this paper appears to be limited.\n\n3. In Figure 1, I find the classification of the scenarios where RFL&FedDG are applicable not very accurate. In the scenarios where RFL&FedDG are applicable, the Test-test relation can also be IID or Non-IID.\n\n4. In the experimental section, the proposed model is only compared to FL and PFL methods. However, I believe it should also be compared to RFL and FedDG methods to provide more convincing experimental results.\n\n5. The experimental section lacks detailed information about the configuration of the model used in this paper. More detailed information is needed.\n\n6. The paper lacks a thorough discussion of the limitations of the proposed FedSDR method. While the authors mention some potential limitations in passing, a more detailed discussion of the assumptions and constraints of the method would be helpful for readers to better understand its applicability in different scenarios. \n\n7. Although the authors provide some high-level explanations of how FedSDR works, a more detailed discussion of the causal modeling framework and how it is used to address shortcut learning would be helpful for readers who are not familiar with this area of research."
                },
                "questions": {
                    "value": "Please see above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7234/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7234/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7234/Reviewer_Qvuh"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7234/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698732135551,
            "cdate": 1698732135551,
            "tmdate": 1699636861517,
            "mdate": 1699636861517,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "s7gprsAgEu",
                "forum": "8FHWkY0SwF",
                "replyto": "3k6Q6iCEsx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7234/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7234/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer Qvuh"
                    },
                    "comment": {
                        "value": "Thanks for the reviewer's valuable feedbacks and suggestions. The detailed responses to the reviewer's questions and concerns are listed as follows:\n\n__1. I believe the main issue with this paper is that the research motivation seems weak. The paper claims to primarily address the scenario where training sets are Non-IID among clients, and where within each client, the training and test sets are also Non-IID. However, I think existing Robust Federated Learning and Federated Domain Generalization methods are capable of handling the aforementioned scenario. Although these two methods primarily focus on the issue of Non-IID training and test sets within each client.__\n\n__Answer:__ Unfortunately, both robust federated learning and domain generalization methods cannot handle the scenarios well where target datasets are Non-IID across local clients. Since both Federated Domain Generalization (FedDG) and Robust Federated Learning (RFL) generate a shared global model, __they abandon the important personalization information on each client.__ Therefore, the relation between our method and RFL/FedDG is same as the relation between the existing personalized federated learning (FL) and traditional federated learning (FL).\n\n__2. The existing Robust Federated Learning and Federated Domain Generalization methods can also address the shortcut trap problem. Therefore, the contribution of this paper appears to be limited.__\n\n__Answer:__ The existing Robust Federated Learning (RFL) and Federated Domain Generalization (FedDG) methods will abandon the important personalization information on each client since they output a shared global model, although they can also mitigate the shortcut features. In many real-world applications (e.g., medical diagnosis and automatic driving), personalization information is of vital importance and cannot be overlooked. The main contribution of this paper is to fully exploit the significant personalization information, and in the meanwhile eliminate the shortcut features. It's rather challenging because the personalized and shortcut features are usually entangled in the real-world scenarios.\n\n__3. In Figure 1, I find the classification of the scenarios where RFL&FedDG are applicable not very accurate. In the scenarios where RFL&FedDG are applicable, the Test-test relation can also be IID or Non-IID.__\n\n__Answer:__ The existing Robust Federated Learning (RFL) and Federated Domain Generalization (FedDG) methods will abandon the important personalization information on each client since they output a shared global model, when target datasets are Non-IID across local clients. Therefore, we conclude that RFL&FedDG can't cover the scenario well. The relation between our method and RFL/FedDG is same as the relation between the existing personalized federated learning (FL) and traditional federated learning (FL).\n\n__4. In the experimental section, the proposed model is only compared to FL and PFL methods. However, I believe it should also be compared to RFL and FedDG methods to provide more convincing experimental results.__\n\n__Answer:__ Actually, __we included three RFL&FedDG methods as baselines in the experimental section.__ The considered competitor DRFA is a typical RFA method while FedSR and FedIIR are two state-of-the-art FedDG methods. The overall experimental results of these baseline methods can be found in Table 1.\n\n[1] Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad Mahdavi. Distributionally robust federated averaging. Advances in Neural Information Processing Systems, 33:15111\u201315122, 2020.\n\n[2] A Tuan Nguyen, Philip Torr, and Ser-Nam Lim. Fedsr: A simple and effective domain generalization method for federated learning. In Advances in Neural Information Processing Systems, 2022.\n\n[3] Yaming Guo, Kai Guo, Xiaofeng Cao, Tieru Wu, and Yi Chang. Out-of-distribution generalization of federated learning via implicit invariant relationships. In Proceedings of the 40th International Conference on Machine Learning, pp. 11905\u201311933, 2023.\n\n__5. The experimental section lacks detailed information about the configuration of the model used in this paper. More detailed information is needed.__\n\n__Answer:__ The detailed information about the adopted models were provided in section 5.1. For CMNIST and CFMNIST, we adopt the deep neural network with one hidden layer of (128, 128) as feature extractor and an subsequent fully-connected layer as classifier. As regard to Waterbird and PACS, ResNet-18 is used as the learning model where the part before the last fully-connected layer works as feature extractor and the last fully connected layer works as classifier."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7234/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700682265796,
                "cdate": 1700682265796,
                "tmdate": 1700682346183,
                "mdate": 1700682346183,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qPPLfj16ro",
                "forum": "8FHWkY0SwF",
                "replyto": "3k6Q6iCEsx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7234/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7234/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer Qvuh,\n\nThanks for your valuable feedbacks. As the deadline for author-reviewer discussion is approaching, we are concerned you might miss the clarifications that we make for your questions. We would appreciate it very much if you could reassess our work according to the clarifications. Of course, more discussions are welcomed if you still have any concerns or questions for this work."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7234/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700724452024,
                "cdate": 1700724452024,
                "tmdate": 1700724452024,
                "mdate": 1700724452024,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "igBLdFK3G2",
            "forum": "8FHWkY0SwF",
            "replyto": "8FHWkY0SwF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7234/Reviewer_2uxd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7234/Reviewer_2uxd"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a new personalized federated learning approach named FedSDR. Considering generalization on unseen test data, the paper utilizes invariant learning in the federated setting. Specifically, FedSDR first extracts shortcut features that are irrelevant to the task and them remove it to extract the most informative personalized invariant features by carefully designing the objectives. Experiments show that FedSDR outperforms the other baselines in the settings where the test data distribution shifts."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Applying invariant learning in the federated setting is interesting and promising.\n\n2. The organization of the paper is clear.\n\n3. FedSDR significantly outperforms the other baselines."
                },
                "weaknesses": {
                    "value": "1. My main concern is about the experimental setting. Experiments are based on the simulated setting where the authors manually add shortcut features and change the test data distributions. Based on the motivation, the shortcut features should naturally exist in datasets. Experiments on real-world natural datasets are necessary. Otherwise, the application of FedSDR may be very limited.\n\n2. The theoretical analysis has strong assumptions, e.g., logistic regression, linear function, etc. The analysis may not be applicable in the experimental settings.\n\n3. The number of clients used in the experiments is missing. Experiments to evaluate the scalability of FedSDR are not provided.\n\n4. Typos: 1. Page 4: \u201cTheorem 1\u201d -> \u201cLemma 1\u201d; 2. Page 6: \u201cguarantee\u201d -> \u201cguarantees\u201d"
                },
                "questions": {
                    "value": "1. Can you add a synthetic dataset with a simple model in the experiments? It can be used to verify the theorems by satisfying the assumptions.\n\n2. Can you add experiments without manually adding shortcut features? It is quite important. Currently, I\u2019m not clear what are the real applications of FedSDR.\n\n3. Can you add experiments that increase the number of clients and adopt client sampling?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7234/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7234/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7234/Reviewer_2uxd"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7234/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698807341428,
            "cdate": 1698807341428,
            "tmdate": 1700721021831,
            "mdate": 1700721021831,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ULWw1RO0IR",
                "forum": "8FHWkY0SwF",
                "replyto": "igBLdFK3G2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7234/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7234/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part 1 of responses to Reviewer 2uxd"
                    },
                    "comment": {
                        "value": "Thanks a lot for the reviewer's valuable feedbacks and suggestions. The detailed responses to the reviewer's questions and concerns are listed as follows:\n\n__1. Can you add a synthetic dataset with a simple model in the experiments? It can be used to verify the theorems by satisfying the assumptions.__\n\n__Answer:__ We generate a synthetic dataset using the same strategy as in [2]. Specifically, it is a logistic regression task and the data instance $X$ is generated by $X=g(Z_C^g, Z_C^U, Z_S)$, where the dimensionalities of $Z_C^g$, $Z_C^U$ and $Z_S$ are $d_C^g=3$, $d_C^U=3$ and $d_S=6$ respectively. The linear function $g$ is implemented by one fully-connected layer which has 12 neurons. The latent variables $Z_C^g$, $Z_C^U$ and $Z_S$ are subject to $\\mathcal{N}(y\\cdot \\mu_{c,g}, \\sigma_{c,g}^2I)$, $\\mathcal{N}(y\\cdot \\mu_{c,u}, \\sigma_{c,u}^2I)$ and $\\mathcal{N}(y\\cdot \\mu_s, \\sigma_s^2I)$ respectively. Target variable $y$ is taken from the distribution $\\mathbb{P}(y=-1)=\\mathbb{P}(y=1)=0.5$. Both $\\mu_{c,g}$ and $\\mu_{c,u}$ are randomly sampled from $\\mathcal{N}(0, 1.5I)$ while $u_s$ is randomly sampled from $\\mathcal{N}(0, 0.75I)$. To make the shortcut representation $Z_S$ easier to learn, we choose $\\sigma_{c,g}=\\sigma_{c,u}=2$ and $\\sigma_s=1$ as in [2]. Each fixed value of $\\mu_s$ indicates one environment. We generate __10__ training environments and __5000__ test environments to evaluate the out-of-distribution generalization performance. Each (training/test) environment contains 10000 data samples (X, y) and the training data samples are distributed onto totally __100__ clients. The training and test data samples on each client are generated with an identical value of $\\mu_{c,u}$. Besides, we choose the client sampling rate as 0.1.  The experimental results on this synthetic dataset are shown in the following table:\n\n| Algorithm | FedAvg |  DRFA   | FedSR   | FedIIR  | FTFA   | pFedMe  |  Ditto  | FedRep  | FedRoD  | FedPAC  | FedSDR |\n| :---  | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | \n| worst-case (\\%)| $3.06$  | $62.41$ | $63.09$ | $67.39$ |  $1.32$  | $10.58$ |  $7.76$  |  $2.57$  | $21.53$ | $8.98$  | $92.49$ |\n| average     (\\%)| $85.56$ | $69.64$ | $70.53$ | $70.75$ | $96.26$ | $95.72$ | $96.50$ | $97.80$ | $97.24$ | $98.77$ | $96.07$ | \n\nIn particular, when we manually select the causal features $[Z_C^g, Z_C^U]$ as the discriminating features, we find the optimal personalized classifiers achieve an stable accuracy around $97.5$ in different test environments. Therefore, the results shown in Table 1 can demonstrate the effectiveness of our FedSDR on developing the optimal personalized invariant predictors, compared with the state-of-the-art FL and PFL methods. \n\n[2] Rosenfeld, E., Ravikumar, P., & Risteski, A. (2021, July). The Risks of Invariant Risk Minimization. In International Conference on Learning Representations.\n\n__2. Can you add experiments without manually adding shortcut features? It is quite important. Currently, I\u2019m not clear what are the real applications of FedSDR.__\n\n__Answer:__ Actually, __PACS__ is a real-world dataset that is commonly used in related papers. It's a multi-class classification task and there doesn't exists explicit (or manually adding) shortcut features. Specifically, It consists of 7 classes distributed across 4 environments (or domains). The results on PACS dataset are also shown in Table 1."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7234/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700671005687,
                "cdate": 1700671005687,
                "tmdate": 1700671005687,
                "mdate": 1700671005687,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ynjIkICNmy",
                "forum": "8FHWkY0SwF",
                "replyto": "5BELyvm4Qz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7234/Reviewer_2uxd"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7234/Reviewer_2uxd"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your response. Most of my concerns have been addressed. I have raised my score to 6."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7234/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700721009342,
                "cdate": 1700721009342,
                "tmdate": 1700721009342,
                "mdate": 1700721009342,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "z0hHEHo2HC",
            "forum": "8FHWkY0SwF",
            "replyto": "8FHWkY0SwF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7234/Reviewer_zjFS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7234/Reviewer_zjFS"
            ],
            "content": {
                "summary": {
                    "value": "The paper focuses on addressing the \"shortcut trap\" issue within personalized federated learning (pFL) by introducing FedSDR. This solution aims to identify and eliminate shortcut features, leading to enhanced performance for individual clients within pFL on their respective local datasets. The authors support their approach with theoretical proofs and comprehensive experiments, demonstrating the effectiveness of FedSDR across multiple scenarios."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Originality: The paper pioneers the exploration of the shortcut trap problem in pFL.\n\n2. Solid Theoretical Support: The inclusion of strong theoretical foundations.\n\n3. Sufficient Experiments: The comprehensive set of experiments strengthens the paper's contributions."
                },
                "weaknesses": {
                    "value": "1. Notation Conciseness: The notation could be more concise, potentially enhancing the paper's readability.\n\n2. Confusing Training Process: A section of the training process appears confusing and requires clarification.\n\n3. Inconclusive Experimental Results: Certain aspects of the experimental outcomes lack conviction and need further clarification for robustness."
                },
                "questions": {
                    "value": "1. The paper\u2019s algorithmic approach (Algorithm 1) deviates from the conventional practice of client selection in Federated Learning (FL). Could the authors elucidate why they've chosen this approach over the typical FL client selection methodology?\n\n2. Concerns arise from certain experimental results in Table 1, particularly the unexpected lower accuracies observed for specific baseline methods on CMNIST and CFMNIST. Can the authors provide an explanation to address these concerns?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7234/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698984432421,
            "cdate": 1698984432421,
            "tmdate": 1699636861242,
            "mdate": 1699636861242,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HxAkAemBud",
                "forum": "8FHWkY0SwF",
                "replyto": "z0hHEHo2HC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7234/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7234/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer zjFS"
                    },
                    "comment": {
                        "value": "Thanks a lot for the reviewer's valuable comments and suggestions. The detailed responses to the reviewer's questions and concerns are listed as follows:\n\n__1. The paper\u2019s algorithmic approach (Algorithm 1) deviates from the conventional practice of client selection in Federated Learning (FL). Could the authors elucidate why they've chosen this approach over the typical FL client selection methodology?__\n\n__Answer:__ We adopted the same federated learning framework as in pFedMe [1] while the conventional client selection is conducted before local updates. In the adopted framework, the global model is generated by aggregating the updates from the selected clients and the updates from the clients that are not selected are never used. Then on each client, the local model will be initialized by the global model before local update. __Therefore, the final output models of these two client selection methods are exactly identical.__ Our method FedSDR can also be implemented using the conventional client selection methodology and the experimental results will keep unchanged.\n\n[1] T Dinh, C., Tran, N., & Nguyen, J. (2020). Personalized federated learning with moreau envelopes. Advances in Neural Information Processing Systems, 33, 21394-21405.\n\n__2. Concerns arise from certain experimental results in Table 1, particularly the unexpected lower accuracies observed for specific baseline methods on CMNIST and CFMNIST. Can the authors provide an explanation to address these concerns?__\n\n__Answer:__ As shown in Table 1, our FedSDR achieved around __6.5\\%__, __9\\%__, __3.5\\%__ and __2\\%__ higher worst-case accuracy than the second best algorithm among the baselines and in the meanwhile reaches the highest average accuracy on CMNIST, CFMNIST, WaterBird and PACS, respectively. So, what do you mean by \"the unexpected lower accuracies observed for specific baseline methods on CMNIST and CFMNIST\"? __In addition, we will make the project codes public soon to enhance the reproducibility of the conducted experiments.__\n\nThanks again for your valuable feedbacks. More discussions are welcomed if you still have any concerns or questions for this work."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7234/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700657711067,
                "cdate": 1700657711067,
                "tmdate": 1700657711067,
                "mdate": 1700657711067,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DgQINBMSC5",
                "forum": "8FHWkY0SwF",
                "replyto": "HxAkAemBud",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7234/Reviewer_zjFS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7234/Reviewer_zjFS"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks a lot for your response. I would like to inquire further about the reasons behind the significantly low worst-case results obtained by pFL baseline methods. It would be greatly appreciated if the authors could provide a reasonable explanation."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7234/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700663720249,
                "cdate": 1700663720249,
                "tmdate": 1700663720249,
                "mdate": 1700663720249,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]