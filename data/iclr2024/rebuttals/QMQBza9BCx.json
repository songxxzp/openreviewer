[
    {
        "title": "Persistent homology for high-dimensional data based on spectral methods"
    },
    {
        "review": {
            "id": "iXrzgTsJPz",
            "forum": "QMQBza9BCx",
            "replyto": "QMQBza9BCx",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3784/Reviewer_BdHd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3784/Reviewer_BdHd"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses an important challenge: the efficient adaptation of persistent homology tools to point clouds in high-dimensional spaces. Many crucial datasets across different domains are presented in this format, but the curse of dimensionality poses a substantial obstacle to the application of an effective feature extraction method, namely persistent homology, in this context. The authors introduce two novel distance measures to facilitate the efficient utilization of persistent homology in this scenario. They validate their approach with several experiments."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The authors address a significant problem in the ML domain related to high-dimensional point clouds. While there exist various dimension reduction techniques for handling such data, a potentially effective feature extraction method, persistent homology, cannot be facilitated efficiently in the presence of noise in high-dimensional data, as they lead to substantial impacts on the output. To tackle this issue, the authors introduce a novel approach, leveraging two distinct distance measures, effectively circumventing the challenges posed by noise.\n\n2. The authors conduct a comprehensive analysis by performing multiple experiments to validate their approach. They establish the effectiveness of their method by comparing it with several alternative approaches across various datasets."
                },
                "weaknesses": {
                    "value": "1. The main concern with the proposed method is combining kNN graphs with persistent homology. While this provides a solution to deal with noisy data, it unfortunately introduces a more subtle problem: The outliers. Employing kNN in such datasets, immediately makes outliers a big problem for the persistent homology, as if one uses kNN graph distance (even with proposed modifications), any outlier will bring extra unnecessary topological features with high persistence up to dimension k-1. \n\nThis is one of the main obstacles to employing PH in high dimensions, and to tackle both outlier and noise problems, many researchers in the field try to employ multiparameter persistence methods. \n\n2. The \"hole detection score\" performance metric proves to be a valuable measure when dealing with datasets featuring a single significant topological feature. However, its effectiveness diminishes when there are multiple topological features of similar sizes in the data. Hence, this metric becomes most useful when one already has prior knowledge of the dataset's topological structure, as illustrated in Figures 4 and 5. On the other hand, if the hidden topological structures within the data remain unknown, the performance metric loses its significance, as the suppression of similar-sized features (resulting in low detection scores) could be a desirable outcome for that specific dataset. Therefore, it's essential to approach the results presented in Figure 9 with caution, as they may potentially be misleading.\n\n3. I greatly appreciate the diverse experiments conducted across various settings with different distance measures. However, what I'm particularly eager to observe is the application of your approach to a meaningful classification problem within high-dimensional point clouds. e.g., analyzing its performance in distinguishing between cancer and normal tissues in single-cell RNA sequencing datasets. Such an experiment would provide a more concrete measure of effectiveness. It would be beneficial to assess the performance of persistent homology vectorizations with various PH settings, such as Euclidean, UMAP, and your proposed distances, in this context. This approach would offer a more robust performance evaluation and further validate the effectiveness of your methodology.\n\n4. The paper's organization could be enhanced. I suggest gathering Sections 3, 4, and 5 as subsections under the \"Background\" section. Placing Section 7 before the \"Experiments\" section should enhance the flow. Additionally, collecting Sections 6 and 8 into an \"Experiments\" section might improve clarity. However, it's important to note that this suggestion is a matter of preference and should be considered a minor comment, subject to your discretion."
                },
                "questions": {
                    "value": "See Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3784/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3784/Reviewer_BdHd",
                        "ICLR.cc/2024/Conference/Submission3784/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3784/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698599160025,
            "cdate": 1698599160025,
            "tmdate": 1700522628218,
            "mdate": 1700522628218,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "RIhDGsEwmj",
                "forum": "QMQBza9BCx",
                "replyto": "iXrzgTsJPz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3784/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3784/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the constructive review!"
                    },
                    "comment": {
                        "value": "Dear reviewer BdHd,  \n\nthank you for you detailed review. We are happy that you found the problem setting we tackle \"significant\", our approach \"novel\", and our analysis \"comprehensive\". We will address your concerns in the following.\n\n**Outlier sensitivity:**  \nThis is an interesting question, but we disagree about outliers being a problem for kNN-graph-related methods. First, all methods but Euclidean distance and Fermat distances, in particular DTM-based filtrations which are designed to handle outliers, rely on the kNN graph in some way. However, they do not use the raw distances as edge weights, but aggregate these in a way that avoids sensitivity to outliers. As an illustrative example, consider effective resistance and the 2-NN graph. In case of single outlier $o$, it would have its nearest neighbors $p_1$ and $p_2$ on the main data structure, say the noisy circle. These neighbors might be far away in the Euclidean distance (which is why Euclidean distance can suffer from outliers). But the 2-NN graph on the circle is densely connected, such that the effective resistance distance between $p_1$ and $p_2$ is small. Thus, the triangle $op_1p_2$ is very slim and does not lead to a highly persistent 1D hole.  \n\nTo validate this, we now conducted additional experiments with uniformly distributed outliers in the bounding box around the noised circle (Appendix G). In low ambient dimension, outliers hurt the Euclidean distance at low noise levels a lot. Effective resistance remained much more robust against outliers.\n\nSecond, as we describe in Section 4, outliers cease to be a big problem in high-dimensional spaces, as they are necessarily extremely sparse. It is highly unlikely that an outlier point falls, say, into the middle of circle in high ambient dimensionality. We backed this up by additional experiments, showing that even the Euclidean distance is robust to adding up to 10% uniformly distributed outliers in $\\mathbb R^{50}$. Effective resistance continues to outperform the Euclidean distance even in the presence of outliers in this setting.  \n\n\n**Usefulness of our detection score:**  \nWe completely agree that our detection score is only useful if ground truth on the number of holes in the data is available. This is akin to most metrics in machine learning, which only work in reference to a ground truth. If ground truth is available, our metric works for any number of holes in the data as it targets the gap between the $m$-th and $(m+1)$-st highest persistence for $m$ ground truth holes. For the synthetic datasets ground truth is known by construction. For the single-cell datasets, we made an effort to only benchmark datasets for which the number of loops is clearly determined by the biology of the sample. For the malaria dataset there are two cycles: the parasite reproduction cycle in red blood cells and the parasite transmission cycle between humans and mosquitos as described in Section 7.2. The other five datasets are created so that the gene expression variation comes from the cell division cycle (mytosis), that is, the process of a cell dividing into two copies of itself. Therefore, we expect one loop in these datasets.  \n\n**Downstream single-cell experiment:**  \nWe are happy that your appreciate our diverse set of experiments! An experiment like the one you suggested is indeed a natural next step. Thanks for making this suggestion. However, this type of experiments is future work and could not be conducted during the rebuttal period (and would probably be of more interest for biologists, as opposed to ML researchers). In addition to using an effective form of persistent homology in a classification pipeline, we also believe that looking for holes in complex single-cell datasets would be an interesting and important research direction. But in order to trust persistent homology as a tool for exploring the structure of single-cell data, we first had to validate which approach to PH is trustworthy. This is the aim of our paper.  \n\n**Restructuring suggestions:**  \nThank you for these constructive suggestions! The section on the curse of dimensionality for persistent homology is a new contribution and not background. Since the flow from persistent homology (Section 3) to its curse of dimensionatlity (Section 4) and finally the resolution with spectral methods (Section 5) seems fitting, we kept these chapters as they were. We did, however, move the more theoretical section on the relation between spectral distances up and combined the two experimental sections, as you suggested.\n\nIf you have are any further concerns, please do let us know and we will be happy to answer them!"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3784/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700243311670,
                "cdate": 1700243311670,
                "tmdate": 1700243311670,
                "mdate": 1700243311670,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "onybWyGlL2",
                "forum": "QMQBza9BCx",
                "replyto": "RIhDGsEwmj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3784/Reviewer_BdHd"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3784/Reviewer_BdHd"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your response. I greatly appreciate your clarifications in other questions, but I disagree with your response to the outlier problem. Yes, in your toy example, the triangle will be very slim, but it will still have high persistence as some edges are long. In any case, I think the outlier problem can be resolved with additional pre-processing steps. So, I am increasing my score. Good luck with your submission."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3784/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522600413,
                "cdate": 1700522600413,
                "tmdate": 1700522600413,
                "mdate": 1700522600413,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KdVLfcLU3h",
            "forum": "QMQBza9BCx",
            "replyto": "QMQBza9BCx",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3784/Reviewer_qoEF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3784/Reviewer_qoEF"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors investigate the problem of applying persistent homology (PH) to high dimensional noisy data. They argue that in high dimension, Euclidean distance is not suitable for creating filtrations involved in computing PH since pairwise distances tend to be similar for noise generated from Gaussians. Instead, the authors propose to use knn graphs as well as their corresponding (modified version of) effective resistance or spectral diffusion distance to induce filtrations. They empirically tested their idea on a toy synthetic dataset as well as 6 single-cell RNA-sequencing datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The clarification of how the curse of dimensionality affects the computation of PH is very clear and easy to understand. This clear explanation can help guide future studies on using PH with high-dimensional data.\n- The empirical comparison between the effective resistance and the corrected effective resistance is interesting. It hints that the corrected version might be the better choice for real-world uses."
                },
                "weaknesses": {
                    "value": "- Although the effect of dimensionality is shown empirically, there is a lack of theoretical results in explaining the curse of dimensionality to PH. See the question section for more details.\n\n- While the paper provides insightful observations, the novelty aspect seems to be limited for the expectations of an ICLR publication.\n  - The major approach is to first use spectral methods for dimension reduction implicitly (as only the distances instead of the coordinates are used for PH). This is quite natural and has been studied intensively in manifold learning. I don't think applying persistent homology to data after this type of dimension reduction is novel enough for publication in ICLR.\n  - The formula in Proposition 1 is nice to have. However, as pointed out by the authors themselves, this is simply a clarification of the existing claim in von Luxburg et al. (2010a) that the corrected effective resistance is a squared Euclidean distance."
                },
                "questions": {
                    "value": "In the curse of dimensionality part, I wonder if the authors can provide some theoretical results to support their claim. For example, can they show that the length of 1-dim barcodes is bounded by some function of the dimension with high probability for the circle data with Gaussian noise?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3784/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3784/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3784/Reviewer_qoEF"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3784/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698713498595,
            "cdate": 1698713498595,
            "tmdate": 1699636335177,
            "mdate": 1699636335177,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Sr5M41WeaP",
                "forum": "QMQBza9BCx",
                "replyto": "KdVLfcLU3h",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3784/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3784/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by the authors"
                    },
                    "comment": {
                        "value": "Dear reviewer qoEF,  \n\nthank you for writing your review! We appreciate that you found our description of the curse of dimensionality for persistent homology \"very clear and easy to understand\". We address your concerns below:\n\n**Novelty**:  \nPlease confer the general comment on novelty. Briefly put, we believe that solving a new, relevant problem with a novel combination of existing methods can be a more valuable contribution than inventing a new method specific to the problem. Please note that the corrected effective resistance had NEVER been combined with persistent homology before (as we now explicitly state in the related work section). Also, all these methods have never been applied to high-dimensional data with high-dimensional Gaussian noise, which is a setting very important in many practical applications. Finally, our theoretical analysis of corrected effective resistance and its relationship to diffusion distances is also novel.\n\n**Explicit formula for corrected effective resistance:**  \nOur explicit formula enabled us to relate corrected effective resistance to diffusion distances. Using it, we found, for instance, that the corrected effective resistance decays eigenvectors with high eigenvalues more aggressively than the uncorrected version, but less aggressively than diffusion distances. We consider it an important theoretical result of our paper.\n\n**Theoretical treatment of curse of dimensionality:**  \nThis is a very interesting, but difficult question, and is beyond the scope of this rebuttal. Our Section 4 provides a qualitative treatment of this curse of dimensionality (which we have not seen explicitly discussed in the literature before). A quantitative treatment remains for future work. In fact, motivated by your question, we started working on it and have some promising ideas for a theoretical treatment, but would need more time to work on it than the rebuttal period allows.\n\nIf you have are any further concerns, we will be happy to answer them!"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3784/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700243167503,
                "cdate": 1700243167503,
                "tmdate": 1700243167503,
                "mdate": 1700243167503,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cxuQMXcYpD",
                "forum": "QMQBza9BCx",
                "replyto": "Sr5M41WeaP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3784/Reviewer_qoEF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3784/Reviewer_qoEF"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for addressing my comments. However, I stand by my point that the current version of the paper is lacking novelty. \n\nTo summarize, the paper posits that (1) persistent homology is affected by curse of dimension, (2) spectral methods could be applied to reduce dimension (the authors didn't present in this way but this is basically what the spectral / effective resistance methods are doing), (3) apply persistent homology afterwards. While the introduction of formula of corrected effective resistance in section (2) is interesting, I believe that a more substantial contribution is required in (1) to elevate the novelty of the paper. While I am pleased that the authors have considered enhancing section (1) per my previous suggestion, as it stands, I decide not to change my score."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3784/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700696426110,
                "cdate": 1700696426110,
                "tmdate": 1700696426110,
                "mdate": 1700696426110,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "umhwInLBMx",
            "forum": "QMQBza9BCx",
            "replyto": "QMQBza9BCx",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3784/Reviewer_k35W"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3784/Reviewer_k35W"
            ],
            "content": {
                "summary": {
                    "value": "The article presents a new approach to compute persistent homology of given set of data points. The approach builds the simplicial complexes using spectral distances, such as diffusion distance and effective resistance, on the k-nearest-neighbor graph of the data. The paper suggests persistent homology computed based on spectral distances correctly detect the topology of the data even in the presence of high-dimensional noise. A closed form formula is also derived for the effective resistance (distance) based on the eigendecomposition of the kNN graph Laplacian. Numerical results are presented on different synthetic and single cell RNA-sequencing datasets to illustrate the performance of the proposed method."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Strengths:\n1. The paper demonstrates that spectral distances such as diffusion distance and effective resistance perform well in detecting cycles in high-dimensional noisy data.\n2. The eigendecomposition based effective resistance formula is interesting and might be of independent interest.\n3. The paper presents several interesting numerical experimental results."
                },
                "weaknesses": {
                    "value": "Weakness:\n1. The presentation can be improved. The paper might be hard to follow for non experts.\n2. The main methodology proposed is not well-defined.\n3. The novelty and advantages of the proposed method are not clear."
                },
                "questions": {
                    "value": "The paper studies an interesting problem of cycle detection in high dimensional noisy data. The findings related to the use of different distance metrics is interesting.\n\nI have the following comments:\n\n1. The presentation can be improved. Currently, the main methodology and several aspects are not at all clear.\n\nFirst, it appears the loops and cycles are detected using a detection score that depends on what is termed as m-th most persistent features . But it is not clear what does persistences p_m of the m-th most persistent features mean? How are these calculated? How are these persistent features related to the loops/holes?  Given a distance metric, how are these features and the detection score computed? If the underlying graph structure for the input data points are not given, how is the k-NN graph constructed? These details are missing.\n\n\nNext, typically, in persistent homology (as described in the intro), the resolution (radius of the ball around the datapoints) is increased, and the Betti number or other homology related features are computed. However, in this paper, it is not clear what exactly is computed. How are the holes/loops detected and what is the persistence (birth-death of holes) with respect to. Is the resolution scale with respect to the different distance metrics considered? If so, what is the role of the K-NN graph? The graph connection is predefined to find these distances in this case. \n\n2. In the related works section, many previous works have been mentioned where similar distance metrics have been used for persistence\nHomology. How does the proposed method differ from them is not clearly described.\n\n3. The advantage of the proposed method is also not clear. It appears some of the recent dimensionality reduction methods such as t-SNE and UMAP seem to perform better at detection holes than the proposed method and these method should also have lower computational cost. \n\n4. In the datasets, the dimension of the holes detected is not clear. Note that a torus has 2 2D holes and 1 3D hole. High dimension holes are formed by higher order simplices (a k-dimensional hole has (k-1)-simplices as its boundary). Here cycles/holes only seem to consider edges, and not higher order simplices. Is this correct?\nHow is the Vetoris-Rips complex constructed? Given n points, the complex can have large number of higher order simplices, and detecting high dimensional holes is very expensive (can be exponential cost and is an NP hard problem).\nAgain, it is hard to understand due lack of details.\n\nOverall, the merits of the paper is difficult to figure out."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3784/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698791694995,
            "cdate": 1698791694995,
            "tmdate": 1699636335057,
            "mdate": 1699636335057,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "QHDDq8KmI6",
                "forum": "QMQBza9BCx",
                "replyto": "umhwInLBMx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3784/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3784/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by the authors (1/n)"
                    },
                    "comment": {
                        "value": "Dear reviewer k35W,  \nthank you for reading our paper and writing the review! Please note many of the details you asked about are all present in the manuscript. Our overall approach is conceptionally standard and close to previous works such as Bendrich et al. 2011, Anai et al. 2020, Fermandez et al. 2023: We compute a pairwise distance matrix, build the filtered Vietoris-Rips complex based on that distance matrix, and compute persistent homology of this filtered simplicial complex. Computationally, this was done using the `ripser` library. We only needed to compute various distances matrices and pass them to `ripser`. We have described this approach in detail in Section 3.\n\nThat said, we will make an effort to resolve any confusion in our replies below!\n\n>But it is not clear what does persistences p_m of the m-th most persistent features mean?\n\nWe describe in Section 3 that the persistence of a feature is the difference between its death and birth time: \"Each hole has associated birth and death times $(\\tau_b, \\tau_d)$, i.e., the first and last filtration value $\\tau$ at which that hole exists. Their difference $p = \\tau_d - \\tau_b$ is called the *persistence* or *life time* of the hole and quantifies its prominence.\"\n\nThe m-th most persistent feature is that with the m-th highest persistence.  \n\n\n>How are these persistent features related to the loops/holes?\n\nWe describe persistent homology in Section 3. A $\\delta$-dimensional feature that persists from $\\tau_b$ to $\\tau_d$ corresponds to $\\delta$-dimensional hole in the simplicial complex between filtration values $\\tau_b$ and $\\tau_d$ which in turn can be thought of $\\delta$-dimensional holes that persist in a union of balls around the data points of radius $\\tau_b$ to $\\tau_d$. We stress that we explain this in Sec.3.\n\n\n>Given a distance metric, how are these features and the detection score computed?  \n\nWe use the package `ripser` to compute the persistence diagram, as stated in Section 3 and Appendix F. This is a standard package for the computation of persistent homology. Given a pairwise distance matrix, ripser computes the persistent homology of the associated Vietoris-Rips complex. The output, a persistence diagram, contains the information about detected holes / loops. When we talk of the persistence of a feature, say, for effective resistance, we mean a feature that was computed by the ripser package when providing it with the effective resistance distance as input.  \nWe describe the computation of our detection score in Section 7 (paragraph \"Performance metric\"): If the ground truth number of holes of dimension $\\delta$ is $m$, we take the persistences $p_m$ and $p_{m+1}$ of the $m$-th and the $(m+1)$-st most persistent feature in dimension $\\delta$ and compute the ratio $s_m=(p_m -p_{m+1}) / p_m$ as our detection score. In particular, all these details of our approach are present in the manuscript."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3784/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700242813508,
                "cdate": 1700242813508,
                "tmdate": 1700242813508,
                "mdate": 1700242813508,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zNLutdj9vs",
                "forum": "QMQBza9BCx",
                "replyto": "umhwInLBMx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3784/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3784/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by the authors (2/n)"
                    },
                    "comment": {
                        "value": "> How are the holes/loops detected and what is the persistence (birth-death of holes) with respect to. Is the resolution scale with respect to the different distance metrics considered?  \n\nHoles are detected with the ripser package (Section 3). Indeed, the resolution scale is with respect to the different distance metrics considered. This is explained in Section 3, where we write that the ball-growing procedure is made computationally tractable by the use of a filtered simplicial complex, that we only work with the Vietoris-Rips complex, and that for this complex it suffices to specify a pairwise distance metric. Later in Section 7, paragraph \"Distance measures\" we write that we consider twelve distances as input to persistent homology.  \n\n\n>  If so, what is the role of the K-NN graph?  \n\nAll distances other than Euclidean and Fermat depend on the kNN graph in various ways. We described the all distances briefly in Section 7 and in detail in Appendix C. Note that the input is always a point cloud, never a predefined graph. If a distance relies on the kNN graph, we compute it from the point cloud (usually with a parallelized brute-force approach implemented with the package `pykeops`). The exact role of the kNN graph depends on the distance. For instance, the distance we call Geodesics is the shortest path distance on the kNN graph.  \n\n> The graph connection is predefined to find these distances in this case.    \n\nWe do not quite understand what you mean by this sentence. Could you please elaborate?\n\n\n> How does the proposed method differ from them is not clearly described.  \n\nOverall, our paper is about evaluating which (possibly existing) methods perform well for detecting holes in the presence of high-dimensional noise, a problem setting that has not been addressed as we state in the first paragraph of the related work section. We added a sentence to the related work section clarifying that persistent homology had so far never been combined with the corrected effective resistance of von Luxburg et al. 2010a, one of the methods that we find performed best in our problem setting.\n\n\n> t-SNE and UMAP seem to perform better at detection holes and these method should also have lower computational cost.  \n\nPlease see the general comment on the performance of t-SNE and UMAP.  t-SNE and UMAP are typically *slower* that effective resistance or diffusion distance. Both first compute the kNN graph of the data, but t-SNE and UMAP then perform an iterative optimization scheme, while effective resistance only needs to compute the pseudoinverse of a matrix and diffusion distances only need to power a matrix.\n\nFurthermore, t-SNE and UMAP are typically used for 2D embeddings, and it is not possible to detect higher-order homologies (e.g. H2 homologies such as voids) using a 2D embedding.\n\n\n> Here cycles/holes only seem to consider edges, and not higher order simplices. Is this correct?   \n\nNo, this is not correct. We always consider simplices of the dimension needed to compute the type of holes (loops, voids) that we are interested in. For instance, if we compute 2D holes (voids), we consider simplices of dimensions 1, 2, and 3. This is handled by the ripser package.  \n\n> How is the Vetoris-Rips complex constructed?  \n\nThe Vietoris-Rips complex is a standard construction in topology. We describe it in Section 3: \"... the Vietoris\u2013Rips complex, which includes an n-simplex (v0, v1, ... , vn) at filtration time $\\tau$ if the distance between all pairs vi, vj is at most $\\tau$. Therefore, to build a Vietoris\u2013Rips complex, it suffices to provide pairwise distances between all pairs of points.\"\n\nIn particular, the Vietoris-Rips complex on $N$ points can contain simplices of dimension up to $N-1$. Whether a particular simplex, even a high-dimensional one, is contained at time $\\tau$ only depends on pairwise distances. The construction of the Vietoris-Rips complex is handled by the `risper` package. One of its arguments is the maximal feature dimension that should be computed. Based on this, it only creates those simplices necessary, so that in practice very high-dimensional simplices are not constructed.  \n\n> Given n points, the complex can have large number of higher order simplices, and detecting high dimensional holes is very expensive.  \n\nAs mentioned above, this part is abstracted away by the ripser package. However, since we always set a maximal dimension for the topological features that should be computed (2 for void detection and 1 for loop detection), no simplices of dimension 4 or higher are needed. Indeed, we observe that then we compute persistent homology of 2D holes (voids) the run time increases a lot. We discussed this in Section 8: \"One limitation of persistent homology is its computational complexity. ....\"\nWe also reported exemplary run times in Table S3, again showing that void detection is much more costly than loop detection."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3784/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700242999885,
                "cdate": 1700242999885,
                "tmdate": 1700243023578,
                "mdate": 1700243023578,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CDIThNZSOQ",
                "forum": "QMQBza9BCx",
                "replyto": "umhwInLBMx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3784/Reviewer_k35W"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3784/Reviewer_k35W"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their thorough responses to all reviewers' comments. These are very helpful, and make many of the details related to the methodology now more clear. \n\nHowever, I think the current version of the paper falls short due to the following reasons, and I encourage the authors to consider these points when revising the draft:\n\n(a) It appears the readers of the paper are expected to know what the ripser library package does, and should be familiar with the \"standard techniques\" presented in the existing literature listed in this response to understand and follow the paper. Many of the details in the responses to the reviewers are clearly missing.\n\n(b) In the response above, authors say \"We have described this approach in detail in Section 3.\"\nHowever, I do not see many of the details that are discussed here in the response, in section 3 (which is half a page) of the paper. In the section, there is just a single sentence, \"We compute persistent homology via the ripser package\", and the readers are expected to know what this package does.\n\n(c) Also, in section 3 and the response above, it is suggested, \"we use the Vietoris\u2013Rips complex, which includes an n-simplex ...\" As noted by the authors above, given $N$ points, a Vietoris\u2013Rips complex can include simplices of order up to $N-1$. However, it appears the full Vietoris\u2013Rips complex (with simplices of all orders) is never constructed, and only a simplicial complex with simplices of order up to $k=2$ or $3$ is considered. This makes sense (due to the cost), but was never clear in the paper.\nSimilarly, the paper just says that persistent homology involves computing the homology groups of the union of all balls in order \nto find the holes. The dimension of these holes are not specified  (mention of $\\delta$-dimensional feature and holes only appear here in the response). Note that the general definition of  persistent homology is constructing the full simplicial complex and finding/counting holes of all dimensions that persist across different scales $t$. The authors' response above suggests in the paper $\\delta =1$ or $2$ are considered.  Again, this is perfectly fine (since higher order holes are expensive to estimate), but is never discussed in the paper.\n\nSince all these details are currently missing in the paper, a reader would just assume the full complex and holes of all dimensions are computed. Since constructing the full Vietoris\u2013Rips complex and computing all Betti numbers will be very expensive (could be of exponential cost), a natural conclusion is to assume that the overall cost of the proposed method will be extremely high.\n\n(d) The role of k-NN graph as related to persistent feature computation is still not clear to me, and section 7 does not contain much details related to this as suggested in the authors' response above. \n\n(e) In the response above, authors say \"our paper is about evaluating which (possibly existing) methods perform well for detecting holes in the presence of high-dimensional noise\". This should have been the main premise of the presentation, but in the abstract and introduction, this fact is never made clear. Therefore, naturally reviewers have asked about novelty and relation to existing methods.\n\nOverall, the current version of the paper is very difficult to follow and the main contributions, methodology, and significance are all not really clear, as also suggested by other reviewers' comments. Hence, I am keeping my current score."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3784/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700630581819,
                "cdate": 1700630581819,
                "tmdate": 1700659706302,
                "mdate": 1700659706302,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QA3hQOTeHA",
                "forum": "QMQBza9BCx",
                "replyto": "umhwInLBMx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3784/Reviewer_k35W"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3784/Reviewer_k35W"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for the response and the changes made to the paper. \n\nBut, I think the authors are missing the main point reviewers are trying to make, that the current paper presentation does not clearly convey different aspects (e.g., main contributions/premise, methodology used, and significance) of the presented work. \n\nOne of the key duties of reviewers is to provide suggestions to help improve the paper.\n\nMentioning something in some part of the paper, is not equivalent to a clear explanation or discussion, right?\nReaders should not be excepted to guess, or go back and forth/search for basic key details. For example, as the authors above say, the fact that only 1D and 2D holes are computed, is just mentioned (and one had to search for it) as a pass-by sentence, but in the main methodology section, this was not discussed. \nSame with the k-NN graph, indeed it is mentioned at several places, but the nice discussion presented in the responses to reviewers (that a $k$-NN graph is constructed from point cloud using certain package, then the spectral distance methods are applied to this graph, etc) was missing, and its role was not clear to the readers. \n\nRegarding the ripser library, I agree a detailed explanation of the package is  certainly not necessary. But, since the study heavily depends on this package,  at least a few sentences on what does it take as inputs and arguments (e.g., the maximal feature dimension), how are the resolution scales defined for persistence (like how many levels does it consider), what does it output for persistent homology (is it a list of holes, how do we get m-th persistent features, etc) should be provided. Right now, we just have a single sentence about this. Without these basic details, it is very difficult to understand the methodology used, right? \n\nSame with the main premise of the paper. The two sentences picked by the authors above might allude that the paper does some kind of comparison. However, the paper is not set up as \"a comparison study of existing methods for detecting holes in the presence of high-dimensional noise\". There are other contradicting sentences which imply differently. For examples,  in the intro, it says \"we suggest to use persistent homology with distances based on the spectral decomposition of the kNN graph Laplacian,\nsuch as the effective resistance ....\", which can be interpreted as a new proposal which was not explored before. In the abstract, the term \"As a remedy, ..\" (which is conveniently skipped above) suggests a new solution is proposed. \nI feel some of the comments by the reviewers are rooted in this fact, that this main premise (which is well explained in the general comment/response by the authors) was not really clear in the paper."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3784/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700667520526,
                "cdate": 1700667520526,
                "tmdate": 1700669534883,
                "mdate": 1700669534883,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LLjshU2eg7",
            "forum": "QMQBza9BCx",
            "replyto": "QMQBza9BCx",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3784/Reviewer_TJmS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3784/Reviewer_TJmS"
            ],
            "content": {
                "summary": {
                    "value": "This paper aims to address the challenge that the persistent homology (PH) faces for noisy high-dimensional data, by replacing the standard Euclidean or other common distances with the diffusion distance and effective resistance."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "(S1) The problem is relevant.\n(S2) The paper is well written, resulting in a nice and enjoyable read.\n(S3) Experiments include a number of synthetic and real-world data."
                },
                "weaknesses": {
                    "value": "(W1) Some (main) statements might not be correct or precise enough, placing some doubts on the overall paper, see the questions below. I will raise my score if these issues are resolved.\n\n(W2) The results are not very convincing: for the synthetic data, tSNE and UMAP seem better or equally good as the proposed distances but are for some reason shown only for 1 out of 7 data sets, and for the real-world data it is not clear how the ground truth is established.\n\n(W3) The contribution might not be strong enough for this venue (e.g., PH on diffusion distance or effective resistance is not novel)."
                },
                "questions": {
                    "value": "(Q1) Are you trying to address the issue of Gaussian noise or outliers, or both? Be precise and consistent.\n\n(Q2) The main issue with Gaussian noise for high-dimensional data is that the small noise adds up over the many coordinates, for Euclidean l_2 distance. A natural adjustment would be to rather consider l_infty, could you include these experiments (at least for the noisy ring that you consider the most), or at least discuss why this would not be a suitable approach?\n\n(Q3) What do you actually mean with \u201cring\u201d, the main example used throughout the paper? If this the circle (Figure S1), I would suggest to rather use that terminology. If this is an annulus, then Figure S1 should be adjusted. If by noisy ring you mean a circle with Gaussian noise, then it is probably clearer to use the latter formulation. On a related note, I think it would be good to include an additional figure that illustrates the different levels of noise (e.g. sigma in {0, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35}) you consider in the experiments, on (2D MDS embedding of) an example shape (like the circle). This can help to get an idea of the level of noise that the different approaches can handle.\n\n(Q4) In Related work, you write that the previous approaches in the literature amount to replacing the Euclidean distance with a different distance matrix. However, the DTM filtration does not simply do this, it rather considers a weighted Vietoris-Rips filtration with nonzero filtration function values on the vertices too. These values correspond to the average distance from a number of nearest neighbors, so that outliers have a large filtration function value and appear only later in the filtration, i.e., they are smoothed out in the process. This does not influence your results, since you only consider 1- and 2-dimensional PH, and the edges that could create loops and voids appear only after the incident vertices would appear. However, this would make a huge difference for 0-dimensional PH, since the outliers would result in persistent connected components with Vietoris-Rips filtration, the issue which is avoided with DTM (which is not clear with your current description). This needs to be made more precise. Revise if this is the case for other filtrations too.\n\n(Q5) How do you define the adjacency matrix A in your experiments?\n\n(Q6) Has the corrected version of the effective resistance also already been introduced in the literature (if so, provide a reference), or is this your contribution?\n\n(Q7) Why do you not show the results for tSNE and UMAP in Figure 5? These seem to perform extremely well on the noisy ring (Figure 4), and definitely better than Fermat or DTM that you do include. Overall, you show results for different subsets of the 12 distances across different figures.\n\n(Q7) When discussing the other approaches in the literature (such as Fermat or DTM), could you make it more explicit that these have not been introduced to tackle the particular issue that you aim to address (noise in high dimensions)? (For example, the idea behind DTM is to smooth out the outliers out, but you do not seem to consider these in your experiments?) Otherwise, it seems you are overstating your contribution, as it appears that you outperform the other approaches that were developed to tackle the same challenge. You even imply this by referring to the other methods as \u201ccompetitors\u201d.\n\n(Q8) You group the different distances into density-based, graph-based (distances computed on kNN graph), embedding-based and spectral. However, are the DTM, Fermat and Core also not computed on the kNN graph (whereas you consider these to be density-based)? In the Discussion, you also explicitly write that spectral methods are based on the kNN graph, so I guess you need to rethink the naming and descriptions of the different groups?\n\n(Q9) The two proposed distances, effective resistance and in particular diffusion, fail terribly in detecting both the 2 loops and the 1 void for torus, even in the case of no noise (Figure 5), but you almost completely ignore this?\n\n(Q10) Figure 5 shows a large variance for the diffusion distance and effective resistance, in particular for eyeglasses and torus. This should be at least briefly discussed, and it would be nice to include an illustrative figure with a few different random walks between two interesting points (e.g. on eyeglasses); ideally, other distances could be visualized too.The number of different random walks also grows with the underlying dimension, since there is many more directions one could take to reach from one point to another? Can you also comment on this, because it makes one wonder why would such distances be reasonable/even suggested for very high dimensional spaces?\n\n(Q11) Where is the variance for Euclidean distance coming from in the left plot of Figure 6?\n\n(Q12) Why do you consider the 2D embedding space for the embedding-based distances, if you also look into 2-dimensional PH?\n\n(Q13) Why is the closed-form formula for effective resistance useful (in your experiments or work)? Motivate this/explain the relevance.\n\n(Q14) What are the dimensions of the real-world RNA-sequencing data? This should be explicitly stated, since high dimensionality is precisely the main focus of your work. This is only mentioned for 1 out of 6 data sets and only in the appendix, but this information should be in the main text.\n\n(Q15) \u201c\u2026 DTM produced only rough approximations (Figure 8b)\u201d What exactly do you mean here, the 1-dimensional PD wrt DTM in Figure 8 clearly identifies the two loops? What\u2019s more, it seems that the loop score s2 would be the best for DTM, since the second most persistent loop is here the furthest from the third most persistent loop (close to the diagonal)? I do not see a clear connection between Figure 8 and first plot in Figure 9.\n\n(Q16) How do you assess the ground truth (the actual number of loops) in the real-world data (besides Malaria data)? \n\n(Q17) You write \u201cpersistent loop(s) was/were likely not correct\u201d, or later, \u201carguably incorrect loops\u201d but you do not explain this further. In other words, how do you determine if a bar in Figure 9 is hatched, since, as you yourself write \u201ceach homology class has many different representative cycles, making interpretation difficult\u201d?\n\n(Q18) Definition of the DTM function in Appendix B is weird, can you provide a reference? In the paper by Anai et al, it seems that only the case of your p=2 is considered? Are the nearest neighbors x_i1, x_i2, \u2026, x_ik ordered according to increasing distance from x_i? If so, please specify. How does it make sense to define dtm_i = ||x_i \u2013 x_ik || (when your p=infty)? Strangely enough, all your main experimental results consider p=infty. On a related note, it is not clear to me why the DTM performs worse than the Euclidean distance in Figure S4? This makes me question how you chose the parameter values for which to report the results, and whether you particularly selected the parameters where the other approaches perform poorly.\n\n(Q19) \u201cWe omitted DTM as all settings got filtered on all datasets.\u201d What does this mean? \n\n(Q20) Interpret all the figures in Appendix G, what do we learn from them? This is currently only done for Figure S3, in its caption.\n\n(Q21) Why is tSNE performing so poorly in Figure S5, even when there is no noise?\n\n(Q22) What about stability?\n\n(Q23) Multiparameter persistence is often suggested to remedy noise, by considering a bifiltration with respect to both distance to the point cloud and density estimates. How do you expect this approach to work in high dimensions?\n\n\nMinor remarks:\n\n-\tMention the homological dimension in the captions of all figures that include persistence diagrams (i.e., stress \u201c1-dimensional persistence diagram\u201d).\n\n-\t\u201c\u2026. distances due to noise dominate the distances to the ring structure\u201d Is this really true, we can still see the ring in Figure 3d?\n\n-\tDescribe the hitting time H_ij more precisely. Is the the sum of edge lengths, or the number of edges?\n\n-\tI assume that the matrix I_d is  matrix of ones (every entry is equal to 1), but this should be made explicit, as this notation is common for the identity matrix (with the non-diagonal entries equal to 0).\n\n-\tFor consistency and clarity, replace \u201cneg. control\u201d with \u201c0 loops\u201d in Figure 5?\n\n-\tWhen you mention t in Section 7, remind the reader what this t represents. Note also that you use t to denote both the filtration scale (could maybe be replaced with r), and for the number of random walk steps.\n\n-\t\u2026 D = 2, but D is a matrix?\n\n-\tProvide a reference for the computational complexity for PH. Should it include delta+1, or delta+2?\n\n-\tBe consistent between capital case vs. lower case for the paper titles in the References.\n\n-\tThe notation in Appendix C could likely be improved: the distances are functions over the vertices rather than of its parameters, i.e., it would be more common to denote e.g. Fermat and DTM respectively as d^F_p(x, y), D^DTM_k, p, xi(x, y).\n\n-\tIn Appendix D, for the eyeglasses data set you write that the two line segments are of length 0.53, separated by 0.7 units linking up the two ring segments, but the width of the rectangle in Figure S1 seems larger than its height?\n\n-\tFor better clarity \u201c, and then added isotropic Gaussian noise samples from \u2026\u201d should probably be the last sentence in this paragraph, since the rest of it discusses the orthogonal embedding? \n\nTypos:\n\n-\tna\u00efve -> naive throughout the paper?\n-\tpersistence homology -> persistent homology\n-\twe mapped each\u2026 -> We mapped each"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3784/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3784/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3784/Reviewer_TJmS"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3784/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698791988643,
            "cdate": 1698791988643,
            "tmdate": 1699636334974,
            "mdate": 1699636334974,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "326Y73Wvef",
                "forum": "QMQBza9BCx",
                "replyto": "LLjshU2eg7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3784/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3784/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the thorough review! (1/n)"
                    },
                    "comment": {
                        "value": "Dear reviewer TJmS,  \nmany thanks for your very detailed and helpful review! We really appreciate all the concrete suggestions and questions. They prompted many improvements to the manuscript. We will address your questions below.\n\n**(W1) Clarifications:**  \nWe clarified numerous aspects of the paper, and maintain that our statements are correct. If any questions remain, we are happy to address them as well.\n\n**(W2) Performance of $t$-SNE and UMAP:**  \nPlease see our general comment on the performance of $t$-SNE and UMAP (as this point came up in several reviews).\n\n**(Q7a) Exclusion of embedding methods from Figure 5:**  \nWe excluded the $t$-SNE and UMAP results from Figure 5 partly for the above reasons and partly because this already busy figure would have become messy otherwise.  \nWe ran a large number of experiments on several datasets. Therefore, we deliberately chose different methods and datasets for the figures in the main text to illustrate the key take-aways of our analysis in a concise way. Note that we show the results of all methods on all dataset, inlcuding $t$-SNE and UMAP in the added supplementary figures S10-S21.\n\n**(Q21) $t$-SNE performance with low perplexity:**  \nThe reason for the dip of the $t$-SNE embedding method for low noise and low perplexity is a curvy embedding of the circle with various bottlenecks that give rise to additional features of high persistence. We included a new Figure S9 explaining this in more detail. \n\n**(W3) Novelty:**  \nPlease, see statement on novelty to all reviewers.\n\n**(Q1) Focus of the paper:**  \nOur work addresses high-dimensional Gaussian noise, however we added an experiment with outliers in the revised version, following reviewer BdHd's concern (Appendix G). As stated at the end of Section 4 and the beginning of Section 9, moving from low to high ambient dimension, outliers cease to be an issue for persistent homology, instead Gaussian noise becomes problematic. For this reason, we focus on Gaussian noise. As can be seen in the new Fig. S6, adding up to 10% outliers impacts all methods only minimally in high ambient dimension. While not the focus of our work, please note that effective resistance also handles outliers better than Euclidean distance in low ambient dimesion (Figure S6).\n\n\n**(Q7b) Adequate presentation of DTM and Fermat:**  \nYou are right that DTM and Fermat distances were introduced to handle outliers, as we write in the related work section and Section 7. We have added a sentence in Section 7 stressing that we apply them to a different type of noise in our paper.\n\n**(Q2) Using $\\ell_\\infty$ to deal with noise:**  \nThank you for this suggestion. We ran experiments on our toy datasets for $\\ell_p$ distances with $p=3,5,7, \\infty$. The results are close to or worse than for the Euclidean distance (Figure S21). We believe that the reason for this is that for any $p\\neq 2$ the $\\ell_p$ distance favors directions and is not isotropic anymore. However, we place our toy datasets in a random orientation in ambient $\\mathbb R^{50}$, so that the directions in which the dataset varies meaningfully are not aligned with the coordinate dimensions.  \n\n**(Q3) Term \"ring\":**  \nThank you for spotting our imprecision. When speaking of \"ring\" we always meant a circle (plus Gaussian noise). We have changed all uses of \"ring\" to a more precise phrasing, as suggested.  \n\nMoreover, we have included Figure S4 that shows the circle with different levels of Gaussian noise in 2D as well as 2D MDS embeddings of the circle with different levels of Gaussian noise in 50D.\n\n**(Q4) Node weights in DTM:**  \nWe deliberately omitted this detail since, as you acknowledge, it does not matter for our experiments and omitting it simiplified the exposition. In the interest of accurarcy, we have added this aspect to the detailed description of DTM in Appendix C. We tweaked the relevant sentence in the related work to \"The main idea of most of these suggestions is to replace the Euclidean distance with a different distance matrix, before running persistent homology. \""
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3784/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700242113688,
                "cdate": 1700242113688,
                "tmdate": 1700242113688,
                "mdate": 1700242113688,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UjIXqGffAL",
                "forum": "QMQBza9BCx",
                "replyto": "LLjshU2eg7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3784/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3784/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the thorough review! (5/n)"
                    },
                    "comment": {
                        "value": "**(Q23) Multiparameter persistence:**  \nMultiparameter persistence is an interesting method and might offer benefits in the high-dimensional setting. It has been employed to spatial transcriptomics data in  Benjamin, Katherine, et al. \"Multiscale topology classifies and quantifies cell types in subcellular spatial transcriptomics.\" arXiv preprint arXiv:2212.06505 (2022).\n\nHowever, its output is not as readily interpretable as the persistence diagrams in single parameter persistent homology, which is why we limited out study to this more established method.\n\n\n**Minor 1. Miscellaneous:**  \nWe added the feature dimension to all persistence diagram, changed the filtration parameter to $\\tau$, changed the notation in Appendix C, replaced \"(neg control)\" by \"(0 loops)\", and inserted a line break after \u201c, and then added isotropic Gaussian noise samples from \u2026\u201d. Thank you for these suggestions!\n\n**Minor 2. MDS of highly noised circle:**  \nIt is true that one can still see a hole in the middle of Figure 3d. But this is a 2D MDS and cannot capture the exact shape of the data in $\\mathbb R^{50}$. Indeed, we see in Figure 3c that the feature for the correct loop disappears into the cloud of noise features (green) and in Figure 1a,b we see that the most persistent loop actually does not wrap around the noisy circle.  \n\n**Minor 3. Definition of hitting times:**  \nThe hitting time $H_{ij}$ is the expected number of edges that a random walker starting at node $i$ traverses before reaching node $j$ for the first time, as stated in Definition 2. We changed the ambiguous term \"average time\" in the main text to \"average number of edges\".  \n\n**Minor 4. Notation for identity matrix:**  \nBy $\\mathbb I_d$ we always denote the $d\\times d$ identity matrix and never the matrix of all ones.  \n\n**Minor 5. Overloaded variable $D$:**  \nWe used $D$ both to denote the embedding dimension of Laplacian Eigenmaps and the degree matrix of the symmetric kNN graph. We changed the former to $\\tilde{d}$. Thanks for your keen eye!\n\n**Minor 6. Complexity of persistent homology:**  \nWe added Myers, Audun D., et al. \"Persistent homology of coarse-grained state-space networks.\" Physical Review E 107.3 (2023): 034303 as reference for the computational complexity of persistent homology. The term $d+1$ is correct: The complexity of the reduction algorithm is $\\mathcal{O}(N^3)$, where $N$ is the number of simplices in the simplicial complex. A Vietoris-Rips complex can contain at most $\\binom{n}{\\delta}$ simplices of dimension $\\delta$. To compute $\\delta$-dimensional homology one needs the simplices of dimension $\\delta-1, \\delta, \\delta+1$. Finally, \n$$\n\\sum_{i=1}^{\\delta+1} \\binom{n}{i} \\leq \\sum_{i=1}^{\\delta+1} n^i \\in \\mathcal{O}(n^{\\delta+1}).\n$$\n\n**Minor 7. Capitalization of references:**  \nWe have originally capitalized the titles of references as in the original publications, but we are going to change it to a unified format in the next days.\n\n**Minor 8. Dimensions of the eyeglasses dataset:**  \nYou are right about the eyeglasses dataset. The length of the straight segments is actually $1.06$. We corrected the text."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3784/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700242641899,
                "cdate": 1700242641899,
                "tmdate": 1700243334307,
                "mdate": 1700243334307,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hUvvi6zWmw",
                "forum": "QMQBza9BCx",
                "replyto": "UjIXqGffAL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3784/Reviewer_TJmS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3784/Reviewer_TJmS"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate and thank the authors for the very detailed responses. If possible and allowed by the Area Chair, could you please update a revised version with all the improvements you made clearly highlighted? Unfortunately, I did not have the time to go through all the new results in detail, but let me at least provide a summary of main comments for now:\n\n-\tDescribe your contribution and novelty more clearly in the paper, as you do in the general comment here.\n-\tThe main idea behind introducing Fermat is not (only) to tackle outliers, please correct this (in Section 7, and elsewhere if needed). In the original paper, you can see that the authors mainly want to incorporate the information about the density, to e.g. detect a single 1-dimensional loop in the eyeglasses data even when no noise is present (rather than 2 loops with the Euclidean distances).\n-\tSome of the figures in the revised version, such as Figure 3, S2, S4, S5 are for me not displayed correctly?\n-\tYou mention a number of times that t-SNE and UMAP are primarily used for 2D embeddings, can you provide a reference? I don\u2019t see why 2D holes could not be assessed from the 3D embedding, have you tried this? On a related note, I don\u2019t think that the comment \u2018we wanted to offer alternatives to t-SNE and UMAP, to separate \"visualization\" from \"topological analysis\"\u2019 makes a lot of sense, since t-SNE and UMAP are not used for visualization in your paper, but precisely as a part of the TDA, i.e., PH pipeline (to calculate the input distance matrix).\n-\tAdjacency matrix: What exactly do you mean with \u201cif edge ij is a part of the graph\u201d? If i and j are point cloud points, the weight of the edge between them is defined as their distance, i.e., we could consider a fully connected graph?\n-\tIdentity matrix: If I_d is the identity matrix, that means that you add Gaussian noise only in one coordinate for each point cloud, why?\n-\tUnfortunately, I still did not have the time to carefully go through your detailed explanation about the results for the DTM filtration, and the related \u201cthresholding\u201d technique that you use, I hope to be able to do this in the following days. \n-\tWhen I asked about the stability, I was referring to the stability theorems for PH: How is the upper bound for d(PD(X), PD(X\u2019)), where X\u2019 is the point cloud X with noise, going to be affected when you consider the two distances you propose?"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3784/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700588530717,
                "cdate": 1700588530717,
                "tmdate": 1700588530717,
                "mdate": 1700588530717,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]