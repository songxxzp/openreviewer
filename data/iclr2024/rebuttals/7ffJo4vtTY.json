[
    {
        "title": "Robust multimodal models have outlier features and encode more concepts"
    },
    {
        "review": {
            "id": "aTLCABnTCG",
            "forum": "7ffJo4vtTY",
            "replyto": "7ffJo4vtTY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3748/Reviewer_8h4M"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3748/Reviewer_8h4M"
            ],
            "content": {
                "summary": {
                    "value": "The goal of this paper is to characterize CLIP-style models in terms of their weights and hidden representations. This is motivated by these model\u2019s superior generalization ability, which suggests that their internal representations are qualitatively different than smaller models trained on less data. The work finds that robust models exhibit outlier features, that is, individual neuron activations with significantly higher magnitude than the average. The work also tries to quantify the number of distinct concepts that these models learn (relative to models either finetuned or trained from scratch on ImageNet), with results suggesting that models with CLIP-training on large datasets learn more concepts."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- **Motivation:** As greater and greater resources are poured into training frontier models, developing an understanding of what makes these models so much more robust than their counterparts trained on smaller datasets becomes a more and more pressing problem. The approach taken by this paper, attempting to characterize robustness, through model structure alone, is promising as a low compute way of assessing the robustness of a model and a starting point to finding a mathematical basis for robustness.  \n- **Clarity:** The work is mostly well-written and well-structured. The reviewer particularly appreciated the way that the work summarizes key takeaways in colored boxes that are easy to find. The visualizations and plots were well-thought-out and communicated their information efficiently.\n- **A strong premise:** Though the reviewer had some concerns around the way the experiments were run and the conclusions that were drawn from them (see the \"Weaknesses\" section), the premise is very interesting and feels like a strong avenue for further exploration."
                },
                "weaknesses": {
                    "value": "- **Experiments:** From this reviewer\u2019s perspective, the main issues with the paper come from the experiments and the conclusions drawn from these. We outline our concerns below.\n    1. **Privileged directions experiment:** This reviewer did not understand how the privileged directions experiment connected with outlier features. To check our understanding, outlier features are a subset of activations that have substantially higher magnitude than the average activation for that input. Privileged directions on the other hand, are (a subset of?) the right singular vectors for the final linear layer. To determine whether a right singular vector $v_i$ is important to the encoder, the cosine similarity between $v_i$ and a sequence of activation vectors is computed and scaled by the corresponding singular value. This is termed the *importance* of $v_i$. It is not clear to the reviewer how \u2018importance\u2019 says anything about outlier features. The latter seems to be a property specifically related to the activation (or neuron) basis whereas the former consists of right singular vectors of the weight matrix, which are almost certainly not the activation basis. To be clear, identifying whether activations align with singular vectors with large singular value seems interesting, it just doesn\u2019t seem to be related to outlier features. Perhaps the tool one wants is closer to a measure of sparsity?\n    2. **Pruning experiment:** In Section 3, \u201cPruning non-privileged directions\u201d, the paper notes that one can prune away the smallest 80% of all singular vectors without substantial loss of accuracy. This technique is a standard method of finding a low-rank approximation of a matrix and well-studied. For large matrices, it does not seem surprising that the impact on classification is small even when using a low-rank approximation as the data itself can be approximated by a low-dimensional subspace of the ambient space. Furthermore, it is hard to tell if the results are specific to robust models when this technique is not applied to the finetuned and trained from scratch models.\n- **Lack of coverage of the multimodal aspect of the models:** Given the title, one would expect that there would be some discussion about how the multimodal aspect of CLIP-type models impacts the results. Surprisingly, this feature was never addressed. This reviewer would suggest either removing the word \u2018multimodal\u2019 from the title or adding a section to address this aspect. Further, it would be more precise to say that the work considers CLIP-type models since the experiments focus exclusively on this particular family.\n- **Experimental breadth:** Related to the previous point, it would make the work stronger if the results were expanded, either by increasing the breadth of the experiments (more models for instance) or providing some analysis of why we see the phenomena that we do. \n\n### Nitpicks\n- The abstract and introduction use the term *outlier feature* without any explanation. The term is not defined for several pages. While outlier features are known within the interpretability community, for the sake of accessibility, this reviewer would recommend putting at least an informal explanation of what this concept is the first time it is mentioned. \n- It\u2019s possible the reviewer missed it, but it seems that $d_X$ and $d_H$ are never defined in Section 3, \u201cApproach\u201d.\n- SVD is a foundational method in linear algebra. As such, there probably isn\u2019t a reason to include (3).  \n- The reviewer appreciates the validation of previous work showing trends in effective robustness (ER). It would be good if more papers did these kinds of validation experiments. On the other hand, as space is precious, this reviewer would suggest moving some of the text in this section to the appendix to focus on this work\u2019s contributions. It would seem that the main point the paper needs to make with regard to ER is that CLIP-style models stand-out for their ER relative to the same architectures finetuned on ImageNet or trained from scratch on ImageNet. This could be done more concisely."
                },
                "questions": {
                    "value": "- Looking at Table 3, one sees that the ImageNet supervised models tend to often have more concepts than some of the finetuned CLIP models. Is there an explanation for why this is?\n- Figure 4 suggests that the ViT models tend to share more of the same concepts between training techniques, are there any guesses for why this is?\n- This reviewer did not understand the remark \u201cAn interesting parallel can be drawn with the work of Bondarenko et al. (2023), which found that outlier features in language models assign most of their mass to separator tokens (such as the end of sentence token).\u201d"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3748/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3748/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3748/Reviewer_8h4M"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3748/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698553715672,
            "cdate": 1698553715672,
            "tmdate": 1700809798888,
            "mdate": 1700809798888,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kCHOHxxAjw",
                "forum": "7ffJo4vtTY",
                "replyto": "aTLCABnTCG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "content": {
                    "title": {
                        "value": "[1/3] Rebuttal to Reviewer 8h4M"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their thoughtful comments and suggestions. Below, we address all the reviewer's remarks. We are keen to address any remaining concerns the reviewer might have during the discussion period. \n\n\n## Re Weakness 1.1 (Priviledged directions and outlier features) \n\n\nFirst, we would link to confirm that the understanding of the reviewer is correct: priviledged directions are a subset of the right singular vectors of the final weight matrix.\n\nWe appreciate the opportunity to elaborate on a crucial point: the connection between privileged directions, outlier features, high kurtosis.\n\nPrivileged directions are one of our contributions and denote outlier features that not only receive substantially higher activations but also contribute significantly to the logits.\n\nOutlier features are directions that receive a substantially higher activation, this term was introduced in  **[1]**. Compared to Privileged Direction, outliers features may or may not contribute significantly to the logits.\n\nA high kurtosis signals that some directions of the model\u2019s representation space receive a substantially higher activation than the other directions. However, since the kurtosis metric defined in *Equation (2)* aggregates over all components of the activation vectors, it is not possible to identifies which directions of the representation space are outlier features.\n\n**Summary**. In summary, high kurtosis indicates the presence of outlier features, without identifying them. Outlier features represent directions with high activations, regardless of their contribution to the logits. Privileged directions are a subset of outlier features that also contribute substantially to the logits and consequently, to the final predictions. \n\n\nBelow we offer a more formal explaination where we also explain how we identify priviledged directions using the importance score.\n\n**Large activations in some directions.** Next, we would like to clarify the construction of the importance scores and how these relate to outlier features. Consider a basis $\\{ v_i \\in \\mathbb{R}^{d_H} \\mid i \\in [d_H] \\}$ of the representation space $\\mathbb{R}^{d_H}$, where $d_H \\in \\mathbb{N}^+$ is the dimension of the representation space. Let us assume that the direction $v_j$ receive substantially higher activations, hence corresponding to an outlier feature. This implies that the absolute cosine similarity of an activation vector $h^{(n)} \\in \\mathbb{R}^{d_H}$ with this direction will typically be higher than average: $|\\cos (v_j, h^{(n)})| \\gg \\frac{1}{d_H} \\sum_{i=1}^{d_H} |\\cos (v_i, h^{(n)})|$. This corresponds to the second factor in our importance score $\\mathrm{Importance}(j)$ defined in *Equation (4)*. \n\n**Contribution to logits.** Now what guarantees that this outlier feature $v_j$ is indeed important for the model? As we argue in the paper, this direction of the latent space needs to play a role in the computation of the logits. In order to restrict to directions of the latent space that matter for the classifier, we study the directions of the latent space corresponding to right singular vectors $\\{ v_i \\in \\mathbb{R}^{d_H} \\mid i \\in [\\mathrm{rank}(W)] \\}$ of the classification head $W \\in \\mathbb{R}^{d_Y \\times d_H}$, where $d_Y = 1,000$ is the number of ImageNet classes. Indeed, this set of vector spans the subspace of $\\mathbb{R}^{d_H}$ that is orthogonal to the kernel of the classification head $\\mathrm{span} \\{ v_i \\in \\mathbb{R}^{d_H} \\mid i \\in [\\mathrm{rank}(W)] \\} = \\ker(W)^{\\perp}$, which means that they allow us to decompose any activation vector $h \\in \\mathbb{R}^{d_H}$ whose contribution to the logits is nonzero. Now the outlier feature $v_j$ has a substantial contribution to the logit only if it corresponds to a large singular value $\\sigma_j \\gg 0$. This motivates our characterization of *priviledged directions* as directions of the representation space that receive a large activation (and, hence, correspond to outlier features) *and* that have a substantial contributions to the logits. This extra contribution corresponds to the first factor in our importance score $\\mathrm{Importance}(j) \\in \\mathbb{R}^+$ defined in *Equation (4)*. Priviledged directions are then characterized by an importance score substantially higher than average $\\mathrm{Importance}(j) \\gg \\frac{1}{d_H} \\sum_{i=1}^{\\mathrm{rank} (W)} \\mathrm{Importance}(i)$.\n\n**[1]** Dettmers, T., Lewis, M., Belkada, Y., & Zettlemoyer, L. (2022). Llm. int8 (): 8-bit matrix multiplication for transformers at scale. arXiv preprint arXiv:2208.07339."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3748/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700308848504,
                "cdate": 1700308848504,
                "tmdate": 1700308848504,
                "mdate": 1700308848504,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KgDZDmZHUr",
                "forum": "7ffJo4vtTY",
                "replyto": "aTLCABnTCG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "content": {
                    "title": {
                        "value": "[2/3] Rebuttal to Reviewer 8h4M"
                    },
                    "comment": {
                        "value": "## Re Weakness 1.2 (Pruning experiment)\n\nWe thank the reviewer for giving some further context to our pruning experiment. We agree with the reviewer that many works exist on studying low-rank approximation of neural networks. We would like to clarify that we do not claim that this low-rank approximation is a signature of robustness. Rather, we claim that for zeroshot CLIP models, this confirms the fact that a small number of latent space directions (including these priviledged directions) explain the high performances of the model, and hence, its high effective robustness.\n\nAdditionally, following the reviewer's recommendation, we have extended the pruning experiment from *Section 3* to finetuned CLIP models and supervised models trained only with ImageNet. These new results are hosted at [this link](https://imgur.com/a/QWuahzn). We make two interesting observations from these new results.\n\n**All models are low-rank.** For all the models (zeroshot, finetuned & supervised), the performances are not substantially affected if we remove the $80 \\\\%$ least important singular directions of their representation space. This confirms the reviewer's point that many existing models admit good low-rank approximations. This also confirms that the fact that these models are low-rank is not necessarily a signature of robustness.\n\n**Faster drop for supervised models.** When the number of ablated singular values ranges between $80\\\\%-100\\\\%$, we see that the ImageNet accuracy of supervised models drop substantially faster than the accuracy of the finetuned and the zeroshot models. In fact, for the ResNet50, the ImageNet accuracy curves even cross. This implies that the most important direction of the zeroshot model's representation space better discriminate between ImageNet classes than the most important directions of the supervised model's representation space. In the former case, these directions correspond to the zeroshot model's priviledged directions. We believe that this new result further reinforces the importance of priviledged directions to understand the performances of robust models. \n\n\nThese new results make a great addition to the manuscript. Hence, we have added the above discussion in *Appendix D* of the updated manuscript. \n\n___\n## Re Weakness 2. (Multimodal aspects)\n\n\nWe agree with the reviewer that our study mostly focuses on CLIP-style models. After an internal discussion and to avoid any confusion, we have decided to update the title to:\n\n*Robustness Signatures in CLIP Models*\n\nIt is also correct that our work restricts to the vision encoder of CLIP models. This is because CLIP vision encoder is very often used without the text encoder in practice. For instance, DALL-E 3 only leverages the vision encoder of CLIP and throws away the text encoder, see e.g. [this video](https://www.youtube.com/watch?v=pgaTOX-RUQ4) by the authors of DALL-E. Another example more related to NLP is BLIP-2 **[1]**, which leverages CLIP vision encoder without its language encoder.\n\n**[1]** Li, J., Li, D., Savarese, S., & Hoi, S. (2023). Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models. arXiv preprint arXiv:2301.12597.\n___\n## Re Questions 1.-3. (Remarks on the concept analysis)\n\nThe reviewers raised several interesting questions with respect to our concept analysis. Below, we answer each of those.\n\n**Q1: More concepts in supervised models.** As the reviewer pointed out, supervised models often have more concepts encoder than finetuned models. We hypothesize that this is due to the fact that finetuning is done for a few epochs (only 10), hence making the models forget many zeroshot concepts without giving it the time to memorize all the ImageNet concepts. The concept forgetting is illustrated by the Venn diagrams in *Figure 4*, where we observe that the finetuned concepts are almost subsets of the zeroshot concepts. \n\n**Q2: Better concept alignment between ViTs.** We thank the reviewer for pointing out this interesting observation! Unfortunately, at this point, we also cannot offer an explanation as to why this happens. If the reviewer has a specific analysis in mind that could help understand this better, we would be keen to look into it.\n\n**Q3: Parallel with the work of Bondarenko et al.** We would like to clarify the parallel described in the paragraph *Interpreting priviledged directions* of *Section 4*. As shown in our analysis, the concepts encoded in the outlier features represent regular alternating patterns (like presence/absence of holes). The outlier features in LLMs focus their attention to separator tokens, which appear regularly and alternate with more informative tokens. Hence, a parallel can be made by considering the visual alternating patterns (like holes) to mimic the behaviour of text separator tokens. Since this parallel is not a key contribution of our work but rather an interesting curiosity, would this reviewer recommend to move this to the Appendix?"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3748/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700309254161,
                "cdate": 1700309254161,
                "tmdate": 1700309254161,
                "mdate": 1700309254161,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "G8qxSMnNdu",
                "forum": "7ffJo4vtTY",
                "replyto": "aTLCABnTCG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "content": {
                    "title": {
                        "value": "[3/3] Rebuttal to Reviewer 8h4M"
                    },
                    "comment": {
                        "value": "## Re Weakness 3. (Experimental breadth) \n\nWe thank the reviewer for their suggestion. Following their recommendation, we have increased the breadth of our experiments in two meaningful ways: by adding non-CLIP style models (CoCa **[1]**), as well as by included larger scale models (with ViT-L-14 backbones). All these results have been added to *Appendix C.1* of the updated manuscript.\n\nBelow, we verify that the empirical results from our paper extend to these models. First we confirm that all these models have high effective robustness when used as zero-shot classifiers. As in the paper, we observe that finetuning on ImageNet decreases the effective robustness of these classifiers. \n\n|**Backbone**|**Pretraining Data**|**Zero-shot ER**|**Finetuned ER**|\n|---|---|---|---|   \n|COCA ViT-B-32|LAION-2B|25%|14%|\n|COCA ViT-L-14|LAION-2B|34%|21%|\n|CLIP ViT-L-14|OpenAI| 37% | 21%|\n|CLIP ViT-L-14|LAION-400M|32%|20%|\n|CLIP ViT-L-14|LAION-2B|32%|21%|\n|CLIP ViT-L-14|DataComp|37%|24%|\n||\n\nNext, we show that all the zero-shot models have high kurtosis, which implies the existence of outlier features in their representation space. Additionally, we show that finetuning again decreases the kurtosis.  \n\n|**Backbone**|**Pretraining Data**|**Zero-shot kurtosis**|**Finetuned kurtosis**|\n|---|---|---|---|   \n|COCA ViT-B-32|LAION-2B|12.0|3.6|\n|COCA ViT-L-14|LAION-2B|15.5|4.6|\n|CLIP ViT-L-14|OpenAI| 60.8 | 4.6|\n|CLIP ViT-L-14|LAION-400M|20.3|5.2|\n|CLIP ViT-L-14|LAION-2B|66.2|6.9|\n|CLIP ViT-L-14|DataComp|37.4|4.6|\n\n\n\n\nFinally, we check that zero-shot model encodes more concepts. Again, we see that finetuning removes some concepts from the model's representation space.\n|**Backbone**|**Pretraining Data**|**Zero-shot #concept**|**Finetuned #concept**|\n|---|---|---|---|   \n|COCA ViT-B-32|LAION-2B|674|530|\n|COCA ViT-L-14|LAION-2B|747|629|\n|CLIP ViT-L-14|OpenAI| 704 | 623|\n|CLIP ViT-L-14|LAION-400M|683|613|\n|CLIP ViT-L-14|LAION-2B|704|633|\n|CLIP ViT-L-14|DataComp|684|619|\n\n\n**[1]** Jiahui Yu, Zirui Wang, Vijay Vasudevan, Legg Yeung, Mojtaba Seyedhosseini, Yonghui Wu. CoCa: Contrastive Captioners are Image-Text Foundation Models"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3748/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700309414744,
                "cdate": 1700309414744,
                "tmdate": 1700309414744,
                "mdate": 1700309414744,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "U5xTZSsUVg",
                "forum": "7ffJo4vtTY",
                "replyto": "aTLCABnTCG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow-up to the Rebuttal for Reviewer 8h4M"
                    },
                    "comment": {
                        "value": "We would like to follow-up on the **Q2: Better concept alignment between ViTs** paragraph in Part [2/3] of our rebuttal. \n\nWe manually inspected the concepts encoded by the models shown in *Figure 4* to investigate this further. We found a number of concepts that lie in the intersection of all models (grey area) for the ViT models, but were only encoded in the ResNets that were trained on ImageNet (through finetuning or supervised from scratch), i.e. that lie in the green, teal, or purple-blue areas. These concepts are:\n\nBaptistry-indoor-s, barbershop-s, castle-s, courtyard-s, crate, gas-station-s, home-theater-s, hunting-lodge-s, pantry, ranch-house-s, reading-room-s, skittle-alley, town_house-s, watchtower. \nFurthermore concepts related to pool tables (corner pocket, pool table, poolroom-establishment-s, poolrome-home-s) and elevators (elevator-lobby-s, elevator_shaft-s, elevator-door-s, elevator-freight_elevator-s, elevator-interior-s).\n\nThese concepts are all related to objects in scenes. It seems like while ViTs picked them up during pretraining (hence also the zeroshot model encodes them), ResNets only learn to encode them when training on ImageNet, where they seem to be more important.  \n___\nWe again thank the reviewer for their useful comments.\nWe hope that our rebuttal has addressed any remaining concern about the paper.\nIf not, we would like to kindly ask the reviewer to engage in discussion before the end of the discussion period (tomorrow).\nOtherwise, we hope that the reviewer will consider updating their recommendation accordingly."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3748/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700573508178,
                "cdate": 1700573508178,
                "tmdate": 1700573508178,
                "mdate": 1700573508178,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rjUO6rrXLu",
                "forum": "7ffJo4vtTY",
                "replyto": "U5xTZSsUVg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3748/Reviewer_8h4M"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3748/Reviewer_8h4M"
                ],
                "content": {
                    "title": {
                        "value": "Replies to rebuttal"
                    },
                    "comment": {
                        "value": "We would like to thank the authors for clarifying a number of aspects of their work and for describing a substantial number of new results. The increased experimental breadth and the further investigation into pruning are particularly appreciated.\n\nThe remaining confusion that the reviewer has can be reduced to two sentences from the rebuttal above:\n\n1. \"priviledged directions are a subset of the right singular vectors of the final weight matrix\".\n2. \"Privileged directions are one of our contributions and denote outlier features that not only receive substantially higher activations but also contribute significantly to the logits.\"\n\nIt is our understanding from the descriptions in this work and others that outlier features are specific coordinates (in the neuron basis) in model hidden representations with substantially larger magnitude. Thus, geometrically we can think of them as elements of the elementary unit vectors $e_1, e_2, \\dots, e_n \\in \\mathbb{R}^n$, where $\\mathbb{R}^n$ is the particular hidden representation space. On the other hand, the right singular vectors cannot in general be expected to belong to $e_1, e_2, \\dots, e_n$. Is there something special in this situation that the reviewer is missing?"
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3748/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700703198895,
                "cdate": 1700703198895,
                "tmdate": 1700703198895,
                "mdate": 1700703198895,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FmevJRnPfL",
                "forum": "7ffJo4vtTY",
                "replyto": "aTLCABnTCG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Re Follow up Questions (Outlier Feature vs. Priviledged Direction)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for narrowing down the confusion. We agree that this point deserves further clarifications. It is correct that previous work considered *outlier features* to be a subset of vectors in the canonical basis $\\\\{ e_1, \\dots, e_n \\in \\mathbb{R}^n \\\\}$ of the $n$-dimensional representation space. With the introduction of privileged directions, which are right singular vectors of the weight matrix $W$, we generalize this definition to *any set of directions of the representation space that receive a projection substantially above average*. We explain this in more detail below, and have also added a clarification in the manuscript (see *Section 3* of the revised manuscript).\n\nLet us imagine, for instance, that two of the elements in the canonical basis $e_1$ and $e_2$ correspond to outlier features. This means that an activation vector $h$ related to an input image $x$ has projections $h_1 = \\mathrm{Proj}\\_{e_1}(h)$ and $h_2 = \\mathrm{Proj}\\_{e\\_2}(h)$ substantially above the average $h_1, h_2 \\gg n^{-1} \\sum_{i=1}^n h_i$. Now let us define a new unit vector $e_1' = 2^{-1/2} (e_1 + e_2)$. We deduce that the projection onto this vector is also substantially higher than average $h_1' = \\mathrm{Proj}\\_{e_1'}(h) = 2^{-1/2} (h_1 + h_2) \\gg n^{-1} \\sum_{i=1}^n h_i$. Hence, the unit vector $e_1'$ can be considered as an outlier feature in a new non-canonical basis. In general, we extend the notion of *outlier features* to any vector in the $\\mathrm{span} \\\\{ e_1, \\dots, e_n \\in \\mathbb{R}^n \\\\}$. This includes the right singular vectors of the weight matrix $W$, i.e. our privileged directions.\n\n\nWe acknowledge that this relaxed definition of *outlier features* distinguishes our work from the related literature, and deserves some further clarifications. We thank the reviewer for pointing this out, and have clarified this point in *Section 3* of the revised manuscript. We thank again the reviewer for their engagement, and hope this clarifies any residual ambiguity."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3748/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737586505,
                "cdate": 1700737586505,
                "tmdate": 1700739930543,
                "mdate": 1700739930543,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Tln0NjUZYo",
            "forum": "7ffJo4vtTY",
            "replyto": "7ffJo4vtTY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3748/Reviewer_YHoY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3748/Reviewer_YHoY"
            ],
            "content": {
                "summary": {
                    "value": "This paper empirically showed that robust multimodal models have outlier features and these outlier features encode more concepts. The paper analyzed the representation spaces of various multimodal models and found that more robust models have much more outlier features. What\u2019s more, by probing these outlier features of robust multimodal models, the authors find that the principled directions in them encode substantially more concepts."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper is tackling an important problem in understanding robust multimodal models. Multimodal models are often found to be more robust than prior supervised models. It is not clear why that is the case. This paper provides many intriguing evidences for this observation.  \n2. The finding that robust multi-modals have more outlier features is interesting. It is another evidence that zero-shot CLIP models are much different than other non-robust models.  \n3. The analysis of the paper is thorough, including using activation kurtosis to analzye outlier features and also the use of concept probing."
                },
                "weaknesses": {
                    "value": "1. It is not clear to the me, what is the reason for selecting the metric of activation kurtosis for the analysis in Section 3. What makes this metric interesting for the analysis of outlier features?   \n2. It seems section 2 is an re-evaluation of existing works on effective robustness. It would be good to summarize these results and definitions in a concise fashion."
                },
                "questions": {
                    "value": "1. In table 2, why would the kurtosis of OpenAI CLIP models be much higher? It seems to be an extreme value. I am interested as to what would be the difference between OpenAI and YFCC-15M/CC-12M CLIP models.  \n2. From equation 3, the definition of privileged directions in representation space seems to be based on SVD decomposition of the classification head. Have the authors tried more involved methods, e.g. reduced rank regression? Instead of finding the low-rank approximation of W, reduced rank regression would find the low-rank approximation of WX."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3748/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698644542760,
            "cdate": 1698644542760,
            "tmdate": 1699636331069,
            "mdate": 1699636331069,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Eqh936PHol",
                "forum": "7ffJo4vtTY",
                "replyto": "Tln0NjUZYo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "content": {
                    "title": {
                        "value": "[1/2] Rebuttal to Reviewer YHoY"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their thoughtful comments and suggestions. Below, we address all the reviewer's remarks. We are keen to address any remaining concerns the reviewer might have during the discussion period. \n\n\n## Re Weakness 1. (Activation kurtosis)\n\n\nOur motivations for choosing the activation kurtosis as a first metric to detect outlier features is similar to **[1]**. The idea is that outlier features create heavy tails in the activation distributions, which is detected by the kurtosis metric.We shall detail this argument below for completeness.\n\nLet us first imagine that a representation space has no priviledged direction. This implies that the model's features are represented in random directions. It turns out that random unit vectors can be obtained by normalizing samples from an isotropic Gaussian. Therefore, if the representation space admits no priviledged direction, we expect the distribution of activation vectors $\\{ h^{(n)} \\in \\mathbb{R}^{d_H} \\mid n \\in [N]\\}$, where $N$ is the number of instances for which the activation vector is computed and $d_H \\in \\mathbb{N}^+$ is the dimension of the representation space, to be well-described by an isotropic Gaussian distribution. In other words, the components $\\{ h_i^{(n)} \\in \\mathbb{R} \\mid i \\in [d_H]\\}$ of these activation vectors should follow a Gaussian distribution for every activation vector $h^{(n)}$.\n\nNow if the representation space admits priviledged directions, one should *not* expect these components to be Gaussianly distributed. In particular, outlier features will correspond to some of these components to be substantially larger than the average of all components. Therefore, the distribution of activation vectors $\\{ h_i^{(n)} \\in \\mathbb{R} \\mid i \\in [d_H]\\}$ should be heavy-tailed. It turns out that the kurtosis is an ideal metric to measure this heavy-tailedness, since Gaussian distributions are known to have a kurtosis of 3. Therefore, any kurtosis substantially larger than 3 indicates that the components of the activation vector do not follow a Gaussian distribution and that some components are substantially larger than average, which suggests the existence of outlier features. \n\n\n**[1]** Elhage, N., Lasenby, R., & Olah, C. (2023). Privileged bases in the transformer residual stream. Transformer Circuits Thread.\n\n___\n## Re Question 1. (Large kurtosis for OpenAI models)\n\nWe were also surprised with the extreme kurtosis of OpenAI CLIP models. Since all of these models have similar backbones and are trained with similar hyperparameters, the difference in kurtosis is likely related to the pretraining set used to obtain these models. Since OpenAI never released the full pretraining set of CLIP, we can can only speculate about the possible explanations for this phenomenon. \n\nOur first intuition was that kurtosis increases with the size of the pretraining set. However, a close inspection of *Table 2* is sufficient to dismiss this hypothesis. Indeed, the kurtosis of LAION-2B models is susbtantially smaller than the kurtosis of OpenAI models, in spite of being  pretrained with 2 billion images, which is almost an order of magnitude of the 400 million images used by OpenAI.\n\nA more plausible explanation is the diversity of the pretraining data and could echo some previous work trying to understand the specificities of OpenAI models **[1]**. We have good reasons to think that all the pretraining sets studied in our paper are less diverse than the one used by OpenAI. For the CC-12M and YFCC-15M sets, this boils down to their size that is one order of magnitude bellow the size of OpenAI's pretraining set. Furthermore, YFCC-15M is a subset of the pretraining set used by OpenAI. For the LAION dataset, it boils down to the fact that these datasets are constructed by filtering image-caption pairs scrapped from the web based on the alignment of their representation in CLIP's representation space. This process is likely to filter-out pairs that are substantially different than the ones used by OpenAI. Therefore, it is legitimate to assume that OpenAI's pretraining set is the most diverse dataset discussed in our paper. \n\nThe exact interaction between this data diversity and kurtosis would consitute an interesting extension of our work. Unfortunately, it is hampered by the lack of access to OpenAI's pretraining set. A possible workaround would be to gradually reduce the diversity of the LAION datasets with a principled filtering technique and study how this impacts the kurtosis of the resulting models. We leave this interesting avenue for future work. \n\n**[1]** Nguyen, T., Ilharco, G., Wortsman, M., Oh, S., & Schmidt, L. (2022). Quality not quantity: On the interaction between dataset design and robustness of clip. Advances in Neural Information Processing Systems, 35, 21455-21469."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3748/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700308421688,
                "cdate": 1700308421688,
                "tmdate": 1700308421688,
                "mdate": 1700308421688,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gASJWkILsj",
                "forum": "7ffJo4vtTY",
                "replyto": "Tln0NjUZYo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "content": {
                    "title": {
                        "value": "[2/2] Rebuttal to Reviewer YHoY"
                    },
                    "comment": {
                        "value": "## Re Question 2. (Alternatives to SVD)\n\n\nWe thank the reviewer for the interesting suggestion. The reason why we used SVD is to extract directions of the model's representation space $\\mathbb{R}^{d_H}$, where $d_H \\in \\mathbb{N}^+$ is the dimension of the representation space, that are relevant for the computation of the logits by the classification head $W \\in \\mathbb{R}^{d_Y \\times d_H}$, where $d_Y = 1,000$ is the number of ImageNet classes.\n\nIf we understood the reviewer's suggestion correctly, the reduced rank regression will consist in stacking the activation $\\{ h^{(n)} \\in \\mathbb{R}^{d_H} \\mid n \\in [N] \\}$, where $N$ is the number of instances for which the activation vectors are computed in a matrix $H \\in \\mathbb{R}^{d_H \\times N}$ in order to find a low rank approximation of $WH \\in \\mathbb{R}^{d_Y \\times N}$, e.g. through a SVD decomposition. We are not sure to understand how this would allow us to distill relevant directions of the model's representation space $\\mathbb{R}^{d_H}$, since the matrix $WH$ has an inconsistent shape $d_Y \\times N$. If the reviewer is interested in this experiment, could they clarify this? We would be keen to run any additional experiment based on the reviewer's feedback."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3748/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700308476603,
                "cdate": 1700308476603,
                "tmdate": 1700308476603,
                "mdate": 1700308476603,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ULHA2xWeCL",
            "forum": "7ffJo4vtTY",
            "replyto": "7ffJo4vtTY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3748/Reviewer_KW5N"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3748/Reviewer_KW5N"
            ],
            "content": {
                "summary": {
                    "value": "This paper demonstrates the existence of outlier features and the substantial encoding of multiple concepts in robust models through the study of models like CLIP."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper provides a systematic investigation of models like CLIP, offering compelling evidence that robust models encode outlier features and a greater variety of concepts. This research is quite interesting."
                },
                "weaknesses": {
                    "value": "1, This paper appears to explain some interesting phenomena but doesn't offer methods for improving model performance. Therefore, I believe the contributions of this research may be relatively limited. As a result, I consider the overall quality of the paper to be at a borderline level.\n\n2, I believe what might be more interesting is understanding why these phenomena occur rather than merely showcasing them.\n\n3, I might have been more eager for the authors to utilize the findings in this paper to inspire some ideas for addressing unresolved problems."
                },
                "questions": {
                    "value": "See Weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3748/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3748/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3748/Reviewer_KW5N"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3748/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698684317879,
            "cdate": 1698684317879,
            "tmdate": 1699636330960,
            "mdate": 1699636330960,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CsE32IBrJf",
                "forum": "7ffJo4vtTY",
                "replyto": "ULHA2xWeCL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "content": {
                    "title": {
                        "value": "[1/2] Rebuttal to Reviewer KW5N"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their thoughtful comments and suggestions. Below, we address all the reviewer's remarks. We are keen to address any remaining concerns the reviewer might have during the discussion period. \n\n\n## Re Weakness 1. and 3. (Impact of findings)\n\nWe appreciate the reviewer thoughtful evaluation of our paper. While we understand that proposing an immediate way to leverage our findings would have been ideal, we would like to highlight the nature of our contribution and the broader spirit of scientific exploration.\n\nOur work focuses on identifying a phenomenon within the model's behavior, aiming to deepen the understanding of underlying mechanisms. It is important to note that scientific progress often involves incremental steps, with each study contributing a piece to the larger puzzle. In this context, our findings serve as a foundation for future research and could inspire novel ideas for addressing unresolved problems.\n\nScientific contributions extend beyond immediate applications and can pave the way for innovative approaches in subsequent studies. By understanding the relationships between effective robustness, outlier features, high kurtosis, and privileged directions, we provide valuable insights that could potentially inform the development of more effective models in the future. We believe that collaboration and building upon prior research are key elements of scientific advancement, and we welcome further exploration and refinement of our work in subsequent investigations.\n    \nFor example, we see two distinct fields of ML research that could benefit from the phenomena we exhibit in this paper: model quantization and mechanistic interpretability.\n\n**Model Quantization.** Quantization is the process of converting floating point tensor operations of a model into integer tensor operations in order to speed-up inference time and decrease memory consumption. Outlier features are known to occur in LLMs training and make the quantization of LLMs challenging **[1]**. In our paper, we demonstrate that the same type of outlier features occur in the robust zeroshot CLIP models. This implies that the quantization of CLIP models will cause the same challenges as the ones encountered in the LLM litterature. Hence, decreasing the memory consumption and inference time of CLIP models cannot be achieved by using out-of-the-box model quantization. \n\n**Mechanistic Interpretability.** The goal of mechanistic interpretability is to reverse engineer neural networks in order to explain their inner working and achieve higher transparency. The common approach is to analyze each neuron / direction of the model's representation space and to investigate how these neurons form circuits connecting the model's input and output **[2]**. A crucial assumption in mechanistic interpretability is the fact that each neuron activates in the presence of related human concepts, hence allowing us to attach unambiguous meaning to the model's neurons. However, empirical analysis show that neural networks tend to superpose many concepts in some directions of their representation spaces, a phenomenon known as *polysemanticity* **[3]**. This phenomenon is the main obstacle to mechanistic interpretability, without definite solutions at this day. In our paper, we show that robust zeroshot CLIP models tend to superpose more concepts that their nonrobust counterparts (finetuned / supervised models). This implies that the interpretation of robust zeroshot CLIP models through mechanistic interpretability is more challenging.\n\n**[1]** Dettmers, T., Lewis, M., Belkada, Y., & Zettlemoyer, L. (2022). Llm. int8 (): 8-bit matrix multiplication for transformers at scale. arXiv preprint arXiv:2208.07339.\n\n**[2]** Olah, C., Cammarata, N., Schubert, L., Goh, G., Petrov, M., & Carter, S. (2020). Zoom In: An Introduction to Circuits.\n\n**[3]** Elhage, N., Hume, T., Olsson, C., Schiefer, N., Henighan, T., Kravec, S., ... & Olah, C. (2022). Toy models of superposition. arXiv preprint arXiv:2209.10652."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3748/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700308037626,
                "cdate": 1700308037626,
                "tmdate": 1700308037626,
                "mdate": 1700308037626,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PPXFFKcOOc",
                "forum": "7ffJo4vtTY",
                "replyto": "ULHA2xWeCL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "content": {
                    "title": {
                        "value": "[2/2] Rebuttal to Reviewer KW5N"
                    },
                    "comment": {
                        "value": "## Re Weakness 2. (Role of signatures in model performances)\n\n\nWe fully agree with the reviewer that it would be valuable to understand *why* these signatures emerge when pretraining the model. While our work does not bring a definite answer to this line of research, we argue that it brings two valuable contributions to the field.\n\n**Extension beyond LLMs.** We note that the presence of outlier features and the superposition of many concepts in the model's representation space has been an active area of research in *mechanistic interpretability* (see e.g. **[1]** and **[2]**). While this line of work has established that these phenomena occur in training large language models (LLMs), we believe that our work constitutes a first bridge with vision models through the multimodality of CLIP. Importantly, our work establishes that these signatures are not specific to LLMs and happen when pretraining vision models on large datasets.\n\n**Challenging existing explanations.** Some recent works have tried to explain the emergence of outlier features in LLMs. For instance **[3]** suggested that outlier are created by attention layers in order to encode \"no-op\" updates in the residual stream. Our work suggests that this explanation is incomplete, as outlier features are also present in CLIP ResNets, without any attention layers. \n\nInterestingly, our signatures are absent from vision models trained on smaller datasets (e.g. ImageNet), as demonstrated in *Sections 3 & 4*. This suggests that the signatures might be a consequence of scaling up the size of the data seen by the model, and are not necessarily tied to a specific modality.\n\n**[1]** Elhage, Nelson, Robert Lasenby, and Christopher Olah. \"Privileged bases in the transformer residual stream.\" Transformer Circuits Thread (2023).\n\n**[2]** Bricken, Trenton, et al. \"Towards Monosemanticity: Decomposing Language Models With Dictionary Learning.\" Transformer Circuits Thread (2023).\n\n**[3]** Bondarenko, Yelysei, Markus Nagel, and Tijmen Blankevoort. \"Quantizable Transformers: Removing Outliers by Helping Attention Heads Do Nothing.\" arXiv preprint arXiv:2306.12929 (2023)."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3748/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700308100877,
                "cdate": 1700308100877,
                "tmdate": 1700308100877,
                "mdate": 1700308100877,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zxpQyWGyAN",
                "forum": "7ffJo4vtTY",
                "replyto": "ULHA2xWeCL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow-up to the Rebuttal for Reviewer KW5N"
                    },
                    "comment": {
                        "value": "We again thank the reviewer for their useful comments. We hope that our rebuttal has addressed any remaining concern about the paper.  If not, we would like to kindly ask the reviewer to engage in discussion before the end of the discussion period (tomorrow). Otherwise, we hope that the reviewer will consider updating their recommendation accordingly."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3748/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700573644965,
                "cdate": 1700573644965,
                "tmdate": 1700573644965,
                "mdate": 1700573644965,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "EX1kJvd7FZ",
            "forum": "7ffJo4vtTY",
            "replyto": "7ffJo4vtTY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3748/Reviewer_qBSE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3748/Reviewer_qBSE"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the features learned by robust multimodal models. This paper explores the concept of robustness in multimodal models, specifically looking at the differences between robust and non-robust models and uncovering two signatures of robustness in the representation spaces of these models. The authors find that robust models have outlier features, which are highly activated components of the representation space. These outlier features induce privileged directions in the representation space, which are important for the model's performance. The authors also find that robust models encode more unique concepts than less robust models. This leads to polysemy, where a single representation can be used to represent multiple concepts. Additionally, they demonstrate that privileged directions in the model's representation space explain the model's predictive power. The paper analyzes multiple robust multimodal models trained on various pretraining sets and backbones. Overall, this paper provides valuable insights into the nature of robustness in multimodal models and sheds light on the factors that contribute to their success."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This paper makes a significant contribution to the field of multimodal models by uncovering two signatures of robustness in the representation spaces of these models. This is a novel approach that has not been explored in previous research. It provides a new understanding of the features that make robust multimodal models robust. The authors identify two key features: outlier features and privileged directions. Outlier features are highly activated components of the representation space, while privileged directions are directions that are important for the model's performance. The authors show that both of these features are more prevalent in robust models than in less robust models.\n\n2. The authors analyze different robust multimodal models trained on various pretraining sets and backbones, providing a comprehensive and rigorous analysis of the factors that contribute to robustness in these models. The paper uses a variety of methods to validate its findings. In addition to using activation kurtosis and singular value decomposition (SVD) to identify outlier features and privileged directions, the authors also use concept probing to show that robust models encode more unique concepts. This provides strong evidence that the authors' findings are not just artifacts of the specific methods they used.\n\n3. The findings of this paper have practical implications for the development of robust multimodal models. The authors demonstrate that outlier features and privileged directions in the model's representation space are key factors in the model's success, which can inform the development of more robust models in the future. The authors' identification of outlier features and privileged directions suggests that these features should be preserved in model training. This could be done by using training objectives that encourage the model to learn these features, or by using regularization techniques to prevent the model from overfitting to the training data."
                },
                "weaknesses": {
                    "value": "1. The paper only analyzes CLIP robust multimodal models with different backbones, which may not be representative of all possible models. This limits the generalizability of the findings. There are many other large scale multimodal models, which should be included, i.e., BLIP [1], FLAVA [2].\n\n2. The paper only focuses on robust models and does not compare them to non-robust models. This makes it difficult to determine the extent to which the findings are specific to robust models. See more questions in Questions section.\n\n3. Lack of explanation of outlier features: While the paper identifies outlier features as a key factor in robustness, it does not provide a clear explanation of what these features are or how they contribute to robustness. While the paper does discuss the practical implications of the findings, it could have gone into more detail about how these findings can be applied in practice to develop more robust multimodal models, i.e., VK-OOD [3]\n\n[1]Li, J., Li, D., Xiong, C., & Hoi, S. (2022, June). Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation. In International Conference on Machine Learning (pp. 12888-12900). PMLR.\n\n[2]Singh, A., Hu, R., Goswami, V., Couairon, G., Galuba, W., Rohrbach, M., & Kiela, D. (2022). Flava: A foundational language and vision alignment model. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 15638-15650).\n\n[3]Wang, Z., Medya, S., & Ravi, S. N. (2023). Differentiable Outlier Detection Enable Robust Deep Multimodal Analysis. arXiv preprint arXiv:2302.05608."
                },
                "questions": {
                    "value": "1. What are the two signatures of robustness in the representation spaces of multimodal models, and how do they contribute to the models' success?\n\n2. How do outlier features in robust multimodal models differ from those in non-robust models, and what is their role in robustness?\n\n3. What are privileged directions in the model's representation space, and how do they explain the model's predictive power?\n\n4. In Figure 1, what are baseline models and baseline models fit training on? Directly from ImageNet? How can this accuracy compare with the multimodal fine-tuning ones?\n\n5. Figure 2 is a little bit hard to read and understand. The authors should present and well-explain the figures clearly.\n\n6. Why only use kurtosis value to determine outlier features? The model of reference work has different number of parameters, how did authors choose the same one as their work?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3748/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3748/Reviewer_qBSE",
                        "ICLR.cc/2024/Conference/Submission3748/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3748/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698824220231,
            "cdate": 1698824220231,
            "tmdate": 1700673857807,
            "mdate": 1700673857807,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7N4WKKZDZP",
                "forum": "7ffJo4vtTY",
                "replyto": "EX1kJvd7FZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "content": {
                    "title": {
                        "value": "[1/3] Rebuttal to Reviewer qBSE"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their thoughtful comments and suggestions. Below, we address all the reviewer's remarks. We are keen to address any remaining concerns the reviewer might have during the discussion period. \n\n## Re Weakness 1. (Restriction to CLIP)\n\n We have taken the reviewers recommendation into account and confirmed our findings on multimodal models outside of the CLIP family, namely CoCa models **[1]**. Beyond that, we have futher extended the experimental breadth of our paper by extending our analysis to larger scale models with ViT-L-14 backbones. All these results have been added to *Appendix C.1* of the updated manuscript.\n\nBelow, we verify that the empirical results from our paper extend to these models. First we confirm that all these models have high effective robustness when used as zero-shot classifiers. As in the paper, we observe that finetuning on ImageNet decreases the effective robustness of these classifiers. \n\n|**Backbone**|**Pretraining Data**|**Zero-shot ER**|**Finetuned ER**|\n|---|---|---|---|   \n|COCA ViT-B-32|LAION-2B|25%|14%|\n|COCA ViT-L-14|LAION-2B|34%|21%|\n|CLIP ViT-L-14|OpenAI| 37% | 21%|\n|CLIP ViT-L-14|LAION-400M|32%|20%|\n|CLIP ViT-L-14|LAION-2B|32%|21%|\n|CLIP ViT-L-14|DataComp|37%|24%|\n||\n\nNext, we show that all the zero-shot models have high kurtosis, which implies the existence of outlier features in their representation space. Additionally, we show that finetuning again decreases the kurtosis.  \n\n|**Backbone**|**Pretraining Data**|**Zero-shot kurtosis**|**Finetuned kurtosis**|\n|---|---|---|---|   \n|COCA ViT-B-32|LAION-2B|12.0|3.6|\n|COCA ViT-L-14|LAION-2B|15.5|4.6|\n|CLIP ViT-L-14|OpenAI| 60.8 | 4.6|\n|CLIP ViT-L-14|LAION-400M|20.3|5.2|\n|CLIP ViT-L-14|LAION-2B|66.2|6.9|\n|CLIP ViT-L-14|DataComp|37.4|4.6|\n\n\nFinally, we check that zero-shot model encodes more concepts. Again, we see that finetuning removes some concepts from the model's representation space.\n|**Backbone**|**Pretraining Data**|**Zero-shot #concept**|**Finetuned #concept**|\n|---|---|---|---|   \n|COCA ViT-B-32|LAION-2B|674|530|\n|COCA ViT-L-14|LAION-2B|747|629|\n|CLIP ViT-L-14|OpenAI| 704 | 623|\n|CLIP ViT-L-14|LAION-400M|683|613|\n|CLIP ViT-L-14|LAION-2B|704|633|\n|CLIP ViT-L-14|DataComp|684|619|\n\n\nIn addition to these multimodal models, we have conducted a similar analysis on a robust SimCLR ViT-B-16 trained on the YFCC-15M dataset. This model is an interesting case study, as it is robust without being multimodal. Interestingly, our analysis in *Appendix G* shows that this model also has privileged directions and a large number of concepts encoded in its representation space. Please refer to *Appendix G* for more details.\n\nFinally, we would like to discuss the BLIP model suggested by the reviewer. We note that this model is implicitly studied in our paper, as it is endowed with the ViT-B-16 pretrained by OpenAI. Hence, we deduce that the analysis in our paper extends to BLIP.\n\n**[1]** Jiahui Yu, Zirui Wang, Vijay Vasudevan, Legg Yeung, Mojtaba Seyedhosseini, Yonghui Wu. CoCa: Contrastive Captioners are Image-Text Foundation Models\n___\n## Re Weakness 2. + Question 2. (Lack of comparison to non-robust models)\n\nWe would like to clarify that the analysis in our paper *does* incorporate comparisons with non-robust models. Indeed, by looking at *Table 1*, we observe that ImageNet supervised models have no (or negligeable) effective robustness, making them non-robust models. Interestingly, the finetuned models have a medium effective robustness. By combining zero-shot, finetuned and supervised models for each backbone, we then have models with high, medium and no effective robustness.\n\n\nEach section of our paper covers all 3 model types, as can be observed in e.g. *Table 2*, *Figure 2*, *Table 3* and *Figure 4*. In particular, we discover the 2 following robustness signatures: \n\n1. High kurtosis inducing priviledged directions in the model's representation space.\n2. A high number of concepts encoded in the model's representation space.\n\nOur experiments demonstrate that these signatures distinguish robust models from non-robust ones. \n\nIn particular, the answer to the reviewer's Question 2 can be found in Table 2: Outlier features in robust models differ from those in non-robust models in that they exist only for robust models (activation kurtosis of $\\gg$ 3), but not for non-robust models (activation kurtosis of $\\approx$ 3).\n\n\nSimilarly, we can deduce the robustness signature nature of the high number of encoded concepts in the model's representation space from *Table 3*: for each backbone, the amount of encoded concept is much higher for the robust zero-shot models than for the other, less robust models. \n\nThese observations reinforce the idea that these properties indeed distinguish robust models from the rest, and hence constitute signatures."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3748/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700307259849,
                "cdate": 1700307259849,
                "tmdate": 1700307259849,
                "mdate": 1700307259849,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Va40i2Xyst",
                "forum": "7ffJo4vtTY",
                "replyto": "EX1kJvd7FZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "content": {
                    "title": {
                        "value": "[2/3] Rebuttal to Reviewer qBSE"
                    },
                    "comment": {
                        "value": "## [1/2] Re Weakness 3. + Questions 3., 5., and 6. (Details on outlier features & priviledged directions)\n\nWe appreciate the opportunity to elaborate on a crucial point: the connection between privileged directions, outlier features, high kurtosis.\n\nPrivileged directions are one of our contributions and denote outlier features that not only receive substantially higher activations but also contribute significantly to the logits. \n\nOutlier features are directions that receive a substantially higher activation, this term was introduced in  **[1]**. Compared to Privileged Direction, outliers features may or may not contribute significantly to the logits.\n\nA high kurtosis signals that some directions of the model\u2019s representation space receive a substantially higher activation than the other directions. However, since the kurtosis metric defined in *Equation (2)* aggregates over all components of the activation vectors, it is not possible to identifies which directions of the representation space are outlier features.\n\n**Summary**. In summary, high kurtosis indicates the presence of outlier features, without identifying them. Outlier features represent directions with high activations, regardless of their contribution to the logits. Privileged directions are a subset of outlier features that also contribute substantially to the logits and consequently, to the final predictions. \n\n\nBelow we offer a more formal explaination where we also explain how we identify priviledged directions using the importance score.\n\n\n**Large activations in some directions.** Consider a basis $\\{ v_i \\in \\mathbb{R}^{d_H} \\mid i \\in [d_H] \\}$ of the representation space $\\mathbb{R}^{d_H}$, where $d_H \\in \\mathbb{N}^+$ is the dimension of the representation space. Let us assume that the direction $v_j$ receive substantially higher activations, hence corresponding to an outlier feature. This implies that the absolute cosine similarity of an activation vector $h^{(n)} \\in \\mathbb{R}^{d_H}$ with this direction will typically be higher than average: $|\\cos (v_j, h^{(n)})| \\gg \\frac{1}{d_H} \\sum_{i=1}^{d_H} |\\cos (v_i, h^{(n)})|$. This corresponds to the second factor in our importance score $\\mathrm{Importance}(j)$ defined in *Equation (4)*. \n\n**Contribution to logits.** Now what guarantees that this outlier feature $v_j$ is indeed important for the model? As we argue in the paper, this direction of the latent space needs to play a role in the computation of the logits. In order to restrict to directions of the latent space that matter for the classifier, we study the directions of the latent space corresponding to right singular vectors $\\{ v_i \\in \\mathbb{R}^{d_H} \\mid i \\in [\\mathrm{rank}(W)] \\}$ of the classification head $W \\in \\mathbb{R}^{d_Y \\times d_H}$, where $d_Y = 1,000$ is the number of ImageNet classes. Indeed, this set of vector spans the subspace of $\\mathbb{R}^{d_H}$ that is orthogonal to the kernel of the classification head $\\mathrm{span} \\{ v_i \\in \\mathbb{R}^{d_H} \\mid i \\in [\\mathrm{rank}(W)] \\} = \\ker(W)^{\\perp}$, which means that they allow us to decompose any activation vector $h \\in \\mathbb{R}^{d_H}$ whose contribution to the logits is nonzero. Now the outlier feature $v_j$ has a substantial contribution to the logit only if it corresponds to a large singular value $\\sigma_j \\gg 0$. This motivates our characterization of *priviledged directions* as directions of the representation space that receive a large activation (and, hence, correspond to outlier features) *and* that have a substantial contributions to the logits. This extra contribution corresponds to the first factor in our importance score $\\mathrm{Importance}(j) \\in \\mathbb{R}^+$ defined in *Equation (4)*. Priviledged directions are then characterized by an importance score substantially higher than average $\\mathrm{Importance}(j) \\gg \\frac{1}{d_H} \\sum_{i=1}^{\\mathrm{rank} (W)} \\mathrm{Importance}(i)$.\n\n**Interpretation of Figure 2.** This leads us naturally to *Figure 2* that shows how the importance scores $\\{ \\mathrm{Importance}(i) \\mid i \\in [\\mathrm{rank}(W)] \\}$ are distributed for various models. Each point on this plot corresponds to a direction of the model's representation space. As we can see, zero-shot models have priviledged directions having significantly higher importance (corresponding blue points that are substantially above the bulk). finetuned models still have priviledged directions (corresponding blue points that are above the bulk), although their gap of importance with the bulk is smaller. Nonrobust supervised models have no priviledged directions, as all their importance scores are comparable (no green point stands out from the bulk).\n\n**[1]** Dettmers, T., Lewis, M., Belkada, Y., & Zettlemoyer, L. (2022). Llm. int8 (): 8-bit matrix multiplication for transformers at scale. arXiv preprint arXiv:2208.07339."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3748/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700307332764,
                "cdate": 1700307332764,
                "tmdate": 1700307725048,
                "mdate": 1700307725048,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3TBSn95OmW",
                "forum": "7ffJo4vtTY",
                "replyto": "EX1kJvd7FZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3748/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow-up to the Rebuttal for Reviewer qBSE"
                    },
                    "comment": {
                        "value": "We again thank the reviewer for their useful comments. We hope that our rebuttal has addressed any remaining concern about the paper. If not, we would like to kindly ask the reviewer to engage in discussion before the end of the discussion period (tomorrow). Otherwise, we hope that the reviewer will consider updating their recommendation accordingly."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3748/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700573578333,
                "cdate": 1700573578333,
                "tmdate": 1700573578333,
                "mdate": 1700573578333,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]