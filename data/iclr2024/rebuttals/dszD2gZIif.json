[
    {
        "title": "Long-term Time Series Forecasting with Vision Transformer"
    },
    {
        "review": {
            "id": "OPg6wdzXW8",
            "forum": "dszD2gZIif",
            "replyto": "dszD2gZIif",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3334/Reviewer_SUuV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3334/Reviewer_SUuV"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a model called Swin4TS for long-term time series forecasting. Swin4TS adopts SwinTransformer with native window-based attention and hierarchical representations adapted for the time series modality, which has shown powerful capability in CV. The paper provides two variants, Swin4TS/CD and Swin4TS/CI, which can adapt to channel-dependent and channel-independent strategies, respectively. The experiments show that the model outperforms existing baselines on eight benchmark datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Swin4TS achieves improved performance on multiple benchmark datasets."
                },
                "weaknesses": {
                    "value": "1. The paper is somewhat not well-organized. The figures (1, 2, and 4) are not rough to convey enough insights and are unportable. The tables (2, 3, and 4) for many experiments are incomplete on the dataset. Some notations can be not so rigorous (\\hat_x may be better to denote the model predictions). Thus, this paper essentially needs further polishing. \n2. The contributions of the paper can be not enough, which is the most fatal point. Swin-transformer modules are adapted for the time series. It's like lowering the dimension of attention directly on 1D time series representations. Is this more motivating than design models considering time series properties? How does inductive bias like shift invariance help time series forecasting? Without considering the gap between the two modalities, I think it has not contributed much to the research field.\n3. The performance incremental is marginal. The forecasting result of Swin4TS over PatchTST can be small. And I think the ablations should be conducted on more extensive datasets. Also, I suggest that experiments such as hyperparameter effects are more suitable to be placed in the appendix, and more experiments exploring the helpful inductive bias should be considered.\n4. Unsolved contribution: \"We successfully apply techniques from ViT to LTSF\", which does not \"indicate the potential of connecting time series with other domains within the Transformer architecture\". What does the 'connection' mean? The author provides no experiments to validate the results of cross-domain/modality transfer."
                },
                "questions": {
                    "value": "1. SwinTransformer in computer vision are commonly leveraged for high-level feature extraction, which is widely applied on tasks such as image classification. The time series forecasting task, on the contrary, belongs to a typical generative task and needs to learn low-level feature representation for time point reconstruction. How does the proposed model cope with the gap between tasks and representation granularity? \n2. Is it an advantage that being able to combine CI/CD mechanisms? Previous forecasting models are commonly implemented by CD, but they can also be easily incorporated with CI, no matter Transformers or non-Transformers."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3334/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3334/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3334/Reviewer_SUuV"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3334/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697811910205,
            "cdate": 1697811910205,
            "tmdate": 1700728465341,
            "mdate": 1700728465341,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VTBvTwx5vH",
                "forum": "dszD2gZIif",
                "replyto": "OPg6wdzXW8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3334/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3334/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer SUuV (Part 1/2)"
                    },
                    "comment": {
                        "value": "&emsp;&emsp;Thank you for your comment. We have carefully and seriously considered the questions and concerns you raised, and provided targeted explanations. We hope our response can change your perception of this work.\n\n### **For the 1st concern of weaknesses**\n&emsp;&emsp;The reviewer mentioned that Figures 1, 2, and 4 do not clearly convey insights. We do not quite understand. Do you have any clearer suggestions? For Tables 2, 3, and 4. Table 2 shows the results of univariate prediction, for which **we only evaluated on the 4 ETT datasets. This is because in the field of time series prediction, univariate prediction is not the main challenge, and conventionally it is evaluated only on these 4 datasets or less**. Anyway, we evaluated Swin4TS on the other four datasets as shown below (evaluated by MSE), and the results showed that Swin4TS still outperformed other baselines.\n|             | Swin4TS/CI | PatchTST/64 |  MICN  | TimesNet | FEDformer | Autoformer |\n|:-----------:|:----------:|:-----------:|:------:|:--------:|:---------:|------------|\n|   Weather   |    0.002   |    0.002    | 0.013  |  0.002   |   0.014   |   0.058    |\n|   Traffic   |    0.134   |    0.193    | 0.285  |  0.167   |   0.236   |   0.271    |\n| Electricity |    0.277   |    0.709    | 0.364  |  0.422   |   0.373   |   0.421    |\n|     ILI     |    0.756   |    0.749    | 2.658  |  0.818   |   1.079   |   1.079    |\n\nHowever, this comparison is unfair to other baselines because they have not conducted the same experiments in their original work, and they may require appropriate adjustments in hyperparameters for these additional datasets to achieve optimal performance. Table 3 is the ablation analysis for ETTm1 and ETTm2. We also conducted ablation experiments on Swin4TS/CI on four other datasets, and in most cases, the effectiveness was confirmed. Please understand that due to limited time, we were unable to complete all the ablation experiments.\n|           | Weather | Traffic | Electricity |  ILI  |\n|:---------:|:-------:|:-------:|:-----------:|:-----:|\n| with all  |  0.220  |  0.356  |    0.157    | 1.740 |\n| w/o shift |  0.222  |  0.355  |    0.157    | 1.751 |\n| w/o scale |  0.228  |  0.358  |    0.165    | 1.812 |\n|  w/o both |  0.225  |  0.359  |    0.162    | 1.787 |\n\n**It should be noted that presenting obvious ablation effects for all datasets is demanding. At least for time series prediction, it is customary to present ablation results only on some datasets**. Table 4 is about the experiment on hierarchy design. We do not take the 4-stage experiment for the ILI dataset. This is because the input length of ILI is 108 which is unreasonable to design a 4-stage architecture, as we have mentioned in the main text. **Overall, results of this work seem incomplete, primarily due to some customary practices rather than our work being incomplete. Hope the reviewer can consider again.**\n\n### **For the 2nd concern**\n&emsp;&emsp; We would like to reiterate the motivation behind our work. Swin Transformer is essentially a Transformer that takes into account information at multiple scales (i.e., hierarchical design) and combines window-based attention to reduce complexity to linear. Although it was originally proposed to solve CV problems, it is essentially designed for handling sequential data. Time series is naturally sequential data, while image is partitioned into patch series. Therefore, from this perspective, Swin Transformer is even more suitable for handling time series.\n\n&emsp;&emsp; **We want to emphasize that the core architecture of Swin Transformer is independent of CV tasks**. It can be applied to a wide range of tasks for modeling sequential data. A good example of this is the Video Swin Transformer (VST, https://arxiv.org/abs/2106.13230), which actually deals with image-based time series. In fact, VST has not made specific designs for video data, but simply extends Swin Transformer from 2D to 3D, and has achieved SOTA performance on different tasks. **If each frame of video data is reduced to a point or vector, then video data becomes time series. This means that VST already implies an attempt to process time series data with Swin Transformer. The main contribution of our work is showing the structural similarity of time series and image, making these two modalities be modeled within a unified framework**.\n\n(To be continued in Part 2/2)"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3334/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700282303920,
                "cdate": 1700282303920,
                "tmdate": 1700282303920,
                "mdate": 1700282303920,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hvE20FTGfv",
                "forum": "dszD2gZIif",
                "replyto": "OPg6wdzXW8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3334/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3334/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer SUuV (Part 2/2)"
                    },
                    "comment": {
                        "value": "(Following Part 1/2)\n\n&emsp;&emsp; Indeed, time series and images have their own characteristics. Or, as you mentioned, there is a gap between these two modalities. **However, the characteristics of these two modalities can be integrated  to their own underlying patterns. As long as Swin Transformer can learn these underlying patterns, there is no need to design too much specifically for their own features. As you know, ViTs do not have strong inductive bias like CNNs. But they still can get superior performance by training on large datasets**. For example the shift invariance in image you mentioned. Due to that the partition of image in ViT destroys the space structure, ViT uses a positional embedding to learn the space structure. For time series analysis, at least for forecasting task, the shift invariance is not obvious. Thus the positional embedding and the relative bias in Swin Transformer do not facilitate the performance in practice. While for time series classification task, we expect to see the shift invariance may help the model performance.\n\n&emsp;&emsp; **Anyway, thank you for pointing out this. Your concerns made us realize that we did not clearly articulate our motivation and contribution in the previous manuscript. In the Conclusion section of the revised one, we added a short discussion to comprehensively address our views. Please kindly consider again.**\n\n### **For the 3rd concern** \n&emsp;&emsp; Regarding the performance incremental. **The SOTA for time series prediction has reached a bottleneck**. As far as we know, very recent works nearly all have limited improvements for PatchTST. Regarding the effectiveness of Swin4TS, we have additionally provided more experimental results to validate the feasibility and effectiveness of Swin4TS, such as TNT4TS and hierarchical analysis. We hope that these results will meet your requirements. Regarding the necessity of using backbones from other fields. As stated in our main text, the significance of our work lies in the recognition of the structural similarity between the time series and image modalities, and modeling them in a unified framework. **Therefore, time series modeling can draw on advanced models from the image modality to solve its own problems, instead of designing various sophisticated models as before. This will promote the development of time series analysis**. Finally, the reviewer suggested more helpful inductive bias to prove the rationality of Swin4TS. This is back to the 2nd concern mentioned above, which we have stated.\n\n###  **For the 4th concern**\n&emsp;&emsp;Our wording may have been misleading. **Our intention was to use a unified model to model time series and image patch series based on their structural similarities, rather than providing contributions for multi-modality task**. In the revised manuscript, we expressed it in a different way.\n\n###  **For the 1st question**\n&emsp;&emsp;Regarding the gap. When Swin Transformer is applied for image classification, it first obtains a representation of the image, and then uses this representation for classification by a linear layer. Similarly, Swin4TS obtains a representation of the input time series and then directly connects a linear layer to map the future time series. **The main difference is just that the former is 2-dimensional and the latter is 1-dimensional**.\n\n&emsp;&emsp;  Regarding the representation granularity. Since existing time series datasets are far less complete than image datasets, large models may overfit. The size of Swin4TS is smaller than Swin4CV, which is mainly reflected in the smaller numbers of attention heads, layers, and stages and dimension of hidden vectors. However, **this does not mean that the underlying pattern of time series is essentially low-level. The patterns of time series data, such as meteorological data, may be very complex**, especially considering the interrelationships between multiple time series.\n\n### **For the 2nd question** \n&emsp;&emsp;Previous prediction models, such as Transformer, Autoformer, and Fedformer, can indeed be compatible with CI/CD. However, these models just fuse multiple channels with an embedding layer and do not explicitly consider the correlations between them, and thus the complexity of these models is not relevant to the number of channels. **Swin4TS, on the other hand, can be compatible with both CI/CD strategies and can explicitly consider the correlations between multiple variables under CD strategy**."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3334/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700282531401,
                "cdate": 1700282531401,
                "tmdate": 1700282574042,
                "mdate": 1700282574042,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NNz98GYvZm",
                "forum": "dszD2gZIif",
                "replyto": "OPg6wdzXW8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3334/Reviewer_SUuV"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3334/Reviewer_SUuV"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your responses. The authors have addressed several questions with more detailed experiments and clarifications. And I would like to specify a few questions mentioned:\n\n* About Figure 1: I think Figure 1 just shows the operation, it needs to show more correspondence. As the author clarified \"times series also require division into patches to eliminate the randomness\", how does the figure convey this?\n* About Figure 2: It is hard to distinguish patches and windows by the line style. It can be more intuitive to use some color for blocks. It is better to explain the circle (time points localized in this or just sub-series in the period?) and avoid dense arrows.\n* About Table 2. As far as I know, ETT is not a well-acknowledged univariate forecasting benchmark, which contains the covariates for predicting each other. Why not test them on a more widely accepted M4 benchmark as proposed in NBEATS[1]?\n\nConsidering the above responses, I am more convinced of the author's motivations. I think the contribution is enough if this work aims to show the structural similarity of time series and image and to make these two modalities benefit a unified framework (finding the same foundation model). However, it still needs more cases to support this  (as the author newly included TNT), focus more on the conclusions instead of detailed structure, and provide some takeaway messages. If this article is to be written in this way, I think there are at least a few points that need further consideration:\n\n- Time series forecasting needs not only locality. It has many properties (such as periodicity) to consider that images do not.\n- The scale of the time series and image are also different. Time series do not have a fixed range like RGB domains.\n- Not only does the attention model matter, but it is also an essential task to consider the other parts. The current projection head, which is a straightforward linear layer from the past features to the future prediction, can overfit on some of the small datasets of the paper since recent research find that a simple linear layer can especially work better on this [2].\n\nOverall, I raised the score to 3. If the author can kindly take into consideration of the experiments and presentation of the paper, I will go further on this.\n\n\n\n[1] N-BEATS: Neural basis expansion analysis for interpretable time series forecasting.\n\n[2] Revisiting Long-term Time Series Forecasting: An Investigation on Linear Mapping."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3334/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700471664127,
                "cdate": 1700471664127,
                "tmdate": 1700477862367,
                "mdate": 1700477862367,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MC1zDUT0KU",
                "forum": "dszD2gZIif",
                "replyto": "HduNui6dTt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3334/Reviewer_SUuV"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3334/Reviewer_SUuV"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the authors' effort in answering my questions. The authors have addressed most of my concerns about the contributions and paper presentations. \n\nThanks for including a detailed discussion on ViT4TS architectures, which gives more insights into the structural similarity of time series and images and how to facilitate it. \n\nI understand the time is limited. However, I think it is still important to compare the forecasting results on larger datasets and ablate more extensively, since the current contributions, as the author clarified, are making the forefront of ViTs to facilitate research in time series analysis. While it is important to find evidence of ViTs that work, it should also convey what can malfunction, with in-depth consideration of the modality gap. The current version does not pay much attention to this point. So the novelty may remain an issue. I believe the paper will go further and it will be tackled by the author in the future. \nOverall, I raised my score to 5. Thank you once again for clarifying a lot of the points."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3334/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700728242584,
                "cdate": 1700728242584,
                "tmdate": 1700728242584,
                "mdate": 1700728242584,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "M0wTbYLiDi",
            "forum": "dszD2gZIif",
            "replyto": "dszD2gZIif",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3334/Reviewer_9qJL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3334/Reviewer_9qJL"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes to transfer the success of vision transformer to time series forecasting. The proposed method incorporates window-based attention and hierarchical representation from Swin Transformer to long-term time series forecasting. Experimental results showed state-of-the-art performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. It's novel to incorporate the window-based attention and hierarchical representation from Swin Transformer to time series forecasting.\n\n2. The performance is better than baselines."
                },
                "weaknesses": {
                    "value": "1. The current time series forecasting datasets are pretty small, and performance may be satuated or over-fitting. Could the method be used for larger datasets?\n\n2. Scalformer [1] also uses hierarchical design and the scales of time series data, this paper didn't mention and compare the similarities and differences with Scalformer.\n[1] Shabani, Amin, et al. \"Scaleformer: iterative multi-scale refining transformers for time series forecasting.\" ICLR (2023)."
                },
                "questions": {
                    "value": "1. The current time series forecasting datasets are pretty small, and performance may be satuated or over-fitting. Could the method be used for larger datasets?\n\n2. Scalformer [1] also uses hierarchical design and the scales of time series data, Could this paper compare the similarities and differences with Scalformer.\n\n[1] Shabani, Amin, et al. \"Scaleformer: iterative multi-scale refining transformers for time series forecasting.\" ICLR (2023)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3334/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699059472449,
            "cdate": 1699059472449,
            "tmdate": 1699636282656,
            "mdate": 1699636282656,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Fa9pwVjW8D",
                "forum": "dszD2gZIif",
                "replyto": "M0wTbYLiDi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3334/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3334/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer 9qJL"
                    },
                    "comment": {
                        "value": "&emsp;&emsp; First of all, thanks very much for your comments.\n\n&emsp;&emsp; Regarding the issue of dataset size, **most existing baselines for time-series prediction use the 8 datasets mentioned in the text as benchmarks. We selected them in order to have a fair comparison with other baselines**. However, as you mentioned, these datasets are relatively small and there are possible distributional shifts between the training and validation sets, which is a problem faced by all existing baseline models.\n\n&emsp;&emsp; In our collaboration project with a wind farm, we applied Swin4TS to predict wind power. The training dataset contained wind power data for 14 wind turbines, recorded every 15 minutes over a span of 5 years, comprising approximately 175k timesteps, far larger than the aforementioned 8 datasets. The goal was to predict wind power for the next 24 hours (96 points) and 72 hours (288 points), with an input size of 288. We compared three models, PatchTST, DLinear, and LightGBM. The prediction results are shown below (the results are in terms of normalized MSE).\n\n|            |     Swin4TS/CI    |     Swin4TS/CD    |     PatchTST    |     DLinear    |     LightGBM    |\n|:------------:|:-------------------:|:-------------------:|:-----------------:|:----------------:|:-----------------:|\n|     96     |     0.472         |     0.468         |     0.512       |     0.587      |     0.502       |\n|     288    |     0.632         |     0.652         |     0.633       |     0.781      |     0.649       |\n\n&emsp;&emsp; Swin4TS has performed well in predicting 96-point and 288-point. Unfortunately, due to commercial cooperation agreements, we cannot open this dataset. **We believe that Swin4TS's superior architecture is the reason for its better performance rather than the accidental fit to specific datasets, and we expect it to perform well on other large datasets as well**.\n\n&emsp;&emsp; Thanks for reminding us of the Scaleformer. Scaleformer and Swin4TS both use a hierarchy design, but their architectures are very different. Firstly, Scaleformer uses an external hierarchy design to obtain predictions at multiple scales, while Swin4TS uses an internal hierarchy design to concentrate information of different scales in the final representation and obtain the final prediction. Secondly, the prediction module in Scaleformer is totally independent, and Scaleformer is compatible with various transformer-based models. However, Swin4TS is a complete model, making it difficult to directly compare the performance with Scaleformer. Due to length limitations, we have added a short comment on Scaleformer in \u201cRelated Work\u201d of the revised manuscript.\n\n&emsp;&emsp; **Although you did not mention the contribution, we believe that the contributions of this work might be underestimated. We not only provide an effective time series prediction framework, but more importantly, it confirms the structural similarity of time series and image, which indicates the possibilities of modeling time series modality using architectures from image modality. We elaborated on this point in detail in our response to reviewer 9ZZq and SUuV. We also supplemented the design of a TNT4TS framework to support our view. We sincerely hope you can consider our work again.**"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3334/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700281638454,
                "cdate": 1700281638454,
                "tmdate": 1700657443423,
                "mdate": 1700657443423,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "tDhmkZYFbG",
            "forum": "dszD2gZIif",
            "replyto": "dszD2gZIif",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3334/Reviewer_9ZZq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3334/Reviewer_9ZZq"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes use Swin Transformers (popularly used as vision transformers) for long-term time-series forecasting (ltsf). The paper proposes both channel independent and channel dependent models for multivariate LTSF forecasting. It shows that the the models can be beat or match prior transformer based baselines. More over the time-complexity does not scale quadratically with the total number of patches as in PatchTST because of the use of shifted window based attention."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. I think the SWin transformer idea fits well into LTSF tasks because it reduces the number of self attention operations which is useful for long concepts and hierarchical representations are logically the right choice for extracting multi time-scale features from time-series data.\n\n2. For the CD model, the SWin transformer concept can again be applied to have not so expensive cross series attention although I have some questions in this regard.\n\n3. The time-complexity is understandably better than other transformer based models.\n\n4. The performance on the model is more often than not better than PatchTST which is the next best transformer based model.\n\n4. The paper is easy to read."
                },
                "weaknesses": {
                    "value": "1. The paper does not compare to non-transformer based baselines which are computationally more efficient.\n\n2. The ordering of the series should matter for the CD model which not a desirable property.\n\n3. The last layer of the CD model is not fully clear.\n\n4. The model performance is not monotonically increasing with size of context in some corner cases which is not the case with other SOTA models.\n\n5. Is the ablation of varying hierarchical design done in the correct manner? As I understand more hierarchies also mean more layers? Is it not better to keep the number of layers the same and just have hierarchy in one model while the scales are fixed in all layers in the ablation one?\n\n6. What would be the strategy to handle static and dynamic covariates ?\n\nOverall I believe the paper is well written and the use SWin is logical at least in the CI case. The architecture is not novel but nevertheless has not been used for time-series before. I would like to see the answers of my questions before deciding on the final score. It would also be good if the authors can think of some way to show whether the different scales in the hierarchy extract different types of information like long term trends vs local seasonality."
                },
                "questions": {
                    "value": "1. Can the authors elaborate what the last layer looks like for the CD model? is it just mapping the flattened version of all output tokens to the future of all M time-series. In this case is this layer not too big? There might be better designs that map only specific patches to specific output predictions.\n\n2. For vision models contiguous patches in the window are visually close in the image. This is not the case for the channel dimension in the CD time-series case. In other words does the order of the time-series matter? It should not matter in the ideal case. Can the authors show this experimentally?\n\n3. Since the paper has a section on time-complexity it would be wise to compare with non transformer methods like TiDE (https://arxiv.org/pdf/2304.08424.pdf) and N-HiTS (https://arxiv.org/pdf/2201.12886.pdf). These methods are much faster and have comparable or better performance. For instance the numbers reported in the traffic dataset for the TiDE model are better than the ones reported in the paper. It would be good to cite and compare to these MLP based works.\n\n4. It seems that for some horizon lengths in Figure 6 the performance decreases a little bit with increasing context. This does not seem to be the case for PatchTST and TiDE. Any intuition on why this might be happening?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3334/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699310911135,
            "cdate": 1699310911135,
            "tmdate": 1699636282583,
            "mdate": 1699636282583,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZPu57EOqF5",
                "forum": "dszD2gZIif",
                "replyto": "tDhmkZYFbG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3334/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3334/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer 9ZZq (Part 1/2)"
                    },
                    "comment": {
                        "value": "&emsp;&emsp; Thanks very much for your review and suggestions. We next reply to your questions and concerns point to point.\n\n### **For the 1st concern about weaknesses**\n&emsp;&emsp;**In fact, we have compared three non-transformer methods:** DLinear (MLP-based), TimesNet (CNN-based), and MICN. Please see the description in the \u201cCompare baseline\u201d section.\n\n ### **For the 2nd concern**\n &emsp;&emsp;Indeed, under the CD strategy, multiple time series can not be treated as an image, as the order of the time series can vary. In our code implementation, the order of the time series is shuffled in each training batch, and we found that this trick yielded better results than fixed initial order. We provided additional clarification on this point in the main text, and relevant experiments presented in the Appendix C.3.\n\n### **For the 3rd concern**\n&emsp;&emsp; The final layer of Swin4TS/CD is directly mapped to MT (M is the number of series, and T is the prediction length) after learning a representation using Swin Transformer. **As you might know, this is not a good choice because for the 720-prediction task on the Traffic dataset, the size of final layer would be 862x720. This is also why the prediction performance on Traffic (M=862) and Electricity (M=321) is relatively poor under the CD strategy.** A reasonable way to address this would be to design a U-net architecture and gradually obtain MT through upsampling on the representation. **We added a part in Appendix D to address the effectiveness of this modified framework**. However, to ensure the algorithm\u2019s simplicity and consistency with the CI strategy, we still chose the simpler one as mentioned above.  We did not want to complicate the main architecture because based on the motivation of this work, we hoped to demonstrate the structural similarity between the two modalities of time series and image and that they can be modeled using the same framework.\n\n### **For the 4th concern**\n&emsp;&emsp;  Our results show that prediction performance varies non-monotonically with input length. **In fact, PatchTST has also reported similar phenomena, as shown in Table 9.** For example, for the 720-prediction task on ETTh2, 336-input leads to 0.379-MSE, 720-input leads to 0.394-MSE. **Autoformer and FEDformer exhibit similar phenomena, as shown in Figure 2 of the PatchTST\u2018s paper**. One possible explanation is that the input data contains both underlying patterns about the time series as well as noise. Once the input length is sufficient to capture the underlying patterns, longer input will introduce more noise and harm prediction performance.\n\n### **For the 5th concern**\n&emsp;&emsp; In our work, we gave the analysis of the hierarchy design in two parts. The first part is the Ablation Study in section 4.2 Results, where **the hierarchy design was ablated in the manner just suggested by the reviewer**, as described in the main text. The second part is the varying hierarchical design in section 4.3 Effect of Hyperparameter (we moved this part in Appendix), which is not ablation of the hierarchy design, but rather an examination of the impact of different hierarchy architectures on the model. Please note the distinction.\n\n### **For the 6th concern** \n&emsp;&emsp; Thanks for your suggestion. We have attempted to integrate dynamic covariates (the timestamp of the samples) into the input via embedding. **Surprisingly, there was a significant improvement in predictive performance on the Traffic dataset!** However, the effect was not observed on other datasets, which may be due to the Traffic dataset\u2019s natural periodicity. We have incorporated this trick into the code, and added some descriptions of it in the Appendix C.6, and update the prediction results in Table 1."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3334/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700281171704,
                "cdate": 1700281171704,
                "tmdate": 1700281171704,
                "mdate": 1700281171704,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QAMnYfg1SO",
                "forum": "dszD2gZIif",
                "replyto": "tDhmkZYFbG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3334/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3334/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer 9ZZq (Part 2/2)"
                    },
                    "comment": {
                        "value": "### **For the 1st question**\n&emsp;&emsp;  We have addressed this in our previous response. **We carefully considered your suggested approach and found that it is similar to our U-net solution**. This design and relevant experimental results are supplemented in the Appendix D.\n\n### **For the 2nd question**\n&emsp;&emsp;  We have answered this above.\n\n### **For the 3rd question**\n&emsp;&emsp;  We appreciate your suggestions. In the revised manuscript, we cited these two works. **However, it\u2018s hard for us to directly compare these two baselines in our main results. This is because the input size L is set to 720 for TiDE, while our Swin4TS sets L=512**. It is unfair to compare with it directly. In N-HiTS, the input size is varied among datasets, which makes the comparison even more difficult. We hope the reviewer can understand this. In addition, after the use of dynamic covariates as you suggested, the prediction performance of Traffic of Swin4TS is comparable with TiDE.\n\n### **For the 4th question**\n&emsp;&emsp;  We have addressed this above.\n\n### **For your suggestion**\n&emsp;&emsp; In addition, we analyze the information extracted by the hierarchical design at different scales. Please see Figure 6 and relevant descriptions.\n\n&emsp;&emsp; **In the end, we hope the reviewer can reconsider the contribution of our work. We not just propose an effective model to handle time series forecasting problem. More importantly, we consider the structural similarity between image (partition into patch series) and time series, which makes these two modalities can be modeled in a unified architecture. Further, time series modeling can benefit from the development of ViTs, please see the extensive discussion with Reviewer SUuV. We added some disscusions at the end of the revised manuscript, and additionlly designed a TNT4TS model to support our view, and showed relevant experimental results in Appendix E.**"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3334/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700281380116,
                "cdate": 1700281380116,
                "tmdate": 1700281380116,
                "mdate": 1700281380116,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8JMWMTZzan",
                "forum": "dszD2gZIif",
                "replyto": "QAMnYfg1SO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3334/Reviewer_9ZZq"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3334/Reviewer_9ZZq"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the discussion"
                    },
                    "comment": {
                        "value": "__Comparison to MLP methods:__ I would like to point out the DLinear is not an MLP as there is no non-linearity. Moreover TimesNET is also CNN based, not an MLP. Therefore I still think comparison to TiDE and NHiTS is essential. In particular Table 2 in TiDE paper has numbers from both the models. Ideally it would be good to your numbers to this table and you are free to tune the prediction horizon per dataset. Note that you already have the results over a variety of context lengths in Table 13, so you could have easily compared the best numbers. I am still confused as why this would have been unfair. Also a comparison wrt to computational complexity is warranted.\n\nThanks for adding the dynamic covariate results and I am glad to see the performance boost on traffic.\n\n__U-Net:__ The U-Net experiments that were added was interesting. I am curious if there was a dataset where CD + U-NET performed better than CI? If that is not the case, then the practical implication of this still remains unexplored.\n\n__Motivation:__ If the main motivation of the paper is indeed merging image and time-series modality, then even preliminary experiments using a mixture of two modalities is warranted. My view of the paper was that it was trying to show that Swin transformers could be SOTA in long-term forecasting, which is slightly different from the motivation listed in the rebuttal answers. I tend to agree with some of the points mentioned by reviewer SUuV in this regard. \n\nI would like to keep the score at 5 for now but will definitely consider raising it after further discussion, including ones with other reviewers."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3334/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700508017472,
                "cdate": 1700508017472,
                "tmdate": 1700508017472,
                "mdate": 1700508017472,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Ik94Tw5Qqy",
            "forum": "dszD2gZIif",
            "replyto": "dszD2gZIif",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3334/Reviewer_xaLq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3334/Reviewer_xaLq"
            ],
            "content": {
                "summary": {
                    "value": "This paper adapts the idea of using Vision Transformers (ViT) to the problem of time series forecasting. Vision transformers divide an image into patches and perform attention on the patches in order to attend to the whole image and yield a prediction. The idea is adapted to the problem of multivariate time series forecasting where the time series are divided into multiple windows and the windows are further divided into multiple patches. Attention layers are applied to the patches within a single window known as window attention. Shifted window attention is window attention on the time series shifted by half a window. The final architecture is a sequence of window and shifted window attentions for processing a particular scale. The model processes at multiple scales by feeding the downsampled output from the output of scale K as the input for scale K+1. The final predictions are derived using a linear layer on the flattened output from each of the scales.\n\nExperimental results show superior performance compared to other neural network based approaches including transformer based approaches."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The main contribution of this paper is an approach for long term forecasting of time series using a transformer based approach.\n- The proposed method can efficiently scale to very long time series due to a ViT like architecture dividing the time series into multiple windows and patches.\n- The model is able to attend to various scales in the time series by virtue of the downscaling steps between different scale blocks.\n- The CD variant of the proposed method can efficiently model the correlation between multiple time series.\n- Experimental results show improved performance for long term prediction problems.\n\nAs summarized in table 4, the proposed model is computationally and memory efficient compared to the other approaches, while being able to model the correlations between multiple time series."
                },
                "weaknesses": {
                    "value": "The paper does not seem to have any significant weaknesses. Some minor issues:\n- Novelty: The main idea of the paper is derived from the existing Swin transformer idea, which slightly weakens the novelty of the paper.\n- The confidence intervals are missing from the MSE and MAE values in the results tables."
                },
                "questions": {
                    "value": "What is the strategy for selecting the hyper-parameters of the architecture? Were the hyper-parameters selected for each dataset individually using the validation set? Or were the hyper-parameters selected globally for all the problems simultaneously?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3334/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699340564210,
            "cdate": 1699340564210,
            "tmdate": 1699636282516,
            "mdate": 1699636282516,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "te7RtH7D0f",
                "forum": "dszD2gZIif",
                "replyto": "Ik94Tw5Qqy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3334/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3334/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer xaLq"
                    },
                    "comment": {
                        "value": "&emsp;&emsp; Thank you very much for your recognition of our work.\n\n&emsp;&emsp; Regarding the issue of the confidence interval for MSE and MAE that you mentioned, our main experiment setup uses a fixed random number, which is conventionally set to the number of current year. Therefore, MSE and MAE are the results of a single experiment, and there is no need to calculate the confidence interval. Of course, we have studied the impact of random seed (i.e. different initialization) on the model's performance, and the relevant results are in Appendix C.1. Since the results are presented in histogram form, there is no calculation of the confidence interval, please understand.\n\n&emsp;&emsp; For the selection of hyperparameters. We make similar datasets adopt the same hyperparameters, such as the 4 ETT datasets. Furthermore, different datasets may require different hierarchical designs, and the setting of hyper-parameters should ensure that the input length can be divisible during the downsampling process. In addition, other hyperparameters will reference the settings of other models, such as learning rate or early stop. Different datasets, due to their own properties, usually have different parameter sets. For example, in Traffic and Weather, the former\u2019s periodicity is more obvious than the latter, and the interaction between multiple variables is also different.\n\n&emsp;&emsp; **For the novelty**. We borrowed the idea of Swin Transformer for modeling time series, and indeed, the novelty is not particularly strong if only considering this. **However, our contribution is not only proposing an effective method for modeling time series. More importantly, we consider the structural similarity between image (partitioned into patch series) and time series, which indicates the possibilities of modeling time series modality using architectures from image modality. We additionally supplemented a TNT4TS framework to support our view.** The reviewer can refer the detailed response to Reviewer 9ZZq and SUuV, and we hope the reviewer can reconsider the contribution of our work."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3334/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700280759981,
                "cdate": 1700280759981,
                "tmdate": 1700657311365,
                "mdate": 1700657311365,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]