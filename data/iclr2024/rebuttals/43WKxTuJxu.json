[
    {
        "title": "Orthogonal Function Representations for Continuous Armed Bandits"
    },
    {
        "review": {
            "id": "i7E14B0f85",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1798/Reviewer_DACT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1798/Reviewer_DACT"
            ],
            "forum": "43WKxTuJxu",
            "replyto": "43WKxTuJxu",
            "content": {
                "summary": {
                    "value": "This paper studies the continuum-armed bandit problem, which is an extension of the traditional multi-armed bandit. Specifically, the authors propose an explicit representation using an orthogonal feature map (e.g. based on Fourier, Legendre functions) to transform the original problem into a linear bandit with misspecification. And the authors develop two algorithms named OB-LinUCB and OB-PE and use a suite of simulations to verify the efficiency of the proposed algorithms."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Most parts of the paper are quite clear and easy to follow. \n\nBased on my knowledge it is new to use orthogonal function bases to transform the continuum-armed bandit into misspecifed linear bandits. The simulations also showcase the high efficiency of proposed algorithms.\n\nI haven't checked all details of the proof in the Appendix, but I feel they should be correct. I will refer to other reviewers' opinions as well."
                },
                "weaknesses": {
                    "value": "1. Nowadays, the study on continuum-armed bandit also focuses on the general metric space. (e.g. Zooming algorithm mentioned in your work studies arbitrary space with any distance). Could you extend your algorithm to general metric space? I feel it should be possible if we can construct a decent orthogonal basis on any metric space, is that true? But how to construct the function base is required but unknown.\n\n2. I agree it is relatively hard to explore multidimensional space $[0,1]^d$, but I feel the current results in this work on multidimensional space are still weak. From Table 1 the proposed OB-PE can achieve non-optimal regret bound under the condition $d < 2s$, which is not up to the state-of-the-art literature in this area. For implementation, both the number of arms and the dimension of arms would increase exponentially, and hence I am not sure whether it can still perform well in multidimensional space.\n\n3. Without knowing the value of $T$, I am not sure if the proposed algorithm still works since some settings (e.g. $N$) rely on the value of $T$.\n\n4. For the presentation of Algorithm 1, why don't the authors specify how to discretize the arm space directly there? It seems that discretization is unavoidable for OB-LinUCB and OB-PE."
                },
                "questions": {
                    "value": "Besides my concerns in the above Weaknesses section, could you also answer my question about your experiment as follows:\n\n1. It seems that you only use OB-LinUCB which is lack of strong theoretical support in your experiment. Why don't you use OB-PE as well since it has some good theoretical property instead? It seems there is some inconsistency between theory and experiments.\n\n2. I may overlook, but how many arms do you choose in experiments for OB-LinUCB? I think you discretize the interval [0,1] evenly (maybe with $\\sqrt{T}$ arms). Do you have any theoretical support for OB-LinUCB when discretizing the arm set? I think this is very important and should be illustrated in your main paper clearly.\n\n3. Some experiments one high-dim space (e.g. [0,1]^2) will make your experiments more reliable. I am concerned on the computational issue of the algorithm since the number of arms and dimension may explode exponentially."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1798/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1798/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1798/Reviewer_DACT"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1798/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697175107374,
            "cdate": 1697175107374,
            "tmdate": 1699636109341,
            "mdate": 1699636109341,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hNu6S9X4lQ",
                "forum": "43WKxTuJxu",
                "replyto": "i7E14B0f85",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1798/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1798/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to the reviewer"
                    },
                    "comment": {
                        "value": "**Continuum-armed bandit on the general metric space.** Unfortunately, generalizing this approach to that setting would be highly nontrivial, as polynomial and trigonometric features are not even defined on arbitrary metric spaces. On the other side, the main competitor of this algorithm, UCB-meta-algorithm, suffers the same issue, also because the concept of \"differentiability\" itself cannot be trivially defined.\n\n**Computational performance in multidimensional space.** Please see the common answer about computational complexity.\n\n**Does the algorithm work without knowing the value of $T$?** Please see the common answer about adaptivity.\n\n**For the presentation of Algorithm 1, why don't the authors specify how to discretize the arm space directly there?** In fact, discretization is unavoidable for all the algorithms considered in the state of the art, the only exception being Zooming, which without discretization is NP-Hard. Therefore, to grant a fair comparison, we preferred not to specify the discretization to show in Table 1 how the performance of every algorithm depends on the number of its elements. Indeed, it is true that in the general case, a uniform $T^{-1/2}-$cover would be the best choice, but also emphasizing the dependence on the cardinality $k$ of a general discretization is important.\n\n**Use of OB-LinUCB rather than OB-PE in the experiments** We made this choice based on the principle that, usually, algorithms that optimize the worst-case regret are not the best option in practice. Coherently with this choice, we have compared our algorithm not with BPE, which achieves the best regret in kernelized bandits, but with IGP-UCB, which is well-known to have superior performance in practice regardless of the worse regret bound. Still, since also the practical performance of OB-PE is an interesting question, we are going to perform the experiments with this algorithm and upload them in a new version of the paper before the end of the discussion period.\n\n**Discretization in the experiments** As the reviewer has understood, we discretize the interval [0,1] evenly with $\\sqrt T$ arms. Unfortunately, OB-LinUCB is not endowed with a regret bound for this setting, and it is only shown as the most natural algorithm that can be built with orthogonal function representation.\n\n**Some experiments one high-dim space (e.g. $[0,1]^2$) will make your experiments more reliable. I am concerned on the computational issue of the algorithm since the number of arms and dimension may explode exponentially.** First point: Being the algorithm valid for $d>1$, it is indeed a good idea to add an experiment in case of a bi-dimensional environment. We will do it and upload it in a new version of the paper before the end of the discussion period. Unfortunately, it will not be possible to include also the baselines used in the current experiment, as their running time is too high, and we cannot have the results in time. Second point: See the common answer about computational complexity.\n\nWe thank the reviewer for their comments and have hope to have addressed all their questions."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1798/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700045365028,
                "cdate": 1700045365028,
                "tmdate": 1700045365028,
                "mdate": 1700045365028,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "b0ZVnTjNHE",
                "forum": "43WKxTuJxu",
                "replyto": "hNu6S9X4lQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1798/Reviewer_DACT"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1798/Reviewer_DACT"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your responses and additional experiments"
                    },
                    "comment": {
                        "value": "I'd like to appreciate authors' responses to my questions and the additional experiments made for OB-PE. I believe this work has its merit and some extensions such as to general metric space is highly non-trivial. And the idea of introducing orthogonal feature mapping is new and interesting. However, I still have concern on some presentation of the work: I feel it would be better to mention how to discretize the space explicitly in the pseudocode in detail. And the computational benefit of the algorithm is not very general. Therefore, I feel this paper is right on the borderline, and I will keep my score for now."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1798/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700628243275,
                "cdate": 1700628243275,
                "tmdate": 1700628243275,
                "mdate": 1700628243275,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "YA1XK2o1ac",
            "forum": "43WKxTuJxu",
            "replyto": "43WKxTuJxu",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1798/Reviewer_MY3R"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1798/Reviewer_MY3R"
            ],
            "content": {
                "summary": {
                    "value": "The paper resolves the continuous arm bandits where the reward function is smooth. By introducing orthogonal Fourier and Legendre feature maps, the paper shows that an approximation of the smooth function is possible even when the feature map is not available to the learner. The proposed algorithm achieves the nearly optimal regret bound in $d=1$ dimensional cases and in $d>1$ dimensional cases where the reward function is analytic. Empirical results show fair performance of the algorithm with computational efficiency."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper eliminates the assumptions on the reward functions in bandit problems with continuous arms and without Gaussianity, by constructing an orthogonal feature map. The proposed algorithm is principled and computationally efficient for estimating general reward functions. Helpful discussion on the hardness of deriving optimal regret bound on multidimensional arms navigates the future work direction."
                },
                "weaknesses": {
                    "value": "(a) In Theorems 3-5, the choice of $N$ requires the knowledge of $T$.\n(b) There is a large gap between the choice of $N$ in theoretical results and empirical results. The performance and the computational time of the proposed algorithms seem to be heavily affected by the choice of $N$. Numerical results and discussions on different choices of $N$ seem missing."
                },
                "questions": {
                    "value": "Q. Could the algorithm be modified to execute without knowing $T$ a priori?\nQ. How could we choose $N$ when we do not know the true reward function? If we choose $N$ as in Theorems 3-5, would computation be heavy?\nQ. How does the choice of $N$ affect the performance and computational time of Fourier UCB and Legendre UCB?\nQ. In Figures 1 (b) and 2 (b), why do Fourier UCB and Legendre UCB perform worse when they use only even functions and the true reward function is even?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1798/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1798/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1798/Reviewer_MY3R"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1798/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698360376913,
            "cdate": 1698360376913,
            "tmdate": 1699636109269,
            "mdate": 1699636109269,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9RFmQKMPtj",
                "forum": "43WKxTuJxu",
                "replyto": "YA1XK2o1ac",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1798/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1798/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to the reviewer"
                    },
                    "comment": {
                        "value": "**Adaptivity for unknown $T$ and how to choose $N$ without $s$.** See the common answer about adaptivity.\n\n**Choice of $N$ in the experiments.**\nKeeping the values of $N$ in the experiments disconnected from theory was a deliberate choice to show that the requirement to know the differentiability of the reward function exists only in theory. In fact, having chosen a fixed value of $N$ for functions with very different levels of regularity suggests that this parameter can be chosen in a totally empirical way and tuned very easily.\n\n**Computational complexity dependence on $N$.**\nThis question is linked to the theme of computational complexity, therefore, we suggest the reviewer to also see the \"Computational complexity\" section in the answer to all reviewers. In short, the computational complexity scales as $N^{3d}$, which means $\\widetilde N^3$, where $\\widetilde N$ is the number of features. This is unavoilable while using algorithms for linear bandits, as inversion of a design matrix is necessary. Still, note that the algorithm chooses $N$ in a way that $N^{d}\\le T$, so that the full computational complexity does not explode.\n\n**In Figures 1 (b) and 2 (b), why do Fourier UCB and Legendre UCB perform worse when they use only even functions and the true reward function is even?**\nWe thank the reviewer for noticing this subtle phenomenon. The reason stays in the true reward function: as it is a polynomial of degree 4, including in the feature map even polynomials of higher degree is as useless as including odd functions. In fact, as high-frequencies are more prone to overfitting the noise, the effect of including these features may be even worse than adding other useless components, as in this example.\n\nWe thank the reviewer for their comments and insightful observations and hope to have addressed all their questions."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1798/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700045317232,
                "cdate": 1700045317232,
                "tmdate": 1700045317232,
                "mdate": 1700045317232,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BnKtOZ6ist",
                "forum": "43WKxTuJxu",
                "replyto": "9RFmQKMPtj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1798/Reviewer_MY3R"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1798/Reviewer_MY3R"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response. It addresses most of my questions. But still, I have some questions on $N$\nQ. Could you explain why $N$ can be tuned very easily?\nQ. If the algorithm chooses in a way $N^d \\le T$, is the condition $N=T^{\\frac{d}{2s}} violated? If $N$ is chosen empirically, does the theoretical regret guarantee still hold?"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1798/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700658198867,
                "cdate": 1700658198867,
                "tmdate": 1700658198867,
                "mdate": 1700658198867,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9m2bRge3lA",
            "forum": "43WKxTuJxu",
            "replyto": "43WKxTuJxu",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1798/Reviewer_hB5r"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1798/Reviewer_hB5r"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies continuum arm bandits with a generic smoothness assumption on the reward being $s$ times continuously differentiable. The main new idea of the paper is that by using a finite representation of the reward function in terms of a known orthogonal basis for the function class, one can reduce the problem to misspecified linear bandits. This leads to an algorithm with optimal regret in some regimes and better computation time than prior algorithms in the literature.\n\nWhile I think the idea of this paper is novel, the theoretical regret bounds are only optimal in some regimes and the overall benefit especially over the cited algorithm UCB-Meta-algorithm is unclear."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The paper is easy to read and well-written despite being quite math heavy, and I found the main algorithmic idea straightforward to follow.\n* The thorough comparison with prior works in Section 5.3 was helpful for placing this result in context with the rest of the literature."
                },
                "weaknesses": {
                    "value": "* It seems like the theoretical regret upper bounds require tuning $N$ with knowledge of the underlying reward function's smoothness $s$. This seems like an unrealistic assumption to me. Can the authors comment on misspecified $s$ or adapting to unknown $s$?\n* In order to even use the orthogonal features (at least for dimension $d=1$), it seems like one also needs $(s+1)$-th derivative of $f$ to be square integrable. Is this a reasonable assumption to make for common reward functions in stochastic optimization? Some discussion on this would be nice.\n* Looking at Table 1, it seems like the UCB-Meta-algorithm attains the optimal regret, while the main procedure of this paper OB-PE does not get optimal regret for $d>1$. The paper claims UCB-Meta-Algorithm has no regret guarantee for infinitely-differentiable rewards, but I don't see why I can't just run UCB-Meta-Algorithm with very large Holder exponent $s \\gg d$ which should get a regret bound which is nearly $T^{1/2}$ acccording to bounds of Liu et al., 2021. Thus, the only real advantage of OB-PE seems to be in time complexity.\n* There is a discrepancy between experiments and theory in the sense that the paper uses two different algorithms OB-PE vs OB-LinUCB for theoretical regret bounds vs experiments. It's not explained why OB-PE is not implemented or analyzed in experiments. Some explanation on this would be nice."
                },
                "questions": {
                    "value": "# Questions\n* See above in \"Weaknesses\".\n* What is the dependence of the regret bounds of OB-PE on the Lipschitz constant $L$? In Lipschitz bandits literature, this is well known to be $L^{\\frac{d}{d+2}}$, but it is not clear to me what dependence appears here.\n* Theorem 4 for the $d>1$ dimensional regret upper bound does not seem to have any condition on the $(s+1)$-th partials of $f$, which seems wrong to me since Theorem 3 required it. Why is this?\n\n# Writing Suggestions/Typos\n* The regret formula in the first paragraph should have the terms reversed in the difference.\n* In the fifth paragraph of page 1, the domain $[a,b]$ of $\\phi$ should be $[a,b]^d$?\n* I was confused why initially the reward function $f:\\mathcal{X} \\to \\mathbb{R}$ has unbounded scale, yet all the regret bounds seem to be scale-free. This is because the paper later on assumes $\\|f\\|_{\\infty}=1$, i.e. assumes knowledge of the scale of $f$. It might be better to just define bounded reward $f:\\mathcal{X}\\to [0,1]$ from the outset to not mislead readers.\n* Many environment references throughout the writing (e.g., algorithm 1, appendix 1, equation (1)) should have their names capitalized (e.g., Algorithm 1).\n* In Section 4.2, the Lipschitz constant $L$ is used before it is defined.\n* In the writing, \"s+1-th derivative\" would read better as \"(s+1)-th derivative\"."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1798/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1798/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1798/Reviewer_hB5r"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1798/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698807444798,
            "cdate": 1698807444798,
            "tmdate": 1699636109186,
            "mdate": 1699636109186,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gK8wgfEtbL",
                "forum": "43WKxTuJxu",
                "replyto": "9m2bRge3lA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1798/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1798/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to the reviewer"
                    },
                    "comment": {
                        "value": "**Adaptivity on $s$.** See common answer about adaptivity.\n\n**Assuming square-integrable derivative in practice.** The setting of stochastic bandits has achieved relevant success in the field of pricing. In this area, bandit algorithms are used to optimize a function of the price $p$ given by $f(p):=p d(p)$ where $d(p)$ is an unknown function known as \"demand curve\", which is non-increasing in $p$ (ref. \"Pricing the long tail by explainable product aggregation and monotonic bandits\" by Mussi et al.). Of course, the differentiability of $f(\\cdot)$ corresponds to the one of $d(\\cdot)$, the demand curve, and since this function is decreasing and bounded in $[0,1]$, its derivative cannot be \"too large too often\". This can be formulated by asking that its derivative is square-integrable.\n\n**Infinitely differentiable functions.** We agree with the reviewer that, being $\\mathcal C^\\infty$ included in $\\mathcal C^s$ for every $s>0$, the algorithm from Liu et al., 2021 can achieve regret of order $\\mathcal O(T^{1/2+\\beta})$ for every $\\beta > 0$ when the function is infinitely differentiable. The point is that UCB-Meta-Algorithm has to choose a number of features that depends on $\\beta$ and diverges for $\\beta \\to 0$ (that algorithm relies on dividing the actions space in hypercubes and running a linear bandit algorithm in each hypercube. We refer to the number of features used by each of these linear bandits). Conversely, our algorithm uses fewer features the higher the value of $s$, and in particular, for $s=+\\infty$, it can achieve regret of order $\\sqrt T$ using the lowest number of features. This strange phenomenon makes the two algorithms complementary, with UCB-Meta-Algorithm being more suitable for large $d$ and small $s$, and our one for $d=1$ or $s=+\\infty$.\n\n**Use of OB-LinUCB in the experiments.**  We made this choice based on the principle that, usually, algorithms that optimize the worst-case regret are not the best option in practice, where simplicity works much better. Coherently with this choice, we have compared our algorithm not with BPE, which achieves the best regret in kernelized bandits, but with IGP-UCB, which is well-known to have superior performance in practice regardless of the worse regret bound. In the end, if ever one of our algorithms has a hope to be used in practical scenarios, this is probably OB-LinUCB, which is the most natural marriage between a Linear Bandit algorithm and the orthogonal function representations. Still, we will implement OB-PE and let the reviewer have its result by the deadline of the discussion period.\n\n**Dependence of the regret bounds of OB-PE on the Lipschitz constant $L$.** Thanks for the question, which opens up some reflections we hadn't considered. Our regret bound is roughly of order\n    $$R_T \\le \\mathcal O\\left (\\sqrt{N^d T}+LN^{d/2}N^{-s}T\\right ),$$\nwhere $L$ is the Lipschitz constant of the $s-1$ derivative. With the optimal choice $N=L^{1/s}T^{1/2s}$ we get, in the regime $d<2s$ where we have regret guarantees,\n    $$R_T \\le \\mathcal O\\left (L^{d/(2s)}T^{(2s+d)/(4s)}\\right ),$$\nmeaning that the dependence is $L^{d/(2s)}$ (which of course becomes vacuous for $d>2s$, when also the regret is unbounded).\n\n**Assumptions of Theorem 4.** The different type of assumption reflects the difference in the type of analysis behind the result. In fact, given that the theory of Legendre polynomials has so far been developed only in one dimension, it is not possible to use it in the general case, and the argument used there does not make assumptions on the $(s+1)$-th derivative. This is linked to the reason why our analysis is sub-optimal for $d>1$.\n\nWe thank the reviewer for their comments and for identifying some typos in our paper. We hope we have addressed all of their concerns."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1798/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700045294749,
                "cdate": 1700045294749,
                "tmdate": 1700045294749,
                "mdate": 1700045294749,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lJIbUjkadw",
                "forum": "43WKxTuJxu",
                "replyto": "gK8wgfEtbL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1798/Reviewer_hB5r"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1798/Reviewer_hB5r"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarifying response. While I originally believed the main benefit of the proposed algorithm was in reduced computational complexity, reading the other discussions and general rebuttal, it seems like even that comparison is only superior in certain regimes of $d,s$. Overall, I think the \"reduction\" of infinite-armed bandits to linear bandits is interesting, but the overall benefit still seems to be lacking. As such, I will keep my score the same."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1798/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700487188987,
                "cdate": 1700487188987,
                "tmdate": 1700487188987,
                "mdate": 1700487188987,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "AqeRlLoVdh",
            "forum": "43WKxTuJxu",
            "replyto": "43WKxTuJxu",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1798/Reviewer_hchS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1798/Reviewer_hchS"
            ],
            "content": {
                "summary": {
                    "value": "Consider a continuous arm bandit problem where the action space is $[0,1]^d$. While Reproducing Kernel Hilbert Space (RKHS) feature maps have been used previously, they present computational difficulties. The authors propose an approach that uses an orthogonal feature map to convert the problem into a linear bandit problem. This approach not only offers competitive regret guarantees compared to existing methods, but also reduces computational complexity."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "An analysis of linear bandit algorithms under misspecification is utilized for continuous armed bandits, proposing an algorithm with a small computational complexity.\n\nIt demonstrates competitive performance numerically as well."
                },
                "weaknesses": {
                    "value": "A significant portion of this paper seems to be dedicated to presenting classical results. While understanding the foundation is essential, I would encourage the authors to consider focusing more on their unique contributions to the field.\n\nFrom my understanding, the proposed algorithm/analysis appears to present a solution for an efficient trade-off between misspecification (bias) and regret (variance) in the continuous arm bandit problem. However, the contribution seems to lie primarily in combining these elements, and I did not find the approach significantly novel. If there is technical novelty, it should be better presented and emphasized.\nThe paper does not clearly address the potential for the $d/s$ value to become significantly large (though not infinite). In such cases, the computational advantages of the proposed method compared to existing methods may not only be positive but could potentially be negative. This issue needs to be addressed.\n\nThe algorithm seems to require a substantial amount of inputs (values dependent on $T, N, s$, the choice of basis, etc.). How much does this limit its adaptability? Are there methods that are agnostic to $T$ or $s$? Or is this level of input requirement comparable to existing research? These questions are crucial when discussing the adaptability of the algorithm.\n\nConsidering the high standards of ICLR, it is unclear whether the contributions of this paper are significant enough to warrant acceptance. The authors might want to better highlight the novelty and impact of their work."
                },
                "questions": {
                    "value": "As I also wrote in the previous section:\n\n- What is the technical novelty of the proposed algorithm/analysis? How is it emphasized?\n- Can you explain how the proposed method addresses the potential for the d/s value to become significantly large?\n- To what extent does the substantial number of inputs required by the algorithm limit its adaptability?\n- Are there methods that are agnostic to T or s?\n- How does the level of input requirement in this paper compare to existing research?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1798/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1798/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1798/Reviewer_hchS"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1798/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698906716189,
            "cdate": 1698906716189,
            "tmdate": 1699636109124,
            "mdate": 1699636109124,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fC47rQEFOL",
                "forum": "43WKxTuJxu",
                "replyto": "AqeRlLoVdh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1798/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1798/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to the reviewer"
                    },
                    "comment": {
                        "value": "**Paper organization**\nThe theory behind our algorithm is highly nontrivial for someone with a background different than mathematics. Therefore, we have decided to keep in the main paper the parts that are essential for comprehending the paper and leave the more advanced and subtle discussions in the appendix.\n\n**Novelty**\nWe acknowledge the reviewer's observation that our analysis relies heavily on theorems already established in the field of functional analysis. However, we disagree with the notion that this diminishes the novelty of our work. On the contrary, given that existing literature predominantly employs Kernel methods or focuses on finding a cover for the arm space, the utilization of a theory previously unexplored in this context should be regarded as a valuable contribution. Recent research in bandits on Reproducing Kernel Hilbert Spaces (RKHS) has revealed that performance guarantees are intricately tied to the decay properties of the eigenvalues of the kernel. In our study, we demonstrate (refer also to appendix E.2) that the same holds true for general continuous armed bandits. This suggests that, even if certain results in our paper fall short of optimality, the methods formulated here could be applied to extend many findings from the extensive RKHS theory to this specific setting.\n\n**Computational advantages where the d/s value to become significantly large** See the common answer about computational complexity.\n\n**Adaptivity for values of $s$ and $T$** See the common answer about adaptivity.\n\n**Input requirement in this paper compared to existing research** All the related papers, like ours, assume knowledge of both the time horizon $T$ and the order $s$ of differentiability. In particular, the four works on Bayesian optimization also presume working in a Reproducing Kernel Hilbert Space (RKHS) with a _known_ kernel. Since the knowledge of the kernel directly determines the order of smoothness of the functions considered in the RKHS, their requirement is notably more stringent than ours.\n\nWe thank the reviewer for their comments and hope to have addressed all their questions."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1798/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700045257263,
                "cdate": 1700045257263,
                "tmdate": 1700045257263,
                "mdate": 1700045257263,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wN9YrSrPh4",
                "forum": "43WKxTuJxu",
                "replyto": "fC47rQEFOL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1798/Reviewer_hchS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1798/Reviewer_hchS"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the rebuttal"
                    },
                    "comment": {
                        "value": "Thank you for your response, but I'm still not clear on why it's novel to combine the results of the misspecification bandit and the functional analysis. If it's simply a matter of combining the results, it seems far from the standards of ICLR. Were there any challenges that arose from combining the existing results? If so, what were the steps you took to overcome those challenges?"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1798/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700622100918,
                "cdate": 1700622100918,
                "tmdate": 1700622100918,
                "mdate": 1700622100918,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]