[
    {
        "title": "A Framework for PromptOps in GenAI Application Development Lifecycle"
    },
    {
        "review": {
            "id": "sdvl6kMKIi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6971/Reviewer_turR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6971/Reviewer_turR"
            ],
            "forum": "ERTp3iQWPW",
            "replyto": "ERTp3iQWPW",
            "content": {
                "summary": {
                    "value": "This paper presents GenFlow, an innovative framework designed to optimize and simplify the development of applications driven by LLM. Serving as a Prompt as a Service product, GenFlow offers substantial benefits to both developers and non-engineers tasked with managing multiple prompts.\n\nIn GenFlow, prompts are abstracted into a highly configurable format, greatly simplifying the management of multiple prompts. At the core of the GenFlow framework lies the GeNode, a foundational component that is both user-friendly and customizable, catering to individual use cases. With the aid of GeNode, users can effortlessly create new prompts, eliminating the need for advanced coding skills, while concurrently ensuring robust version control. This approach revolutionizes the way prompts are handled, offering a streamlined and accessible solution for a diverse range of users."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "Thank you for your interest in the ICLR. The paper is well-crafted, logically structured, and written in an accessible manner. The exploration of PromptOps is an interesting and noteworthy topic, particularly in the context of the increasing complexity and attention garnered by LLM.\n\nOne commendable aspect of this paper is its real-world application and the insights it shares regarding the practical experiences gained. The proposal of the Prompt as a Service concept for efficient prompt management is innovative and thought-provoking.\n\nThe choice of prompt in a specific use case as a fundamental component appears well-aligned with contemporary software development needs. This paper offers valuable perspectives on addressing challenges related to advanced language models, making it a meaningful addition to the discourse in this area."
                },
                "weaknesses": {
                    "value": "This paper introduces the concept of GenFlow, aimed at enhancing application development driven by LLM. However, a notable limitation of the paper is the absence of detailed insights into the design and detailed metrics of this service. Consequently, it remains unclear how much improvement GenFlow can offer in comparison to existing methods.\n\nIn Section 4, the paper briefly acknowledges the existence of similar services, but it does not delve into what sets GenFlow apart or the innovative aspects that distinguish it from its counterparts.\n\nWhile Figure 1 provides an overview of the prompt management workflow, the paper primarily focuses on the prompt structure design and configuration settings. An area that warrants further exploration is how GenFlow enhances prompt testing and deployment. A more comprehensive examination of these aspects would offer a more balanced perspective on the tool's capabilities."
                },
                "questions": {
                    "value": "GenFlow presents a promising concept for improving prompt development, and I'm curious about a few aspects:\n\n1. Have you developed a prototype of GenFlow, and if so, could you provide insights into its performance and usability in real-world scenarios?\n\n2. Is GenFlow trained based on a specific language model like ChatGPT, or is it compatible with various language models? Can it be adapted to support models trained by users themselves?\n\n3. In what ways does GenFlow streamline and simplify the prompt testing process? Are there specific features or mechanisms that make this part of the workflow more efficient?\n\n4. Does GenFlow include any provisions or strategies for enhancing prompt deployments, ensuring a smooth and effective transition from development to real-world implementation?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6971/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6971/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6971/Reviewer_turR"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6971/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697226263557,
            "cdate": 1697226263557,
            "tmdate": 1699636814591,
            "mdate": 1699636814591,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "z10BiYK8ya",
            "forum": "ERTp3iQWPW",
            "replyto": "ERTp3iQWPW",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6971/Reviewer_uFs3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6971/Reviewer_uFs3"
            ],
            "content": {
                "summary": {
                    "value": "The paper describes a tool for easily creating prompts (prompt\nengineering) for LLMs, called GenFlow. They integrate a prompt\nmanagement which can be used by non-experts.\n\nPrompts are defined in terms of parameter-value pairs. Can become an\nAPI, different prompts can be combined and has a web interface."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- An application to create prompts"
                },
                "weaknesses": {
                    "value": "- An application tool build with well-known techniques\n- It is not clear how easy is to build prompts by non-experts, which\nquestions the usefulness of the tool\n- The are no tests showing the functionality of the system and how it\n  compares with manual prompting"
                },
                "questions": {
                    "value": "Even with this tool, the used still needs to carefully define the\nGeNode to generate the prompts.\n\nIt is not clear if the tools could be used to generate more advanced\nprompts, like Chain of Thought, self-consistent COT, tree of thought,\netc.\n\nIt is not clear once a GeNode is specified, how the systems generates\ndifferent training prompts.\n\nThe paper does not provide any tests to validate their system.\n\nThe authors need to pay attention to the references. None of them are\ncomplete (there is no information of where they were published). Also\nreference for PromptSource (Bach et al, 2022) is not included."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6971/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698614185232,
            "cdate": 1698614185232,
            "tmdate": 1699636814467,
            "mdate": 1699636814467,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "E2bsymnaZx",
            "forum": "ERTp3iQWPW",
            "replyto": "ERTp3iQWPW",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6971/Reviewer_MEeF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6971/Reviewer_MEeF"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a framework for prompt operations, similar to what devops operations offer for code and other artifacts."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Prompt operations are a vital part of optimizing LLM-based applications and providing solutions that are customized to the nature of prompts as part of the input and ecosystem is important for developer productivity."
                },
                "weaknesses": {
                    "value": "W1- The paper misses an evaluation or usability study that shows how useful the framework is to end users.\n\nW2- The paper does not justify precisely what parts of the current MLOps and DevOps processes are to be rethinked because of the new nature of LLM-based applications in the generative space, that are sensitive to prompt optimization. For example, why isnt code version control not sufficient for prompts?\n\nW3- The paper does not describe architectural details of the framework."
                },
                "questions": {
                    "value": "- Do the authors consider this submission as a contribution to the open source frameworks for LLMs? If so this needs to be clarified in the paper.\n\n- For future submissions, the paper would benefit by showing a case study to how someone could use the framework in practice and from a user study that can demonstrate and evaluate usability."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6971/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6971/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6971/Reviewer_MEeF"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6971/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698813236177,
            "cdate": 1698813236177,
            "tmdate": 1699636814332,
            "mdate": 1699636814332,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "hp2QORcsie",
            "forum": "ERTp3iQWPW",
            "replyto": "ERTp3iQWPW",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6971/Reviewer_dxyD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6971/Reviewer_dxyD"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a novel methodology called \u201cPromptOps\u201d for integrating prompt management into the development lifecycle of Generative Artificial Intelligence (GenAI) systems. It emphasizes the role of prompts in GenAI, proposing a framework that aims to enhance prompt efficiency, reduce bias, and lower development costs. They highlight integration of PromptOps into standard software development practices like CI/CD pipelines, workflows, and APIs. The concept of \"Prompt as a Service\" (PaaS) is introduced, extending prompt utility beyond development teams to various stakeholders.\n\nThe key contributions are 1) Incorporation of Prompt Management into DevOps, 2) GenFlow Tool: This tool democratizes prompt usage by providing an accessible interface for various stakeholders, including non-engineers, to create, modify, and optimize prompts, and 3) Prompt as a Service (PaaS): The paper extends the application of prompts beyond development teams, enabling a broader range of stakeholders to use prompts as integral components in application building."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper is well-written and easy to understand. The implemented framework provides a practical illustration of the proposed methodology."
                },
                "weaknesses": {
                    "value": "The idea presented in the paper is innovative and holds promise for the future of GenAI application development. However, the lack of results, either from real-world applications or theoretical analysis, is a major limitation. To strengthen the paper's scientific merit, it is essential to include results that demonstrate the framework's effectiveness and potential impact on GenAI development. As it stands, the paper presents a nice idea but falls short of the standards expected for a scientific publication at ICLR."
                },
                "questions": {
                    "value": "No questions."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6971/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6971/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6971/Reviewer_dxyD"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6971/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1700034413518,
            "cdate": 1700034413518,
            "tmdate": 1700034413518,
            "mdate": 1700034413518,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]