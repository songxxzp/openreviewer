[
    {
        "title": "Identifiable Latent Causal Content for Domain Adaptation under Latent Covariate Shift"
    },
    {
        "review": {
            "id": "nkj410Owne",
            "forum": "xU7VWHIo1i",
            "replyto": "xU7VWHIo1i",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4251/Reviewer_cTbd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4251/Reviewer_cTbd"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a latent covariate shift paradigm to perform multi-source domain adaptation. They refer to a specific causal structure involving latent content and latent style variables, and demonstrate partial identifiability of the latent content variable. This then allows to adapt to a new target distribution, using the unlabaled target data. The authors show that their method performs well across simulated and benchmark data."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Relaxing the assumptions of adaptation or generalization methods is an important problem. \n- The specific latent covariate shift proposed is novel, and the causal framing allows to corroborate prior experimental findings (e.g. the entropy term helped).\n- The paper is overall clearly written.\n- Multiple datasets are used to demonstrate the method.\n- Multiple baselines are considered.\n- The work is overall well situated in the literature."
                },
                "weaknesses": {
                    "value": "**Update**: I have read the response but still find the justification of the assumptions lacking. This is a common comment across multiple reviewers, and I believe I was a bit too optimistic on my score. I would suggest to include an impactful real-world application to show that these assumptions indeed make a difference (but I understand this was not feasible in the response timeframe).\n\n- I found that one main piece missing related to the assumptions this specific graph is making. For instance, the authors try to relate $n_c$ to an original label $\\hat{y}$. However, they use a specific distribution for $n_c$, and don't discuss the impact of this assumption on how applicable the graph is to real-world applications.\n- Similarly, it is unclear to me how this graph relates to the causal or anti-causal tasks typically defined. For instance, how would the graph map to a segmentation task? I believe this relates to the assumption of a lack of direct influence between $X$ and $Y$.\n- I found the discussion missing, with no mention of limitations.\n- While the obtained method is different, the current work can be related to that of Alabdulmohsin et al., 2023 [1], which also investigates latent shift. It would be great to discuss the $n$ and $z$ variables compared to the proxies in [1] and whether some cases would be more adapted to one method or the other, or whether the authors believe their method would be superior (and why).\n \n[1] https://proceedings.mlr.press/v206/alabdulmohsin23a/alabdulmohsin23a.pdf"
                },
                "questions": {
                    "value": "- I would suggest to frame the graph as a set of assumptions, rather than as another \"view\" of the MSDA problem. This would make the limitations of the work clearer.\n- This could include the clarification on how this graph relates to typical causal and anti-causal tasks.\n- Please add a discussion and mention the limitations of the work. For instance, how easy is it to train the VAE with the complex loss designed? Given that the entropy loss seems important, how much target data is needed to achieve a good model?\n\nnit: please refrain from using superlatives. I felt that some of the adjectives describing the method were a bit optimistic, especially in the absence of a proper discussion."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4251/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4251/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4251/Reviewer_cTbd"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4251/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698066641262,
            "cdate": 1698066641262,
            "tmdate": 1700915948660,
            "mdate": 1700915948660,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SpgraHQDrJ",
                "forum": "xU7VWHIo1i",
                "replyto": "nkj410Owne",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4251/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4251/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "**Q1: I would suggest to frame the graph as a set of assumptions, rather than as another \"view\" of the MSDA problem. This would make the limitations of the work clearer.**\n\n**R1:** Thank you for your thoughtful feedback. We agree that presenting our graphical representation in this manner would enhance clarity regarding the limitations of our work. We have added a Section A.8 in the revised version, including assumptions (i)-(iii) in proposition 4.2, and most importantly, assumptions on the proposed causal graph as formulated in Eqs. (1)-(3), to understand our assumptions for identifying $\\mathbf{z}_c$. For examples, we assume two-parameter exponential family members for latent noise variables $\\mathbf{n}$ as defined in Eq. (1), considering informative latent noise variables $n_i$ can be automatically separated from noise by an estimating model (see [1]). However, in real applications, the distribution of $\\mathbf{n}$ could be arbitrary. In this context, assumption Eq. (1) may only serve as an approximation for the true distribution of $\\mathbf{n}$. More details please see Section A.8.\n\n[1] Sorrenson, Peter, Carsten Rother, and Ullrich K\u00f6the. \"Disentanglement by nonlinear ica with general incompressible-flow networks (gin).\" arXiv preprint arXiv:2001.04872 (2020).\n\n**Q2: This could include the clarification on how this graph relates to typical causal and anti-causal tasks.**\n\n**R2:** Thank you for your valuable suggestion. Regarding causal or anti-causal tasks, we recognize that the complexities of specific tasks may require a more tailored causal graph structure. Nevertheless, we posit that these tasks might benefit from the proposed causal graph. The link between the proposed causal graph and causal or anti-causal tasks could be attributed to the deliberate modeling of latent causal variables within our framework. To illustrate, let us explore its potential application in segmentation tasks, where interpreting graph nodes as distinct regions may be reasonable. In this scenario, justifying the absence of direct connections between nodes may be conceivable; instead, connections should be conceptualized within high-level latent variables, as highlighted in the proposed causal graph. More details can be found in Section A.9 in the revised version.\n\n**Q3: Please add a discussion and mention the limitations of the work**\n\n**R3:** Thank you once again for your insightful suggestions. The most challenging assumption in our model necessitates the presence of substantial changes in latent noise variables, as they play a crucial role in identifiability. However, in practical applications, a prevalent challenge arises from the scarcity of extensive source domain datasets that adequately capture such substantial changes. In this context, the assumptions related to identifiability in our results may not be satisfied, and thus, the performance of the proposed method may benefit from the introduction of certain regularizations. One potential regularization approach involves leveraging the independence among the noise variables, and further details can be found in Appendix A.10.\n\n**Q4: Related to that of Alabdulmohsin et al., 2023**\n\n**R4:** Thank you once again for your valuable suggestions. We have incorporated the referenced work into our related work section. We think that each method possesses its own set of advantages and disadvantages. For instance, proxy-based methods offer the advantage of relaxing model assumptions, but they need a high-quality proxy. In contrast, our approach eliminates the need for a proxy variable but entails making stronger assumptions within the model.\n\n**Q5: please refrain from using superlatives**\n\n**R5:** Thank you for your valuable suggestions. Due to the constraints of the rebuttal time frame, our priority is to address more complex reviews. We will thoroughly revise inappropriate presentations in the final version. Your understanding is greatly appreciated."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4251/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700453350029,
                "cdate": 1700453350029,
                "tmdate": 1700453591434,
                "mdate": 1700453591434,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "L1d6XBh1Ui",
            "forum": "xU7VWHIo1i",
            "replyto": "xU7VWHIo1i",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4251/Reviewer_4yH5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4251/Reviewer_4yH5"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed a causal generative model in the Multi-source domain adaptation scenario, which was based on a latent covariate shift paradigm that contains two latent variables, a content variable, and a style variable. Compared to existing methods, the proposed method additionally modeled the causal generation from the content variable to the style variable. The authors then provided the identifiability analysis regarding the content latent variable and implemented a VAE-based method for learning. Experiments on PACS and Terra Incognita data were conducted."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The considered problem is interesting."
                },
                "weaknesses": {
                    "value": "This paper is highly incremental, and moreover, suffers from many technical flaws. \n\nFirst, its causal graph, learning method, and identifiability analysis are very similar to existing works [1, 2]. The only difference may lie in the addition modeling of the causal generation from $z_c$ to $z_s$. However, this assumption may not be widely applicable. Particularly, in the Terra Incognita data and PACS data considered, the authors failed to elaborate why $z_c \\to z_s$ (this is important, since without this edge, the causal graph is the same as [1]). Besides, the identifiability analysis is also a simple application of [3]. \n\nSecond, I am not sure the identifiability result is right for me. In the derivation of Eq. (19), the authors exploited the d-separation between $n_s$ (or $\\hat{n}_s$) and $y$ given $u$, however, this separation does not necessarily means $n_c$ only depends on $\\hat{n}_c$, since the inclusion of $\\hat{n}_s$ does not violate the dependency between $n_c$ and $y$ (given $u$). Besides, the parameterization of the variational posterior does not follow the dependency constraints implied in Fig. 2 (a). Specifically, given $x$, $n_c$ and $n_s$ are no longer independent, since $x$ is the collider in the path between $n_c$ and $n_s$. \n\nLast but not least, the compared baselines do not rely on the unlabeled data in the target domain (such as IRM), while it has been exploited in the term of $L_{ENT}$ (Eq. (9)). Without the ablation study, it is not clear whether the advantages come from this additional term. Besides, as the theoretical results have proven the identifiability of $z_c$, this term seems redundant. \n\n\n[1] Sun, Xinwei, et al. \"Recovering latent causal factor for generalization to distributional shifts.\" Advances in Neural Information Processing Systems 34 (2021): 16846-16859.\n[2] Lu, Chaochao, et al. \"Invariant causal representation learning for out-of-distribution generalization.\" International Conference on Learning Representations. 2021.\n[3] Khemakhem, Ilyes, et al. \"Variational autoencoders and nonlinear ica: A unifying framework.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2020."
                },
                "questions": {
                    "value": "Please see the weakness above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "Not applicable."
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4251/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698673145187,
            "cdate": 1698673145187,
            "tmdate": 1699636392024,
            "mdate": 1699636392024,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Cpfmzrpnot",
                "forum": "xU7VWHIo1i",
                "replyto": "L1d6XBh1Ui",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4251/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4251/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "**Q1: This paper is highly incremental...its causal graph, learning method, and identifiability analysis are very similar to existing works [1, 2]. The only difference may lie in the addition modeling of the causal generation from zc to zs. However, this assumption may not be widely applicable. Particularly, in the Terra Incognita data and PACS data considered, the authors failed to elaborate why (this is important, since without this edge, the causal graph is the same as [1]). Besides, the identifiability analysis is also a simple application of [3].**\n\n**R1, Part A:** We strongly disagree the above. \n\nPrimarily, we wish to emphasize that the fundamental essence of our contribution is encapsulated within the proposed paradigm. Within this framework, each element of our proposed causal graph, learning method, and identifiability analysis has been meticulously crafted to address the nuances of the entirely novel problem paradigm we have introduced. This deliberate tailoring ensures that our methodologies are not merely incremental but intricately designed to suit the distinctive challenges posed by this innovative problem context. Regrettably, we observe a substantial oversight by the reviewer in recognizing the paramount importance of this foundational aspect.\n\nRegarding to the proposed causal graph. In the context of causal graph analysis, a commonly accepted assumption asserts that the domain index causally affects latent variables, and subsequently, these latent variables causally influence the observed data denoted as X. Rooted in this foundational premise, the disparities among causal models becomes evident in the nuanced modeling of the latent space. Notably, our approach to modeling the latent space markedly diverges from that outlined in references [1,2]. As pinpointed, the core distinction lies in the modeling of the causal generation from zc to zs. This critical divergence encapsulates a pivotal aspect of our model, reinforcing the compelling rationale behind our unique representation of latent causal relationships within the system.\n\nConcerning learning methods and identifiability analysis, the divergences in latent causal models underscore the imperative for distinct approaches. Each latent causal model necessitates a specialized learning method, tailored to capture the intricacies of its unique latent space. Furthermore, disparities in model structures and assumptions mandate a nuanced identifiability analysis, essential for ensuring robust and precise inference of causal relationships within the specified framework. In essence, the selection of a latent causal model not only shapes the learning strategy but also underscores the critical need for a meticulous identifiability assessment, reinforcing the foundation for reliable causal inference. \n\n\nWe firmly disagree with the assertion that 'our assumption may not be widely applicable.\n\nBoth assumptions\u2014whether latent content variables cause latent style variables or by using a confounder, are inherently reasonable. It is challenging to definitively argue against the widespread applicability of our assumption that 'latent content variables cause latent style variables'. A robust method for validation involves a thorough assessment of the distinct advantages associated with each assumption within real-world applications, coupled with its recognition within the community.\n\nFor real-world applications, 'latent content variables cause latent style variables,' we present compelling experimental results for real-world dataset, showcasing a robust performance. For recognition within the community: Our assumption, latent content variables cause latent style variables, aligns with established works in the domain adaptation/generalization field [L1,L2,L3], as well as recent advancements in self-supervised learning [L4,L5]."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4251/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700451022225,
                "cdate": 1700451022225,
                "tmdate": 1700451022225,
                "mdate": 1700451022225,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gXxyphK9ga",
                "forum": "xU7VWHIo1i",
                "replyto": "L1d6XBh1Ui",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4251/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4251/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Could you kindly verify if the provided clarification addresses your concerns?"
                    },
                    "comment": {
                        "value": "Dear Reviewer 4yH5,\n\nWe greatly appreciate your feedback. Could you kindly verify if the provided clarification addresses your concerns, particularly regarding contributions?\n\nAllow us to emphasize our contributions anew. The core of our work is embedded within the proposed paradigm. Under this framework, every component of our suggested causal graph, learning method, and identifiability analysis has been intricately fashioned to navigate the intricacies of the entirely novel problem paradigm we've presented. This intentional customization guarantees that our methodologies transcend mere incremental advancements, as they are intricately fashioned to align with the distinctive challenges posed by this innovative problem context.\n\nIf there are lingering uncertainties or if additional clarification is necessary, please don't hesitate to notify us. We understand the time constraints you face and truly appreciate your thoughtful consideration. Your reassessment plays a crucial role in advancing our work, and we stand prepared to offer any further clarification needed.\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4251/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700643437276,
                "cdate": 1700643437276,
                "tmdate": 1700643437276,
                "mdate": 1700643437276,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "61TMcshovT",
            "forum": "xU7VWHIo1i",
            "replyto": "xU7VWHIo1i",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4251/Reviewer_Corp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4251/Reviewer_Corp"
            ],
            "content": {
                "summary": {
                    "value": "In practical scenarios, label distributions often exhibit variations across different domains, thereby constraining the applicability of existing methods that rely on covariate shift or conditional shift. In this paper, the authors introduce a novel paradigm called latent covariate shift (LCS), which brings about increased diversity and adaptability across domains. From a causal perspective, the paper presents a method to learn the invariant conditional distribution p_u(y|z_c), aimed at achieving a more nuanced representation of observational data. The method is shown to deliver remarkable performance and effectiveness on both simulated and real-world datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The proposed paradigm, i.e., LCS, allows variable distributions to vary across different domains while ensuring that p_u(y|z_c) remains invariant, is interesting and also seems sound.\n2. Empirical evaluation on synthetic and real datasets confirmed the theoretical results and the effectiveness of the proposed method, outperforming existing methods."
                },
                "weaknesses": {
                    "value": "1.\tThe contributions of this paper are limited. While this paper introduces a different paradigm, it appears to still be a latent representation disentangle mechanism from a causal perspective.\n2.\tThe authors propose a more versatile domain adaptation paradigm and construct iLCC-LCS based on it. However, the feasibility of their latent variable modeling approach relies on conditions made in Proposition 4.2, which are not adequately explained and ensured against potential violations.\n3.\tTable 3 in APPENDIX underscores that the proposed method exhibits limited performance when confronted with smaller label distribution shift across domains. Some commonly used datasets, such as Digits-five, Office-Home, and DomainNet, were omitted. If the method struggles with simple cases, i.e., D_{kl}<0.3, it raises concerns about its applicability and effectiveness.\n4.\tRecommend that the authors provide an overview diagram or a detailed description of the implementation of iLCC-LCS to enhance its intuitiveness and readability.\n5.\tt-SNE can distort the high-dimensional geometry of embeddings. While it can help visualization, it's not suitable for evaluating the quality of embeddings. Could the authors consider employing numerical measures for this purpose?"
                },
                "questions": {
                    "value": "see above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4251/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698731559090,
            "cdate": 1698731559090,
            "tmdate": 1699636391935,
            "mdate": 1699636391935,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "czYkzj3MOM",
                "forum": "xU7VWHIo1i",
                "replyto": "61TMcshovT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4251/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4251/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "**Q1: The contributions of this paper are limited. While this paper introduces a different paradigm, it appears to still be a latent representation disentangle mechanism from a causal perspective.**\n\n**R1:** We appreciate your time and careful consideration of our work, as reflected in your insightful review. However, we would like to express a disagreement with the notion that the contributions of our paper are limited. We believe our work significantly advances the field, particularly in the context of Latent Covariate Shift, and we would like to address the specific concerns raised.\n\nNew Problem Setting - Latent Covariate Shift: We introduce a novel paradigm, latent covariate shift, which deviates from the commonly-used Conditional Shift. This paradigm shift represents a substantial contribution to the field, offering a fresh perspective on addressing covariate shift issues.\n\nIntricate Latent Causal Generative Model: Our paper presents a sophisticated latent causal generative model, introducing latent content variables and latent style variables. This model provides a nuanced understanding of latent covariate shift mechanisms, offering a more comprehensive and realistic representation.\n\nTheoretical Analysis of Identifiability: We conduct a thorough analysis of identifiability in the proposed causal model, presenting both a complete non-identifiability result and a partial identifiability result for latent content variables. This theoretical foundation adds depth to our work and contributes valuable insights to the research community.\n\nNew Method for Latent Covariate Shift: Guided by our theoretical results, we design a new method specifically tailored for latent covariate shift. The proposed method is a practical application of our theoretical findings, showcasing the applicability and relevance of our work.\n\nVerification of Advantages: Through rigorous experimentation, we validate the advantages of latent covariate shift and the proposed method. Our empirical results provide concrete evidence of the effectiveness and superiority of our approach.\n\nIn summary, the introduction of a new paradigm, theoretical analysis, method design, and empirical verification collectively demonstrate the significance and impact of our work on addressing latent covariate shift challenges.\n\nFurthermore, we wish to emphasize that the fundamental essence of our contribution is encapsulated within the proposed paradigm. Within this framework, each element of our proposed causal graph, learning method, and identifiability analysis has been meticulously crafted to address the nuances of the entirely novel problem paradigm we have introduced. This deliberate tailoring ensures that our methodologies are not merely incremental but intricately designed to suit the distinctive challenges posed by this innovative problem context. Regrettably, we observe a substantial oversight by the reviewer in recognizing the paramount importance of this foundational aspect.\n\n**Q2: However, the feasibility of their latent variable modeling approach relies on conditions made in Proposition 4.2, which are not adequately explained and ensured against potential violations**\n\n**R2:** We appreciate your time and careful review again. The main assumptions, encompassing i to iii in Proposition 4.2, stem from the realm of nonlinear ICA. Over recent years, nonlinear ICA has found applications in diverse real-world scenarios, such as domain adaptation [1], image generation and translation [2], domain generalization [3]. Consequently, we assert that these three assumptions have been substantiated through practical applications. We have add a new Section A.8 for understanding these assumptions. \n\n[1] Kong, Lingjing, et al. \"Partial Identifiability for Domain Adaptation.\" ICML 2022.\n\n[2] Xie, Shaoan, et al. \"Multi-domain image generation and translation with identifiability guarantees.\" ICLR 2022.\n\n[3] Wang, Xinyi, et al. \"Causal balancing for domain generalization.\" arXiv preprint arXiv:2206.05263 (2022)."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4251/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700450655155,
                "cdate": 1700450655155,
                "tmdate": 1700453999703,
                "mdate": 1700453999703,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dO3is4x8Vw",
                "forum": "xU7VWHIo1i",
                "replyto": "61TMcshovT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4251/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4251/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Could you kindly confirm whether the clarification we provided adequately addresses your concerns?"
                    },
                    "comment": {
                        "value": "Dear Reviewer Corp,\n\n\nYour feedback is invaluable to us. Could you kindly confirm whether the clarification we provided adequately addresses your concerns? If any uncertainties persist or if additional clarification is required, please donot hesitate to inform us. We genuinely appreciate your time, recognizing that you are undoubtedly busy. Your reconsideration is crucial for the progress of our work, and we are more than willing to provide any further clarification."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4251/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700640518172,
                "cdate": 1700640518172,
                "tmdate": 1700640518172,
                "mdate": 1700640518172,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Y04Eb4FlpZ",
            "forum": "xU7VWHIo1i",
            "replyto": "xU7VWHIo1i",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4251/Reviewer_YFyZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4251/Reviewer_YFyZ"
            ],
            "content": {
                "summary": {
                    "value": "This manuscript studies the multi-source adaptation where the shifts occur in the latent space. The authors introduced two latent variables $z_c$ and $z_s$ as the causes of $x$ and $y$. They assumed that the conditional distribution $p_u(y\\mid z_c)$ is invariant across domains while other distributions are allowed to be variant. Under this setting, they showed that the joint observed distribution is unidentifiable without further assumptions. Additionally, they proved that the latent variables are identifiable up to an invertible mapping under some regularity conditions. To estimate the components, they proposed a variational autoencoder type algorithm to learn each conditional distribution."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Overall, I think this is an interesting topic and agree with the authors\u2019 opinion that most domain adaptation techniques have strict assumptions on the distribution shifts. This manuscript proposes a more general setting that allows the distribution of $p(y\\mid x)$ and $p(y)$ to change across domains. In contrast, the Covariate Shift assumes $p(y\\mid x)$ to be invariant across domains and the Conditional Shift assumes $p(y)$ to be invariant across domains. The proposed method outperforms the baseline models on the TerraIncognita dataset."
                },
                "weaknesses": {
                    "value": "The main concern is that the justification of graph 1(c) is not clear. While the authors justify partial edge directions in Section 3, e.g., $z_c\\rightarrow y$ and $z_c\\rightarrow z_s$, it is not clear whether there is a real-world setting that fits this graph. Specifically, it would be nice to give a motivating example that clearly explains what each variable $(u,z_c,z_s,y,x)$ refers to and when $p_u(y\\mid z_c)$ is invariant and other distributions are variant. The difference of $z_c$ and $z_s$ is not clear as well. \n\n\nProposition 4.2 shows the identifiability of $z_c$. However, from the result, it is not clear whether $p_u(y\\mid z_c)$ is identifiable. Hence, it is not clear whether true $p_u(y\\mid z_c)$ can be recovered from data. \n\n\n$g_c$ and $g_{s_2}$ in Equation (2) are invertible function. In this case, it seems trivial to introduce variables $z_c$ and $z_s$ since Equation (3) can be rewritten as\n$$\nx=f(g_c(n_c), g_{s_2}(g_{s_1}(g_c(n_c)) + n_s))+\\varepsilon\n$$"
                },
                "questions": {
                    "value": "what does the index $i$ and $j$ in Equation (1) refer to?\n\nFrom Figure 2(b), it looks like $n_c$ and $n_b$ are observed variables as they are shaded. Seems like a typo?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4251/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4251/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4251/Reviewer_YFyZ"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4251/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698775127522,
            "cdate": 1698775127522,
            "tmdate": 1699636391832,
            "mdate": 1699636391832,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "A1YkjDymID",
                "forum": "xU7VWHIo1i",
                "replyto": "Y04Eb4FlpZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4251/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4251/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "**Q1: The justification of graph 1(c), $\\mathbf{z}_c$ causes $\\mathbf{z}_s$...Provide a motivating example.. The difference of $\\mathbf{z}_c$ causes $\\mathbf{z}_s$..**\n\n**R1:** Thank you for your time and efforts in enhancing this work. For clarifying these questions, we would like first further clarify the notations, including the domain index $\\mathbf{u}$, latent content variables $\\mathbf{z}_c$, latent style variable $\\mathbf{z}_s$, label $\\mathbf{y}$, and observation $\\mathbf{x}$.\n\nIn domain adaptation, latent content variables, latent style variables, domain index, and labels play distinct roles in capturing and aligning information across different domains. Let us consider an example in the context of animal data, were collected from different locations:\n\n\nDomain index $\\mathbf{u}$: it denotes an indicator of the source domain from which the data originates, e.g., locations index).\n\nLatent content variables $\\mathbf{z}_c$: this denotes unobservable factors that represent the essential content or intrinsic characteristics of the object. For example: latent content variables encompass features such as the species, or specific morphological characteristics that are inherent to each type of animal.\n\nLatent style variables $\\mathbf{z}_s$: These variables aim to capture aspects of the data that are not specific to the intrinsic features, but style-related variations in the data. For example: latent style variables could represent variations in background, lighting conditions, environmental context.\n\nObservation $\\mathbf{x}$: The actual image data, including both content and style, including all visual information captured by camera.\n\nLabels $\\mathbf{y}$: it represents ground truth labels indicating the class or category of each instance. Example: a label refers to the assigned category or class that indicates the identity or type of each animal in the dataset.\n\nLet us illustrate Figure 1 (c) with an example in the context of animal data. The relationship between $\\mathbf{u}$ causing $\\mathbf{x}$ is modeled to capture the fact that input in domain adaptation changes across different domains (locations). \n\nNow, considering why $\\mathbf{u}$ causes $\\mathbf{z}_c$, let us explore how the unique characteristics and environmental factors associated with each location influence the latent content variables for zebras. For instance, the shades and patterns of the stripes on zebras vary based on the specific location, and certain adaptations to the local ecosystem can be reflected in $\\mathbf{z}_c$. \n\nMoving on to why $\\mathbf{z}_c$ causes $\\mathbf{y}$, $\\mathbf{z}_c$ essentially capture features relevant to predicting $\\mathbf{y}$ in a classification task. For a more detailed explanation, please refer to the paragraph 'zc causes y:' in the main paper.\n\n$\\mathbf{z}_c$ influence observations $\\mathbf{x}$ because they serve as a conceptual representation of the underlying, unobservable factors that contribute to the observed data. \n\nFinally, let us provide a example why $\\mathbf{z}_c$ causes $\\mathbf{z}_s$ in Figure 2 (a). An apt example is that different animals (corresponding to $\\mathbf{z}_c$) often choose different environments (corresponding to $\\mathbf{z}_s$) where the basic needs of the animals to survive are met.\n\nThus far, we have provided comprehensive explanations for all variables and causal directions depicted in Figure 1 (c) and Figure 2 (a). These causal directions not only elucidate the internal relationships within the models but also indicate how we effectively model the changes in various distributions across domains ($\\mathbf{u}$). These considerations underscore the holistic nature of our approach, wherein the causal relationships guide our representation of the dynamic shifts in distributions across different domains.\n\nFor when $p(\\mathbf{y}\u2223\\mathbf{z}_c)$ remains invariant: it aligns with a fundamental principle in causality, specifically the notion of independent causal mechanisms. This principle posits that the conditional distribution of $p(\\mathbf{y}\u2223\\mathbf{z}_c)$ remains stable and unaffected by external factors. In the context of domain adaptation, assuming the invariance of $p(\\mathbf{y}\u2223\\mathbf{z}_c)$across domains is a common practice. The invariance in $p(\\mathbf{y}\u2223\\mathbf{z}_c)$ is crucial for ensuring the model's ability to make consistent and robust predictions in the target domain. This assumption implies that the predictive relationship between the label $\\mathbf{y}$ and $\\mathbf{z}_c$ remains unchanged despite variations in data distributions across different domains. This stability facilitates a seamless transition from training on source domains to making reliable predictions in the target domain, contributing to the model's adaptability and generalization."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4251/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700449542145,
                "cdate": 1700449542145,
                "tmdate": 1700449542145,
                "mdate": 1700449542145,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "G0KMriaA3Z",
                "forum": "xU7VWHIo1i",
                "replyto": "Y04Eb4FlpZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4251/Reviewer_YFyZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4251/Reviewer_YFyZ"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for addressing my comments. I would like to clarify my points. If $g_c$ and $g_x$ are invertible functions, then it seems to me that one can merge $z_c$ and $n_c$ ($z_s$ and $n_s$) for the adaptation task. What is the intuition/technical reason to introduce additional variables? Will we still be able to identify the graph without them? \n\nAdditionally, I would suggest adding a remark in Proposition 4.2 to discuss why $p(y\\mid z_c)$ is identifiable. \n\nThanks for the nice explanation for Q1. Connecting to the previous question, can the authors also give an example of $n_c$ and $n_s$ in this case?\nBesides, I have slightly mixed feelings about the explanation for $z_c\\rightarrow z_s$. Would it also be the case that due to natural selection, the environment would cause animals with certain characteristics to survive? Although my point is not to overemphasize the justification, it might strengthen the motivation of the paper if there is an example that demonstrates a clear $z_c\\rightarrow z_s$. A bidirectional edge case is also good, but I am not sure if this would break the analysis or not."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4251/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700593515555,
                "cdate": 1700593515555,
                "tmdate": 1700594837849,
                "mdate": 1700594837849,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SikUB6RUEk",
                "forum": "xU7VWHIo1i",
                "replyto": "Y04Eb4FlpZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4251/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4251/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Regarding to \"bidirectional edge case is also good\". We acknowledge and do not refute this perspective. Indeed, existing literature has explored various ways to model the relationship between latent content variables $\\mathbf{z}\\_{c}$ and $\\mathbf{z}\\_{s}$, for example, bidirectional edge $\\mathbf{z}\\_{c} - \\mathbf{z}\\_{s}$, or a confounder $\\mathbf{c} \\rightarrow \\mathbf{z}\\_{s}, \\mathbf{c}  \\rightarrow \\mathbf{z}\\_{c}$, or  $\\mathbf{z}\\_{c} \\rightarrow \\mathbf{z}\\_{s}$.  We acknowledge the complexity of definitively arguing for the superiority of one assumption over another. In our opinion, the choice among these three assumptions is inherently reasonable, contingent upon the specific application scenarios under consideration, as we asserted in the related work. In the context of our study, particularly focused on animal classification tasks, we express a preference for the $\\mathbf{z}\\_{c} \\rightarrow \\mathbf{z}\\_{s}$. This preference also aligns with the findings and methodologies of exsting works, including references [L1,L2,L3,L4,L5], which have demonstrated its effectiveness in capturing and explaining the underlying dynamics of similar systems. \n\n[L1] Gong, Mingming, et al. \"Domain adaptation with conditional transferable components.\" International conference on machine learning. PMLR, 2016.\n\n[L2] Stojanov, Petar, et al. \"Data-driven approach to multiple-source domain adaptation.\" The 22nd International Conference on Artificial Intelligence and Statistics. PMLR, 2019.\n\n[L3] Mahajan, Divyat, Shruti Tople, and Amit Sharma. \"Domain generalization using causal matching.\" International Conference on Machine Learning. PMLR, 2021.\n\n[L4] Von K\u00fcgelgen, Julius, et al. \"Self-supervised learning with data augmentations provably isolates content from style.\" Advances in neural information processing systems 34 (2021): 16451-16467.\n\n[L5] Daunhawer, Imant, et al. \"Identifiability results for multimodal contrastive learning.\" arXiv preprint arXiv:2303.09166 (2023).\n\nWe hope that these clarifications further address any concerns you may have. Should you have additional questions or concerns, we welcome further discussion. We sincerely appreciate the time and effort you dedicated to reviewing our work."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4251/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700626063990,
                "cdate": 1700626063990,
                "tmdate": 1700648306231,
                "mdate": 1700648306231,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TgCsBqEnDL",
                "forum": "xU7VWHIo1i",
                "replyto": "Y04Eb4FlpZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4251/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4251/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Could you please verify if the clarification we offered sufficiently resolves your concerns?"
                    },
                    "comment": {
                        "value": "Dear Reviewer YFyZ,\n\nThank you sincerely for the further discussion. We have offered additional clarification. Your feedback holds immense value for us. \n\nCould you please verify if the clarification we offered sufficiently resolves your concerns? If any uncertainties linger or if you require further elucidation, please inform us without hesitation. \n\nWe understand the demands on your time and genuinely appreciate your consideration. Your reconsideration is pivotal for advancing our work, and we are fully committed to furnishing any additional clarification you may need.\n\nBest,"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4251/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700720215861,
                "cdate": 1700720215861,
                "tmdate": 1700720215861,
                "mdate": 1700720215861,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]