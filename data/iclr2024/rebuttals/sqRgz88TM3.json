[
    {
        "title": "VFLAIR: A Research Library and Benchmark for Vertical Federated Learning"
    },
    {
        "review": {
            "id": "RA1P3zOR7B",
            "forum": "sqRgz88TM3",
            "replyto": "sqRgz88TM3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1159/Reviewer_Gb2U"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1159/Reviewer_Gb2U"
            ],
            "content": {
                "summary": {
                    "value": "This paper aims to develop a lightweight vertical federated learning (VFL) platform (VFLAIR) framework consisting of multiple model partitions, communication protocols, and attack and defense algorithms using datasets of different modalities. Under this platform, the unified evaluation metrics and benchmark defense performance with various attacks are introduced,  which sheds light on choosing defense techniques in practical deployment.\nAlthough this paper summarizes most of the VFL settings, some advanced model partition and communication protocol algorithms are missed. In this way, I suggest authors should add these missed algorithms. In addition, I think some evaluations of this platform should be developed to show how it is lightweight. Some recommendation tasks should be considered, such as Criteo, Avazu, etc."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "This paper can provide a VFL platform for researchers to evaluate the performance and efficiency of their proposed algorithms. This platform from five aspects, i.e., model partitions, communication protocols, attacks, defenses, and dataset modalities, which are very significant for VFL studies. The strengths of this paper are as follows: \n1. Most of the VFL settings, e.g., model partitions, communication protocols, attacks, defenses, and dataset modalities, are included in this platform.\n2. This platform provides unified evaluation metrics and benchmark defense performance with various attacks,  which can guide the selection of defense techniques in practical deployment.\n3. The analysis of experimental results is sufficient and insightful."
                },
                "weaknesses": {
                    "value": "Some weaknesses are shown as follows:\n1. Although this paper summarizes most of the VFL settings, some advanced model partition and communication protocol algorithms are missed.  In this way, I suggest authors should add these missed algorithms, such as quantization, federated graph neural networks, etc.\n2. I think some evaluations of this platform should be developed to show how it is lightweight.\n3. VFL is usually adopted in recommendation tasks instead of image classification. The authors apply too many image classification datasets in the experiments.\n4. As discussed in limitations, the cryptographic techniques that are significant, are not included in this library. \n5. The communication and computation efficiencies are also very important. The metrics should include the evaluation of the communication and computation efficiencies."
                },
                "questions": {
                    "value": "1. Please add some advanced model partition and communication protocol algorithms, such as quantization, federated graph neural networks, etc.\n2. Add some compassion and discussion on how this platform is lightweight.\n3. The authors apply too many image classification datasets in the experiments. Some recommendation tasks should be considered, such as Criteo, Avazu, etc.\n4. As discussed in limitations, the cryptographic techniques that are significant, are not included in this library. \n5. The communication and computation efficiencies are also very important. The metrics should include the evaluation of the communication and computation efficiencies."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1159/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1159/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1159/Reviewer_Gb2U"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1159/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698459747288,
            "cdate": 1698459747288,
            "tmdate": 1699636042379,
            "mdate": 1699636042379,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pCQjnka4kA",
                "forum": "sqRgz88TM3",
                "replyto": "RA1P3zOR7B",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1159/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1159/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Questions and Weaknesses from R-Gb2U"
                    },
                    "comment": {
                        "value": "### **Response to Weakness 1 and Question 1**\n\nThank you for your constructive suggestions. We have included 3 new communication protocols, including Quantizate [1], Top-k [1] and CELU-VFL [2]. We also added FedGNN to benchmark its performance on Cora dataset. Details on these experimental settings including model partition, hyperparameters are shown in Tab. 10 to 12 in Appendix H. Results are all included in Tab. 6 for communication protocols and in Tab. 7 for Cora dataset with FedGNN, both in Section 6.1. For quicker access, please refer to our reply in *\"Response to Weakness 4 and Question 3 for Reviewer z5tx\"* (communication protocols) and *\u201cResponse to Weakness 3 and Question 3 for Reviewer z5tx\u201d* (Cora dataset with FedGNN, Tab(1) in the response). We do not show them here again to avoid repeatitiveness and redundancy.\n\n### **Response to Weakness 2 and Question 2**\n\nTo demonstrate that our platform is lightweight, we compare it with FATE, one of most widely used FL platform supporting a broad range of VFL functionalities, on their system requirements for deployment.  According to FATE ([link](https://github.com/FederatedAI/FATE/blob/master/deploy/standalone-deploy/README.md)), deploying a stand-alone version of the FATE framework requires at least a 8 core CPU with 16G memory and 500G hard disk and the downloaded docker package for deployment is of size 4.92G for version 1.7.1.1. However, for our VFLAIR, a 1 core CPU with less than 4G memory and less than 4.0G hard disk is required for installation.\n\n(4) Comparision between FATE and VFLAIR\n|                                     |       CPU      |              memory              | Installation required hard disk |\n|:-----------------------------------:|:--------------:|:--------------------------------:|:-------------------------------:|\n| FATE (stand-alone, version 1.7.1.1) |     8 core     |                16G               |              4.92G              |\n|                VFLAIR               |     1 core     |                4G                |              $<$4G              |\n\n### **Response to Weakness 3 and Question 3**\nThank you for your suggestions. We have added Criteo and Avazu into our experiments, and results are included in Tab. 7 in Section 6.1. For quicker access, please refer to our reply in *\u201cResponse to Weakness 3 and Question 3 for Reviewer z5tx\u201d* (Tab(1) in the response). We do not show them again here to avoid repeatitiveness and redundancy.\n\n### **Response to Weakness 4 and Question 4**\n\nThanks for the suggestion. We prioritized benchmarking non-cryptographic defense methods because they are emerging more rapidly in recent years due to their capability of defending various types of atttacks, whereas cryptographic techniques typically protect data in-transit during training, can not defend backdoor attacks or inference-time attacks effecitively while incurring significant computation and communiction cost to run. The benchmark of cryptographic techniques focus more on efficiency. Nevertheless, we think that the combination of cryptographic and noncryptographic methods would be an interesting research direction and potential solution for practical deployment. \n\nFor VFLAIR, we have already included one of most commonly used cryptographic techniques, i.e. Paillier Encryption, in tree-based VFL and evaluated its impact on model performance and computation efficiency in Table. 5 in Section 6. We are currently implementing Encryption techniques to NN-based VFL and also plan to add more advanced privacy-preserving cryptographic methods to our VFLAIR in the near future. \n\n### **Response to Weakness 5 and Question 5**\nThank you for your suggestions. We have now formally added **communication rounds (\\#Rounds)** and **amount of exchanged inforation each round (Amount)** for the evaluation of communication efficiency, as well as **Execution Time (Exec. Time)** for evaluating computation efficiency in Section 5.3 Evaluation Metrics. Further we applied these metrics in our results in Section 6.1 when comparing multiple communication protocols in Tab. 6, and when comparing the computation efficiency in Tab. 5. \n\n**Reference**\n\n[1] Castiglia, Timothy J., et al. \"Compressed-vfl: Communication-efficient learning with vertically partitioned data.\" International Conference on Machine Learning. PMLR, 2022.\n\n[2] Fu, Fangcheng, et al. \"Towards communication-efficient vertical federated learning training via cache-enabled local updates.\" arXiv preprint arXiv:2207.14628 (2022)."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700280963439,
                "cdate": 1700280963439,
                "tmdate": 1700280963439,
                "mdate": 1700280963439,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UgAjCHlK2V",
                "forum": "sqRgz88TM3",
                "replyto": "RA1P3zOR7B",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1159/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1159/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We are anxiously looking forward to your replies to our responses"
                    },
                    "comment": {
                        "value": "Dear reviewer, do our responses to your questions as well as the updated paper address your concerns? We have added federated graph neural network as advanced model (Tab. 7 in Section 6); quantization, Top-k compression as well as CELU-VFL for additional communication protocols (Tab. 6 in Section 6); recommandation datasets including Criteo and Avazu (Tab. 7 in Section 6); as well as more communication and computation effectiveness evaluation metrics to our VFLAIR platform and benchmark experiments (in Section 6) according to your reviews. We have also added comparition to FATE to show that our platform is lightweight (in Appendix D). We are currently working on supporting Paillier Encryption in Linear Regression models in our platform. We hope the above have solved your concerns and we are still looking forward to your further replies. We will remain open and available if there is any further concerns."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700636532663,
                "cdate": 1700636532663,
                "tmdate": 1700639628571,
                "mdate": 1700639628571,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "p1x3Mj4799",
            "forum": "sqRgz88TM3",
            "replyto": "sqRgz88TM3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1159/Reviewer_1nCt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1159/Reviewer_1nCt"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed a benchmarking framework for vertical federated learning. It proposes new evaluation metrics such as defence capability score (DCS)"
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "This paper aims to propose a framework that can provide universal benchmarking solution for vertical federated learning. \n\nThe literature review is commendable, especially on the attack and defence part."
                },
                "weaknesses": {
                    "value": "- The paper predominantly centers on evaluating attacks and defence strategies. But the paper title implies a broader scope \u2013 VFL in its entirety. The paper title could be more specific to align with the focus of the paper. \n\n- A notable contribution is the introduction of new evaluation metrics such as defence capability score (DCS). However, the experiments did not validate the effectiveness of the proposed metrics. What is the evidence that shows that the proposed metrics indeed work, representing the real ability of the evaluated algorithms?\n\n- The paper claims to \u201cimplement basic VFL training and evaluation flow under multiple model partition, communication protocols and attacks and defences algorithms using datasets of different modality\u201d. But it lacks a clear exposition of the workflow. What is the training and evaluation flow in VFLAIR and how does the workflow facilitate the benchmarking? \n\n- Following on the above point, the evaluation section is not organised systematically according to model partition, communication protocols, and attack and defence algorithms. The current evaluation section only amounts to a compilation of experimental results, which \nrequires a more structured, systematic and coherent organization. \n\nThere is only one paragraph in related work. There is no need to employ a bullet point at the beginning"
                },
                "questions": {
                    "value": "See the weakness part"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1159/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1159/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1159/Reviewer_1nCt"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1159/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698794027229,
            "cdate": 1698794027229,
            "tmdate": 1699636042289,
            "mdate": 1699636042289,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lRzpUE6zfz",
                "forum": "sqRgz88TM3",
                "replyto": "p1x3Mj4799",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1159/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1159/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Questions and Weaknesses from R-1nCt"
                    },
                    "comment": {
                        "value": "### **Response to Weakness 1**\n\nThank you for the suggestion. As a **research library** designed to facilitate research development in the VFL, our VFLAIR incorporated all the essential components of a VFL system, including 2 model partition strategies, 5 communication protocols (3 added during discussion), 1 encryption protocol, 13 datasets (4 added during discussion) of different modality and data partition methods, 29 model architectures, in addition to 11 attacks and 8 defenses. In addition, our VFLAIR can be easily used and extended to perform evaluations on various aspects of a VFL system, including model performance, computation and communication efficiency under a broad range of settings. \n\nTherefore, we consider our VFLAIR a comprehensive VFL library and will continue to add more state-of-art privacy-preserving and communication-efficient methods in the future. As for our benchmark evaluations, we have further refined and completed new evaluations on model performance of new datasets (Tab. 7 in Section 6.1), communication and computation efficiency of various communication strategies (Tab. 6 in Section 6.1). Therefore, although comprehensive evaluation of attack and defense is an outstanding feature of our benchmark, we think other aspects should not be overlooked. So we would prefer to **keep our title unchanged**.\n\n### **Response to Weakness 2**\n\nWe validate the effectiveness of our proposed DCS metrics from the following 3 aspects.\n\n- **Robustness.**  The results of the C-DCS rankings are generally consistent across all datasets (MNIST, CIAFR10 and NUSWIDE) in Tabs. 14 to 16 under the same setting. Also, the C-DCS ranking of the defense methods are still generally consistent under different model partition setting and communication protocols in Tabs. 14, 17 and 18. Below we plot the mean and standard derivation (std) of the ranking of each defense in the above 5 ranking tables with different defense hyper-parameter shown in [this figure (link)](https://anonymous.4open.science/r/VFLAIR_discussion/dcs_roubustness.png). As shown in this figure,  the ranking is relatively stable and the std is small across multiple settings for all the defenses. Finally, as shown in Figs. 4, 14 and 15, the C-DCS ranking is also generally stable with the change of $\\beta$, especially when $\\beta \\leq 0.7$. All these demonstrate the good stability and credibility of our proposed C-DCS metrics. \n- **Sensitivity.** We demonstrate that the changes in DCS value is a good indicator of relative defense capability with the following evidence: (1) From Tabs. 14 to 16, we show that T-DCS$_{FR}$ (T-DCS for feature reconstruction attacks) values are much lower than the T-DCS values of other attack types, indicating inferior defense capabilities under feature reconstruction attacks. This phenomenon is consistent with the fact that feature reconstruction attacks, especially TBM which uses auxiliary data for reconstruction, result in much stronger attack capabilities (shown in Figs. 3, 11 and 12). Here we also show the visualization of the reconstructed images of TBM under different defense methods in [this figure (link)](https://anonymous.4open.science/r/VFLAIR_discussion/5ressfl.png). It is apparent that although the reconstructed images are noisy, the contour can still be seen easily. This further validates the effectiveness of our proposed T-DCS in measuring the relative defense strength of different types of attacks. (2) The differences in DCS scores between splitVFL and aggVFL settings (in Section 6) are also consistent with the human domain knowledge that splitVFL is less vunerable to attacks compared to aggVFL, which is consistent with findings in [1], demonstrating the effectiveness of the metrics.\n- **Alignment with human intuition.** By definition (Eq. (1)), our DCS score measures its closeness to a perfect defense (Fig. 2).  Intuitively, a higher DCS score represents a defense that achieves a lower AP at a higher level of MP compared to others. This definition aligns with the defense target, i.e. limiting the AP to a lower level while maintaining a higher level of MP. \n\n**Reference**\n\n[1] Yan Kang, et al. \"A framework for evaluating privacy-utility trade-off in vertical federated learning\". arXiv preprint arXiv:2209.03885, 2022"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700279303937,
                "cdate": 1700279303937,
                "tmdate": 1700279303937,
                "mdate": 1700279303937,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kaBmqkduyf",
                "forum": "sqRgz88TM3",
                "replyto": "p1x3Mj4799",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1159/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1159/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We are anxiously looking forward to your replies to our responses"
                    },
                    "comment": {
                        "value": "Dear reviewer, do our responses to your questions as well as the updated paper address your concerns? We have added a workflow figure in (in the appendix and the link in the response), testified the effectiveness of our DCS evaluation (in the response and in the appendix) and reorganized the result section (Section 6) and related work section (Section 2) according to your reviews. We hope the above have solved your concerns and we are still looking forward to your further replies. We will remain open and available if there is any further concerns."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700636014083,
                "cdate": 1700636014083,
                "tmdate": 1700639468289,
                "mdate": 1700639468289,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BI2vKvVf0X",
                "forum": "sqRgz88TM3",
                "replyto": "p1x3Mj4799",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1159/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1159/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We are still anxiously looking forward to your replies to our responses"
                    },
                    "comment": {
                        "value": "Dear reviewer, we are still anxiously looking forward to your replies to our responses. Time is limited with less than **5** hours till the end of the discussion period. We are curious to know if our responses to your questions as well as the updated paper have already addressed your concerns. We have put a lot of effort into working to address your concerns and to improve our work. We summarize our modifications with respect to your reviews as below:\n\n- We testified the effectiveness of our DCS evaluation in our response from 3 different aspects to answer your question, including Robustness, Sensitivity and Alignment with human intuition. We have also included these analyses in our updated paper in Section 6 and Appendix I.2.6.\n- We have added a workflow figure in (in appendix D and a link for quick access in the response).\n- We reorganized the result section (Section 6) in a more systematic way according to your reviews. We also modified the related work section (Section 2) according to your helpful suggestion. \n- We carefully considered your comment on the paper title and clearly presented the reasons why we choose to kept it unchanged.\n\nWe hope the above have solved your concerns and we are still looking forward to your further replies. We will remain open and available if there is any further concerns."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700723580585,
                "cdate": 1700723580585,
                "tmdate": 1700723628354,
                "mdate": 1700723628354,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "kzw0g8RJd1",
            "forum": "sqRgz88TM3",
            "replyto": "sqRgz88TM3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1159/Reviewer_z5tx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1159/Reviewer_z5tx"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a research library and benchmark named VFLAIR for vertical federated learning. VFLAIR contains 9 datasets, 29 models, 2 communication protocols, 3 data partitioning, 11 attacks, and 8 defense methods. Model performance, attack and defense performance, and communication protocol comparison are comprehensively evaluated."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. While vertical federated learning is a promising research direction with many real-world applications, it is less exploited compared with horizontal federated learning. Unlike horizontal federated learning systems, there is a lack of a comprehensive vertical FL library. This work is a significant contribution to the FL community.\n\n2. The library is comprehensive and includes many models, attacks, and defense methods.\n\n3. Experiments are extensive, especially for the attack and defense part."
                },
                "weaknesses": {
                    "value": "1. The writing needs to be further improved. The paper claims that VFLAIR is a lightweight and extensible framework but does not demonstrate why it is. The introduction of the framework is limited. Besides introducing the components of VFLAIR in Figure 1, the paper should also introduce what is the systematic design of VFLAIR and demonstrate why it is very easy to use and extend.\n\n2. The insights in Section 6 should be highlighted. Currently, the paragraph is too long (especially Section 6.2) and readers are hard to find interesting results from the experiments. I suggest the authors put the insights at the beginning of each subsection.\n\n3. It seems that the paper divides the datasets into multiple subsets equally. Non-IID data partitioning is an important factor in FL and would be good to be included in VFLAIR. Also, it\u2019d be better to include real-world vertical federated datasets besides partitioning a centralized dataset.\n\n4. The communication protocols in the library are not rich. Only two methods are considered."
                },
                "questions": {
                    "value": "1. Can you demonstrate how to use VFLIR and how to extend it? \n\n2. Can you summarize and highlight interesting findings at the beginning of each subsection of Section 6.1?\n\n3. Will you consider including more communication protocols, real-world vertical federated datasets, and data partitioning methods in the library?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1159/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1159/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1159/Reviewer_z5tx"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1159/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698807065819,
            "cdate": 1698807065819,
            "tmdate": 1700692270034,
            "mdate": 1700692270034,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "a0hwPZbfTm",
                "forum": "sqRgz88TM3",
                "replyto": "kzw0g8RJd1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1159/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1159/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Questions and Weaknesses from R-z5tx"
                    },
                    "comment": {
                        "value": "### **Response to Weakness 1 and Question 1**\n\nIn order to better illustrate the systematic design of VFLAIR, we add Fig. 10 in Appendix D (see also [this figure (link)](https://anonymous.4open.science/r/VFLAIR_discussion/workflow_new.png)) to demonstrate the key modules and workflow of VFLAIR. We also add a step by step guidance for using and extending VFLAIR in Appendix C. In summary, building on a modularized design of components covering all essential aspects of a VFL system, using VFLAIR only requires 5 easy steps as shown in Fig. 8 in Appendix C (see also [this figure (link)](https://anonymous.4open.science/r/VFLAIR_discussion/demo/demo_how_to_use.png)), with a single line to run: \"python main_pipeline.py --configs my_config\".  \n\nFor extending VFLAIR, we summarized the necessary steps and also included 2 demo cases (\"how to add a new attack\" and \"how to add a new local model\") in Appendix C. In summary, extending VFLAIR requires only modifying the configuration file, implementing code by inheriting corresponding classes (e.g. attacker) or by adding the model architecture and run. \n\nPlease see Appendix C and D for more details. \n\n\n### **Response to Weakness 2 and Question 2**\nThanks for the suggestions. We have added and highlighted the summary of insights at the beginning of each paragraph throughout section 6. Please see our modified manuscript.\n\n\n### **Response to Weakness 3 and Question 3**\nThanks a lot for your suggestions. We first need to clarify that, different from horizontal federated learning (HFL) where datasets are partitioned by samples, \"non-IID data\" distribution is not considered in VFL because datasets are partitioned by features. That said, we did consider \"unequal split of features among each party\" in our experiments with justifiable partitioning methods. For example, as we already included in our submission, NUSWIDE is a cross-modal dataset which contains an image field of 634 features and a text field of 1000 features, which are naturally partitioned into two parties by modality, resulting in an unbalanced feature set among parties. This also aligns with real-world data distribution where text and its paired image are held by different parties. \n\nDespite the rapid growth of real-world VFL applications, it is still difficult to collect truly distributed real-world dataset due to data privacy and regulations. However, we have additionally added Criteo, Avazu, Cora and News20 into our benchmark results in Tab. 7 in Section 6.1 (and below). They are considered real-world datasets for typical VFL applications (Criteo and Avazu for click through rate prediction in advertising, Cora for node classification in citation network, and News20 for classification of news data). As shown in the table below, we adopt partition strategies aligning with human observation of features, resulting in unbalanced features among parties (see also Tab.10 in Appendix H for complete dataset and partition details).\n\n(1) Tab. 7 (in paper). MP, communication rounds (\\#Rounds) for reaching specified MP with 4 real-world datasets of NN-based VFL with **FedSGD** communication protocol.\n|  Dataset  |      aggVFL     |  aggVFL  |     splitVFL    | splitVFL |\n|:---------:|:---------------:|:--------:|:---------------:|:--------:|\n|            |        MP       | \\#Rounds |        MP       | \\#Rounds |\n|   Criteo  | 0.715$\\pm$0.053 |     2    | 0.744$\\pm$0.001 |     3    |\n|   Avazu   | 0.832$\\pm$0.001 |     5    | 0.832$\\pm$0.001 |     9    |\n|    Cora   | 0.721$\\pm$0.004 |    11    | 0.724$\\pm$0.012 |    13    |\n| News20-S5 | 0.882$\\pm$0.014 |    57    | 0.893$\\pm$0.013 |    61    |\n\n(2) Feature (dataset) partition strategies that are unequal. (p): passive party, (a): active party for column 'Number of Features'.\n| Dataset | Number of Features  |                Partition Criteria                |       Added during Discussion      |\n|:-------:|:------------------------------------------:|:------------------------------------------------:|:----------------------------------:|\n| NUSWIDE |              1000 (p), 634 (a)             |           feature type (text or image)           | No (already included in subission) |\n|  Credit |                12 (p), 11(a)               | feature meaning (bill/previous statement or not) | No (already included in subission) |\n|  Criteo |               13 (p), 26 (a)               |         feature type (discrete or dense)         |                 Yes                |\n|  Avazu  |                9 (p), 13 (a)               |          feature type (anonymous or not)         |                 Yes                |"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700278449778,
                "cdate": 1700278449778,
                "tmdate": 1700278449778,
                "mdate": 1700278449778,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "18xkarAC1b",
                "forum": "sqRgz88TM3",
                "replyto": "kzw0g8RJd1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1159/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1159/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We are anxiously looking forward to your replies to our responses"
                    },
                    "comment": {
                        "value": "Dear reviewer, do our responses to your questions as well as the updated paper address your concerns? We have added more unequal dataset partition methods (in Tab. 7 in Section 6); more communication protocols (in Tab. 6 in Section 6) like quantization, Top-k compression and CELU-VFL to our VFLAIR platform and benchmark experiments according to your reviews. We have also added a step by step user guidance as well as 2 demos on how to extend VFLAIR in the appendix (Appendix C). Moreover, we have reorganized Section 6 and highlighted the insights of each paragraph in our updated paper. We hope the above have solved your concerns and we are still looking forward to your further replies. We will remain open and available if there is any further concerns."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700636879471,
                "cdate": 1700636879471,
                "tmdate": 1700639549258,
                "mdate": 1700639549258,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "M2bGwoyRsx",
                "forum": "sqRgz88TM3",
                "replyto": "kzw0g8RJd1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1159/Reviewer_z5tx"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1159/Reviewer_z5tx"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your response. The revision has addressed most of my concerns. The paper is more clear now. I have raised my score to 8. For the benchmark, it'd be great if the authors could make it a Python library so that researchers can easily import the approaches for more flexible usage."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700692258711,
                "cdate": 1700692258711,
                "tmdate": 1700698683268,
                "mdate": 1700698683268,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]