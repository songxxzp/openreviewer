[
    {
        "title": "Differentially Private Principal Component Analysis for Vertically Partitioned Data"
    },
    {
        "review": {
            "id": "GIhsulnZA6",
            "forum": "Z0ojN315Uf",
            "replyto": "Z0ojN315Uf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5097/Reviewer_qWzN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5097/Reviewer_qWzN"
            ],
            "content": {
                "summary": {
                    "value": "This research paper provides a comprehensive solution called Secure Principal Component Analysis (SPCA) for differentially private principal component analysis (PCA) in vertical Federated Learning. SPCA technique introduces minimal noise to the obtained subspace while preserving differential privacy (DP) without assuming any trusted client or third party. Ensuring data privacy can be a challenge, especially when clients are adversarial. SPCA, on the other hand, ensures privacy protection for both the server and clients. The authors provide a theoretical analysis that indicates that it can achieve the same level of privacy-utility trade-off as the optimal baseline in a centralized setting. Through experiments on real-world datasets, the researchers demonstrate that SPCA achieves optimal error rates comparable to the centralized baseline. Overall, this paper presents a new solution for DP-PCA on vertically partitioned data, with a theoretical analysis demonstrating its effectiveness."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1) The paper proposes a solution called Secure Principal Component Analysis (SPCA) for differentially private principal component analysis in vertical Federated Learning.\n2) The paper presents a theoretical analysis demonstrating that SPCA can achieve the privacy-utility trade-off of the optimal baseline in the centralized setting. The analysis shows the solution's effectiveness.\n3) The research paper presents real-world experiments that confirm the theoretical analysis. The paper demonstrates how the analysis has been validated on various datasets."
                },
                "weaknesses": {
                    "value": "1) Although the paper includes experiments on real-world datasets, the number of experiments is relatively small, which could limit the generalizability of the results.\n\n2) Comparisons with other existing solutions for differentially private principal component analysis for vertically partitioned data are not presented in the paper."
                },
                "questions": {
                    "value": "1) Wang et al. did \"Differentially Private Principal Component Analysis Over Horizontally Partitioned Data,\" but what is your novelty for vertically partitioned data?\n2) Can you elaborate on how the proposed solution can be practically applied?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5097/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5097/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5097/Reviewer_qWzN"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5097/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698506149102,
            "cdate": 1698506149102,
            "tmdate": 1699636501212,
            "mdate": 1699636501212,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XbHHOnCloX",
                "forum": "Z0ojN315Uf",
                "replyto": "GIhsulnZA6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5097/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5097/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer qWzN"
                    },
                    "comment": {
                        "value": "Thanks for the comments. In what follows, we provide a detailed response. Please kindly let us know if you have any further questions.\n\n---\n\n**Weaknesses 1. Although the paper includes experiments on real-world datasets, the number of experiments is relatively small, which could limit the generalizability of the results.**\n\n---\n\n**Response.** We believe this is a misunderstanding. First of all, we have included an *extensive* set of experiments, covering different parameter regimes, including both high-dimensional datasets with $n\\ll m$ (CiteSeer and Gene), as well as the KDDCUP dataset, which was commonly used for evaluating PCA (e.g., see Chaudhuri et al. [1]), and the recently released ACSIncome dataset [2] that is commonly used for evaluating FL algorithms. In terms of *theory*, we have also proved that our solution is able to achieve comparable performance as the strong centralized baseline.  Both the empirical results and theoretical analysis confirm the performance and generalizability of our solution.\n\n---\n\n**Weaknesses 2. Comparisons with other existing solutions for differentially private principal component analysis for vertically partitioned data are not presented in the paper.**\n\n---\n\n**Response.** Thanks for raising this concern. As we have mentioned, existing solutions for private PCA for vertically partitioned data that utilize MPC alone do not provide any rigorous DP guarantees (e.g., see [3,4]). Other works, which attempted to achieve DP under vertical FL by letting one of the clients or a third party to inject random DP noises to the sensitive outcome, are **not differentially private** either, as the party might be curious and infer the sensitive outcome (e.g., see [5,6]). As a result, these baselines are **not comparable** with ours, which simultaneously preserves two levels of DP, regarding both a curious server and the curious clients in FL, without assuming any trusted third parties. The only baseline that is comparable to ours is the baseline introduced on page 6 (detailed in Algorithm 3 of page 14), whose performance is much worse than our SPCA, as illustrated in both the theoretical analysis and empirical evaluations."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5097/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699867394415,
                "cdate": 1699867394415,
                "tmdate": 1699868449050,
                "mdate": 1699868449050,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fIoHk6mBq4",
                "forum": "Z0ojN315Uf",
                "replyto": "GIhsulnZA6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5097/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5097/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewr qWzN (continued)"
                    },
                    "comment": {
                        "value": "**Question 1. Wang et al. did \"Differentially Private Principal Component Analysis Over Horizontally Partitioned Data,\" but what is your novelty for vertically partitioned data?**\n\n---\n\n**Response.** Thanks for the question. We would like to first clarify that existing DP solutions for **horizontally partitioned data** (including the approach by Wang et al. [7]) **do not apply** to our setting of **vertically partitioned data**. The key reason, as we have mentioned in the introduction section, is non-linearity. In the horizontal setting, the clients are able to linearly aggregate their locally perturbed results whereas in the vertical setting, different clients must collaborate to compute the target. In the case of PCA, each entry of the covariance matrix is computed as the inner product between two column vectors possessed by different clients. As a result, the perturbation process cannot be done by a single client alone, since otherwise, the client would learn the sensitive outcome, violating differential privacy.\n\nIn terms of contribution, we present the first DP algorithm for PCA over *vertically partitioned data* that simultaneously protects the partitioned data from both the curious server and curious clients, without assuming any trusted third parties. In addition, our algorithm achieves comparable performance as the strong centralized baseline, which is also **a first of its kind** in the vertical FL literature. Although it is well known that DP algorithms under *horizontal FL* are able to achieve comparable performance as in the centralized setting, with the help of secure aggregation or secure shuffling, whether the same can be done under *vertical FL*, however, *has not been answered until this work*. We provide a positive answer in this work, which, we believe is a notable contribution to the privacy community.\n\n---\n\n**Question 2. Can you elaborate on how the proposed solution can be practically applied?**\n\n---\n\n**Response.** To apply our solution in practice, there are four steps in general, as outlined in Algorithm 1 on page 7.\n\nFirst, each client independently discretizes her local data partition. This computation can be done efficiently on the client side since only multiplication and random rounding are involved (see Algorithm 2).\n\nNext, each client independently samples Skellam noises on the local side privately, which is done by taking the difference between two identically distributed independent Poisson random variables. Sampling algorithms for Poisson are implemented in commonly used libraries such as NumPy and SciPy.\n\nThe clients then collaboratively compute the sum of the covariance matrix and the sampled local Skellam noises (as in Eq.(7) on page 6) using any secure multiparty computation (MPC) algorithm without affecting the privacy guarantees (e.g., using the classic BGW protocol). The computation of Eq.(7) involves only summation and multiplication, which are considered elementary operations and can be done efficiently in modern MPC algorithms (e.g., SPDZ by Keller et al. [8]).\n\nFinally, the server reconstructs the covariance matrix from the outcome of MPC in the previous step and computes the $k$-dimensional singular subspace from the covariance matrix on her side. The server is free to use any centralized algorithm for the computation without affecting the privacy guarantees since post-processing preserves DP (e.g., using the power iteration method for efficient computation of eigenvectors [9])."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5097/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699867512303,
                "cdate": 1699867512303,
                "tmdate": 1699868101986,
                "mdate": 1699868101986,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SJZJsnFL9m",
                "forum": "Z0ojN315Uf",
                "replyto": "GIhsulnZA6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5097/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5097/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Any further questions or comments?"
                    },
                    "comment": {
                        "value": "We want to thank the reviewer for their comments.\n\nAs the deadline for the rebuttal phase is approaching, we would like to encourage the reviewer to engage in the interactive rebuttal to help improve our paper and clarify misunderstandings."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5097/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700379449376,
                "cdate": 1700379449376,
                "tmdate": 1700635415589,
                "mdate": 1700635415589,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "70TpnDUADD",
            "forum": "Z0ojN315Uf",
            "replyto": "Z0ojN315Uf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5097/Reviewer_fmuB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5097/Reviewer_fmuB"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a differentially private technique for PCA on vertically partitioned data."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The approach is mostly sound (but see a few important notes below).\nThe text is well written and understandable.\nProbably the most important contribution is the analysis of the privacy as a function of noise (if it is correct)."
                },
                "weaknesses": {
                    "value": "The paper mentions secret sharing, but then doesn't mention an important baseline to consider.  In particular, the brute-force approach which needs \"minimal (*)\" noise is that the clients secret-share their portion of the data, that they compute the covariance matrix together in secret shared form (this only requires additions and multiplications, which under SSS can be performed rather efficiently once the data is secret shared), together add the (minimally required) noise, and then reveal the noisy covariance matrix C.  This algorithm is clearly differentially private and doesn't leak intermediate results.  The only thing another approach can hope to do better is to require fewer communication (and computation).  Unless you can show that your proposal is significantly less expensive than this fully secret-sharing based approach, it doesn't seem a very valuable contribution.  In fact, it seems that Algorithm 1 is not much more efficient that the brute force algorithm I sketch above as it needs to involve all N clients for the computation of each inner product of columns i and j not belonging to the same client.  I guess Algorithm 1 isn't significantly faster than the baseline I describe above, while you could have made it faster by computing D[:,i].D[:,j] using a multi party computation involving only the clients owning columns i and j.\n\nWhile \\sum_{q=1}^N z_q offers some privacy, every client k knows z_k and can therefore compute \\sum_{q=1}^{k-1} z_q + \\sum_{k+1}^N z_q which is the sum of only (N-1) noise terms and hence gives only (N-1)/N of the privacy provided by Sk(\\mu).  Ideally, in line 4 of Algorithm 1 clients should sample from Sk(\\mu/(N-1)).  Alternatively, instead of letting all clients sample from Sk(\\mu/(N-1)) it would be even better to let the clients collaborative sample from Sk(\\mu) without any client learning the sampled value (i.e., sampling using SSS).  In that case, the \"minimal (*)\" amount of noise Sk(\\mu) would be added to the final result.\n\nWhen the abstract (and my comments above) say \"minimal noise\", this is not really the minimal noise, but the smallest amount of noise for which the proof of DP is easy and straightforward.  There is no proof that there doesn't exist an even smaller amount of noise (where in particular possibly not every component C[i,j] gets independent noise) which leads to a result which can also be proven to be DP.\n\nThe proof of the main result (privacy) contains several mistakes, and it is therefore hard to verify its overall correctness, even if I believe that at a high level the result is plausible (i.e., I'm confident such a result is possible but I don't know whether the lower-order terms or constant factors are correct).  For example:\n* \"Since the L2 norm for each row in D and D' is bounded by \\sqrt{\\gamma^2+n} ... we have that ... \\|D^\\top D - D'^\\top D'\\|_F^2 \\le \\gamma^2 + n\" : I would expect that the bound on the norm of these inner products is also linear in \\sqrt{m} with m the number of rows.\n* \"In addition, that the L1 norm of an integer-valued vector v is always less than or equal to \\|v\\|_2^2 and \\sqrt{n}\\|v\\|_2\" : this sentence isn't fully grammatically clear.  It is not correct that the L1 norm of v, i.e., \\sum_i |v_i| is always smaller than \\|v\\|_2^2 = \\sum_i v_i^2 (especially not for \"integer valued v\" where it is possible some components of v are larger than 1 in absolute value.\n* Next, the text just calls for lemma 1, but it would help significantly if the text would first make all parameters of lemma 1 explicit, e.g., \\Delta_1, \\Delta_2, ..."
                },
                "questions": {
                    "value": "I assume that what you describe in \"Baseline in vertical FL.\" corresponds to what is more commonly known as \"Local differential privacy\", i.e., every client adds so much noise that the publication of the data doesn't allow an adversary to reveal any sensitive information ?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "--"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5097/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698682766349,
            "cdate": 1698682766349,
            "tmdate": 1699636501082,
            "mdate": 1699636501082,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Q2eYAL4XDB",
                "forum": "Z0ojN315Uf",
                "replyto": "70TpnDUADD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5097/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5097/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer fmuB"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for the thoughtful comments. In what follows, we provide a detailed response. Please kindly let us know if you have any further questions.\n\n---\n\n\n**1. The brute-force baseline.**\n\n---\n\n**Response.** Indeed, we have considered the brute-force algorithm you mention above, where for each $C(i,j)$, only the corresponding clients who own columns $i$ and $j$ (say client $p$ and client $q$) participate in the secret sharing process. However, this brute-force approach has the drawback that both client $p$ and client $q$ know exactly *half* the overall DP noise. As a result, it is *easier* for client $q$ to infer the data of client $p$, compared with our solution, where both client $p$ and $q$ know only $1/N$ of the overall DP noise. In cases when $N>2$, our solution is *more private considering curious clients*.\n\n---\n\n\n**2. Client's knowledge of $Sk(\\mu/N)$.**\n\n---\n\n**Response.** You are correct. From a client\u2019s perspective, the DP guarantee is provided by $Sk((N-1)\\mu/N)$. Hence, the levels of client-observed DP and server-observed DP (which is provided by $Sk(\\mu)$) are different, as we have stated in Lemma 2 (see Eq.(9) and Eq.(10) in page 8). For better comparison with previous works from the centralized setting and the horizontal FL setting [1,2], we focus on server-observed DP. The corresponding levels of client-observed DP are reported in Tables 1 and 2 of page 17. \n\n\n---\n\n\n**3. The minimal noise.**\n\n---\n\n**Response.** You are correct. We could not technically prove that our noise is minimal. We have revised the term *minimal noise* to ``noise of scale comparable with the strong centralized baseline'' in the draft.\n\n---\n\n\n**4. Alternative solution for collaborative sampling from $Sk(\\mu)$.**\n\n**Response.** Although it is a tempting idea to let the clients sample from $Sk(\\mu)$ directly while getting rid of the slackness of $1/N$, we are not aware of any *efficient* and *rigorous* approach to do so under distributed FL settings (either vertical or horizontal). \n\nIn particular, the slackness of $1/N$ was also observed in the state-of-the-art approaches of horizontal FL [1,2], where each client independently injects locally generated DP noises to the sensitive outcome. Wang et al. [3] attempted to remove the slackness by letting the clients jointly sample from a discrete Gaussian distribution using a shared random seed. However, as pointed out by Kairouz et al. [1], a single curious client could learn the overall DP noise from the shared seed, leading to **privacy violation**. \n\nIn vertical FL, Wu et al. [3] propose to use a secret-shared random seed to generate Laplace noise to achieve DP when generating decision trees under vertical FL. However, they *did not* provide any **formal DP analysis** from the perspective of a curious client. In addition, the process for converting shared randomness to the designated distribution of DP noise (e.g., discrete Gaussian [1] and Skellam [2]) might be a huge **overhead** for the clients to bear, considering that even the centralized algorithms for generating discrete Gaussian and Skellam distributions from random bits are *complicated and time-consuming* (see Section 5 in [4], page 487 of [5], and [6]) and the clients also need to *synchronize repeatedly* in such complicated algorithms under the MPC model. \n\nOn the contrary, the overhead of DP in SPCA comes from the addition of $N$ Skellam noises, as the client can generate Skellam noises in an *offline manner* without collaboration. This overhead of $N$ additions is *not significant* when compared with the computation of an element in the covariance matrix that involves the addition of $m$ multiplications, considering that the number of clients $N$ is usually much smaller than the number of records $m$ in vertical FL. In addition, when $N$ is large, the difference between $N$ and $N-1$ *becomes negligible*. Further closing this gap would be an interesting direction to explore."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5097/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699866903997,
                "cdate": 1699866903997,
                "tmdate": 1699868657765,
                "mdate": 1699868657765,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MBAgFeMa85",
                "forum": "Z0ojN315Uf",
                "replyto": "70TpnDUADD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5097/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5097/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer fmuB (continued)"
                    },
                    "comment": {
                        "value": "**5. Correctness about proofs.**\n\n---\n\n**Response.** We apologize for the unclear presentation of the proofs. We have revised the proof. In particular, we have included more details to explain that the sensitivity of the covariance matrix of the quantized data is independent of $m$. We also note that since every non-negative integer $u$ is smaller than or equal to $u^2$ (equality holds for $u=0,1$), we have that $||v||_1\\leq ||v||_2^2$ for any integer vector $v$. Finally, we have explicitly stated the parameters in the proof for Lemma 2. Please refer to Page 15 of the revised draft for more details.\n\n---\n\n\n**6. I assume that what you describe in ''Baseline in vertical FL'' corresponds to what is more commonly known as ''Local differential privacy'', i.e., every client adds so much noise that the publication of the data doesn't allow an adversary to reveal any sensitive information ?.**\n\n---\n\n**Response.** You are correct. The vertical FL baseline is indeed a local DP algorithm. As we have mentioned in the draft, other existing vertical FL approaches either involve a client, the server, or a third party to perform the noise injection step, which is not differentially private considering that these parties can be curious or do not provide any rigorous DP analysis (such as [7]).\n\n\n---\n\n**References.**\n> [1]. Peter Kairouz, Ziyu Liu, and Thomas Steinke. 2021. The Distributed Discrete Gaussian Mechanism for Federated Learning with Secure Aggregation. In ICML. \n\n> [2]. Naman Agarwal, Peter Kairouz, and Ziyu Liu. 2021. The Skellam Mechanism for Diferentially Private Federated Learning. In NeurIPS. \n\n> [3]. Yuncheng Wu, Shaofeng Cai, Xiaokui Xiao, Gang Chen, and Beng Chin Ooi. Privacy preserving vertical federated learning for tree-based models. In PVLDB.\n\n> [4]. Cl\u00e9ment L. Canonne, Gautam Kamath, and Thomas Steinke. 2020. The Discrete Gaussian for Diferential Privacy. In NeurIPS.\n\n> [5]. Luc Devroye. 1986. Non-Uniform Random Variate Generation. Springer. https://doi.org/10.1007/978-1-4613-8643-8\n\n> [6]. Philippe Duchon and Romaric Duvignau. 2016. Preserving the Number of Cycles of Length k in a Growing Uniform Permutation. Electron. J. Comb. 23 (2016), P4.22.\n\n> [7]. Thilina Ranbaduge and Ming Ding. Differentially private vertical federated learning. CoRR, abs/2211.06782, 2022."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5097/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699867119982,
                "cdate": 1699867119982,
                "tmdate": 1699868592204,
                "mdate": 1699868592204,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "v4crCjgB5M",
                "forum": "Z0ojN315Uf",
                "replyto": "Q2eYAL4XDB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5097/Reviewer_fmuB"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5097/Reviewer_fmuB"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your clarifications.\n\nYou don't answer my question on whether the proposed algorithm is really better than what I called the \"brute force\" algorithm.\n\nOn the other hand, there is an interesting discussion on whether computing an inner product of two columns is more efficient with two or with all partners.  It seems to come down to the question whether the parties know the noise they generate.  I agree that if the parties know the noise they generate and you consider client-observed DP, then it is better to let all parties participate in the inner product computation.  However, in your response you say you mainly consider server-observed DP and are not so interested in client-observed DP.  Moreover, it is not needed that clients know the noise, and in that case the provided argument (that clients know half of the noise) isn't relevant.\n\nThe paper and the answer about the knowledge by the clients of $Sk(\\mu/N)$ suggests that the clients always generate each a part of the noise and then combine the noise.  This is a classic strategy, also used by Dwork in the early DP papers, and as you point out has been used since then in a lot of the state of the art with many authors not considering in depth better alternatives.  However, given that you anyway use secret sharing, it is possible to generate noise which none of both clients know, at a constant cost per pair of parties.  While I agree this cost may be non-trivial (you claim it is large), it is only a constant cost per pair of clients. A constant cost between each pair of parties, independent of the dataset size, may still be acceptable as nowadays datasets have become very large and any algorithm running over the complete dataset  typically has much higher cost than the joint generation of a random number. \n\nIn conclusion, while there may be arguments why you prefer to not go beyond the state of the art in terms of oblivious noise generation, and there may be reasons to stay with an approach where all parties are involved in all inner product computations, this also makes it harder to see how exactly the proposed algorithm goes beyond a brute-force secret sharing of the PCA algorithm.  \n\nYour resolution of point (3) seems appropriate."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5097/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699876311311,
                "cdate": 1699876311311,
                "tmdate": 1699876311311,
                "mdate": 1699876311311,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6n61MTasnb",
                "forum": "Z0ojN315Uf",
                "replyto": "70TpnDUADD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5097/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5097/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer fmuB"
                    },
                    "comment": {
                        "value": "Thanks for your kind explanations.\n\nWe agree that the brute-force approach you have suggested *indeed is better* than our proposed solution in terms of the privacy-utility trade-off from the perspective of a *curious client*, who no longer has the knowledge of $Sk(\\mu/N)$. \n\nHowever, we would like to point out that, still, the difference *may be negligible* in scenarios where $N$ is large (e.g., $N=20$). In addition, in certain scenarios, the cost of the brute-force approach could be more significant (despite that it is a constant regarding the size of data). For example, considering the Skellam noise generation with a large $\\mu$ (corresponding to strong privacy constraints), the clients would need to collaboratively generate $\\mu$ *independent copies* of $Sk(1)$ (let's say $\\mu$ is an integer for the ease of discussion), which could be time-consuming. On the other hand, in our solution, each of the $N$ clients independently generates a much smaller Skellam noise in a more efficient offline manner, which could be an advantage under strong privacy constraints and when the number of records is small."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5097/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700029554691,
                "cdate": 1700029554691,
                "tmdate": 1700073973311,
                "mdate": 1700073973311,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "a3rRsNbWaK",
            "forum": "Z0ojN315Uf",
            "replyto": "Z0ojN315Uf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5097/Reviewer_DSCS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5097/Reviewer_DSCS"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the principal component analysis (PCA) in the vertical FL setting, where each party owns a subset of columns in the data matrix. It requires the observations by each client or the server to be differentially private and the error of PCA in the end can be small. The paper proposes an algorithm, where the MPC protocol is utilized and the noise from each party is carefully calculated. In the empirical evaluation, the proposed method is compared with a reasonable baseline and centralized DP algorithm."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The clarity of this paper is great. The arguments in the paper are well-explained.\n2. The problem is well formulated and it is clear the see the advantage of the proposed algorithm over the baseline. The proposed algorithm is independent of $m$ and the baseline highly depends on $m$.\n3. The empirical evaluation looks reasonable. The selected dataset covers different range of $(m, n)$."
                },
                "weaknesses": {
                    "value": "1. The utility result (Lemma 3) doesn't show $N$, which is an important factor in vertical FL. It would be great to show how $N$ influences the results empirically.\n2. It would be meaningful to present the time/communication cost that happened during the MPC, which is dependent on the choice of $\\gamma$.\n3. Dataset release in RMGM-OLS [1] would provide another reasonable baseline: unlike the baseline in the paper which adds noise to the data matrix directly, it adds noise after a random projection, which can reasonably reduce the scaling of noise.\n\n[1] Wu, Ruihan, et al. \"Differentially Private Multi-Party Data Release for Linear Regression.\" Uncertainty in Artificial Intelligence. PMLR, 2022"
                },
                "questions": {
                    "value": "Please see the \"Weakness\" above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5097/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698723911462,
            "cdate": 1698723911462,
            "tmdate": 1699636500989,
            "mdate": 1699636500989,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Ib5zQJqHyt",
                "forum": "Z0ojN315Uf",
                "replyto": "a3rRsNbWaK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5097/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5097/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer DSCS"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for the thoughtful comments. In what follows, we provide a detailed response. Please kindly let us know if you have any further questions.\n\n---\n\n**Weakness 1. The utility result of Lemma 3 does not show N, which is an important factor in vertical FL. It would be great to show how N influences the results empirically.**\n\n---\n\n**Response.** This is an insightful question. The utility result of Lemma 3 and the empirical performance of SPCA is indeed *independent* of $N$, which is exactly why SPCA achieves *comparable performance* as the strong centralized baseline (think of it as $N=1$). To explain, recall that the core idea of SPCA is to aggregate $N$ independent Skellam noises distributed as $Sk(\\mu/N)$ from the client side into $Sk(\\mu)$, a larger Skellam noise. Here, the scale of $\\mu$, which determines the result utility, is in turn determined by the required server-observed level of DP, which is *independent* of $N$. \n\nInstead, what $N$ influences is the level of *client-observed* DP (with the level of server-observed DP fixed), since each client knows her local DP noise out of the overall N contributions. As $N$ increases, the client-observed level of DP becomes stronger since each client\u2019s knowledge about the overall noise becomes smaller. As an illustration, in what follows, we fix the server-observed level of DP to $\\epsilon=4$, $\\delta=10^-5$ and vary $N$ from {10,20,40,80,160,320,640} for the ACSIncome data with $d=817$. \n\nWe report the corresponding levels of *client-observed* $\\epsilon$ with $\\delta$ fixed to $10^{-5}$ for $\\gamma=2^{12}$. \n\n| client count $N$ | 10 | 20 | 40 | 80 | 160 | 320 | 640 | \n| ----------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |\n| **client-observed** $\\epsilon$ | 9.61 | 8.97 | 8.68 | 8.55 | 8.48 | 8.45| 8.43 |\n\nNote that the change of $\\epsilon$ is almost negligible when $N$ reaches $20$. A similar conclusion also applies to other choices of $d$, $\\gamma$, as well as different levels of server-observed $\\epsilon$. We have revised the draft to incorporate the above discussion. \n\n---\n\n**Weakness 2. It would be meaningful to present the time/communication cost that happened during the MPC, which is dependent on the choice of $\\gamma$.**\n\n---\n\n**Response.** Thanks for the suggestion. $\\gamma$ represents the level of quantization granularity, which is reflected as the number of bits (namely, $\\log \\gamma$) in communication. For example, quantizing a real number from $0$ to $1$ with $\\gamma=2^{12}$ results in a $12$-bit vector. In the case of the classic BGW protocol, the communication is $O(\\log \\gamma)$ for sharing the secrets. The time complexity, on the other hand,  is independent of $\\gamma$ as the computation for constructing the secret shares (matrix multiplication) and reconstructing the secret (polynomial interpolation) are done on the client side, and the algorithms for these computations are usually dependent on the *size* of the input, rather than the *range* of the input. For example, the Newton interpolation on $N$ points ($N$ secret shares of all clients) incurs a time complexity of $O(N^2)$, which is independent of $\\gamma$. In general, the time and communication complexity may vary for different MPC protocols and implementations. We have revised the draft to incorporate the above discussion.\n\n---\n\n\n**Weakness 3. Dataset release in RMGM-OLS [1] would provide another reasonable baseline: unlike the baseline in the paper which adds noise to the data matrix directly, it adds noise after a random projection, which can reasonably reduce the scaling of noise.**\n\n---\n\n**Response.** Thanks for the reference. Although random projection is an interesting idea, RMGM-OLS by Wu et al. does not apply to our problem. In particular, the utility goal of Wu et al. (see Eq.(1) on page 3 of their paper) considers linear regression, which is a *supervised learning* problem. Based on linear regression, the clients are able to *train* the model weights to better predict the label of the data, a key component of RMGM-OLS. On the contrary, we consider PCA, an *unsupervised learning* problem where there is no target label. As a result, it is not straightforward to apply RMGM-OLS to PCA and compare it with our solution. We have revised the draft to incorporate the above discussion."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5097/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699866617270,
                "cdate": 1699866617270,
                "tmdate": 1699867233873,
                "mdate": 1699867233873,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Z7uvZjWtU8",
                "forum": "Z0ojN315Uf",
                "replyto": "a3rRsNbWaK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5097/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5097/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Any further questions or comments?"
                    },
                    "comment": {
                        "value": "We want to thank the reviewer for their comments.\n\nAs the deadline for the rebuttal phase is approaching, we would like to encourage the reviewer to engage in the interactive rebuttal to help improve our paper and clarify misunderstandings."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5097/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700379479152,
                "cdate": 1700379479152,
                "tmdate": 1700635395294,
                "mdate": 1700635395294,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "W2gzTtGs3t",
                "forum": "Z0ojN315Uf",
                "replyto": "Ib5zQJqHyt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5097/Reviewer_DSCS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5097/Reviewer_DSCS"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Reviewer DSCS"
                    },
                    "comment": {
                        "value": "Thank the authors for their clarification. It is intuitive that the observed $\\varepsilon$ doesn't have too much difference among large $N$, but the difference might be more significant when $N$ is at a small range."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5097/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700714724912,
                "cdate": 1700714724912,
                "tmdate": 1700714724912,
                "mdate": 1700714724912,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]