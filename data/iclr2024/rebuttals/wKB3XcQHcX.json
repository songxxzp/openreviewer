[
    {
        "title": "Speed Limits for Deep Learning"
    },
    {
        "review": {
            "id": "8OVDF39ON2",
            "forum": "wKB3XcQHcX",
            "replyto": "wKB3XcQHcX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2770/Reviewer_5tEv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2770/Reviewer_5tEv"
            ],
            "content": {
                "summary": {
                    "value": "This problem considers the continuous dynamic of gradient-based learning problems. Studying the problem from a thermodynamic perspective, the paper derives a lower bound on the time for a process to go from an initial state to a target state using Wasserstein-2 distance. The paper further considers two realizations of the problem, namely the linear regression and the NTK, and presents the implication of the result under various limiting scenarios."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. It seems an interesting idea to connect the machine learning optimization dynamic with notions in thermodynamics.\n\n2. The paper provides interesting interpretations of the speed limit in linear regression and NTK learning."
                },
                "weaknesses": {
                    "value": "1. I am not sure about the significance of this theoretical investigation. It seems that the paper only considers the lower bound of the time that goes from an initial parameter state to a target parameter state. It does not tell us information about e.g. the time lower bound to get to a near-stable parameter state, or the time lower bound to get to near-zero potential.\n\n2. Characterizing the speed limit using the Wasserstein-2 distance is not easily interpretable since it is in general hard to compute the Wasserstein-2 distance. The paper seems only able to derive interpretable results under limiting conditions like no noise or infinite parameters.\n\n3. The models considered in this paper are fairly simple. Both the linear regression and the learning under NTK assumption are linear models and are not representative of deep learning in general.\n\n4. The writing of the paper can be improved. I hope to see formal theorems in the paper stating the main contribution, and notations need to be clearly stated. For instance, I am not sure what is $Z_T$ and $Z_0$ in Eq. (4). There is also no related works section."
                },
                "questions": {
                    "value": "Given the conclusion in the paper that in the NTK regime the dynamic in the paper achieves a rate that is almost optimal, is this contradicting the fact that the continuous heavy-ball dynamic achieves a faster rate to converge to the stable point (see, e.g. https://link.springer.com/article/10.1007/s1022-01164-w)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2770/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2770/Reviewer_5tEv",
                        "ICLR.cc/2024/Conference/Submission2770/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2770/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698439161730,
            "cdate": 1698439161730,
            "tmdate": 1700512289602,
            "mdate": 1700512289602,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KQEPWrozJl",
                "forum": "wKB3XcQHcX",
                "replyto": "8OVDF39ON2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2770/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2770/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you very much for your review. We would first like to comment that the revised version contains a more detailed discussion of practical implications in the discussion section."
                    },
                    "comment": {
                        "value": "Reply to weakness: \n\n1. The time bound is interesting because it sets a threshold of optimal learning. Unlike what the referee suggests, the speed limit bounds in the paper hold quite generally whether one is in an equilibrium state or not (see for instance Eq. 8 in the revised manuscript). Admittedly, computing it analytically during the dynamics and finite-width networks may be challenging. However, in our NTK section, we compute it analytically for infinite-width networks. Furthermore, in our numerical experiment, we compute it numerically for a finite-channel CNN working well outside the NTK regime and still find that the results are in qualitative agreement with NTK analytics (see also new App. Sec. D.) \n\n2. Based on your feedback, we've extended the discussion at the end of section 2.2 and the discussion section to emphasize that besides the analytical investigations like those we undertake in the paper, one could hope to study much more realistic scenarios (including ones with SGD noise) by numerically bounding the Wasserstein distance (using techniques like those in \"2-Wasserstein Approximation via Restricted Convex Potentials with Application to Improved Training for GANs\" by Taghvaei and Jalali, or \"Wasserstein-2 Generative Networks\" by Korotin et al.; references we've added) and by numerically bounding or calculating the entropy production directly, closer to Section 4. The latter is predominantly determined by the geometry of the loss landscape, in terms of the gradient and the Hessian along the training trajectory (Eq (5)). With help of contemporary finite-size network theory (e.g., Li \\&,Sompolinsky 2020, Hanin\\&Slopaka 2022, Zavatone-Veth\\&Pehlevan (2021), Seroussi\\&Ringel 2023), moreover, analytical estimates of the partition function required by our Eq. (4) for the entropy production, are within reach.\nMoreover, since all quantities involved in the time bound are readily measurable (see new paragraph \"measurability\" in the discussion), the inefficiency ratio may be used as an indicator to identify periods within the training that are furthest from optimality and hence would predominantly benefit from optimization, thus serving as a guide for the development of training algorithms.\nFinally, we comment that even using finite-batch SGD our bound still applies in the limit of very low learning rates, as the SGD noise averages out giving us again gradient flow type behavior. It seems plausible to us, that improving the architecture/training hyperparameters so that the dynamics travels closer to the time bound in this low learning rate region, would also improve the behavior at higher learning rates used in experiments.\n\n3. We would first like to point out that a major part of this work is really about bridging the two worlds of stochastic thermodynamics and deep learning. For instance, our expressions for entropy production due to learning [Eq. (4,5,6) in the revised version] are, to the best of our knowledge, new results. In the final version, we plan to highlight those results as theorems for which this status can be justified from a mathematical point of view. \nStill, as you point out, in this work we consider fairly simple models: high-dimensional linear regression, the NTK, but also a more realistic finite-channel Mytrle-5 network trained on cifar10. We felt that these fairly simple scenarios, besides being more analytically tractable, were easier to interpret and reason about.  \nNotwithstanding, there is a clear roadmap to extend these results to networks in the feature learning regime using recent DMFT results or adaptive kernel approaches wherein feature learning is reflected by an augmented GP kernel governing the outputs layer and the hidden layers. For instance, using the approaches of https://www.nature.com/articles/s41467-023-36361-y one can readily estimate $\\log(Z_{T})$ at $T \\rightarrow \\infty$ and using the approach https://arxiv.org/abs/2111.00034 similarly calculate the time bound. As said, this paper is mainly about introducing this new concept and its potential applications. One of the reasons we find it exciting is that it opens the door to a fundamental understanding of the efficiency of learning with ample future possibilities.\n\n4. Thank you for pointing out this notation issue, which was indeed unclear. This has been fixed in the revised version. We added a subsection in the introduction describing related work, as well as related literature in the discussion."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2770/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700167193229,
                "cdate": 1700167193229,
                "tmdate": 1700167193229,
                "mdate": 1700167193229,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8A7zzC46Sg",
                "forum": "wKB3XcQHcX",
                "replyto": "KQEPWrozJl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2770/Reviewer_5tEv"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2770/Reviewer_5tEv"
                ],
                "content": {
                    "title": {
                        "value": "Response to the author's rebuttal"
                    },
                    "comment": {
                        "value": "Thank you for your effort in updating the paper and clarifying my concerns. Indeed, I agree that this direction is only in its starting phase and what we can do right now is quite limited. While my concerns remain about whether this analysis can be extended to more realistic settings, given that my other questions are resolved and this is a fairly novel paper, I would like to increase the rating from 5 to 6."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2770/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700512263188,
                "cdate": 1700512263188,
                "tmdate": 1700512263188,
                "mdate": 1700512263188,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qLODIY8VFR",
                "forum": "wKB3XcQHcX",
                "replyto": "UQbN7SDLl4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2770/Reviewer_5tEv"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2770/Reviewer_5tEv"
                ],
                "content": {
                    "title": {
                        "value": "Further clarification of the questions."
                    },
                    "comment": {
                        "value": "I am referring to the paper: \"Convergence rates for the Heavy-Ball continuous dynamics for non-convex optimization, under Polyak-\u0141ojasiewicz condition\" (hopefully this link will work: https://arxiv.org/abs/2107.10123). It seems that the heavy ball dynamic indeed has an acceleration effect in some scenarios. Does this contradict the argument in the paper that the GD achieves an optimal speed limit (if we ignore the constant)?"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2770/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700512508701,
                "cdate": 1700512508701,
                "tmdate": 1700512508701,
                "mdate": 1700512508701,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "alLqlZ0wPO",
            "forum": "wKB3XcQHcX",
            "replyto": "wKB3XcQHcX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2770/Reviewer_M1Mw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2770/Reviewer_M1Mw"
            ],
            "content": {
                "summary": {
                    "value": "The paper applies recent advances in stochastic thermodynamics to analyze the efficiency of training neural networks. It derives analytical expressions relating the speed limit (minimum training time) to the Wasserstein 2-distance between initial and final weight distributions and the entropy production. For linear regression and neural networks in the NTK regime, exact formulas are provided for the quantities involved in the speed limit. Under plausible assumptions on the NTK spectrum (power law behavior) and residue (defined as the target minus the initial prediction), NTKs exhibit near-optimal training efficiency in the scaling sense. Small-scale experiments on CIFAR-10 qualitatively support the theoretical findings."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "I think this is a technically sound paper that makes good contributions. The application of stochastic thermodynamics concepts to neural network training is novel. I have not seen it before in prior literature. The analysis done in the paper is insightful and to the best of my knowledge seems mathematically rigorous. The results on optimal scaling efficiency are intriguing. The writing is clear and relatively compact. It seems like the relevant prior works cited correctly. Moreover this paper provides a good literature review on various different topics across entropy production and the various bounds on that quantity."
                },
                "weaknesses": {
                    "value": "It is unclear if the near optimal scaling efficiency result applies to large realistic models and datasets. The CIFAR-10 study used very small networks. It would be very nice to see an empirical example with a larger scope. \n\nFurther, it would be nice to be more explicit of how much of the entropy production is due to the presence of nonzero initial weights. It would be nice to cover the case of either the perceptron or the NTK starting with $\\theta_0 = 0$. \n\nIt is rather unclear whether there are any takeaways from practitioners. Its not strictly necessary that their should be, but given the title one is left to wonder whether there are possible statements that can be made about the compute-optimal frontier."
                },
                "questions": {
                    "value": "It's interesting that power law scalings in the target (ie in the residues) seem to imply an inefficiency factor that grows with dataset size. Can the authors comment on whether this is representative of realistic datasets? \n\nThe initial transient period seems important. The current characterization is that the low modes are learned very quickly during this period, however many other things are also happening. For one, the kernel could be drastically realigning its eigenstructure (as in e.g. Atanasov Bordelon Pehlevan https://arxiv.org/abs/2111.00034). Relatedly, it would be interesting to see these empirical results for the NN as the feature learning parameter (as in $\\alpha$ in Chizat and Bach https://arxiv.org/abs/1812.07956) is varied. \n\nIt seems strange that in the high noise regime the formalism tells the perceptron learns in \"zero time\" when really its unable to learn at all. Am I understanding this correctly? \n\nTo the best of my understanding, the only setting in which the W2 distance enters practically is when the marginals are delta functions. So it only is realized as the 2-norm in weight space. Is there any use to the optimal transport formalism beyond this?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2770/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2770/Reviewer_M1Mw",
                        "ICLR.cc/2024/Conference/Submission2770/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2770/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698718381473,
            "cdate": 1698718381473,
            "tmdate": 1700583835486,
            "mdate": 1700583835486,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YpMMRGjkto",
                "forum": "wKB3XcQHcX",
                "replyto": "alLqlZ0wPO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2770/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2770/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We thank the reviewer for this concise summary and for the insightful and helpful comments we received from their review."
                    },
                    "comment": {
                        "value": "Weakness:  \n\n1. We completely agree with you. This work however is more theoretical in nature and shows the potential of the speed bound as an object of study. We plan to investigate numerically the speed limit in various settings, performing large-scale experiments in follow-up works. To pick up this point, we have amended the outlook section of the discussion in this direction. \n\n2. Thank you for your question, this is an interesting limit. We added an analysis of this case in the linear perceptron in Appendix C of the paper. In this case, the initial loss is just the norm of the target. Calculation of the final and initial free energies shows that the norm of the target is canceled by a similar term in the free energy, and the term with the significant contribution to the entropy production is the bias of the linear regression estimator. \n\n3. This is an important point. We agree that our paper in its current form focuses on theoretical insights, provided by a direct computation of the speed bound. The analysis indicates that the optimality is tightly connected to the spectrum of the NTK and the projection of the residuals. One important message is that when the residuals are uniform, the learning process is optimal. The assumed power law distributions are, moreover, observed in various applied settings (see, e.g., Moloney et al. 2022).\nAn additional practical use of the speed limit is as an additional quantity to calculate, which gives an indication of whether the optimization and the training process are efficient.  In fact, for gradient descent with infinitesimal step size ($\\beta \\to \\infty$), we can calculate the speed limit numerically very efficiently since it is the Euclidean distance between the initial and final weights divided by the difference in the loss function, i.e. $\\frac{\\|\\theta_0-\\theta_T\\|^2}{\\mathcal{L}(\\theta_0)- \\mathcal{L}(\\theta_T)}$. For small noise, the denominator can be computed from the slope and Hessian of the loss along the training trajectory. For a general noise level, you are right that this would be harder. However, there is recent research suggesting ways of calculating the W2 distance efficiently. We added a discussion about that in the text.\nAnother practical insight is that the inefficiency of training is mostly\ntied to the initial period of the training process. Concretely, the\nlink of inefficiency to the shape of the power law of residuals at\ninitialization opens the door to design specific weight initialization\nthat bring this exponent into the optimal regime."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2770/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700166098344,
                "cdate": 1700166098344,
                "tmdate": 1700166098344,
                "mdate": 1700166098344,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GSvaYIzL8P",
                "forum": "wKB3XcQHcX",
                "replyto": "alLqlZ0wPO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2770/Reviewer_M1Mw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2770/Reviewer_M1Mw"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors' Rebuttal"
                    },
                    "comment": {
                        "value": "I thank the authors for their thoughtful rebuttal and clarifications on my questions about the paper. I hope that the authors will add these clarifications and additional discussion about connections to more realistic settings. I think that the paper is quite thorough and novel and I recommend acceptance. I've raised my score appropriately."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2770/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700583780806,
                "cdate": 1700583780806,
                "tmdate": 1700583780806,
                "mdate": 1700583780806,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KTy4Mxfz4N",
            "forum": "wKB3XcQHcX",
            "replyto": "wKB3XcQHcX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2770/Reviewer_8rXj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2770/Reviewer_8rXj"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a study of the \"time\" it takes for a neural network (NN) to travel from its initialization distribution to its final distribution (after training). The study is based on of the transport of the distribution of the parameters and the related evolution of the entropy of the system. To use this theoretical framework, it is necessary to do some assumptions: continuous-time training, full-batch optimization, simplified models (linear regression, Neural Tangent Kernel (NTK) setting), etc.\n\nThis theoretical study comes with a series of experiments, with a setting as close as possible as the theoretical assumptions (small learning rates, full-batch gradient descent). The experimental results are not entirely consistent with the theoretical predictions. The authors claim that the \"training time\" they have computed theoretically is close to the actual training time of NNs in the experiments."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "## Originality\n\nTo my knowledge, this work is original. But I am not a specialist of statistical physics applied to NNs.\n\n## Clarity\n\nThe authors made the effort to make their paper understandable to the reader who would not be a specialist in statistical physics applied to NNs. Overall, the paper is easy to read.\n\n## Quality\n\nThe experimental section, despite being narrow (only one setting has been tested), provides enough results to evaluate the significance and the limitation of the theoretical section."
                },
                "weaknesses": {
                    "value": "## Significance\n\n### Narrowness of the theoretical setting\n\nOnly two setups have been studied: linear regression and NNs in the NTK regime. Moreover, the continuous-time SGD does not model faithfully the discrete SGD when training practical NNs on realistic data.\n\nMoreover, the authors does not discuss how $T_{SL}$ (lower bound on the training time) obtained in the NTK regime compare to a hypothetical $T_{SL}$ obtained in finite-width NNs. Would it be larger of smaller? ...\n\n### Motivation\n\nGiven the theoretical framework, I do not fully understand how this work is related to the usual challenges in deep learning. Can we use this work to improve optimization? to obtain theoretical guarantees? ..."
                },
                "questions": {
                    "value": "Main questions:\n * motivation: can we use this work to evaluate the quality of an optimizer?\n * stronger results: how does the $T_{SL}$ obtained in the NTK limit relate to some \"$T_{SL}$\" in the finite width setting?\n * experimental setup: the authors claim that a learning rate of $10^{-5}$ is small and apply the NTK setting to Myrtle-5; how to justify these choices? Is $10^{-5}$ really small enough? is Myrtle-5 wide enough to consider that we are in the NTK regime?\n\nOther questions:\n * Eqn (10) is difficult to interpret: in the proof, the effective learning rate is $\\eta/n$; how such a proof can be interpreted in the limit $n \\rightarrow \\infty$?\n * I may have misunderstood one point: Figure 1.b seems to indicate that the training time is about $10$-$30$ times larger than $T_{SL}$. We are far from the \"$O(1)$\" factor written in the claims... while it is true that the ratio of the trajectory lengths (Fig. 1.e) is of order 1. How to solve this contradiction?\n * it is clear to me that the result written in Eqn. (10) depends on the distribution of the data. To obtain such a result, the data are assumed to be Gaussian. It is then not surprising that Fig. 1.d contradicts Eqn. (10), since CIFAR-10 images are far from being Gaussian vectors."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2770/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699275773859,
            "cdate": 1699275773859,
            "tmdate": 1699636219734,
            "mdate": 1699636219734,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JIysRZn3ht",
                "forum": "wKB3XcQHcX",
                "replyto": "KTy4Mxfz4N",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2770/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2770/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We thank the reviewer for this concise summary and for the insightful and helpful comments we received from their review. These have considerably helped us to clarify the message."
                    },
                    "comment": {
                        "value": "Reply to Weakness:\n \nSignificance reply by points: \n\nPoint 1: \n\nThis is an important insight, and we are grateful to the reviewer for\npointing it out. We agree that usual training algorithms employ\ndiscrete updates for training, and we share the intuition by\nthe reviewer that this may cause important differences. In fact,\nin the literature on stochastic thermodynamics, similar speed limits\nalso exist for discrete (Markov) systems; we are planning to address\nthis in future work. We will discuss this outlook in the revised manuscript.\n\nYet, we found that certain features seem to be more universal\nand to carry over between discrete and continuous dynamics; also they\nseem to generalize from the NTK regime (of infinite-sized networks)\nto fully trained finite-sized networks:\nThe presented numerical experiments on Myrtle-5 networks in fact employ\na usual discrete training scheme. Also, we agree that training here is\nnot in the NTK regime proper (See also App. Sec. D.). Still, the initial transient of entropy\nproduction, as explained by the NTK analysis, exists in a qualitatively\nsimilar manner in the fully trained network. Moreover, the influence of\nthe spectrum of the residuals, as predicted by the NTK analysis, correctly\npredicts the transition from the inefficient to the efficient training\nregime."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2770/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700167719317,
                "cdate": 1700167719317,
                "tmdate": 1700167719317,
                "mdate": 1700167719317,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]