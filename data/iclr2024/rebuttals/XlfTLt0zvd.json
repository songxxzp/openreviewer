[
    {
        "title": "An Efficient Multi-Task Transformer for 3D Face Alignment"
    },
    {
        "review": {
            "id": "bKJBB6BxDV",
            "forum": "XlfTLt0zvd",
            "replyto": "XlfTLt0zvd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5361/Reviewer_PGZe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5361/Reviewer_PGZe"
            ],
            "content": {
                "summary": {
                    "value": "Authors proposed the multi-task framework based on the transformer architecture to efficiently capture the high-resolution information in facial landmark detection task. Query-aware memory module is newly introduced and the multi-layer additive residual regression module and Euler angles loss are proposed. Experiments on two public benchmarks show the effectiveness of the proposed method showing the SOTA results."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "QAMem module looks sound and it is well presented in the Figure 2.\nMARR and Euler angles loss also look effective to tackle the targetted problem.\nEnglish and presentation are sufficiently good to understand the work."
                },
                "weaknesses": {
                    "value": "Less qualitative results: only 1 dataset is used for qualitative results. More is required.\nEven though the authors insist that the proposed method is efficient; while there is no report for the time complexity in their results.\nIn ablation study, when comparing Euler+QA and MARR+QA, the accuracy improvement is quite limited. It is unclear the accuracy improvement was due to the components, or not.\nExplanations for some equations are rather blurry (for eqs 2 and 3)."
                },
                "questions": {
                    "value": "There is less explanation for how to proceed the equations from 2 to 3. \nWhy in ablation study, the three combination only can improve the final accuracy, even though partial combination is not that effective?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5361/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698742188161,
            "cdate": 1698742188161,
            "tmdate": 1699636540744,
            "mdate": 1699636540744,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "saja8L2f6F",
                "forum": "XlfTLt0zvd",
                "replyto": "bKJBB6BxDV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5361/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5361/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer PGZe"
                    },
                    "comment": {
                        "value": "## [Question 1]\nLess qualitative results: only 1 dataset is used for qualitative results. More is required. \n## [Answer] \nThank you for your comment. We have added qualitative results on AFLW2000-3D dataset to visually display the facial landmark detection results predicted by SynergyNet, DAD-3DNet, and the proposed Trans3DHead. As shown in Figure 12 in the appendix, our Trans3DHead performs better in the mouth, face contour regions, and atypical head poses. \n\n## [Question 2]\nEven though the authors insist that the proposed method is efficient; while there is no report for the time complexity in their results. \n## [Answer] \nThank you for the comment. Please refer to the Common Questions and Responses 2. \n\n\n## [Question 3]\nIn ablation study, when comparing Euler+QA and MARR+QA, the accuracy improvement is quite limited. It is unclear the accuracy improvement was due to the components, or not. Why in ablation study, the three combination only can improve the final accuracy, even though partial combination is not that effective?\n## [Answer] \nThank you for your comment. Since each component is proposed to address a specific problem, the accuracy improvement is limited when each component is used independently. However, when considering the comprehensive problems, the combination of all the components will achieve better results. Specifically, the Euler angle loss is only proposed for head pose estimation, so comparing Euler+QA to QA, it only improves the pose error and Z5 accuracy of the entire 3D head, but it does not improve the landmark detection and chamfer distance for face shape, as 3D head is quite related to head pose, but face shape is relatively not. As for MARR, as commented by Reviewer QjYA, the average face may have some limitation in handling large head pose variations, therefore, its effectiveness is more observed when the Euler angle loss is applied to improve the performance under large pose variations, that is, from Euler+QA to Trans3DHead (Euler+QA+MARR). We will make this point clearer in the paper.\n\n## [Question 4]\nExplanations for some equations are rather blurry (for eqs 2 and 3). There is less explanation for how to proceed the equations from 2 to 3. \n## [Answer] \nThank you for pointing out this. We have updated the Eq. (2) and Eq. (3) to make it easier to understand. The Eq. (2) is the original calculation form of the QAMem module, which represents that each query corresponds to a separate memory rather than the shared memory. In order to reduce computations in practice, according to the associative law of multiplication, the operation order of multiplication can be changed to the form of Eq. (3), with the advantage that A $\\times$ M can be precomputed only once, resulting in only one matrix multiplication for each query i, in contrast to two matrix multiplications for each query i in Eq. (2). This significantly reduces redundant computations and memories.\n\nSpecifically, with Eq. (2) the complexity in terms of multiplications is O(NSd + NSdd)), while that of Eq. (3) is O(NSd + Ndd). Therefore, Eq. (3) reduces the computation of O(Ndd(S-1)), which is significant especially when N=68 and S=8 $\\times$ 8 in the Trans3DHead model."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5361/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700690778739,
                "cdate": 1700690778739,
                "tmdate": 1700729259075,
                "mdate": 1700729259075,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Y5Ri9X41xq",
            "forum": "XlfTLt0zvd",
            "replyto": "XlfTLt0zvd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5361/Reviewer_zzMV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5361/Reviewer_zzMV"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a multi-task 3D face alignment framework based on a transformer. The objective is to overcome three main drawbacks of existing methods: (i) first, the 2D facial landmark detection task and the 3DMM parameters prediction task are parallelized in the form of two transformer branches. 3DMM parameters are regressed through Transformers, where the cross-attention mechanism is used to enhance the information communication among task-oriented queries and extracted feature maps in the designed decoder; (ii) A lightweight module named query-aware memory (QAMem) is proposed that makes up the accuracy loss from lower feature map resolutions. To enhance the robustness of the predicted landmarks, the average vertices coordinates of the training set are calculated, then a multi-layer additive residual regression (MARR) module is designed in the decoder to guide the detection under the reference of an average face model. (iii) A multi-information loss function is used to optimize the network."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The main contributions are:\n- A Transformer-based multi-task framework is proposed for 3D face alignment, using a multi-task structure. 3DMM parameters are regressed through Transformers, where the cross-attention mechanism achieves the information communication among different elements.\n- A Euler Angles Loss in introduced to the multi-information loss function for network optimization, which enhances the predictive ability in the case of atypical head poses."
                },
                "weaknesses": {
                    "value": "- The title of the paper is not appropriate in my opinion. The title emphasizes a face alignment contribution, while the content focuses more on face landmarks detection. \n- Table 2 indicates results that are comparable to the state-of-the-art but for some cases do not improve on it. \n- Parameters of a 3DMM are regressed in this work. However, it is not clear how much the choice of the 3DMM impacts on the results. Did the authors try with different 3DMMs? \n- In the ablation study it is not clear the impact of the 3DMM on the results. \n- An analysis of the computational cost of the method in comparison with other solutions is missing. For landmarks detection the capacity of the approach to work in real time is important. Authors should clarify this point."
                },
                "questions": {
                    "value": "Q1: The contribution of the used 3DMM on hte final results is not clear. Did the authors try with different 3DMMs? Can they show results using different 3DMMs?\nQ2: In the ablation study it is not clear the impact of the 3DMM on the results. \nQ3: Authors should discuss and illustrate the computational cost of the method in comparison with other solutions is missing."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5361/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698754934664,
            "cdate": 1698754934664,
            "tmdate": 1699636540588,
            "mdate": 1699636540588,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AhlHB0It2F",
                "forum": "XlfTLt0zvd",
                "replyto": "Y5Ri9X41xq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5361/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5361/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## [Question 1]\nThe title of the paper is not appropriate in my opinion. The title emphasizes a face alignment contribution, while the content focuses more on face landmarks detection.\n## [Answer]\nOur main task is 3D alignment, while landmark detection is only an auxiliary task. The major goal is to predict the 3DMM parameters to reconstruct 3D head shape. As shown in Figure 1, our model mainly consists of a 3DMM parameter regression branch and an auxiliary facial landmark detection branch. The 3D alignment relies on 3DMM parameters regression branch which can regress a set of 3DMM parameters and reconstruct the 3D head shape by a differentiable FLAME decoder. In the paper, Figure 1 shows the overall 3D alignment pipeline, Sec. 3.1 introduces the proposed 3D alignment framework, and Sec. 3.4 describes the overall losses for both landmark detection, as well as 3D shape reconstruction and reprojection. Besides, the Euler angle loss is proposed in Sec. 3.4.1 for improving the 3D alignment via 3D pose estimation. Thank you for your comment. We will further improve the presentation of Sec. 3.1 for the whole 3D alignment framework.\n\n## [Question 2]\nTable 2 indicates results that are comparable to the state-of-the-art but for some cases do not improve on it.\n## [Answer]\nThank you for the comment. Please refer to the Common Questions and Responses 1 for the comparison to SynergyNet.\n\n## [Question 3]\nParameters of a 3DMM are regressed in this work. However, it is not clear how much the choice of the 3DMM impacts on the results. Did the authors try with different 3DMMs? In the ablation study it is not clear the impact of the 3DMM on the results. The contribution of the used 3DMM on hte final results is not clear. Did the authors try with different 3DMMs? Can they show results using different 3DMMs? In the ablation study it is not clear the impact of the 3DMM on the results. \n## [Answer] \nThank you for your valuable suggestion. The 3DMM parameters used in DAD-3DNet and the proposed Trans3DHead are adapted to FLAME, which are extensions of the standard 3DMM parameters. The number of the extended 3DMM parameters used in the final Trans3DHead is 413, including 300 shape parameters, 100 expression parameters, 3 jaw parameters, 6 rotation parameters, 3 translation parameters, and 1 scale parameter to control FLAME, which allows to use the first few parameters of the 300 shape parameters, 100 expression parameters, and 3 jaw parameters to express the shape and expression. \n\nWe have conducted experiments with two additional 3DMM parameter settings. The first one is with the same number of 3DMM parameters as in SynergyNet (40 shape parameters, 10 expression parameters without jaw parameter), while the second one is used in RingNet (100 shape parameters, 50 expression parameters without jaw parameter). Keeping the original setting of 6 rotation parameters, 3 translation parameters, and 1 scale parameter in FLAME, we use two parameter settings of 60 parameters and 160 parameters to train our Trans3DHead and DAD-3DNet on the DAD-3DHeads dataset, respectively. \n\nAs shown in Table 8 in the appendix, regressing more parameters is helpful for better reconstructing 3D head shape for both DAD-3DNet and the proposed Trans3DHead. Besides, the proposed Trans3DHead is superior to DAD-3DNet in all three parameter settings. When only regressing 60 parameters, our model shows more significant advantages over DAD-3DNet, which also indicates that the cross-attention mechanism in Trans3DHead is effective to achieve the information communication among different elements of the 3DMM parameters.\n\n## [Question 4]\nAn analysis of the computational cost of the method in comparison with other solutions is missing. For landmarks detection the capacity of the approach to work in real time is important. Authors should clarify this point. Authors should discuss and illustrate the computational cost of the method in comparison with other solutions is missing.\n## [Answer] \nThank you for the comment. Please refer to the Common Questions and Responses 2."
                    },
                    "title": {
                        "value": "Responses to Reviewer zzMV"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5361/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700689362715,
                "cdate": 1700689362715,
                "tmdate": 1700690660640,
                "mdate": 1700690660640,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "slTtXCnPvL",
            "forum": "XlfTLt0zvd",
            "replyto": "XlfTLt0zvd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5361/Reviewer_QjYA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5361/Reviewer_QjYA"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new method for 3D face landmarks detection. The contributions are:\n- The paper also jointly estimate 2D face landmarks. \n- The paper employs a DETR like approach and each estimated parameter is associated with a query embedding. This can help information communication in joint estimation of all the parameters. \n- The paper also proposes a module to improve the model efficiency using low resolution features. \n- The proposed method predicts residuals from the average face instead of directly predicting the original face. \n- And Euler Angles loss is proposed to improve the performance on atypical head poses. \n\nExperiments show the competitiveness of proposed method compared with baselines."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "+ The presentation of the paper is good.\n+ The use of query embeddings and cross attention can help information communication in joint estimation of all the parameters. And this is interesting and novel.\n+ Visual demos show the effectiveness of the proposed method in 3D pose and landmarks estimation."
                },
                "weaknesses": {
                    "value": "- For the qualitative comparisons, only DAD-3DNet is compared with. From table 5, DAD-3DNet is already worse than the proposed method. While SynergyNet, which performs better than the proposed method, is not compared with in the visual demos.\n- section 3.2, the description about QA memory is not super clear. Does the proposed method use more features maps to trade for a lower resolution? What is the benefit in doing this?\n- Due to large variation of head poses and face shape, it might not be a good idea to compute the average face and predict the residuals.\n- The paper proposes a Euler Angles loss, but from figure 4, it requires an estimation of the Euler angles from predicted 3DMM parameters. Therefore another module needs to be introduced do the estimation. This module introduces additional errors and might not benefit the supervision for 3DMM parameters.\n- From table 3, the QA module seems not to improve the accuracy compared with baseline.\n- From table 5, the proposed method is not quantitatively better than SynergyNet 3DV 2021."
                },
                "questions": {
                    "value": "- The paper first mentions \"memory\" in the second paragraph in section 3.1. But there is no context and explanation about it. What does memory mean? Which part does it correspond to in the network structure?\n- Can the authors give more explanation and proof about the QA module and its effectiveness? Does the module use more feature maps to trade for lower resolution?\n- From section 3.3, the paper uses multiple decoders. What are the decoders like? Why are multiple decoders used? Do they make it computationally less efficient? There are no explanation about the usage of multiple decoders. Maybe I miss something.\n- section 3.4.1, how are Euler angles estimated from 3DMM parameters? Is a neural network used here?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5361/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698818777277,
            "cdate": 1698818777277,
            "tmdate": 1699636540501,
            "mdate": 1699636540501,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "yXxi4q45XP",
                "forum": "XlfTLt0zvd",
                "replyto": "slTtXCnPvL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5361/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5361/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer QjYA"
                    },
                    "comment": {
                        "value": "## [Question 1]\nFor the qualitative comparisons, only DAD-3DNet is compared with. From table 5, DAD-3DNet is already worse than the proposed method. While SynergyNet, which performs better than the proposed method, is not compared with in the visual demos.\n## [Answer]\nThank you for the comment. Please refer to the Common Questions and Responses 1 for the comparison to SynergyNet. \n\nIn the 3D head alignment task, the DAD-3DNet is the most relevant work and the closed competitor to the proposed Trans3DHead, so the most important experimental comparisons of this work are shown in Table 1. Thank you for the encouraging statement that \u201cDAD-3DNet is already worse than the proposed method\u201d. \n\nAnyway, including SynergyNet for visual comparison is indeed a good idea. Thank you for your suggestion. Besides the new Figure 10, to further illustrate the difference between the SynergyNet and the proposed Trans3DHead, we have additionally visualized some examples of head pose estimation predicted by the SynergyNet and the proposed Trans3DHead on the AFLW2000-3D dataset, as shown in Figure 11 in the appendix. It can be observed that the SynergyNet performs slightly better in predicting pitch and roll, while the proposed model has more advantages in handling side faces.\n\n## [Question 2]\nsection 3.2, the description about QA memory is not super clear. Does the proposed method use more features maps to trade for a lower resolution? What is the benefit in doing this? Can the authors give more explanation and proof about the QA module and its effectiveness? Does the module use more feature maps to trade for lower resolution?\n## [Answer]\nThank you for your comment. Using low-resolution feature maps often leads to a decrease in accuracy. Based on an observation, we find that in Transformers the queries will act differently if the memory is of higher resolutions. Therefore, QAMem is proposed to simulate the working mechanism of high-resolution feature maps in the actual low-resolution feature maps we used to improve the accuracy. In practice, the QAMem layer can be simply implemented as a convolutional layer with 1 $\\times$ 1 kernel, 1 stride, and N groups. Note that we do not use more feature maps to trade for a lower resolution. In our implementation of QAMem in Eq. (3), the feature map channels are the same $d$ channels, but N groups of 1 $\\times$ 1 convolutions are applied to transform the $d$ channels per query. As a result, QAMem provides discriminative values for different queries with marginal additional computation, and enhances discriminative abilities of the model on using low-resolution feature maps. \n\nNote also that the implementation of applying high-resolution feature maps usually uses additional network for up-sampling, such as the commonly used FPN structure where the parameters, computation, and memory requirement are significantly larger.\n\n## [Question 3]\nDue to large variation of head poses and face shape, it might not be a good idea to compute the average face and predict the residuals.\n## [Answer]\nThe average face provides a general initial topology of the landmark detection with which the predicting task will be easier with small or not too large head poses. When encountering large head poses, the decoders with sufficient training are also able to output larger residual to correct the initial landmarks. Thank you for pointing out this. To address large variation of head poses and face shape better, a better way could be considering multiple average faces, which will be our future study.\n\n## [Question 4]\nThe paper proposes a Euler Angles loss, but from figure 4, it requires an estimation of the Euler angles from predicted 3DMM parameters. Therefore another module needs to be introduced do the estimation. This module introduces additional errors and might not benefit the supervision for 3DMM parameters. section 3.4.1, how are Euler angles estimated from 3DMM parameters? Is a neural network used here?\n## [Answer]\nThe estimation of the Euler angles from the predicted 3DMM parameters is a deterministic matrix calculation, with no additional network or learnable parameters in introducing errors. Specifically, the 3DMM parameters used in DAD-3DNet and the proposed Trans3DHead are adapted to FLAME, which are extensions of the standard 3DMM parameters. The number of the extended 3DMM parameters regressed in the final Trans3DHead is 413, including 403 3DMM shape parameters, 6 rotation parameters, 3 translation parameters, and 1 scale parameter. Then, the Euler angles are estimated by a deterministic matrix calculation from the predicted 6 rotation parameters, because any orientation can be expressed as a composition of rotations. In our implementation, we use SciPy, a scientific computation Python library, through scipy.spatial.transform.Rotation.as_euler()."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5361/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687136538,
                "cdate": 1700687136538,
                "tmdate": 1700723884497,
                "mdate": 1700723884497,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "4od13g86tm",
            "forum": "XlfTLt0zvd",
            "replyto": "XlfTLt0zvd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5361/Reviewer_eTNq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5361/Reviewer_eTNq"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents an efficient multi-task transformer for 3D face alignment, self-attention and corss-attention mechanisims were sused to enhance information communication among different elements of the network. Query aware memory (QAMem) is also designed to remove dependence on high-resolution feature maps. Experiments on two public benchmarks show that the approach can achieve resonable peformance."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The presentation is clear and easy to follow.\nThe experiments seem to be intensive and resonable results were achieved."
                },
                "weaknesses": {
                    "value": "1) The contributions seem to be a combination of deep learning tricks like multi-task structure, QAMem module, MARR and Euler Angles Loss, the improvement of each module seems to be incremental and the combination of these incremental contributions, do not become a significant contribution.\n\n2) The pose estimation results on AFLW2000-3D dataset, shown in Table 2, don't support that the proposed approach achieve better performance than SOTA. Th MAE, pitch and roll of the proposed approach are not as good as SynergyNet published in 2021.\n\n3) The ablation study in Table 3 don't support the effeictiveness of proposed modules as well. For example, the performance of Cham Dist for Trans3DHead is not as good as the baseline.\n\nI have read the response from authors and the comments of other reviewers. Most of the reviews also questioned the experiments and the results, which does not seem to be convincingly better than sota approaches, so I keep my orginal ratings."
                },
                "questions": {
                    "value": "Further discussion of the novelty of the work need to be elaborated, I don't thnk the contribution listed in the paper, make a good work for top conference like ICLR."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5361/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5361/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5361/Reviewer_eTNq"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5361/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698850454941,
            "cdate": 1698850454941,
            "tmdate": 1700881961109,
            "mdate": 1700881961109,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "V36mCsb2o6",
                "forum": "XlfTLt0zvd",
                "replyto": "4od13g86tm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5361/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5361/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer eTNq"
                    },
                    "comment": {
                        "value": "## [Question 1]\nThe contributions seem to be a combination of deep learning tricks like multi-task structure, QAMem module, MARR and Euler Angles Loss, the improvement of each module seems to be incremental and the combination of these incremental contributions, do not become a significant contribution.\n## [Answer]\nThank you for your review but we do not agree. This work is well motivated to solve respective problems instead of using deep learning tricks to improve the performance. First, this is the first work in regressing 3DMM parameters through Transformers, which can help information communication among 3DMM parameters via attention mechanism in joint estimation. With this architecture, the proposed multi-task framework for 3D head alignment simultaneously predicts 3D head shape and 2D landmarks. This not only facilitates applications by directly providing multiple available outputs, but also helps mutual improvements between the two branches. Our experimental findings show that with this design the proposed method is more robust with reducing 3DMM parameters (see A.1.6 and Table 8 in appendix), thanks to the unified Transformer architecture for two branched tasks.\n\nSecond, the proposed lightweight QAMem module is an interesting and valuable idea (supported by Reviewers QjYA and PGZe) for dense prediction tasks requiring high-resolution feature maps. It ingeniously uses separate memories with low-resolution feature maps and designs an efficient implementation to get rid of the high-resolution feature map requirement. The QAMem design enables improved accuracy with minimal additional computational burden. \n\nThese are the two major innovations in this paper. We do not agree that they can be simply categorized into deep learning tricks or incremental combinations.\n\n## [Question 2]\nThe pose estimation results on AFLW2000-3D dataset, shown in Table 2, don't support that the proposed approach achieve better performance than SOTA. Th MAE, pitch and roll of the proposed approach are not as good as SynergyNet published in 2021.\n## [Answer]\nWe may did not make it clear. Thank you for the comment. Please refer to the Common Questions and Responses 1 for the comparison to SynergyNet. \n\n\n## [Question 3]\nThe ablation study in Table 3 don't support the effeictiveness of proposed modules as well. For example, the performance of Cham Dist for Trans3DHead is not as good as the baseline.\n## [Answer]\nThank you for the comment. The measurements and comparisons in Table 3 are comprehensive, including evaluations of not only 3D face shape prediction (Chamfer distance), but also face landmark detection (NME), head pose estimation (pose error), and 3D head shape estimation (Z5). In DAD-3DHeads benchmark, Chamfer distance is used for measuring the 3D shape of human face, and the proposed method achieves quite comparable results with the baseline in terms of Chamfer distance (2.796 vs. 2.791). Except this the proposed method outperforms the baseline in all other metrics. Especially, the proposed model performs better than the baseline with Z5 (0.9585 vs. 0.9578). As Z5 is used for measuring 3D head shape, it is more important than Chamfer distance for 3D face shape only."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5361/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700670847272,
                "cdate": 1700670847272,
                "tmdate": 1700670918322,
                "mdate": 1700670918322,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]