[
    {
        "title": "End-Effector-Elbow: A New Action Space for Robot Learning"
    },
    {
        "review": {
            "id": "vRkhF1Yfxr",
            "forum": "sb0ojNl7F6",
            "replyto": "sb0ojNl7F6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6452/Reviewer_Sd65"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6452/Reviewer_Sd65"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents E3, a new action space for robot arm manipulation. Essentially, the proposed method presents an action space containing both end-effector pose and control over one additional joint in the arm. Compared to previous 2 established actions space, i.e. end-effector pose or joint-space, E3 brings the advantages of both, and show performance gain on a set of experiments."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The idea is straightforward, reasonable and easy to follow\n- the paper presentation is clear\n- empirical results showing value of the proposed method"
                },
                "weaknesses": {
                    "value": "- My biggest concern is, the proposed method is more like a small engineering trick, rather than a rigorous scientific approach. It is specific to 7-DoF arm, which presents opportunities for such method due to the one additional redundant joint. The method won't work for 6-DoF arms, which although doesn't come with redundancy, but will also present multiple disconnected IK solutions given one end-effector pose, and only a subset of them would satisfy the task constraints.It also won't work for arms with DoFs greater than 7: which joint should we choose then? Or do we need to control 2 joints?\n- Some explanations are not clear: \n   - It says `elbow`, but in the method it says empirically it uses the base joint\n   - i don't understand why choosing any joint in between would make problems for IK solver: it's just removing 1 DoF and the solver should work just fine. There's also no experiments to empirically validate which joint to choose"
                },
                "questions": {
                    "value": "See above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6452/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6452/Reviewer_Sd65",
                        "ICLR.cc/2024/Conference/Submission6452/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6452/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698778560528,
            "cdate": 1698778560528,
            "tmdate": 1700690281272,
            "mdate": 1700690281272,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vc9U6ro2lN",
                "forum": "sb0ojNl7F6",
                "replyto": "vRkhF1Yfxr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6452/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6452/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for their feedback. We provide an answer to their questions below.\n\n***\n\n**The work can be seen as an engineering trick**: Contrary to viewing the 7 DoF as an inherent opportunity for E3, our new action space is a simple strategic response to this overactuation problem, commonly encountered in robot arms with greater than 6 DoF. The E3 action space applies classical robotics control techniques to Robot Learning (see \"Redundant manipulators control\" part of the \"Related Work\" section of the original paper), aiming to replace Joint and EE action spaces currently used in the robot learning literature.\n\nWhile the E3 action space offers a straightforward solution, its simplicity is its strength: it can be seamlessly applied to many existing and future robot learning works. Additionally, it is clear from our findings that this simple change in action space for robot learning dramatically improves performance on tasks where whole-arm control is imperative. As we confront increasingly complex challenges, such as navigating real-world scenes involving cupboards and other intricate, hard-to-navigate areas, it becomes evident that conventional action spaces fall short in providing the necessary control over the arm's configuration whilst maintaining data-efficient learning.\n\nPrevious contributions, which also mostly focus on re-engineering the action space, e.g. by adopting primitives [1] or next-best pose [2], has had a significant impact on the field, leading to higher performance, through only minor modifications of the learning algorithm.\n\n\n\n**Generalization to $\\neq$ 7 DoF arms**: In the case of a 6 DoF arm, such as the UR robot family, where the \"elbow\" has two solutions for end-effector (EE) poses (elbow up or elbow down), E3J method would utilize pose information along with a binary flag indicating elbow orientation. This contrasts with the conventional approach in robot control for UR robots, where the elbow joint is typically constrained to either the up or down position.\n\nAdditionally, 6 DoF arms face limitations due to their morphology. Unlike overactuated arms, they may struggle with tasks demanding flexibility. For instance, consider our real-world setup with a cabinet except replacing the Franka Emika Panda arm with a UR5. The UR robot's vertical elbow position would hinder solving the task from this position where the elbow needs to be rotated to the horizontal place in order to reach inside the cupboard. Visual example in simulation available at https://imgur.com/a/n4L5UZH : while the cup position would be reachable by the UR5, the presence of the obstacle and the stiffness of the UR5's elbow do prevent the robot from reaching inside the cabinet.\n\n\n**Why the method talks about the elbow?** in most 7 DoF arms, the redundancy of the robot allows control over one more dimension, which can be identified in the position of the elbow. As we mention in the Introduction, E3A allows direct control of the elbow by controlling its angle, while E3J allows indirect control of the elbow by constraining one of the joints to fix the elbow position. Thus, both the methods presented allow control over the elbow redundancy (see Figures 2 and 3 from the original submission for further illustration).\n\n**Experiments to validate the choice of the joint**: in Section 4.4, we motivated our choice for mainly considering E3J-base and E3J-wrist in the first iteration of the manuscript. In order to further validate our choice, we have now completed the ablation study, where we attempt to constrain other joints of the robot for E3J (see Section A4 and Figure 13 in Appendix). The results show that our intuitions generally proved correct, but there are tasks where constraining other joints than the base or the wrist improves sample efficiency. We also believe E3A may constitute a more general strategy than E3J, but in practice we found that the agent struggles to directly control the elbow angle more than indirectly controlling the elbow through one constrained joint. As finding out what's the best action space for robot learning, in terms of full-body control and efficiency, is one of the main goals of this work, we have chosen E3J as the idea that best fits this definition according to empirical evidence.\n\n***\n\nWe hope our revision answers the reviewers' doubts and we look forward to any further suggestions to improve our work.\n\n\n[1] Accelerating Robotic Reinforcement Learning via Parameterized Action Primitives, *Dalal et al*\n\n[2] Q-attention: Enabling Efficient Learning for Vision-based Robotic Manipulation *James et al*"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699940618190,
                "cdate": 1699940618190,
                "tmdate": 1699941548898,
                "mdate": 1699941548898,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NHgdI43Y9c",
                "forum": "sb0ojNl7F6",
                "replyto": "vRkhF1Yfxr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6452/Reviewer_Sd65"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6452/Reviewer_Sd65"
                ],
                "content": {
                    "title": {
                        "value": "Reviewer response"
                    },
                    "comment": {
                        "value": "My concerns have been partially addressed, but this work's technical novelty is till not fully convincing to me. I will raise my score to a positive one."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700690269006,
                "cdate": 1700690269006,
                "tmdate": 1700690269006,
                "mdate": 1700690269006,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "m1YK5XH1Bo",
                "forum": "sb0ojNl7F6",
                "replyto": "vRkhF1Yfxr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6452/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6452/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear reviewer,\n\nwe would like to thank you for answering to our rebuttal.\n\nWe are glad to have addressed some of your concerns. In addition, we would like to report that the following experimental studies have been added to the revised manuscript, to corroborate the general applicability of our method:\n*  **evaluation on different robotic platforms**: using the Kuka iiwa 7 and xArm. In this setup, we showed that E3J can be applied in other platforms than the Panda\n * **evaluation on a robot with more than 7 joints**: given the absence of common 8 DOFs, we designed a custom Panda, with additional joints, where the agent can control 8 joints. In this setup, we showed that E3J can be applied to robotic arms with more than 1 redundant joint to control.\n\nThe results can be found in the Appendix of the revised manuscript. \n\nWe hope the additional evaluations address the concerns that have been raised about evaluating only on a single 7 DOFs arm and extending the work to arms with higher DoFs."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700694504218,
                "cdate": 1700694504218,
                "tmdate": 1700694890926,
                "mdate": 1700694890926,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7agpEKvetM",
            "forum": "sb0ojNl7F6",
            "replyto": "sb0ojNl7F6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6452/Reviewer_H84E"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6452/Reviewer_H84E"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new action space for robot learning, dubbed End-Effector-Elbow. The basic idea for this new action space is to avoid the joint space redundancies that end-effector based control incurs (when N (degress-of-freedom) of a robot > 6). \n\nTo avoid these redundancies the paper extends the robot\u2019s action space to 6 (EE) + (N - 6), where the latter part is controlling the redundant part of the joint space. In many robots (e.g. Franka-Pandas) these redundant dofs arise in the elbow of the robot and probably thus the name. The paper shows that their proposed action space works better in some RLBench tasks (although 4 of the tasks seem to be new tasks) and in some small-scale real-world experiments."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The overall motivation of designing an action space that enables fast learning while not being adversely affected by the null-space is an important problem statement. The overall paper is well written and seems to present an interesting solution to this problem. The experiments (although limited) do seem to suggest that the approach works."
                },
                "weaknesses": {
                    "value": "I think the overall approach is highly engineered for particular scenarios and robots and is not general. For instance, in the E3J method (the main method), the paper proposes to constraint the base joint but that is an arbitrary choice. Certain parts of the task may find it beneficial to constraint the wrist joint. Further, there can be tasks, which use configurations where constraining the middle joint is useful. For instance, consider scenario where the franka arm has been rotated such that it lies flat and thus the middle joint acts as an elbow. Clearly the proposed approach is infeasible in these scenarios.\n\n**Relation to existing work:** To some extent the E3J idea can be viewed from the lens of a hierarchical policy (where first a constrained joint is learned and then the EE-action). Similar idea of hierarchical control and learning in hierarchical action spaces especially with respect to null-spaces has been considered in prior work (Sharma et al.). Unfortunately, the paper is not cited (or discussed). \n\nInfact, the idea of hierarchical composition in Sharma etal is more general since it composes arbitrary number controllers in null-spaces. This automatically leads to the E3J approach where first a joint is selected and then the IK is used under the constraint of this joint to reach the desired agent (thus automatically acting in the null-space). One difference, between Sharma et al. and the current work is that the former only considers task-space constraints and use task-space impedance control to control the robot. While the current work uses a joint-constraint and task-constraint/goal and use IK for control. However, there are prior works (as referenced in Sharma eta al), which do controller composition directly in the joint space. \n\nInfact, it may actually be useful to combine this paper with Sharma etal. and consider more general hierarchical policies.  Finally, there is other related works which focus on learning constraints from demonstrations that should also be potentially cited.\n\nSharma et al. *Learning to Compose Hierarchical Object-Centric Controllers for Robotic Manipulation*\n\nLin et al. *Learning Null Space Projections*\n\nHoward et al. *A novel method for learning policies from variable constraint data*\n\n**Generality of the approach:** Can you talk about the challenges in using this approach on very differently settings. For instance, consider the UR arms and if the task only requires one degree of freedom for successful execution. The presented approach wouldn\u2019t consider this scenario but wouldn\u2019t the benefits of a constrained action space for learning be useful even in this setting? \n\nIt would also be useful to show images/videos of simulation tasks which are being considered as full-body tasks.\n\n**Use of IK:** As is briefly noted in the paper, can the authors clarify if they indeed used constrained IK (with the joint constraint) to solve for the end-effector target pose? Were there any issues or challenges related with solving this optimization problem. For instance, what if the IK failed because the joint constraint makes it hard for the robot to reach the desired EE pose. I would imagine such scenarios to arise, but the paper is very light on such implementation details. \n\nAnother issue with an IK based approach is that it can be expensive to solve at every RL step especially when we perform delta end-effector actions. In such settings most works use the jacobian based controller (osc), how would the proposed approach work with such a choice?"
                },
                "questions": {
                    "value": "Please see above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6452/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698813026188,
            "cdate": 1698813026188,
            "tmdate": 1699636720853,
            "mdate": 1699636720853,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pspIEHyXk2",
                "forum": "sb0ojNl7F6",
                "replyto": "7agpEKvetM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6452/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6452/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for their feedback. We provide an answer to their questions below.\n\n***\n\n**The approach is not general**: as pointed out by the reviewer, the idea of constraining one specific joint for E3J is an arbitrary choice and may not always be the most effective choice. In the original submission, we discussed this in Section 4.4, in the Joint Selection and Practical Implementation Choices paragraphs, where we motivated our choice for mainly considering E3J-base and E3J-wrist. In order to further validate our choice, we have now completed the ablation study, where we attempt to constrain other joints of the robot for E3J (find results in the updated manuscript's Appendix). The results show that our intuitions generally proved correct, but there are tasks where constraining other joints than the base or the wrist improves sample efficiency. We also believe E3A could be a more general strategy than E3J, but in practice we found that the agent struggles to directly control the elbow angle more than indirectly controlling the elbow through one constrained joint. As studying what's the best action space for robot learning, in terms of full-body control and efficiency, is one of the main goals of this work, we have selected E3J as the idea that best fits this definition according to empirical evidence.\n\n\n**Relation to existing work**: we found the work of Sharma et al, which presents a hierarchical framework to combine task-space constraints, to be relevant to our method, and thus we added a discussion about it in the revised manuscript. Overall, as pointed out by the reviewer, the work presents several differences from our approach, in the settings and the goal pursued: (i) it presents a hierarchical method for selecting actions, while our method focuses on learning flat policies; (ii) it applies task-space constraints, while we combine task-space control with joint constraints, (iii) the goal of Sharma et al's work is to present a modular framework that improves sample efficiency and generalization, while we explicitly focus on studying the most convenient action spaces that enable reinforcement learning or imitation learning methods to solve full-body tasks, whilst retaining the benefits of controlling the agent in task space coordinates. We discuss the work in the Related Work section of the revised manuscript (highlighted in green), along with citing the relevant literature about null-space projections and task-space constraints that have been recommended.\n\nFurthermore, the reviewer made a comment that an interesting direction could be to combine our constraints for controlling the elbow (controlling the elbow angle or one of the robot's joints) with a hierarchical controller (as in Sharma et al). This indeed sounds promising for future research, and so we added it in the Conclusion (see the revised manuscript, in green text).\n\n\n**Benefits of applying the approach in tasks that require less DoFs**: in order to compare the learning efficiency of our approach compared to EE on tasks that do not require full-body control, we presented results on 8 RLBench popular tasks, providing aggregated performance in the main paper and detailed results in the Appendix. We did not find any significant difference in performance between EE and E3 in these settings. However, we would like to highlight that 2 out of the 6 full-body tasks are also standard RLBench tasks (`meat off grill` and `take cup out cabinet`), requiring in theory <= 6 DoFs. However, the presence of obstacles in reaching the task's main object ends up favouring our method in terms of learning efficiency, as E3 provides the control necessary for consistent obstacle avoidance.\n\n**Images/videos of full-body tasks**: we added the requested visualizations, with a Figure in the Appendix, and with videos on the [project website](https://doubleblind-repos.github.io/).\n\n[continues]"
                    },
                    "title": {
                        "value": "Rebuttal pt. 1"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699940434599,
                "cdate": 1699940434599,
                "tmdate": 1699943428550,
                "mdate": 1699943428550,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HVs7mN9EAd",
                "forum": "sb0ojNl7F6",
                "replyto": "7agpEKvetM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6452/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6452/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear reviewer,\n\nwe would like to report that the following experimental studies have been added to the revised manuscript:\n* **evaluation on different robotic platforms**: using the Kuka iiwa 7 and xArm. In this setup, we showed that E3J can be applied in other platforms than the Panda\n* **evaluation on a robot with more than 7 joints**: given the absence of common 8 DOFs, we designed a custom Panda, with additional joints, where the agent can control 8 joints. In this setup, we showed that E3J can be applied to robotic arms with more than 1 redundant joint to control. \n\nThe results can be found in the Appendix of the revised manuscript.\n\nWe hope the additional evaluations address some of the concerns that have been raised. In particular, the studies should show the more general applicability of our approach. Furthermore, regarding your concerns about the benefits of using a constrained action space in tasks that do not require full-body control, the new results show that our approach (E3J) tends to learn faster than EE, even in standard RLBench tasks, which only require grasping and moving objects to a target (such as `take lid off saucepan` and `stack wine`)."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700694926403,
                "cdate": 1700694926403,
                "tmdate": 1700694946303,
                "mdate": 1700694946303,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "atMl7JIrRs",
                "forum": "sb0ojNl7F6",
                "replyto": "HVs7mN9EAd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6452/Reviewer_H84E"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6452/Reviewer_H84E"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the response."
                    },
                    "comment": {
                        "value": "Thank you for your comments. I think this is an interesting submission but I think much more work needs to be done to make it a solid contribution. I would encourage the authors to further consider reviewer comments to improve the submission.  \n\n> where we attempt to constrain other joints of the robot for E3J (find results in the updated manuscript's Appendix).\n\nThe issue is not merely about which joint to constraint but more about the same task may require different joints to be constrained during different sub-tasks within the same task e.g. grasping a block and then putting it into a cabinet (side insertion) will require different joints to be constrained. I don\u2019t think the proposed method can handle these scenarios and that is why the lack of generality.   \n\n> we provided additional details in the Appendix\n\nI checked the details in the Appendix and they are really light on implementation. There are many oddities in the text as well. For instance, the paper states \u201csolving the IK for 6 constraints.\u201d, I am not really sure what to make of this statement? There are 6 variables in the objective function or 6 constraints in the optimization\u2019s objective? There are multiple ways to solve for IK, which ones did the authors use? What happens when there exists no IK solution? All of these are important details that should be provided in the paper.  \n\n> Related work\n\nWhat this paper seems to suggest is very similar to the idea of hierarchical control, which in my opinion can go beyond redundant manipulators. I know the latter is discussed in this paper but I would encourage the authors to consider more general hierarchical control works as well."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700716580002,
                "cdate": 1700716580002,
                "tmdate": 1700716580002,
                "mdate": 1700716580002,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "o1id9lQpbL",
                "forum": "sb0ojNl7F6",
                "replyto": "7agpEKvetM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6452/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6452/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer H84E,\n\nwe would like to thank you for participating in the rebuttal and providing additional comments on our work.\n\n**Choice of joint for E3J and generality of the approach**\n\nWe understand the idea of \"constraining one joint\" of the robot may sound less general. However, we believe this is more of a wording issue and how the method is perceived than an actual issue of the generality of the approach.\n\nWhen using E3J, the outputs of the agent are organized as\n(x, y, z, yaw, pitch, roll, joints_controlled_separately), which can also be read as (task space coordinates, joints_controlled_separately). This means the agent provides the same control of the standard EE action space, plus control over additional joints. Clearly, this **extends the control of the agent over a larger set of joint configurations**, as it implies the agent can achieve EE poses, by setting six joints using the IK, and where there would normally be many arm configurations which achieve an EE pose, the additional controlled joints enable the agent to choose one configuration to move to. We suggest looking at Figures 2 and 3 to gain additional visual insights into how our method works.\n\nWe empirically verified that our method provides more extensive control in the ablation introduced with the revision (now under the name `E3J controlling different joints`), where we showed that controlling any of the redundant joints (which are the oddly numbered ones - 1,3,5,7) allows control over the full-body pose of the robot, as shown in the `reach elbow pose` task, which requires precise control over the robot's configuration to be solved. The main difference in performance between controlling different joints arises from how convenient directly controlling one joint is, compared to the others, and we found controlling the base shoulder joint as empirically being the most versatile option. \n\nThe reason why we used the term \"constrain\" was due to the underlying implementation, which works by setting the controlled joint position directly and computing the remaining joints' position using the IK, with one less constraint given that the joint is directly controlled by the agent. To avoid any further confusion, **we have replaced the term \"constraining\" with the term \"controlling\"**, as from the agent's perspective, the joint is directly controlled (see text highlighted in orange in the revised manuscript).\n\n**Implementation details**\n\nWe ensured that all the implementation details are present on the paper as follows:\n\n- \"What are the 6 constraints?\"\n\nWe apologise for the ambiguity about which constraints are being solved by the IK. We further specified that these are the task space coordinates of the end effector as follows: \"solving the IK for 6 constraints that are dictated by the task space coordinates (position and orientation of the end effector)\".\n\n- There are multiple ways to solve for IK, which ones did the authors use?\n\nThis implementation detail is already described in the paper. \n\nFor the simulation experiments, we mentioned:\n\n> \"We rely on the internal IK solver of CoppeliaSim for EE, E3J and E3A, which, for quickly computing the IK in delta action spaces, employs the pseudoinverse Jacobian method.\"\n\nFor the real-world experiments, we mentioned:\n\n> \"We use MoveIt and PickNikRobitics\u2019 [pick ik](https://github.com/PickNikRobotics/pick_ik) with default parameters for solving the IK for EE and E3J. For E3J we first simulate the motion created by the joint that is controlled separately and then compute the IK on the remaining joints.\"\n\nWe also added the following information (in orange text), to provide easier access to how Pick IK works (and how we used it) to the reader:\n\n> \"We followed the standard [\"pick\\_ik Kinematics Solver\" tutorial](https://moveit.picknik.ai/main/doc/how_to_guides/pick_ik/pick_ik_tutorial.html#pick-ik-kinematics-solver) from the pick\\_ik documentation, which references the default parameters from the [pick\\_ik\\_parameters.yaml file](https://github.com/PickNikRobotics/pick_ik/blob/main/src/pick_ik_parameters.yaml). We only altered two parameters for the IK: changing both approximate\\_solution\\_position\\_threshold and approximate\\_solution\\_orientation\\_threshold from 0.05 to 0.01, to reduce the tolerance on the EE pose.\"\n> \n> \"pick\\_ik uses a local optimizer, which solves inverse kinematics via gradient descent, and a global optimizer, based on evolutionary algorithms\"\n\n(continues...)"
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700735209337,
                "cdate": 1700735209337,
                "tmdate": 1700738383952,
                "mdate": 1700738383952,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gGSJhKKuhZ",
                "forum": "sb0ojNl7F6",
                "replyto": "7agpEKvetM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6452/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6452/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "(...continues)\n\n\n* What happens when there exists no IK solution?\n\nThis implementation detail is already described in the paper. In the Environment details section, we mentioned:\n\n> \"Invalid actions are rewarded with 0 and the agent is kept still, to discourage the agent from taking them.\"\n\nand invalid actions are described in the main text as:\n\n> \"Note that invalid actions can be caused by the Jacobian-based IK solver failing due to an impossible configuration request. This could be due to: (i) joint configurations that are too far from the current one and thus unreachable, (ii) attempts to collide with objects, or (iii) configurations outside the joint limits.\"\n\nWe also would like to highlight that we have shared our code, so that any implementation detail can be verified for the simulated experiments, and **we will open source the code shared in the supplementary material upon publication** to foster further research in this direction (thanks to the new two action spaces, the four new tasks and the three new robots we introduced).\n\n**Hierarchical control**\n\nWhile the idea of hierarchical control would definitely be interesting to explore for future work, and we discussed this in the paper, as the reviewer acknowledged, **the current work is about a new action space, involving no hierarchy**.  Hierarchical control requires the agent to reason about actions in different stages while our work requires the agent to output a hybrid set of coordinates, in task and joint spaces, in one flat stage. Hierarchical control mostly employs actions that are temporally-consistent and last for a longer time, while our work focuses on atomic actions that should be provided at high frequency for closed-loop control.\n\nFor example, in the work mentioned by the reviewer [1], the agent should reason about which controllers should be combined, by selecting multiple object-axis controllers in a prioritized order, which are composed together using null-space projections. In contrast, in our work, there is no priority as the action's dimensions have all the same priority, and thus the policy is \"flat\".\n\nAnother example is primitives [2], where the agent should reason, first, about which primitive to use, and then, on the parameters for applying the primitive to the environment. Our approach jointly controls the robot's configuration by providing targets in task and joint coordinates, rather than prioritizing any of them.\n\nExtending our work to flexibly choose which joint to directly control with E3J is described as a future work direction in the Conclusion, and we believe our work, including all the assets we are releasing (new E3A and E3J action spaces, new full-body tasks to evaluate, new robot models to experiment with), will provide **an useful starting point and a solid baseline for future research in this area**.\n\n[1] Learning to Compose Hierarchical Object-Centric Controllers for Robotic Manipulation, *Sharma et al*\n\n[2] Accelerating Robotic Reinforcement Learning via Parameterized Action Primitives, *Dalal et al*\n\n---\n\nWe are encouraged that the reviewer finds our submission interesting and we hope that the above clarifications along with the revisions to the manuscript address the reviewer's remaining comments.\n\nIf you are more satisfied with our revision, we would kindly ask you to update your score to reflect this."
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700735285783,
                "cdate": 1700735285783,
                "tmdate": 1700735862622,
                "mdate": 1700735862622,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "irYCGt0dWl",
            "forum": "sb0ojNl7F6",
            "replyto": "sb0ojNl7F6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6452/Reviewer_XGZj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6452/Reviewer_XGZj"
            ],
            "content": {
                "summary": {
                    "value": "- Proposes a new action space called End-Effector-Elbow (E3) for robot arm control that allows both efficient learning and full control over the arm configuration by utilizing the extra degree of freedom in a 7-DoF robot arm used for 6-DoF EE control. Introduces two realizations of E3: E3Angle (E3A) which controls the elbow angle directly, and E3Joint (E3J) which controls the elbow position indirectly by fixing a joint.\n- Shows through RL experiments in simulation that E3, especially E3J, outperforms joint and end-effector control in tasks requiring precise arm configuration. Real-world imitation learning experiments all show that E3 succeeds in confined spaces while end-effector control fails."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Addresses limitations of standard joint and end-effector control spaces.\n- Achieves better sample efficiency than joint control and better arm control than end-effector control.\n- E3J alignment with task space enables efficient learning like end-effector control.\n- Experiments show benefits in simulation and real-world settings in both generic simulation benchmarks and also a hard real-world manipulation setup."
                },
                "weaknesses": {
                    "value": "- The E3 action space does not consider the dynamics or contact forces of the robot and the environment, which may affect the performance and stability of the robot learning algorithms.\n- The E3 action space is only tested on 7 DoF robot arms, and may not generaliz to other types of manipulators with different degrees of freedom or kinematics."
                },
                "questions": {
                    "value": "- Only evaluated on a 7 DoF arm. The framework may not extend well to arms with higher DoFs and 6 DoFs. How does this method extend to higher DoFs? Is there is a generalized version of this framework?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6452/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6452/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6452/Reviewer_XGZj"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6452/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698948292161,
            "cdate": 1698948292161,
            "tmdate": 1699636720731,
            "mdate": 1699636720731,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "uHnF2dS4aB",
                "forum": "sb0ojNl7F6",
                "replyto": "irYCGt0dWl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6452/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6452/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for their positive feedback. We answer the remaining questions as follows.\n\n***\n\n**The evaluation does not consider dynamics/contact forces**: for all the approaches we tested, we control the robot by setting target joint positions derived from the agent's output action space: either directly with joint space or through Inverse Kinematics (IK) for EE and E3 action spaces. In regard to the observations/inputs, the agent receives as inputs two RGB images, from the environment and wrist cameras, and a set of proprioceptive states. We did not account for contact forces, however in the RL experiments the agent can infer contacts, by visual or proprioceptive feedback (e.g. the end-effector is blocked) or through the rewards (e.g. the agent is rewarded to stay in contact with some object to complete the task). Nonetheless, we understand this would be useful to know for future readers and thus we added some additional comments on this, when discussing the agent's inputs from the environment, in the revised manuscript (see green text in Appendix A.5).\n\n **Extension to higher DoFs**: arms with more than 7 DoFs are less common than 6 and 7 DoFs arms, and they are often designed for specific applications, which makes them hard to evaluate in common environments. We discussed this choice of focussing mostly on 7 DoF arms in Section 4.2 (highlighted in blue from the original submission) and, in order to provide a more general idea on how to extend our framework, we provided additional comments (in green) in Section 4.4, discussing how E3J could be adapted for higher DoFs.\n \n***\n\nWe hope our revision responds to the reviewer's questions about our work and we look forward to any further suggestions to improve our work further."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699940208641,
                "cdate": 1699940208641,
                "tmdate": 1699940208641,
                "mdate": 1699940208641,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5ydbC5uAa7",
                "forum": "sb0ojNl7F6",
                "replyto": "15cS2c65ca",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6452/Reviewer_XGZj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6452/Reviewer_XGZj"
                ],
                "content": {
                    "comment": {
                        "value": "thanks for the rebuttal! I would like to invite the authors to address the concerns raised by other reviewers."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700603580651,
                "cdate": 1700603580651,
                "tmdate": 1700603580651,
                "mdate": 1700603580651,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "YctjzkCvJf",
            "forum": "sb0ojNl7F6",
            "replyto": "sb0ojNl7F6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6452/Reviewer_AKTt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6452/Reviewer_AKTt"
            ],
            "content": {
                "summary": {
                    "value": "It is common in robot learning to use either an end-effector or joint position action space. Many robots are 7-dof, where as EE action spaces are 6 dof, which means that there is an overactuated degree of freedom, leading to consistency issues. Most of the tasks and corresponding cost functions are metric, thus not aligned with joint action space. This paper proposed EE3 which overcomes both challenges by adding a joint angle (usually base or wrist to make sure there is kinematic consistency) to EE action space. The approach is evaluated on RLBench, where they show that this action space can boost performance in 6 RL tasks which require a good amount of obstacle avoidance, and performance does not drop in other tasks. The paper also shows results on 3 real-world tasks on the Franka arm."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Rethinking action spaces and adding inductive biases for downstream tasks is an important problem \n- EE3 is well motivated and the presentation of the problem statement is extremely clear\n- The experiments are insightful, as we can see that EE3J helps in downstream robot tasks \n- The real world experiments support the hypothesis"
                },
                "weaknesses": {
                    "value": "- I think there is a lack of discussion of other action spaces (primitives, OSC etc) \n- There is a lack of comparison to other action spaces as well \n\n- I don't fully believe this approach is novel - it can be seen in some ways as a special case of [1]. I believe the authors should discuss this further. \n- It would be good to see this applied to other robots than Franka (including those with higher Dof). \n- There are also concerns about how general this approach can be - it is only applicable to overactuated manipulation scenarios. It would be good to discuss this more in the paper. \n\n[1] Riemannian Motion Policies. Nathan Ratliff, Jan Issac, Daniel Kappler, Stan Birchfield, Dieter Fox. 2018"
                },
                "questions": {
                    "value": "See weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6452/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6452/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6452/Reviewer_AKTt"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6452/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699722641057,
            "cdate": 1699722641057,
            "tmdate": 1699722641057,
            "mdate": 1699722641057,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mIbGGTGbKT",
                "forum": "sb0ojNl7F6",
                "replyto": "YctjzkCvJf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6452/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6452/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for their feedback. Please find our responses to the questions below.\n\n***\n\n**Lack of discussion/comparison to other action spaces**: the reviewer mentioned primitives and OSC as potential action spaces to compare with E3. We believe that, while both ideas are very relevant to the robot learning setting we work on, they are also orthogonal to our approach. Primitives, as in [1,2], provide a more abstract level for controlling the agent, through temporally consistent behaviors (often parameterized in task space coordinates). OSC controllers provide an alternative to IK solvers for controlling the robot in task space coordinates. In both cases, when working with a 7 DoF robot, additional control over the robot configuration needs to be provided to the learning agent for solving tasks in constrained spaces. \n\nIn our work, we discuss and implement two ways (E3J and E3A) to address such limitations, and we test them in RL and IL settings, in a temporally fine-grained setting and using IK solvers. Nonetheless, we agree with the reviewer that testing our approach using OSC controllers, or defining primitives to control the remaining degrees of freedom of the agent, i.e. the elbow of the robot, are relevant ideas to mention for additional evaluations/future work and thus we discuss them in our revised manuscript (highlighted blue content in the Related Work section about primitives and OSC, new green content about OSC controller comparison in Section 5.1/Analysis).\n\n**Is the work a special case of Riemannian Motion Policies (RMP; Ratliff et al)?** We acknowledge that RMP represents one more way of controlling the elbow of a 7 DoF robot, and thus we added it to the \"Redundant manipulators control\" paragraph in the related work section, where we discuss other ideas to control the elbow. However, the nature of our work is very different from RMP: we aim to specifically discuss the issue of controlling the full-body pose for 7 DoFs robots, using data-driven learning techniques such as reinforcement and imitation learning. We discussed and empirically validated two implementations, and we acknowledge in the Discussion section that there are many opportunities to extend our study, along which we now also mention RMPs (see Related Work and Conclusion in the updated manuscript).\n\n**Testing on other robots than Franka**: we understand that an evaluation on multiple robot platforms could be more insightful and we have started experimentation with two other 7 DoFs robots: XArm 7 with XArm gripper and Kuka iiwa 7 with Robotiq gripper, and we aim to update the manuscript with partial results before the end of the rebuttal period. We will post additional comments when the results are ready. \n\n**Specify the method is designed for overactuated manipulation scenarios**: The initial submission made this statement in the Abstract, Introduction, Methods and Conclusion sections (see parts highlighted in blue in the manuscript). To further make it clear, we specified this additional times along the manuscript (in green, see the mentions to \"overactuacted arms\").\n\n***\n\nWe hope our revision responds to the reviewer's doubts about our work and we look forward to any further suggestions to improve our work further. \n\n[1] Accelerating Robotic Reinforcement Learning via Parameterized Action Primitives, *Dalal et al*\n\n[2] Augmenting Reinforcement Learning with Behavior Primitives for Diverse Manipulation Tasks, *Nasiriany et al*"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699940141687,
                "cdate": 1699940141687,
                "tmdate": 1699940141687,
                "mdate": 1699940141687,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]