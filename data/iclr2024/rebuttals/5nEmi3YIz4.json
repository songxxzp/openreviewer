[
    {
        "title": "ProtoNMF: Turning a Black Box into a Prototype Based Interpretable Model via Non-negative Matrix Factorization"
    },
    {
        "review": {
            "id": "vgRANnq9s1",
            "forum": "5nEmi3YIz4",
            "replyto": "5nEmi3YIz4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1839/Reviewer_XoPR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1839/Reviewer_XoPR"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a post-training decomposition technique for learning prototypes for interpretable image classification. Specifically, the paper leverages Non-negative Matrix Factorization (NMF) to learn prototypes (bases) for a certain class from a batch of hidden image features from the same class. The prototypes are then used to reconstruct the learned feature classifier for this class. By visualizing the attention on the prototypes, researchers can identify interpretable regions and their importance in arriving at the final classification results. The paper demonstrated good interpretability in the experiment."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* **Simple post-training solution**: the paper proposed a simple solution to enable better interpretability for a trained model without modifying the training process. Compared to prior works, the proposed method is computationally efficient and is architecture-agnostic. \n\n* **Good interpretability and classification accuracy**: while prior works often sacrifice classification accuracy because of the modification to the training pipeline, the proposed model brings interprtablity without loosing accuracy. \n\n* **Detailed analysis**: the paper provides a detailed empirical analysis of various aspects of the model, including the discriminativeness of the extracted prototypes, which is also a limitation of the method."
                },
                "weaknesses": {
                    "value": "* **Lacking an inference description**: the paper lacks a discussion on the inference procedure in the method section. While Figure 1 provides schematics, it is not clear enough. My understanding is the following: the paper uses the *original* head classifier for classification because \n$$V^c = R^c + C^c_{opt}B^c$$\nwhere $V^c$ is the original classifier vector, $R^c$ is the residual prototype and $ C^c_{opt}B^c$ is the extracted prototypes. The paper uses both the residual and the extracted prototypes, the sum of which amounts to the original classifier. This is equivalent to using the original classifiers for classification. This is the reason why the proposed method guarantees no drop in accuracy. \n\n* **Extracted prototypes not discriminative**: the paper provides a detailed analysis of the discriminativeness of the extracted prototypes $ C^c_{opt}B^c$. The conclusion is that they are not discriminative enough (if at all when the number of prototypes is small according to Table 3) .This makes one wonder if this discovery defeats the main purpose of the paper: discovering meaningful prototypes and shedding light on a transparent reasoning process, because these prototypes are neither meaningful nor explaining the model's decision for a specific class. The fact that using the extracted prototypes alone results in poor classification accuracy makes one think that the proposed NMS procedure is ineffective in extracting good prototypes for classification."
                },
                "questions": {
                    "value": "* Can the authors comment on my concerns regarding the meaningfulness and usefulness of the extracted prototypes in the weakness section? \n\n* A follow-up question is how important the discriminativeness of the prototypes is in interpreting the decision-making process in classification and what information we would miss if the prototypes were not discriminative as in the proposed method.\n\nI really like the proposed method but the main concern regarding the discriminativeness of the prototypes also weighs heavily in my decision. I will be happy to raise my score if the authors can address it convincingly."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1839/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698523528703,
            "cdate": 1698523528703,
            "tmdate": 1699636113897,
            "mdate": 1699636113897,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ODOBR239hf",
                "forum": "5nEmi3YIz4",
                "replyto": "vgRANnq9s1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1839/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer XoPR"
                    },
                    "comment": {
                        "value": "Thank you so much for liking our paper and we are highly encouraged by your positive and constructive feedback! It is our pleasure to address the primary concerns in the following sections in addition to the general rebuttal given above.\n\n**Adding an inference description** Thank you for pointing this out. Your understanding is completely correct and we fully agree that it is helpful for readers to better understand our method. We have revised the section 3 of the manuscript to include this part.\n\n**How important the discriminativeness of prototypes is** We agree that if the extracted prototypes are less discriminative, one may challenge their roles in the decision making. Thus we further propose a simple re-parameterization (detailed in general response above) to remove the residual prototype and increase the discriminative power of NMF prototypes, yet maintaining the interpretability of these prototypes.\n\n**What is missing in original NMF prototypes?** A straightforward answer is the parameters in the residual prototype, because empirical evidence shows adding them can reach the original performance. A more intuitive understanding is: the features extracted by the pre-trained feature extractor are optimized to fit the pre-trained classifier, thus a precise reconstruction of the pre-trained classifier becomes important in maintaining the discriminativeness. However, in the general case, it's hard to obtain a precise reconstruction of a high-dimensional (e.g., 320 for coc-tiny, 512 for res34, 768 for vit-base) classification head using a basis consisting of small number of prototypes (e.g., 1,3,5,10), which is why the approximated head using only NMF prototypes does not perform well. Therefore, it's important that the missing part after the optimal reconstruction could be incorporated into the existing basis if one wants to express the classification head using exactly $p$ interpretable prototypes. The above analysis largely inspired the re-parameterization idea and we are very grateful to your in-depth and insightful comments!\n\nWe hope our rebuttal could address your concerns and sincerely hope that the reviewer could consider increasing the score."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700534693546,
                "cdate": 1700534693546,
                "tmdate": 1700534693546,
                "mdate": 1700534693546,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qUCaarKceo",
            "forum": "5nEmi3YIz4",
            "replyto": "5nEmi3YIz4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1839/Reviewer_A726"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1839/Reviewer_A726"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors proposed ProtoNMF, a method to turn a black-box model into a prototype-based interpretable model using non-negative matrix factorization (NMF). The method involves constructing a feature matrix A^c for a given class c by stacking the D-dimensional feature vectors of n*H*W image features from n images as rows, and applying NMF to A^c to yield the factorization A^c = E^c B^c where B^c is the prototype matrix whose rows are D-dimensional prototype basis vectors, and E^c is the encoding matrix whose rows represent the coordinates of the image features along the prototype basis vectors. The method also involves another step to reconstruct a classification head V^c for a given class c, using a linear combination of prototype vectors (rows) of B^c, and to find a residual prototype R^c = V^c - C^c_opt B^c, where C^c_opt B^c is the best linear combination of prototype vectors (rows) of B^c that approximates the classification head V^c. The computation of the logit of class c of the original black-box model on the image features A^c can then be thought of as first computing a linear combination of prototype vectors in B^c (i.e., E^c_opt B^c), and then adding scalar multiples of the residual prototype R^c to each spatial position of each image (i.e., H^c_opt R^c). The authors conducted experiments on CUB-200-2011 and ImageNet to demonstrate the efficacy of their ProtoNMF."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed ProtoNMF can preserve the accuracy of a black-box model."
                },
                "weaknesses": {
                    "value": "- The proposed ProtoNMF cannot be interpreted in the same way as the baseline ProtoPNet. Its interpretability is far from ProtoPNet. The prototypes are not constrained to be actual image features of some training images. How are they visualized?\n- The proposed ProtoNMF uses linear combinations of prototypes, rather than similarities to prototypes. This, again, reduces interpretability of ProtoNMF. What do linear combinations of (abstract) prototype vectors even mean?\n- The proposed ProtoNMF also relies on a residual prototype for each class. Again, the interpretation of a \"residual prototype\" is unclear."
                },
                "questions": {
                    "value": "- As mentioned earlier, the prototypes from ProtoNMF are obtained via NMF and are not constrained to be actual image features of some training images. How are the prototypes visualized?\n- As mentioned earlier, ProtoNMF uses linear combinations of prototypes. What do linear combinations of (abstract) prototype vectors even mean?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A."
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1839/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698796313907,
            "cdate": 1698796313907,
            "tmdate": 1699636113827,
            "mdate": 1699636113827,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "d66a2fyZka",
                "forum": "5nEmi3YIz4",
                "replyto": "qUCaarKceo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1839/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer A726 (Part I)"
                    },
                    "comment": {
                        "value": "We express our deepest gratitude for the reviewer\u2019s time and constructive comments. It is our pleasure to address the primary concerns in the following sections in addition to the general rebuttal given above.\n\nBefore addressing the reviewer's concern, we want to clarify two miss-understanding points based on the reviewer's summary. \n\n**Computation of the logit of class c** is not based on the $E^c_{opt} B^c$, but is based on the $C^c_{opt}B^c$ [equation 4,5]. $C^c_{opt}$ are the coefficients optimized to make the NMF prototypes approximate the black box's classification head $V_c$ and the $E^c_{opt} \\in \\mathbb{R}^{nHW \\times p}$ is used to indicate the interpretability of $B^c$ [section 3.1, 1st paragraph, last sentence].\n\n**The residual prototype** is not added into each spatial position of each image via $H^c_{opt} R^c$. The $H^c_{opt} \\in \\mathbb{R}^{nHW\\times 1}$ is used to indicate where and how strong the residual prototype is present in n images [section 3.2, paragraph below equation 6]. As pointed out by reviewer XoPR, the final classification head $V^c\\in \\mathbb{R}^{1\\times D}$ decomposition can be expressed via rewriting the equation 5 as: \n\\begin{equation}\n    V^c = C_{opt}^cB^c+R^c\n\\end{equation}\n\nWe apologize for causing the miss-understanding and have improved our writing in section 3 of the revised manuscript. We also added the Figure 8 to the appendix to compare the inference process of the black box, ProtopNet and our ProtoNMF.\n\n**How are latent prototypes which are not directly the feature of any image patch visualized** It is visualized via indicating how important this prototype is to reconstruct the feature of each position of a set of real images. Given one prototype, such importance scores in all positions of one image together build one visualization. And combining such visualizations of all images makes human even easier to understand what exactly is important in these areas by observing common features in salient areas across all images. \n\n**Visualization of NMF prototypes** The $E^c_{opt} \\in \\mathbb{R}^{nHW \\times p}$ is used for visualization [section 3.1, $1^{st}$ paragraph, last sentence]. As a simple example, the first row in $E^c_{opt} \\in \\mathbb{R}^{nHW\\times p}$ represents the $p$ coefficients of the first image patch (e.g., the upper left patch of an image) of the first image, and the first coefficient in this row indicates to which degree the feature of this patch can be approximated/reconstructed by the first prototype. So a large value in the $E^c_{opt}[1,1]$ means the first patch's feature is very similar to the first latent prototype. Combining the first $HW$ values of the first column tells us how similar each patch of the first image is to the first prototype. A visualization is shown in the dashed line's area of step 1 of Figure 1 of the manuscript, where the strength of the red color in the first bird image correspond to the first $HW$ red values in the first column of the $E^c$. \n\n**Visualization of the residual prototype**. The visualization is similar. The only difference is: instead of looking at how similar the residual prototype is to the image patch's features, we look at how similar the residual prototype is to the image patch's \"residual\" feature. The \"residual\" feature indicates the feature that can not be modeled by the NMF prototypes [section 3.2, paragraph under equation 6]. For both types of prototypes, we apply a bilinear interpolation to upsample the resolution of the feature map to the resolution of the original image [section 3.2, last sentence]. At last but not least, we want to point out that a recently published paper by the ProtopNet's author also leverages the latent prototype and visualize them via a set of images instead of a single image patch [1].\n\n[1] Chiyu Ma, Brandon Zhao, Chaofan Chen, Cynthia Rudin. This Looks Like Those: Illuminating Prototypical Concepts Using Multiple Visualizations, NeurIPS 2023."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700496642202,
                "cdate": 1700496642202,
                "tmdate": 1700496642202,
                "mdate": 1700496642202,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7wfXMplstU",
            "forum": "5nEmi3YIz4",
            "replyto": "5nEmi3YIz4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1839/Reviewer_eeCj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1839/Reviewer_eeCj"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a method that turns a black-box pretrained image classification network into a more interpretable prototype-based network, by performing non-negative matrix factorization to decompose the final features of the network into non-negative linear combinations of bases of classes. The authors claim that in this way, the model can achieve interpretability without sacrificing performance. Empirical evaluations are performance on two datasets and three difference model architectures."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The comprehensive evaluations of different model architectures are appreciated. \n\n2. The idea of turning a black box model into a more interpretable one is interesting."
                },
                "weaknesses": {
                    "value": "1. Interpretability\n\nI believe the main contribution of this paper is to improve the interpretability of a pretrained black-box model. However, after reading the paper, I have no idea how to measure the improvements in interpretability quantitatively. The visualization of the prototypes may show how the model makes the final prediction, but I believe regular 'black-box' networks + GradCAM can do the same and there is no obvious evidence of the advantage of the proposed method. \nOne thing the author mentioned is that such prototypes can help the post-training human intervention in the model. However, the missing of this part in the experiment section makes it very hard to justify the contribution of 'interpretability.' \n\nAnd I am afraid that the 'residual prototypes,' which seem to be crucial for maintaining the recognition performance, will make it even harder to intervene manually in the model.\n\nIn summary, the authors are expected to do more than visualizations to support the interpretability. \n\n2. Writing and presentation\n\nThe overall writing of this paper is relatively casual and in many cases not precise enough for the readers to properly learn the ideas.\nAnd some examples are not solid enough. \nFor example, in Figure 2, it is true that ProtopNet is clearly converging to fewer prototypes as the training goes longer, the visualization of the learned prototypes of ProtoNMF on different images does not show the superiority in terms of diversity. How distinct are those learned prototypes?\n\n3. Evaluations\n\nPlease consider adding the performance of the standard ResNet34 to table 2.\n\nAnd I personally believe the results in Table 3 do not support the claim 'guarantee the performance on par with the black box models.' In most the cases, the performance decreases drastically. And the best performance is with the not-so-interpretable residuals."
                },
                "questions": {
                    "value": "Please evaluate the interpretability of the proposed method quantitatively."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1839/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698814671678,
            "cdate": 1698814671678,
            "tmdate": 1699636113753,
            "mdate": 1699636113753,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "URqrru7cQc",
                "forum": "5nEmi3YIz4",
                "replyto": "7wfXMplstU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1839/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer eeCj"
                    },
                    "comment": {
                        "value": "We express our deepest gratitude for the reviewer\u2019s time and constructive comments. It is our pleasure to address the primary concerns in the following sections in addition to the general rebuttal given above.\n\n**Interpretability advantage over black box+grad-cam**\nCompared to Grad-CAM, although we could readily offer more detailed visualizations (e.g., multiple heatmaps for prototypical parts of each class instead of only a single heatmap for each class as in Grad-CAM), we argue that *the visualization is neither our only advantage, nor the most important one*. A much more important advantage is: Grad-CAM only tells what the network is looking at, but cannot tell what prototypical parts the focused area looks similar to, lacking the explanation on how these areas are actually used for decision [1]. In contrast, our method clearly tells what prototype the focused area looks similar to, how similar they are, and how important is that prototype in classifying an image to a certain class. Thus our method offers a much more transparent reasoning process by design. An example is given in section 4, last paragraph. Since Grad-CAM does not even have these capabilities, it's hard to show prototype based models are quantitatively more interpretable (section 1, paragraph 5 of our baseline [1] also claims this). Regarding the experiment on the potential usage for test-time intervention as a benefit: thanks for your suggestion! We add a case study in section A.4 of the appendix using re-parameterized NMF prototypes. This section demonstrates how human could intervene by setting the importance of the intervened prototype to zero using expert knowledge to correct the model's prediction. We show that assuming an expert can intervene one most important prototype once when correcting the prediction, the Top1 performance of coc-tiny can increase from $71.9\\%$ to $82.7\\%$ in ImageNet.\n\n[1] Chen, Chaofan, et al. \"This looks like that: deep learning for interpretable image recognition.\" Advances in neural information processing systems 32 (2019).\n\n**Writing and presentation**\nThank you for pointing this out! We have improved the method description in the revised manuscript. Regarding the diversity of prototypes: Note that we do not claim our prototypes to be more diverse than ProtopNet and we acknowledge that the perceptual diversity is hard to measure because the similarity of prototypes in the latent space doesn't necessarily match the human perceptual similarity [2]. Instead, we claim that they are more comprehensive (diverse yet complete, as explained in page 2, line 4) and offer quantitative results in Table 1. Seeking for pure diversity might not be that meaningful because even a set of random prototypes could be very diverse.\n\n[2] Nauta, Meike, Ron Van Bree, and Christin Seifert. \"Neural prototype trees for interpretable fine-grained image recognition.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\n\n\n**The standard ResNet34** The result is already in the existing table. Our method only tries to decompose the classification head of a trained model for more transparent prototype based reasoning process, and thus has no influence on the performance. \n\n**Results in Table 3**\nWe refer to the common response to all reviewers, where a simple re-parameterization could remove the not-so-interpretable residual prototype and increase the discriminative power of NMF prototypes, yet maintaining the interpretability of these prototypes.\n\nWe hope our rebuttal could address your concerns and we sincerely hope that the reviewer could consider increasing the score."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700495492088,
                "cdate": 1700495492088,
                "tmdate": 1700495492088,
                "mdate": 1700495492088,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]