[
    {
        "title": "Why is SAM Robust to Label Noise?"
    },
    {
        "review": {
            "id": "x7rYxIHpMd",
            "forum": "3aZCPl3ZvR",
            "replyto": "3aZCPl3ZvR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8452/Reviewer_Cbxh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8452/Reviewer_Cbxh"
            ],
            "content": {
                "summary": {
                    "value": "This paper analyzes the label noise robustness of the SAM (Sharpness-Aware Minimization) optimizer. SAM is known to achieve large gains in test accuracy over SGD when there is label noise, but the reasons are not well understood. The authors decompose SAM's sample-wise gradient into a logit term and Jacobian term. In linear models, they show SAM's logit term acts like an explicit reweighting that upweights low-loss (likely clean) examples. However, in neural networks, SAM's gains come primarily from regularization effects induced by the Jacobian term rather than explicit reweighting. The authors analyze the Jacobian term in a 2-layer linear network, showing it induces feature norm regularization. Adding just these implicit regularization terms recovers much of SAM's performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Provides theoretical analysis and experiments investigating an important practical phenomenon - SAM's label noise robustness.\n\n2. Careful decomposition and ablation studies (logit vs Jacobian SAM) elucidate the source of gains.\n\n3. Analysis of the Jacobian term shows it induces implicit regularization that aids robustness.\n\n4. Proposes a simplified method motivated by analysis that recovers much of SAM's gains."
                },
                "weaknesses": {
                    "value": "1. Analysis limited to 2-layer linear networks, unclear if insights extend to deep nonlinear networks.\n\n2. Lacks comparison to other label noise robust methods."
                },
                "questions": {
                    "value": "Does the analysis for 2-layer linear networks provide insights into deep nonlinear networks? What are the limitations?\n\nCould you compare the proposed simplified method to existing techniques like MentorNet?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8452/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698374088367,
            "cdate": 1698374088367,
            "tmdate": 1699637054440,
            "mdate": 1699637054440,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HwDtcJWOFw",
                "forum": "3aZCPl3ZvR",
                "replyto": "x7rYxIHpMd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8452/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8452/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your time and constructive feedback"
                    },
                    "comment": {
                        "value": "Thank you for the feedback! We appreciate your recognition of the strengths of our paper. We address your concerns below.\n\n**1. Analysis limited to 2-layer linear networks, unclear if insights extend to deep nonlinear networks.**\n\nGreat question! To reiterate, our nonlinear section makes the following connection between the 2-layer linear network analysis and deep networks: \n- In 2-layer linear networks, SAM regularizes the norm of the intermediate features and last layer weights (Equation 4.6). \n- If we apply a feature regularization and weight decay in a similar fashion to the _last two layers_ of a deep model (ResNet18), we can close the gap between SAM and SGD halfway. \n\nWe\u2019ve also added the following new experiment to further connect the two.\n\n- When training with SAM, the norm of the last-layer activations and weights are smaller than SGD. In Figure 7 (Page 19), we plot the norm of the last-layer activations and weights during the training trajectory of SAM and it is indeed noticeably smaller. \n\n    This suggests that SAM does implicit feature/weight norm regularization in deep models, similar to what we identified in the 2-layer linear network analysis, and this regularization is important for label noise. \n- Under no label noise, we find that our regularization method (with hyperparameter search) only leads to a 1% boost in accuracy and the gain disappears at convergence. See Figure 5 (Page 18) for the test accuracy plots for SAM, SGD, and SGD + our weight/feature penalty. \n\\\n\\\n    While under label noise, the last layer regularization closes half the SAM-SGD performance gap, the regularizer only closes an eighth of the performance gap with no label noise. This finding suggests that last-layer feature regularization, which is clearly only just a small aspect of SAM, is especially important under label noise. \n\n**2. Lacks comparison to other label noise robust methods. Could you compare the proposed simplified method to existing techniques**\n\nThanks for the suggestion! We\u2019d like to first emphasize that this paper is not proposing any state-of-the-art label noise robustness technique. Instead, we would like to understand why SAM, an optimizer designed to converge to flat minima, has surprisingly good label noise robustness close to state-of-the-art. \n\nPrevious works do a thorough comparison of SAM to other state-of-the-art methods:\n- Table 4 of [1] compares SAM against methods including Co-teaching, MentorNet, Mixup, MentorMix, and Bootstrap. They observe SAM is better than these methods by 0-5% on CIFAR10. \n- Table 9 of [2] compares SAM against logit clipping, and shows SAM can benefit from additional logit clipping by 3%. \n\nIn our paper, we restrict comparing the performance of our regularizer to SAM since our goal is not to achieve state-of-the-art but understand what makes SAM robust. We see that the penalty does _halve the gap between SAM and SGD\u2019s performance_ suggesting that feature regularization at the last layer can be a key component for explaining why SAM is robust to label noise. \n\nWe hope these adjustments address your main concerns. Please let us know if you have any further feedback!\n\n**References**\n\n[1] Foret et al (2020) Sharpness-Aware Minimization for Efficiently Improving Generalization [https://arxiv.org/abs/2010.01412] \n\n[2] Wei et al (2022) Mitigating Memorization of Noisy Labels by Clipping the Model Prediction  [https://arxiv.org/abs/2212.04055]"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700254572322,
                "cdate": 1700254572322,
                "tmdate": 1700254589200,
                "mdate": 1700254589200,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0TpWeIlSxj",
                "forum": "3aZCPl3ZvR",
                "replyto": "XQiZ7cL8cu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8452/Reviewer_Cbxh"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8452/Reviewer_Cbxh"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Reviewer Cbxh"
                    },
                    "comment": {
                        "value": "Thank you for the responses.  They provide clarification on the questions raised.  After discussing with other reviewers, I will reassess my score."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700706311210,
                "cdate": 1700706311210,
                "tmdate": 1700706311210,
                "mdate": 1700706311210,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "jZYU4pZxBB",
            "forum": "3aZCPl3ZvR",
            "replyto": "3aZCPl3ZvR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8452/Reviewer_WpDM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8452/Reviewer_WpDM"
            ],
            "content": {
                "summary": {
                    "value": "This paper examines why SAM has better generalization performance than SGD in the presence of label noise. This phenomenon can't be explained by flatness minimization because the best performance is usually reached before the loss converges. The author decomposed SAM's robustness into two effects, one induced by the logit term and the other induced by changing network Jacobian. In the linear setting, the Jacobian is independent of weight, and the logit effect upweights the gradient of clean examples. In a neural network setting, however, the logit effect is neither necessary nor sufficient for performance improvement. The authors conclude by deriving a regularization method that is cheaper than SAM and can almost recover the benefit of SAM for experiments on CIFAR10."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* **Originality.** Although the robustness of SAM towards label noise has been discussed, this paper shows surprisingly logit effect is in fact not important for this robustness.\n\n* **Clarity.** The paper is well-written and easy to read.\n\n* **Significance.** The paper examines an interesting and important question in understanding SAM."
                },
                "weaknesses": {
                    "value": "* Equation 4.5 includes a stop gradient operator in a minimization target, which, to the reviewer's knowledge, is a non-standard way of writing. The reviewer would recommend to rephrase into an update rule."
                },
                "questions": {
                    "value": "* How would the regularization method perform when there is no label noise present?\n\n* Is the performance gain bring by SAM additive to current robust training algorithm or will this performance gain diminishes when more sophisticated training algorithm than SGD is used?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8452/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698498415192,
            "cdate": 1698498415192,
            "tmdate": 1699637054316,
            "mdate": 1699637054316,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VSeMX6Gqf6",
                "forum": "3aZCPl3ZvR",
                "replyto": "jZYU4pZxBB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8452/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8452/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your time and constructive feedback"
                    },
                    "comment": {
                        "value": "Thank you for the feedback! We appreciate your recognition of the strengths of our paper. We address your concerns below.\n\n**1. Equation 4.5 includes a stop gradient operator in a minimization target, which, to the reviewer's knowledge, is a non-standard way of writing. The reviewer would recommend rephrasing into an update rule.**\n\nThank you for the suggestion, we\u2019ve modified the paper accordingly.\n\n**2. How would the regularization method perform when there is no label noise present?**\n\nUnder no label noise, we find that our regularization method (with hyperparameter search) only leads to a 1% boost in accuracy and the gain disappears at convergence. See Figure 5 (Page 18) for the test accuracy plots for SAM, SGD, and SGD with our regularization. \n\nWhile under label noise, the last layer regularization closes half the SAM-SGD performance gap, the regularizer only closes an eighth of the performance gap with no label noise. This finding suggests that last-layer feature regularization, which is clearly only just a small aspect of SAM, is especially important under label noise. \n\n\n**3. Is the performance gain brought by SAM additive to current robust training algorithms or will this performance gain diminish when a more sophisticated training algorithm than SGD is used?**\n\nGreat question! The analysis we provide for SAM in the linear section shows that in SAM has properties similar to other label noise robustness methods that also leverage the speed at which examples are learned i.e. clean points losses tend to go down faster than noisy point losses (see our Related Works). In direct relation are methods that prevent gradient starvation of low loss points either by logit clipping [1] or a more balanced loss function than cross-entropy [2]. \n\nGetting back to your original question, when applying SAM on top of label noise robustness methods, it may be possible to observe further improvements. See Table 4 in [3] where SAM observes further gains with bootstrapping and Table 9 of [1] where SAM is paired with logit clipping. \n\nWe hope these adjustments address your main concerns. Please let us know if you have any further feedback!\n\n**References**\n\n[1] Wei et al. (2022) Mitigating Memorization of Noisy Labels by Clipping the Model Prediction [https://arxiv.org/abs/2212.04055]\n\n[2] Ghosh et al. (2017) Robust Loss Functions under Label Noise for Deep Neural Networks [https://arxiv.org/abs/1712.09482]\n\n[3] Foret et al. (2020) Sharpness-Aware Minimization for Efficiently Improving Generalization  [https://arxiv.org/abs/2010.01412]"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700254279773,
                "cdate": 1700254279773,
                "tmdate": 1700254279773,
                "mdate": 1700254279773,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0iHKjwXXNP",
                "forum": "3aZCPl3ZvR",
                "replyto": "k9ANu5tCsY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8452/Reviewer_WpDM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8452/Reviewer_WpDM"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response. It answers my questions and I will keep my score."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700617339288,
                "cdate": 1700617339288,
                "tmdate": 1700617339288,
                "mdate": 1700617339288,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "C0tntVLy4Y",
            "forum": "3aZCPl3ZvR",
            "replyto": "3aZCPl3ZvR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8452/Reviewer_M3rX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8452/Reviewer_M3rX"
            ],
            "content": {
                "summary": {
                    "value": "This paper provides analysis to understand robustness of SAM to label noise through the lens of implicit regularization. The key idea is that the benefits of SAM can be primarily attributed to the network Jacobian part appearing in the sample-wise gradient. Analysis of the Jacobian term is then provided in simplified settings and empirical experiments are also provided to illustrate the general applicability of the idea (in CIFAR-10 classification)."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Provide refreshing insights on robustness of SAM to input labels through the lens of implicit regularization\n- Overall the paper is well written and is easy to follow"
                },
                "weaknesses": {
                    "value": "- No analysis/empirical demonstrations on tasks other than classification are provided (e.g., regression tasks)\n- Missing discussions/analysis on how the robustness benefits depend on parameters such as number of parameters, number of training samples, learning rate , etc. (see also Questions below)\n- Missing some references in Related Work, e.g.: https://arxiv.org/abs/1609.04836, https://arxiv.org/abs/1705.10694"
                },
                "questions": {
                    "value": "- How does robustness of SAM depend on the network width/number of parameters (d) and number of training samples (n)? Are there additional benefits (or otherwise) that SAM provide in the overparametrized regime (or some non-trivial regimes in terms of n and d)?\n- How does robustness of SAM in the stage of SGD training depends on the learning rate? Does the learning rate need to be small enough  to better isolate the benefits of SAM? \n- Perhaps one could investigate the above  questions in the setting of Section 3.1 and also perform empirical studies on benchmark tasks like CIFAR-10 classification?\n\n\nMinor comments:\n- typos in the formula for $\\epsilon_i$ in Eq. (2.6): $y_i \\mapsto t_i$"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8452/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698855779734,
            "cdate": 1698855779734,
            "tmdate": 1699637054208,
            "mdate": 1699637054208,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xbmRfG3ap6",
                "forum": "3aZCPl3ZvR",
                "replyto": "C0tntVLy4Y",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8452/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8452/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your time and constructive feedback"
                    },
                    "comment": {
                        "value": "Thank you for the constructive feedback! We appreciate your recognition of the strengths of our paper. We address your concerns below.\n\n**1. No analysis/empirical demonstrations on tasks other than classification are provided (e.g., regression tasks)**\n\nThis is correct, we focus on understanding SAM\u2019s regularization for the cross-entropy loss (classification), which may have different qualitative behaviors than SAM for the squared loss (regression). We hope this is clear from our abstract, and we believe our findings for classification alone can still be quite interesting to the research community. \n\n**2. Missing some references in Related Work, e.g.: https://arxiv.org/abs/1609.04836, https://arxiv.org/abs/1705.10694**\n\nThank you for the pointers to these works! Keskar was already cited in Subsection 5.2, and we added Rolnick to Subsection 5.3 of our related works section. \n\n**3. How does robustness of SAM depend on the network width/number of parameters (d) and number of training samples (n)? Are there additional benefits (or otherwise) that SAM provide in the overparameterized regime (or some non-trivial regimes in terms of n and d)?**\n\nGreat questions! To answer, we added the following ablation studies on Page 19 to observe the effect of width (or overparameterization) on the performance difference between SAM and SGD. \n- Figure 9 (Page 19), SAM vs SGD in linear models trained on different numbers of examples.\n- Figure 11 (Page 20) SAM versus SGD trained on _different data percentages_ of CIFAR10 on ResNet18.\n- Figure 12 (Page 20) SAM versus SGD on CIFAR10 for _different number of convolution filters_ (to adjust for width) in ResNet18.\n\nWe observe that in both linear and nonlinear models, for the same SAM perturbation rho, the gap between SAM and SGD actually increases with the number of training examples. In particular, looking at the effect in linear models in Figure 9, one can observe that the difference between SAM and SGD is especially significant when the model is under-parametrized ($n > d$). \n\nThis may seem contrary to your expectations. However, note that we are not analyzing the performance of models at convergence, but the best test performance along its training trajectory. As a result, even when the loss is strictly convex where SAM and SGD may _converge_ to the same solution, depending on the training trajectory, the early stopping accuracy can be very different between the two optimizers. \n\nOn the other hand, we see in Figure 12 that while decreasing the number of data (keeping the model size fixed) makes the model more \u201coverparameterized\u201d, but _reduces_ the gap between SAM and SGD, overparameterization by increasing model width (and fixing data size) _increases_ the gap between SAM and SGD. We suspect that the relationship between label noise and overparameterization/width is complicated, and do not draw any strong conclusions from these results.\n\n**4. How does robustness of SAM in the stage of SGD training depends on the learning rate? Does the learning rate need to be small enough to better isolate the benefits of SAM?**\n\nGreat question! See Figure 10 (Page 20) and 13 (Page 21), where we conduct an ablation study over the learning rate for SGD and SAM in linear and nonlinear models respectively. We do a grid search over SAM\u2019s hyperparameter rho for each learning rate. Indeed as the learning rate scales up, SGD\u2019s early stopping test accuracy also increases. However, SAM\u2019s performance also improves and \nSAM\u2019s gains do not disappear at higher learning rates. \n\n**5. Typos in the formula 2.6**\nThanks! We fixed this.\n\nWe hope these adjustments address your main concerns. Please let us know if you have any further feedback!"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700254166695,
                "cdate": 1700254166695,
                "tmdate": 1700254166695,
                "mdate": 1700254166695,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "eN6iNG1MVF",
                "forum": "3aZCPl3ZvR",
                "replyto": "uPLlNrTKLZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8452/Reviewer_M3rX"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8452/Reviewer_M3rX"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for addressing my concerns"
                    },
                    "comment": {
                        "value": "I appreciate the efforts of the authors in addressing my concerns and I am happy to see these discussions being included in the revised version."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700652097730,
                "cdate": 1700652097730,
                "tmdate": 1700652097730,
                "mdate": 1700652097730,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "DZpPC17VYe",
            "forum": "3aZCPl3ZvR",
            "replyto": "3aZCPl3ZvR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8452/Reviewer_ATLV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8452/Reviewer_ATLV"
            ],
            "content": {
                "summary": {
                    "value": "The submission studies early stopping performance of Sharpness-Aware Minimization (SAM) under label noise. The effect of SAM on optimization is first decomposed into a logit term and a Jacobian term. In logistic regression, the Jacobian term is ineffectual and the effect is totally explained by the logit term which upweights the gradients of clean labels and delays fitting the noise. In neural networks, the logit term plays a similar role of reweighting gradients. However, here this term has little effect on the overall performance and the beneficial effects are due to the Jacobian term. A simple theoretical analysis on a two-layer linear network shows that the Jacobian term regularizes the representation and the last layer weights."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Understanding the effect of SAM is of paramount interest due to the popularity of this technique. The baselines and the experiments are designed to directly answer the questions. The theory, although rather simple, is not known nor trivial. The related work is adequately covered."
                },
                "weaknesses": {
                    "value": "The following concerns are the reasons for the low score and I can raise the score if all three are addressed.\n\n**1. Little evidence on the role of early stopping.** Most of the narrative highlights that SAM is especially effective when combined with early stopping. The importance of early stopping in the analysis is emphasized throughout the paper. However, when I look at the ResNet experiments in Fig 1 and 3, early stopping seems to have little to no effect, and the difference in performance is already largely present in the final stage of training. I ask the authors to either provide more evidence on the special role of early stopping or edit the text in the abstract, introduction, and sections 5 and 6 to deemphasize the importance of early stopping. In addition, the presentation of the middle plot in Figure 1 is problematic: The caption says \"SAM fits much more clean data however before beginning to overfit to mislabeled data\" but the evidence is hard to infer from the plot. The revision should present this result more clearly.\n\n**2. Little insight on the effects of the regularization.** Section 4.2 shows that the role of the Jacobian term is similar to a certain regularization on the representation and the final layer weights. The discussion does not properly connect this regularization effect to the overall narrative about robustness to label noise and the role of early stopping. The text below the theory only briefly says \"In linear models, weight decay has somewhat equivalent effects to SAM\u2019s logit scaling in the sense that it balances the contribution of the sample-wise gradients and thus, prevents overfitting to outliers,\" but I did not find any basis for this claim, nor any discussion on the effect of regularizing the representation. \n\n**3. Inadequate empirical support.** The large-scale experiments in the submission are only on Cifar-10. This is not nearly enough for an ICLR publication and hardly supports the claims in the paper. There are many other medium- to large-scale datasets (Tiny ImageNet, ImageNet, MS-COCO, flowers102, places365, food101, etc.) and the revision should include at least one of these datasets (the new dataset should not be too similar to Cifar-10 like Cifar-100 or too small like MNIST). \n\nOther comments:\n- In regression there is a rigorous theoretical framework for studying the role of early stopping on performance under label noise [1,2]. The type of task and label noise in this framework is different from the submission and discussing these tools is outside the scope of this paper but the authors may find them interesting for future work.\n\n[1] Advani, Madhu S., Andrew M. Saxe, and Haim Sompolinsky. \"High-dimensional dynamics of generalization error in neural networks.\" Neural Networks 2020.\n\n[2] Ali, Alnur, J. Zico Kolter, and Ryan J. Tibshirani. \"A continuous-time view of early stopping for least squares regression.\" AISTATS 2019."
                },
                "questions": {
                    "value": "See Weaknesses 1, 2, and 3."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8452/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699387524357,
            "cdate": 1699387524357,
            "tmdate": 1699637054086,
            "mdate": 1699637054086,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "OKAHHP0PMY",
                "forum": "3aZCPl3ZvR",
                "replyto": "DZpPC17VYe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8452/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8452/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your time and constructive feedback"
                    },
                    "comment": {
                        "value": "Thank you very much for the thorough feedback! We appreciate your recognition of the strengths of our paper. We address your concerns below\n\n**1. [De-emphasizing early stopping] I ask the authors to either provide more evidence on the special role of early stopping or edit the text in the abstract, introduction, and sections 5 and 6 to deemphasize the importance of early stopping.**\n\nThank you for pointing out, we apologize for the confusion. We would first like to clarify that it is _not_ that the difference in performance between SAM and SGD is aggravated with early stopping and that is not the point of our work. Empirically, the difference is aggravated _with random label noise_ (reported in Table 4 of [1]; see our Figure 5 (Page 18) where with no label noise, SAM only observes an 8% boost in accuracy).\n\nThe reason we had emphasized early stopping is the following. To characterize SAM\u2019s label noise robustness, we want to compare the _best performance_ of SAM with the best performance of SGD. Under heavy label noise, the best test performance often occurs with early stopping for gradient based optimization methods [2]. Like SGD, SAM\u2019s peak test accuracy also occurs before convergence as shown in Figures 1, 2, and 3. \n\nTo reiterate, we aren\u2019t claiming that early stopping has a special role in observing improvements with SAM. The point is we want to study SAM under label noise, and the best performance often occurs before convergence when mislabeled training points have not been fit.\n\nWe\u2019ve modified our submission to de-emphasize early stopping, and we hope this fix clarifies our motivation. Please let us know if the modifications are sufficient. We\u2019re happy to make further improvements. \n\n**2. [Better depiction of faster learning of clean training examples] In addition, the presentation of the middle plot in Figure 1 is problematic: The caption says \"SAM fits much more clean data however before beginning to overfit to mislabeled data\" but the evidence is hard to infer from the plot. The revision should present this result more clearly.**\n\n\nWe apologize for the confusion. To clarify this point, we\u2019ve added another subfigure in Figure 1 (also in Figure 6 on Page 18) plotting the ratio of the accuracy of clean training examples over that of noisy training examples. As shown in the figure, the ratio of clean training accuracy over noisy training accuracy peaks to a noticeably higher value with SAM, and the ratio is highly correlated with the test accuracy.  Does this help present the result more clearly? We will incorporate it into the main body for the final draft.\n\n**3. [Connecting the regularization to label noise] The discussion does not properly connect this regularization effect to the overall narrative about robustness to label noise\u2026**\n\nThank you for the feedback! First, we reiterate the connections we do make for context. Through deriving SAM\u2019s updates for a two layer deep linear network, we identified that SAM regularizes  the norm of the intermediate features and last layer weights (Equation 4.6). Applying a similar treatment to the last two layers in deep networks, we empirically observed that the difference in performance between SAM and SGD under label noise is more than halved, suggesting that this implicit regularization of SAM does provide robustness to label noise.\n. \n\nAdmittedly, we do not provide precise theoretical analysis of the robustness effects of SAM\u2019s network Jacobian term. Yet we find our empirical results alone quite surprising and we hope it provides interesting insights about the behavior of SAM \u2013 a large proportion of SAM\u2019s improvements above SGD can be retrieved by a simple regularization to the last layer weights and features of the network. \n\nWe contribute the following additional experimental results to strengthen the connection between the conclusion derived in 2-layer linear networks and label noise. \n- In Figure 8 (Page 19), we plot the norm of the last-layer intermediate features and weights with SAM and it is indeed noticeably smaller than SGD. Thus, a similar regularization seems to be occurring at the final two layers with SAM in deep networks.\n- Under no label noise, we find that our regularization method (with hyperparameter search) only leads to a 1% boost in accuracy (out of the 8% total performance gap between SAM and SGD) and the gain disappears at convergence. See Figure 6 (Page 18). \n\\\n\\\n    While under label noise, the last layer regularization closes half the SAM-SGD performance gap, the regularizer only closes an eighth of the performance gap with no label noise. This finding suggests that last-layer feature regularization, which is clearly just one aspect of SAM, is especially important under label noise. \n\nWe think it would be interesting future work to make this connection theoretically precise."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700253714705,
                "cdate": 1700253714705,
                "tmdate": 1700253714705,
                "mdate": 1700253714705,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mwTRjUYXHk",
                "forum": "3aZCPl3ZvR",
                "replyto": "RRCuY0KJZ2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8452/Reviewer_ATLV"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8452/Reviewer_ATLV"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the elaborate response. It answers my comments and, unless other issues are raised during the reviewer discussions, I will raise my score."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8452/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700604425652,
                "cdate": 1700604425652,
                "tmdate": 1700604425652,
                "mdate": 1700604425652,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]