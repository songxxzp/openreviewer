[
    {
        "title": "MapLearn: Indoor Mapping using Audio"
    },
    {
        "review": {
            "id": "OJ1qsqt6Rd",
            "forum": "PdwrCm5Msr",
            "replyto": "PdwrCm5Msr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5801/Reviewer_Cs1q"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5801/Reviewer_Cs1q"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, a MapLearn method is proposed to generate indoor floorplan maps from audio signals by learning a conditional GAN. Instead of directly conditioning the GAN on the audio signals, the authors seek to derive spatial information from audio signals. Results on simulated and real-world data validate the effectiveness of MapLearn to some extent."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "++ A spatial hint map derived from audio signals attains geometric information.\n\n++ Using the envelope to mitigate the signal noise is insightful."
                },
                "weaknesses": {
                    "value": "1) How is the envelope of h calculated?\n\n2) What does \"patch\" mean for the patch GAN discriminator?\n\n3) Could the authors add the precision and recall values of each estimated floor plan map to the third and fourth rows of Figure 10?\n\n4) What if the MLP for corner prediction from the envelope is removed and directly using the envelope along with the hint map as the input?\n\n5) Will the data and code be released for reproducibility?\n\n\nMinor:\n-- page 2: \"it's introduction\"\n\n-- page 4: \"a MLP\"\n\n-- page 5: \"a MSE\", \"a L1\"\n\n-- Figure 5: \"cGAN outpu\""
                },
                "questions": {
                    "value": "See the weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5801/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5801/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5801/Reviewer_Cs1q"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5801/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698244531808,
            "cdate": 1698244531808,
            "tmdate": 1699636611139,
            "mdate": 1699636611139,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oEZMVVbbW7",
                "forum": "PdwrCm5Msr",
                "replyto": "OJ1qsqt6Rd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5801/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5801/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "#### Q1: How to calculate envelope h?\n\nResponse: Thanks, we should have explained this better. \nWe use Hilbert transform. We will make it clearer in the paper.\n\n#### Q2: What is PatchGAN?\n\nResponse: We should have clarified this. PatchGAN is from the \u201cImage-to-Image Translation with Conditional Adversarial Networks\u201d paper in the reference. Instead of outputting a final real/fake value directly for the entire image, PatchGAN crops the image into patches and outputs a real/fake for each patch. A learnable function that fuses small patch results together is utilized for final real/fake decisions. This method has proven to be effective for recovering local details inside images.\n\n#### Q3: Add P(d) and R(d) for figure 10.\n\nResponse: \nWe report the P(40) and R(40) values for all the six floor plan visualizations here (we will add this table if the paper is accepted). The P and R values are all around 0.6, showing promising floor plan estimation result. For the full MapLearn pipeline, due to the fewer fake walls predicted, the P(40) value is overall better than that of HintMap only solution.\n\n|          | FP1         | FP2         | FP3         | FP4         | FP5         | FP6         |\n|----------|-------------|-------------|-------------|-------------|-------------|-------------|\n|          | P(40)/R(40) | P(40)/R(40) | P(40)/R(40) | P(40)/R(40) | P(40)/R(40) | P(40)/R(40) |\n| MapLearn | 0.522/0.497 | 0.720/0.559 | 0.472/0.484 | 0.533/0.504 | 0.655/0.566 | 0.689/0.592 |\n| HintMap  | 0.560/0.610 | 0.622/0.553 | 0.482/0.559 | 0.611/0.675 | 0.658/0.599 | 0.582/0.635 |\n\n\n\n#### Q4: Directly use the envelope along with the hint map as the input.\n\nResponse: Thanks for the comment. The envelope should be used in conjunction with location information (i.e., the location where the measurement is being performed). We find that explicitly telling the network about measurement locations (and shifting the local map-patches to those locations) is beneficial. It is more generalizable than directly inputting the measurement location (x,y) as two other dimensions and relying on the neural network to learn.\n\n#### Q5: Will the data and code be released for reproducibility?\n\nResponse: Yes, we will release the data and code if the paper is accepted.\n\n\n#### Q6: Minor typos\nResponse: Thank you for identifying these issues. We will fix them."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5801/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700704255785,
                "cdate": 1700704255785,
                "tmdate": 1700704255785,
                "mdate": 1700704255785,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hCqZ2Eu4eh",
            "forum": "PdwrCm5Msr",
            "replyto": "PdwrCm5Msr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5801/Reviewer_qNkX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5801/Reviewer_qNkX"
            ],
            "content": {
                "summary": {
                    "value": "This paper tries to reconstruct the floorplan of an area via audio reflections. In detail, by accepting recorded audio reflections and corresponding locations as input, a conditional GAN is used to predict the floorplan contour as output. Experiments of the model trained on synthetic dataset gives promising accuracy on real datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.\tInteresting idea. Cameras and Lidars are generally used to reconstruct the map of an environment. In the paper, the authors propose to use audio reflections to recover the floorplan of an environment. The idea is different to previous methods and sounds very interesting.\n\n2.\tRobust solution. Predicting the indoor map from only audio reflections is very challenging due to limited and sometimes noisy information in the audio reflections. Therefore, the authors introduce the Hint map to recover a coarse geometry of an area according to the time of receiving responses. The Hint map then is used to replace original signals as the input to cGAN, making results more accurate and robust.\n\n3.\tIndividual room estimation. It is really difficult to recover the whole area all at once, so recovering one room individually and stitching rooms into floorplan with known locations should give better results."
                },
                "weaknesses": {
                    "value": "1.\tLimitation. My major concern is the limitation of the idea. Audio signals contain much less information than visual or lidar signals for map reconstruction, which means the floorplan generated from audio reflections are not that accurate as also shown in the experiments. Moreover, audio reflections vary in environments with different painting materials, decorations, and objects in the area. These factors may further impair the accuracy and generalization.\n\n2.\tPose accuracy. In the paper, the location is obtained from IMU. However, IMU is very sensitive to error accumulation especially in large rooms. Currently, as GPS is not available in indoor environments, visual information is the best to obtain location information. My concern is that if we have visual information, why don\u2019t we just recover an accurate map with SfM techniques from images? Note that audio reflections only provide very coarse floorplan.\n  \n3.\tApplications of floorplan contour. In Section 1, the authors mention that \u2018a simple floorplan contour may suffice in most cases\u2019 but don\u2019t provide examples. Maps reconstructed by cameras and Lidars can be used for localization which is the key technique to AR/VR and robotics navigation. It is not very clear to see how to use floorplan contour in real applications."
                },
                "questions": {
                    "value": "Please see Weaknesses for details."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5801/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698633937979,
            "cdate": 1698633937979,
            "tmdate": 1699636611011,
            "mdate": 1699636611011,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "eYpXzqNqwR",
                "forum": "PdwrCm5Msr",
                "replyto": "hCqZ2Eu4eh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5801/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5801/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "#### Q1: Audio has low resolution leading to impaired mapping accuracy.\n\nResponse: True, audio signals have much longer wavelengths compared to optical cameras and LIDARs, hence much lower spatial resolution. \nHowever, this lack of resolution hides rich details about the environment, leading to better privacy. \nWe think many in-home applications (Alexa, digital twins, localization) may favor coarse-grained maps and strong privacy as opposed to the vice versa; in this tradeoff, audio lies in the sweet spot. \nFinally, even extracting this coarse-grained information is not easy; traditional signal processing methods do not work well. \nWe have demonstrated that using cGAN can be effective.\n\n#### Q2: IMU location error will affect system performance.\n\nResponse: Yes, this is a valid comment. \nWe acknowledge the accumulation of IMU error would impact mapping. \nHowever, a growing body of literature is showing improved IMU-based localization [1,2] using (re)calibration opportunities from the environment (using Wifi, BLE, magnetic, and other sensory landmarks, etc. [3,4,5]). \nIn sum, IMU-based drifts can be reset periodically  allowing the error to be bounded.\nWe evaluated the sensitivity of map error as a function of IMU location error (Table 3). \nSo long as the IMU error is unbiased, the mapping performance degrades gracefully with IMU error.\n\n#### Q3: Application of the MapLearn pipeline.\n\nResponse: We mentioned the following to Reviewer 1 as well. \nMapping with audio-reverberations is relevant when cameras or LIDARs are  not acceptable (e.g., privacy concerns in homes, poor lighting conditions, and unavailability of LIDARs).\nPotential use-cases include: \n\n+ Digital twins of homes are useful for various applications, e.g., when away from home, a user wants to track her aging parent or her pet on a digital twin of the home floorplan.\nThe floorplan is valuable for visualization.\n+ Conversational AI agents (e.g., Alexa and Google Home) intend to understand the spatial context of a conversation with a user.\nKnowing the user's location is useful, but contextualizing that location on an even coarse-grained floorplan offers much more context (e.g., user is in kitchen, living room, etc.).\nMapping with cameras/LIDARs raise privacy concerns inside homes.\n+ Localization algorithms (e.g., particle filters) routinely use floorplans to update their posterior distributions. A coarse-grained floor plan with wall location uncertainties will still significantly improve trajectory estimation.\n+ Floorplans are useful to signal processing applications, e.g., WiFi radios may beamform better with an understanding of walls around it. \nOn similar lines, 3D surround sound can be synthesized better with knowledge of floorplans.\n+ Firefighters may rapidly need to map out a floor plan or army troops may need to map out an enemy building; cameras may be inadequate due to smoke or poor lighting conditions.\nAudio reverberations (inaudible) should be more effective.\n\n\n\n##### [1] Liu, Wenxin, et al. \"Tlio: Tight learned inertial odometry.\" IEEE Robotics and Automation Letters 5.4 (2020): 5653-5660.\n##### [2] Sun, Scott, Dennis Melamed, and Kris Kitani. \"IDOL: Inertial deep orientation-estimation and localization.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 35. No. 7. 2021.\n##### [3] Wang, He, et al. \"No need to war-drive: Unsupervised indoor localization.\" Proceedings of the 10th international conference on Mobile systems, applications, and services. 2012.\n##### [4] Chintalapudi, Krishna, Anand Padmanabha Iyer, and Venkata N. Padmanabhan. \"Indoor localization without the pain.\" Proceedings of the sixteenth annual international conference on Mobile computing and networking. 2010.\n##### [5] Shu, Yuanchao, et al. \"Magicol: Indoor localization using pervasive magnetic field and opportunistic WiFi sensing.\" IEEE Journal on Selected Areas in Communications 33.7 (2015): 1443-1457."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5801/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700704090629,
                "cdate": 1700704090629,
                "tmdate": 1700713801081,
                "mdate": 1700713801081,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1ZG2eu869t",
            "forum": "PdwrCm5Msr",
            "replyto": "PdwrCm5Msr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5801/Reviewer_ycoX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5801/Reviewer_ycoX"
            ],
            "content": {
                "summary": {
                    "value": "The authors aim to generate floorplans of indoor environments from audio transmitted from a mobile device. They make a few assumptions \u2013\n1.\tKnown locations of the multiple walking paths where recordings were made.  \n\n2.\tThe rooms are devoid of clutter.\n\n3.\tThe rooms are rectangular.\n\nHowever, they do not assume complete coverage of the home and show results on 60% of the grid cells. The conditional GAN model (using a cGAN loss + certain audio processing priors) is pre-trained on simulated floor plans, and then tested on 4 real environments. The specific novel aspects of the architecture are \u2013\n\n1.\tThe paper suggests generating a hint_map based on the principles of signal propagation in reflective environment (an echo is a attenued time-delayed copy of the source signal). The authors use this fact to generate reflector circles corresponding to the peaks (impulse response) of the deconvolutions between the source and the echo.\n\n2.\tInstead of the raw impulse response, the paper suggests using the envelope of the response as that is less noisy.\n\n3.\tThe impulse response is rotationally invariant, hence the paper inputs 4 measurements to the encoder to resolve this ambiguity."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The problem statement is novel and it appears that it has not been tackled earlier.\n\n2. The authors propose exploiting audio and floorplan specific priors to generate floor plans. This is an interesting direction. \n\n3. The end-to-end evaluation is reasonable."
                },
                "weaknesses": {
                    "value": "- I'm not convinced about the motivation and practicality of this problem. \n     - While I admit there are applications wherein privacy dictates that camera or LIDARs can't be used, wouldn't the same privacy concerns persist if an audio beacon is used? \n     - What is the range of audio frequencies that this method can operate on (does it need to operate in the audible range)? I would imagine the application is expected to not operate in the audible range, please correct me on this if I'm wrong.\n\n- Results in Section 4.1 is unclear. What does the HintMap baseline indicate? Isn't Hint map part of the MapLearn method? If so, what are the contribution of the rest of the components (ablations)?\n- Question about the metrics and visualizations, the paper does not motivate why the improvement matters. \n   - If an approximate floorplan suffices for downstream application(s), does the improvement in P(d) and R(d) matter? \n   - It's difficult to interpret images in Fig 10, I'm not sure if Row 2 is better than Row 3 or vice versa.\n\n- Demonstrating an application where a more accurate floorplan from audio is needed would be useful in showing the benefit of the improvement in floorplan estimate (as the goal is anyways to obtain an approximate floorplan)."
                },
                "questions": {
                    "value": "Please answer the questions listed in Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5801/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5801/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5801/Reviewer_ycoX"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5801/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698856199894,
            "cdate": 1698856199894,
            "tmdate": 1699636610874,
            "mdate": 1699636610874,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hACAyQJbv9",
                "forum": "PdwrCm5Msr",
                "replyto": "1ZG2eu869t",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5801/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5801/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "#### Reviewer 2\n#### Q1: Motivation; why does acoustics not have privacy concerns?\n\nResponse: Audio sensing will record ambient voices and sound events, which is indeed a privacy leakage.\nHowever, we have used the ultrasonic audio bands of 20kHz-40kHz (mentioned at the end of page 5).\nHuman voice and music have no footprint in these frequencies.\nAs a result, we can preserve privacy.\nAdditionally, note that cameras end up ``seeing'' details of the environment (e.g., bathrooms, bedrooms, closets, text and images of documents on the table and fridge, etc.). \nAudio preserves this notion of privacy as well.\n \n#### Q2: What does hint map baseline indicate? How to interpret Fig 10 row 2 and 3?\n\nResponse: The hint-map is the floorplan prior estimated from only the first audio reflection.\nThe later reflections capture additional environmental information and contribute to boosting the paper's final performance.\nWe have used the hint-map as a baseline (and as an ablation study to compare the value of first vs. late reflections).\nIn  Figure 10, row 2 shows the ground truth and row 3 shows the estimation based on the hint-map alone.\nRow 4 shows the final results after including the late reflections.\nWith hint maps, the estimated floor plan exhibits more fake walls because the neural network tries to insert walls at the boundary of open spaces. With the full MapLearn pipeline, fake walls are fewer. \n\n\n#### Q3: If approximate floorplan suffices, why does P(d), R(d) matter?\n\nResponse: \nThanks for recognizing this point.\nWe have struggled to design reasonable metrics -- not too harsh, not too lenient -- that can capture the quality of learnt floorplans.\nClearly, the application determines when an approximate floorplan is sufficient, but to develop some application-agnostic quantification, we decided on P(d) and R(d).\nThis is by no means the perfect metric and we are very open to suggestions. \nWe will continue to think about better metrics for this problem but believe that P(d), R(d) are reasonably fair measures of performance. \n\n\n#### Q4: Application where a more accurate floor plan from audio is needed.\n\nResponse: When a user walks around a lot (covering say 80% of the home) then the hint-map generates a reasonably good floorplan (and the late audio reflections are less crucial).\nFor such cases, the hint-map and MapLearn can both satisfy the same applications. \nHowever, when the user walks less, the hint-map degrades quicker and the value of late reflections becomes pronounced.\nIf this paper is accepted, we will add results that visually compares floorplan accuracy between MapLearn and the hint-map, when the user has walked say 60%. \nThis will highlight the additional accuracy gain from late reflections.  \n\n\nNow, what applications will need more accuracy than just a good visual approximation? \nMany indoor localization applications use particle filters [1] on a floorplan. \nVery briefly, a user's possible location is modeled by many particles, each associated with a probability. \nEach particle is a hypothesis of where the user may be located.\nAs the user moves, the particles are propagated in the measured walking direction.\nWhen a particle moves through a wall, these particles must be removed since they are an infeasible hypothesis. \nSaid differently, the floorplan helps update the posterior distribution of the user's location.\nThe floorplan accuracy directly impacts the convergence (and accuracy) in such Bayesian methods for localization.\n\n\n#### [1] Del Moral, Pierre. \"Nonlinear filtering: Interacting particle resolution.\" Comptes Rendus de l'Acad\u00e9mie des Sciences-Series I-Mathematics 325.6 (1997): 653-658."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5801/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700703869144,
                "cdate": 1700703869144,
                "tmdate": 1700713797653,
                "mdate": 1700713797653,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "6i7GYBmLvi",
            "forum": "PdwrCm5Msr",
            "replyto": "PdwrCm5Msr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5801/Reviewer_R9N4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5801/Reviewer_R9N4"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a map construction system by using acoustic signals. The problem is interesting and useful, and can support lots of location based services."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "An interesting problem, to support location based services. The GAN architecture to improve robustness against acoustic measurement noises."
                },
                "weaknesses": {
                    "value": "There are some recent work using smartphone's acoustic signals to measure the environment and construct the map, e.g., BatMapper, the only difference is the mode, thus please compare with some recent work.\nI'm not sure how they train the GAN network, especially how they collect the ground truth. BatMapper doesn't need any ground truth. If they need the ground truth, it will harm its application and user experimence.\nTheir evaluations are based on simulation, and why not implement a prototype and conduct experiment in real buildings."
                },
                "questions": {
                    "value": "1. How to gather the ground truth, and what is the usage scenario.\n2. Comparison with recent work, e.g., BatMapper.\n3. Develop a prototype and test in real buildings, instead of simulation."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5801/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699245488031,
            "cdate": 1699245488031,
            "tmdate": 1699636610770,
            "mdate": 1699636610770,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gI14k0kUkz",
                "forum": "PdwrCm5Msr",
                "replyto": "6i7GYBmLvi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5801/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5801/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "#### Q1: How to get ground-truth for training?\n\nResponse: We trained our model entirely using simulated data from the ZinD 3D-scan dataset (cited and explained in Section 3). The ground-truth floorplans are part of this dataset.\nThe real-world experiments were only performed during testing and results are promising (i.e., training on simulation data generalized to real environments). \nOf course, to report error for the real-world experiments, we obtained ground-truth floorplans from the facilities manager of the buildings.\n\n\n#### Q2: What is the usage scenario?\n\nResponse: Mapping with audio-reverberations is relevant when cameras or LIDARs are  not acceptable (e.g., privacy concerns in homes, poor lighting conditions, presence of fog or smoke, and unavailability of LIDARs). \nPotential use-cases include: \n\n+ Digital twins of homes are useful for various applications, e.g., when away from home, a user wants to track her aging parent or her pet on a digital twin of the home floorplan.\nThe floorplan is valuable for visualization.\n+ Conversational AI agents (e.g., Alexa and Google Home) intend to understand the spatial context of a conversation with a user.\nKnowing the user's location is useful, but contextualizing that location on a floorplan offers much more context (e.g., kitchen, living room, etc.).\nMapping with cameras/LIDARs raise privacy concerns inside homes.\n+ Localization algorithms or state estimation problems (e.g., particle filters) routinely use floorplans to update their posterior distributions.\n+ Floorplans are useful to signal processing applications, e.g., WiFi radios may beamform better with an understanding of walls around it. \nOn similar lines, 3D surround sound can be synthesized better with knowledge of floorplans.\n+ Firefighters may rapidly need to map out a floor plan; cameras may be inadequate due to smoke and poor lighting conditions.\nAudio reverberations should be more effective.\n\n\n\n#### Q3: Comparison with BatMapper.\n\nResponse: Thanks for bringing this up; we should have elaborated more in the paper. \nBatMapper uses a pure signal processing-based approach under the assumptions that: (1) floorplans are rectangular shaped rooms or corridors, and (2) users need to walk quite close to the walls.\nThis is necessary because BatMapper only utilizes information from early reflections (similar to our hint map) to ultimately infer the parameters of the rectangle.\nOur model is crucially different since it uses all the audio reverberations (i.e., the room impulse response) to learn any layout of the environment (including partitions, L or U-shaped rooms, etc.).\nResults show that we need the user to walk less and our maps are far more complex than BatMapper (see our Figure 10 and 11 vs. BatMapper Figure 17). \n\n  \n#### Q4: Develop a prototype and test in a real building.\n\nResponse: We indeed implemented the prototype and performed the experiments in real world across 4 different buildings.\nPlease find details regarding experiment setup in section 3 (Figure 8) and results in section 4 (Figure 11).\n\n#### Q5: The need for ground-truth harms its application and user experience.\n\nResponse: We respectfully disagree with this. \nWe only need ground-truth for training and since we train on simulation data, the ground-truth is easily available.\nWe carefully performed the simulation (channel models developed on real signal propagation physics) so that it resembles real world as much as possible. This is why the proposed method works in real world as well. \nWe do not need ground-truth when mapping an unknown floorplan in a real building (we validated this in 4 real buildings)."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5801/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700703454529,
                "cdate": 1700703454529,
                "tmdate": 1700713792062,
                "mdate": 1700713792062,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]