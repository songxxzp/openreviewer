[
    {
        "title": "WASSERSTEIN-GUIDED SYMBOLIC REGRESSION: MODEL DISCOVERY OF NETWORK DYNAMICS"
    },
    {
        "review": {
            "id": "qRaAYsFtHH",
            "forum": "pNfniUgXJt",
            "replyto": "pNfniUgXJt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7152/Reviewer_XDzL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7152/Reviewer_XDzL"
            ],
            "content": {
                "summary": {
                    "value": "The authors developed a white-box Symbolic Distribution Flow Learner (SDFL) based on Monte-Carlo Tree Search (MCTS) with the 2-Wasserstein distance loss for ODE model discovery, given snapshots. Two experiments based on simulated Kuramoto model and reduced single-cell trajectory data have shown the fitting performance of SDFL."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "SDFL provides a solution to learn ODE models with interpretable functional forms by MCTS-based symbolic regression. \n\nWasserstein-based loss for MCTS leads to the theoretical analysis of sample complexity of SDFL.\n\nExperimental results have shown that SDFL outperforms JKONet and TrajectoryNet significantly under small and noisy data settings."
                },
                "weaknesses": {
                    "value": "The major concern is that the presentation needs to be improved significantly. For example, the sample complexity proof is mostly based on the reference Shah et al. (2020) while the SDFL takes the UCT-based loss for MCTS, where V(s,a) was not clearly defined in the submission. The provided proof in Appendix B was based on specific loss functional form $h$, which does not seem to be consistent with the text description in Section 3.3. This raises the concern on the validity of the presented theoretical analysis. It is also not really clear how equation (2) is relevant or actually used to derive the presented solution in SDFL. The authors may need to clearly present how MCTS was performed based on Wasserstein distance with stochastic roll-outs. \n\nThe presented results on two small systems are based on the fitting performance. It would be interesting to have more comprehensive evaluation, for example, checking the prediction performance in the second experiment?\n\nThe authors also need to check on the math notations and reference format. For example, the subscripts in equation (7) in Appendix C need to be fixed and it may be better to use $\\theta$ instead of $x$ to be consistent with the notations in Section 5.1."
                },
                "questions": {
                    "value": "1. How coefficient regression was done in the Kuramoto example? In Appendix C, if K is fixed at 1/3, which two regression parameters in the model need to fit? \n\n2. For both experiments, are there any additional constraints imposed in MCTS? How can the functional forms along three dimension be perfectly consistent using MCTS? \n\n3. What is the run-time for SDFL? Is it scalable for high-dimensional ODEs? Is it possible to provide a time complexity analysis?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7152/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698684267820,
            "cdate": 1698684267820,
            "tmdate": 1699636847337,
            "mdate": 1699636847337,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "D6PhxH45In",
                "forum": "pNfniUgXJt",
                "replyto": "qRaAYsFtHH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7152/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7152/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the genuine and constructive  comments, which are helpful in improving the paper. Please find our responses below. Revisions have also been made in the paper, in particular the numerical results have been updated. \n\nWeaknesses:\n\n1. Thanks for this comment. The presentation has indeed been updated and the value of $V(s, a)$ has been explicitly stated. Regarding the proof of proposition 1 (sample complexity), in fact MCTS is a maximization algorithm, so minimizing the loss $L$ which is the initial goal, is equivalent to maximizing $\\frac{1}{1+ L}$. Hence, the latter expression was used for the algorithm and that is why it is the one  used for the proof. This information has now been explicitly stated in subsection 4.2. Regarding equation $(2)$, it was provided (in the background material) to give more context on the problem, but it is -indeed- not explicitly  needed for the results. \n\n2. Thanks for this comment. The numerical results are actually not fitting performance but rather prediction performance, on an unseen test data-set (as mentioned in the captions of the tables). \n\n3. Thank you for your attention to these details. We appreciate it. We have updated the notations accordingly. \n\nQuestions:\n\n1. Thanks for this question. One coefficient was used for $K$ and one for the intercept (i.e. the additive constant known as natural frequency).\n\n2.  Thanks for these remark and questions. That was enforced using the permutation invariance trick, since such a structure is what's expected for a network model. We added in appendix D.2 a model obtained without enforcing permutation invariance, and the performance is lower. Additionally, we note that the task of modelling scRNAseq data has been previously shown to benefit from network modelling in static settings, such as in [1] and [2]. \n\n3. Many thanks for these relevant points. A comparison of computational time between the different methods has been added in appendix D.1. Scalability of symbolic search to high dimensions is still an open problem (in general) as stated in the updated conclusion and left for future work. \n\nReferences\n\n[1] Wang, Juexin, et al. \"scGNN is a novel graph neural network framework for single-cell RNA-Seq analyses.\" Nature communications 12.1 (2021): 1882.\n\n[2] Van Dijk, David, et al. \"Recovering gene interactions from single-cell data using data diffusion.\" Cell 174.3 (2018): 716-729."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7152/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700485655376,
                "cdate": 1700485655376,
                "tmdate": 1700485655376,
                "mdate": 1700485655376,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "xXe31IQch3",
            "forum": "pNfniUgXJt",
            "replyto": "pNfniUgXJt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7152/Reviewer_97PM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7152/Reviewer_97PM"
            ],
            "content": {
                "summary": {
                    "value": "Authors propose the combination of Neural ODE with symbolic regression using MCTS and Wasserstein loss to learn dynamical systems under an observational setting, where longitudinal data is measured at random times. The problem of learning the dynamics from the observed snapshots is a type of inverse problem which is in general non-identifiable. \n\nThe method requires a set of symbolic operators to be considered for building the symbolic expressions. The method uses MCTS and the set of provided operators to search for an analytical formula of the ODE system, and the Wasserstein loss is used to measure the discrepancy between the predictions and observations.\n\nThe method was tested on a toy dynamical model and on single cell data."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The major strength of this approach is the combination of Neural ODEs and the MCTS component to find symbolic expressions for an ODE system, in which observations of the system come at random times. Being able to learn more interpretable models in this setting is the major strength."
                },
                "weaknesses": {
                    "value": "The primary shortcoming of this paper lies in its evaluation. It seems that the primary bottleneck of the method is its scalability since learning symbolic expressions is a complex problem. As such, the method is only suitable for very low-dimensional data. In this respect, the authors only provide a single toy model (3 dims and 15 observations) where the equations are known, and a basic comparison against JKOnet is offered. In this setting, it is expected that the method performs better, as the operators given to the method are part of the equations. While this analysis is adequate as a sanity check, it doesn\u2019t offer much information about the overall capabilities of the method and it's hard to judge the method's effectiveness. Moreover, running times are not mentioned, so it's unclear how the costs of running SDFL compare to JKOnet or TrajectoryNet. Only the Wasserstein error is provided as a metric for comparison.\n\nThe authors also present a second experiment on single-cell dynamics. However, I'm skeptical about the usefulness of this method in this context, given the vast number of dimensions typical of such problems. Here, 20K measurements of genes are available for hundreds or thousands of cells at different time points. This doesn't seem like an ideal setting for this method. To handle the complexity of this dataset, the authors analyzed the data in a very low-dimensional space (d=3), mentioned only in Appendix C, with little detail on how this was accomplished. For instance, with JKOnet, the authors pick the 4K most variable genes and then use the first 20 principal components of PCA on those genes. I assume the authors used a similar approach to reduce from 20K dimensions to just 3. However, even if the authors argue that one of the method's strengths is interpretability, it's hard to see how one can interpret the equations of a 3D embedding of a dynamical system. Unless the authors can offer some interpretation or highlight which genes are the main drivers of changes across timepoints in ways that other methods can't, I question the utility of this example. A more in-depth analysis would be beneficial, illustrating, on small-scale problems, how this method might yield better or more interpretable results than its peers."
                },
                "questions": {
                    "value": "The proposed method is interesting and appears to offer some advantages over two other SOTA methods in a very ad-hoc setting. Although the method holds promise for practical application, the authors fall short of demonstrating this in a broader experimental context using realistic yet low-dimensional datasets. Since interpretability (\"white-box\") is one of the major claims, I believe situations where authors must artificially reduce the problem's dimensionality should be sidestepped unless this process improves interpretability. Can you explain in more detail how one can interpret the equations of a 3D embedding of a dynamical system?\n\nThe authors should illustrate the method's performance on low-dimensional datasets across various settings, especially when partial knowledge of the symbolic operators is provided to the algorithm. Emphasis should be placed on interpreting the learned dynamics rather than just showcasing a decrease in Wasserstein loss. Additionally, a thorough description of the competitor methods' configurations is expected to be provided. How comprehensive is the comparison? Did the authors optimize the hyperparameters for the competing methods? this information is not available.\n\nCan the method learn a good approximation of the dynamics if a cosine is provided instead of a sine as part of the input? How would it perform with only partial prior knowledge compared to JKOnet, which doesn\u2019t need this prior knowledge? \n\nThe manuscript lacks a comprehensive comparison in terms of scalability, making it challenging to assess the method's practicality. It seems to be challenging to apply the method even in a low dimensional setting, since the authors resort to a two-step procedure: the initial step identifies the structure, and the subsequent step estimates coefficients. Does this suggest potential scalability issues even with modest sample sizes?\n\nAs acknowledged by the authors, MCTS was used before in the context of symbolic regression, as well as Neural ODEs + Symbolic regression. Some additional refs that can be interesting for the authors are https://arxiv.org/abs/1901.07714 and https://arxiv.org/abs/2202.02435."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7152/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698686627760,
            "cdate": 1698686627760,
            "tmdate": 1699636847222,
            "mdate": 1699636847222,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kC8v2vbOZ3",
                "forum": "pNfniUgXJt",
                "replyto": "xXe31IQch3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7152/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7152/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the constructive comments, which are helpful in improving the paper. Please find our responses below. Revisions have also been made in the paper, in particular the numerical results have been updated. \n\nWeaknesses:\n\n1. Thank you for this comment. As mentioned in appendix C, the operators that were given to the search algorithm are \n $$\\{+, - , \\times, \\frac{ \\cdot  }{ \\cdot }, \\cos, \\sin, \\exp \\}.$$ This leads to a large search space of the order of millions of possible expressions, for a predefined maximum length of 10 to 20 symbols. Yet, the proposed method is able to recover the model with very sparse observations and no use of the velocities. Symbolic search usually requires a much higher sampling frequency, and does not handle randomness (see for e.g. \\url{https://par.nsf.gov/servlets/purl/10357448}). We believe our method is the first that is able to address the important challenges of data-sparsity and randomness. Not only that, but the method also shows promising improvement in performance in comparison to the state-of-the-art in trajectory inference. Computational time comparison has also been added in appendix D.1. As mentioned by the reviewer, scaling symbolic learning to high dimensions is still an open problem, which is out-of-the-scope of this paper. Regarding the evaluation metric, it measures the ability of the model to accurately predict the system under study. It is also the metric that was used by previous works (e.g. JKOnet and TrajectoryNet). Additionally, as kindly acknowledged below by the reviewer, we also propose a real-world experiment where the equations are not known, which we discuss below. \n\n2. Many thanks for this comment. More details on the pre-processing of the data have been added in the updated version, which we briefly mention here. (In the previous version, the embedding technique was only mentioned in Appendix C). The dimension was reduced using the recent dimensionality reduction technique PHATE, proposed in [4]. PHATE is specifically designed to preserve maximum variablity in the low-dimensional space, while allowing for intuitive visualization, and therefore interpretation. Given that visualization is more intuitive in dimension 3, we believe learning a model on top of that would lead to improved interpretation. We also note that TrajectoryNet paper uses a dimension $d=5$, which is of the same order of what we use. Furthermore, We emphasize and kindly remind the reviewer that the pre-processing is not part of our method, nor was it part of other trajectory inference algorithms such as JKOnet and TrajectoryNet. Hence, the \" white-box \" claim mostly concerns the main task addressed in the paper, i.e. devising a model that is able to predict probability distribution flows accurately."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7152/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700485164816,
                "cdate": 1700485164816,
                "tmdate": 1700485229064,
                "mdate": 1700485229064,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8edBNfh6Me",
                "forum": "pNfniUgXJt",
                "replyto": "xXe31IQch3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7152/Reviewer_97PM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7152/Reviewer_97PM"
                ],
                "content": {
                    "comment": {
                        "value": "I would like to thank the authors for the taken time and effort to address some of the questions. While they offer a bit more insight, they do not sufficiently address the raised issues to the extent that it warrants change of rating. Some of the answers address the questions only partially, for example not addressing direct requests for comparison. The authors also don't address more explicitly the pointed domain specific interpretability issues, a major upside of symbolic methods, beyond simple single metric comparison. Furthermore, a standard benchmark dataset hasn't been established nor routinely used in the single cell community and there are large number of datasets and findings obtained from trajectory inference methods that the outcome of the approach can be compared to on the basis of various metrics capturing different aspects of the results. See for example https://doi.org/10.1038/s41587-019-0071-9."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7152/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700661035530,
                "cdate": 1700661035530,
                "tmdate": 1700661035530,
                "mdate": 1700661035530,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wCVdU0luWP",
            "forum": "pNfniUgXJt",
            "replyto": "pNfniUgXJt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7152/Reviewer_QgHg"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7152/Reviewer_QgHg"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the symbolic learning of probability flows \u2013the flows are originated by a distribution of initial conditions that the ODE has. The solution is based on a Monte Carlo Search Tree solution to solve a given optimization problem, and theoretical guarantees is given for the approximation of the optimization problem given that we only use samples of the trajectories, and for sample complexity in finding a close to optimal solution. Experiments in both different settings are given to show its competitive performance -- one where the \"ground-truth\n ODE is known and one where isn't."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "-> An important strength is combining MCTS methods for symbolic regression to the minimization of a Wasserstein-based metric for the probability flows of the system. From what I see in the paper, this is the first time such formulation has been done.\n\n-> It is great that the paper has both theory and experiments, since both are needed due to the nature of the problem being resolved. \n\n-> Experimental results show competitive performance in discovering the underlying dynamics of a Kuramoto oscillator network and of single-cell population dynamics. The method is compared to recent methods in the literature. \n\nI believe the paper is of interest to the community."
                },
                "weaknesses": {
                    "value": "The paper has considerable room for improvement in the presentation of its results, both theoretical and experimental, as well as in literature review, and the writing in general. I am expanding on my concerns below.\n\n-> In subsection 3.1 I would imagine that assumptions on regularity or continuity on the vector field $f$ must be enforced, to avoid, for example, solutions that escape in finite-time (will diverge at some finite time before $T$), e.g., $\\dot{x}=x^2$.\n\n-> Is $s$ in Theorem 1 any real number that we must choose to be greater than $d$, or is it some parameter coming from the setting from the sections before Theorem 1?\n\n-> Proposition 1 requires more explanation. First of all, would it be possible to include a mathematical expression that defines what an $\\epsilon$-optimal solution is? Would it be possible to reference the objective that is being optimized? Moreover, two expressions are introduced whose definition is nowhere to be found: \u201cmaximum allowed expression length\u201d and \u201csize of the chosen elementary function set\u201d.\n\n-> Regarding the main algorithm (subsection 4.2): It is mentioned that a \u201cpermutation invariant\naggregation operation (e.g. sum)\u201d is included to reduce the search space to the MCTS. So, how does such invariants help reducing such search-space? I guess such operation is part of a leaf of the MCTS, right? Should it be highlighted in Figure 1 or in Algorithm 1? \n\n-> Something which makes not much sense to me is the fact that the introduction section makes it clear that there is an interest in analyzing network systems and much of the paper\u2019s inspiration comes from it. However, in the next sections until the experimental section, there is not mentioning of network systems playing a particular role in the derivations of the theoretical results or even the algorithm \u2013 perhaps with the exception of the brief mentioning of \u201cpermutation invariant aggregation operation\u201d, which, as I mentioned before, is barely explained and noticeable in the algorithm and the paper itself. Is there any explanation missing regarding the role of having network systems in the technical derivations and algorithm? I don\u2019t really see the connection \u2013as far as how things look to me, all the derivations in the paper and algorithm should work for appropriate general vector fields $f$ that are not necessarily corresponding to network systems of some sort.\n\n-> The description of the Monte-Carlo tree search for symbolic regression is not self-contained in my opinion and requires more explanation. Would it be possible to describe it as an algorithm, with \u201cfor loops\u201d and precise instructions? I need to find answer to questions such as: Are the nodes, especially the first node of the tree, considering both binary and unitary operations? What is the \u201cpredefined measure of accuracy\u201d on step 2 (Simulation)? Is this \u201cback-propagation\u201d step similar to the one in dynamic programming? How many times is step 4 (Selection) repeated? \nI believe that an example with a graphic will greatly help.\n\n-> Why is TrajectoryNet not depicted in Table 1? Its comparison must be added to understand fully the comparison of SDFL.\n\n-> Authors must include a detailed comparison between their solution and \u201cTrajectoryNet\u201d and \u201cJKOnet\u201d, their similarities and difference in their algorithms. This is crucial and currently absent from the paper. For the Kuramoto experiment I would expect TrajectoryNet to perform better since it seems to be based on neural networks, which perform well when there is a lot of data.\n \n-> Why does SDFL have better performance in the simulations (considering that a comparison with TrajectoryNet is absent in the first experiment, as pointed above)? An explanation or even a speculation should be given, since it highlights how different the method done by the authors are with respect to the others. \nAlso, do the other methods also incorporate some permutation invariant properties in their methods? \nAlso, is there perhaps a metric (besides the Wasserstein difference) under which the other methods perform better? What do they use in their own papers to assess accuracy?\n\n-> What happens when you remove the aggregation operation (which is permutation invariant) in both experiments? I want to see how much it really plays a role; this is a very important ablation study whose results must be in the paper. Moreover, the last experiment had nothing to do with networks, so I wonder what role adding such additive operations was important. \n\n-> So, for the Kuramoto oscillator experiment, what is the \u201cdiscovered\u201d ODE according to the paper\u2019s method SDFL? The whole point of the paper is being able to show that the method discovers the symbolic expression of the dynamical system, and this is absent in the paper! It would be nice to see what it says on the other experiment too. \n\n-> The simulations don\u2019t show anything regarding the computational time taken by all the methods. Please, include this. Maybe there is a trade-off between accuracy and performance in your algorithm.\n\n==\n\n-> In the introduction, properties such as \u201cpermutation invariance\u201d and \u201cpartial observability\u201d are mentioned without any reference to what they mean. Their meaning should be stated, at least from a qualitative perspective, as well as why they are important or show up in the problem being studied of network flows."
                },
                "questions": {
                    "value": "Please, see the \"Weaknesses\" section above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7152/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698706402128,
            "cdate": 1698706402128,
            "tmdate": 1699636847097,
            "mdate": 1699636847097,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ulj7aSJVhV",
                "forum": "pNfniUgXJt",
                "replyto": "wCVdU0luWP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7152/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7152/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the constructive and detailed comments, which are very helpful in improving the paper. Please find our responses below. Revisions have also been made in the paper, in particular the numerical results have been updated.   \n\n1. Thanks for this very good remark. The vector fields leading to solutions which explode before the time horizon $T > 0$, are discarded in the assumption that the solution is defined on the compact interval $[0, T]$. From a practical perspective, since the system is observed at predefined observation times, if an expression such as $\\dot{x} = x^2$ is wrongly selected -for evaluation- then the loss function between the observed values and the predicted ones will be large as the time step approaches the explosion time and such an expression will be discarded. On the other hand, if it is the right equation then the observation times would be such that the explosion time does not belong to the interval $[0, T]$. Additionally, the search space is reduced (by construction in the method) to functions $f$ which have an explicit analytical expression and therefore smooth (i.e. infinitely differentiable) on their domains. \n\n2. Thanks for this comment. We have updated Theorem 1 using results more specific to $\\mathbb{R}^d$, and the variable $s$ is no longer needed. \n\n3. Thanks for this comment. A definition of $\\varepsilon-$optimal solution has been added (as a footnote to the proposition, given that it's usually considered a common notion) and the function to be maximized has clearly been restated in the paragraph preceding the proposition (i.e. subsection 4.2). Regarding the expressions \u201cmaximum allowed expression length\u201d and \u201csize of the chosen elementary function set\u201d, they refer to the previously explained fact that the search algorithm is based on a set of elementary operations/functions $(+, \\times, \\cos, \\dots)$ with the goal of combining them to output an accurate model. This entails fixing the maximal length that a mathematical expression is allowed to have (which is denoted $M$ in the updated version, in subsection 3.3 stochastic roll-outs paragraph), to define a relevant search space.\n\n4. Thanks for this comment. An aggregation operation (ensuring permutation invariance) reduces the search space in the sense that, since the expected expression will be symmetrical (or more precisely invariant) with respect to permutations of variables, the search can be reduced to looking for the part of an expression that depends only on two variables, but generates the full expression. For example, suppose the (first component of the) optimal expression is $\\dot{x_1} = x_1 \\cdot x_2 + x_2 \\cdot x_3 + x_1 \\cdot x_3$, then the algorithm can look for $x_1 \\cdot x_2$ and deduce the rest. This has been added to subsection 4.2.  \n\n5. This is a very good point. Indeed, the theoretical results apply to any vector field (satisfying the stated assumptions). On the other hand, in the algorithm, depending on whether the system is a network or not, one may use the permutation invariance trick. Regarding the motivation mentioned in the introduction, it comes from the fact that network systems are an important use-case of the proposed method, which is why the numerical evaluation is dedicated to such systems. \n\n6. Thanks for this comment. The description of MCTS in subsection 3.3 has been clarified and a more detailed pseudo-code of SDFL -clearly featuring how MCTS components are used- has been added in appendix E. As for the specific questions the reviewer is asking: \na) Indeed, all the nodes consider both binary and unitary operations, except leaves.\\\\\nb) The predefined measure of accuracy is $S(\\hat{f})$  (as defined in subsection 4.2). \\\\\nc) The \"back-propagation\" operation consists in updating the encountered tree state values (i.e. node values) -denoted $V(s, a)$ where $a$ is the  operation selected at tree state $s$- for relevant selection in the next rounds. Hence, it is rather different from the one in dynamic programming.\nd) Selection (step 4 in the first manuscript) is repeated until the tree is complete and corresponds to a coherent mathematical expression, or until the length of the latter reaches the predefined maximal length (denoted by $M$, see subsection 3.3), for as many episodes as chosen in the input of the global algorithm. \n\n7. Thanks for this comment. TrajectoryNet has also been added in the first experiment (as well) in the updated manuscript.  \n\n8. Thank you for this comment. Such a comparison has been added in section 5. Both the other methods (which are the current state-of-the art) are based on neural networks. Still, they do not perform as well as SDFL in either of the experiments because the datasize is not large enough. In the corresponding papers which introduced JKOnet and TrajectoryNet, the authors use data-sizes of the order of 2000-3000 per screen-shot, whereas we use at most 300 samples per screenshot."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7152/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700483949796,
                "cdate": 1700483949796,
                "tmdate": 1700483949796,
                "mdate": 1700483949796,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "kJ7RLRSO9d",
            "forum": "pNfniUgXJt",
            "replyto": "pNfniUgXJt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7152/Reviewer_h3SD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7152/Reviewer_h3SD"
            ],
            "content": {
                "summary": {
                    "value": "The article presents a methodology for symbolic regression of ODE-driven probability distributions. The method is white box and the relies on a Wasserstein loss"
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Symbolic learning is of interest across the ML community and data science practitioners due to transparency requirements. Furthermore, combining this with a Wasserstein loss is a challenge and, thus a strength of this paper."
                },
                "weaknesses": {
                    "value": "Although the article's aim is of great interest, the proposal is not explored in depth for this venue. For instance: \n\n- One motivation for studying symbolic regression (in the abstract) is interpretability. However, no interpretation is provided in the experimental/validation part. Furthermore, though the proposal is referred to as a _white box_ it is never inspected. \n\n- There are some referencing issues: Sec 4 refers to a Fig 4, but there are only three figures in the paper. As mentioned Fig 4.2 does not exist.\n\n- The article dedicates a fair share of its extension to the background: up until page 6 is previous work. Though this can be useful for those unfamiliar with the required background, it leaves little space to discuss the proposal in more detail. For instance, the core contribution of the article (referred to as Technical Approach in Sec 4) is only contained in 1.5 pages. \n\n- Following the above point, one would expect that this is an experimental contribution; however, the experimental validation is rather limited. Both the synthetic and real-world examples are implemented for different amounts of datapoints; however, the reason for a varying-size dataset is not justified, and in particular, it is not stated whether the performance is expected to increase or decrease with more data. Also, there are no error bars. \n\n- Fig 3, which shows the experiments of the real-world dataset, provides no insight into the contribution. In particular, 3b only compares the Euclidean and Wasserstein distances in two cases.\n\n- There is no reference or discussion about the computational cost of the presented strategy"
                },
                "questions": {
                    "value": "Please refer to the comments in the previous section"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7152/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698726855687,
            "cdate": 1698726855687,
            "tmdate": 1699636846977,
            "mdate": 1699636846977,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kgL4BI6URa",
                "forum": "pNfniUgXJt",
                "replyto": "kJ7RLRSO9d",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7152/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7152/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the constructive comments, which are helpful in improving the paper. Please find our responses below. Revisions have also been made in the paper, in particular the numerical results have been updated. \n\n1. One motivation for studying symbolic regression (in the abstract) is interpretability. However, no interpretation is provided in the experimental/validation part. Furthermore, though the proposal is referred to as a white box it is never inspected. \n\nThanks for this comment. The proposed scheme yields white-box models, in the sense that the models are explicit ODEs (reported in appendix C), which can be interpreted by domain experts. This contrasts with the current state-of-the-art competitors, which are based on neural networks, and which neither allow interpretation nor qualitative studies such as synchronization, stability, etc., although the latter are also crucial in practice. An explicit reference to the equations obtained by SDFL, reported in appendix C, has been added in the first paragraph of section 5.    \n\n2. There are some referencing issues: Sec 4 refers to a Fig 4, but there are only three figures in the paper. As mentioned Fig 4.2 does not exist.\n\nMany thanks for your attention to that. We have corrected these issues and we will do another round of proofreading to make sure any typos are fully eliminated. \n\n3. The article dedicates a fair share of its extension to the background: up until page 6 is previous work. Though this can be useful for those unfamiliar with the required background, it leaves little space to discuss the proposal in more detail. For instance, the core contribution of the article (referred to as Technical Approach in Sec 4) is only contained in 1.5 pages.\n\nThis is a good point. We have reduced the related works section accordingly. As for the general setup and Wasserstein guidance sub-sections, we kindly ask the reviewer to note that they introduce both the required technical setup and the proposed loss function (which is an important and novel component of the approach). \n\n4. Following the above point, one would expect that this is an experimental contribution; however, the experimental validation is rather limited. Both the synthetic and real-world examples are implemented for different amounts of data-points; however, the reason for a varying-size dataset is not justified, and in particular, it is not stated whether the performance is expected to increase or decrease with more data. Also, there are no error bars.\n\nThanks for these comments. Please note that before the numerical results, the contribution includes two theoretical results, whose proofs are postponed to appendices A and B. Regarding the sample-size, the reason why it was varied is because the method tackles the small data regime, with applications where data measurements are highly costly. This remark has been added in the updated version along with comments on the evolution of performance with the increasing sample size. Additionally, error bars have been added. \n\n5. Fig 3, which shows the experiments of the real-world dataset, provides no insight into the contribution. In particular, 3b only compares the Euclidean and Wasserstein distances in two cases.\n\nThanks for this comment. In fact, figure 3(a) illustrates the closeness of the estimated curve with the ground truth one for the Kuramoto model task. On the other hand, figure 3(b) illustrates the robustness of the Wasserstein distance across time, as it is a key ingredient of the proposed loss function $\\hat{L}_{m, n}$. Both of these facts were stated in subsection 5.1. Additionally, the equations obtained by SDFL were reported in appendix C. \n\n6. There is no reference or discussion about the computational cost of the presented strategy.\n\nThanks for this comment. We have added a comparison of the computational time of the method with the competitors in appendix D.1."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7152/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700483557417,
                "cdate": 1700483557417,
                "tmdate": 1700485745486,
                "mdate": 1700485745486,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]