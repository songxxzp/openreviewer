[
    {
        "title": "Cycle Consistency Driven Object Discovery"
    },
    {
        "review": {
            "id": "SiSQ1fboI0",
            "forum": "f1xnBr4WD6",
            "replyto": "f1xnBr4WD6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8392/Reviewer_nRCE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8392/Reviewer_nRCE"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a novel regularization for object-centric learning methods which\ncluster features into slots, for example Slot Attention. The proposed loss terms\nregularize the cycle consistency between features and slots and vice versa:\nSlot-feature-slot similarities are regularized towards an identity matrix and\nfeature-slot-feature similarties are regularized towards feature-feature similarities.\nThis regularization is shown to improve the segmentation performance compared to the\noriginal Slot Attention model and other object-centric models. Moreover, the\nregularization is shown to lead to more useful features for reinforcement learning."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed regularization is conceptually sound and leads to consistent improvements\n  across the considered datasets and tasks.\n- The proposed method is not only evaluated for unsupervised segmentation performance,\n  but the learned, object-centric representation is also tested on a downstream task\n  (reinforcement learning)."
                },
                "weaknesses": {
                    "value": "- It is claimed that the proposed losses address that existing approaches \"rely on\n  architectural priors\" for learning objects. In my view that's not true. Slot\n  Attention can be related to soft k-means clustering; the proposed losses enforce more\n  compact and better separated clusters. But what is considered as one cluster (i.e.,\n  an object) is still determined by architectural biases.\n- In my view it is not sufficiently motivated why training unsupervised object-centric\n  models on RGB images is the best approach for improving \"object-based reasoning\n  capabilities\":\n    - Segment Anything (Kirillov et al. 2023) suggests that generalizable object\n      segmentation can be learned from limited supervised data.\n    - Object-centric methods based on contrastive features such as DINO features are\n      very capable, e.g. Dinosaur (Seitzer et al. 2022) or CutLER (Wang et al. 2023).\n      It is argued that it \"limits the applicability of the method to domains that the\n      pretrained encoders are trained on\". The works mentioned earlier however show that\n      the resulting models work well on a range of datasets, including datasets that\n      were not used to train DINO (e.g., MOVi).\n    - Some works show that using additional data, such as optical flow or depth, allows\n      training strong object centric methods (e.g., Karazija et al. 2022). The paper\n      claims that \"relying on [...] optical flow and motion is not feasible since many\n      datasets and scenes do not come with this information\". In my experience however,\n      unlabelled video data is abundant for most practical settings.\n  In summary, it is not clear to me why the restriction to unsupervised, image based\n  methods trained from scratch is adequate for the goal of \"developing object-based\n  reasoning\".\n- Only FG-ARI is used as a metric for quantifying segmentation performance. It has been\n  pointed out several times in the literature that this metric is problematic since it\n  does not take into account whether object boundaries are accurate and favours\n  undersegmentation (e.g., Engelcke et al 2020, Karazija et al. 2021, Monnier et al.\n  2021). More established segmentation metrics, such as mIoU or AP, should be used that\n  do not share these problems.\n\n**Update:** The authors addressed the concerns in the rebuttal. In particular, additional experiments have shown that the improvements by the proposed method are orthogonal to other approaches, such as using contrastive features or videos. I therefore update my rating of this work."
                },
                "questions": {
                    "value": "- Slot Attention can be related to soft k-means clustering, as mentioned by Locatello\n  et al. 2020. From this perspective the proposed regularization terms can be\n  interpreted as enforcing compact, well separated clusters. In my view the paper would\n  profit from discussing the proposed loss terms from this angle.\n- The Dinosaur model, which is mentioned in the paper, shows improved scalability of\n  object-centric learning to real world data by applying Slot Attention in the feature\n  space of a large scale contrastive model (DINO). Do the proposed regularization terms\n  also improve the Dinosaur model?\n- I would find the result section more natural to read if object discovery came before\n  the experiments on downstream tasks."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8392/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8392/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8392/Reviewer_nRCE"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8392/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698653284340,
            "cdate": 1698653284340,
            "tmdate": 1700651749054,
            "mdate": 1700651749054,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0V75iY0SgI",
                "forum": "f1xnBr4WD6",
                "replyto": "SiSQ1fboI0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8392/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8392/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer nRCE"
                    },
                    "comment": {
                        "value": "We thank the reviewer for appreciating our experimental results and their valuable feedback for our paper.\n\n**On the point about reliance on architectral priors**\n\nThe reviewer points that our claim that slot-attention based approaches rely on architectural priors while the proposed losses remove this reliance is not entirely correct. \n\nWe agree with the reviewer and we apologise for any confusion caused by our claim. We would like to clarify our point. Slot-attention relies on architectural priors due to the competitive attention mechanism between the slots and the features. The proposed objectives do not remove the reliance on these architectural priors but act as a further enforcing function for the slots to learn the correct object representations which might further make it easier for the attention mechanism in slot attention to learn the correct slots thus the proposed objectives have an effect that helps or aids the architectural priors rather than reducing reliance on them. We will update this point in the main paper."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8392/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700092194752,
                "cdate": 1700092194752,
                "tmdate": 1700092213810,
                "mdate": 1700092213810,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Lv3JK5VeL9",
                "forum": "f1xnBr4WD6",
                "replyto": "RArTIu56CG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_nRCE"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_nRCE"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your detailed response.\n\n1. **Segment anything shows that segmentation masks can be learned from limited supervised data**.\n   I agree that SAM is trained with supervision which is different from the setting\n   addressed in this work. My point was that SAM suggest that it may\n   be possible to train a *general* segmentation model from limited supervised data that\n   performs well on unseen domains. I find the results on ScanNet more convincing that\n   show that this is not (yet) the case and unsupervised learning performs\n   competitively.\n2. **Object-Centric Methods based on Contrastive Features such as DINO**\n   - In my view the improvements by combining your method with DINOSAUR are\n   convincing since they show that the approach in the paper is orthogonal to other\n   improvements such as using pretrained contrastive features. I would like to encourage\n   the authors to include the results in the main paper.\n   - In principle, I see the point that the method in this paper can be applied to\n   observation spaces that do not work with the DINO encoder. However I don't think the Atari\n   DQN Replay dataset is a good example. Grayscale images are a subspace of RGB images,\n   the DINO encoder could be used by simply repeating the single channel of the\n   grayscale images."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8392/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700213080072,
                "cdate": 1700213080072,
                "tmdate": 1700213080072,
                "mdate": 1700213080072,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5kjZUlVbYb",
                "forum": "f1xnBr4WD6",
                "replyto": "Cj51XEAYT5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_nRCE"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_nRCE"
                ],
                "content": {
                    "comment": {
                        "value": "I agree that current object-discovery approaches do not scale well. However this does\nnot address my original point. You do not compare to methods that improve\nobject-discovery by considering additional information such as optical flow. Among\nothers, Karazija et al. 2022 and Bao et al. 2023 show promising improvements with that\napproach. In your paper your argue that these methods are not relevant competitors\nsince \"relying on [...] optical flow and motion is not feasible since many datasets and\nscenes do not come with this information\"\u2014which I think is not true for many relevant\nsettings.\n\nBao et al. (CVPR 2023), Object Discovery from Motion-Guided Tokens.\n\nKarazija et al. (NeurIPS 2022), Unsupervised Multi-Object Segmentation by Predicting Probable Motion Patterns."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8392/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700213165529,
                "cdate": 1700213165529,
                "tmdate": 1700213165529,
                "mdate": 1700213165529,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vhxQOWD8N0",
                "forum": "f1xnBr4WD6",
                "replyto": "k6OTh3bjlg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_nRCE"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_nRCE"
                ],
                "content": {
                    "comment": {
                        "value": "Yes I agree and apologise since my original criticism of only using FG-ARI was not\ncompletely justified; other metrics are used in some settings. However for me the\npaper would still be strengthend if less controversial metrics would also be used for\nthe evaluation on the synthetic datasets used for the majority of experiments in the\nmain paper."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8392/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700213215103,
                "cdate": 1700213215103,
                "tmdate": 1700213215103,
                "mdate": 1700213215103,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4JfdCGPL3z",
                "forum": "f1xnBr4WD6",
                "replyto": "0V75iY0SgI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_nRCE"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_nRCE"
                ],
                "content": {
                    "comment": {
                        "value": "In summary, I would like to thank the authors for their detailed response including\nmany additional and convincing results which I will acknowledge in my final rating of\nthe paper. Including the additional results and changes promised to the other reviewers\nand me while respecting the page limit seems to be challenging and will most likely\nrequire compromises. Therefore it would be great if the authors could submit a revision\nduring the discussion period."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8392/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700213255014,
                "cdate": 1700213255014,
                "tmdate": 1700213255014,
                "mdate": 1700213255014,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "9xUjU4Ck4J",
                "forum": "f1xnBr4WD6",
                "replyto": "SiSQ1fboI0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8392/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8392/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Updating the paper"
                    },
                    "comment": {
                        "value": "We thank the reviewer again for the detailed comments. The reviewers comments have definitely helped us improve our paper. The reviewer has asked to submit an updated version of the paper incorporating the changes by all reviewers. We have submitted this updated version. Below we detail all the changes we made to the paper based on the comments from all reviewers\n\n- Putting the object-discovery experiments before the downstream tasks - Reviewer nRCE suggested this. We have made this change in the paper. \n- Added a line in the introduction that our method does not remove the reliance on architectural priors rather augments architectural priors with an extra layer of reliability - This point was brought up by Reviewer nRCE. We have made the change in the paper. \n- Relation of cycle consistency objectives to soft-k means clusterin - This point was raised by Reviewer nRCE. We have added a paragraph about this in the method section (Section 2 last paragraph)\n- Adding the results on dinosaur to the main paper - This point was suggested by Reviewer nRCE. Based on their suggestion we have added the results on dinosaur to the main paper in the object-discovery experiments section (Section 4.1 last paragraph). \n- We added a line in the future work and conclusion (Section 5) stating that we do not address all limitations of object-centric methods on downstream tasks. Rather we take a step towards making object-centric methods useful in downstream tasks. This was pointed by Reviewer sbRA.\n- Added more games for the atari experiments as requested by Reviewer DLp5. \n\nWe hope that the reviewer finds these changes satisfactory and would be willing to change their rating of the paper. We would like to once again thank the reviewer and let the reviewer know that we would be happy to address any more queries that the reviewer may have regarding our paper and we would be happy to perform any more experiments that the reviewer thinks are important to improve the paper."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8392/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700256782012,
                "cdate": 1700256782012,
                "tmdate": 1700256804175,
                "mdate": 1700256804175,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kDE5iBlBWE",
                "forum": "f1xnBr4WD6",
                "replyto": "IUHeswXL9n",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_nRCE"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_nRCE"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your updates. My major concerns are addressed and therefore I am happy to recommend the paper for acceptance.\n\n> the improvements from our approach are agnostic to the base model used and only require that the base model uses a slot attention module\n\nThis is the most convincing update in my view, demonstrating this for DINOSAUR and MoToK are great additional results. It would be great to integrate the latter in the main paper as well.\n\n> We completely agree that using other segmentation metrics might strengthen the experimental section of the synthetic datasets as well. However, we used the FG-ARI metric as that is considered standard by the various other papers in the object-discovery community.\n\nI agree that FG-ARI is important for comparisons to previous works which often quantified performance only using this metric. Nevertheless I still think that *additionally* reporting less controversial metrics (as done for a subset of the experiments) would further strengthen the paper."
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8392/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700493062800,
                "cdate": 1700493062800,
                "tmdate": 1700493062800,
                "mdate": 1700493062800,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Gj5KUxBwcr",
                "forum": "f1xnBr4WD6",
                "replyto": "SiSQ1fboI0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8392/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8392/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Update Rating ?"
                    },
                    "comment": {
                        "value": "Dear. Reviewer, \n\n\"Thank you for your updates. My major concerns are addressed and therefore I am happy to recommend the paper for acceptance.\"\n\nThank you for taking time to read the rebuttal, and also for recommending the paper. \n\nSince the discussion period is coming to an end, we are wondering if it's possible to update your rating ? We are also very happy to clarify any other concerns. \n\nThank you"
                    }
                },
                "number": 28,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8392/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700599653566,
                "cdate": 1700599653566,
                "tmdate": 1700599653566,
                "mdate": 1700599653566,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bkqREqLMI4",
                "forum": "f1xnBr4WD6",
                "replyto": "Gj5KUxBwcr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_nRCE"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_nRCE"
                ],
                "content": {
                    "comment": {
                        "value": "I have just updated the rating in my original review."
                    }
                },
                "number": 32,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8392/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700651776370,
                "cdate": 1700651776370,
                "tmdate": 1700651776370,
                "mdate": 1700651776370,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "DjsTPfFsL3",
            "forum": "f1xnBr4WD6",
            "replyto": "f1xnBr4WD6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8392/Reviewer_7qi5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8392/Reviewer_7qi5"
            ],
            "content": {
                "summary": {
                    "value": "- This work identifies two shortcomings with existing object discovery methods. The first one being excessive reliance on specific architectural priors and meticulous engineering efforts. The second shortcoming is the gap in investigating the real world application of representations learned using the discovery methods.\n- To mitigate the first shortcomings, authors propose an objective function based on cycle consistency that constraints features of a single or multiple instances of an object in a scene to belong to a single slot. \n- To mitigate the second limitation, authors demonstrate the effectiveness of learned representation in two downstream reinforcement learning tasks.\n- Authors demonstrate that these enhancements hold true consistently across both synthetic and real world datasets showcasing the effectiveness of the proposed approach."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is well written and easy to follow.\n- Authors validate all the claims made in the paper through appropriate experiments\n- The proposed cycle consistency objectives are very simple and effective and I can foresee such objectives being useful for other q-former architectures like [1-2].\n[1] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko, End-to-End Object Detection with Transformers. \n[2] Junnan Li Dongxu Li Silvio Savarese Steven Hoi, BLIP-2:Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models."
                },
                "weaknesses": {
                    "value": "- I do not see any major drawbacks with the current work but I believe it misses a few more analysis to show the effectiveness of the cycle consistency objectiveness.\n- For example, does the Slot-feature-slot consistency objective reduce the total number of required slots creating a bottleneck? Does it have an effect on the size of the feature dimension of the slots?\n- Authors showed that increasing the value of $\\lambda_{s f s}$ results in a trivial solution but are there any other modes of failure?"
                },
                "questions": {
                    "value": "- In Eq. 8 the softmax is applied using $\\tilde F$ but only along the diagonal? Can the authors elaborate what happens if the full matrix is used for the loss? Isn't that a stricter case?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "I do not foresee any immediate ethical concerns with this work."
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8392/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698789433416,
            "cdate": 1698789433416,
            "tmdate": 1699637044938,
            "mdate": 1699637044938,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fLLT2VCpYx",
                "forum": "f1xnBr4WD6",
                "replyto": "DjsTPfFsL3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8392/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8392/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer 7qi5"
                    },
                    "comment": {
                        "value": "We thank the reviewer for appreciating our paper and pointing out various use-cases of the cycle consistency objectives presented in the paper. \n\nThe reviewer also points that they do not see any major drawbacks with the current work.\n\n**does the Slot-feature-slot consistency objective reduce the total number of required slots**\n\nThe reviewer raises the question whether the proposed cycle-consistency objectives reduce the total number of required slots by creating a bottleneck. \n\nIn our qualitative evaluation, we find that this is not the case. In general, we find that the slot utilization of models trained with the cycle consistency objectives is same as that for the models trained without it.\n\nAs we can see in Figure 2 and Appendix Figure 7, both the baseline and the cyclic models utilize the same number of slots while the cyclic model result in better disentanglement of objects into slots.\n\n**Effect on Feature Dimension of the slots**\n\nWe thank the reviewer for pointing this out. We haven't studied the effect of the proposed cycle consistency objectives on the dimensions of the slots or the features. We will conduct this analysis and add it to the paper.\n\n**On other modes of failure**\n\nThe reviewer has asked whether there exist various modes of failures for the proposed objectives.\n\nWe find that the various design decisions that we have made are important for the approach to perform well. For example, in Table 2 we have shown that having both the losses is necessary to get the best performance out of the approach. In Table 3 and 4 we have shown that applying the objectives on all iterations of slot attention and using an EMA encoder is respectively important to achieve good performance. \n\n**On using the full feature similarity matrix for the feature-slot-feature loss**\n\nThe reviewer has asked about using the full feature similarity matrix for the feature-slot-feature loss.\n\nFirst, we would like to point that the softmax in the feature similarity matrix \\tilde{F} is applied across the rows of the matrix not along the diagonal. The loss is calculated only for the diagonal elements. \n\nWe have conducted an experiment wherein the loss is calculated for the entire matrix instead of only the diagonal of the matrix. We performed this experiment for the ObjectsRoom, Shapesstacks, and ClevrTex datasets. We have presented the results for this experiment in Appendix Table 8. We find that applying the loss only for the diagonal elements works consistently better than applying it for the entire matrix. \n\nWe would like to once again thank the reviewer for their valuable feedback and time. We hope that the rebuttal has addressed all their questions. If there are further questions still remaining or if there are any more experiments that the reviewer would like us to perform we would be happy to do so."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8392/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700156800868,
                "cdate": 1700156800868,
                "tmdate": 1700156800868,
                "mdate": 1700156800868,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "H0IgNwoply",
                "forum": "f1xnBr4WD6",
                "replyto": "fLLT2VCpYx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_7qi5"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_7qi5"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "I thank the reviewer for their detailed response. \nI am satisfied with most of the responses.\nAuthors state that the cycle consistency losses enable better disentaglement of objects. Can the authors quantify that using some form semantic/instance segmentation masks and metrics? The only evidence I see of this is Fig. 2 and it is qualitative."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8392/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700163620181,
                "cdate": 1700163620181,
                "tmdate": 1700163620181,
                "mdate": 1700163620181,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UkjW6IdmAH",
                "forum": "f1xnBr4WD6",
                "replyto": "xmheSBmP85",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_7qi5"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_7qi5"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "I thank the reviewers for their detailed response. I am fully convinced and would retain my rating."
                    }
                },
                "number": 33,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8392/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700695172535,
                "cdate": 1700695172535,
                "tmdate": 1700695172535,
                "mdate": 1700695172535,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "lfrHJtqwpX",
            "forum": "f1xnBr4WD6",
            "replyto": "f1xnBr4WD6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8392/Reviewer_SbRA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8392/Reviewer_SbRA"
            ],
            "content": {
                "summary": {
                    "value": "This paper tackles object discovery and introduces additional constraints to existing slot-based methods. Specifically, two cycle consistency objectives, slot-feature-slot consistency, and feature-slot-feature consistency are explored. The authors applies the learned object-centric representations to downstream reinforcement learning tasks and demonstrates the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is well-written and easy to follow. \n2. The motivation and the development of the two consistency losses are clearly conveyed. \n3. Experiments are extensively conducted to evaluate the proposed method."
                },
                "weaknesses": {
                    "value": "1. The authors point out one of the limitations of existing methods that a notable gap exists for the learned object-centric representations to be used in the downstream tasks. However, it does not make sense to claim the proposed method overcomes this by achieving better performance on downstream tasks. The logic here is somewhat doubtful. \n\n2. The main contribution of this paper is the two proposed consistency losses which constrain the model to learn discriminative slots. The technical novelty is limited."
                },
                "questions": {
                    "value": "How to determine the number of slots? \n\nAs shown in Fig. 2, in the bottom right, multiple semantics exist in slot 6. Why the model cannot depart them?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8392/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8392/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8392/Reviewer_SbRA"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8392/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698933115049,
            "cdate": 1698933115049,
            "tmdate": 1699637044839,
            "mdate": 1699637044839,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UrZiG0gucD",
                "forum": "f1xnBr4WD6",
                "replyto": "lfrHJtqwpX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8392/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8392/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer sbRA"
                    },
                    "comment": {
                        "value": "We thanks the reviewer for appreciating that the paper is \"well-written and easy to follow\".\n\n**On the claim that the proposed method addresses the gap in downstream tasks of existing object-centric methods**\n\nThe reviewer says that our claimed that the proposed approach addreses the limitations of existing object-centric models in downsteam tasks is doubtful.\n\nWe apologise for the confusion. We do not want to claim that the proposed approach solves all limitations of object-centric methods on downstream tasks. Rather, we want to claim the proposed approach takes a step towards addressing the limitations of existing methods on downstream tasks.\n\nWe will update the paper to reflect this.\n\n\n**Question on how to determine number of slots**\n\nIn all existing object-centric papers [1, 2, 3 ...] including this one, the number of slots is a hyperparameter. The actual number of slots used by the model is problem dependent. In our experiments, we use the same number of slots used by previous papers for a given experiment. \n\n[1] Object-Centric Learning with Slot Attention Locatello et al 2020\n[2] Illiterate DALL-E Learns to Compose singh et al 2021\n[3] Improving Object-centric Learning with Query Optimization Jia et al 2022\n\n\n**On multiple semantics in slot 6 for Figure 2**\n\nThe reviewer has questioned as to why multiple semantics exist in slot 6 of figure 6.\n\nIn general, in slot-attention based methods it is observed that one slot ends up representing the background while other slots are representing the foreground object. This is also followed in Figure 2. We can see that slot 6 in Figure 2 (for the cyclic one) represents the base of the green arm and the bowl which constitutes the background. While the rest of the slots represent parts of the foreground. For example, slot 1 represnts the actual arm which moves the objects. Slot 4 and 5 represent the golden and blue blocks respectively. \n\nWe would like to once again thank the reviewer for their valuable feedback and time. We hope that the rebuttal has addressed all their questions. If there are further questions still remaining or if there are any more experiments that the reviewer would like us to perform we would be happy to do so."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8392/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700156721256,
                "cdate": 1700156721256,
                "tmdate": 1700156721256,
                "mdate": 1700156721256,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QrBZhAH7N9",
                "forum": "f1xnBr4WD6",
                "replyto": "UrZiG0gucD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_SbRA"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8392/Reviewer_SbRA"
                ],
                "content": {
                    "comment": {
                        "value": "The rebuttal addresses my questions (across the responses to all reviewers) with qualitative and quantitative results. I confirm my positive rating for this submission."
                    }
                },
                "number": 31,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8392/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700647315266,
                "cdate": 1700647315266,
                "tmdate": 1700647315266,
                "mdate": 1700647315266,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "lDv9n1Spnk",
            "forum": "f1xnBr4WD6",
            "replyto": "f1xnBr4WD6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8392/Reviewer_DLp5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8392/Reviewer_DLp5"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a cyclic training loss to improve the slot-attention-based, object-centric representation learning in neural networks. Specifically, it aims to make the mapping from features to slots and from slots to features more distinct. Additionally, it emphasizes applying the learned representations to downstream tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "It is a reasonable idea to use additional regularization terms in the training objective to make each slot in slot attention represent a more distinct concept. The paper presents this idea clearly.\nExperimental results show improved performance across various downstream tasks, including four Atari games, object discovery, and COCO/Scannet segmentation.\nFor segmentation tasks, it is interesting to see that additional cyclic losses are helpful with BO-Slate, as BO-Slate's optimization method should already aim to enhance disentangling between slots."
                },
                "weaknesses": {
                    "value": "The experimental results show improvement, the overview accuracy level is low for real-world object discovery tasks. I doubt if adding more constraints on the disentanglement of representation is a promising direction. \n\nThe results on Atari games are a bit mixed. Also, why only evaluate it on four games?"
                },
                "questions": {
                    "value": "As there are already some works aiming to improve the slot attention-based method, the significance of this paper would be enhanced if it could show more compelling practical results, demonstrating that the overall direction is promising.\nWhy are the results limited to only 4 Atari games? Do the results generalize to more games?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8392/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698939618767,
            "cdate": 1698939618767,
            "tmdate": 1699637044692,
            "mdate": 1699637044692,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YAyYymJplG",
                "forum": "f1xnBr4WD6",
                "replyto": "lDv9n1Spnk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8392/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8392/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer DLp5"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their valuable feedback and we are glad that the reviewer finds the paper clearly written. \n\n\n**Regarding whether the proposed objectives are a promising research direction**\n\nThe reviewer questions whether adding objectives that constrain the representation to be disentangled is a promising research direction. \n\nMany existing unsupervised object discovery approaches that are based on slot attention use pixel-level reconstruction objecives [1, 2, 3 ...]. We have already seen in self-supervised learning literature [4, 5, 6, ...] that objectives which operate in the latent space are far superior at learning strong representations as compared to objectives that directly operate in the pixel space. Pixel-space objectives may be prone to capture unecessary details while latent-space objectives learn stronger representations that are more conducive to downstream tasks. \n\nTo the best of our knowledge there are only two papers on unsupervised object-discovery that utilize objectives in the latent space [7, 8], both these papers use pretrained and frozen encoders thus the objectives dont have any effect on the encoder itself. Ours is one of the first unsupervised object-discovery works which utilizes latent space objectives and training happens end-to-end i.e. the objectives affect the encoder itself. By utilizing such an approach, we hope that the model will not only learn a disentangled representation but also learn to represent objects in a meaningful manner.\n\nThe proposed objectives are inspired by the cycle consistency objectives that already exist in self-supervised learning literature for videos [9] and images [10] and have shown to learn strong self-supervised representations when trained on a lot of data. The promise of our approach comes from the fact that it opens a new direction of research on designing self-supervised learning objectives for end-to-end learning of object discovery models. In self-supervised learning literature it has been shown that models trained with self-supervised learning objectives [4, 5, 6] with a lot of data result in very strong representations. Even though it might seem that the current paper does not show very strong improvements, we hope that we will see similar scaling trends with respect to data in object-discovery methods when trained with objectives such as the ones presented in this paper. \n\nFurthermore, we would also like to point that in terms of results we do outperform the current state-of-the-art model in end-to-end object centric learning (BO-QSA [3]) on various real-world datasets - Table 5 and Appendix Table 11. \n\nIn summary, we firmly believe this paper showcases promising results and paves the way for promising future works to stem from its foundations.\n\n\n[1] Object-Centric Learning with Slot Attention Locatello et al 2020\n\n[2] Illiterate DALL-E Learns to Compose singh et al 2021\n\n[3] Improving Object-centric Learning with Query Optimization Jia et al 2022\n\n[4] Emerging Properties in Self-Supervised Vision Transformers Caron et al 2021\n\n[5] Bootstrap your own latent: A new approach to self-supervised Learning Grill et al 2020\n\n[6] Barlow Twins: Self-Supervised Learning via Redundancy Reduction Zbontar et al 2021\n\n[7] Bridging the Gap to Real-World Object-Centric Learning Seitzer et al 2022\n\n[8] Object-centric Learning with Cyclic Walks between Parts and Whole Wang et al 2023\n\n[9] Space-Time Correspondence as a Contrastive Random Walk Jabri et al 2020\n\n[10] Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency (ICLR 2024 submission)"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8392/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700092007122,
                "cdate": 1700092007122,
                "tmdate": 1700092007122,
                "mdate": 1700092007122,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cj5B3EYbPc",
                "forum": "f1xnBr4WD6",
                "replyto": "lDv9n1Spnk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8392/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8392/Authors"
                ],
                "content": {
                    "title": {
                        "value": "More atari results"
                    },
                    "comment": {
                        "value": "We were able to run our approach on 4 more atari games\n\n| Game           | Model             | Returns              |\n|----------------|-------------------|----------------------|\n| Crazy Climber  | DT                | 76564.0+/-24713.859  |\n|                | DT + SA           | 51490.0+/-28676.178  |\n|                | DT + SA + Cyclic  | **94254.0+/-7569.641**|\n| BankHeist      | DT                | 11.4+/-6.974          |\n|                | DT + SA           | 105.0+/-88.808       |\n|                | DT + SA + Cyclic  | **144.8+/-116.68**    |\n| Space Invaders | DT                | **602.2+/-67.972**       |\n|                | DT + SA           | 392.0+/-189.67       |\n|                | DT + SA + Cyclic  | 598.2+/-52.147   |\n| MsPacman       | DT                | 1461.4+/-329.76      |\n|                | DT + SA           | 1220.8+/-237.301     |\n|                | DT + SA + Cyclic  | **1900.0+/-206.364** |\n\nWe can see that here also in 3/4 games DT + SA + Cyclic is the best performing model. Even in space invaders, where DT + SA + Cyclic performs worse than DT, we find that the performance of both the models is actually quite comparable.\n\nIn total, we have run our approach on 13 atari games and find that it outperforms the baseline 10/13 games."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8392/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700485771345,
                "cdate": 1700485771345,
                "tmdate": 1700489443411,
                "mdate": 1700489443411,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]