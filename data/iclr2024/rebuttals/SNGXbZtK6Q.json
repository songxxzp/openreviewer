[
    {
        "title": "Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization"
    },
    {
        "review": {
            "id": "q08EMQvIMe",
            "forum": "SNGXbZtK6Q",
            "replyto": "SNGXbZtK6Q",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission577/Reviewer_iXGU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission577/Reviewer_iXGU"
            ],
            "content": {
                "summary": {
                    "value": "The study focuses on the issue of out-of-distribution (OOD) in neural networks by examining the activity of neurons. A notion termed as \"neuron activation coverage\" (NAC) is introduced to describe the operation of neurons under in-distribution (ID) and OOD data. The researchers utilize NAC to attain good OOD detection results and demonstrate a positive association between NAC and the capacity of model generalization. Models that are more robust are chosen through the NAC-based standard and it presents a higher correlation with OOD test outcomes compared to conventional validation standards."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The holistic approach of tackling both OOD detection and generalization issues concurrently is not only commendable but also crucial. \n\n2. The meticulous evaluation, inclusive of visualization and ablation study, is praiseworthy. This level of precision in assessment bolsters the understanding of the research outcomes and solidifies the integrity and robustness of the findings."
                },
                "weaknesses": {
                    "value": "1. The introduction contains some issues: The methods like ASH, React do not negatively impact the ID accuracy. The model can employ an unchanged classifier for the ID task, which only introduces a negligible computational cost. \n\n2. The motivation is somewhat perplexing: The author suggests that OOD is more prone to activate neurons with lower activation frequency. However, this paper fails to provide empirical evidence to back up this assertion.\n\n3. Also, I think that the confusion between OOD and ID images stems from the fact that OOD images can potentially activate the same neurons as ID images. How does the author's approach works in such a scenario? It would be beneficial for the author to include near-ood experiments [1] to enhance the comprehensiveness of the study.\n\n4. The performance of NAC-UE, as depicted in Tables 1 and 2, is not consistent and competitive across all OOD datasets, indicating a considerable bias in its effectiveness on different OOD datasets. For example, when CIFAR100 is used as ID and Places365 as OOD, NAC-UE only yields a 73.05% AUROC and 73.57 FPR95.\n\n5. The author has overlooked a discussion on a comparable study [2].\n\n[1]  Fort, Stanislav, Jie Ren, and Balaji Lakshminarayanan. \"Exploring the limits of out-of-distribution detection.\" Advances in Neural Information Processing Systems 34 (2021): 7068-7081.\n\n[2] Bai, Haoyue, et al. \"Feed two birds with one scone: Exploiting wild data for both out-of-distribution generalization and detection.\"\u00a0International Conference on Machine Learning. PMLR, 2023."
                },
                "questions": {
                    "value": "The absence of open-source code is a setback as it impedes the reproducibility and validation of the results presented in the study."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission577/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission577/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission577/Reviewer_iXGU"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission577/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697536816955,
            "cdate": 1697536816955,
            "tmdate": 1700623355069,
            "mdate": 1700623355069,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "m1XzrBOVLo",
                "forum": "SNGXbZtK6Q",
                "replyto": "q08EMQvIMe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission577/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission577/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you; justifications and new near-ood experiments [1/3]"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for dedicating your time and effort to reviewing our paper. We are glad that you find our approach holistic and evaluation meticulous. We carefully considered your suggestions and conducted additional experiments to improve our paper. Please find our point-to-point responses below.\n\n---\n\n**Q1:** The introduction contains some issues: The methods like ASH, React do not negatively impact the ID accuracy. The model can employ an unchanged classifier for the ID task, which only introduces a negligible computational cost.\n\n**A1:** We apologize for the confusion. In practice, our claim that \"ASH, ReAct decrease the model classification ability\" is referred from the ASH paper [R1], where they clearly state that ReAct and their ASH methods lead to InD accuracy drops due to pruning. We would like to invite the reviewer to check **Figure 2 in ASH paper** [R1] for the details.\n\n[R1] Extremely Simple Activation Shaping for Out-of-Distribution Detection. ICLR, 2023. https://openreview.net/pdf?id=ndYXTEL6cZz \n\nDespite the above clarification, we do agree with the reviewer that using an unchanged classifier can be an efficient solution. However, it is also important to recognize that the success of **this solution hinges on the strict assumption that only later layers are utilized by neuron pruning**. This restricted perspective may largely limit the potential of neuron-based methods, since shallow layers also offer valuable information, as demonstrated in Table 4 of our paper. Therefore, it is imperative to approach this solution with caution and careful consideration. \n\nTo further address your concern, **we have added a footnote in our Introduction** to clarify this point: \"While it may be argued that maintaining neuron outputs for double-propagation preserves InD accuracy with low computational cost,  it relies on the assumption that only later layers are utilized in neuron pruning, thus undermining the potential of these neuron-based methods.\"\n\nLastly, we would also like to remind the reviewer that our **NAC-UE significantly outperforms ReAct and ASH on three benchmarks**. For your convenience, we provide their averaged AUROC results below. The scores are sourced from our Table 1 and 2, where ReAct and ASH are officially implemented by OpenOOD.\n\n|| ReAct     | ASH   | NAC-UE | \n|----|---|----|---|\n| CIFAR-10  | 90.42 | 78.49  | **94.60** |\n| CIFAR-100 | 80.39 | 80.58  | **86.98** |\n| ImageNet  | 89.68 | 73.65  | **94.22** |\n\n[To be continued]"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700203874991,
                "cdate": 1700203874991,
                "tmdate": 1700203874991,
                "mdate": 1700203874991,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MGCoBPKG2k",
                "forum": "SNGXbZtK6Q",
                "replyto": "bNWYHAqwEA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission577/Reviewer_iXGU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission577/Reviewer_iXGU"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you to the author for the detailed response, which has cleared up most of my doubts, though some questions remain:\n* The use of an unchanged classifier for ID classification tasks is clearly stated in DICE and ReAct's original papers. I also notice the expression in ASH Figure 2. However, in reading various post-hoc OOD detection method articles, it's common to find claims that one objective of OOD detection is to maintain ID classification performance unchanged [1]. Hence, I suggest the author should be cautious about considering a decline problem in ID classification accuracy as the motivation.\n* As for the performance issue, I suggest the author provide explanations for the poor performance on certain OOD datasets. Notably, NAC evidently excels in small-scale datasets (like CIFAR) compared to the large-scale benchmarks, potentially indicating some limitations of the NAC method. Additionally, when using CIFAR100 as ID and Places365 as OOD, NAC-UE achieves only 73.05% AUROC and 73.57 FPR95. It would be beneficial to explain why NAC-UE underperforms on Places365.\n\nOverall, I will raise my score.\n\n[1] Yang, Jingkang, et al. \"Generalized out-of-distribution detection: A survey.\"\u00a0arXiv preprint arXiv:2110.11334\u00a0(2021)."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700623339945,
                "cdate": 1700623339945,
                "tmdate": 1700623339945,
                "mdate": 1700623339945,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "OsHkg1wES5",
            "forum": "SNGXbZtK6Q",
            "replyto": "SNGXbZtK6Q",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission577/Reviewer_sJ3q"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission577/Reviewer_sJ3q"
            ],
            "content": {
                "summary": {
                    "value": "This paper propose a new metric named neuron activation coverage (NAC) to quantify the out-of-distribution. It uses neuron behaviors to quantify data distribution. It extends from original raw neuron output, models the neuron influence with combine neuron output with gradient from KL divergence of network output and a uniform vector. It is a simple metric while achieve SOTA results compared to previous methods on three benchmarks. It also shows correlation with generation, and could be used as a metric to quantify the robustness of model, and also correlate with OOD test performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Method:\n\n1. Combine neuron output with gradient from KL divergence of network output and a uniform vector is a novel contribution and well-motivated approach, and it is simple while shows effective results.\n2. It preserves more information in a continuous fashion, without discretizing it to become binary values compared to previous approach. \n3. The measurement is further extended for uncertainty estimation for test samples with using average of all neurons.\n\nEvaluation:\n1. The method demonstrates its soundness on multiple benchmarks and outperforms existing SOTA.\n2. Multiple ablation studies are performed.\n3. Guidance and decisions of hyper parameters choice is discussed.\n\nWriting:\n1. The paper is well-organized, and the presentation is in good structure."
                },
                "weaknesses": {
                    "value": "Time complexity:\n\n1. Given the time-consuming process of using KL gradient, computational cost of proposed method with other SOTA should be reported.\n\nEvaluation:\n\n1. The proposed metric is extended for uncertainty estimation, while no quantification or evaluation (calibration of uncertainty) on this dimension."
                },
                "questions": {
                    "value": "1. How does the choice of rank correlation instead Pearson correlation might affect the results?\n\n2. How does this metric generalized to regression problems?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "n/a"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission577/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission577/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission577/Reviewer_sJ3q"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission577/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698737200124,
            "cdate": 1698737200124,
            "tmdate": 1699635985094,
            "mdate": 1699635985094,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7RSh4tdA8G",
                "forum": "SNGXbZtK6Q",
                "replyto": "OsHkg1wES5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission577/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission577/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you; new experiments and explanations [1/2]"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for dedicating your time and effort to reviewing our paper. We sincerely appreciate your positive remarks regarding the writing, novelty of the method, motivation, and robustness of our evaluations. We carefully considered your suggestions and conducted additional experiments to improve our paper. Please find our point-to-point responses below.\n\n---\n\n**Q1:** Given the time-consuming process of using KL gradient, computational cost of proposed method with other SOTA should be reported.\n\n**A1:** Thanks for your valuable comment! Following your suggestion, we have conducted a series of experiments to analyze the efficiency of our method. To provide a comprehensive comparison, we selected the top-3 performed methods from Table 2 as baselines, and compared them with our NAC-UE in terms of preprocessing and inference time on ImageNet. For consistency, we used the same software and hardware configurations as in our previous experiments, which are detailed in Appendix F.\n\n|| Preprocessing Time (s)| Total Inference Time (s) | AUROC\u2191| \n|---|---|---|---|\n| GEN *(CVPR' 2023)* | 0.00 \u00b1 0.0 | 43.33 \u00b1 0.3\t| 89.76 |\n| ViM *(CVPR' 2022)*  | 1087.82 \u00b1 9.0 | 48.10 \u00b1 0.4 | 92.68 |\n| SHE *(ICLR' 2023)* | 1019.34 \u00b1 2.2 | 41.85 \u00b1 0.5 | 90.92 |\n| NAC-UE (layer4) | 5.43 \u00b1 0.3 | **39.63** \u00b1 0.2 | 94.57 |\n| NAC-UE (layer4+layer3)  | 6.75 \u00b1 0.3  | 46.09 \u00b1 0.7 | 95.05 |\n| NAC-UE (layer4+layer3+layer2) | 7.75 \u00b1 0.2  | 69.73 \u00b1 0.4 | **95.23** |\n\n\nFrom the above results, the following observations can be made:\n\n1) While NAC-UE requires more inference time as more layers are considered, **it significantly reduces preprocessing time compared to ViM and SHE**, e.g., 7.75s (NAC-UE) vs. 1019.34s (ViM). This finding coincides with our previous experiments (Appendix G.1), where we show that NAC-UE achieves favorable performance despite utilizing only 1% of the training data for NAC modeling.\n\n2) Remarkably, even when utilizing just a single layer (layer4), **NAC-UE outperforms SoTA methods in terms of both inference time and detection performance**. For example, NAC-UE achieves an AUROC of 94.57 (39.63s inference time), whereas GEN achieves only 89.76 on AUROC with 43.33s inference time. This highlights the efficiency of our approach.\n\nAdditionally, it is also worth noting that there are numerous ongoing research efforts dedicated to facilitating gradient calculation [R1, R2], which could potentially complement our proposed method. We will include the above experiments in Appendix G.\n\n[R1] Low Complexity Gradient Computation Techniques to Accelerate Deep Neural Network Training, TNNLS, 2021.\\\n[R2] Acceleration of DNN Backward Propagation by Selective Computation of Gradients, DAC, 2019. \n\n---\n\n**Q2:** The proposed metric is extended for uncertainty estimation, while no quantification or evaluation (calibration of uncertainty) on this dimension.\n\n**A2:** We are so sorry for the confusion. In line with many prevalent OOD uncertainty estimators (e.g., Gram [R3], ReAct [R4], MOS [R5]), our uncertainty estimation mainly serves for OOD detection problems: _predicting whether a test sample is from OOD or not_. Thus, our experiments primarily emphasize OOD detection performance rather than calibration errors, similar to the aforementioned studies.\n\nIn response to your suggestions, **we have conducted additional experiments to further explore the potential of our NAC-UE**. Our experiments carefully align with [R6], where two calibration error measures (RMS and MAD) are employed. For the calibration evaluation, we utilized a pretrained model on the CIFAR-10 dataset as the foundation, and assessed the calibration errors on both InD and OOD test data. We mainly compare NAC-UE with two simple baselines: MSP (Hendrycks & Gimpel, 2017) and Temperature (Guo et al., 2017). \n\n|OOD Dataset| | RMS\u2193 ||| MAD\u2193 ||\n|---|---|---|---|---|---|---|\n|  | MSP| Temp | NAC-UE | MSP | Temp | NAC-UE |\n| CIFAR100| 50.62 | 43.01 | **33.04** | 42.56| 36.64  | **26.92** |\n| Tiny ImageNet | 48.01 | 40.25 | **31.99** | 38.86| 32.88  | **26.25** |\n| MNIST | 71.74  | 60.91| **51.30** | 67.81 | 57.16  | **49.45** |\n| SVHN  | 65.82 | 56.41| **45.32** | 59.57 | 51.05  | **41.60** |\n| Texture | 42.65 | 35.19 | **28.74** | 32.37| 26.90  | **23.72** |\n| Places365 | 68.85 | 59.67  | **48.65** | 64.65  | 56.02  | **45.33** |\n\nFrom the above results, we can see that our NAC-UE significantly outperforms two baseline approaches, which demonstrates its potential in prediction calibration. We will include the above experiments in Appendix G.\n\n[R3] On the Importance of Gradients for Detecting Distributional Shifts in the Wild. NeurIPS, 2021\\\n[R4] ReAct: Out-of-distribution Detection With Rectified Activations. NeurIPS, 2021\\\n[R5] MOS: Towards Scaling Out-of-Distribution Detection for Large Semantic Space. CVPR, 2021\\\n[R6] Deep Anomaly Detection with Outlier Exposure. ICLR, 2019\n\n[To be continued]"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700203441632,
                "cdate": 1700203441632,
                "tmdate": 1700203441632,
                "mdate": 1700203441632,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "54ZZx6vmH6",
                "forum": "SNGXbZtK6Q",
                "replyto": "OsHkg1wES5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission577/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission577/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you; new experiments and explanations [2/2]"
                    },
                    "comment": {
                        "value": "---\n\n**Q3:** How does the choice of rank correlation instead Pearson correlation might affect the results?\n\n**A3:** Great question! The choice between rank correlation (RC) and Pearson correlation (PC) can have an impact on the results. More specifically, as supported by [R7], **RC is more suited to our situations**.\n \nRC measures the **monotonic relationship** between two variables, while PC assesses the **linear relationship**. In our situations where the target is to select the best model based on InD evaluation criteria, the monotonic relationship becomes crucial [R7].\nTo gain a clearer understanding, let's consider the following example:\n\nA (Test Accuracy): [0, **0.7**, 0.6, 0.5];  \nB ( Val. Accuracy): [0, 0.8, 0.8, **0.9**],\n\nHere, sets A and B consist of test and validation accuracy at each epoch, respectively. PC between A and B is 0.93, while RC is 0.3. \nIf we rely on PC, we might conclude that validation accuracy is highly correlated with test performance, and safely choose the best model with the highest validation accuracy (0.9). However, such a model only achieves a test accuracy of 0.5, contradicting our expectations. This example highlights the limitation of PC in our scenario, where the linear relationship could be misleading.\n\nIn addition to the above toy example, **we have also conducted an analysis by measuring PC on Vit-b16 model**. As exhibited below, results mostly show surprisingly high PC values, i.e., 0.98/0.99 on three datasets. This contrasts sharply with our RC results in Table 8, where RC is hardly larger than 0.5. As the performance gap between the oracle-selected and validation-selected/NAC-selected model consistently exists, this again leads to the deduction that Pearson correlation is not as suitable as rank correlation in our situations.\n\n|| VLCS   | PACS  | OfficeHome | TerraInc |\n|----|----|----|----|----|\n| InD Val. vs. OOD Test ACC | 0.994 | 0.983      | 0.999          | 0.866 |\n| InD NAC-ME vs. OOD Test Acc    | 0.995 | 0.983      | 0.999          | 0.893 |\n\n[R7] Ensemble of Averages: Improving Model Selection and Boosting Performance in Domain Generalization. NeurIPS 2022.\n\n---\n\n**Q4:** How does this metric generalized to regression problems?\n\n**A4:** Thank you for this insightful question. Our proposed metric NAC, which focuses on neuron distributions, can indeed be generalized to regression problems without any changes to its definition. The only update required is about the formulation of neuron states. Since the current formulation involves KL divergence which is not suitable for regression problems, we need to simplify the neuron states from $ z \\odot g'(z) (p-u)$ to $ z \\odot g'(z) $. This simplified version corresponds to the Input $\\times$ Gradient explanation, which is also meaningful in explaining neuron behaviors and provides insights into the model status."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700203707034,
                "cdate": 1700203707034,
                "tmdate": 1700375241158,
                "mdate": 1700375241158,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nF08aLHsiQ",
                "forum": "SNGXbZtK6Q",
                "replyto": "54ZZx6vmH6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission577/Reviewer_sJ3q"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission577/Reviewer_sJ3q"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the authors' clarifications and efforts to add new experiment results. Most of my concerns are well addressed. I maintain my original recommendation of acceptance."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700692863216,
                "cdate": 1700692863216,
                "tmdate": 1700692863216,
                "mdate": 1700692863216,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "RKChnUJxm5",
            "forum": "SNGXbZtK6Q",
            "replyto": "SNGXbZtK6Q",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission577/Reviewer_pybD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission577/Reviewer_pybD"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses the out-of-distribution (OOD) problem in neural networks, which occurs when the encountered data significantly deviates from the training data distribution (in-distribution, InD). The authors approach the OOD problem by studying neuron activation states, considering both the output of the neuron and its influence on model decisions. They introduce a measure called neuron activation coverage (NAC) to characterize the relationship between neurons and OOD issues under InD data.\n\nBy leveraging NAC, the authors demonstrate two key findings. Firstly, they show that InD and OOD inputs can be effectively separated based on neuron behavior. This separation greatly simplifies the OOD detection problem and outperforms 21 previous methods across three benchmark datasets (CIFAR10, CIFAR-100, and ImageNet-1K). Secondly, they observe a consistent positive correlation between NAC and model generalization ability across different architectures and datasets. This correlation enables the use of NAC as a criterion for evaluating model robustness. In comparison to prevalent InD validation criteria, the authors demonstrate that NAC not only selects more robust models but also exhibits a stronger correlation with OOD test performance.\n\nOverall, the paper proposes a novel approach to the OOD problem by studying neuron activation states and introducing NAC as a measure. The findings highlight the effectiveness of NAC in separating InD and OOD inputs, as well as its potential for evaluating model robustness."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Novel approach: The paper introduces a fresh perspective on addressing the OOD problem by studying neuron activation states and proposing the concept of neuron activation coverage (NAC). This approach offers a new and innovative methodology for tackling the OOD problem, contributing to the advancement of the field.\n\nEffective separation of InD and OOD inputs: The paper demonstrates that the proposed neuron behavior-based approach, leveraging NAC, can effectively separate InD and OOD inputs. This separation significantly eases the OOD detection problem and outperforms 21 previous methods across multiple benchmark datasets. The ability to accurately distinguish between InD and OOD inputs is crucial for improving the reliability and robustness of neural networks.\n\nConsistent correlation with model generalization ability: The authors observe a consistent positive correlation between NAC and model generalization ability across different architectures and datasets. This correlation indicates that NAC can serve as a reliable criterion for evaluating model robustness. By considering neuron activation behaviors, NAC provides valuable insights into the model's ability to generalize well beyond the training distribution, facilitating OOD generation. \n\nPractical applicability: The proposed approach holds promise for real-world applications. By focusing on neuron activation states, the method does not require modifications to the neural network architecture, making it easily implementable in existing systems. Furthermore, the demonstrated effectiveness of NAC in separating InD and OOD inputs across different benchmark datasets reinforces its potential for diverse application scenarios."
                },
                "weaknesses": {
                    "value": "The definitions of OOD are different for OOD Detection and OOD Generalisation. From my view, the former focuses on the semantic shift and the latter focuses on the covariate shift. Such a difference may raise two problems. First, it seems better if the authors could discern OOD in detection and generalisation, with further discussion and detailed definition. Second, why the purposed method, i.e., NAC, can handle both of these two cases. Heuristically, the proposed method is motivated by previous works in OOD detection (i.e., using gradient information), so why it is also applicable for OOD generalization. \n\nThere are many dimensions that are useless, and even worse, components/directions [1], instead of individual elements, can model the contribution of model outputs in making prediction. It means that there may exist misleading information and redundant message when using NAC to compute the activated rates, of which the performance cannot be guaranteed, at least from my personal view. \n\nWhen it comes to OOD generalization, the authors suggest use NAC-based learning objective to improve OOD performance. It seems that it just makes the embedding features to be sparse, which has been discussed in previous works in OOD generalization, such as [2]. Moreover, the gradient-based learning objective can be computational hard, since the second order gradients are needed to be computed in each optimisation step. \n\nDetailed discussion about the hyper parameter setups should be given, especially for the hyper parameter tuning. More ablation studies should  be given to test the respective power of z \\times g'(z) and p-u.\n\n[1] Intriguing Properties of Neural Networks\n\n[2] Sparse Invariant Risk Minimisation."
                },
                "questions": {
                    "value": "please see the weaknesses above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission577/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission577/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission577/Reviewer_pybD"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission577/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698817257463,
            "cdate": 1698817257463,
            "tmdate": 1700700158709,
            "mdate": 1700700158709,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5u8poB08Av",
                "forum": "SNGXbZtK6Q",
                "replyto": "RKChnUJxm5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission577/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission577/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you; new experiments and justifications [1/2]"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for dedicating your time and effort to reviewing our paper. We are glad that you think our method is novel, effective, and practically applicable. We took your suggestions very carefully, and have conducted additional experiments to update our paper. \n\n**Clarification:** Before diving into detailed responses, we hope to firstly clarify one fundamental aspect of our NAC, which seems misunderstood by the reviewer. That is, **our NAC-based methods all operate in a post-hoc fashion, which do not involve any training process**. Specifically, for OOD generalization, our NAC-ME is designed to assess model robustness for the purpose of best model selection, rather than directly improving OOD performance through optimization.\n\n---\n\n**Q1:** The definitions of OOD are different for OOD Detection and OOD Generalisation...... so why it is also applicable for OOD generalization.\n\n**A1:** Thank you for this insightful comment. The response to your valuable question can be three-fold:\n\n1) **The overlap between OOD detection and generalization exists**: While we agree with the reviewer that OOD detection/generalization mainly centers on semantic shift/covariate shift, the overlap between these two problems indeed exists. Previous studies have also explored covariate shift for OOD detection [R1, R2, R6], as well as semantic shift for OOD generalization [R3, R4]. Given such situations, it seems **less suitable if we consider these two problems as entirely separate**. We will include a discussion section in Appendix H. \n\n2) **NAC benefits from data-centric modeling (Reason 1)**: Our NAC method is rooted in a data-centric approach, leveraging the neuron distributions within InD training data to characterize model status. This data-centric modeling enables NAC to effectively capture the intrinsic patterns and characteristics of the model (i.e., from a neuron level), thus serving as an effective tool for model robustness evaluation (i.e., applicable to OOD generalization). This also aligns with the principles of network quality assessment in system testing [R5].\n\n3) **Shallow to deep layers account for covariate and semantic shifts (Reason 2)**: As noted by [R6], shallow layers in models often closely correlate with the image style information (*covariate* level), while deep layers capture *semantic* information. Since our NAC often works by leveraging multiple layers spanning from shallow to deep, it naturally accounts for both covariate and semantic shifts.\n\n[R1] Exploring Covariate and Concept Shift for Detection and Calibration of Out-of-Distribution Data. NeurIPS workshop, 2021.\\\n[R2] Unified Out-Of-Distribution Detection: A Model-Specific Perspective. ICCV, 2023\\\n[R3] Overcoming Concept Shift in Domain-Aware Settings through Consolidated Internal Distributions. AAAI, 2023\\\n[R4] NICO++: Towards Better Benchmarking for Domain Generalization. CVPR 2023\\\n[R5] NPC: Neuron Path Coverage via Characterizing Decision Logic of Deep Neural Networks. ACM Trans. Softw. Eng. Methodol. 2022.\\\n[R6] Full-Spectrum Out-of-Distribution Detection. IJCV, 2023.\n\n---\n\n**Q2:** There are many dimensions that are useless, and even worse......there may exist misleading information and redundant message when using NAC to compute the activated rates, of which the performance cannot be guaranteed.....\n\n**A2:** We appreciate this valuable comment, and concur with the reviewer regarding the possible redundancy and noise in multiple dimensions/neurons. Nonetheless, it is still worth noting that there are also **numerous neurons that are meaningful** and can encode significant information [R7, R8]. This observation underscores the viability of neuron-based methods (which is also supported by our Figure 4 and 5).\n\nOn the other hand, our **NAC method actually goes beyond considering individual neurons alone**. It models the neuron distributions on InD data, and leverages averaged statistics of neuron behavior to reflect model status. This also aligns with the widely adopted statistical method in many network testing methods (e.g., [R9, R10]), which allows for the modeling of more abundant information.\n\nDespite the above clarification, we do acknowledge that filtering noisy neurons in NAC-based methods can be a viable strategy to further improve the performance. But we still want to remind the reviewer that **our NAC method has already demonstrated strong results** on three benchmarks for OOD detection (i.e., outperforming 21 baselines), and four datasets for OOD generalization. This has showcased the effectiveness and robustness of our approach.\n\n\n[R7] Understanding the role of individual units in a deep neural network. PNAS, 2020\\\n[R8] Interpreting Deep Visual Representations via Network Dissection. TPAMI, 2018\\\n[R9] DeepGauge: Multi-Granularity Testing Criteria for Deep Learning Systems. ASE, 2018\\\n[R10] DeepXplore: Automated Whitebox Testing of Deep Learning Systems. SOSP, 2017\n\n[To be continued]"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700203096536,
                "cdate": 1700203096536,
                "tmdate": 1700203096536,
                "mdate": 1700203096536,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TZX3WXEVLD",
                "forum": "SNGXbZtK6Q",
                "replyto": "RKChnUJxm5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission577/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission577/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you; new experiments and justifications [2/2]"
                    },
                    "comment": {
                        "value": "---\n\n**Q3:** When it comes to OOD generalization, the authors suggest use NAC-based learning objective to improve OOD performance. It seems that it just makes the embedding features to be sparse, which has been discussed in previous works in OOD generalization, such as [2]. Moreover, the gradient-based learning objective can be computational hard, since the second order gradients are needed to be computed in each optimisation step. \n\n**A3:** We are so sorry for the confusion. As we clarified earlier, our NAC-based method specifically targets the evaluation of model robustness for OOD generalization, which actually does not involve optimization processes. Thus, **we do not need to calculate 2nd-order gradients**, which saves computational cost. \n\nOn the other hand, NAC also differs from [2] in the following aspects: \n\n1) As noted, unlike the approach in [2] which concentrates on refining model training, our NAC focuses on the evaluation of existing models, thus providing a different perspective.\n\n2) Drawing parallels with system testing coverage criteria, **NAC tracks neuron behaviors in the whole network**. In contrast, feature sparsity, as addressed in [2], is primarily concerned with feature representation, specifically identifying areas where most features are zero or irrelevant. Hence, these two methods differ in their measurement and targets.\n\nWe will cite [2] and add a discussion in Appendix H.\n\n[2] Sparse Invariant Risk Minimisation. ICML, 2022\n\n\n---\n\n**Q4:** Detailed discussion about the hyper parameter setups should be given, especially for the hyper parameter tuning. More ablation studies should be given to test the respective power of z \\times g'(z) and p-u.\n\n**A4:** Thank you for this valuable comment. In practice, our **Appendix D.4 and E.4 have already provided the details for all employed hyperparameters**. \n\nTo further address your concern, **we have added more ablation studies** to analyze the respective power of z, g'(z), and p-u. We provided the results on ImageNet below. Firstly, it can be drawn that z\\*g'(z)\\*(p-u) does perform best among all variants of formulations, showing its superiority. \nMoreover, arbitrary combinations of z, g'(z), and p-u can lead to improvements compared to using a single component alone. For instance, utilizing z*(p-u) yields better performance than using either z or p-u in isolation.\nThese findings suggest that all three components encode meaningful information in OOD scenarios, further supporting the rationale behind our proposed neuron states. We will include these experiments in Appendix G.\n\n\n |Formulation | z | g'(z) | p-u | FPR95\u2193 | AUROC\u2191 | \n|---|---|:-:|---|---|---|\n| z | \u2714 |  | |45.7  | 89.42 | \n| g'(z)   | | \u2714  | |84.2  | 64.13 | \n| p-u  || | \u2714|59.39 | 80.96 | \n| z*g'(z)  | \u2714| \u2714  | |43.43 | 88.9  |\n| g'(z)*(p-u) || \u2714 | \u2714  |49.29 | 87.85 |\n| z*(p-u) | \u2714| | \u2714|44.71 | 89.47 | \n| z\\*g'(z)\\*(p-u) | \u2714 | \u2714 | \u2714  | **26.89** | **94.57** |"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700203203247,
                "cdate": 1700203203247,
                "tmdate": 1700208684945,
                "mdate": 1700208684945,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "woEpYuqDP3",
                "forum": "SNGXbZtK6Q",
                "replyto": "TZX3WXEVLD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission577/Reviewer_pybD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission577/Reviewer_pybD"
                ],
                "content": {
                    "title": {
                        "value": "Many thanks for the response"
                    },
                    "comment": {
                        "value": "The authors more or less address my concerns, and I would like to raise my score to 6."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700700136696,
                "cdate": 1700700136696,
                "tmdate": 1700700136696,
                "mdate": 1700700136696,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qMIsDsYbm3",
            "forum": "SNGXbZtK6Q",
            "replyto": "SNGXbZtK6Q",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission577/Reviewer_xpKd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission577/Reviewer_xpKd"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces the concept of neuron activation coverage (NAC) to characterize neuron behaviors under in-distribution (InD) and out-of-distribution (OOD) data. The key idea is to quantify the coverage degree of neuron activation states using training data, such that rarely covered states likely contain defects that could lead to poor OOD performance. The authors formulate neuron states by combining raw outputs and KL divergence gradients, and model coverage through a probability density function. NAC is applied to improve OOD detection via uncertainty estimation (NAC-UE), and OOD generalization through model evaluation (NAC-ME). Experiments demonstrate state-of-the-art OOD detection results on CIFAR and ImageNet benchmarks. NAC-ME also shows favorable correlation with OOD test accuracy for model selection."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* Novel perspective of leveraging neuron coverage to reflect OOD issues. This is intuitive and well-motivated through the analogy to software testing.\n* Simple yet effective formulation of neuron activation states and coverage function.\n* Improvements over strong baselines across multiple datasets and tasks. NAC-UE sets new state-of-the-art results while preserving model accuracy."
                },
                "weaknesses": {
                    "value": "* For NAC-UE uncertainty estimation, the paper averages coverage scores across layers when applying to multiple layers. Is it possible to weight the contribution of different layers especially given that earlier layers tend to be more general?\n* Missing a related work that shares a similar motivation of leveraging neuron behaviors. [1] uses neural mean discrepancy of neuron activations for OOD detection. Discussing relations to such works could provide additional insights.\n\n[1] Dong, Xin, et al. \"Neural mean discrepancy for efficient out-of-distribution detection.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022"
                },
                "questions": {
                    "value": "* Is it possible to directly train or regularize models based on NAC to improve robustness. For example, one could minimize the entropy of NAC distributions to encourage balanced coverage. Evaluating such NAC-driven training schemes could further validate its usefulness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission577/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission577/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission577/Reviewer_xpKd"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission577/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698820163114,
            "cdate": 1698820163114,
            "tmdate": 1700626805382,
            "mdate": 1700626805382,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Jg85vmNHm9",
                "forum": "SNGXbZtK6Q",
                "replyto": "qMIsDsYbm3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission577/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission577/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you; new experiments and discussions"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for dedicating your time and effort to reviewing our paper. We are glad that you think our method is well-motivated and presents strong improvements. We took your suggestions very seriously, and have conducted additional experiments to update our paper. Please see below for our point-to-point responses.\n\n---\n\n**Q1:** For NAC-UE uncertainty estimation, the paper averages coverage scores across layers when applying to multiple layers. Is it possible to weight the contribution of different layers especially given that earlier layers tend to be more general?\n\n**A1:** Nice suggestion! Inspired by your question, we have conducted a series of experiments on the CIFAR-10 benchmark, where we randomly searched the weight for each layer within the same space: [0.2, 0.4, 0.6, 0.8, 1.0]. We found that our **NAC-UE can be further improved in this weighted version** (e.g., 2.47% gain on average FPR):\n\n|  |   MNIST  || SVHN         || Textures     || Places365    || Average  ||              \n|------|---|--------|------|------|--------|-----|-----|-------|----|-----|\n|                       | FPR\u2193               | AUROC\u2191          | FPR\u2193          | AUROC\u2191          | FPR\u2193         | AUROC\u2191          | FPR\u2193          | AUROC\u2191          | FPR\u2193          | AUROC\u2191          | \n| NAC-UE            | 15.14 \u00b1 2.60 | 94.86 \u00b1 1.36 | 14.33 \u00b1 1.24 | 96.05 \u00b1 0.47 | 17.03 \u00b1 0.59 | 95.64 \u00b1 0.44 | 26.73 \u00b1 0.80 | 91.85 \u00b1 0.28 | 18.31 \u00b1 0.92 | 94.60 \u00b1 0.50 |\n| NAC-UE (weighted) | 13.94 \u00b1 2.42 | 95.55 \u00b1 1.08 | 9.90 \u00b1 1.09  | 98.10 \u00b1 0.18 | 13.36 \u00b1 0.65 | 97.25 \u00b1 0.21 | 26.16 \u00b1 0.79 | 92.31 \u00b1 0.26 | 15.84 \u00b1 0.65 | 95.80 \u00b1 0.24 |\n\nWhat's interesting is that we noticed assigning larger weights to the deeper layers often results in better performance. We conjecture this is due to that deeper layers often encode richer semantic information than shallow layers, making them crucial in detection problems. We will include such experiments in Appendix G. \n\n---\n\n**Q2:** Missing a related work that shares a similar motivation of leveraging neuron behaviors. [1] uses neural mean discrepancy of neuron activations for OOD detection. Discussing relations to such works could provide additional insights.\n\n**A2:** Thank you for pointing out the missed related work. We will cite the paper and add a discussion section in Appendix H. Here are the main differences outlined:\n1)  [1] primarily investigates the raw neuron output, while **our paper centers on a new formulation of neuron states**. This formulation can be decoupled as the neuron gradients, neuron output, and model prediction deviations, thus offering a fresh interpretation of neurons in OOD scenarios.\n2) Our NAC specifically focuses on the **distribution** of neuron states, while [1] mainly examines the **mean** of neuron output. This distinctive perspective makes our NAC more comprehensive and superior in understanding neuron behaviors. \n3) While Neural Mean Discrepancy [1] may effectively detect OOD samples, it requires an additional classifier during the inference phase. Instead, NAC directly calculates the coverage scores in a **parameter-free** manner, serving as an efficient measure for both OOD detection and generalization. \n\n[1] Dong, Xin, et al. \"Neural mean discrepancy for efficient out-of-distribution detection.\" CVPR, 2022\n\n---\n\n**Q3:** Is it possible to directly train or regularize models based on NAC to improve robustness. For example, one could minimize the entropy of NAC distributions to encourage balanced coverage. Evaluating such NAC-driven training schemes could further validate its usefulness.\n\n**A3:** Yes, it is possible! Based on your suggestion, we have tried to regularize the model using our NAC entropy loss: \n$H(\\mathbf{z})= -\\sum_{i=1}^{N}p_i(z_i) \\log{p_i(z_i)}$, where $p_i$ associates with the NAC distribution of $i$-th neuron.  We conducted experiments on the PACS dataset, and the results are shown below:\n\n|| Art      | Cartoon     | Photo       | Sketch      | Average     |\n|----|---|----|-----|----|----|\n| ERM| 77.32 \u00b1 0.7 | 71.91 \u00b1 0.7 | 72.36 \u00b1 1.1 | 94.44 \u00b1 0.2 | 79.01 |\n| ERM+NAC (Minimizing Entropy)| 77.28 \u00b1 0.2 | 69.17 \u00b1 0.2 | 66.73 \u00b1 1.2 | 93.21 \u00b1 0.2 | 76.60 |\n| ERM+NAC (Maximizing Entropy)| 78.64 \u00b1 0.5 | 72.97 \u00b1 0.3 | 72.39 \u00b1 0.3 | 95.09 \u00b1 0.1 | 79.77 |\n\n\nInterestingly, **we find that maximizing NAC entropy leads to improved performance**. This finding also aligns with the intuitive understanding presented in [2]. By maximizing NAC entropy, we encourage the activation of neurons in unexplored regions over NAC distribution, thus diversifying the neuron activities and improving the model robustness. Conversely, minimizing entropy may result in collapsed neuron behavior. We will include the above experiments in Appendix G. \n\n[2] Dubey, Abhimanyu, et al. \"Maximum-Entropy Fine-Grained Classification\". NeurIPS 2018."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700202955776,
                "cdate": 1700202955776,
                "tmdate": 1700202955776,
                "mdate": 1700202955776,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "a4u1unh4Zl",
                "forum": "SNGXbZtK6Q",
                "replyto": "Jg85vmNHm9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission577/Reviewer_xpKd"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission577/Reviewer_xpKd"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the experiments and discussion from the authors. \nIt is interesting to see that NAC-UE can be further improved in weighted version and NAC entropy leads to improved performance. \nThese results make the work stronger. \nI would like to raise my score."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700626775807,
                "cdate": 1700626775807,
                "tmdate": 1700626775807,
                "mdate": 1700626775807,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]