[
    {
        "title": "The Trifecta: Three simple techniques for training deeper Forward-Forward networks"
    },
    {
        "review": {
            "id": "sz16GAqwb2",
            "forum": "wcKGK0tRHD",
            "replyto": "wcKGK0tRHD",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5349/Reviewer_kPrg"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5349/Reviewer_kPrg"
            ],
            "content": {
                "summary": {
                    "value": "The paper focuses on forward-forward (FF), an alternative to backpropagation proposed by G. Hinton in 2022 (arxiv only). FF is based on a contrastive loss applied layer-wise between the original points and \"negative\" points. The authors apply three modifications to the original algorithm (that they call \"the Trifecta\"), which include a different loss term, batch normalization instead of layer normalization, and a blockwise model where some layers receive feedback from the subsequent layers. With these three modifications they are able to scale FF from MNIST to CIFAR-10 with good performance."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "Finding alternatives to backpropagation that scale to larger datasets is a very interesting research direction. In this sense, the results shown here are good if compared with state-of-the-art models with no backward passes, although the authors are not providing these comparisons (see below). The paper is well written and easy to read, apart from the mathematical notation that could be drastically improved."
                },
                "weaknesses": {
                    "value": "I see a few weaknesses making me lean towards rejection.\n\n1. NOVELTY: the \"Trifecta\" (which is a bit excessive as name) is composed of three small modifications, of which one was already published and applied to FF (different loss term), one was published but not applied to FF (Overlapping Local Updates), the final one is using batch normalization instead of layer normalization. These 3 methods are also justified in an informal way or empirically by some visualization (which are mostly copy-paste from a W&B run). Overall, this looks more like a report of someone experimenting on FF than a true scientific publication. This is made worse by the fact that (a) FF is unpublished, and (b) there is no convergence guarantee to begin with on FF optimization.\n\n2. RELATED WORKS: the paper is very shallow in its analysis of the related works, which should include other backpropagation-free techniques such as zeroth-order gradients (https://arxiv.org/abs/2305.17333), forward gradients (https://openreview.net/forum?id=JxpBP1JM15-), error-driven input modulation (https://proceedings.mlr.press/v162/dellaferrera22a/dellaferrera22a.pdf), etc. Many of these methods are similar to FF.\n\n3. EXPERIMENTS: connected to 2, it's unclear why the authors are only validating with respect to standard FF and not other alternatives to backpropagation (e.g., direct feedback alignment). Many of these methods are on-par with the results shown here."
                },
                "questions": {
                    "value": "I don't have many questions on the paper. Improving related works and the experimental evaluation are good points (see above), but the paper remains of an incremental value and lacking any formal guarantees of convergence. Hence, I do not think this is a valuable contribution to the conference."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5349/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698058654193,
            "cdate": 1698058654193,
            "tmdate": 1699636538683,
            "mdate": 1699636538683,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xur0VJlo8o",
                "forum": "wcKGK0tRHD",
                "replyto": "sz16GAqwb2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5349/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5349/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their time and feedback linked to our related work section and our comparisons to other work.\n\n> The paper is well written and easy to read, apart from the mathematical notation that could be drastically improved.\n\nWe acknowledge the math is slightly informal in the spirit of readability, but should be sufficient to bring across all necessary statements we set out to make. We would appreciate it if the reviewer could provide a more concrete pointer to any specific formula or notation that could be improved.\n\n> These 3 methods are also justified in an informal way or empirically by some visualization (which are mostly copy-paste from a W&B run)\n\nWe made certain that we referenced the corresponding appendices (A through E) for a more comprehensive evaluation that proposes numerous experiments and plots to back up our statements. As noted in the work, all conclusions drawn from these plots are verified across a multitude of settings that are not all shown. If there are any missing justifications in your opinion, we would be very glad to hear them.\n\n> Overall, this looks more like a report of someone experimenting on FF than a true scientific publication. This is made worse by the fact that (a) FF is unpublished, and (b) there is no convergence guarantee to begin with on FF optimization. \n\nIt is true that the FF paper is unpublished. However, given its author and the recent popularity and scrutiny it has received from the wider ML community, we would argue that it has been verified to a further extent than many publications (for instance, the work was presented at NeurIPS https://neurips.cc/virtual/2022/invited-talk/55869). Further, FF indeed doesn't have a convergence guarantee, its main focus is to be a preliminary investigation into a novel learning algorithm based on the popular contrastive learning method, that has been shown to work in numerous publications. \n\n> The paper is very shallow in its analysis of the related works, which should include other backpropagation-free techniques such as zeroth-order gradients\n\nThis is a very valid point. Backpropagation-free techniques and local learning have received increased attention in the past years resulting in lots of papers. To our knowledge, all existing items in the literature differ from FF by at least one key aspect (and most times by more). For instance, the reference [https://arxiv.org/abs/2305.17333](https://arxiv.org/abs/2305.17333) is quite similar in approach but is presented as a finetuning technique of LMMs, not a full learning algorithm. Further, [https://openreview.net/forum?id=JxpBP1JM15-](https://openreview.net/forum?id=JxpBP1JM15-) differs by its use of a block-based approach. There are several block-based learning algorithms without any specific approach standing out in similarity to FF or in popularity which led us to the choice to not discuss them. We have included (https://proceedings.mlr.press/v162/dellaferrera22a/dellaferrera22a.pdf) and some additional work in our related work discussion.\n\n> connected to 2, it's unclear why the authors are only validating with respect to standard FF and not other alternatives to backpropagation (e.g., direct feedback alignment)\n\nAs stated above, to our knowledge, there are no algorithms that stand out in similarity to FF that would lead to an informative and direct comparison (apart from BP, which was chosen as a baseline due to its ubiquity). Nevertheless, the reviewer is fully accurate in saying that additional comparisons are necessary to paint a more comprehensive picture. Therefore, Table 2 will soon be updated to demonstrate a more thorough comparison with the closest alternatives.\n\n> but the paper remains of an incremental value\n\nThe Trifecta is composed of three existing techniques, this is correct. However, we argue that our contributions reach further than simply proposing The Trifecta. Primarily, we uncover and study three weaknesses within the vanilla FF algorithm and elucidate how they can be solved by our proposed techniques to achieve very competitive accuracy on several datasets. Additionally, we outline the general characteristics of our solutions that cause the improvement such that future work can build upon our findings. In conclusion, there are several findings that are of significant importance on the road to further our understanding of FF and other local learning algorithms. \n\nWe thank the reviewer again for the feedback and look forward to hearing if the primary concerns have been resolved with our modifications."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5349/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700002827671,
                "cdate": 1700002827671,
                "tmdate": 1700002827671,
                "mdate": 1700002827671,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iWsCT9ulkz",
                "forum": "wcKGK0tRHD",
                "replyto": "xur0VJlo8o",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5349/Reviewer_kPrg"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5349/Reviewer_kPrg"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for the answer. I briefly comment on some points.\n\n1. On the math: currently there are only 2-3 equations that are loosely discussed inside the main text. This is enough to provide a loose understanding of the topic, but many details are unclear in this way. For example, reviewer ugNW has several interesting points on the batch dimension that for the most part could have been avoided by precise, mathematical descriptions. However, I underline this is only a minor part of my evaluation of the paper.\n\n2. On justification and novelty: we are saying the same thing; all methods are justified informally by changing a component, running some experiments, and seeing if the results improve. I am not saying this is necessarily a wrong approach, but in itself it is a limited approach since the methods themselves are known and repurposed.\n\n3. Backpropagation-free: the FF algorithm is an example of backpropagation-free training of neural networks. I suggested several other examples which I think are sufficiently known to be added as comparisons (e.g., direct feedback alignment). Saying \"there are no algorithms that stand out in similarity to FF\" seems a way to avoid having comparisons. I do not think there is anything special in FF apart from avoiding backpropagation.\n\nOverall, while I appreciate the effort in answering, I believe the paper is still a mostly incremental evaluation that adapts existing methods to FF."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5349/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700230474725,
                "cdate": 1700230474725,
                "tmdate": 1700230474725,
                "mdate": 1700230474725,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "buP6t96DLl",
            "forum": "wcKGK0tRHD",
            "replyto": "wcKGK0tRHD",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5349/Reviewer_xPoW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5349/Reviewer_xPoW"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose The Trifecta\u2014three modifications to the recent Forward-Forward algorithm to improve convergence stability and scalability to more complex datasets. Specifically, they transfer existing techniques into their design of a modified Forward-Forward training algorithm and empirically demonstrate that their Trifecta Forward Forward (TFF) algorithm outperforms vanilla Forward-Forward and brings the accuracy on a collection of datasets equal or closer to accuracy achieved by training the same models via backpropagation. Motivation for this research is the consideration and development of alternative training paradigms for deep learning models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "\u2022 Design of Trifecta Forward Forward (TFF) algorithm for backpropagation free neural network training\n\n\u2022 Large-scale empirical analysis of TFF on 3 architectures and 4 datasets to compare performance against vanilla Forward-Forward (VFF) and backpropagation\n\n\u2022 TFF offers sizeable improvements compared to VFF\n\n\u2022 CIFAR-10 accuracy of TFF/d achieves nearly-SOTA performance for gradient-free training"
                },
                "weaknesses": {
                    "value": "\u2022 Work feels largely incremental\u2014authors adopt existing technologies (SymBa loss, Batchnorm, Overlapping Local Updates) to design TFF algorithm\n\n\u2022 Main paper seems to contain information that could be summarized more concisely or moved to appendix (e.g., Section 5 seems very long for experimental setup)."
                },
                "questions": {
                    "value": "1. While the performance of TFF on CIFAR-10 is very good for backpropagation-free training, I found the design of the algorithm to borrow from existing technologies. I wanted to give you the chance to clarify if there were additional contributions in the design of TFF beyond adopting existing methods from the literature.\n\n2. On p. 8, you say that \u201cFurther, on simple datasets, our algorithm is on par with our backpropagation baseline, in the same amount of epochs.\u201d Considering Table 2, this only appears to be the case for MNIST. Am I missing something?\n\n3. What is the walltime per epoch when using TFF compared to BP? I know this will vary per architecture and dataset so let\u2019s say the largest model on CIFAR-10."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5349/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5349/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5349/Reviewer_xPoW"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5349/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698802209009,
            "cdate": 1698802209009,
            "tmdate": 1699636538590,
            "mdate": 1699636538590,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "19ntPx7z5d",
                "forum": "wcKGK0tRHD",
                "replyto": "buP6t96DLl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5349/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5349/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are thankful for the time and effort of the reviewer in providing feedback related to the general contributions of this work.\n\n> Work feels largely incremental\u2014authors adopt existing technologies (SymBa loss, Batchnorm, Overlapping Local Updates) to design TFF algorithm\n\nGiven the nascent state of the FF algorithm, our goal is to further explore its learning properties and uncover simple changes that improve the scalability and overall accuracy in a wide range of settings. To this end, we uncovered and focussed on three weaknesses of the original algorithm. Following this, we propose three modifications with techniques that are purposefully easily implementable due to their familiarity or simplicity. We argue that the main contributions of our work lie in finding these weaknesses, proposing general solutions to them and subsequently improving the scaling behaviour of the FF algorithm.\n\n> Main paper seems to contain information that could be summarized more concisely or moved to appendix (e.g., Section 5 seems very long for experimental setup).\n\nThanks for the feedback, due to the novelty of the algorithm, we strove to make our setup and implementation-related decisions abundantly clear. However, we agree it is slightly too long for our intended purposes. The hyperparameter section has now been moved to the appendix.\n\n> While the performance of TFF on CIFAR-10 is very good for backpropagation-free training, I found the design of the algorithm to borrow from existing technologies. I wanted to give you the chance to clarify if there were additional contributions in the design of TFF beyond adopting existing methods from the literature.\n\nIndeed, the main components of TFF borrow from existing techniques, as motivated above. However, this is not the main contribution of this work. Nevertheless, there are some minor modifications that are not specifically highlighted in the paper. The architecture, or specifically, the layer composition is slightly different from ordinary CNNs. Namely, we use the ordering BN, Conv, ReLU and then Maxpool. We found that performing a ReLU before the maxpool is very beneficial to the overall scaling behaviour of the network. Further, we propose a method to embed the label suitably in a CNN. These modifications are stated in the paper but are also the main reason we openly share our code, such that future experiments of FF can start on a solid foundation.\n\n> On p. 8, you say that \u201cFurther, on simple datasets, our algorithm is on par with our backpropagation baseline, in the same amount of epochs.\u201d Considering Table 2, this only appears to be the case for MNIST. Am I missing something?\n\nThis is indeed only the case for MNIST, this is updated to be more clear.\n\n> What is the walltime per epoch when using TFF compared to BP? I know this will vary per architecture and dataset so let\u2019s say the largest model on CIFAR-10.\n\nWe did not include any details on this aspect as this is in line with expectation: FF is twice as slow per epoch due to the inclusion of negative samples. These are the averaged wall-clock times for CIFAR-10 (first) and MNIST (second) when trained for 100 epochs (on an rtx4080). As the models are identical (except the first layer) throughout datasets, this stays largely consistent. Please note that these experiments were not performed in a controlled environment and therefore, suffer from substantial variance.\n\n- BP small: 5m 53s <-> FF small : 10m 36s\n- BP large: 7m 54s <-> FF large: 16m 38s\n- BP small: 4m 41s <-> FF small: 9m 39s\n- BP large: 7m 22s <-> FF large: 15m 03s\n\nHopefully, our answers are satisfactory and have answered your questions. If the reviewer has any additional comments, please let us know."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5349/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700002038139,
                "cdate": 1700002038139,
                "tmdate": 1700003868195,
                "mdate": 1700003868195,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rxNe6VjDcL",
                "forum": "wcKGK0tRHD",
                "replyto": "GVed82nEqw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5349/Reviewer_xPoW"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5349/Reviewer_xPoW"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for addressing the weaknesses I listed and answering all of my questions. I appreciate the results on the wall-clock time for FF. I do not have any follow up questions and I will keep my original score for the paper."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5349/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700676855814,
                "cdate": 1700676855814,
                "tmdate": 1700676855814,
                "mdate": 1700676855814,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BOsoinzlFC",
            "forum": "wcKGK0tRHD",
            "replyto": "wcKGK0tRHD",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5349/Reviewer_ugNW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5349/Reviewer_ugNW"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes 3 techniques that together significantly help training a deep network with forward-forward algorithms. Those techniques are:\n* Improved loss function which treats false positives and false negatives equally.\n* Use of batch normalisation instead of layer normalisation.\n* Use of overlapping local updates, so that each layer is also optimised to produce useful features to help the next layer goodness loss.\n\nThe method is evaluated on MNIST, Fashion-MNIST, SVHN and CIFAR-10 using CNNs and FCNs. While ablating the added techniques the performance on CIFAR-10 is brought from 44% to 75%. When training longer with more layers it reaches 83% while the backprop reaches 89%."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The main text is overall easy to read without significant previous knowledge. The three techniques are motivated and refer to previous work. The main contribution seems to be using them all together on a FF setup for a combined improved accuracy and to map to the community the sort of techniques that can bring FF closer to BP training.\n\nThe ablations are clear, e.g. the layernorm->batchnorm has a very significant effect on allowing the subsequent layers to improve on the decisions from previous ones (Figure 1). Table 1 also shows the effect of the BN and OLU applied on top of a SymBA loss baseline."
                },
                "weaknesses": {
                    "value": "It appears to me that the proposed techniques run somehow counter to (what I on my limited knowledge) perceive to be some of the motivation of FF:\n* Weight updates as described in section 3, are supposed to be done in 2 forward steps, one for positive and one for negative samples (maybe aiming to be able to completely decouple them further in time eventually (sleep section in Hinton 2022)). However here by removing the threshold it appears one needs the batch to contain both positive and negative examples and resembles a self-supervised contrastive setup.\n* Overlapping local updates although not using non-global gradients is a step away from being able to introduce black boxes in the middle of the forward pass.\n* I also can't stop to notice that batch normalization as done here also disallows training by seeing one example at a time (though maybe keeping batch statistics would easily address that?).\n\nCombined together with CNN and evaluated on a supervised contrastive training it is maybe of no surprise that this set of techniques obtain better results than vanilla FF. Despite that, I think this work may still be interesting to help mapping the set of techniques that bridge the gap to BP and leave the discussion to whether they are in the spirit of VFF or biologically plausible to the reader."
                },
                "questions": {
                    "value": "A) Since in the loss discussion and appendixes the batch dimension is mostly left out, I feel like some details were unclear. E.g. is g_pos and g_neg used in the SymBa loss the mean of l2_norm of all the positive and negative examples in the batch? How is the batch constructed, is it highly correlated (e.g. contains the same input in both positive and negative case)?\n\nB) Do you think keeping moving averages of the norm of positive and negative activations would allow one to train this without requiring both positive and negative examples to be in the batch?\n\nC) Given the size of networks would it be practical and interesting to provide ablation of BN and OLUs on top of a VFF without the SymBa loss? Or am I missing something?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5349/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5349/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5349/Reviewer_ugNW"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5349/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698831037058,
            "cdate": 1698831037058,
            "tmdate": 1699636538496,
            "mdate": 1699636538496,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "aACB7xBLmJ",
                "forum": "wcKGK0tRHD",
                "replyto": "BOsoinzlFC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5349/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5349/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their time and valuable comments. The reviewer raises some very valid questions and comments that will result in a solid improvement to the work. Some questions and comments are addressed slightly out of order to allow for more structure within our answers.\n\n> Since in the loss discussion and appendixes the batch dimension is mostly left out, I feel like some details were unclear. E.g. is g_pos and g_neg used in the SymBa loss the mean of l2_norm of all the positive and negative examples in the batch? How is the batch constructed, is it highly correlated (e.g. contains the same input in both positive and negative case)?\n\nThis was previously not made clear enough in the main text, g^pos and g^neg are vectors containing the goodness for positive and negative samples respectively within each batch. Further, the reviewer is correct in saying that each batch is highly correlated; the negative samples are simply the same positive samples with a bogus label. Among other public implementations, we found that using a highly correlated setup produces the best results. The manuscript was updated to clarify the topic in accordance with this explanation.\n\n> Weight updates as described in section 3, are supposed to be done in 2 forward steps, one for positive and one for negative samples (maybe aiming to be able to completely decouple them further in time eventually (sleep section in Hinton 2022)). However here by removing the threshold it appears one needs the batch to contain both positive and negative examples and resembles a self-supervised contrastive setup. \n\nGiven the fact that the sleep idea currently is not possible, as stated by Hinton 2022 in the revised version, using a concatenated batch (pos+neg) or two separate batches yields identical results, but the former is slightly faster on most hardware. The FF algorithm differentiates itself from most forms of contrastive learning by its use of goodness. Instead of performing similarity comparisons on entire embeddings, they are done on this goodness value. By changing the loss function to SymBa, these goodness values are indeed compared to each other to calculate the loss, instead of to a set threshold. These would need to be stored if used in a fully decoupled manner.\n\n> Do you think keeping moving averages of the norm of positive and negative activations would allow one to train this without requiring both positive and negative examples to be in the batch?\n\nAs alluded to above, this decoupling is certainly achievable but in a slightly different manner from the proposed method. There are two observations that are key to this topic: first, samples within g^pos and g^neg are correlated and hence, the distance is calculated on a per-sample basis. Second, there is some variance between the thresholds of different samples, which results in this observed, stabler convergence. Therefore, rolling averages are not the best way to approach this decoupling as we have verified in a small experiment. However, the statistics necessary are quite minimal, as only the goodness needs to be stored. \n\n> Overlapping local updates although not using non-global gradients is a step away from being able to introduce black boxes in the middle of the forward pass.\n\nThere are several aspects to consider when using semi-local gradients (outlined in Appendix F). \n - Biological plausibility: Within our setup, all error communication is very local, further, by using slight alterations like random synaptic feedback, biological plausibility can be increased (if desired).\n - Black boxes: OLU doesn't hinder black boxes, it simply improves parts of the network that are uninterrupted. The strength of FF lies in its flexible objective that does not necessitate specialised classification layers that may disturb these black boxes.\n - Non-differentiable operations: There are instances where each layer has a non-differentiable operation and therefore OLU cannot be used. However, these scenarios are quite niche but we would like to highlight that training on MNIST without OLU actually yields slightly better results (~99.7% instead of ~99.6%). On more complex datasets such as Cifar-10, OLU works better as seen in the ablation.\n\n> I also can't stop to notice that batch normalization as done here also disallows training by seeing one example at a time (though maybe keeping batch statistics would easily address that?).\n\nThis is exactly true. As our experiments show, BN works well in this scenario as it finds a middle ground between fully renormalising features and no normalisation. We argue any sensible normalisation function with this property would thus perform comparably. We performed the proposed experiment, using only running averages of BN during training, with otherwise identical settings as TFF in Table 1 and achieved 73.3%, which is slightly lower but still very competitive. As this is quite specific these updates will be pushed to the appendix (E), instead of the main text."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5349/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700001797390,
                "cdate": 1700001797390,
                "tmdate": 1700001797390,
                "mdate": 1700001797390,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "CzFzxYZVd2",
            "forum": "wcKGK0tRHD",
            "replyto": "wcKGK0tRHD",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5349/Reviewer_i3k6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5349/Reviewer_i3k6"
            ],
            "content": {
                "summary": {
                    "value": "Modern machine learning models are able to outperform humans on a variety of non-trivial tasks. However, as the complexity of the models increases, they consume significant amounts of power and still struggle to generalize effectively to unseen data. Local learning, which focuses on updating subsets of a model\u2019s parameters at a time, has emerged as a promising technique to address these issues. Recently, a novel local learning algorithm, called Forward-Forward, has received widespread attention due to its innovative approach to learning. Unfortunately, its application has been limited to smaller datasets due to scalability issues. To this end, we propose The Trifecta, a collection of three simple techniques that synergize exceptionally well and drastically improve the Forward-Forward algorithm on deeper networks. Our experiments demonstrate that our models are on par with similarly structured, backpropagation-based models in both training speed and test accuracy on simple datasets. This is achieved by the ability to learn representations that are informative locally, on a layer-by-layer basis, and retain their informativeness when propagated to deeper layers in the architecture. This leads to around 84% accuracy on CIFAR-10, a notable improvement (25%) over the original FF algorithm. These results highlight the potential of Forward-Forward as a genuine competitor to backpropagation and as a promising research avenue."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The methods are relatively straightforward to be applied to the existing Forward-Forward Algorithm.\n- Paper is well-written. It is easy to follow the explanations written in the paper itself.\n- Experiemnt results have shown that following these recipes improves the vanilla Forward-Forward Algorithm and exhibits an on-par result with network learned from backpropagation in terms of classification accuracy.\n- Code is available."
                },
                "weaknesses": {
                    "value": "My main concern is with regard to the generalizability and scalability of the proposed method when it is applied to the Forward-Forward algorithm. This can be viewed from multiple lenses as follows:\n- First of all, while the image classification results are promising when Trifecta is applied to the Forward-Forward algorithm, that does not mean that the only task we need to tackle is the classification task. It is desirable to see how well the Trifecta fares with the vanilla FF and SGD on a wider variety of tasks such as Machine Translation, image generation, or different types of learning mechanisms such as self-supervised learning, reinforcement learning, multimodal learning, etc.\n- In addition, the network used for evaluating this method is relatively small compared to most experiments that are performed in this avenue. It would bring substantial improvement to the paper to use larger networks such as ResNet and attention-based models to evaluate the performance of Trifecta on a given task compared to the vanilla FF and SGD.\n- Furthermore, in the ablation, it would be interesting if we include ablation studies on how the vanilla loss function and incorporate either BN or OLU and compare it when we use the SymBa loss function [2] with one of these two other ingredients just like the results in Table 1. \n- Finally, even though it is not desired to perform evaluation on large datasets such as ImageNet, I am curious regarding the performance of TFF when it is compared to VFF and BP on image classification task, since most of the methods proposed in this avenue are evaluated on large datasets."
                },
                "questions": {
                    "value": "See Weaknesses\n\n[1] Hinton, Geoffrey. \"The forward-forward algorithm: Some preliminary investigations.\" arXiv preprint arXiv:2212.13345 (2022).\n\n[2] Lee, Heung-Chang, and Jeonggeun Song. \"SymBa: Symmetric Backpropagation-Free Contrastive Learning with Forward-Forward Algorithm for Optimizing Convergence.\" arXiv preprint arXiv:2303.08418 (2023)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5349/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5349/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5349/Reviewer_i3k6"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5349/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699534748675,
            "cdate": 1699534748675,
            "tmdate": 1699636538358,
            "mdate": 1699636538358,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "T1qi04SgnI",
                "forum": "wcKGK0tRHD",
                "replyto": "CzFzxYZVd2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5349/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5349/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their detailed concerns regarding the further scalability of the TFF algorithm.\n\n> First of all, while the image classification results are promising when Trifecta is applied to the Forward-Forward algorithm, that does not mean that the only task we need to tackle is the classification task. It is desirable to see how well the Trifecta fares with the vanilla FF and SGD on a wider variety of tasks \u2026\n\nThis is absolutely correct and is an interesting avenue for future research. However, given the nascent state of FF, we opted to limit the scope of this work to image classification. This has two reasons: the original paper exclusively has results in this modality, to which we wanted to make a direct comparison, and image classification tasks have the most well-known and standardized datasets.\n\n> In addition, the network used for evaluating this method is relatively small compared to most experiments that are performed in this avenue. It would bring substantial improvement to the paper to use larger networks such as ResNet and attention-based models to evaluate the performance of Trifecta on a given task compared to the vanilla FF and SGD.\n\nAgain, we certainly agree that a more thorough architecture search is very desirable. In the context of local learning, however, many ubiquitous architectures from BP simply do not work well. For example, a bottleneck architecture will yield terrible accuracy as the error signal is \"not strong enough\" to learn compressed representations. That said, we have tried adding residual connections to our networks. From our limited experiments, we found that the accuracy increases (slightly less than 1% on the CIFAR-10 model). However, as this is only a very slight improvement, we decided not to include this finding and put more focus on our three main modifications.\n\n> Furthermore, in the ablation, it would be interesting if we include ablation studies on how the vanilla loss function and incorporate either BN or OLU and compare it when we use the SymBa loss function [2] with one of these two other ingredients just like the results in Table 1.\n\nAfter some consideration, we opted to not show the full ablation table in the spirit of clarity. The primary reason is that SymBa was found to be the most important technique, without it, the accuracy differences given other techniques are comparably minor and therefore less informative. However, we now understand this was not made clear enough. Therefore, the manuscript has been updated appropriately by discussing this aspect and showing the full table (shown below for ease of access).\n\n- No SymBa (tau=10) + BN: 37.3%\n- No SymBa (tau=10) + OLU: 50.8%\n- No SymBa (tau=10) + BN + OLU: 59.0%\n\n- No SymBa (tau=2) + BN: 41.0%\n- No SymBa (tau=2) + OLU: 48.2%\n- No SymBa (tau=2) + BN + OLU: 57.9%\n\n> Finally, even though it is not desired to perform evaluation on large datasets such as ImageNet, I am curious regarding the performance of TFF when it is compared to VFF and BP on image classification task since most of the methods proposed in this avenue are evaluated on large datasets.\n\nIn light of this comment, we performed experiments on Cifar-100. The small model is able to achieve 35.8% after 200 epochs and the large model achieves 35.4% after 500 epochs using the same setup as all other datasets. Originally, we decided not to evaluate larger datasets as the main goal was to scale from MNIST to CIFAR-10 and compare the results to the original paper. Most local learning approaches currently are not yet competitive with BP for more complex datasets. We have added these new results to Table 2.\n\nLastly, if there are any additional questions or comments, we would be glad to hear them in detail."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5349/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700001673141,
                "cdate": 1700001673141,
                "tmdate": 1700001673141,
                "mdate": 1700001673141,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wf9hJ1VtoC",
                "forum": "wcKGK0tRHD",
                "replyto": "CzFzxYZVd2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5349/Reviewer_i3k6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5349/Reviewer_i3k6"
                ],
                "content": {
                    "comment": {
                        "value": "I highly appreciate the authors for addressing my concerns.\n\nHowever, I still find the reasoning for the first and second weaknesses to be not substantial enough.\n\n- For instance, in my first point regarding the weakness, it is desirable to include different tasks as evaluation benchmarks to better understand how TFF performs against VFF.\n- In addition to that, you can simply include your initial findings for using residual networks in the benchmarks.\n\n\nDue to this, I believe that I will keep my score as it is."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5349/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700652648075,
                "cdate": 1700652648075,
                "tmdate": 1700652648075,
                "mdate": 1700652648075,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]