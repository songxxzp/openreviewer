[
    {
        "title": "PrACTiS: Perceiver-Attentional Copulas for Time Series"
    },
    {
        "review": {
            "id": "LtzmIZBw8m",
            "forum": "HL9YzviPCy",
            "replyto": "HL9YzviPCy",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission420/Reviewer_n61f"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission420/Reviewer_n61f"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a new approach for time-series prediction called Perceiver-Attentional Copulas for Time Series (PrACTiS). \n\nPrACTiS combines the Perceiver IO model with attention-based copulas to enhance time series modeling and improve computational efficiency. The architecture consists of a perceiver-based encoder and a copula-based decoder. It first transforms the input variables into temporal embeddings, effectively handling both observed and missing data points. A latent attention mechanism then maps these embeddings to a lower-dimensional space, reducing computational complexity. The decoder utilizes the copula structure to handle missing data and formulate their joint distribution, which is then sampled to produce predictions."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The model is validated through extensive experiments and shows competitive performance against state-of-the-art methods like TACTiS, GPVar, SSAE-LSTM, and deep autoregressive AR. \n\nThe method is sound, even though of low risk of having errors, as it is a simple extension over sota."
                },
                "weaknesses": {
                    "value": "The paper heaviliy extends upon TACTiS. They basically change the encoder. Thus novelty is low."
                },
                "questions": {
                    "value": "I would like to see more experiments, with at least al TACTiS paper datasets."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission420/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697577264031,
            "cdate": 1697577264031,
            "tmdate": 1699635968703,
            "mdate": 1699635968703,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "iX9czA3sTa",
                "forum": "HL9YzviPCy",
                "replyto": "LtzmIZBw8m",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission420/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission420/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer n61f"
                    },
                    "comment": {
                        "value": "Thank you for providing your feedback. We appreciate your perspective, and while we respect your comments, we would like to express our disagreement. Our model is designed with the explicit goal of enhancing TACTiS and optimizing it for multimodal scenarios. Through the incorporation of the Perceiver architecture as the encoder, we successfully encode multimodal data into a latent space domain. This improvement results in a performance boost of up to 40%, achieved with only half the computational resources of TACTiS. Additionally, we introduce midpoint inference to further reduce complexity, contributing to an overall enhancement in performance.\n\nIn the course of our research, we conducted a total of six experiments, comprising three multimodal and three unimodal scenarios. It's worth noting that the unimodal datasets used in our experiments are sourced from the TACTiS paper. We firmly believe that our contributions in the realm of multimodal scenarios, coupled with the substantial improvement over the state-of-the-art, make our work well-suited for presentation at this conference."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission420/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700506921016,
                "cdate": 1700506921016,
                "tmdate": 1700506921016,
                "mdate": 1700506921016,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "DSZO2nf5Yv",
            "forum": "HL9YzviPCy",
            "replyto": "HL9YzviPCy",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission420/Reviewer_Eqmq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission420/Reviewer_Eqmq"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a model called PrACTiS, which combines the perceiver architecture with a copula structure to perform time-series forecasting. The proposed architecture models the timeseries using a compact latent space, which reduces the computational demands. The authors further use local attention mechanisms to capture dependencies within imputed samples. The authors empirically evaluate the proposed method, and show that the proposed method consistently outperforms the state-of-the-art methods."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- It is interesting to use the copula structure to model timeseries, which gives the model capability to model non-synchronized time series data."
                },
                "weaknesses": {
                    "value": "**Contribution of the proposed work is unclear**\n1. The authors claim that the proposed model \u201ccan effectively handle synchronized, non-synchronized, and multimodal data, expanding its applicability to diverse domains\u201d. Does any of the experiments demonstrate the model\u2019s performance on handling non-synchronized or incomplete datasets?\n2. The authors claim that one of the major advantages of the proposed model is that it is memory-efficient. However, (i) the model takes more parameter than many baseline models; (ii) both the parameters and memory usage of the proposed model and baselines are tiny (<1M parameters; <10G memory usage). Why does memory have to be further reduced in this case?\n\n**Inadequate performance**\n1. If none of the selected dataset contains non-synchronized timeseries, have the authors considered using more advanced architecture for benchmarking? E.g. AutoFormer; FedFormer; Informer; PatchTST.\n2. The prediction performance seems really bad based on the visualizations in Appendix. Specifically, as shown in Figure 4, the prediction is not even close to the ground truth values."
                },
                "questions": {
                    "value": "NA"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission420/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698699798508,
            "cdate": 1698699798508,
            "tmdate": 1699635968624,
            "mdate": 1699635968624,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Z5VhQlsSUu",
                "forum": "HL9YzviPCy",
                "replyto": "DSZO2nf5Yv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission420/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission420/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Eqmq"
                    },
                    "comment": {
                        "value": "Thank you for recommending those insightful papers. Our approach is specifically tailored for short-term prediction, with a focus on enhancing the adaptability of the TACTiS model for multimodal scenarios. In contrast, AutoFormer, FedFormer, Informer, and PatchTST primarily address long-term prediction challenges. However, we acknowledge the importance of providing a comprehensive comparison, and in our revised version, we will include an analysis of these approaches in the context of medium-sized or short-term prediction. This will help underscore the distinctiveness of our methodology.\n\nRegrettably, the unavailability of unsynchronized datasets has hindered our experimentation in this domain, a limitation shared with the TACTiS paper. Despite these challenges, we have managed to excel in short-term multimodal prediction scenarios by outperforming the TACTiS approach significantly. Some experiments proved to be particularly demanding, given our reliance on a short-term window to predict future short-term windows.\n\nYour feedback is invaluable in refining our presentation, and we appreciate your understanding of the experimental constraints. We are committed to addressing these aspects in the revised manuscript. Once again, thank you for your thoughtful recommendations."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission420/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700506232722,
                "cdate": 1700506232722,
                "tmdate": 1700506232722,
                "mdate": 1700506232722,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "GIqHETH4D5",
            "forum": "HL9YzviPCy",
            "replyto": "HL9YzviPCy",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission420/Reviewer_jRTE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission420/Reviewer_jRTE"
            ],
            "content": {
                "summary": {
                    "value": "The authors introduce the Perceiver-Attentional Copulas for Time Series (PrACTiS) architecture based on the TACTiS model to study time-series prediction. The proposed architecture combines the Perceiver model with attention-based copulas. It consists of the perceiver-based encoder and the copula-based decoder, enabling the incorporation of a more general class of copulas that are not exchangeable. To validate the efficacy of the practice, the authors conducted extensive experiments on the unimodal datasets and the multimodal datasets. In addition, the authors conduct memory consumption scaling experiments using random walk data to demonstrate the memory efficiency of PrACTiS."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "By adopting the technique of the Perceiver model, midpoint inference, and local attention mechanisms, the authors successfully address the issue of computational complexity associated with self-attention mechanisms. In addition, the authors thoroughly test their approach on multiple datasets, providing a comprehensive assessment of its performance."
                },
                "weaknesses": {
                    "value": "The organization and writing style of the paper appears to suffer from several issues, making it challenging for readers to grasp the presented notions and ideas. Specifically, Section 3 primarily focuses on the intricate details of TACTiS, with much of the content possibly better suited for inclusion in the supplementary material. To improve the flow and readability of the paper, it would be beneficial for the authors to introduce a figure illustrating TACTiS and highlighting the distinctions between TACTiS and the proposed model before delving into detailed explanations in Section 4. This would provide readers with a clearer understanding of the context and facilitate comprehension of subsequent sections.\n\nAdditionally, the authors propose to integrate the Perceiver model as the encoder to enhance the expressiveness of dependence between covariates. The author should give a brief introduction to the  Perceiver model and explain why combining it in the encoder in detail. Considering that a significant portion of the paper is derived from TACTiS and the proposed model appears to be a modification or extension of TACTiS, there are concerns regarding the novelty of the research. It is essential for the authors to explicitly address this issue and clearly articulate the drawbacks of TACTiS and the advancements brought by their proposed model."
                },
                "questions": {
                    "value": "1.  The definition, notations, and explanation of section Perceiver-based encoding are not clear. For example, what is the predefined set of learned latent vector $\\vec{u}_k$? What is the latent vector set $\\vec{W}$?\n\n2. Please clarify and elaborate on the objective of introducing midpoint inference. In addition, the mechanism of the midpoint inference is not stated/explained clearly. In addition, please clarify and elaborate on the objective of the local attention.\n\n3. If possible, please add the ablation study by comparing the results of PrACTiS with the results of PrACTiS (but no midpoint inference), the results of PrACTiS (but no variance test), and the results of PrACTiS (but no local attention)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission420/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission420/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission420/Reviewer_jRTE"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission420/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698734723691,
            "cdate": 1698734723691,
            "tmdate": 1699635968533,
            "mdate": 1699635968533,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "j3UVWJylBr",
                "forum": "HL9YzviPCy",
                "replyto": "GIqHETH4D5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission420/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission420/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer jRTE"
                    },
                    "comment": {
                        "value": "Thank you for your constructive feedback. Our primary objective is to enhance the state-of-the-art TACTiS model by integrating the Perceiver IO model as its encoder. This modification enables us to tackle the previously unexplored realm of multi-modal prediction. We believe that our empirical research in this direction aligns well with the preferences of this conference's audience.\n\nWe apologize for any confusion in the current manuscript and are committed to revising it to ensure greater clarity. We appreciate your input. If you have any further suggestions or specific areas of concern, please highlight them, and we will address them comprehensively in the revised version."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission420/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700356956002,
                "cdate": 1700356956002,
                "tmdate": 1700356956002,
                "mdate": 1700356956002,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "GwlZ9lwNbf",
            "forum": "HL9YzviPCy",
            "replyto": "HL9YzviPCy",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission420/Reviewer_JVje"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission420/Reviewer_JVje"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents Preceiver-Attentional Copulas (PrACTiS), a new method for time series forecasting. PrACTiS provides an efficient solution by combining Preceiver IO model with attention-based copulas. The idea of combining transformers with Copulas has been proposed in TACTiS [Drouin et al. 2022]. This paper proposes using Preciever IO for the encoder to overcome the computational cost of transformers. Experimental results are presented to validate the performance of PrACTiS."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The points of strengths include:\n\n- The proposed method performs well compared to TACTiS and is more efficient"
                },
                "weaknesses": {
                    "value": "The points of weaknesses include:\n\n1- The idea of combining transformers with copulas for forecasting has been proposed in TACTiS [Drouin et al. 2022]. The contribution seems to be limited to replacing transformers with Perceiver IO to increase efficiency which is already a known fact.\n\n2- Some parts of the paper need more clarity such as a summary of contributions."
                },
                "questions": {
                    "value": "- Could you please clarify why you did not include more baselines such as Autoformer [Wu et al. 2021]?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission420/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699240084657,
            "cdate": 1699240084657,
            "tmdate": 1699635968435,
            "mdate": 1699635968435,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "A2n8lUVnbv",
                "forum": "HL9YzviPCy",
                "replyto": "GwlZ9lwNbf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission420/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission420/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer JVje"
                    },
                    "comment": {
                        "value": "Thank you for providing feedback on our work. Our primary objective is to enhance the existing TACTiS model by leveraging the Perceiver architecture. We are pleased to report a substantial improvement in prediction performance for unimodal tasks, with gains of up to 40%. Notably, we successfully extend the applicability of our proposed model to multimodal tasks, achieving a significant performance boost compared to the original paper.\n\nWe acknowledge the absence of a comparison with the Autoformer model, mainly designed for long-term prediction under different assumptions. In our revised version, we will address this gap by incorporating a comparative analysis with Autoformer, emphasizing the distinctions between our approach and this specific technique.\n\nWe are committed to enhancing the clarity of our paper. We appreciate your insights, and the forthcoming revisions will aim to provide a more transparent motivation for our work. If you have any additional suggestions or concerns, please feel free to share them, and we will address them in our revision. Once again, thank you for your thoughtful feedback."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission420/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700356454121,
                "cdate": 1700356454121,
                "tmdate": 1700356454121,
                "mdate": 1700356454121,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]