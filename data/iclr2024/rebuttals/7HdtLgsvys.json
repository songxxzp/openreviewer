[
    {
        "title": "Tube Loss: A Novel Approach for High Quality Prediction Interval Estimation"
    },
    {
        "review": {
            "id": "JeTzMw7A49",
            "forum": "7HdtLgsvys",
            "replyto": "7HdtLgsvys",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7514/Reviewer_PHGF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7514/Reviewer_PHGF"
            ],
            "content": {
                "summary": {
                    "value": "This work propose a continuous loss, named tube loss, for prediction interval estimation. The loss is a Piecewise linear function with respect to the predictions. It optimizes the upper and lower functions of the prediction interval to find the proper confidence space and minimize the width of the space simultaneously. The effectiveness of the proposed loss is verified both theoretically and experimentally."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The optimization of the prediction interval and the minimization of the width are combined into the same objective, which is much simpler than existing methods. It introduces a tuning parameter r to separate the prediction interval into two parts, r can be adjusted to enable the PI tube to capturing the denser regions of the prediction, and thus reducing the width. \nthe method is claimed to be able to cover the densest regions of response values, thus allowing the sharpening of the width of PI, especially when the distribution of the response is skewed."
                },
                "weaknesses": {
                    "value": "The optimization is a two-stage process. The setting of r and lambda is not automatically, need human experience.\nThe manuscript needs more serious revision, some equations contain undefined variables, some figures have no captions, and some figures are not explained/referred in the main material.\nthe effectiveness of the proposed method on situations where the distribution of the response is skewed is not clearly shown in the experimental part."
                },
                "questions": {
                    "value": "1.\tThe equation on page one need to be rectified, E(y/x)?.\n2.\tEquation(8), there is no i in the second summation, and what is l for?\n3.\tHow many iterations are used in the optimization? How to find a proper tuning parameter r for a new dataset?\n4.\tFigure 1 is not referred in the main material. Figure 6, 7 have no captions.\n6.\tTable 3, the proposed method is not always better than QD, e.g. on data Energy, the performance of QD is better than Tube loss, and the MPIW measure of QD is better than Tube loss, the authors should provide a detailed discussion on these results.\n7.\tSection 4.2, what kind of neural network is used in the experiments? Please provide a description on the architecture.\n8.\tThe tile for section 4.3 needs revision"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7514/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698754523921,
            "cdate": 1698754523921,
            "tmdate": 1699636907705,
            "mdate": 1699636907705,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "xq3s2VvmB9",
            "forum": "7HdtLgsvys",
            "replyto": "7HdtLgsvys",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7514/Reviewer_9f1c"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7514/Reviewer_9f1c"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a new loss function named tube loss for prediction interval estimation. The authors also demonstrate the effectiveness of tube loss by numerical experiments."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The prediction interval estimation problem addressed in this paper might be a relatively significant issue."
                },
                "weaknesses": {
                    "value": "1. The writing style of this article does not meet the standards expected for academic publications.\n2. This paper fails to elucidate certain crucial symbols and concepts, such as the function $E$ and $\\mu$ mentioned in the first paragraph. 3. The paper lacks a section on related work, making it challenging for me to discern the challenges addressed and the contributions made by this manuscript.\n4. The experimental section is rather cursory and lacks detailed descriptions of many aspects."
                },
                "questions": {
                    "value": "What are the primary challenges addressed by the article? And what are its main contributions?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7514/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7514/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7514/Reviewer_9f1c"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7514/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698842386390,
            "cdate": 1698842386390,
            "tmdate": 1699636907542,
            "mdate": 1699636907542,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "lqNSLCGuOF",
            "forum": "7HdtLgsvys",
            "replyto": "7HdtLgsvys",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7514/Reviewer_tfsf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7514/Reviewer_tfsf"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a loss function that allows estimating prediction intervals. The authors propose parametrizing the lower and upper \u201cquantiles\u201d of the prediction interval via kernel machines, and simultaneously learn them while reducing the expected interval width."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- The paper tackles an important problem: estimating reliable prediction intervals. \n- The proposed loss function seems interesting."
                },
                "weaknesses": {
                    "value": "- The paper is written quite poorly, badly organized etc.\n- The proposed loss function is not motivated enough.\n- Baselines with quantile-regression\u2013based interval estimation are missing.\n- Experiments on real data are limiting and do not indicate that the proposed method is better."
                },
                "questions": {
                    "value": "- _The loss function._ The proposed loss function, while seems interesting, looks arbitrary \u2013 i.e., the authors do not motivate it well. I appreciate the authors doing extensive experiments studying the effect of the parameter r. But I would encourage the authors to motivate the loss function better before introducing it. This makes the reader appreciate it better.\n- _Quantile regression._ The de-facto approach for producing confidence intervals is quantile regression. However, it seems that the authors neither compare to nor discuss even a single work related to quantile regression. This makes me wonder if the authors are even familiar with this large body of work. I would encourage the authors to add a discussion and a comparison to quantile regression. This helps the reader understand the context of this work in the literature.\n- _Real data experiments._ While I appreciate the synthetic data experiments and the exploration of the effect of the parameter r, the experiments on real data are limited. Moreover, the experiments on real data (Table 3) suggests that the proposed loss function produces consistently larger width QD loss (a prior work). The authors mention that this is because the QD loss does not reach desired level of coverage: but I believe this is inaccurate characterization, consider for e.g. $\\texttt{Concrete}$ and $\\texttt{Energy}$ datasets, they produce about the same coverage, but significantly lower width. This indicates that QD loss is better than the proposed loss function. On the other two datasets, since QD loss does not achieve the same coverage, it is _not comparable_ to the proposed loss function, but this does *not* indicate that the proposed loss function performs better.\n- _Writing, organization etc._ The paper is written poorly overall. The proofs and Page 6 do not contribute much to the paper. I would rather see this space utilized for more real-data experiments. \n\nOverall, due to the above limitations, I believe the paper is not up to the standard of the conference. I encourage the authors to incorporate the aforementioned suggestions, it might make the paper better."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7514/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7514/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7514/Reviewer_tfsf"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7514/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698987504490,
            "cdate": 1698987504490,
            "tmdate": 1699636907372,
            "mdate": 1699636907372,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "CJA75PRCRf",
            "forum": "7HdtLgsvys",
            "replyto": "7HdtLgsvys",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7514/Reviewer_RfXE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7514/Reviewer_RfXE"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a new loss function that can simultaneously learn upper and lower confidence intervals. The authors show that in the limit of samples $ \\to \\infty$, the proposed loss function will yield prediction intervals for $t$ fraction of the values. Experiments are run on kernel machines, LSTMs, on synthetic data as well as real world time series data ( ocean wave height, as well as benchmark datasets from Pearce et al 2018)."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The suggested loss function simultaneously learns both boundaries of the prediction interval, which allows for minimizing the mean average width.\n\n- The loss is continuous and differentiable almost everywhere, which allows for using modern optimization algorithms.\n\n- Experiments show improvements over the QD loss proposed in Pearce et al 2018."
                },
                "weaknesses": {
                    "value": "- It's not clear what the main strength of this paper is. The propositions themselves are not very technically novel, the loss function is a modification of the Huber loss, with four pieces instead of two, and the experiments are either on synthetic data or compared to a paper from 2018. \n\n- The baseline comparisons are weak -- the authors only consider a paper from 2018 by Pearce et al, and the claim is that in table 3, the intervals are more accurate in the proposed approach. (it's also not clear how to interpret Table 3 -- what's the verification that TUBE loss is better than QD loss?)\n\n- The experiments are mostly on synthetic data, except for the comparison to Pearce et al, and experiments without baselines on the Ocean wave height dataset ( section 4.3)."
                },
                "questions": {
                    "value": "See the weaknesses section"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7514/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699048419430,
            "cdate": 1699048419430,
            "tmdate": 1699636907252,
            "mdate": 1699636907252,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]