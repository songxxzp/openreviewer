[
    {
        "title": "Understanding Convergence and Generalization in Federated Learning through Feature Learning Theory"
    },
    {
        "review": {
            "id": "Syx4Un7xbj",
            "forum": "EcetCr4trp",
            "replyto": "EcetCr4trp",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission923/Reviewer_aCq5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission923/Reviewer_aCq5"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the optimization dynamics and generalization behavior of FedAvg several neural networks in federated learning. Inspired by feature learning theory, they prove that FedAvg converges with gradient descent optimization under a certain data-generating model."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is generally well-written, making me easy to follow the logic flow. The motivation is strong, and the theoretical results are intuitive. Moreover, the authors honestly discuss the limitations of the paper in conclusion."
                },
                "weaknesses": {
                    "value": "The contribution of this paper is still a bit unclear to me, probably since I am not familiar with federated learning: It seems that the optimization dynamics turns to be *explicit* in the setting of this paper (a certain data-generating model, homogeneous two-layer CNNs and gradient descent optimization), and the results seem *direct* under the classical analysis of gradient descent. I am wonder whether this setting is representative enough, could the authors elaborate the technical innovations on this point?\n\nAnother thing that I am concerned is that the current result are strongly related to the neural networks. In my understanding, federated learning is a topic *independent* of neural networks. Could the authors discuss the probabilities that the theory in this paper can go beyond just using two-layer CNNs to be individual models? \n\n(minor) Some symbols and equations should be defined and clearly explained. The authors should check Section 3 and 4 to make sure that all symbols are defined in their occurances."
                },
                "questions": {
                    "value": "- It would be better if the authors explain the rationale behind the two-patch feature generation model again *just below* its definition. Moreover, should the signal patch and the noise patch necessarily have same dimension? \n- What is the expression of the distribution $P(\\mu^{(1)},\\mu^{(2)},\\cdots,\\mu^{(C)})$?\n- Page 3: $F_{-1}(W_{+1}, x)$ should be $F_{-1}(W_{-1}, x)$\n- Page 4: $yf(\\bar{W}^{(t)}, x<0)$ should be $yf(\\bar{W}^{(t)}, x)<0$\n- What is $w_{k',j,r}$ in eq.(6) and (8)? It seems that the right-hand-side is independent of $k'$.\n- (minor) Theorem 4.3 is a \"best-iterate\" result. Could it be turned into a \"last-iterate\" or \"average-iterate\" guarantee?\n- The discussion below Theorem 4.4 could be made more accessible. Specifically, when justifying the superiority of FedAvg compared to local training, could the authors elaborate more, rather than just discussing on two equations on SNR?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission923/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission923/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission923/Reviewer_aCq5"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission923/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698071732495,
            "cdate": 1698071732495,
            "tmdate": 1700540966629,
            "mdate": 1700540966629,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VbMHBVygft",
                "forum": "EcetCr4trp",
                "replyto": "Syx4Un7xbj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission923/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission923/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer aCq5 [Part I]"
                    },
                    "comment": {
                        "value": "Thank you for your thoughtful review and the constructive comments on our submission. We are pleased that you found the paper well-structured and the strong motivation and theoretical results. We appreciate your feedback and would like to address your concerns as follows:\n\n___\n\n> **Weakness 1 The contribution of this paper is still a bit unclear to me, probably since I am not familiar with federated learning: It seems that the optimization dynamics turns to be explicit in the setting of this paper (a certain data-generating model, homogeneous two-layer CNNs and gradient descent optimization), and the results seem direct under the classical analysis of gradient descent. I am wonder whether this setting is representative enough, could the authors elaborate the technical innovations on this point?**\n\nWhile our setting might initially appear explicit with homogeneous two-layer CNNs and gradient descent optimization, the complexity and challenges of our analysis are significantly increased by the inherent non-convexity of two-layer neural networks and the unique dynamics of federated learning. We elaborate on our main contributions as follows:\n\n1. **Impact of Weight Averaging:**\n\nUnlike single network models, federated learning involves weight averaging across multiple neural networks. This introduces additional complexity, as the training dynamics of each network are influenced by this averaging process. This will lead to the dynamic correlation between neural networks after weight averaging. Besides, despite the fact that weight averaging is a linear combination of weight, its impact on the nonlinear dynamics of individual clients is substantial. We address this by employing a global weight decomposition approach, enabling us to effectively track the dynamics of feature learning within this federated framework.\n\n2. **Impact of Data heterogeneity**\n\nIn federated learning, unlike in single network scenarios, the design of a data model distribution that encompasses both iid and non-iid cases is a significant challenge. To capture the nuances of data heterogeneity and its impact on generalization, we introduce an effective signal-to-noise ratio. This innovative approach allows us to characterize the influence of data diversity on the learning process more accurately.\n\n\n___\n\n> **Weakness 2: Another thing that I am concerned is that the current result are strongly related to the neural networks. In my understanding, federated learning is a topic independent of neural networks. Could the authors discuss the probabilities that the theory in this paper can go beyond just using two-layer CNNs to be individual models?**\n\nWhile federated learning is a broad topic that encompasses a variety of models, our research specifically addresses the challenges and dynamics associated with neural networks, which are increasingly prevalent in modern federated learning applications. The urgency to analyze federated learning within the neural network paradigm stems from both their widespread usage and the complexity of their optimization and generalization characteristics, particularly given their non-convex nature.\nThe main motivation for our work is the lack of existing studies that comprehensively reveal the generalization gap between Federated Averaging (FedAvg) and local training within the neural network framework. Our focus on two-layer CNNs is driven by the need to tackle these hard-to-analyze aspects and to provide foundational insights into how federated learning operates in neural network settings.\n\nRegarding the possibility of extending our results to more complex neural network models, we recognize this as a challenging yet intriguing direction for future research. Currently, most studies on feature learning, including our references [1,2,3], concentrate on two-layer CNNs due to their tractable analysis framework. Expanding this research to encompass more intricate neural network architectures presents a valuable opportunity for advancing the field and is an exciting prospect for subsequent work.\n\n___\n\n> **Weakness 3: (minor) Some symbols and equations should be defined and clearly explained. The authors should check Section 3 and 4 to make sure that all symbols are defined in their occurances.**\n\nWe appreciate the reviewer's attention to detail in highlighting the need for clearer definitions and explanations of certain symbols and equations in our paper. In these sections, we have now ensured that:\n\n- All symbols are defined clearly at their first point of use.\n\n- Equations are explained with adequate context and clarity to facilitate better understanding"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission923/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700490049427,
                "cdate": 1700490049427,
                "tmdate": 1700490049427,
                "mdate": 1700490049427,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "T6Tr3iIOks",
                "forum": "EcetCr4trp",
                "replyto": "xnZSBpPSWr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission923/Reviewer_aCq5"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission923/Reviewer_aCq5"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response. The authors' response has resolved my main concerns. Given that the authors will make revision as promised, I will no longer stand on the way of acceptance."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission923/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700540948325,
                "cdate": 1700540948325,
                "tmdate": 1700540948325,
                "mdate": 1700540948325,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "f0YzTdNP2e",
            "forum": "EcetCr4trp",
            "replyto": "EcetCr4trp",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission923/Reviewer_bJ2V"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission923/Reviewer_bJ2V"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies a scenario where each\nclient employs a two-layer CNN for local training\non their own data by tracking the trajectory of signal learning and noise\nmemorization in FLs. The paper shows\nthat FedAvg can achieve near-zero test error by effectively increasing the signal-to-noise ratio in feature learning, while pure local training without communication\nachieves a large constant test error. Inspired by the theoretical results, the paper proposes a heuristic weighted FedAvg which leverages the similarity of local representations into mixing weights."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper presents a fresh perspective and innovative techniques. It successfully demonstrates fruitful results, offering valuable insights into the generalization of FedAvg."
                },
                "weaknesses": {
                    "value": "1. My primary concern with this work is its inability to effectively account for the influence of local training rounds (i.e., $E$ in the paper) on generalization performance. The paper only demonstrates that when $E=\\infty$, which signifies no server-worker communication, the generalization performance is inferior compared to the scenario with $E<\\infty$. This can be partly attributed to the reduced amount of data utilized in client collaboration. It will be more exciting to see any trend within the regime $1\\leq E<\\infty$. \n\n2. The paper establishes that training convergence is independent of data heterogeneity, a finding that appears to contrast with a substantial body of research and empirical observations in FL. It would be greatly beneficial if the authors could provide further elucidation regarding why this particular model exhibits this behavior.\n\nI am open to raising my score if the two points can be adequately addressed.\n\n3. A minor point relates to the clarity of the writing. The paper's notations appear somewhat redundant and disorganized. For instance, the notations $\\mu^{(1)}, \\dots, \\mu^{(C)}$ are not used beyond Section 3.2, and the definition of $\\sigma_p$, which plays a pivotal role in signal-to-noise ratios, is missing. In Equation (4), it might be more appropriate to replace $n$ with $n_k$. I recommend that the authors thoroughly review the manuscript to enhance its overall clarity and coherence."
                },
                "questions": {
                    "value": "NA\n\n\n=================================\n\nI raised my score after the rebuttal."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission923/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission923/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission923/Reviewer_bJ2V"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission923/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698527310036,
            "cdate": 1698527310036,
            "tmdate": 1700593602677,
            "mdate": 1700593602677,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qfRivXdEtY",
                "forum": "EcetCr4trp",
                "replyto": "f0YzTdNP2e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission923/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission923/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer bJ2V"
                    },
                    "comment": {
                        "value": "Thank you for your insightful feedback and constructive comments on our submission. We appreciate the opportunity to clarify your concerns and questions as follows:\n\n___\n\n> **Weakness 1: My primary concern with this work is its inability to effectively account for the influence of local training rounds (i.e., E iin the paper) on generalization performance. The paper only demonstrates that when  which signifies no server-worker communication, the generalization performance is inferior compared to the scenario with . This can be partly attributed to the reduced amount of data utilized in client collaboration. It will be more exciting to see any trend within the regime**\n\nWe are a bit confused about this comment \u201cThe paper only demonstrates that when $E= \\infty$ \u2026\u201d as we never do that. Our analysis actually focuses on the regime where  $ 0 < E < \\infty $. This means that during the communication rounds, the number of local updates $E$ is finite. In particular, we use $T = E R$ to count the total number of local update steps, where $R$ is the number of communication rounds. In summary, all of our theoretical analyses are based on  $ 0 < E < \\infty $ instead of $E= \\infty$.\n\n___\n\n> **Weakness 2: The paper establishes that training convergence is independent of data heterogeneity, a finding that appears to contrast with a substantial body of research and empirical observations in FL. It would be greatly beneficial if the authors could provide further elucidation regarding why this particular model exhibits this behavior.** \n\nThe effect of data heterogeneity on convergence is a critical aspect of our analysis and highlights the significant influence on convergence rates. As demonstrated in Theorem 4.4,  we establish condition related to the signal-to-noise ratio (SNR):\n\n$ \\overline{n} \\cdot \\frac{\\|\\boldsymbol{\\mu}\\_k \\|^2\\_2}{\\sigma^2\\_p} \\cdot \\overline{\\mathrm{SNR}}^2\\_k =  \\Omega( 1 )$ \nwith the effective SNR for each climent $k$ given by\n $ \\overline{\\mathrm{SNR}}\\_{k} = \\left(\\sum\\_{k'=1}^K \\frac{\\langle \\boldsymbol{\\mu}\\_k, \\boldsymbol{\\mu}\\_{k'}  \\rangle}{ \\| \\boldsymbol{\\mu}_k \\|^2\\_2} \\right) \\mathrm{SNR}_k   $\n\nIn scenarios with increased data heterogeneity, the term $\\sum\\_{k'=1}^K \\frac{\\langle \\boldsymbol{\\mu}\\_k, \\boldsymbol{\\mu}\\_{k'}  \\rangle}{ \\| \\boldsymbol{\\mu}_k \\|^2_2}$ tends to decrease. To maintain a consistent SNR level in such cases, it becomes necessary to reduce $\\sigma^2_p d$, which, according to the convergence time in Theorem 4.3:\n $T = \\tilde{\\Theta}( \\eta^{-1} K mn\\sigma\\_0 ^{-1} \\sigma^{-2}\\_p d^{-1} +  \\eta^{-1}\\epsilon^{-1} mn \\sigma^{-2}\\_p K d^{-1})$\n\nresults in slower convergence.  On the contrary, if we reduce the data heterogeneity, the convergence time will become shorter.\n\n___\n\n> **Weakness 3: A minor point relates to the clarity of the writing. The paper's notations appear somewhat redundant and disorganized. For instance, the notations  are not used beyond Section 3.2, and the definition of  which plays a pivotal role in signal-to-noise ratios, is missing. In Equation (4), it might be more appropriate to replace with. I recommend that the authors thoroughly review the manuscript to enhance its overall clarity and coherence.**\n\nWe greatly appreciate your feedback regarding the clarity and organization of notations in our manuscript.\n\n1. We would like to clarity in section 4.2, we have used $|\\mu^{(C)}|$;  \nWe have introduced a clear definition of $\\sigma_p$, which represents the strength of the noise vector. The definition is now presented as follows: \n\n2.  Noise vector is distributed as  $\\boldsymbol{\\xi}\\_{k,i} \\sim \\mathcal{N}(\\mathbf{0}, {\\sigma^2\\_p}\\mathbf{I}-\\sum\\_{c=1}^C \\boldsymbol{\\mu}^{(c)} {\\boldsymbol{\\mu}^{(c)}}^\\top/\\| \\boldsymbol{\\mu}^{(c)} \\|\\_2^{2})$,  \n\n3. Thanks for your suggestion, we have replaced the term $n_k$ in Eq (4). \nWe have conducted a thorough review of the manuscript to ensure that all notations are used consistently and defined clearly at their first point of use."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission923/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700489860540,
                "cdate": 1700489860540,
                "tmdate": 1700556569906,
                "mdate": 1700556569906,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UvwMK3veIV",
                "forum": "EcetCr4trp",
                "replyto": "qfRivXdEtY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission923/Reviewer_bJ2V"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission923/Reviewer_bJ2V"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your response. \n\nJust for clarification, for weakness 1, you compared FedAvg ($0<E<\\infty$) with pure local training (i.e., no client-server communication) in the last paragraph of Section 4. The latter can somewhat interpreted as FedAvg but with $E=\\infty$. It is clear and natural that FedAvg outperforms pure local training in generalization due to more accessible data (or equivalently, stochastic gradients). However, it is more interesting to me to see how generalization performance varies with $E\\in(0,\\infty)$. Any discussion regarding this is valued.\n\nThe responses to other points make sense to me. I will reevaluate after further clarifications are given."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission923/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700499924672,
                "cdate": 1700499924672,
                "tmdate": 1700499924672,
                "mdate": 1700499924672,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hcOrEgcwVD",
                "forum": "EcetCr4trp",
                "replyto": "wX9Pk1mkpP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission923/Reviewer_bJ2V"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission923/Reviewer_bJ2V"
                ],
                "content": {
                    "comment": {
                        "value": "I understand your results but the response does not address my question. Let's leave the discussion regarding pure local training. What conclusion can you make for FedAvg's generalization performance with different values of $E$. For example, does FedAvg with a smaller $E$ generalizes better than the one with a larger $E$? Intuitively it should be the case, but if my understanding is correct, the current results are not capable to justify the difference in generalization."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission923/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700537946638,
                "cdate": 1700537946638,
                "tmdate": 1700537946638,
                "mdate": 1700537946638,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6Akjl9Wb3v",
                "forum": "EcetCr4trp",
                "replyto": "f0YzTdNP2e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission923/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission923/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your further question.\n\nFirstly, it is important to note that a smaller $E$ does not necessarily imply better generalization. To explore this relationship further, we conducted additional experiments of FedAvg on CIFAR 10. From Table 1 we can see that the generalization performance of FedAvg is not closely related to the local epoches $E$:\n\n*Table 1: Test Accuracy of FedAvg on CIFAR10 with IID setting and 10 clients, learning rate is 0.01*\n\n|   $E$ \\ $R$ |  1       |   20       | 40      | 60    |  80|\n|----------|--------|----------|-------|-------|-------| \n|   5         | 48.18 |   66.28  | 66.24 | 64.98|  64.55|\n|  10        | 54.17 |    64.6  |  64.48 | 63.44 | 64.5 |\n|  15        |  54.34 |  64.1 |   63.91 |  63.44 | 64.33|\n\nRegarding the local update $E$ there is an implicit relationship with the convergence time. Under our learning rate assumption $\\eta \\leq  \\tilde{O}(\\frac{K}{E} \\min \\{\\|\\boldsymbol{\\mu}\\|\\_{2}^{-2}, \\sigma\\_{p}^{-2}d^{-1}\\})$, increasing $E$ may lead to slower convergence. This observation aligns with the discussion in Weakness 4 with Reviewer vgxi.\n\nThe impact of varying $E$ on the required number of communication rounds to achieve adequate convergence is demonstrated in Table 2 of the FedAvg work [10], which compares the communication rounds needed for the same training accuracy on MNIST. The table shows:\n \n|     E    | B (batch size)  |  R (IID) | R (Non-IID)\n|----------|-----|--------------|--------| \n|   1      | 10 |   34 | 350 |\n|   5      | 10 |   20 | 229 | \n|   20     | 10 |   18 | 173 |\n\nThis table indicates a clear trend: as $E$ increases, so does the total number of updates ($T=ER$), evident in both IID and Non-IID settings.\n\nLastly, we would like to emphasize that our theorem does not just simply show that federated learning generalizes better than local training. Instead, our theorem demonstrates that the generalization performance of federated learning relies on the signal-to-noise ratios (SNR) among the clients. SNR effectively captures the similarity in data distribution across different clients. The large SNR values mean less data non-IID, leading to better generalization performance. This assertion also matches the practices of federated learning."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission923/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700568164662,
                "cdate": 1700568164662,
                "tmdate": 1700569565849,
                "mdate": 1700569565849,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mAVEIMoh77",
                "forum": "EcetCr4trp",
                "replyto": "6Akjl9Wb3v",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission923/Reviewer_bJ2V"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission923/Reviewer_bJ2V"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarification and I am good with it now. I suggest that the authors incorporate the supplementary experiments and discussions related to $E$ in later revisions. I have revised my evaluation accordingly. Personally, I am eagerly anticipating any theoretical justifications concerning generalization with $E$. Exploring this could present an intriguing avenue for future consideration."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission923/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700593527852,
                "cdate": 1700593527852,
                "tmdate": 1700593527852,
                "mdate": 1700593527852,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "2ufiGFj0gO",
            "forum": "EcetCr4trp",
            "replyto": "EcetCr4trp",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission923/Reviewer_u4St"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission923/Reviewer_u4St"
            ],
            "content": {
                "summary": {
                    "value": "The paper does joint generalization and convergence analysis of FL, using 2-layer NNs."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is largely well-written and seems to be a good work. I have some basic questions which I have asked below."
                },
                "weaknesses": {
                    "value": "Minor writing issues:\n- Page 2, para 1: \"under\" (rather than \"in\") a certain condition. Last sentence in this para is not clear. Didn't you earlier say that local algo has no comm.?\n- At a few places, mathematical symbols or terms are used before being defined. E.g, $\\sigma_p$ in Assum. 4.2, weighted FedAvg in the para above Sec. 6.2.\n- Questions are listed below."
                },
                "questions": {
                    "value": "3.2 Data Model:\n- Why is $y_{k,i}$ Rademacher if $\\mathbf y_k$ are labels? Are you assuming a balanced dataset? What is the distr. $P$?\n\n4.1:\n- Eq. (6) and (8) are not clear. What is $k'$? And why is there a sum over $k$ present? Where is $k'$ on r.h.s.?\n\n4.2:\n- Why is using the same training size for all clients without loss of generality?\n- Assum 4.2: what is $\\sigma_p$?\n- What is the motivation for the defn of $\\bar{SNR}_k$? \n- Theorem 4.4: in the following discussion, it is stated that $\\xi_k \\geq 1$. Since $\\{\\mu_c\\}$ are orthogonal, are you assuming that $K \\geq C$?\n\nExperiments:\n- In Assum 4.2 it was assumed that $d$ is larger than $\\bar{n} m$. But, in experiments in Sec 6.1, that's not the case ($d=1000 < \\bar{n}_{train}.m=5000$). Why?\n- In Assum 4.2, $\\eta \\lesssim 1/d$ is assumed, but in experiments, $\\eta=1$ is chosen. Can you explain this divergence?\n- In some rows of both Tables 1 and 2, singleset has better performance than FedAvg, e.g., CIFAR10 with Dirichlet or SVHN in Table 2. Why is this happening?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission923/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698871552582,
            "cdate": 1698871552582,
            "tmdate": 1699636019056,
            "mdate": 1699636019056,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "N7bj2EL7F7",
                "forum": "EcetCr4trp",
                "replyto": "2ufiGFj0gO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission923/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission923/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer u4St [Part I]"
                    },
                    "comment": {
                        "value": "Thank you for your thorough review and constructive feedback. We appreciate your recognition of our paper's strengths and would like to address the concerns you raised:\n\n___\n\n> **Minor writing 1: Page 2, para 1: \"under\" (rather than \"in\") a certain condition. Last sentence in this para is not clear. Didn't you earlier say that local algo has no comm.?**\n\nWe agree with your suggestion to use the term 'under' rather than 'in' a certain condition, and have amended this in the manuscript.\n\nRegarding the last sentence of this paragraph, we have revised it for better clarity. Our intent was to convey that by 'local training', we refer to the training process that occurs without any communication among the different clients. \n\n___\n\n> **Minor writing 2: At a few places, mathematical symbols or terms are used before being defined. E.g,  sigma_p in Assum. 4.2, weighted FedAvg in the para above Sec. 6.2.**\n\nThank you for highlighting the need for clearer definitions of certain mathematical symbols and terms used in our manuscript.\nWe have introduced a clear definition of $sigma_p$, which represents the strength of the noise vector. The definition is now presented as follows: \n\n Noise vector is distributed as  $\\boldsymbol{\\xi}\\_{k,i} \\sim \\mathcal{N}(\\mathbf{0}, {\\sigma^2\\_p}\\mathbf{I}-\\sum\\_{c=1}^C \\boldsymbol{\\mu}^{(c)} {\\boldsymbol{\\mu}^{(c)}}^\\top/\\| \\boldsymbol{\\mu}^{(c)} \\|\\_2^{2})$,  \n\nBesides, we have refined the description of the Weighted FedAvg method in Section 6.1. \n\n___\n\n\n> **3.2 Data Model: Why is  Rademacher if y are labels? Are you assuming a balanced dataset? What is the distr P.**\n\nIn our analysis, we draw labels from a Rademacher distribution, which are essentially binary variables taking values {+1,-1}. Regarding the balance of the dataset, we assume that with a sufficiently large training sample, the dataset will be approximately balanced. In this context, 'balanced' means that each class is represented proportionately in the dataset, with each class having at least one-third of the samples, as can be provably achieved under our assumptions.\n\n$P$ is defined as a discrete distribution that assigns probabilities to each element in the range from 1 to $C$, where $C$ represents the number of classes or distinct data categories.$P$ is a discrete distribution assigning probabilities to each element from $1$ to $C$. It governs the likelihood of each class or category appearing within the data set of a client. We have added this information in our updated manuscript.\n\n\n___\n\n\n> **4.1: Eq. (6) and (8) are not clear. What is ? And why is there a sum over  present? Where is  on r.h.s.?**\n\nTo address the concerns regarding Equation (6) and Equation (8), we offer the following clarification: \n\nThe rewritten form of Equation (6) is as follows:\n\n$ \\mathbf{w}\\_{k,j,r}^{(t)}  =  \\sum\\_{k'=1}^K ( \n   \\alpha^{(t)}\\_{k',j,r}   \\mathbf{w}\\_{k',j,r}^{(0)} + \\gamma\\_{k',j,r}^{(t)}   \\| \\boldsymbol{\\mu}\\_{k'} \\|^{-2}\\_2   \\boldsymbol{\\mu}\\_{k'}  +  \\sum\\_{i=1}^{n\\_{k'}} \\rho\\_{k',j,r,i}^{(t)}  \\|  {\\boldsymbol{\\xi}}\\_{k',i} \\|^{-2}\\_2    {\\boldsymbol{\\xi}}\\_{k',i}) $\n\nfor all $k \\in [K]$. The right-hand side of this equation involves a summation over all $k\u2019 \\in [K]$, which includes the specific $k$ on the left hand side. This formula represents the iteration considering weight averaging in our model. Crucially, in each iteration, the variable $\\gamma^{(t)}\\_{k,j,r}$ and $\\rho^{(t)}\\_{k,j,r,i}$ will be differ for each $k$, leading to distinct growth rates for $\\mathbf{w}\\_{k,j,r}$ across different clients.\n\n___\n\n> **4.2 Why is using the same training size for all clients without loss of generality?** \n\nWe use the same training size for all clients for simplicity and to establish a baseline for comparison. However, our framework allows for generalization to cases with varying client numbers. A more general effective signal-to-noise ratio (SNR) can be derived to account for different training sizes across clients, which adds versatility to our model.\n\n___\n\n> **Assum 4.2: what is sigma_p**\n\nThe $\\sigma^2_p$ is the variance of the noise vector. We have added this information.\n\n___\n\n> **What is the motivation for the defn of SNR**\n\nThe definition of $\\overline{SNR}_k$ is introduced to characterize the generalization of Federated Averaging (FedAvg) in the presence of data heterogeneity. While the standard SNR is sufficient for demonstrating the generalization of local training, FedAvg introduces communication among clients, affecting their individual learning processes. Therefore, $\\overline{SNR}_k$ measures the effective SNR on client $k$ under FedAvg, providing a more comprehensive understanding of generalization in a federated learning environment."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission923/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700489432101,
                "cdate": 1700489432101,
                "tmdate": 1700489432101,
                "mdate": 1700489432101,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Wj4MjKE2Xg",
                "forum": "EcetCr4trp",
                "replyto": "2ufiGFj0gO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission923/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission923/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Respectful Inquiry Before Discussion Deadline"
                    },
                    "comment": {
                        "value": "Thanks again for your thorough review and constructive feedback. As the deadline for the author-reviewer discussion phase is nearing, we would like to respectfully inquire if our rebuttal has effectively addressed the concerns raised in your review.\n\nYour insightful feedback, particularly concerning the clarifications of Eq. (6) and Eq. (8), as well as other notations and the verification of experimental results, has been invaluable in refining our manuscript. We have carefully addressed each of these points in our rebuttal and have made corresponding updates to our manuscript to reflect these changes.\n\nThank you once again for your valuable contributions to the review process. Your feedback is crucial to the continued refinement of our work."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission923/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700632640244,
                "cdate": 1700632640244,
                "tmdate": 1700632697019,
                "mdate": 1700632697019,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "efUaw94NYw",
            "forum": "EcetCr4trp",
            "replyto": "EcetCr4trp",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission923/Reviewer_vgxi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission923/Reviewer_vgxi"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the convergence and generalization properties of FedAvg for two-layer convolutional neural networks (CNNs). To do so, the authors consider a setting where the input data is divided into a signal part and noise part, with the signal being different across different clients and the noise being independently sampled from a Gaussian distribution. The analysis then tracks the coefficients of the signal and noise in the model updates done by clients and also in the global averaging step done in FedAvg. Based on this analysis, the authors show that FedAvg can provably benefit from the communication across clients by increasing the signal to noise ratio (SNR) in the global model updates. In some regimes, this can lead to FedAvg achieving near-zero test error while individual local training at clients achieves a large constant error. These theoretical results are then verified experimentally on a synthetic dataset. The authors also propose a weighted FedAvg approach which is tested empirically on some real-world datasets and shown to outperform FedAvg."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The analysis clearly establishes feature learning for this particular class of NNs, unlike most existing work on NNs which are focused on the lazy training regime and hence are not really doing feature learning.\n\n* The analysis shows that FedAvg provably benefits from collaboration among clients, by increasing the SNR compared to local training. This in turn leads to better generalization guarantees for FedAvg."
                },
                "weaknesses": {
                    "value": "* The presentation of the neural network model can be improved. The authors refer to this as a CNN model but it is not clear immediately what is the channel size, width and stride of this CNN model. It would be nice if authors could illustrate this in a figure either in the main text or appendix. Additionally, the authors also assume the weights of the second layer are fixed, which simplifies the problem.\n\n* Assumptions need to be justified better. For instance, I don't understand why $d$ has to be large to ensure an over-parameterized setting. In my understanding, just increasing $m$ should be enough to imply over-parameterization as done in [1]. Also please specify what the are 'statistical properties' that are maintained using Assumption 2. \n\n* There either seems to be a major typo/mistake in Equation (6) (and consequently Equation 8) or I am misunderstanding something. The LHS of Eq. (6) has a $k'$ but the RHS has no dependence on $k'$. Effectively this is implying that $w_{k',j,r}^{(t)}$ is going to be the same for any $k'$, which does not seem to be correct.\n\n* The analysis does not discuss the effect of the number of local epochs $E$ on the convergence of FedAvg in Theorem 4.3. For instance, in the i.i.d case when $\\mu_1 = \\mu_2 = \\dots, \\mu_K$, we would expect that doing more local steps leads to faster convergence. However, if we substitute the lower bound on $\\eta$ from Assumption 3 in Theorem 4.3, then it appears that doing more local steps slows down convergence regardless of the data heterogeneity. \n\n* I'm not sure if Lemma 5.2 is implying convergence due to the dependence of $\\bar{w}^{\\*}\\_{j,r}$ on $\\log(2/\\epsilon)$. In my understanding, if we set $\\epsilon \\rightarrow 0$ then this would imply $\\bar{w}^\\*_{j,r} \\rightarrow \\infty $ and hence $\\|\\|\\bar{W}^{(T_1)}-\\bar{W}^\\*\\|\\|_F^2 \\rightarrow \\infty$. \n\n* The authors should add personalization baselines in the experiments on measuring the performance of Weighted FedAvg. I'm not surprised to see Weighted FedAvg outperform FedAvg in Table 1 and Table 2 given that each client has a personalized model for Weighted FedAvg. Also the authors should make it clear in the abstract and introduction that Weighted FedAvg is a personalization method."
                },
                "questions": {
                    "value": "* What are some of the novelties/challenges of this analysis compared to Cao et al. (2022) and Kou et al. (2023)? It seems that many of the proof techniques such as using coefficient dynamics is similar to these works.\n\n* Can the analysis be extended the case where clients have signals of different kinds (say with some bound on the dissimilarity of signals at a particular client)? Restricting the data at one client to belong to only one signal is a bit too restrictive in my opinion.\n\n* How is $P$ defined in Section 3.2?\n\n* What is the difference between Lemma 5.3 and Theorem 4.4? It seems they are almost stating the same thing. \n\n* I would also advise the authors to use different superscripts when referring to local iteration steps versus global averaging steps. One common notation is to use $w_k^{(t,r)}$ for the local models where $t$ refers to the round number and $r$ refers to the iteration number in the $t$-th round. In the current analysis the authors use $t$ for both the local update (Eq. (4)) and global update (Eq. 5) which is a bit confusing.\n\nTypos\n\n* $F_{-1}(W_{+1}, x) $ should be $F_{-1}(W_{-1},x) $ in the line above Eq. (2)\n* Summation should be over $n_k$ in the Eq. (4) and not $n$\n* $<$ should be outside the bracket in the definition of $L_{D_k}^{(0-1)}(\\bar{W}^{(t)})$\n* $L_{D_k}$ in Lemma 5.3 is not defined. Maybe the authors meant $L_{D_k}^{(0-1)}$\n* \"Provably\" and not \"Probably\" in the heading of Section 4.2\n\n\n\n**References**\n[1] Du, Simon S., et al. \"Gradient descent provably optimizes over-parameterized neural networks.\" arXiv preprint arXiv:1810.02054 (2018)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission923/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission923/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission923/Reviewer_vgxi"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission923/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699167906168,
            "cdate": 1699167906168,
            "tmdate": 1699636018987,
            "mdate": 1699636018987,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7penKyD6GP",
                "forum": "EcetCr4trp",
                "replyto": "efUaw94NYw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission923/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission923/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer vgxi [Part I]"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for acknowledging our work on feature learning theory and the significant generalization result achieved. We address your concerns and question as follows:\n\n___\n\n> **Weakness 1: The presentation of the neural network model can be improved. The authors refer to this as a CNN model but it is not clear immediately what is the channel size, width and stride of this CNN model. It would be nice if authors could illustrate this in a figure either in the main text or appendix. Additionally, the authors also assume the weights of the second layer are fixed, which simplifies the problem.**\n\nOur choice to label the model as a CNN is based on the specific characteristics of the data model we used. We adopt a two-patch model, where $\\mathbf{x} = [\\mathbf{x}^{(1)}, \\mathbf{x}^{(2)} ]$. We implement a convolution operation using a single weight across these two patches, akin to applying a filter in traditional CNNs. This is concisely represented as follows:\n\n$f=  \\frac{1}{m} \\sum_{r=1}^m [  \\sigma( \\mathbf{w}^\\top_{k,+1,r}  \\mathbf{x}^{(1)})      + \\sigma( \\mathbf{w}^\\top_{k,+1,r}  \\mathbf{x}^{(2)}) ] -  \\frac{1}{m} \\sum_{r=1}^m [  \\sigma( \\mathbf{w}^\\top_{k,-1,r}  \\mathbf{x}^{(1)})      + \\sigma( \\mathbf{w}^\\top_{k,-1,r}  \\mathbf{x}^{(2)}) ]    $ \n\nHere the filter $\\mathbf{w}_{k,j,r}$ operates on two patch, with $k \\in [K]$ denoting the index of client, $j \\in \\{+1, -1 \\}$ corresponding to the weights value at the second layer, and $r \\in [m]$ as the filter index.\n\nOur approach alongside fixing the second layer is consistent with the related works [1,2,3], where similar network structures applying weights across multiple data patches are identified as CNNs. Despite the fixed second layer, the optimization remains non-convex despite the fixed second layer, adding complexity to our analysis.\n\nWe have added an explanation in the appendix.\n\n___\n\n> **Weakness 2: Assumptions need to be justified better. For instance, I don't understand why d has to be large to ensure an over-parameterized setting. In my understanding, just increasing m should be enough to imply over-parameterization as done in [4]. Also please specify what the are 'statistical properties' that are maintained using Assumption 2.**\n\nOur approach differs significantly from the \"lazy training\" or \"neural tangent kernel (NTK)\" regime [4,5,6]. This is because we consider a smaller initialization scale than that in the NTK regime. In our model, the width of the neural network $m$ is set to be at least polylogarithmic in the dimension, rather than extremely large as typically assumed in the NTK regime [4]. Then, to make sure that the learning is in a sufficiently over-parameterized setting, we set $d$ to be large, this can make sure that the noise vectors are near-orthogonal among each other. Similar conditions have been made in the study of learning over-parameterized models [7,8,9].\n\nRegarding the 'statistical properties' referenced in Assumption 2, these are detailed in Lemma B.1 and Lemma B.2 of our paper. These lemmas require the width of the network and number of samples to be polylogarithmic in $d$. Under this condition, our theoretical results hold with a high probability of at least $1-1/d$.\n\n___\n\n> **Weakness 3: There either seems to be a major typo/mistake in Equation (6) (and consequently Equation 8) or I am misunderstanding something. The LHS of Eq. (6) has a k\u2019 but the RHS has no dependence on k\u2019.  Effectively this is implying that w is going to be the same for any k\u2019, which does not seem to be correct.**\n\nWe appreciate the reviewer's attention to the details of our mathematical formulation. To address the concerns regarding Equation (6) and Equation (8), we offer the following clarification: \n\nThe rewritten form of Equation (6) is as follows:\n\n$ \\mathbf{w}\\_{k,j,r}^{(t)}  =  \\sum\\_{k'=1}^K ( \n   \\alpha^{(t)}\\_{k',j,r}   \\mathbf{w}\\_{k',j,r}^{(0)} + \\gamma\\_{k',j,r}^{(t)}   \\| \\boldsymbol{\\mu}\\_{k'} \\|^{-2}\\_2   \\boldsymbol{\\mu}\\_{k'}  +  \\sum\\_{i=1}^{n\\_{k'}} \\rho\\_{k',j,r,i}^{(t)}  \\|  {\\boldsymbol{\\xi}}\\_{k',i} \\|^{-2}\\_2    {\\boldsymbol{\\xi}}\\_{k',i}) $\n\nfor all $k \\in [K]$. The right-hand side of this equation involves a summation over all $k\u2019 \\in [K]$, which includes the specific $k$ on the left hand side. This formula represents the iteration considering weight averaging in our model. Crucially, in each iteration, the variable $\\gamma^{(t)}\\_{k,j,r}$ and $\\rho^{(t)}\\_{k,j,r,i}$ will be differ for each $k$, leading to distinct growth rates for $\\mathbf{w}\\_{k,j,r}$ across different clients."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission923/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700487891805,
                "cdate": 1700487891805,
                "tmdate": 1700551935568,
                "mdate": 1700551935568,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uUDOc3ilV8",
                "forum": "EcetCr4trp",
                "replyto": "efUaw94NYw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission923/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission923/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer vgxi [Part II]"
                    },
                    "comment": {
                        "value": "> **Weakness 4: The analysis does not discuss the effect of the number of local epochs on the convergence of FedAvg in Theorem 4.3. For instance, in the i.i.d case when, we would expect that doing more local steps leads to faster convergence. However, if we substitute the lower bound from Assumption 3 in Theorem 4.3, then it appears that doing more local steps slows down convergence regardless of the data heterogeneity.**\n\nWe thank the reviewer for highlighting the need to clarify the effect of the number of local epochs on the convergence of FedAvg as presented in Theorem 4.3. In our analysis, the term $T$ in Theorem 4.3 represents the total number of local updates, defined as $T = ER$, where $R$ is the number of commutation rounds and $E$ is the number of local epochs.\n\n\nWe would like to offer further clarification on the impact of increasing the number of local updates ($E$) on the overall training process in federated learning. This relationship is illustrated in the results shown in Table 2 of the referenced seminar work [10], which we have partially reproduced below for clarity\n \n|     E    | B (batch size)  |  R (IID) | R (Non-IID)\n|----------|-----|--------------|--------| \n|   1      | 10 |   34 | 350 |\n|   5      | 10 |   20 | 229 | \n|   20     | 10 |   18 | 173 |\n\nAs demonstrated in this table, there is a clear trend that as the number of local updates $E$, the total number of updates also increases. This trend is evident in both IID and Non-IID settings. \n  \nAdditionally, the effect of data heterogeneity on convergence is a critical aspect of our analysis. As demonstrated in Theorem 4.4,  we establish condition related to the signal-to-noise ratio (SNR):\n\n$ \\overline{n} \\cdot \\frac{\\|\\boldsymbol{\\mu}\\_k \\|^2\\_2}{\\sigma^2\\_p} \\cdot \\overline{\\mathrm{SNR}}^2\\_k =  \\Omega( 1 )$ \nwith the effective SNR for each climent $k$ given by\n $ \\overline{\\mathrm{SNR}}\\_{k} = \\left(\\sum\\_{k'=1}^K \\frac{\\langle \\boldsymbol{\\mu}\\_k, \\boldsymbol{\\mu}\\_{k'}  \\rangle}{ \\| \\boldsymbol{\\mu}\\_k \\|^2\\_2} \\right) \\mathrm{SNR}\\_k   $\n\nIn scenarios with increased data heterogeneity, the term $\\sum\\_{k'=1}^K \\frac{\\langle \\boldsymbol{\\mu}\\_k, \\boldsymbol{\\mu}\\_{k'}  \\rangle}{ \\| \\boldsymbol{\\mu}\\_k \\|^2\\_2}$ tends to decrease. To maintain a consistent SNR level in such cases, it becomes necessary to reduce $\\sigma^2\\_p d$, which, according to the convergence time in Theorem 4.3:\n $T = \\tilde{\\Theta}( \\eta^{-1} K mn\\sigma\\_0 ^{-1} \\sigma^{-2}\\_p d^{-1} +  \\eta^{-1}\\epsilon^{-1} mn \\sigma^{-2}\\_p K d^{-1})$ results in slower convergence.  On the contrary, if we reduce the data heterogeneity, the convergence time will become shorter.\n\n___\n\n> **Weakness 5: I'm not sure if Lemma 5.2 is implying convergence due to the dependence of $\\bar{w}^\\ast_{j,r}$ on $log\u2061(2/\\epsilon)$. In my understanding, if we set $\\epsilon \\rightarrow \\infty$ then this would imply $|| \\bar{w}^\\ast_{j,r}||\\_2\u2192\\infty$**\n\nWe appreciate the opportunity to clarify the implications of Lemma 5.2, particularly in the context of classification problems where logistic loss is applied. In such scenarios, the logistic loss function is defined as $\\ell = \\log(1+\\exp(-fy))$\n\nIn the case of logistic loss, it is a well-established property that as the loss tends to zero, the optimal weight vector tends to grow to infinity as training time goes on. Therefore, in the context of Lemma 5.2, the expectation is that the norm of the optimal weight vector $ || \\bar{\\mathbf{w}}_{j,r}^\\ast ||\\_2$ will increase over time, reflecting the model's convergence towards an optimal solution by minimizing the logistic loss. This behavior aligns with the principles of logistic regression models in machine learning and has been similarly observed and established in related works [8,11,12]."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission923/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700488447999,
                "cdate": 1700488447999,
                "tmdate": 1700556423112,
                "mdate": 1700556423112,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]