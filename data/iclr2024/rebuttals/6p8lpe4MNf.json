[
    {
        "title": "A Semantic Invariant Robust Watermark for Large Language Models"
    },
    {
        "review": {
            "id": "STnC04qn76",
            "forum": "6p8lpe4MNf",
            "replyto": "6p8lpe4MNf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1853/Reviewer_yZti"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1853/Reviewer_yZti"
            ],
            "content": {
                "summary": {
                    "value": "In this research, the authors present a semantic invariant watermark, achieved through the generation of watermark logits, taking into account the semantics of all preceding tokens. The empirical tests underscore the proposed methodology's resilience to attacks, particularly in semantically invariant contexts, including synonym substitution and paraphrasing. Furthermore, evidence corroborates that the proposed watermarking approach maintains substantial security robustness."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The conception of a semantic invariant watermark heralds an innovative and potentially transformative approach in the realm of resilient watermarking techniques.\n\nThe study introduces an novel model that adeptly converts semantic embeddings into watermark logits."
                },
                "weaknesses": {
                    "value": "1. My main concern is on the watermark detection algorithm, as detailed in Section 4.3. The detection process seemingly necessitates the logits of tokens, thereby mandating language model inference during the detection phase. This requirement poses substantial practical limitations, particularly for users with restricted computational resources, and significantly extends the time commitment for watermark detection compared to the methodology employed in KGW (2023). Crucially, accessing the language model's logits during detection implies that customers must possess knowledge of the prompt, a stipulation often unfeasible in real-world scenarios.\n\n2. Contrary to the assurances offered by KGW (2023), the detection algorithm articulated in this study does not furnish a stringent statistical affirmation concerning the rate of false positives.\n\n3. Concerning experimental configurations, the authors elected to compare their model against the KGW-k variant, where k represents the count of preceding tokens subject to hashing. It is evident that amplifying k inversely impacts watermark robustness under text modifications since any token modification influences the red-green list of k+1 tokens per the KGW (2023) framework. It would be expedient for the authors to pivot their attention toward the more resilient KGW-1 model, exploring the effects of varying parameters like watermark strength $\\delta$ and the red-green list delineation $\\gamma$.\n\n4. A scrutiny of Table 1 reveals a distinct advantage of KGW-1 over the Semantic Invariant Representation (SIR) in scenarios employing beam-search. This observation prompts the question of the necessity for SIR when KGW-1 already demonstrates superior robustness, efficiency, and a more systematic detection methodology."
                },
                "questions": {
                    "value": "The study appears to omit specific details regarding the parameters $\\delta$ and $\\gamma$ within the KGW-k model during experiments. Referring to KGW (2023), variances in these parameters can profoundly influence both the quality of watermarked text and robustness. Could the authors provide insight into how these variables were determined in the experimental setups?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1853/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697983633232,
            "cdate": 1697983633232,
            "tmdate": 1699636115735,
            "mdate": 1699636115735,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "sWxquNvFpg",
                "forum": "6p8lpe4MNf",
                "replyto": "STnC04qn76",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1853/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1853/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## About the watermark detection method\n\nPlease refer to the first response in \"Response to all reviewers.\".\n\n\n## About experimental configurations \uff08$\\delta$ and $\\gamma$\uff09\n\nFirstly, it is crucial to note that for our SIR method, the chosen hyperparameters are $\\delta= 2$, and our watermark model is trained with $\\gamma= 0.5$. These settings are consistent with the hyperparameters used in the KGW series methods, ensuring a fair comparison in experimental setups.\n\nFurther, from an algorithmic perspective, in the KGW series watermark algorithms, the most influential parameter on watermark robustness is $k$ (window size), while $\\delta$ and $\\gamma$ have minimal impact on watermark robustness. Consequently, these two parameters are seldom explored in watermark research for their effect on robustness. Below is a detailed explanation:\n\n1. Concerning the $\\delta$ parameter, it primarily influences the strength of watermark embedding. However, increasing watermark strength comes with a trade-off, affecting the quality of the generated text. A very large $\\sigma$ would degrade the algorithm to a hard red-green algorithm, where some tokens cannot be chosen at all. Conversely, a very small $\\sigma$ might result in insufficient watermark strength, rendering it undetectable in later stages.\n\n2. Regarding the $\\gamma$ parameter, this determines the proportion of the 'green' part. The most common parameter in current studies is 0.5. While a smaller $\\gamma$ might enhance watermark effectiveness in no-attack scenarios experimentally, its impact is not significant. Therefore, comparisons controlled at the same $\\gamma$ value are fair. Additionally, we conducted the following experiments to test $\\gamma$.\n\n| Method        | Ori. F1 (KGW-1) | Re. F1 (KGW-1) | Ori. F1 (SIR) | Re. F1 (SIR) |\n|---------------|-----------------|----------------|---------------|--------------|\n| $\\gamma$=0.25 | 100             | 90.6           | 100           | 90.3         |\n| $\\gamma$=0.5  | 99.8            | 90.5           | 100           | 90.0         |\n| $\\gamma$=0.75 | 98.6            | 89.8           | 98.9          | 89.9         |\n\nThe observation can be stated as follows: Although a marginal improvement in F1 is noted when comparing different values of $\\gamma$, the enhancement is not particularly significant. Consequently, it is a common practice among various works to set $\\gamma$ at 0.5.\n\n## The necessity of our method.\n\nPlease refer to the second response in \"Response to all reviewers\"\n\nWe must reiterate the contributions of our method, which were initially addressed at the beginning of the paper. The inherent issue with the KGW-N series methods is highlighted: when N is large, there is poor adversarial robustness to text modifications but strong safety robustness. Conversely, with a smaller N, adversarial robustness improves, yet safety robustness decreases.\n\nOur method ultimately achieves adversarial robustness comparable to the KGW-1 approach (albeit slightly less in beam search scenarios) but exhibits a significant enhancement in safety robustness. For details, refer to Section 6.3, particularly Figure 3(a), where our method markedly surpasses KGW-1 in safety robustness. Thus, our approach contributes uniquely. Thank you for your question, and we hope you will consider our method's soundness and contributions more thoroughly in your assessment."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700398014122,
                "cdate": 1700398014122,
                "tmdate": 1700695158707,
                "mdate": 1700695158707,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "OTI0WMEoKc",
                "forum": "6p8lpe4MNf",
                "replyto": "sWxquNvFpg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1853/Reviewer_yZti"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1853/Reviewer_yZti"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Reviewer yZti"
                    },
                    "comment": {
                        "value": "Thank you for your reply.\n\nHowever, I find that some of my concerns and questions have not been adequately addressed:\n\n1. The detection algorithm relies on prompts to generate watermarked text, which are typically unavailable in practical scenarios. If we possess the (prompt, generated text) pair, it would be evident that the text is produced by Large Language Models (LLMs). This critical issue seems to have been overlooked in the authors' rebuttal.\n\n2. The symbol $\\sigma$ is unclear. In both Algorithm 1 and in the KGW (2023) paper, $\\delta$ is used to denote the watermark strength. I would recommend that the authors maintain consistency in their notation throughout the rebuttal. Furthermore, the definition of $\\delta$ in Algorithm 1 and in KGW (2023) differs, suggesting that the authors should conduct comparisons with KGW-k at various $\\delta$ values, such as $\\delta_{KGW}=1,2,5$."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700669696373,
                "cdate": 1700669696373,
                "tmdate": 1700669696373,
                "mdate": 1700669696373,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "uYxoYawYuN",
            "forum": "6p8lpe4MNf",
            "replyto": "6p8lpe4MNf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1853/Reviewer_1s48"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1853/Reviewer_1s48"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors introduce a semantic-level watermark for large language models. This watermark perturbs the next-word logits based on the semantic meaning of preceding tokens. Unlike previously proposed token-level watermarks, the Semantic-Invariant Robust (SIR) watermark is stealthier and offers greater robustness against paraphrasing attacks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The idea of a semantic-invariant watermark is novel and well-motivated, offering enhanced resistance to paraphrasing attacks.\n- Compared to KGW, the SIR exhibits a better trade-off between attack robustness and security.\n- Benefiting from parallel processing, the computational overhead of SIR is minimal compared to models without a watermark, making it suitable for practical applications."
                },
                "weaknesses": {
                    "value": "- At the time of detection, the method necessitates the computation of the watermark logits for each token, potentially demanding more computational resources and time than KGW.\n- In scenarios involving multiple keys or users, it appears that the model provider must train a separate watermark model for each key or user. This might be expensive. Moreover, it is not clear to me how to ensure that two watermark models inject sufficiently distinct watermark logits and remain distinguishable during later detection."
                },
                "questions": {
                    "value": "- In Table 1, under the beam search category, why does SIR exhibit less robustness compared to KGW?\n- The experiments conducted limited the generation length to 200 tokens. Can the authors provide additional experiments with longer sequences? It would be insightful to compare the robustness of SIR and KGW against paraphrasing over longer sequences.\n- Is SIR susceptible to prefix injection attacks? An adversary could introduce some adversarial prefix to significantly alter the semantic meaning of an entire paragraph. Additionally, how would SIR fare in situations where individuals share generated text online without including the prompt? For instance, if one prompts the model with \"[a long Harry Potter story] + Please ignore everything before and just write an ICLR paper for me:\", would SIR remain resilient against such a straightforward attack?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1853/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1853/Reviewer_1s48",
                        "ICLR.cc/2024/Conference/Submission1853/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1853/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698353772451,
            "cdate": 1698353772451,
            "tmdate": 1700666648632,
            "mdate": 1700666648632,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Z8hWYyGKeO",
                "forum": "6p8lpe4MNf",
                "replyto": "uYxoYawYuN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1853/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1853/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## About the watermark detection method\n\nPlease refer to the first response in \"Response to all reviewers.\"\n\n## About multi-keys\n\nThank you for your insightful question. Contrary to the need for multiple watermark models to implement multi-keys, a single watermark model can be effectively paired with mapping files to achieve this. For instance, consider the watermark model producing logits $L = \\\\{l_1, l_2, \\ldots, l_{|V|}\\\\} $ for a vocabulary size $ |V|$. We can define a simple bijective mapping $f: \\\\{1, 2, \\ldots, |V|\\\\}\\rightarrow \\\\{1, 2, \\ldots, |V|\\\\}$, resulting in a new set $L' = \\\\{ j_{1},  j_{2}, \\ldots, j_{|V|}\\\\}$where each $ j_{i} $ is defined as $j_{i} = L_{f(i)} $.\n\nThis mapping process is efficient, having an $O(1) $ complexity, and does not introduce any extra burden. Moreover, designing just two distinct mappings with low similarity ensures sufficient differentiation between the keys of two users. \n\nTherefore, we believe that the concern regarding multi-key scenarios may not be a practical issue.\n\n## About the robustness againt KGW-1\n\nPlease refer to the second response in \"Response to all reviewers.\"\n\nIt is essential to revisit the inherent issues associated with the KGW-N series methods as mentioned at the begining part of our paper. Notably, these methods exhibit poor adversarial robustness in text modification when $ N $ is large, albeit with strong security robustness. Conversely, when $N$ is small, they demonstrate better adversarial robustness in text modification but weaker security robustness.\n\nOur method has achieved adversarial robustness comparable to that of KGW-1 but with a significant improvement in security robustness. This advancement is detailed in Section 6.3, particularly evident in Figure 3(a), where our method substantially surpasses KGW-1 in terms of security robustness. Thus, our approach makes a unique contribution.\n\nRegarding the slightly inferior performance of our method compared to KGW-1 under beam search conditions, it is hypothesized that the tendency for self-repetition in the KGW-1 method during beam search is more pronounced than in our approach. The beam search algorithm is known to favor sequences with higher overall generation probabilities, potentially leading to higher repetition rates.\n\nThis hypothesis is supported by our analysis of the generated texts, where we assessed the frequency of N-gram repetitions. The findings indicate that KGW-1 exhibits a marginally higher degree of self-repetition compared to our SIR method. Such a propensity for self-repetition in KGW-1 might be a contributing factor to the observed differences in performance under beam search conditions.\n\n| Method    | 1-gram | 2-gram | 3-gram |\n|-----------|--------|--------|--------|\n| SIR(ours) | 0.41   | 0.11   | 0.02   |\n| KGW-1     | 0.46   | 0.14   | 0.03   |\n| KGW-2     | 0.40   | 0.09   | 0.02   |\n| KGW-4     | 0.38   | 0.07   | 0.01   |\n\n\n## Prefix injection attacks\n\nPlease refer to the third response in \"Response to all reviewers.\""
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700396951618,
                "cdate": 1700396951618,
                "tmdate": 1700637668799,
                "mdate": 1700637668799,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5Eh0lsGHiq",
                "forum": "6p8lpe4MNf",
                "replyto": "Z8hWYyGKeO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1853/Reviewer_1s48"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1853/Reviewer_1s48"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response."
                    },
                    "comment": {
                        "value": "I really appreciate the authors' explanations and additional experiments. Therefore, I have raised my score accordingly."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700666638105,
                "cdate": 1700666638105,
                "tmdate": 1700666638105,
                "mdate": 1700666638105,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "UfRAJKhni3",
            "forum": "6p8lpe4MNf",
            "replyto": "6p8lpe4MNf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1853/Reviewer_FTnC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1853/Reviewer_FTnC"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a robust watermarking method for large language models (LLMs) that balances attack robustness and security robustness without the usual trade-offs. By using semantic embeddings of text, the proposed method embeds watermarks that remain consistent despite semantically invariant changes like synonym substitution or paraphrasing. The technique uses an auxiliary LLM to generate embeddings which a watermark model transforms into watermark logits, combined with LLM logits to generate text. Experiments show that the method maintains robustness against semantic perturbations and is secure against watermark cracking, with minimal impact on text generation. The approach represents a novel contribution to watermarking in LLMs, effectively distinguishing between watermarked and non-watermarked text."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The authors proposed an important issue in the era of generative models.\n2. High Accuracy: Achieves high accuracy in detecting text generated by LLMs.\n3. Security Robustness: Designed to be secure against attempts to crack the watermark.\n4. Efficiency: Allows watermark logits to be generated in parallel with LLM logits, causing only marginal latency increase.\n5. Novelty: First of its kind to be semantically invariant and robust in both attack and security aspects."
                },
                "weaknesses": {
                    "value": "1. It is advisable to consider a more comprehensive range of attack scenarios, similar to the approach taken by Kirchenbauer et al. The authors have conducted experiments to assess robustness, as evident in the attack rephrasing described in Section 6.2 and the security robustness analysis in Section 6.3. I am curious about the extent to which the proposed method demonstrates resilience against the attacks evaluated by Kirchenbauer et al. In Section 7 of their work, Kirchenbauer et al. have presented a diverse set of attack scenarios, including the Emoji attack. \n\nReference\nKirchenbauer et al., A Watermark for Large Language Models, ICML 2023 (https://arxiv.org/pdf/2301.10226.pdf)"
                },
                "questions": {
                    "value": "1. Could you kindly elaborate on the definition of 'watermark' within the scope of LLM? It appears that the primary emphasis of the paper is on the detection of text generated by LLMs and a detailed definition would be beneficial for clarity.\n\n2. I would appreciate additional information on the reconstruction process of the watermark. The method described in Section 4.3, involving calculations for each token t_j, piques my interest for a more in-depth understanding.\n\n3. What is the theoretical or practical capacity of the watermark within the framework presented? An explanation of its capabilities would greatly enhance the comprehensiveness of your findings.\n\n4. Could you provide further insights into the practical applications of the watermark in the realm of LLM? Digital watermarking is typically used to identify ownership of the copyright of such signal."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1853/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698788859381,
            "cdate": 1698788859381,
            "tmdate": 1699636115583,
            "mdate": 1699636115583,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "q3RVxF1q7y",
                "forum": "6p8lpe4MNf",
                "replyto": "UfRAJKhni3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1853/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1853/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## About more attack type\n\nPlease refer to third response in \"Response to all reviewers\".\n\nIn summary, we supplemented experiments regarding Emoji attack and copy paste attack, demonstrating that our method is robust in these scenarios.\n\n## About the definition of watermark\n\n\nIn the section three, we have already provided a rather detailed definition and explanation of watermark algorithms. Here, we will elaborate further.\n\nBroadly speaking, the concept of large model watermarking refers to the integration of certain covert features into the text generated by large models. These features are designed to be detectable by specific algorithms, yet remain largely imperceptible to human observation.\nThe paradigm adopted in this paper is adding small watermark logits to the already generated next token logits.\nThis is the most widely used watermark paradigm for large models.\nSpecifically, the watermark logits can be defined as  $P_{\\mathrm{W}}(x^{prompt}, t_{:l-1})$,\n and the final logits could be defined as $P_{\\hat{\\mathrm{M}}}(x^{prompt}, t_{:l-1}) = P_{\\mathrm{M}}(x^{prompt}, t_{:l-1}) + P_{\\mathrm{W}}(x^{prompt}, t_{:l-1})$, where $\\hat{\\mathrm{M}}$ is the watermarked LLM. The watermark detector $P_{\\mathrm{D}}$ corresponds to $P_{\\mathrm{W}}$, outputting 1 if text $t$ contains the watermark, otherwise 0.\n\n## Additional information on the reconstruction process of the watermark\n\nPlease refer to the first response in \"Response to all reviewers.\"\n\n\n\n## Theoretical or practical capacity of the watermark within the framework presented \n\nTo clarify the meaning of 'practical capacity' as you mentioned, if it refers to the amount of information that a watermark can carry, our watermarking technique is similar to that of Kirchenbauer et al. In both cases, the capacity of the watermark is limited to binary classification of the text, determining whether it contains a watermark or not. The watermark itself does not involve carrying additional information.\n\nThe primary contribution of our paper lies in enhancing the robustness of the watermark. This can be understood as, although the information borne by the watermark is limited to 0 (no watermark) and 1 (contains watermark), our method increases the difficulty of editing from 1 to 0. In other words, removing the watermark has become more challenging compared to previous approaches.\n\n## Application of Watermark\n\nThe primary role of watermarks in large models is to identify texts generated by these models, which has several applications:\n\n1.Large models might be prohibited in certain contexts, such as student homework or examinations. Watermarks facilitate the identification of texts produced by these models in such scenarios.\n\n2.Large models can generate a substantial volume of false or low-quality content online. Watermarks can help in recognizing these texts, contributing to a better online environment.\n\n3.If texts generated by large models are watermarked, it becomes easier to detect instances where someone might use these texts to train their own models. This acts as a deterrent against data theft, providing a layer of protection for the large models themselves. [Zhao et al. (2022)]\n\nIn summary, thank you for your question. Your inquiry is very helpful in enhancing the quality of our paper.\n\n## Reference \n\nZhao, Xuandong, Yu-Xiang Wang, and Lei Li. \"Protecting language generation models via invisible watermarking.\""
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700396876037,
                "cdate": 1700396876037,
                "tmdate": 1700397174827,
                "mdate": 1700397174827,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nQOnyh9XVc",
                "forum": "6p8lpe4MNf",
                "replyto": "q3RVxF1q7y",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1853/Reviewer_FTnC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1853/Reviewer_FTnC"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your reply.\n\n1. Watermarking is understood primarily as a method for asserting copyright ownership. Your approach, as described, seems to incorporate aspects of authenticity verification, similar to detecting fake or real signals. Could you please clarify if ownership tracking is possible?\n\n2. You've highlighted the enhancement of the watermark's \"security robustness\" as a key contribution of your research. However, the concept of 'security robustness' appears to be not clearly defined in the introduction. Given its significance to your work, a more comprehensive explanation would be beneficial especially in the Introduction. Could you kindly elaborate on what constitutes 'security robustness' in the context of your research, and why it is a focal point of your study? This would greatly aid in understanding the implications and novelty of your approach. This is just suggestion."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700630792384,
                "cdate": 1700630792384,
                "tmdate": 1700630792384,
                "mdate": 1700630792384,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ewV948MiFp",
                "forum": "6p8lpe4MNf",
                "replyto": "OK001i8YbC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1853/Reviewer_FTnC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1853/Reviewer_FTnC"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your reply and for considering my suggestion. I appreciate your explanation of how ownership can be identified using your method. However, to make a convincing argument about ownership, a methodological explanation alone is not sufficient; supporting experiments are also necessary. If the experimental results do not provide support, the argument may be considered weak. Alternatively, narrowing the scope of the study could be another option. From the perspective of proactive method for generated language detection, your paper is well-written.\n\nIf I have overlooked any experiments related to ownership in your study, could you please direct me to them?"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700672360287,
                "cdate": 1700672360287,
                "tmdate": 1700672360287,
                "mdate": 1700672360287,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0NjtXcpC8h",
                "forum": "6p8lpe4MNf",
                "replyto": "UfRAJKhni3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1853/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1853/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your patient and valuable feedback!"
                    },
                    "comment": {
                        "value": "## About Ownership Tracking\n\nThere is indeed no experiment (or any content) about ownership tracking in our paper.  This is because the application of watermark algorithms to ownership tracking falls beyond the scope of this paper. Our objective is to present a semantically invariant, robust watermarking algorithm that achieves an optimal balance in terms of resistance to attacks and security robustness, compared to previous methods. We believe that elaborating on the integration of watermarking into ownership tracking systems is not necessary within this article.  Our previous description (in rebuttal) of how our method could perform ownership tracking was primarily to demonstrate the potential of our approach in this area. \n\nThank you once again for your suggestion.\n\n## update\n\nWith less than three hours remaining until the end of the rebuttal period, if you have no further questions, would you consider updating your rating?"
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700694121650,
                "cdate": 1700694121650,
                "tmdate": 1700730630475,
                "mdate": 1700730630475,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "j7eBevX8d5",
            "forum": "6p8lpe4MNf",
            "replyto": "6p8lpe4MNf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1853/Reviewer_1hfF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1853/Reviewer_1hfF"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a method for watermarking the outputs of autoregressive large language models. Following previous works, the proposed approach intervenes at the sampling step by perturbing the language model's predicted logits for the current token. Rather than determine the logit perturbation vector (\"watermark logits\") via a fixed partition of the token vocabulary or a hash of preceding tokens, the proposed method uses a \"semantic\" representation of preceding tokens to determine the perturbation. Because detection is performed analogously, the proposed method is robust against semantics-preserving transformations of watermarked text, while obtaining stronger security against the reverse-engineering attack of Sadasivan et al. [1].\n\n[1] Vinu Sankar Sadasivan, Aounon Kumar, Sriram Balasubramanian, Wenxiao Wang, and Soheil Feizi. Can ai-generated text be reliably detected? arXiv preprint arXiv:2303.11156, 2023."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Using a \"semantic\" representation of previous tokens to determine the watermark logits for the current token, rather than e.g. a hash of the preceding n-gram, is a novel and interesting idea.\n\nThe general method of mimicking the green-list/red-list vocabulary partition of Kirchenbauer et al. [1] by using embedding and mapping networks to generate logit perturbations in $\u00b11$ is clever, and the proposed training scheme for the mapping (\"watermark\") network is intuitive and well-motivated.\n\nThe proposed method achieves similar or better robustness to established language model watermarking methods while maintaining similar or better generated text quality (as measured by perplexity) and increased robustness against the reverse-engineering attack of Sadavisan et al.\n\n[1] John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein. A watermark for large language models. arXiv preprint arXiv:2301.10226, 2023."
                },
                "weaknesses": {
                    "value": "The detection equation (7) on pp.5 is not very clear. I'm assuming that detection is performed by computing the watermark logits vector for each time step, checking if the vector entry corresponding to the observed text token at each time step is 1 (as these logits should roughly be $\u00b11$ given the saturated $tanh$), and keeping a running tally (in practice, a running sum of these selected logit values). This is basically how detection works with the watermark of Kirchenbauer et al., with the \"green list\" corresponding to watermark logits valued $1$ and the \"red list\" to logits valued $-1$. If this is indeed the case, it doesn't really come across in equation (7) -- the notation looks like we are taking the logit at the index corresponding to our current integer time step $j$ rather than the one corresponding to the observed token at the current time step $j$. I think either better notation or some additional explanation is needed.\n\nWhile the authors consider the attack of Sadasivan et al., they do not consider _adaptive_ attacks performed with general knowledge of their proposed watermarking method. Could a motivated attacker leverage a semantic embedding model of their own to better estimate or remove the watermark? Even with access to only a surrogate embedder model and no access to the mapping/watermark model, my intuition is that the tight correspondence between semantic embeddings and watermark logits might make such an adaptive attack feasible. If the number of semantic contexts that need to be observed to infer the watermark's \"rules\" in such a scenario is much lower than, say, the number of n-grams that need to be observed for KGM-n, this would constitute a serious security flaw.\n\nThe evaluation of the quality of watermarked text is somewhat limited, only covering perplexity."
                },
                "questions": {
                    "value": "If the semantic embeddings are insufficiently sensitive -- i.e., if they remain similar as more tokens are generated and added to the context -- couldn't this lead to highly repetitive generations as the same logits are boosted (similar semantic embeddings are mapped to similar watermark logits)? I could see this becoming an issue as the length of the context passed to the semantic embedder increases, as new tokens will constitute an increasingly small portion of the context window. The provided example of text generated with the proposed method (Appendix A, pp.12) seems more repetitive than the Kirchenbuaer et al. examples. It would be interesting to know whether the authors evaluated the quality of watermarked texts in terms of repetitiveness or other metrics beyond perplexity.\n\nHave the authors tried using different fixed context lengths for the semantic embedder? Because the experiments in the paper use a generation length of only 200 tokens, the authors presumably feed all previous tokens to the semantic embedder. It would be interesting to see how short and long contexts (e.g. up to the limit of the embedding model) affect the performance of the watermark in terms of robustness, security, and text quality. The required context length could also have implications for the strength of the watermark as a function of the number of tokens generated, and its robustness to cut-and-paste attacks where generated text is spliced into human-written text [1].\n\nThe watermark of Kirchenbauer et al. allows for an arbitrary \"green-list\" size. With normalization, the distribution of watermark logits produced by the proposed method looks very symmetric (Figure 2c, pp.8), corresponding to a \"green-list\" size of 50% of the vocabulary. However, this is presumably computed in aggregate over the data distribution. In practice, do the watermark logits for individual time steps ever deviate significantly from an even split between $\u00b11$?\n\n\n[1] John Kirchenbauer, Jonas Geiping, Yuxin Wen, Manli Shu, Khalid Saifullah, Kezhi Kong, Kasun Fernando, Aniruddha Saha, Micah Goldblum, and Tom Goldstein. On the Reliability of Watermarks for Large Language Models. arXiv preprint arXiv:2306.04634, 2023."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1853/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1853/Reviewer_1hfF",
                        "ICLR.cc/2024/Conference/Submission1853/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1853/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698874201438,
            "cdate": 1698874201438,
            "tmdate": 1700717579922,
            "mdate": 1700717579922,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FWoEM2wGIk",
                "forum": "6p8lpe4MNf",
                "replyto": "j7eBevX8d5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1853/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1853/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## About the watermark detection method\n\nPlease refer to the first response in \"Response to all reviewers\".\n\n## About the potential adaptive attacks\n\nWe understand your concern that users might be aware that our watermark insertion is related to the semantic embedding of the text. Therefore, we specifically demonstrate in Figure 3(a) the effect of a spoofing attack using text with highly concentrated semantic domain types(embeddings are more similar). While attacking the watermark with text of fine-grained topics like L2 class indeed shows some improvement in the attack's effectiveness, the enhancement is not significant. This, to some extent, indicates the sufficient security robustness of our method.\n\nFurthermore, for a user possessing an embedding model and attempting to break our watermark, designing such an algorithm is not straightforward and may constitute a highly complex task in algorithmic design. If you have a proposal, we are open to experimenting with it based on your approach.\n\n## Text quality Evaluation\n\n\nTo better validate the quality of the text generated by our watermarking method, we conducted further experiments in the field of machine translation. Specifically, we utilized the NLLB-200-distilled-600M model [Costa-juss\u00e0 et al. (2022)] to perform experiments on the WMT14 dataset, focusing on two translation scenarios: French to English and German to English. The results of these experiments are as follows:\n\n| Setting | Mehod     | Ori.BLEU | Wat.BLEU | Detection F1 |\n|---------|-----------|----------|----------|--------------|\n| FR-EN   | KGW-1     | 37.9     | 36.5     | 99.8         |\n| FR-EN   | SIR(ours) | 37.9     | 36.8     | 1.0          |\n| DE-EN   | KGW-1     | 38.5     | 37.7     | 1.0          |\n| DE-EN   | SIR(ours) | 38.5     | 37.9     | 1.0          |\n\nAlthough there is a slight decrease in the BLEU score after watermarking, the extent of this decrease is minimal. This indicates that the impact of our method on the quality of the text is smaller compared to that of the KGW-1 approach. We have updated the result in appendix G.\n\n## About the repetitiveness\n\nWith increasing text length, the degree of variation in embeddings diminishes. In the most extreme scenario, if the addition of any token does not alter the embedding, our method essentially degenerates to KGW-1 (a global red-green list). Consequently, the texts produced by our approach theoretically exhibit less repetition compared to KGW-1. To examine the repetition issue, we conducted statistical experiments on the N-gram repetition ratio in generated texts. The results are as follows:\n\n\n| Method    | 1-gram | 2-gram | 3-gram |\n|-----------|--------|--------|--------|\n| SIR(ours) | 0.41   | 0.11   | 0.02   |\n| KGW-1     | 0.46   | 0.14   | 0.03   |\n| KGW-2     | 0.40   | 0.09   | 0.02   |\n| KGW-4     | 0.38   | 0.07   | 0.01   |\n\n\nThe level of repetition in our generated texts is lower than that of KGW-1, but higher than KGW-2 and KGW-4. Although our method did not achieve the lowest degree of repetition, compared to the KGW series, it still represents an optimal balance in terms of text repetitiveness, robustness, and security. We have updated the result in appendix I.\n\n## About the context length\n\nA longer context length can enhance the effectiveness, yet a shorter context length results in a decrease in the overall watermark detection performance and robustness. However, this is an inherent limitation of watermark algorithms not only our methods. Here we present a comparison of the effects at different lengths.\n\n| Method    | 50-L  Ori/Re | 100-L Ori/Re | 300-L Ori/Re | 600-L Ori/Re |\n|-----------|--------------|--------------|--------------|--------------|\n| SIR(ours) | 92.8/78.4    | 98.4/87.5    | 100/92.2     | 100/98.7     |\n| KGW-1     | 92.5/77.3    | 97.5/88.0    | 100/92.4     | 100/98.9     |\n| KGW-2     | 91.7/71.5    | 98.0/81.2    | 100/84.8     | 100/93.2     |\n| KGW-4     | 92.3/65.2    | 98.1/71.4    | 100/73.5     | 100/82.1     |\n\nThe shows that as the generation length increases, both the effectiveness and robustness of detection improve. This trend is consistent with the KGW. Even when the length exceeds 600, surpassing the 512-length limit of the embedding model, truncating the context does not affect the specific detection. We have updated the result in appendix H.\n\n## About the copy paste attack\nPlease refer to the third response in \"Response to all reviewers\".\n\n## About the variance of watermark logits distribution\n\nYour concern is valid, but in reality, our statistical analysis has found that in all steps, the watermark logits are consistently divided into two parts, 1 and -1, without any significant deviation. We have calculated the proportion of 1 and -1, finding the mean to be 0.5 with a standard deviation not exceeding 0.01.\n\n## Reference\n\nKirchenbauer,et al.\"A watermark for large language models.\"\n\nCosta-juss\u00e0, et al.\"No language left behind: Scaling human-centered machine translation.\""
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700396920669,
                "cdate": 1700396920669,
                "tmdate": 1700396920669,
                "mdate": 1700396920669,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6SEJaq59nr",
                "forum": "6p8lpe4MNf",
                "replyto": "j7eBevX8d5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1853/Reviewer_1hfF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1853/Reviewer_1hfF"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "I thank the authors for their reply and for performing additional experiments. I think the inclusion of these experiments, particularly the additional attacks, will strengthen the paper. I'm willing to raise my score, but I have a three points that I'd like addressed/clarified:\n\n__1.__ In the final draft it would be good to see the additional experimental results cleaned up a bit, with the new attacks moved into Table 1 if at all possible. I also think some additional details on the copy-paste attack are necessary -- e.g. how \"topics\" are defined.\n\n__2.__ I think the paper could make the connection between KGW and the proposed method even more explicit. For example, the authors could highlight how the {\u00b11} logit perturbations essentially define red/green lists, and how detection is essentially performed in the same manner as KGW using these \"relaxed\" red/green lists. \n\n__3.__ The paper's central idea -- extending the \"red-list/green-list\" approach of KGW to enable more general conditional control over logit perturbations via embedding and mapping networks -- is novel and interesting. It allows for replacing the n-gram hashing of KGW with any suitable text embedding, and appears to offer some flexibility over \"red-list/green-list\" distributions through the training objectives of the mapping network. It would be nice if the authors could remark on this potential generality -- i.e., whether the authors expect that the proposed method only works within a narrow range of configurations (CBERT/SBERT sentence embeddings mapped to ~50/50 \u00b11 logit distributions), or whether it might be worth exploring other configurations in future work. The embedder experiments in section C suggest some rough guidelines (e.g. \"near-normal\" distribution of embedding distances), but I think the generality/flexibility angle is interesting enough to merit addressing directly, even if only briefly."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700642845465,
                "cdate": 1700642845465,
                "tmdate": 1700642902958,
                "mdate": 1700642902958,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4G98cWVNFm",
                "forum": "6p8lpe4MNf",
                "replyto": "5GgxoQEEtL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1853/Reviewer_1hfF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1853/Reviewer_1hfF"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "I thank the authors for addressing my comments. I have adjusted my score correspondingly. \n\nA few notes for the final draft:\n\n* The copy-paste attack should be updated to match at least a couple of the configurations used by Kirchenbauer et al. [1] (Section 4.2), i.e. using a fixed number of insertions and proportion of watermarked text rather than simply prepending a fixed number of tokens. Kirchenbauer et al. do this at passage lengths as small as 200 tokens, so it should be feasible.\n\n* The authors should either re-do the emoji attack with the same language model used in other attacks and incorporate the results into Table 1, or explain why a different model was used.\n\n[1] John Kirchenbauer, Jonas Geiping, Yuxin Wen, Manli Shu, Khalid Saifullah, Kezhi Kong, Kasun Fernando, Aniruddha Saha, Micah Goldblum, and Tom Goldstein. On the reliability of watermarks for large language models. arXiv preprint arXiv:2306.04634, 2023."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1853/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700666417715,
                "cdate": 1700666417715,
                "tmdate": 1700666417715,
                "mdate": 1700666417715,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]