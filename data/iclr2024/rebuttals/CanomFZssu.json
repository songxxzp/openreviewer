[
    {
        "title": "Boosting Graph Anomaly Detection with Adaptive Message Passing"
    },
    {
        "review": {
            "id": "eVAV86405O",
            "forum": "CanomFZssu",
            "replyto": "CanomFZssu",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1730/Reviewer_va1S"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1730/Reviewer_va1S"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors address the challenge of unsupervised graph anomaly detection, a crucial task in various real-world applications. Existing methods often conflict in their focus between local inconsistency mining (LIM) and message passing. LIM emphasizes identifying high similarities between abnormal nodes and their neighbors, while message passing, commonly employed by graph neural networks (GNNs), tends to make connected nodes similar, leading to local anomaly signal loss. To reconcile this conflict, the authors propose GADAM, a novel framework that not only resolves the tension between LIM and message passing but also utilizes message passing to enhance anomaly detection through a unique approach to anomaly mining beyond LIM. The effectiveness and efficiency of GADAM are extensively evaluated on nine benchmark datasets, including two large-scale OGB datasets. The results demonstrate that GADAM outperforms existing state-of-the-art methods, showcasing superior effectiveness and efficiency in unsupervised graph anomaly detection."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed method is technically sound, i.e., to overcome the issues of LIM in previous anomaly detection methods.\n- The proposed method has been tested on both synthetic and real-world anomalies and the experimental results show the effectiveness of the proposed method.\n- The conducted experiments are comprehensive including performance comparison, efficiency comparison, and ablation studies."
                },
                "weaknesses": {
                    "value": "- Although the effectiveness and efficiency of the proposed method have been empirically studied from different aspects, this is no theoretical guarantee of the proposed method.\n- The first step of MLP-based LIM aims to identify local anomalies only. However, if the given data contains more contextual anomalies, will the proposed method fail to capture them?\nThe influence of different types of anomalies on the proposed method is not discussed."
                },
                "questions": {
                    "value": "1. How to calculate H_{global} in details?\n2. If there is no prior information about the ratio of anomalous nodes in a given graph, how should one select k_{ano}? If the selected k leads to more anomalies than actual ones, will the proposed method be impacted negatively?\n3. What are the detailed steps in injecting anomalies? What the performance will change if different numbers of contextual or structural anomalies are injected (especially the proposed method first detects local structural anomalies)?\n\n--------------------------\n\nAfter rebuttal, my concerns have been addressed."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1730/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1730/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1730/Reviewer_va1S"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1730/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698711979713,
            "cdate": 1698711979713,
            "tmdate": 1700700061467,
            "mdate": 1700700061467,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Nmh9NltzPQ",
                "forum": "CanomFZssu",
                "replyto": "eVAV86405O",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer va1S, Part I"
                    },
                    "comment": {
                        "value": "We greatly appreciate your valuable time and constructive comments. We are pleased that you found our paper to be clear and of good quality. We hope our answers can fully address your concerns.\n\n**W1.** Although the effectiveness and efficiency of the proposed method have been empirically studied from different aspects, this is no theoretical guarantee of the proposed method.\n\nInspired by CoLA[1], in the first stage of the model, we employs a \"node vs. local subgraph\" contrastive learning approach to extract local anomalies. In this process, the model aims to maximize the similarity between nodes and their adjacent subgraphs. Nodes that are challenging to optimize receive higher anomaly scores due to their high local inconsistency. The motivation for such a contrastive learning framework is intuitive and fits well with the goal of mining local inconsistency. Meanwhile, our contrast learning framework has demonstrated its effectiveness in local anomaly detection, as affirmed by a considerable body of work[1,2,3].\n\nIn the second stage of the model, we focus on mining another kind of abnormal signals from the perspective of \"node vs. global normal context\". Inspired by previous work[4], we **theoretically demonstrate** that by optimizing the loss loss function Eq.(13), our model can make the distribution of learned abnormal node features spread uniformly as much as possible in the feature space. Thus GADAM can better deal with the diverse abnormal distributions.\n\nWe begin with the formal problem statement. Given a graph $G$ containing $N$ nodes, let $h_i$ be the embedding of node $v_i$, and let $q$ be the embedding for global context. Let $y_i$ be the label of node $v_i$, where $y_i=0$ corresponds to normal nodes, and $y_i=1$ indicates abnormal nodes. Assume there are $n$ normal nodes and $m$ abnormal nodes, satisfying $n+m=N$. We consider a relatively simple case by optimizing the loss function defined by Eq (13), where $n$ normal nodes are pulled closer to $q$, and the opposite for $m$ abnormal nodes:\n\n$\n\\mathcal{L} = -\\mathbb{E}_{i,j}[\\text{log}(q^Th_i) + \\text{log}(1-q^Th_j)], where ~ y_i=0, y_j=1\n$\n\nFor better clarity, we use $h^+$ to represent the embedding of a normal node, and $h^-$ to represent the embedding of an abnormal node. We perform mean pooling on all nodes to obtain $q$, thus $q = \\frac{1}{N}(\\sum_{i=1}^n h_i^+ + \\sum_{j=1}^m h_j^-)$. Then we have:\n\n**Theorem 1**: Let $X^+$ denote the random variable of normal node and $p^+$ denote its marginal distribution, thus $X^+ \\sim p^+(x^+)$. Likewise, we denote the abnormal node by $X^-$ and its marginal distribution by $p^-$. Assume $p^+$ and $p^-$ are mutually independent. Then we have: minimizing the loss $\\mathcal{L}$ forms the lower bound of 1) the cross-entropy of the two data distributions $p^+$ and $p^-$ plus 2) the entropy of $p^-$. Formally, $\\text{min}~ \\mathcal{L} \\iff \\text{max}~[H(p^-,p^+) + H(p^-)]$.\n\nThe **proof of Theorem 1** can be found in Appendix F in our revision. Below are some key conclusions drawn from Theorem 1:\n+ The cross-entropy term $H(p^-,p^+)$ in Theorem1 links to the node-wise contrastive loss, which is proved to be the cross-entropy between the predicted labels and the ground truth labels[5]. This enables GADAM to distinguish between normal and abnormal nodes effectively.\n+ Maximizing the entropy of abnormal nodes ($H(p^-)$) can be viewed as a form of data augmentation, as it enrich the information of minor classes, which helps to reduce the label imbalance issue. Also, it helps GADAM to better deal with the diverse abnormal distributions.\n+ GADAM obtains global normal context through mean pooling on high-confidence normal set $V_n$. This approach is more representative of the distribution of normal nodes when compared to the global context $q$, as it involves less contamination. \n\nIn summary,  as per Theorem 1, GADAM can effectively handle diverse distributions of anomalies and enhance its anomaly detection capabilities with a solid theoretical guarantee.\n\n**W2.** Thank you for your detailed review. We will address your conceens one by one:\n\n>(1) The first step of MLP-based LIM aims to identify local anomalies only.\n\nActually, MLP-based LIM has the ability to detect some structural anomalies. It's worth noting that the neighbors of some structural anomalies may include normal nodes(e.g. node 7 in Figure 2 of our paper). Consequently, these structural anomalies can exhibit high local inconsistency, making them detected in the first stage. Hence, $S^{local}$ remains effective in detecting structural anomalies with this characteristic.\n\n>(2) If the given data contains more contextual anomalies, will the proposed method fail to capture them? The influence of different types of anomalies on the proposed method is not discussed.\n\nThis is a good idea to do further testing of our model. We noticed that you asked a similar question in Q3, so we will answer it in detail in Q3."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1730/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700219795026,
                "cdate": 1700219795026,
                "tmdate": 1700222850157,
                "mdate": 1700222850157,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oEirFZitzL",
                "forum": "CanomFZssu",
                "replyto": "eVAV86405O",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer va1S, Part II"
                    },
                    "comment": {
                        "value": "**Q1.** How to calculate H_{global} in details?\n\nThanks for bringing this up! In the second stage, we deploy a new MLP on the raw node features and follow Eq.(3) to get $H_{global}$. After that we extract anomaly signals by considering the consistency between nodes and the global normal context. The learning process for $H_{global}$ is undertaken by optimizing Equation (13).\n\n**Q2.** If there is no prior information about the ratio of anomalous nodes in a given graph, how should one select k_{ano}? If the selected k leads to more anomalies than actual ones, will the proposed method be impacted negatively?\n\nThanks for your thoughtful consideration. We'll respond to each in turn:\n\n>(1) How to select $k_{ano}$ if there is no prior information about the ratio of anomalous nodes?\n\n$k_{ano}$ determines the size of the high-confidence abnormal set $V_a$. So the setting of $k_{ano}$ relies on two principles: (1) making $V_a$ contain as many true anomalies as possible, and (2) making $V_a$ contain as few normal nodes as possible. Ideally, the optimal value of $k_{ano}$ should be the percentage of anomalies in each dataset, i.e., it relies on the percentage of anomalies in the dataset as a priori. But we kindly emphasize that **we do not rely on the anomaly proportion of the dataset as a priori when setting $k_{ano}$**. Given that anomalies typically represent minor classes, we just empirically set $k_{ano}$ within a reasonable interval, typically no greater than 5. Ablation studies conducted in Sec 4.5.1 also demonstrate the robustness of GADAM to different $k_{ano}$ values in this interval. \n\n>(2) If the selected k leads to more anomalies than actual ones, will the proposed method be impacted negatively?\n\nIf $k_{ano}$ continues to increase, it will clearly have a negative impact on the model, as it will cause $V_a$ to be contaminated by more normal nodes, thus providing the wrong supervised signals for model training. Also, we did observe the phenomenon of negative impact on the Pubmed dataset from the ablation study of Sec 4.5.1, i.e., when $k_{ano}=4$ is larger than the actual percentage of anomalies in Pubmed (3.1%), there is a slight decrease in the AUC of the model. However, on other datasets, the $k_{ano}=5$ setting in our experiments leads to more anomalies than actual ones on many datasets according to Appendix A2, but we empirically find that the model still reaches state-of-the-art performance by a large advantage.\n\nIn summary,we set $k_{ano}$ in a reasonable interval (not greater than 5) . Also within this interval GADAM shows strong robustness as shown in ablation studies conducted in Sec 4.5.1.\n\n**Q3.** Thank you for your insightful question! Below are the detailed responses to each question:\n\n>(1) What are the detailed steps in injecting anomalies ?\n\nIn fact we provide a detailed description in Appendix A.1. For your convenience, here's a quick summary:\n\nTo inject a contextual anomaly, we randomly choose a node $i$ and select $n$ nodes as candidates.  Among the candidates, we pick node $j$ based on the largest Euclidean distance from node $i$: $||x_i \u2212 x_j || ^2$, and we replace the feature $x_i$ with $x_j$ to generate contextual anomaly.\n\nFor structural anomalies, we randomly select $m$ nodes and make them fully connected to form a cluster, and all $m$ nodes are regarded as structural anomalies. \n\nThe aforementioned methods can be applied to generate a specified number of anomalies, as detailed in Appendix A.1."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1730/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700220195047,
                "cdate": 1700220195047,
                "tmdate": 1700220195047,
                "mdate": 1700220195047,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CdFxYBQsbd",
                "forum": "CanomFZssu",
                "replyto": "eVAV86405O",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer va1S, Part III"
                    },
                    "comment": {
                        "value": ">(2) What the performance will change if different numbers of contextual or structural anomalies are injected ?\n\nThanks for your valuable suggestion! To comprehensively assess the performance of our model with different numbers of anomalies injected, we selected three representative benchmark datasets for detailed testing: **Cora** represents a small dataset that is regular and has a low average node degree, **ACM** represents a larger dataset that contains a high number of anomalies, and **BlogCatalog** represents a dataset with a large average node degree that may pose a greater challenge to structural anomaly detection. We kept the total number of anomalous nodes unchanged (consistent with our paper, see appendix A.2) and conducted tests under three scenarios: contextual anomalies only, a balanced number of anomalies, and structural anomalies only.  We measured GADAM's effectiveness using the AUC-ROC metric, with bolded results indicating the scenarios in which GADAM excels in detecting the two types of anomalies. Using the Cora dataset as an example, the bolded results show that GADAM is best at detecting contextual anomalies in the contextual only case and structural anomalies in the structural only case:\n\n**Cora**\n| contextual only |             | balanced anomalies |              | structural only |               |\n| :-------------- | ----------- | ------------------ | ------------ | --------------- | ------------- |\n| contextual=150  | structual=0 | contextual=75      | structual=75 | contextual=0    | structual=150 |\n| **0.9425**      | \\           | 0.9416             | 0.9929       | \\               | **0.9962**    |\n\n**ACM**\n\n| contextual only |             | balanced anomalies |               | structural only |               |\n| --------------- | ----------- | ------------------ | ------------- | --------------- | ------------- |\n| contextual=600  | structual=0 | contextual=300     | structual=300 | contextual=0    | structual=600 |\n| **0.9607**      | \\           | 0.9586             | **0.9721**    | \\               | 0.9678        |\n\n**BlogCatalog**\n\n| contextual only |             | balanced anomalies |               | structural only |               |\n| --------------- | ----------- | ------------------ | ------------- | --------------- | ------------- |\n| contextual=300  | structual=0 | contextual=150     | structual=150 | contextual=0    | structual=300 |\n| **0.9333**      | \\           | 0.9094             | **0.7763**    | \\               | 0.7553        |\n\nThe experimental results reveal the following insights:\n\n+ Regarding the detection of contextual anomalies, our model consistently demonstrates optimal performance in scenarios where only contextual anomalies are included. This effectively addresses the concern expressed in W2 regarding the potential impact of continuously adding contextual anomalies. It serves as validation for the excellent performance of our model in mining local anomaly signals using the conflict-free Local Inconsistency Mining (LIM) approach.\n+ In detecting structural anomalies, our model achieves competitive results when only structural anomalies are included, as compared to the scenario with a balanced number of anomalies. Surprisingly, it even outperforms on the Cora dataset. This results show that GADAM is also a strong detector of structural anomalies.\n\nIn summary, our model is capable of handling extreme anomaly distributions (contextual/structural only), and achieves very good performance in the more common balanced case. We appreciate your insightful questions, and we will integrate them in the later revision, which will help us to further improve the paper!\n\n**Reference**\n\n[1] Anomaly detection on attributed networks via contrastive self-supervised learning (TNNLS 2021)\n\n[2] Anemone: graph anomaly detection with multi-scale contrastive learning (CIKM 2021)\n\n[3] Reconstruction Enhanced Multi-View Contrastive Learning for Anomaly Detection on Attributed Networks (IJCAI 2022)\n\n[4] Gccad: Graph contrastive coding for anomaly detection (TKDE 2022)\n\n[5] A unifying mutual information view of metric learning: cross-entropy vs. pairwise losses (ICCV 2020)"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1730/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700220323827,
                "cdate": 1700220323827,
                "tmdate": 1700222661166,
                "mdate": 1700222661166,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Eja08OOyT2",
                "forum": "CanomFZssu",
                "replyto": "CdFxYBQsbd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1730/Reviewer_va1S"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1730/Reviewer_va1S"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for response"
                    },
                    "comment": {
                        "value": "Thanks for the detailed response especially the detailed explanation in Q2. These answers addressed my concerns. Therefore, I will increase my rating."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1730/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700700013752,
                "cdate": 1700700013752,
                "tmdate": 1700700013752,
                "mdate": 1700700013752,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "j0YQh5ScOa",
            "forum": "CanomFZssu",
            "replyto": "CanomFZssu",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1730/Reviewer_6vV6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1730/Reviewer_6vV6"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a model for unsupervised anomaly detection in graphs. In particular, the model focuses on 2 types of anomalies: 1) contextual (a node having attributes that are very different from its neighbors') and 2) structural (dense subgraphs). The innovation is a two-stage model that first uses an MLP to find possible contextual anomalies and then uses a message-passing graph neural network with an attention mechanism to find dense subgraphs of anomalous nodes."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Takes inspiration of previous work on contrastive learning and recent work on attention for message passing \n- Competitive time complexity\n- Experimental evaluation is fairly comprehensive and shows modest improvement over existing methods, of which there are plenty"
                },
                "weaknesses": {
                    "value": "- Performance reported for competing methods is lower than in the papers where these methods were proposed. It raises the question of whether the models are sufficiently tuned\n- No comparison to methods in the vast literature outside deep learning / neural networks. See for example https://arxiv.org/abs/1404.4679"
                },
                "questions": {
                    "value": "- The AnomalyDAE paper reports an AUC of over 97 for the BlogCatalog dataset. Do you have an explanation for the discrepancy in your paper (AUC of 76.58)? Were the authors of that paper injecting anomalies in a totally different way?\n\n- The AUC for Sub-CR, DOMINANT, and  COLA is higher in the Sub-CR paper. Do you think hyperparameters for the baseline models are sufficiently tuned?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1730/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698733736023,
            "cdate": 1698733736023,
            "tmdate": 1699636101542,
            "mdate": 1699636101542,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZgrXG1QNgl",
                "forum": "CanomFZssu",
                "replyto": "j0YQh5ScOa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer 6vV6, Part I"
                    },
                    "comment": {
                        "value": "Thanks a lot for your insightful comments and detailed suggestions, which are very helpful for us to further improve this paper. We hope our following answers will address the points you have raised and improve your view of our work.\n\n**W1.** Performance reported for competing methods is lower than in the papers where these methods were proposed. It raises the question of whether the models are sufficiently tuned\n\nThanks for your careful review and bringing this up! We will provide a more detailed explanation in our responses to Q1 and Q2 below. In summary, we adhered to the hyperparameters recommended in the original papers and employed a standardized dataset generated uniformly with PyGod[1] library to ensure fair comparisons.\n\n**W2.** No comparison to methods in the vast literature outside deep learning / neural networks. See for example https://arxiv.org/abs/1404.4679\n\nThanks for pointing this out! After a thorough examination of the relevant literature, we have identified the following key findings:\n\n+ We have incorporated the definition of anomaly from the literature into our paper. Specifically, in Section 2.1.2, it is mentioned that community based methods identify anomalies by finding densely connected nodes, which is consistent with our definition of structural anomaly.  Additionally, in Section 2.2.2, some methods mark nodes with deviate attributes from other members in a community as anomalies, which is consistent with our definition of contextual anomaly.  Consequently, certain methods from the literature hold relevance as baselines.\n+ Many methods discussed in the literature operate under a singular assumption about anomalies, tailored for a specific anomaly type. For instance, LOF[2] relies solely on node attributes to identify contextual anomalies by gauging the degree of deviation of nodes and their neighbors. On the other hand, SCAN[3] relies solely on structural information within the graph, detecting clusters through clustering for the identification of structural anomalies. In contrast, existing deep learning methods go beyond these limitations by adeptly utilizing both graph attributes and structural information, enabling a more comprehensive anomaly detection approach.\n\nIndeed, some methods outside deep learning / neural networks continue to hold relevance in contemporary anomaly detection. We refer to the benchmark[1] and chose LOF and SCAN as representative methods. Additionally, we included the widely adopted isolation forest (IF)[4] for further evaluation. Experimental results on three benchmark datasets are as follows:\n\nAUC-ROC\uff1a\n\n|              | Cora       |            |            | ACM        |            |            | BlogCatalog |            |            |\n| ------------ | ---------- | ---------- | ---------- | ---------- | ---------- | ---------- | ----------- | ---------- | ---------- |\n|              | contextual | structural | overall    | contextual | structural | overall    | contextual  | structural | overall    |\n| LOF          | 0.862      | 0.5156     | 0.7012     | 0.6167     | 0.4543     | 0.5567     | 0.3738      | 0.4741     | 0.4146     |\n| SCAN         | 0.4548     | 0.8121     | 0.6463     | 0.4534     | 0.8182     | 0.6678     | 0.4970      | 0.7579     | 0.6564     |\n| IF           | 0.7798     | 0.5054     | 0.6019     | 0.5655     | 0.5443     | 0.5602     | 0.6481      | 0.5024     | 0.5917     |\n| GADAM (ours) | **0.9416** | **0.9929** | **0.9556** | **0.9586** | **0.9721** | **0.9603** | **0.9094**  | **0.7763** | **0.8117** |\n\nThe experimental results indicate that LOF and SCAN struggle to balance performance in detecting both anomaly types, aligning with our own observations. Furthermore, IF doesn't exhibit effectiveness, likely due to its lack of specialization for graph-based data. In contrast, our proposed model showcases effective detection capabilities for both contextual and structural anomalies, leveraging the combined information from graph attributes and structure.\n\nWe sincerely appreciate your insightful review, and we will integrate the experimental results into a later revision with references to these literatures. Thank you again for enriching our paper with your valuable comment!"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1730/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700208144479,
                "cdate": 1700208144479,
                "tmdate": 1700462624077,
                "mdate": 1700462624077,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "h40Bqd928u",
                "forum": "CanomFZssu",
                "replyto": "j0YQh5ScOa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer 6vV6, Part II"
                    },
                    "comment": {
                        "value": "**Q1.** The AnomalyDAE paper reports an AUC of over 97 for the BlogCatalog dataset. Do you have an explanation for the discrepancy in your paper (AUC of 76.58)? Were the authors of that paper injecting anomalies in a totally different way?\n\nThank you for bringing up this concern! We've thoroughly reviewed the original AnomalyDAE paper and its associated source code[9]. However, it appears that the anomaly injection method is not clearly outlined in the article, and the provided source code only includes the BlogCatalog dataset with anomaly labels. To ensure a fair and comprehensive comparison, we utilized PyGOD[1], an open library from the NIPS'22 benchmark for unsupervised graph anomaly detection. We applied this library uniformly across all datasets to generate anomalies, striving for consistency and fairness.\n\nSimultaneously, we conducted experiments using the parameter configurations specified in the original AnomalyDAE paper. The obtained results align with those reported in the updated work[6]. Regrettably, due to the lack of clarity on how AnomalyDAE injects anomalies and the absence of support for other datasets in its source code, we couldn't replicate experiments on additional datasets using the provided code. We made diligent efforts to ensure the fairness of our experiments through PyGOD, and observed performance variations in AnomalyDAE may be dataset-dependent.\n\n**Q2.** The AUC for Sub-CR, DOMINANT, and COLA is higher in the Sub-CR paper. Do you think hyperparameters for the baseline models are sufficiently tuned?\n\nThank you for your thoughtful consideration. Regarding CoLA and DOMINANT, we employed PyGOD for their implementation and adhered to the parameters suggested in the original papers. We have carefully compared the results with those reported in past works[5, 6, 7] and believe that the results we obtained for these two models are in the normal range.\n\nConcerning Sub-CR, as it lacks open-source availability, we initiated communication with the authors to obtain the source code. Unfortunately, the provided source code only includes prepared datasets without an interface for anomaly injection. Consequently, we injected anomalies and tested model perfromance through PyGOD's unified interface to ensure a fair comparison. Additionally, we maintained consistency by employing the same hyperparameter settings as specified in the original paper[8].\n\nAdditionally, it's important to note that the results of the experiments will also vary with the anomaly injection implementation, software library versions, and hardware environments. In our efforts to uphold fairness, we have standardized the processes of dataset generation, baseline implementation, and model evaluation through PyGOD. We appreciate your understanding and consideration in this regard.\n\n**Reference**\n\n[1] BOND: Benchmarking Unsupervised Outlier Node Detection on Static Attributed Graphs (NIPS 2022)\n\n[2] LOF: Identifying Density-Based Local Outliers (SIGMOD 2000)\n\n[3] Scan: a structural clustering algorithm for networks. (KDD 2007)\n\n[4] Isolation forest (ICDM 2008)\n\n[5] Anemone: graph anomaly detection with multi-scale contrastive learning (CIKM 2021)\n\n[6] ComGA: Community-Aware Attributed Graph Anomaly Detection (WSDM 2022)\n\n[7] Generative and contrastive self-supervised learning for graph anomaly detection (TKDE 2021)\n\n[8] Reconstruction Enhanced Multi-View Contrastive Learning for Anomaly Detection on Attributed Networks (IJCAI 2022)\n\n[9] https://github.com/haoyfan/AnomalyDAE"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1730/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700208202043,
                "cdate": 1700208202043,
                "tmdate": 1700208202043,
                "mdate": 1700208202043,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "faPlI9ge1g",
            "forum": "CanomFZssu",
            "replyto": "CanomFZssu",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1730/Reviewer_deYB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1730/Reviewer_deYB"
            ],
            "content": {
                "summary": {
                    "value": "The authors investigate the two main paradigms, both used in many unsupervised graph anomaly detection models, message passings (MP) and local inconsistency mining (LIM). Traditionally, many graph anomaly detection models utilize the LIM for determining nodes that have inconsistency with their surroundings and mark them as anomalous. However, the use of MP with many GNN layers tends to smooth out everything, which decreases the contrastive difference between a node and its surroundings. The authors aim to address this conflict by proposing GADAM, a method that first performs LIM via a regular MLP network to get local anomaly scores without using message passing. It then combines these local scores with global scores that use an attention-based adaptive message passing that enables nodes to selectively absorb normal/abnormal signals from their surroundings. The authors then demonstrate the benefit of the models compared with baselines on several public datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Strengths:\n- An interesting approach in unsupervised anomaly detection. The over-smoothing problem is a well-known problem in GNN, and it may impact the performance of GNN-based anomaly detection models. Most unsupervised graph anomaly detection models work by finding inconsistent nodes among the neighbors. The use of message passing in GNN may impact the finding as the over-smoothing problem may make the nodes less inconsistent.\nI would argue that the conflict between LIM and overs-smoothing could be resolved within a message-passing framework by designing a better message-passing flow, imposing stricter bottlenecks in the encoder-decoder process, or other means. However, the paper proposed a different way outside the message-passing framework.\n\n- The methods combine both local perspective and global perspective to create combined perspective anomaly scores.\n- The authors demonstrate the benefit of the model against many GNN baselines"
                },
                "weaknesses": {
                    "value": "I have a few concerns and questions regarding the paper:\n1) In the contrastive pair construction (Section 3.1 item (2)), the authors mentioned that the method uses the complete adjacency subgraph. Does it mean that it includes all 1-hop neighbors? If that's the case, then the receptive field of the method is limited to just the immediate neighbors. This may limit the expressiveness of the model. There may be cases where determining normal/abnormal nodes requires more than just looking at the immediate neighbors. \n2) If in (1), it is not just 1-hop neighbors but all k-hop neighbors, then the size of the subgraphs can be potentially very large in densely connected graphs. How does the model address that?\n3) In the shuffling process, there are some chances that neighboring nodes are accidentally picked as negative pairs. How does the model account for those cases?\n4) The representations of a subgraph G in the local context are just an average of the representation of the node embeddings in G. Then, the anomaly scores for each node are measured by the difference between its node representation and the subgraph representation. It is possible that the node embedding of each neighbor is really different than the target node's embedding, but the average of the neighbor embeddings is similar to the target node. Doesn't it also introduce an over-smoothing problem? It could be worse than the standard message passing, where the aggregation is not just standard averaging but parameterized by a weight matrix. Here, the aggregation is just a plain average.\n5) The use of attention mechanisms may be counter-intuitive in unsupervised anomaly detection that is based on finding abnormal signals from the surroundings. The ability of the attention mechanism to ignore certain signals may make the model ignore suspicious signals, which will result in an abnormal case tagged as a normal case. Has the author tried to replace the attention mechanism with another mechanism, like convolution, that forces the model to utilize all signals?\n6) The experiment results of the baselines presented in the paper are rather different from the ones reported in the original paper for the same datasets. For example, in the original AnomalyDAE paper, the AUC are 97.81 (BlogCatalog), 90.05 (ACM); whereas in this paper, they are 76.58 (BlogCatalog), 75/16 (ACM). Could the authors explain more about it?\n7) How to decide topk% included in the second stage. How does the selection of this percentage affect the results?\n8) The paper is missing some unsupervised graph anomaly detection papers:\n     - Ding, Kaize, Jundong Li, Nitin Agarwal, and Huan Liu. \"Inductive anomaly detection on attributed networks.\" In Proceedings of the twenty-ninth international conference on international joint conferences on artificial intelligence, pp. 1288-1294. 2021.\n     - Huang, Yihong, Liping Wang, Fan Zhang, and Xuemin Lin. \"Are we really making much progress in unsupervised graph outlier detection? Revisiting the problem with new insight and superior method.\" arXiv preprint arXiv:2210.12941 (2022).\n     - Yang, Shujie, Binchi Zhang, Shangbin Feng, Zhanxuan Tan, Qinghua Zheng, Jun Zhou, and Minnan Luo. \"Ahead: A triple attention based heterogeneous graph anomaly detection approach.\" In Chinese Intelligent Automation Conference, pp. 542-552. Singapore: Springer Nature Singapore, 2023.\n     - Fathony, Rizal, Jenn Ng, and Jia Chen. \"Interaction-Focused Anomaly Detection on Bipartite Node-and-Edge-Attributed Graphs.\" In 2023 International Joint Conference on Neural Networks (IJCNN), pp. 1-10. IEEE, 2023.\n     - Wang, Qizhou, Guansong Pang, Mahsa Salehi, Wray Buntine, and Christopher Leckie. \"Cross-domain graph anomaly detection via anomaly-aware contrastive alignment.\" In Proceedings of the AAAI Conference on Artificial Intelligence, vol. 37, no. 4, pp. 4676-4684. 2023."
                },
                "questions": {
                    "value": "Please answer my questions in the previous section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1730/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698980038583,
            "cdate": 1698980038583,
            "tmdate": 1699636101465,
            "mdate": 1699636101465,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Zfis0wogak",
                "forum": "CanomFZssu",
                "replyto": "faPlI9ge1g",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer deYB, Part I"
                    },
                    "comment": {
                        "value": "We greatly appreciate your valuable time and constructive comments. We are pleased that you found our paper to be clear and of good quality. We hope our answers can fully address your concerns.\n\n**W1.** Thanks for your detailed review! We will address your concerns one by one:\n>(1)Does it mean that it includes all 1-hop neighbors?\n\nYes, we construct positive contrastive instance using the adjacent subgraph containing all 1-hop neighbors.\n\n>(2)The expressiveness of the model may be limited, as there may be cases where determining normal/abnormal nodes requires more than just looking at 1-hop neighbors.\n\nWe acknowledge the possibility you've pointed out. Our choice to use only 1-hop neighbors is based on several considerations:\n\n+ **Contextual Anomaly Characteristics:** Considering the nature of contextual anomalies, their primary feature is the significant inconsistency with their immediate neighbors. Utilizing 1-hop neighbors, which provides the most direct local contextual information, proves highly effective in constructing contrastive learning samples to extract the local inconsistency of nodes.\n\n+ **Normal Node Perspective:** Multi-hop neighbor information may encompass more abnormal nodes from the viewpoint of normal nodes, potentially contaminating their contextual information. For instance, node 11 in Fig.2 of our paper, employing 2-hop neighbors will introduce a substantial number of abnormal nodes, leading the model to inaccurately identify node 11 as an anomaly. Thus, while multi-hop neighbors could enhance the receptive field, they introduce uncontrollable factors into the node's context, potentially hindering model performance.\n\n+ **Efficiency Considerations:** As you rightly highlighted in W2, utilizing multi-hop neighbors increases both computational and memory overhead for the model. Both the efficiency and scalability of the model are also crucial aspects that we consider.\n\n+ **Experimental Results:** We have empirically observed that relying solely on 1-hop neighbor enables GADAM to outperform current baselines significantly. This indicates that our approach achieves a favorable balance between model effectiveness and computational efficiency.\n\n**W2.** If in (1), it is not just 1-hop neighbors but all k-hop neighbors, then the size of the subgraphs can be potentially very large in densely connected graphs. How does the model address that?\n\nAs mentioned above, our model uses only 1-hop neighbors, so the size of the subgraphs will not be too large. However, there are works such as CoLA[1] and ANEMONE[2] that utilize random walks to sample multi-hop neighbors for nodes, aiming to enhance the model's receptive filed while reducing the size of the neighborhood subgraph.  Nevertheless, these approaches have significant drawbacks:\n\n+ Neighbor information obtained through sampling introduces considerable randomness, as explicitly stated in the original paper[1]. To address this randomness, CoLA constructs multiple contrastive instances by sampling each node with $R$ rounds in the final computation of the anomaly score, as described in Sec 2.2 in our paper. In CoLA, $R$ is recommended to be set to 256, meaning each node needs to sample 256 neighborhood subgraphs for stable and competitive results, imposing a significant computational overhead.\n+ As we mentioned in W1, utilizing multi-hop neighbors may contaminate a node's neighborhood information to a greater extent, a factor that has been overlooked in existing works.\n\nWhat's more, our experimental results show that our model not only surpasses them significantly in terms of computational efficiency and GPU memory overhead but also outperforms them in terms of detection performance. We hope our explanations have addressed your queries regarding neighborhood subgraph construction. Thank you for your question, which has provided us with the opportunity for further clarification!\n\n**W3.** In the shuffling process, there are some chances that neighboring nodes are accidentally picked as negative pairs. How does the model account for those cases?\n\nThanks for your detailed review. We did take this into account in our code implementation (utils.py/idx_sample), and we utilized a pseudo-shuffle approach. Suppose `idx` is a node index vector of length N, where `idx = [0, 1, ..., N-1]`. We implemented the shuffle by first generating a random number `rand` in the range `[1, N)`, and the negative instance index corresponding to node `i` is obtained by `neg_idx[i] = (i + rand) % N`, where `% ` denotes the modulo. For example, with `N=5` and `idx = [0, 1, 2, 3, 4]`, if `rand = 2`, then `neg_idx = [2, 3, 4, 0, 1]`. This approach ensures that the negative instance of any node will not be itself."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1730/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700207177029,
                "cdate": 1700207177029,
                "tmdate": 1700207177029,
                "mdate": 1700207177029,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "R2btOlH04U",
                "forum": "CanomFZssu",
                "replyto": "faPlI9ge1g",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer deYB, Part II"
                    },
                    "comment": {
                        "value": "**W4.** The simple mean pooling method for subgraph embedding may introduce an over-smoothing problem. It could be worse than the standard message passing, where the aggregation is not just standard averaging but parameterized by a weight matrix.\n\nWe acknowledge your concerns. However, we empirically found that using only 1-hop neighbors and employing a simple mean pooling method for subgraph embedding is effective. **Introducing more parameters to learn subgraph embedding may lead to potential overfitting issues**. To address your concern, we experimented with using GCN and GAT instead of mean pooling in the first stage for subgraph embedding, while keeping the rest of GADAM unchanged. The results under AUC-ROC metric are as follows:\n\n|              | Cora       | Citeseer   | Pubmed     | ACM        | BlogCatalog | Books      | Reddit     |\n| ------------ | ---------- | ---------- | ---------- | ---------- | ----------- | ---------- | ---------- |\n| GCN          | 0.6322     | 0.7995     | 0.7561     | 0.5803     | 0.5175      | 0.5328     | 0.4242     |\n| GAT          | 0.4727     | 0.6009     | 0.7867     | 0.4001     | 0.6657      | 0.534      | 0.387      |\n| Mean pooling | **0.9556** | **0.9415** | **0.9581** | **0.9603** | **0.8117**  | **0.5983** | **0.5809** |\n\nThe experimental results demonstrate that using more advanced methods for subgraph embedding results in a significant performance drop. The primary reason for this is that the first stage of GADAM operates in an unsupervised manner, where the model enhances the consistency of all nodes and their neighbors by optimizing the loss function in Eq.(1). In this process, most nodes with high consistency are further optimized by the model, while nodes with lower consistency are identified as anomalies due to the optimization difficulty. Introducing more parameters increases the expressive power of the model, but it also leads to overfitting of the loss function, resulting in a loss of local inconsistency of the anomalous nodes.\n\n **W5.** Issues about hybrid attention mechanism.\n\nThanks for your thorough consideration! We will address your concerns one by one:\n\n>(1)The use of attention mechanisms may be counter-intuitive in unsupervised anomaly detection that is based on finding abnormal signals from the surroundings. \n\nOur attention mechanism doesn't solely rely on anomaly scores; we incorporate post-attention based on feature similarity, aligning with some traditional attention mechanisms (e.g., GAT). These two attentions are dynamically weighted to create a hybrid attention mechanism, as demonstrated to be highly effective in the ablation study in Sec 4.5.2.\n\n>(2) The ability of the attention mechanism to ignore certain signals may make the model ignore suspicious signals.\n\nIf we interpret your concern correctly, you're highlighting that our attention mechanism operates at the \"node-subgraph\" level, while traditional attention mechanisms like GAT operate at the more fine-grained \"node-node\" level. To address your concerns, we conducted additional experiments. In the second stage, we replaced the MLP+hybrid attention mechanism with GCN and GAT to extract features for nodes, while keeping the rest of GADAM unchanged. The experimental results under AUC-ROC metric are as follows:\n\n|                 | Cora       | Citeseer   | Pubmed     | ACM        | BlogCatalog | Books      | Reddit     |\n| --------------- | ---------- | ---------- | ---------- | ---------- | ----------- | ---------- | ---------- |\n| GCN             | 0.9179     | 0.9290     | 0.9514     | 0.9240     | 0.5175      | 0.5260     | 0.5585     |\n| GAT             | 0.9383     | 0.9337     | 0.9507     | 0.9334     | 0.6077      | 0.3905     | 0.5623     |\n| MLP+hybrid attn | **0.9556** | **0.9415** | **0.9581** | **0.9603** | **0.8117**  | **0.5983** | **0.5809** |\n\nThe experimental results indicate that simple convolution(GCN) is ineffective due to the over-smoothing problem, where convolution tends to make anomalies indistinguishable. Although traditional attention mechanisms(GAT) can yield competitive results in some cases, the overall performance doesn't match GADAM. This discrepancy arises because, at the beginning of training in the second stage, the encoder as well as $H_{global}$ is not fully optimized. Node-node attention relies solely on feature similarity, offering less effective guidance in the early stages despite its finer granularity. In contrast, our hybrid attention, which integrates pre-attn based on anomaly scores and post-attn based on feature similarity through a dynamic weighted sum, has proven to be a highly effective design, as demonstrated in Sec 4.5.2.\n\nIf we have misunderstood your concerns, feel free to let us know!"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1730/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700207610793,
                "cdate": 1700207610793,
                "tmdate": 1700221848100,
                "mdate": 1700221848100,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "okUBPOQlWY",
                "forum": "CanomFZssu",
                "replyto": "faPlI9ge1g",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer deYB, Part III"
                    },
                    "comment": {
                        "value": "**W6.** Issues about baseline performance reported in this paper, particularly in comparison to the AnomalyDAE paper. The AUC are 97.81 (BlogCatalog), 90.05 (ACM) in the original paper; whereas in this paper, they are 76.58 (BlogCatalog), 75.16 (ACM).\n\nThank you for bringing up this concern! We've thoroughly reviewed the original AnomalyDAE paper and its associated source code[3]. However, it appears that the anomaly injection method is not clearly outlined in the article, and the provided source code only includes the BlogCatalog dataset with anomaly labels. To ensure a fair and comprehensive comparison, we utilized PyGOD[4], an open library from the NIPS'22 benchmark for unsupervised graph anomaly detection. We applied this library uniformly across all datasets to generate anomalies, striving for consistency and fairness.\n\nSimultaneously, we conducted experiments using the parameter configurations specified in the original AnomalyDAE paper. The obtained results align with those reported in the updated work[5]. Regrettably, due to the lack of clarity on how AnomalyDAE injects anomalies and the absence of support for other datasets in its source code, we couldn't replicate experiments on additional datasets using the provided code. We made diligent efforts to ensure the fairness of our experiments through PyGOD, and observed performance variations in AnomalyDAE may be dataset-dependent.\n\n**W7.** How to decide topk% included in the second stage. How does the selection of this percentage affect the results?\n\nThanks for brining this up! For both $k_{nor}$ and $k_{ano}$, the common setting principle is to include as many correct supervisory signals as possible.\n\n+ $k_{nor}$ determines the size of the high-confidence normal set $V_{n}$\u3002Given that normal nodes constitute the majority of the dataset,  $V_{n}$ generally includes a very small proportion of true anomalies. Consequently,  $k_{nor}$ can be set as long as it ensures an adequate supply of supervisory signals,  and we set it to a larger value in our experiments. We also found in our implementation that the setting of $k_{nor}$ has minimal impact on the model's performance.\n+ $k_{ano}$ determines the size of the high-confidence abnormal set $V_a$, it seeks to include as many true anomalies as possible and exclude normal nodes. So $k_{ano}$ is ideally set to be as close as possible to, but not substantially larger than, the proportion ($p$) of anomalies in the datasets. Intuitively, when $k_{ano}>p$, a continuous increase in $k_{ano}$ will cause more normal nodes to be marked as anomalous, thus provide more false pseudo-labels for the second stage, and lead to model's performance drop. Importantly, we kindly emphasize that **we do not rely on the true anomaly proportion of the dataset as a priori when setting $k_{ano}$.** We just empirically set $k_{ano}$ within a reasonable interval, typically no greater than 5. Ablation studies conducted in Sec 4.5.1 also demonstrate the robustness of GADAM to different $k_{ano}$ values. \n\n**W8.** The paper is missing some unsupervised graph anomaly detection papers\u3002\n\nWe appreciate your thorough review and a wealth of related works you've provided. We carefully examined these works you mentioned and will introduce each method systematically:\n\n+ **AEGIS[6]:** AEGIS mainly focuses on inductive learning, including an anomaly-aware GNN layer and gives the model the ability to detect new anomalies by generative adversarial learning. Unfortunately, AEGIS is not open sourced and unavailable through PyGOD, a fair comparison may not be feasible.\n+ **VGOD[7]:**  VGOD designs two modules for structural and contextual anomalies respectively, which belongs to the same domain as our work. In the following section, we will conduct a detailed comparison with VGOD.\n+ **AHEAD[8]:** AHEAD is designed for anomaly detection in heterogeneous graphs. Therefore its research has little relevance to us, and its open source code is specifically implemented for IMDB dataset, so we cannot include AHEAD in our baseline.\n+ **GraphBEAN[9]:** GraphBEAN is designed for bipartite node-and-edge-attributed graphs, and detects anomalous nodes and edges simultaneously. Taking the example of consumer-purchase-product graph, GraphBEAN is designed to detect edges representing anomalous transactions, and users with anomalous behavior. Thus its research area has little overlap with our work, and we won't consider it as a baseline in our study.\n+ **ACT[10]:** ACT focuses on cross-domain graph anomaly detection (CD-GAD), which describes the problem of detecting anomalous nodes in an unlabeled target graph using auxiliary, related source graphs with label nodes. Recognizing the specific requirements for auxiliary source graphs,  we agree that it's not suitable for inclusion in our baseline."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1730/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700207912808,
                "cdate": 1700207912808,
                "tmdate": 1700207912808,
                "mdate": 1700207912808,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3qKhc58tzE",
                "forum": "CanomFZssu",
                "replyto": "faPlI9ge1g",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer deYB, Part IV"
                    },
                    "comment": {
                        "value": "**GADAM vs. VGOD**\n\nThe anomaly detection module of VGOD is designed specifically for two types of anomalies. It uses autoencoder to reconstruct the nodes and the reconstruction error is used to detect the contextual anomaly. At the same time, it uses the variance of the node's neighborhood features as a measure of the structural anomaly score, and finally the two anomaly scores are jointly used as the criteria for anomaly detection. Therefore, in order to explore whether VGOD is also applicable to real datasets containing organic anomalies, we extended our evaluation to include the Disney dataset, and the statistic of Disney is as follows:\n\n|        | #Nodes | #Edges | Degree | #Anomalies | Ratio |\n| ------ | ------ | ------ | ------ | ---------- | ----- |\n| Disney | 124    | 335    | 2.7    | 6          | 4.8%  |\n\nWe performed extensive comparative experiments across seven datasets, where * denotes datasets with organic anomalies. Except for Disney, the other datasets are the ones utilized in our paper, and their statistics are provided in Appendix A.2. The results, evaluated under various metrics, are presented below:\n\n**AUC-ROC**\n\n|       | Cora       | Citeseer   | Pubmed     | BlogCatalog | Books*     | Reddit*    | Disney*    |\n| ----- | ---------- | ---------- | ---------- | ----------- | ---------- | ---------- | ---------- |\n| VGOD  | 0.9503     | **0.9845** | **0.9813** | 0.796       | 0.373      | 0.523      | 0.387      |\n| GADAM | **0.9556** | 0.9415     | 0.9581     | **0.8122**  | **0.5983** | **0.5809** | **0.8178** |\n\n**recall@k**\n\n|       | Cora       | Citeseer | Pubmed    | BlogCatalog | Books*     | Reddit*    | Disney*    |\n| ----- | ---------- | -------- | --------- | ----------- | ---------- | ---------- | ---------- |\n| VGOD  | 0.593      | **0.76** | **0.555** | 0.313       | 0          | 0.025      | 0          |\n| GADAM | **0.7299** | 0.712    | 0.462     | **0.3667**  | **0.0143** | **0.0699** | **0.1667** |\n\n**average precision**\n\n|       | Cora      | Citeseer | Pubmed   | BlogCatalog | Books*     | Reddit*    | Disney*    |\n| ----- | --------- | -------- | -------- | ----------- | ---------- | ---------- | ---------- |\n| VGOD  | 0.695     | **0.84** | **0.56** | 0.212       | 0.016      | 0.035      | 0          |\n| GADAM | **0.728** | 0.7512   | 0.4264   | **0.296**   | **0.0279** | **0.0481** | **0.1695** |\n\nExperimental results show that VGOD is a very strong baseline on some generative datasets (Citeseer, Pubmed), but its performance on real datasets containing organic anomalies has a dramatic drop. Especially on Books and Disney, its performance is not good than random guess. We attribute this observation to VGOD being specifically tailored for synthetic anomalies, making its poor performance on real-world datasets. In contrast, our model excels by capturing two types of anomaly scores from both local and global perspectives, showcasing superior generalization capabilities and practical utility for real-world applications.\n\nWe sincerely thank you for the valuable related works, we will integrate the results into the later revision, which will help us to achieve a great improvement of our paper!\n\n**Reference**\n\n[1] Anomaly detection on attributed networks via contrastive self-supervised learning (TNNLS 2021)\n\n[2] Anemone: graph anomaly detection with multi-scale contrastive learning (CIKM 2021)\n\n[3] https://github.com/haoyfan/AnomalyDAE\n\n[4] BOND: Benchmarking Unsupervised Outlier Node Detection on Static Attributed Graphs (NIPS 2022)\n\n[5] ComGA: Community-Aware Attributed Graph Anomaly Detection (WSDM 2022)\n\n[6] Inductive anomaly detection on attributed networks. (IJCAI 2021)\n\n[7] Are we really making much progress in unsupervised graph outlier detection? Revisiting the problem with new insight and superior method. (arxiv 2022)\n\n[8] Ahead: A triple attention based heterogeneous graph anomaly detection approach (2023)\n\n[9] Interaction-Focused Anomaly Detection on Bipartite Node-and-Edge-Attributed Graphs (IJCNN 2023)\n\n[10] Cross-domain graph anomaly detection via anomaly-aware contrastive alignment (AAAI 2023)"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1730/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700207997996,
                "cdate": 1700207997996,
                "tmdate": 1700207997996,
                "mdate": 1700207997996,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xVfNiZ69z4",
                "forum": "CanomFZssu",
                "replyto": "3qKhc58tzE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1730/Reviewer_deYB"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1730/Reviewer_deYB"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks the authors for the detailed response. \nI do not have additional concerns. \n\nFor the additional papers I listed, even though they may not totally align with this paper direction (and hence not suitable for baseline), I still suggest citing the papers, to provide the reader a broader overview of the research on unsupervised graph anomaly detection."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1730/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700731007152,
                "cdate": 1700731007152,
                "tmdate": 1700731007152,
                "mdate": 1700731007152,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fA6iR08AUp",
                "forum": "CanomFZssu",
                "replyto": "faPlI9ge1g",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow-up response"
                    },
                    "comment": {
                        "value": "Based on your valuable suggestions, we have integrated the related works you suggested into Sec. 5 of the revision (detailed in Appendix B.4). We are pleased that our detailed response has helped address your concerns. We sincerely hope that these enhancements will contribute to achieving a higher score!"
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1730/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700735816266,
                "cdate": 1700735816266,
                "tmdate": 1700736751551,
                "mdate": 1700736751551,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1YPycJpAX9",
            "forum": "CanomFZssu",
            "replyto": "CanomFZssu",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1730/Reviewer_WYWU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1730/Reviewer_WYWU"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses the problem of unsupervised node-level anomaly detection in a graph through an adaptive message passing framework. The paper rightly motivates the fact that message passing in GNNs results in local anomaly signal loss. The authors have proposed an approach to obtain local and global anomaly scores through MLP and hybrid attention based adaptive message passing. The paper has conducted experiments on anomaly detection on real world datasets with both injected and ground truth anomalies, and used a good number of baseline approaches from the literature."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The idea of using local anomaly score to compute the global anomaly score is interesting.\n2. The paper uses a good number of baseline algorithms from the literature."
                },
                "weaknesses": {
                    "value": "1. The problem formulation seems to be problematic. Authors have mentioned \"Structural anomalies are densely connected nodes in contrast to sparsely connected regular nodes\". What about the networks that are dense by nature? Moreover, if density is the only criteria for being a structural anomaly, why can't we use degree of a node as the metric to find the structural anomalies? Are we over-complicating the solution of a relatively simple problem?\n\n2. I am not convinced with the proposed solution. s^local (in Eq. 6) can only capture contextual anomalies, but not the structural anomalies because of the L2 normalization in Eq. 3. Where exactly are we capturing the structural anomalies in this framework?\n\n3. What is the difference between H_local and H_global? They seem to be computed in the same way through Eq. 3. Why are we calling the second one as \"global\"?\n\n4. Some of the claims in the paper should have been explained more. Can you please elaborate the reason of \"as the training advances, the influence of pre-attention gradually diminishes, while the opposite for post-attention\".\n\n5. In Table 1, overall anomaly detection performance is reported. I am curious to see the performance on contextual and structural anomalies separately.\n\n6. As mentioned before, degree centrality seems to be a good metric to capture the structural anomalies. Can you please include this heuristic as a baseline to compare with?\n\n7. How do you capture the nodes which are both contextual and structural anomalies? Also, will your approach be able to capture \"Combined Outliers\" (or combined anomalies) as introduced in \"Outlier Aware Network Embedding for Attributed Networks\" (AAAI-2019)?"
                },
                "questions": {
                    "value": "Please see the questions above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1730/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699557416544,
            "cdate": 1699557416544,
            "tmdate": 1699636101383,
            "mdate": 1699636101383,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ELS3VdQjOl",
                "forum": "CanomFZssu",
                "replyto": "1YPycJpAX9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer WYWU, Part I"
                    },
                    "comment": {
                        "value": "Thanks for your insightful review. We provide detailed answers to your questions as follows, and we hope that our response can address your concerns.\n\n**W1.** Thanks for brining up this fundamental question! We will address your concerns one by one:\n> (1) Definition of structural anomaly\n\nThe definition of structural anomaly in our paper aligns with the latest benchmark from NIPS'22[1]. Notably, this definition is widely used in the field of unsupervised graph anomaly detection and is evident in the majority of existing works[2,3,4,5]. Structural anomaly is prevalent in the real world and is characterized by **nodes which are densely connected with abnormal links**. Examples range from members of organized fraud gangs, people from different communities but closely connected to each other, and even papers that engage in malicious citations. In our work, we adopt the anomaly injection method used in previous papers[1,2,3,4,5] to generate densely and abnormally connected nodes as structural anomalies (see Appendix A.1). While we acknowledge that solely emphasizing on \"densely connected\" can lead to ambiguities in the understanding of structural anomalies, and we will add a new term for \"abnormal links\" in a later revision.\n\n> (2) What if the networks are dense by nature?\n\nAs discussed earlier, **structural anomalies are essentially clusters of densely and abnormally linked nodes**. Therefore, there is no inherent conflict between the graph itself being dense and the definition of structural anomalies. In a dense graph, normal nodes are normally connected to each other, while structural anomalies have abnormal connections to each other. As we introduced in Appendix A.1, when generating structural anomalies, we randomly select $m$ (e.g. $m=15$) nodes and connect them to each other. The randomly selected nodes come from different communities, thus creating densely and abnormally linked structural anomalies, which is consistent with the definition of structural anomalies.\n\n> (3) Can we use node degrees to find structural anomalies\uff1f\n\nThis is indeed an interesting idea. However, as previously discussed, employing node degree is not aligned with the essence of detecting structural anomalies, since the degree does not reflect the abnormal links of nodes. For instance, in networks like Twitter's following network or paper citation networks such as Cora, it is clear that we cannot simply mark accounts with high number of followers or highly cited papers as anomalies, even though they have significantly higher node degrees compared to other nodes. We will delve deeper into validating the effectiveness of utilizing node degree for structural anomaly detection in response to W6.\n\n> (4) Are we over-complicating the solution of a relatively simple problem?\n\nFollowing the discussion above, we don't consider the detection of structural anomalies to be overly complicated. Utilizing node degree only exploits the phenomenon of being densely connected and can easily fail in graphs with high average node degrees, as we will demonstrate in response to W6. In contrast, our model takes a principled approach to anomaly detection by capturing two types of anomaly signals from both local and global perspectives. The anomaly signals are propagated through dense links in the cluster of abnormal nodes by adaptive message passing in the second stage. This process enhances the anomaly scores of structural anomalies as a whole, and we believe this approach possesses greater generalization capabilities and is more in line with the essence of anomaly detection.\n\n\n **W2.** Thank you for raising this point.\n\n Firstly, the anomaly signal in the first stage is derived from the local inconsistency between nodes and their neighbors. L2 normalization is applied to normalize node features, facilitating the use of cosine similarity as a consistency discriminator. However, **this doesn't lead to the failure of detecting structural anomalies**. It's worth noting that the neighbors of some structural anomalies may include normal nodes(e.g. node 7 in Figure 2 of our paper). Consequently, these structural anomalies can exhibit high local inconsistency, making them detected in the first stage. Hence, $S^{local}$ remains effective in detecting structural anomalies with this characteristic.\n\nIn addition to the structural anomalies described above that are captured, in the second stage, we enhance structural anomaly detection through adaptive message passing. Specifically, structural anomalies identified in the first stage act as supervisory signals in the second stage, guiding the model to push them away from the global normal context. The hybrid attention mechanism plays a crucial role in this process by amplifying the message passing of these structural anomalies in a cluster. Consequently, other structural anomalies align with these captured nodes and move away from the global normal context, thereby contributing to an improved overall cluster anomaly score."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1730/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700205279000,
                "cdate": 1700205279000,
                "tmdate": 1700206774437,
                "mdate": 1700206774437,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VKkaY4dKJf",
                "forum": "CanomFZssu",
                "replyto": "1YPycJpAX9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer WYWU, Part II"
                    },
                    "comment": {
                        "value": "**W3**. What is the difference between H_local and H_global? Why are we calling the second one as \"global\"?\n\nIndeed, both $H_{local}$ and $H_{global}$ are calculated in the same way through Eq.(3), but as we claimed in  Sec. 3.2.1, $H_{global}$ employs a new MLP as an encoder.\n\nTo elaborate, in the first stage, we utilize one MLP on the raw node features to obtain $H_{local}$, employing the local inconsistency of the nodes as anomaly signals and learning $H_{local}$ through Eq.(1). While in the second stage, we deploy another MLP on the raw features to get $H_{global}$, mining the anomaly signals from the consistency of the nodes and global normal context, and learning $H_{global}$ through Eq.(13). We refer to the second one as \"global\" from the perspective of anomaly signaling.\n\n**W4**.  Can you please elaborate the reason of \"as the training advances, the influence of pre-attention gradually diminishes, while the opposite for post-attention\"?\n\nThanks for brining this up. We will explain the reasons for this in terms of formula definitions and design intuitions, respectively:\n\n+ As defined in Ep.(12), pre-attention and post-attention regulate the weights by a weight coefficient $\\beta_t$ that varies with the training step. In this process the weight of pre-attn is gradually decreased while the weight of post-attn is increased through $\\beta_t$.\n+ This is a special design with the following considerations: (1) At the beginning of training in the second stage,  $H_{global}$ is not fully optimized, and pre-attn serves a reliable criterion to judge whether a node should align with its neighbors. However, we consider that the local anomaly scores in the first stage may contain inherent errors. For example, it fails to detect certain structural anomalies with high local consistency. Gradually reducing the weight of pre-attn aims to prevent inherent errors in local anomaly scores from continuously misdirecting attention for nodes. (2) As training progresses, nodes adaptively align with their neighbors through message passing involving hybrid attention. Therefore, we increase the weight of post-attn based on feature similarity as a complementary and corrective measure to pre-attn.\n+ In the ablation experiments in Section 4.5.3, we also examined various attentional mechanisms. The results demonstrate that the dynamic sum approach exhibits a substantial advantage over other alternatives.\n\nThe explanations provided above are also articulated in our paper, accompanied by visualizations of the attention coefficients in Appendix E. These visualizations demonstrate that hybrid attention effectively reduces the message passing of contextual anomalies while enhancing them for normal nodes and structural anomalies with their surroundings. We hope that our explanations could help you further understand our design motivations!\n\n**W5.** I am curious to see the performance on contextual and structural anomalies separately.\n\nThanks for your valuable comment! To assess the efficacy of our model in detecting two types of anomalies, we selected three benchmark datasets for experimentation. **Cora** serves as a small, regular dataset with a low average node degree. **ACM**, on the other hand, represents a larger dataset with a substantial number of anomalies. Finally, **BlogCatalog** is characterized by a large average node degree, presenting a greater challenge for the detection of structural anomalies. Additionally, we chose representative models from the baseline families\u2014DOMINANT, CoLA, Sub-CR and ComGA\u2014for comparative experiments. The experimental results under the AUC-ROC metric are as follows:\n\n|          | Cora       |            | ACM        |            | BlogCatalog |            |\n| -------- | ---------- | ---------- | ---------- | ---------- | ----------- | ---------- |\n|          | contextual | structural | contextual | structural | contextual  | structural |\n| DOMINANT | 0.7173     | 0.9312     | 0.7045     | 0.8182     | 0.7371      | 0.7664     |\n| CoLA     | 0.8934     | 0.8213     | 0.9103     | 0.8325     | 0.8585      | 0.7325     |\n| ComGA    | 0.8173     | 0.9052     | 0.7525     | 0.8989     | 0.8294      | 0.7679     |\n| Sub-CR   | 0.9057     | 0.9293     | 0.7067     | 0.7913     | 0.8267      | 0.7573     |\n| GADAM    | **0.9416** | **0.9929** | **0.9586** | **0.9721** | **0.9094**  | **0.7763** |\n\nThe results show that:\n\n+ Most of the baselines struggles to balance the detection of both types of anomalies, while GADAM achieves the best.\n+ On the two sparser datasets, Cora and ACM, GADAM significantly outperforms baselines in structural anomaly detection. Even on the denser BlogCatalog dataset, GADAM continues to outperform all baselines, providing further validation of the effectiveness for structural anomaly detection. This outcome aligns with our model designs described in W2.\n\nWe intend to incorporate these valuable results into our later revisions, thanks again for your valuable comment!"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1730/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700205686816,
                "cdate": 1700205686816,
                "tmdate": 1700205686816,
                "mdate": 1700205686816,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JaY2IkHq0k",
                "forum": "CanomFZssu",
                "replyto": "1YPycJpAX9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1730/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer WYWU, Part III"
                    },
                    "comment": {
                        "value": "**W6.** Can you please include degree as a baseline to compare with?\n\nCertainly. Given that degree is only capable of detecting structural anomalies, we evaluated its performance **specifically on structural anomalies** using the benchmark datasets mentioned in our paper. We have also provided the average node degree (avg_d) for each dataset, and listed the datasets in increasing avg_d to offer more clarity. The results, measured under the AUC-ROC metric, are as follows:\n\n|        | Citeseer(avg_d = 1.4) | Pubmed(avg_d = 2.3) | ACM(avg_d = 4.4) | ogbn-Products(avg_d = 25.3) | BlogCatalog(avg_d = 33.1) |\n| ------ | ------------------------- | ----------------------- | -------------------- | ------------------------------- | ----------------------------- |\n| Degree | 0.9919                    | 0.9421                  | 0.9264               | 0.6397                          | 0.64                          |\n| GADAM  | **0.9956**                | **0.9718**              | **0.9721**           | **0.7963**                      | **0.7763**                    |\n\nAs evident from the experimental results:\n\n+ Degree is indeed a good metric for detecting structural anomalies in certain datasets but exhibits poor performance in datasets characterized by high average degrees (e.g., ogbn-Products, BlogCatalog). This limitation underscores the metric's challenges in achieving robust generalization across diverse datasets.\n+ GADAM consistently outperforms Degree across all datasets, with the disparity being particularly pronounced in datasets featuring higher average degrees. This robust performance stems from GADAM's design, rooted in the fundamental principles of anomaly detection, enabling stronger generalization across diverse datasets.\n\nWe acknowledge that the effectiveness of using degree as a metric for detecting structural anomalies may be contingent on the limitations of current anomaly generation methods. Designing more realistic and flexible synthetic outlier generation in graphs is also a critical challenge[1]. Our work, while based on a general anomaly injection approach, strives to align with the essence of anomaly detection. We sincerely hope that our underlying motivations resonate with your understanding!\n\n**W7.** How do you capture the nodes which are both contextual and structural anomalies?\n\nThanks for brining this up! Intuitively, our framework is poised to effectively capture nodes that exhibit both contextual and structural anomalies (mixed anomalies for short). The first stage of GADAM captures well the contextual abnormal features exhibited by mixed anomalies. In the second stage, GADAM facilitates the absorption of anomalous signals from the neighboring structural anomalies through adaptive message passing, further enhancing the detection of mixed anomalies.\n\nMoreover, after a thorough examination of the mentioned paper (AAAI-2019), we confirm that \"combined anomalies\" align with our concept of mixed anomalies. To further address your concern, we generated a certain number of mixed anomalies on the five benchmark datasets. Specifically, we randomly selected $q$ structural anomalies from the original datasets in our paper, and employed the contextual anomaly injection method outlined in Appendix A.1 to substitute features for these nodes, thereby creating $q$ mixed anomalies. Our evaluation utilized the representative baselines mentioned in W5, and the performance of mixed anomaly detection under the AUC-ROC metric is as follows:\n\n|          | Cora (q=15) | Citeseer(q=15) | Pubmed(q=60) | ACM(q=60) | BlogCatalog(q=30) |\n| -------- | -------------- | ------------------ | ---------------- | ------------- | --------------------- |\n| DOMINANT | 0.8354         | 0.8498             | 0.7904           | 0.7448        | 0.7723              |\n| CoLA     | 0.8976         | 0.8928             | 0.9618           | 0.7909        | 0.7965              |\n| ComGA    | 0.8828         | 0.9335             | 0.9255           | 0.8433        | 0.8275                |\n| Sub-CR   | 0.9236         | 0.9400             | 0.9810           | 0.7518        | 0.7963                |\n| GADAM    | **0.9970**      | **0.9994**         | **0.9863**       | **0.9884**    | **0.9685**            |\n\nThe results indicate that GADAM exhibits a strong ability to detect mixed anomalies across all datasets, aligning with the motivation behind the model design. We will incorporate these findings into a subsequent revision. Thanks for your insightful review!\n\n**Reference**\n\n[1] BOND: Benchmarking Unsupervised Outlier Node Detection on Static Attributed Graphs(NIPS 2022)\n\n[2] Deep anomaly detection on attributed networks(SDM 2019)\n\n[3] Anomaly detection on attributed networks via contrastive self-supervised learning(TNNLS 2021)\n\n[4] Reconstruction Enhanced Multi-View Contrastive Learning for Anomaly Detection on Attributed Networks(IJCAI 2022)\n\n[5] Generative and contrastive self-supervised learning for graph anomaly detection(TKDE 2021)"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1730/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700206520516,
                "cdate": 1700206520516,
                "tmdate": 1700479517861,
                "mdate": 1700479517861,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uXVUWcM8HY",
                "forum": "CanomFZssu",
                "replyto": "ELS3VdQjOl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1730/Reviewer_WYWU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1730/Reviewer_WYWU"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "Dear Authors,\n\nThank you for your reply.\n\n\"In a dense graph, normal nodes are normally connected to each other, while structural anomalies have abnormal connections to each other\" - Can you please define \"abnormality\" in the context of structural anomalies? In Fig. 1 of the paper, I can see structural anomalies are densely connected among themselves. But how to even manually understand which links are normal and which are abnormal without the help of node attributes? In this discussion, I want to keep node attributes separate since they are captured through contextual anomalies. Also, since these structural anomalies are densely connected among themselves, their edges to other nodes in the graph can be somewhat insignificant. Is there a way we can separate them out from \"genuine\" densely connected nodes in the graph without using node attributes?"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1730/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700455996005,
                "cdate": 1700455996005,
                "tmdate": 1700455996005,
                "mdate": 1700455996005,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "T8Ywk7HXsM",
                "forum": "CanomFZssu",
                "replyto": "JaY2IkHq0k",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1730/Reviewer_WYWU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1730/Reviewer_WYWU"
                ],
                "content": {
                    "title": {
                        "value": "Reviewer Response"
                    },
                    "comment": {
                        "value": "I thank the authors for posting the results on contextual and structural anomalies separately and other experiments they have conducted to answer the doubts I have. I also request them to incorporate mixed (or combined) anomalies in the paper if space permits."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1730/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700456229018,
                "cdate": 1700456229018,
                "tmdate": 1700456229018,
                "mdate": 1700456229018,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]