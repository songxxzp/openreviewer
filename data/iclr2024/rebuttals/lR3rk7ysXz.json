[
    {
        "title": "On Diffusion Modeling for Anomaly Detection"
    },
    {
        "review": {
            "id": "NNMTQ2oPM2",
            "forum": "lR3rk7ysXz",
            "replyto": "lR3rk7ysXz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7999/Reviewer_udy2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7999/Reviewer_udy2"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors investigate diffusion modeling for anomaly detection and introduce an efficient approach called Diffusion Time Estimation (DTE), showing its competitive performance and improved inference times compared to traditional methods and deep learning techniques."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This paper is well-organized and easy to follow.\n2. Investigating the diffusion model to facilitate anomaly detection is an interesting and promising research issue.\n3. The authors conduct comprehensive experiments to demonstrate the effectiveness of the proposed method."
                },
                "weaknesses": {
                    "value": "1. The contribution of this paper appears limited. There are several existing works on anomaly detection utilizing diffusion models, such as those mentioned below:\n[1] Unsupervised Surface Anomaly Detection with Diffusion Probabilistic Model, ICCV23.\n[2] Feature Prediction Diffusion Model for Video Anomaly Detection, ICCV23.\n[3] DiffusionAD: Denoising Diffusion for Anomaly Detection, Arxiv.\n[4] Diffusion models for medical anomaly detection, MCCAI22.\nCan the authors point out the unique contributions of this paper compared with them?\n2. The motivation and rationale for introducing the diffusion model into anomaly detection are somewhat unclear. The authors should emphasize it.\n3. Authors should compare with some latest AD methods proposed in 2023. Besides, it would be more convincing to include diffusion model-based anomaly detection approaches.\n4. The reviewer has thoroughly reviewed the experimental results presented in the appendix. The authors have done a comprehensive experiment by including the results from dozens of datasets in this paper. However, the reviewer observed that the proposed method did not consistently outperform other methods on each individual dataset. It achieved the best performance only on a subset of the datasets."
                },
                "questions": {
                    "value": "See weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7999/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7999/Reviewer_udy2",
                        "ICLR.cc/2024/Conference/Submission7999/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7999/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698730350061,
            "cdate": 1698730350061,
            "tmdate": 1700619817753,
            "mdate": 1700619817753,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "uV8K64JdcV",
                "forum": "lR3rk7ysXz",
                "replyto": "NNMTQ2oPM2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7999/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7999/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their careful and thorough review.\n\n> The contribution of this paper appears limited. There are several existing works on anomaly detection utilizing diffusion models, such as those mentioned below: [1] Unsupervised Surface Anomaly Detection with Diffusion Probabilistic Model, ICCV23. [2] Feature Prediction Diffusion Model for Video Anomaly Detection, ICCV23. [3] DiffusionAD: Denoising Diffusion for Anomaly Detection, Arxiv. [4] Diffusion models for medical anomaly detection, MCCAI22. Can the authors point out the unique contributions of this paper compared with them?\n\nThe main difference between DTE and other applications of diffusion model to anomaly detection, including [1-4] is that DTE does not learn a generative model. We note in section 3 that \u201cwe propose a much simpler approach that does not require modeling the reverse diffusion process but instead models the distribution over diffusion time corresponding to noisy input samples.\u201d As a result, not only this is orders of magnitude faster than learning a generative diffusion model (Figure 1 and 11), but it also performs better (Figure 5). Another distinguishing feature is that we are focused on finding anomalous samples rather than identifying localized anomalies within images.\nWe would also like to clarify that papers [1,2] are published after the May 28, 2023, which is ICLR cut-off deadline for citation, and papers [3,4] are already cited and discussed in Section 5. Nevertheless, we have added a discussion of [1] to section 5 and cited both [1,2].\n\n> The motivation and rationale for introducing the diffusion model into anomaly detection are somewhat unclear. The authors should emphasize it.\n\nHistorically, all generative modelling techniques are used for anomaly detection since they can implicitly identify low-probability samples. Diffusion models are not an exception. As we explain in Section 3, \u201cThe reverse diffusion process implicitly learns the score function of the data distribution and can be used for the likelihood-based identification of anomalies.\u201d We then further investigate this application of diffusion modelling for anomaly detection and find an alternative use of diffusion, explained in the previous answer, leading us to DTE.\n\n> Authors should compare with some latest AD methods proposed in 2023. Besides, it would be more convincing to include diffusion model-based anomaly detection approaches.\n\nADBench was used as our benchmark and was published at NeurIPS 2022. As discussed in Section 5, We include all baselines from that benchmark in addition to ICL (ICLR 2022), DROCC (ICML 2020), GOAD (ICLR 2020). We updated the paper using two new 2023 baselines that were published after the cut-off deadline: SLAD [1] and DIF [2]. DTE outperforms both methods overall on ADBench. We found that methods created specifically for image anomaly detection tend to perform poorly on tabular datasets, and most of the recent papers are tailored for images. As discussed in the paper, the latest anomaly detection methods, such as [3] and [4], use variations on vanilla DDPM, where the difference between the original input and its reconstruction is used. We do compare to this baseline and find DTE superior to both in efficiency and accuracy.\n\n[1] Hongzuo Xu, Yijie Wang, Juhui Wei, Songlei Jian, Yizhou Li, and Ning Liu. Fascinating supervisory\nsignals and where to find them: Deep anomaly detection with scale learning. In Proceedings of\nthe 40th International Conference on Machine Learning, ICML\u201923\n\n[2] Hongzuo Xu, Guansong Pang, Yijie Wang, and Yongjun Wang. Deep isolation forest for anomaly\ndetection. IEEE Transactions on Knowledge and Data Engineering, pp. 1\u201314, 2023a.\n\n[3] Julia Wolleb, Florentin Bieder, Robin Sandk \u0308uhler, and Philippe C Cattin. Diffusion models for\nmedical anomaly detection. In Medical Image Computing and Computer Assisted Intervention\u2013\nMICCAI 2022: 25th International Conference, Proceedings,\nPart VIII, pp. 35\u201345. Springer, 2022.\n\n[4] Julian Wyatt, Adam Leach, Sebastian M. Schmon, and Chris G. Willcocks. Anoddpm: Anomaly\ndetection with denoising diffusion probabilistic models using simplex noise. In 2022 IEEE/CVF\nConference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 649\u2013655,\n2022.\n\n> The reviewer has thoroughly reviewed the experimental results presented in the appendix. The authors have done a comprehensive experiment by including the results from dozens of datasets in this paper. However, the reviewer observed that the proposed method did not consistently outperform other methods on each individual dataset. It achieved the best performance only on a subset of the datasets.\n\nDue to dataset diversity in ADBench, it is indeed challenging for a single method to consistently outperform others across all datasets. Our method shows competitive performance and, in many cases, outperforms other methods on an aggregate score across various datasets while remaining the most efficient in inference time."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7999/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700505761735,
                "cdate": 1700505761735,
                "tmdate": 1700505761735,
                "mdate": 1700505761735,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "q5klB5bEtF",
                "forum": "lR3rk7ysXz",
                "replyto": "uV8K64JdcV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7999/Reviewer_udy2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7999/Reviewer_udy2"
                ],
                "content": {
                    "title": {
                        "value": "Reply to authors."
                    },
                    "comment": {
                        "value": "Thanks for the authors\u2019 reply.  The authors have clarified the contribution and motivation. Although the performance improvement is still the reviewer\u2019s concern, it has shown effectiveness in many datasets and inference time. Besides, after carefully checking for the responses of other reviewers. I think the authors have addressed most of their concerns. Therefore, I want to increase my rating."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7999/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700619722022,
                "cdate": 1700619722022,
                "tmdate": 1700619722022,
                "mdate": 1700619722022,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qEzRJM9h88",
            "forum": "lR3rk7ysXz",
            "replyto": "lR3rk7ysXz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7999/Reviewer_vggP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7999/Reviewer_vggP"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a non-parametric approach based on the inverse Gamma distribution of diffusion time for noisy input, achieving accurate predictions and ranking anomalies similarly to kNN. Additionally, a parametric strategy employs a deep neural network for large datasets, demonstrating competitive performance and significantly improving inference time. Pre-trained embeddings for images are found to enhance diffusion-based methods, highlighting the potential advantage of using latent space diffusion. The evaluation on ADBench, a benchmark for anomaly detection datasets, shows promising results in comparison to prior work."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "+ The proposed approach offers a simpler alternative that avoids modeling the reverse diffusion process. Instead, it focuses on modeling the distribution over diffusion time associated with noisy input samples. The assumption is that anomalies are distant from the data manifold, leading to higher density for larger timesteps in the distribution.\n+ Both non-parametric and parametric strategies are employed for DTE based anomaly detection, and the parametric strategies achieve a tradeoff between accuracy and inference time.\n+ The evaluation is conducted on ADBench, as well as additional image datasets such as Visa, CIFAR-10, and MNIST."
                },
                "weaknesses": {
                    "value": "-The performance in the semi-supervised setting is more competitive compared to the unsupervised setting. This indicates that DTE benefits from labeled data, allowing for a more accurate modeling of the distribution of diffusion time."
                },
                "questions": {
                    "value": "How does varying the ratio of labeled data in the semi-supervised setting affect the performance of DTE? Can this method be extend to more challenging tasks, such as the localization of anomaly in data?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7999/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698769868263,
            "cdate": 1698769868263,
            "tmdate": 1699636985372,
            "mdate": 1699636985372,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kK4rg3miXp",
                "forum": "lR3rk7ysXz",
                "replyto": "qEzRJM9h88",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7999/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7999/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their feedback.\n\n> The performance in the semi-supervised setting is more competitive compared to the unsupervised setting. This indicates that DTE benefits from labeled data, allowing for a more accurate modeling of the distribution of diffusion time.\n\n> How does varying the ratio of labeled data in the semi-supervised setting affect the performance of DTE? Can this method be extend to more challenging tasks, such as the localization of anomaly in data?\n\nSince the question and the point raised under weakness are related, we answer both at the same time: As mentioned in Section 2, the semi-supervised setting used in the paper is also known as one-class classification, where the model only has access to normal samples when training and no labeled data. The ratio is the number of normal samples used for training on the normal samples used for testing. Increasing the ratio simply increases the training data, which should increase the model performance, but can make the test less accurate. This setting is more competitive compared to the unsupervised setting since it does not have any anomalies in its training data, allowing the model to learn the distribution of the normal data more accurately."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7999/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700505768683,
                "cdate": 1700505768683,
                "tmdate": 1700505768683,
                "mdate": 1700505768683,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "QiX0JX6TjT",
            "forum": "lR3rk7ysXz",
            "replyto": "lR3rk7ysXz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7999/Reviewer_ahnY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7999/Reviewer_ahnY"
            ],
            "content": {
                "summary": {
                    "value": "The work explores the use of diffusion models for anomaly detection (AD), and proposes an AD method based on diffusion time estimation (DTE), with three models under the DTE framework introduced. The DTE models, particularly the DNN-based parametric model, can achieve desired detection performance while substantially reducing the inference time. The models are evaluated on 57 datasets and show comparable performance compared to a set of 19 baseline/SOTA methods in both semi-supervised and unsupervised settings."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The work is well motivated and easy-to-follow.\n- The idea of using diffusion time estimation (DTE) for AD is interesting and new. It also provides a way for learning parametric DTE models that allow efficient inference time.\n- The proposed DTE models generally perform substantially better than the popular diffusion model DDPM, and show comparable performance to a large number of competing methods on 57 tabular datasets."
                },
                "weaknesses": {
                    "value": "- The performance of the DTE models seems to be upper bounded by the simple kNN-based AD method. There are a number of kNN-based AD methods, including some deep methods like Refs [1]. It would be helpful for the empirical evidence support if these advanced kNN variants are included in the empirical comparison.\n- The models rely on distance in original feature space, and they would fail to work if the data lies in very high-dimensional space, e.g., datasets with hundreds of thousands of features or millions of features.\n- Since the method is based on generative models, it is important to discuss and compare with other generative model-based AD methods, such as GAN-based methods, to highlight the advantages of the proposed method. \n- Since the models directly work on tabular datasets, it is misleading to claim that the evaluation is performed on diverse tabular, image, and natural language datasets.\n- The work may be improved by having more discussion on recent diffusion model-based AD studies, such as [2-4].\n\n\n\n**Refs**\n- [1] Learning representations of ultrahigh-dimensional data for random distance-based outlier detection. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining (pp. 2041-2050).\n- [2] Unsupervised Surface Anomaly Detection with Diffusion Probabilistic Model. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 6782-6791).\n- [3] Feature Prediction Diffusion Model for Video Anomaly Detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 5527-5537).\n- [4] Multimodal Motion Conditioned Diffusion Model for Skeleton-based Video Anomaly Detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 10318-10329)."
                },
                "questions": {
                    "value": "Please see the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7999/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698929947355,
            "cdate": 1698929947355,
            "tmdate": 1699636985255,
            "mdate": 1699636985255,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GzUl0wNa2T",
                "forum": "lR3rk7ysXz",
                "replyto": "QiX0JX6TjT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7999/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7999/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their detailed feedback and suggestions.\n\n> The performance of the DTE models seems to be upper bounded by the simple kNN-based AD method. There are a number of kNN-based AD methods, including some deep methods like Refs [1]. It would be helpful for the empirical evidence support if these advanced kNN variants are included in the empirical comparison.\n\nThanks for the pointer; we have now cited this paper and briefly discussed it. We would like to point out that while kNN remains one of the top-performing methods, DTE (parametric) is not upper-bounded by kNN: DTE (categorical, inverse Gamma) outperforms kNN on several datasets, as shown in Tables 13-18. Moreover, as we show, while DTE (parametric) is comparable with kNN/DTE(non-parametric), it has a significant efficiency advantage (Figure 1 and 11).\n\nThe referenced paper uses unsupervised embedding followed by kNN in the embedding space. Appendix D presents ablations that compare kNN/DTE (non-parametric) and DTE parametric on embeddings produced through self-supervised learning and pre-trained models. Indeed, many of the datasets in ADBench are embeddings produced by pre-trained models. We generally observe better performance for all methods when using high-quality embeddings.\n\n> The models rely on distance in original feature space, and they would fail to work if the data lies in very high-dimensional space, e.g., datasets with hundreds of thousands of features or millions of features.\n\nIt is informative to consider this point for diffusion models used for generative modeling: there again, while using latent diffusion can improve results for high-dimensional inputs, diffusion modeling remains competitive in the observation space. Similarly, as also discussed in answer to previous question, using embedding improves the performance of our method. We would also like to note that distance to nearest neighbours (in case of DTE non-parametric) can still be reliable in high-dimensions due to manifold hypothesis (i.e., distance to closes point in high-dimension resembles the distance on data-manifold and therefore the distance in any isometric embedding). Overall, we do observe that for high-dimensional data, performance on learned embeddings is better; see Appendix D.\n\n> Since the method is based on generative models, it is important to discuss and compare with other generative model-based AD methods, such as GAN-based methods, to highlight the advantages of the proposed method. \n\nWe agree with the reviewer. In addition to the DDPM and the normalizing flows baselines, we have added a comparison on both semi-supervised and unsupervised AD to a GAN-based method from ADBench and VAE-based method (implementation from PyOD). DTE outperforms all these methods in terms of effectiveness and efficiency. We\u2019ve added a sentence identifying the AD baselines that rely on generative models, per the reviewer\u2019s suggestion.\n\n> Since the models directly work on tabular datasets, it is misleading to claim that the evaluation is performed on diverse tabular, image, and natural language datasets.\n\nWe have reworded this sentence, which now reads \u201ctabular data and embeddings of images and natural language datasets.\u201d\n\n> The work may be improved by having more discussion on recent diffusion model-based AD studies, such as [2-4].\n\nThanks for the pointers; we have cited them and briefly discussed [1,2] in the updated paper. We would also like to note that two of these papers are on video anomaly detection, and all were published after May 28, 2023, which is the cut-off date according to ICLR guidelines. \n\n[1] Learning representations of ultrahigh-dimensional data for random distance-based outlier detection. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining (pp. 2041-2050).\n\n[2] Unsupervised Surface Anomaly Detection with Diffusion Probabilistic Model. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 6782-6791).\n\n[3] Feature Prediction Diffusion Model for Video Anomaly Detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 5527-5537).\n\n[4] Multimodal Motion Conditioned Diffusion Model for Skeleton-based Video Anomaly Detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 10318-10329)."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7999/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700505792632,
                "cdate": 1700505792632,
                "tmdate": 1700505792632,
                "mdate": 1700505792632,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gAow8II9yG",
                "forum": "lR3rk7ysXz",
                "replyto": "GzUl0wNa2T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7999/Reviewer_ahnY"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7999/Reviewer_ahnY"
                ],
                "content": {
                    "title": {
                        "value": "Follow-up comments"
                    },
                    "comment": {
                        "value": "Thanks for the rebuttal. It helps address my concerns on comparison on other generative models, relevance to other DM-based AD studies, and partly the high-dimensional AD issues. My concern on comparison to more advanced kNN-based AD methods is not properly addressed though. \n\nOverall, I like the proposed idea in that it is intuitive and interesting, and generally effective on diverse datasets. Even though the method might not be the state-of-the-art on some cases, it provides some new insights into how DMs could be exploited for AD. I therefore retain my positive rating for this work."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7999/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700704506532,
                "cdate": 1700704506532,
                "tmdate": 1700704506532,
                "mdate": 1700704506532,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zluJMjfJEw",
            "forum": "lR3rk7ysXz",
            "replyto": "lR3rk7ysXz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7999/Reviewer_BHmN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7999/Reviewer_BHmN"
            ],
            "content": {
                "summary": {
                    "value": "The manuscript proposes *diffusion time estimation* (DTE) for the task of unsupervised and semi-supervised point anomaly detection. DTE assumes a data point to be produced by diffusion process and estimates the distribution of the denoising time step required to reconstruct the data point. The mean of mode of the distribution is regarded as the anomaly score of the data point. \n\nIn addition to its effectiveness demonstrated in prior works, DTE avoids the actual denoising process redundant for anomaly detection and directly estimates the extend to which the sample appers to be anomalous. With this keen insight, the manuscript provides detailed derivation of the posterior distribution of variance of time (decided by time step) given an input image assumed to be produced by a diffusion process. Based on the derivation, the manuscript designs one non-parametric model and two parametric models (regressive and categorical respectively). \n\nThe performances of the three models are evaluated on 57 datasets from ADBench demonstrating the capabilities of DTE for the task of anomaly detection and its advantages over DDPM in quaility and efficacy."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "* The paper provides a new perspective for adopting diffusion modeling in the field of anomaly detection\n* The paper provides one parametric and two non-parametric practical models for the task of anomaly detection \n* The methods proposed in the paper (DTE) achieve significate margins in both performance and efficacy compared with DDPM"
                },
                "weaknesses": {
                    "value": "* The advantage of DTE methods hold should be demonstrated quantitatively. As the DTE methods perform worse than kNN in both quality and efficiency, quantitative results are recommended to demonstrate the distinctions in scalability of DTE methods\n* The presentation in Figure 3 needs optimization. To demonstrate the small difference between non-parametric estimate and analytical posterior, the visualization of residual part seems more straightforward."
                },
                "questions": {
                    "value": "See *Weaknesses*."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7999/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7999/Reviewer_BHmN",
                        "ICLR.cc/2024/Conference/Submission7999/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7999/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699376772734,
            "cdate": 1699376772734,
            "tmdate": 1701021520737,
            "mdate": 1701021520737,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Q5tO1APwNz",
                "forum": "lR3rk7ysXz",
                "replyto": "zluJMjfJEw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7999/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7999/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their insightful comments.\n\n> The advantage of DTE methods hold should be demonstrated quantitatively. As the DTE methods perform worse than kNN in both quality and efficiency, quantitative results are recommended to demonstrate the distinctions in scalability of DTE methods\n\nThis is a misunderstanding. As seen in figure 1, DTE (parametric) is significantly more efficient than KNN, which we show is similar to DTE (non-parametric). Exact computation times for training and inference are given in Appendix C.4. In terms of performance, the reviewer is correct that the average performance of DTE (parametric) and KNN is comparable. This is where we believe the efficiency of DTE can facilitate its applications to large datasets. \n\n> The presentation in Figure 3 needs optimization. To demonstrate the small difference between non-parametric estimate and analytical posterior, the visualization of residual part seems more straightforward.\n\nThank you for the suggestion. It makes sense, and we will improve this in the next revision (we are considering several alternatives.)"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7999/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700505811613,
                "cdate": 1700505811613,
                "tmdate": 1700505811613,
                "mdate": 1700505811613,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]