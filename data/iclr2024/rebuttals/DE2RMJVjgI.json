[
    {
        "title": "Fine-grained Separation of Action-Background for Point-Level Temporal Action Localization"
    },
    {
        "review": {
            "id": "gkJBkZy12v",
            "forum": "DE2RMJVjgI",
            "replyto": "DE2RMJVjgI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1718/Reviewer_L6ip"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1718/Reviewer_L6ip"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a framework to mine pseudo point-level labels for improving the performance of weakly supervised temporal action localization. There are four components, including label extension, pseudo label mining, score contrast module and feature separation module. Extensive experiments on four benchmarks verify the state-of-the-art performance of the proposed framework."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The proposed method is well-motivated with the error analysis and is also technically sound. Extensive experiments on four benchmarks verify the state-of-the-art performance of the proposed framework."
                },
                "weaknesses": {
                    "value": "1. The major drawback of this paper is its incremental novelty. The proposed components are all modified versions of the off-the-shelf methods, for example, label extension originates from dynamic sampling, pseudo label mining modifies the one of LACP [1], score contrast module and feature separation module also borrow the idea of OIC loss [2] and Co-Activity Similarity [3].\n2. Some important references are missing, for example, Zhou et al. [4] also explore generating high-quality pseudo labels for weakly supervised temporal action localization.\n3. More ablation studies are needed, for example, the performance with a single proposed component.\n4. Qualitative results are needed to show the performance.\n\n[1] Learning action completeness from points for weakly-supervised temporal action localization, ICCV 2021.\n\n[2] Autoloc: Weakly supervised temporal action localization in untrimmed videos, ECCV 2018.\n\n[3] W-talc: Weakly-supervised temporal activity localization and classification, ECCV 2018.\n\n[4] Improving Weakly Supervised Temporal Action Localization by Bridging Train-Test Gap in Pseudo Labels, CVPR 2023."
                },
                "questions": {
                    "value": "1. There are too many hyper-parameters in the proposed method, which may increase the difficulty of reproduction. How much would these hyper-parameters affect the model? Please show more sensitivity analysis of hyper-parameters.\n2.  In Formula 1, why $\u03c4_2$ is only assigned to the nearest frame of the boundary but not the outer segment like OIC loss?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1718/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698673247544,
            "cdate": 1698673247544,
            "tmdate": 1699636100705,
            "mdate": 1699636100705,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "z527g3naWL",
                "forum": "DE2RMJVjgI",
                "replyto": "gkJBkZy12v",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1718/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1718/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your question. I will answer them one by one. \n\n**Q1: The major drawback of this paper is its incremental novelty.**\n\n**A1**: I will emphasize the technical novelty of this paper. The overall two-step framework does indeed refer to LACP to some extent, but there are significant differences. Firstly, we take the lead in designing label extension module and feature up-sampling method to enhance action features in point-level supervision, using location information provided by point labels. Secondly, our proposed feature separation module is also novel and it is worth noting that this is different from the Co-Activity Similiarity of W-TALC. The role of Co-Activity Similiarity is to determine the correlation between similar categories of videos, in contrast, our feature separation module extracts the corresponding action feature matrix and background feature matrix, and calculates the feature separation loss by using the cosine similarity, to amplify the differences between action-backgrounds and enhance the similarity between actions or backgrounds. This calculation method for feature separation has not been proposed before, and our experimental results show that it is successful. Besides, we optimized the pseudo label mining algorithm in LACP, enhancing performance of mining pseudo action labels. Finally, we make a correction to the overlapping issue between action instances during loss calculation for practical scenarios, although this is only a minor change, it is a problem discovered through extensive experimental verification, and as shown in Table 7, the performance improvement it brings is also significant. We believe that this correction has good implications for many methods in this field.\n\n**Q2: Some important references are missing and more ablation studies are needed.**\n\n**A2**: We have added some of the latest articles you mentioned to the related work. And we demonstrated the effectiveness of our proposed modules or methods through ablation experiments in Table 2. Firstly, in Sec. A of appendix, we provide a detailed description of the algorithm for the label extension module, which relies on the rough action positions provided by point labels for feature upsampling and label extension. Intuitively, this will definitely lead to performance improvement. In future paper versions, we can align and visualize labels with action features to prove the accuracy of label extension in the temporal dimension. Besides, in Figure 3, we visualize the range selection of the pre-and post-optimizatized outer-inner contrast score, and it is obvious that our optimized calculation method is more accurate and can magnify the difference between the action-background segments for practical scenarios. Meanwhile, Figure 4 visualizes the comparison between our FS-PTAL and LACP in pseudo label mining methods, it is evident that the pseudo labels mined by our method are more closely aligned with GT and have a wider coverage area, indicating that our optimized method for label mining is more effective. Finally, the effectiveness of the feature separation module is also intuitive, by mapping to the feature embedding space, all action feature matrices and background feature matrices are extracted to calculate the cosine similarity and the feature separation loss, achieving action-background separation. Table 2 shows that the impact of the feature separation module on the experimental results is significant.\n\n**Q3: There are too many hyper-parameters in the proposed method, which may increase the difficulty of reproduction.**\n\n**A3**: In Sec. C of the appendix, we provide detailed training hyper-parameter settings. Numerous comparative experiments can demonstrate that our hyper-parameter settings are reasonable. In Table 3, we show the influence of different settings of several hyper-parameters on the results. If necessary, we can add more hyper-parameter comparison results in subsequent versions. Specifically, the weighted parameter $\u03bb_1$, $\u03bb_2$, $\u03bb_3$ and $\u03bb_4$  are all 1, these are determined based on massive previous works and experience.\n\n**Q4: In Formula (1), why $\u03c4_2$ is only assigned to the nearest frame of the boundary but not the outer segment like OIC loss?**\n\n**A4**: Formula (1) in the label extension module, which belongs to the data preprocessing stage. We determine the rough position of the action based on the point-level labels and assign fixed sampling weights $\u03c4_1$ and $\u03c4_2$ within and around the actions. The outer segment like OIC loss need to undergo convolution operations and class activation functions, and filter out action segments. Obviously, this operation undoubtedly wastes a lot of time and is very complex. Our label extension module was originally in the preprocessing stage, so directly using the rough information of point-level labels is quite intuitive."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1718/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700652733187,
                "cdate": 1700652733187,
                "tmdate": 1700652733187,
                "mdate": 1700652733187,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dmeRWT4WDi",
                "forum": "DE2RMJVjgI",
                "replyto": "z527g3naWL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1718/Reviewer_L6ip"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1718/Reviewer_L6ip"
                ],
                "content": {
                    "title": {
                        "value": "Post-rebuttal comments"
                    },
                    "comment": {
                        "value": "I appreciate the authors' response.\n\nThe authors emphasize their novelty in the rebuttal, which is however not convincing to me. The authors acknowledge that their framework draws inspiration from LACP, essentially representing an enhanced version of it. Moreover, while each component they propose is linked to existing works and has been modified by them, the reasoning behind their design choices remains somewhat unclear.\n\nFor Table 2, the authors have not yet included an ablation study for each individual component. In addition, for Q4, the response cannot convince me without a quantitative comparison.\n\nDue to these factors, I have decided to maintain my rating as it is."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1718/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700711250814,
                "cdate": 1700711250814,
                "tmdate": 1700711250814,
                "mdate": 1700711250814,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "bUmAQLTfK0",
            "forum": "DE2RMJVjgI",
            "replyto": "DE2RMJVjgI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1718/Reviewer_KUWp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1718/Reviewer_KUWp"
            ],
            "content": {
                "summary": {
                    "value": "The paper tackles the problem of weakly supervised temporal action detection with point-level supervision. The proposed method follows a similar pipeline to LACP and introduces design on label extension, pseudo label mining, feature separation and score contrasting to improve detection performance. Extensive experiments on popular benchmarks show improvements based on previous state-of-the-art point-level weakly-supervised methods."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The proposed method achieves non-trivial improvement on Thumos14 compared to previous weakly supervised method. The ablation study supports the effectiveness of each component in the framework."
                },
                "weaknesses": {
                    "value": "- The proposed method looks incremental on LACP (Lee & Byun (2021)). The overall pipeline, pseudo label mining, feature separation and score contrast module are very similar to LACP.  The technical contributions look like modifications to each LACP component from the engineering side. There should be more in-depth analysis to explain the motivation of each proposed design. \n- Experiments: \n  - Missing important benchmark results (ActivityNet) in the main paper.\n  - Missing important methods in comparison table (tab.4). Is there a reason to not compare with other point-level supervision methods (SF-Net, BackTAL and Ju et.al. ) method on ActivityNet?\n  - The performance on Activitynet against video-level supervision methods does not look competitve. If this is due to the sparsity of action in activitynet videos, then the authors should provide  comparison with video-level approaches on other benchmarks (GTEA and BEOID), as GTEA and BEOID has denser action distributions and should be better according to the authors' claim. \n- Generally, the paper suffers from bad writing, including grammatical errors (subject-verb agreement, verb tense, etc), confusing wording, poor organization (introduction too long, and experiments too short), and inconsistent citation style (e.g. for pointTAD). The overall paper feels repetitive and lacks flow. The authors need to revise the whole paper thoroughly and properly organize the content in the main paper (eg. move important comparison results from supp. to main paper).\n- There's a factual error in Introduction, Related Work and Comparison table, that pointTAD is in fact not a weakly supervised approach to TAD, but a fully-supervised method."
                },
                "questions": {
                    "value": "- Figure 3 is confusing and lacking important captions. The meaning of R(S_c) and how to compute the inner and outer score is not clear in the figure. Although section 3.4 seems to explain figure 3, we don't see consistent notations in the text and figure, for example the notations in text (s_n^c , e_n^c  and R(SL_c)) do not have corresponding illustration in the figure."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1718/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1718/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1718/Reviewer_KUWp"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1718/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698740925367,
            "cdate": 1698740925367,
            "tmdate": 1699636100624,
            "mdate": 1699636100624,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1Dd4ebntok",
                "forum": "DE2RMJVjgI",
                "replyto": "bUmAQLTfK0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1718/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1718/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your question. I will answer them one by one.\n\n**Q1: The proposed method looks incremental on LACP.**\n\n**A1**: I will emphasize the technical novelty of this paper. The overall two-step framework does indeed refer to LACP to some extent, but there are significant differences. Firstly, we take the lead in designing label extension module and feature up-sampling method to enhance action features in point-level supervision, using location information provided by point labels. Secondly, our proposed feature separation module is also novel, we extract and merge the positions marked by point labels to generate the action point feature matrix and the background point feature matrix. We use cosine similarity to amplify the differences between action-backgrounds and enhance the similarity between actions or backgrounds. This calculation method for feature separation has not been proposed before, and our experimental results show that it is successful. Besides, we optimized the pseudo label mining algorithm in LACP, enhancing performance of mining pseudo action labels. Finally, we make a correction to the overlapping issue between action instances during loss calculation for practical scenarios, although this is only a minor change, it is a problem discovered through extensive experimental verification, and as shown in Table 7, the performance improvement it brings is also significant. We believe that this correction has good implications for many methods in this field.\n\n**Q2: Regarding the experiments.**\n\n**A2**: We have experimental results on the ActivityNet1.3 in Table 4, but we did not compare with other point-level supervision methods (SF-Net, BackTAL and Ju et.al. ) because hese methods either have poor performance on ActiviNet1.3 (for example, the mean Map@[0.5,0.95] of SF-Net is only 21.2) or lack parameters trained on this dataset. All in all, we only select the most representative point supervised method LACP for comparison. Besides, we would like to provide experimental results of video-level methods on GTEA and BEOID, but all video-level methods do not provide training parameters on these two benchmarks. We attempted to debug the source code of these video-level methods on these two benchmarks, but did not achieve success. Therefore, we only present the results of point-level methods on these two benchmarks.\n\n**Q3: The paper suffers from bad writing, including grammatical errors (subject-verb agreement, verb tense, etc), confusing wording, poor organization (introduction too long, and experiments too short), and inconsistent citation style (e.g. for pointTAD).**\n\n**A3**: We provide explanations for writing and PointTAD. If this paper can pass, in future versions of the paper, we will reduce the description of introduction and related work, and move the presentation of Figure 1 to the appendix. We will add more experimental tables in the main text section. Finally, regarding the description of PointTAD, we do have a minor error, and we have removed its description from Table 1 and related work.\n\n**Q4: Figure 3 is confusing and lacking important captions.**\n**A4**: We have modified the incorrect $R (S_c)$ to $R (SL_c)$, so there will be corresponding illustration in the Figure 3. Regarding the specific calculation process of $R (SL_c)$, the steps are as follows: Firstly, we calculate the segment length $l_{seg}$ from $s_n^c$ and $e_n^c$. Next, we select the external calculation range according to formula (8). Finally, the calculation of $R (SL_c)$ is based on the following formula. For the convenience, we define the length on the left and right side of the external range as $l_{left}$, $l_{right}$, respectively.\n\n$R (SL_c)=\\frac{1}{N_{s l}^{c}}\\sum_{n=1}^{N_{s l}^{c}}(\\frac{1}{l_{\\text {seg}}}\\sum_{t=s_{n}^{c}}^{e_{n}^{c}} \\widehat{q_{t}}[c]-\\frac{1}{l_{\\text{left}}+l_{\\text {right}}}(\\sum_{t=\\min(s_{n}^{c}-\\delta l_{seg}, e_{n-1}^{c})}^{s_{n}^{c}-1} \\widehat{q}_{t}[c]$\n\n$+\\sum_{t=e_{n}^{c}+1}^{\\min(e_{n}^{c}+\\delta l_{seg}, s_{n+1}^{c})} \\widehat{q}_{t}[c]))$"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1718/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700652434328,
                "cdate": 1700652434328,
                "tmdate": 1700652434328,
                "mdate": 1700652434328,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Dv5rxSxoGx",
                "forum": "DE2RMJVjgI",
                "replyto": "1Dd4ebntok",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1718/Reviewer_KUWp"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1718/Reviewer_KUWp"
                ],
                "content": {
                    "title": {
                        "value": "Post-rebuttal Comment"
                    },
                    "comment": {
                        "value": "I appreciate the authors efforts in providing the response, but my concerns with the novelty remain unrelieved. Each component in the framework has its counterpart in previous works and the improvement merely looks like technical modifications. The insights in proposing these modules remain similar to previous works. Furthermore, I agree with reviewer PXaQ and L6ip on the need for an apple-to-apple ablation study. Based on the above reasons, the paper in its current form does not meet the standards of ICLR, therefore I keep my original rating."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1718/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700724346605,
                "cdate": 1700724346605,
                "tmdate": 1700724346605,
                "mdate": 1700724346605,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wEIuSuwBwA",
            "forum": "DE2RMJVjgI",
            "replyto": "DE2RMJVjgI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1718/Reviewer_8Huu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1718/Reviewer_8Huu"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the author proposes a new method for point-level temporal action localization. The proposed method utilizes multiple modules including label extension module, pseudo label mining and score contrast module to enhance the performance of point-level supervised temporal action localization. The proposed method achieves performance gain over the standard benchmark temporal action localization datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "In general, I think this paper has clear definitions, good illustrations, and exhaustive experiments to verify the effectiveness of the proposed method. The proposed method has superior performance on major benchmark datasets."
                },
                "weaknesses": {
                    "value": "However, I still have some little concerns about this paper: \n\n1. The writing should be polished. There are some grammatical errors like \"genearting\" on page 5. Also, some abbreviations should be re-introduced like OIC on page 6, though the author introduces it on page 2. Also, all formulas should end with a comma or period, and space after the bracket, etc.\n\n2. I think the experiment part could be revised to provide a clear comparison. First, in Table 1, the author could provide provides more recent fully supervised temporal action localization methods like ActionFormer, TriDet, etc. They can easily achieve around 66+ mean mAP@[0.3,0.7] on THUMOS14. Don't claim those state-of-the-art methods will make the result table not convincing. Also, Table 1 reports mean mAP@[0.1,0.5] and mean mAP@[0.3,0.7]. While in Table 2, the author only reports the mean mAP@[0.1,0.7]. It is confusing here. Also, Table 2 should become a step-to-step ablation, the current form is somehow weird."
                },
                "questions": {
                    "value": "Please mainly see the weaknesses section for details."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1718/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698747524132,
            "cdate": 1698747524132,
            "tmdate": 1699636100555,
            "mdate": 1699636100555,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hjoWqSHDka",
                "forum": "DE2RMJVjgI",
                "replyto": "wEIuSuwBwA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1718/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1718/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your question. I will answer them one by one. \n\n**Q1: The writing should be polished.**\n\n**A1**: We have corrected the two errors you raised. If this paper can pass, we will polish the writing and pay attention to the formatting of all formulas in subsequent versions of the paper.\n\n**Q2: The experiment part could be revised to provide a clear comparison.**\n\n**A2**: We think your proposed modification of the experimental section is clear. There are no recent temporal action localization methods such as ActionFormer and TriDet in Table 1, because these methods are based on the transformer structure, while the methods which we compare are mainly based on convolutional architecture. These methods have smaller models, fewer parameters, and lower costs. In Table 2, we believe that the mean mAP@[0.1,0.7] is sufficient to identify the performance gap. The reason why Table 1 is divided into the mean mAP@[0.1,0.5] and the mean mAP@[0.3,0.7] is because some methods only have the former and some methods only have the latter, which is not enough to calculate the mean mAP@[0.1,0.7]. Therefore, we use two standards to display performance. Meanwhile, for the ablation experiment in Table 2, we refer to previous work. We delete the proposed innovative modules or methods separately to observe the effect of each module or method on performance."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1718/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700650371825,
                "cdate": 1700650371825,
                "tmdate": 1700650371825,
                "mdate": 1700650371825,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "AhacqDJQqj",
                "forum": "DE2RMJVjgI",
                "replyto": "hjoWqSHDka",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1718/Reviewer_8Huu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1718/Reviewer_8Huu"
                ],
                "content": {
                    "title": {
                        "value": "Postrebuttal comments"
                    },
                    "comment": {
                        "value": "After reading the author's rebuttal and reviews from other reviewers, I would like to keep my original rating. The author's rebuttal doesn't convince me about the experiment part, also I raise some new concerns about the novelty part/hyperparameter part."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1718/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700714978645,
                "cdate": 1700714978645,
                "tmdate": 1700714978645,
                "mdate": 1700714978645,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Ik3RhfGmeZ",
            "forum": "DE2RMJVjgI",
            "replyto": "DE2RMJVjgI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1718/Reviewer_PXaQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1718/Reviewer_PXaQ"
            ],
            "content": {
                "summary": {
                    "value": "This paper address the task of temporal action localization under point-level supervision. The authors focus on the observation that existing approaches have difficulty in discriminating the action and background, leading to significant localization and background errors. To tackle this, the authors introduce FS-PTAL, a new framework that aggregates pseudo labels based on sparse point-level annotations and enhances the contrast between the action and background. Experiments on benchmark datasets confirm the superiority of the proposed model over existing state-of-the-arts."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "+ The manuscript is overall well-organized and easy to follow.\n+ The motivation behind the work is clear and reasonable; enlarging the discrepancy between action and background frames is the key challenge in the weakly-supervised setting.\n+ The proposed model surpasses the prior arts by non-trivial margins, which manifests its effectiveness well."
                },
                "weaknesses": {
                    "value": "- The technical novelty of the paper is limited. The overall two-step framework strictly follows that of LACP (Lee & Byun, 2021), with improvements made to the original loss (i.e., Feature Separation loss), a correction to the overlapping issue between action instances during loss calculation (i.e., Score Contrast loss), and addition of new elements (i.e., Label Extension Module). While these contribute to the paper, from my view, this work seems an extension of the previous work (Lee & Byun, 2021), and the newly introduced contributions are slightly under the standard bar of top-tier conferences.\n- This paper lacks comprehensive analyses to substantiate the effectiveness of the proposed components. As noted in the above weakness, the model improves the previous approach with modifications and additions. However, their actual effects and how they help are not analyzed in the experiments. Also, apple-to-apple comparisons with the original method would be desirable.\n- The paper is not self-contained in its current form, distracting the readers by making them alternate between the main paper and the appendix. Also, only the two kinds of experimental results are provided in the manuscript, while the remaining ones are in the appendix. It is strongly encouraged for the authors to trim the inappropriately long content in Introduction and Related work (e.g., Figure 1 occupies too much space), and add more experimental results in the main text.\n\n(Minor)\n\nThe reference format to PointTAD is wrong; it should be formatted as (Tan et al., 2022). Additionally, PointTAD is not a weakly-supervised approach, so the comparison with it in Table 1 is inappropriate."
                },
                "questions": {
                    "value": "Please refer to Weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1718/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1718/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1718/Reviewer_PXaQ"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1718/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698824974524,
            "cdate": 1698824974524,
            "tmdate": 1699636100492,
            "mdate": 1699636100492,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2NGUoxTa8p",
                "forum": "DE2RMJVjgI",
                "replyto": "Ik3RhfGmeZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1718/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1718/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your question. I will answer them one by one. \n\n**Q1: The technical novelty of the paper is limited.**\n\n**A1**: I will emphasize the technical novelty of this paper. The overall two-step framework does indeed refer to LACP to some extent, but there are significant differences. Firstly, we take the lead in designing label extension module and feature up-sampling method to enhance action features in point-level supervision, using location information provided by point labels. Secondly, our proposed feature separation module is also novel, we extract and merge the positions marked by point labels to generate the action point feature matrix and the background point feature matrix. We use cosine similarity to amplify the differences between action-backgrounds and enhance the similarity between actions or backgrounds. This calculation method for feature separation has not been proposed before, and our experimental results show that it is successful. Besides, we optimized the pseudo label mining algorithm in LACP, enhancing performance of mining pseudo action labels. Finally, we make a correction to the overlapping issue between action instances during loss calculation for practical scenarios, although this is only a minor change, it is a problem discovered through extensive experimental verification, and as shown in Table 7, the performance improvement it brings is also significant. We believe that this correction has good implications for many methods in this field.\n\n**Q2: This paper lacks comprehensive analyses to substantiate the effectiveness of the proposed components.**\n\n**A2**: We demonstrated the effectiveness of our proposed modules or methods through ablation experiments in Table 2. Firstly, in Sec. A of appendix, we provide a detailed description of the algorithm for the label extension module, which relies on the rough action positions provided by point labels for feature upsampling and label extension. Intuitively, this will definitely lead to performance improvement. In future paper versions, we can align and visualize labels with action features to prove the accuracy of label extension in the temporal dimension. Besides, in Figure 3, we visualize the range selection of the pre-and post-optimizatized outer-inner contrast score, and it is obvious that our optimized calculation method is more accurate and can magnify the difference between the action-background segments for practical scenarios. Meanwhile, Figure 4 visualizes the comparison between our FS-PTAL and LACP in pseudo label mining methods, it is evident that the pseudo labels mined by our method are more closely aligned with GT and have a wider coverage area, indicating that our optimized method for label mining is more effective. Finally, the effectiveness of the feature separation module is also intuitive, by mapping to the feature embedding space, all action feature matrices and background feature matrices are extracted to calculate the cosine similarity and the feature separation loss, achieving action-background separation. Table 2 shows that the impact of the feature separation module on the experimental results is significant.\n\n**Q3: The paper is not self-contained in its current form, distracting the readers by making them alternate between the main paper and the appendix.**\n\n**A3**: If this paper can pass, in future versions of the paper, we will reduce the description of introduction and related work, and move the presentation of Figure 1 to the appendix. We will add more experimental tables in the main text section.\n\n**Q4: The reference format to PointTAD is wrong.**\n\n**A4**: Regarding the description of PointTAD, we do have a minor error, and we have removed its description from Table 1 and related work."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1718/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700650160508,
                "cdate": 1700650160508,
                "tmdate": 1700650160508,
                "mdate": 1700650160508,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XR4GgJyRtu",
                "forum": "DE2RMJVjgI",
                "replyto": "2NGUoxTa8p",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1718/Reviewer_PXaQ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1718/Reviewer_PXaQ"
                ],
                "content": {
                    "title": {
                        "value": "Post-rebuttal Comment"
                    },
                    "comment": {
                        "value": "I appreciate the careful response of the authors.\n\nAlthough the authors re-claim the technical novelty of the paper, it is not convincing enough to me.\n\nI believe some of the contributions are rather implementation tricks and the overall significance does not reach the standard bar of ICLR 2024.\n\nIn addition, as most of the proposed modules are individually designed to improve their own counterparts, I believe there should be experiments on their superiority over the counterparts.\n\nHowever, I noticed that Table 2 only provides the results by excluding one of the modules, and the authors fail to present apple-to-apple comparisons to showcase the relative advantages of the components.\n\nFor these reasons, I will keep my rating unchanged."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1718/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700706803552,
                "cdate": 1700706803552,
                "tmdate": 1700706803552,
                "mdate": 1700706803552,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]