[
    {
        "title": "Unleashing the power of Neural Collapse for Transferability Estimation"
    },
    {
        "review": {
            "id": "YzSV2vnZBk",
            "forum": "UDbEpJojik",
            "replyto": "UDbEpJojik",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission919/Reviewer_TZ7d"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission919/Reviewer_TZ7d"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the notion of transferability of pretrained models, ie how well one can predict the performance of a model on a downstram task after finetuning on the target dataset. The paper proposes using the degree of Neural Collapse  (Papyan et al., 2020) as a way of measuring the transferability of models. The proposed metric, FaCe, is a function of inter-/intra class covariance and distributions."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "* The paper deals with a hard and open problem: transferabiltiy estimation\n\n* It proposes a solution based on properties of NC of the pretrianed model, and shows some gains vs other transferability metrics.\n\n* the paper seems reproducible, as the authors further shared code as supplementary materials"
                },
                "weaknesses": {
                    "value": "1. There is a very relevant related work that is discussing NC for transfer learning, that is currently not cited in this submission:\nGalanti, Tomer, Andr\u00e1s Gy\u00f6rgy, and Marcus Hutter. \"On the role of neural collapse in transfer learning.\" ICLR 2022.\nThe authors should discuss this paper and the contributions of the submission related to that. \n\n2. The authors claim that a key component of their method is the class fairness term. It is unclear how FaCe compares to a variant without that term (and everything else the same), ie if S_m = C_m and not C_m+F_m. There is no ablation to understand how this part affects the final metric. \n\n3. The experimental validation is weak. There are very few and small -scale datasets in Tab1, while even fewer in Tabs 2 and 3. A more extensive evaluation is needed to showcase any improvements of FaCe vs the other metrics. Currently this is not clear from Tab1 where there seems to not be a clear winner at all.\n\n\nA note:\nA very related concurrent work from ICCV 2023 should be cited and possibly also discussed (as concurrent work, of course, not limiting this papers novelty):\nWang, Zijian, et al. \"How Far Pre-trained Models Are from Neural Collapse on the Target Dataset Informs their Transferability.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023."
                },
                "questions": {
                    "value": "- Can you provide ablations for performance when only one of the two terms is used, ie C and F for FaCe? ie add two more columns in tables 1/2/3 with that. I understand that GBC is close, but it would be great to see the performance of your method, in your experimental setup, for each of the two terms separately and then together. I think this would help clarify the contribution of this paper. \n\n- What are only a subset of papers presented in Tab2 and 3? Ca you provide results for all, eg in an appendix if the issue is space?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission919/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission919/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission919/Reviewer_TZ7d"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission919/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698831764289,
            "cdate": 1698831764289,
            "tmdate": 1700673960230,
            "mdate": 1700673960230,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CspkAOULmn",
                "forum": "UDbEpJojik",
                "replyto": "YzSV2vnZBk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for providing valuable comments and address your concerns in the following responses.\n\n> **[Q1]**: \"On the role of neural collapse in transfer learning. [1]\" ICLR 2022. The authors should discuss this paper and the contributions of the submission related to that.\n\n\n**[A1]** Thank you for your kind reminder. We added a discussion in the related work section.\n\n\n[1] investigates the impact of pre-trained networks undergoing neural collapse on source training data on various types of target datasets. The authors find that neural collapse occurring on the source data can generalize to new samples and even unseen categories. We list the main difference from [1] below:\n\n- The task and setting are different.  [1] study the ability of models, which undergo neural collapse on source tasks, to learn representations for classification that are transferable to new, unseen classes. However, our task is to propose a metric to estimate the transferability of a given pre-trained model.  Whether this model undergoes neural collapse on the source data is unknown.\n- [1] primarily investigates the performance of models experiencing neural collapse in experiments to learn about phenomena and draw conclusions. In contrast, our work is inspired by the characteristics of neural collapse to propose a method for transferability estimation.\n\n> **[Q2]**: The authors claim that a key component of their method is the class fairness term. It is unclear how FaCe compares to a variant without that term. There is no ablation to understand how this part affects the final metric.\n\n**[A2]** We agree that the ablation study is crucial. As shown in Section 4.6, we provide the ablation study of two terms of FaCe. The results validate that both terms are effective, and they complement each other to achieve the best average performance.\n\n\n> **[Q3]**: The experimental validation is weak. A more extensive evaluation is needed to showcase any improvements of FaCe vs the other metrics. \n\n**[A3]** We follow existing work and select a set of common-used representative target datasets. These datasets cover various data types, such as animals, traffic signs, textures, and more, providing a diverse set of evaluation scenarios.\n\n**In Appendix A.3, we add experiments on the large-scale dataset food101 (~101,000 images) in Table 1, and include more target datasets in Table 2, 3.**\n\nAs shown in Appendix A.3, Table 6,7,8, in the presence of a large-scale dataset, we still achieve competitive average performance (Table 6). Moreover, on more target datasets, we also obtain the best average performance on the other two model zoos (Table 7, 8).\n\n\n> **[Q4]**: A very related concurrent work from ICCV 2023 should be cited and possibly also discussed (as concurrent work, of course, not limiting this paper's novelty): \n\n**[A4]** Thank you for your kind reminder. We have also noticed the paper [2], which was released after our submission and shares similar ideas with ours.  We have added a discussion about it in the related work section.\n\nNCTI (their method) is a concurrent work of our method, which is also inspired by neural collapse. NCTI consists of three terms, which correspond to three characteristics of neural collapse, respectively.  Different from NCTI, which assesses the geometry structure based on nuclear norm, FaCe is based on the class distribution overlapping matrix entropy. We will make effort to reproduce this work and include a comparative analysis with it in the future.\n- [2] How Far Pre-trained Models Are from Neural Collapse on the Target Dataset Informs their Transferability. ICCV 2023.\n\n\n>   **[Q5]**: What is only a subset of papers presented in Tab 2 and 3? Can you provide results for all, eg in an appendix if the issue is space?\n\n**[A5]** In Table 1-3, the comparison methods are the same (LEEP, NCE, LogME, H-score, GBC).\n\nWe suspect that when you mentioned \"a subset of papers,\" you might refer to the target datasets. We also provide more results in Appendix A.3. **On these new target datasets, FaCe still achieves state-of-the-art performance.**"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700397595602,
                "cdate": 1700397595602,
                "tmdate": 1700397595602,
                "mdate": 1700397595602,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Cvoz8hk8Fs",
                "forum": "UDbEpJojik",
                "replyto": "YzSV2vnZBk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Invitation to further discussion"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nWe genuinely appreciate the time and effort you've invested in reviewing our paper. We have carefully provided relevant responses and results to your concerns. We are eager to further discuss with you and gain your insights **before the end of the Author/Reviewer phase**. Please let us know if any aspect of our work remains unclear or if you have additional feedback.\n\nThank you."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700573432606,
                "cdate": 1700573432606,
                "tmdate": 1700573432606,
                "mdate": 1700573432606,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "L3ckIJXjK7",
                "forum": "UDbEpJojik",
                "replyto": "Cvoz8hk8Fs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Reviewer_TZ7d"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Reviewer_TZ7d"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the responses"
                    },
                    "comment": {
                        "value": "I want to thank the reviewers for their responses.\n\n> addition of missing reference [1]\n\nThank you for discussing this. It is true that the task is different but I see a lot of shared motivation. \n\n> Ablation on F and C contributions\n\nThank you for making this ablation now clear. However, the results in Tab 4 suggest that the class fairness term only helps in 1 out of three zoo cases ( homogeneous model zoo with multiple sources ) and not in the other two. Are there any intuitions why? this is the main contribution and it should be thoroughly discussed. \n\n>  select a set of common-used representative target datasets.\n\nI still belive the evaluation to be not as strong as needed. The set selected is a _subset_ of the datasets commonly used, ie 7 vs 9 used in LogME and 8 in GBC. Conclusions would be much stronger if results on all datasets used in related works were there.\n\nI have one more question/clarification on the hyperparameters used. The authors say:\n>  We used the validation set to find the best hyperparameters\n\nWhich val set of which dataset is used? Are the same hyperparameters used in all experiments? Is the exact same protocol also used for setting the hyperparameters of the compared methods and baselines?\n\nThank you"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700647541116,
                "cdate": 1700647541116,
                "tmdate": 1700647541116,
                "mdate": 1700647541116,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QvXyxqECjt",
                "forum": "UDbEpJojik",
                "replyto": "mR8UxplJAB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Reviewer_TZ7d"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Reviewer_TZ7d"
                ],
                "content": {
                    "title": {
                        "value": "Thanks - but one more thing"
                    },
                    "comment": {
                        "value": "Thank you for your quick reply. I agree there exist differences in your work, it is just that this missing reference slightly decreases it. \n\nYou are right, I apologize for confusing F and C. The gains seem clear now in T4.\n\nI do however have one remaining question  from your response: are you assuming the existence of a validation set from each _downstream task_ and tune your methods parameters with that, per dataset? Do you consider this set labeled or unlabeled? what would be your method\u2019s performance when you simply use one set of parameters for all downstream datasets? Apologies for any misunderstanding."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700667928806,
                "cdate": 1700667928806,
                "tmdate": 1700667928806,
                "mdate": 1700667928806,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Thvf34Wl1R",
                "forum": "UDbEpJojik",
                "replyto": "YzSV2vnZBk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Reviewer_TZ7d"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Reviewer_TZ7d"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "Alright, thanks for clarifying an important part  of the tuning for the task that I confused. My apologies again, it is busy times. \n\nBased on the author responses I will increase my score to borderline accept."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700673902413,
                "cdate": 1700673902413,
                "tmdate": 1700674028115,
                "mdate": 1700674028115,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "m8RE0nbTxN",
            "forum": "UDbEpJojik",
            "replyto": "UDbEpJojik",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission919/Reviewer_Rkcn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission919/Reviewer_Rkcn"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a metric designed to evaluate the transferability of a model trained under the so-called Terminal Phase of Training (TPT), at which neural collapse manifests. The key idea is to use a Gaussian distribution surrounding the collapsed feature. Subsequently, the Bhattacharyya score (available in this case in closed form) is computed to assess the difference between the pretrained model and its fine-tuned version. The authors support their approach with empirical evidence, drawing from multiple datasets and models."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The practical result of selecting the optimal model from a set of pretrained models, which best fine-tunes with the available data prior to training, appears to be a significant strength, given its potential appeal to a broad audience and its broader implications. Additionally, the closed-form formulation further shows its strength, with implications both in practical and theoretical contexts."
                },
                "weaknesses": {
                    "value": "Considering the rapid dissemination of models online by third-party sources, the approach of selecting the optimal model for fine-tuning might have constrained applicability.\n\nThe assertion of a strong correlation is not clearly evident from the paper. For example It would be beneficial if from the experimental results some takeaway message were more explicit provided. In its current shape the paper requires visiting the experimental result section and understanding which specific model or architecture best transfer according to the proposed metric. Given that a significant portion of the paper's contribution is about empirical validation of the proposed transferability metric, this aspect should be improved. This is important as the paper claims \"strong correlation\" both in the abstract and conclusion. \n\nThe paper frequently refers to the \"domain shift\" causing features not to lie on the hypersphere. The implications of this assertion are not clear, and what is meant by it being \"too strict,\" needs clearer elaboration. The paper seems to lack a direct discussion on this. In which way not lying on the hypersphere is related to neural collapse? For instance, could the final classifier bias parameters be disregarded, thereby naturally aligning features with the hypersphere? The connection between domain shift and features not aligning with the hypersphere should be better clarified.\n\nThe metric introduced appears to hold even when training does not proceed until TPT. Given this, what is the significance of emphasizing the necessity for neural collapse in the proposed method?"
                },
                "questions": {
                    "value": "Questions and weaknesses are grouped together to facilitate a clearer understanding and correlation of the issues."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission919/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission919/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission919/Reviewer_Rkcn"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission919/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698872963884,
            "cdate": 1698872963884,
            "tmdate": 1699636018904,
            "mdate": 1699636018904,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gFBw8LZnWR",
                "forum": "UDbEpJojik",
                "replyto": "m8RE0nbTxN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for providing valuable comments and address your concerns in the following responses.\n\n> **[Q1]**: Considering the rapid dissemination of models online by third-party sources, the approach of selecting the optimal model for fine-tuning might have constrained applicability. \n\n**[A1]** It is precisely because there are numerous third-party models that it becomes necessary to evaluate these models to estimate their suitability for downstream tasks without time-consuming fine-tuning for all the models.\n\n> **[Q2]**: The assertion of a strong correlation is not clearly evident from the paper. For example, It would be beneficial if, from the experimental results, some takeaway messages were more explicitly provided. \n\n**[A2]** We feel sorry for any confusion. We want to explain the strong correlation observed in Figure 1 as follows. The NC score ranking in these pre-trained models remains mostly consistent during fine-tuning. For instance, in subfigure (a), the yellow line represents the variation curve in NC for ResNet152 during the fine-tuning process. It starts with the highest NC on the target data from the initial moment and continues to maintain the highest NC throughout fine-tuning. The black curve (DenseNet201) starts with the lowest degree of NC, and continues to maintain the lowest level during the fine-tuning process. Other models also exhibit similar patterns, therefore, we posit the existence of a strong correlation between the NC of the pre-trained model and that of the fine-tuned model.\n\n\n \n> **[Q3]**: In its current shape the paper requires visiting the experimental result section and understanding which specific model or architecture best transfers according to the proposed metric. \n\n\n**[A3]** Our metric does not exhibit bias towards specific network structures or loss functions. For example, on the DTD dataset, FaCe gives ResNet152 the highest score, while on Cifar-10, FaCe gives EfficientNetB3 the highest score.\n\nThis sounds reasonable for a qualified transferability estimation score since the best model is related to the specific downstream task. For different tasks, the best model, loss function or source datasets vary.\n\nThe task of transferability estimation aims to find a metric for assessing the appropriateness of pre-trained models for downstream tasks, rather than evaluating the effectiveness of particular architectures or loss functions.\n\n\t\n> **[Q4]**: The paper frequently refers to the \"domain shift\" causing features not to lie on the hypersphere. The implications of this assertion are not clear, and what is meant by it being \"too strict,\" needs clearer elaboration. The paper seems to lack a direct discussion on this.\n\n**[A4]** When Neural Collapse (NC) occurs, the features of the training data collapse to class means, and the class means, along with the classifier weights, converge to the vertices of a simplex equiangular tight frame (ETF). At this point, the class means of the features can be considered as distributed on a hypersphere [1]. However, the model is pre-trained on the source data. On downstream target data,  domain shift exists, and the class means will not be located on the hypersphere. \n\nOur class fairness term is inspired by NC2. A widely-used metric in existing literatures is defined as $$ \\mathcal{NC}_2(W) = \\left\\|\\frac{W W^{\\top}}{\\left\\|{W} {W}^{\\top}\\right\\|_F}-\\frac{1}{\\sqrt{K-1}}\\left({I}_K-\\frac{1}{K} \\mathbf{1}_K \\mathbf{1}_K^{\\top}\\right)\\right\\|_F.$$ Essentially, this metric measures the equiangularity of the classifier weights or class means. To use this metric, it should be under the scenarios where the class means are located on the hypersphere. This is the meaning of \"too strict\" in our manuscript.\n\n\nWe apologize for any confusion caused by the unclear description.  We have clarified the relevant description in Section 3.2.\n- [1] Neural Collapse: A Review on Modelling Principles and Generalization. TMLR 2023.\n\n\n> **[Q5]**: Could the final classifier bias parameters be disregarded, thereby naturally aligning features with the hypersphere? \n\n**[A5]** The classifier is pre-trained on the source dataset, which has a different label space from the downstream target dataset, therefore, using the classifier makes no sense.\n\n\n> **[Q6]**: The metric introduced appears to hold even when training does not proceed until TPT. Given this, what is the significance of emphasizing the necessity for neural collapse in the proposed method?\n\n**[A6]** Sorry for the misunderstanding. We do not assume Neural Collapse in fine-tuning the pre-trained model. By contrast, we study the degree of NC of pre-trained models during fine-tuning, through the process and find an interesting observation. Our method is motivated by this observation, to estimate the degree of NC of the pre-trained model, and it is independent of whether training has reached TPT."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700397308557,
                "cdate": 1700397308557,
                "tmdate": 1700397308557,
                "mdate": 1700397308557,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DwXhGgayl1",
                "forum": "UDbEpJojik",
                "replyto": "m8RE0nbTxN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Invitation to further discussion"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nWe genuinely appreciate the time and effort you've invested in reviewing our paper. We have carefully provided relevant responses and results to your concerns. We are eager to further discuss with you and gain your insights **before the end of the Author/Reviewer phase**. Please let us know if any aspect of our work remains unclear or if you have additional feedback.\n\nThank you."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700573408111,
                "cdate": 1700573408111,
                "tmdate": 1700573408111,
                "mdate": 1700573408111,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "I3z7O1Nz0u",
                "forum": "UDbEpJojik",
                "replyto": "m8RE0nbTxN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nSince the discussion deadline is approaching in less than 11 hours, we kindly request your feedback on whether the response adequately addresses your concerns. If you have any more questions, we would be happy to provide further clarification.\n\nYour timely response is greatly appreciated.\n\nThanks."
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700702092780,
                "cdate": 1700702092780,
                "tmdate": 1700702092780,
                "mdate": 1700702092780,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "sfV5FxFcBf",
            "forum": "UDbEpJojik",
            "replyto": "UDbEpJojik",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission919/Reviewer_JPai"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission919/Reviewer_JPai"
            ],
            "content": {
                "summary": {
                    "value": "The \"pre-training followed by fine-tuning\" paradigm has become the standard training approach for many tasks in the deep learning domain. Selecting the appropriate pre-trained model for a specific downstream task poses a challenge. This paper introduces a transferability estimation method, Fair Collapse (FaCe). The method aims to determine a metric that indicates the potential performance of pre-trained models on a target dataset without the need to fine-tune every model. Ideally, transferability metrics should closely correlate with the actual performance post-fine-tuning."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.The paper addresses a significant challenge in transfer learning: the selection of the optimal pre-trained model for a designated downstream task.\n2.The correlation between neural collapse in pre-trained models and their subsequent fine-tuned versions is intriguing and serves as the foundation for the method proposed.\n3.The introduced FaCe method is innovative and incorporates both class separation and class fairness, potentially preventing biases during model selection.\n4.The array of experiments span multiple tasks and training methodologies, underscoring the robustness and universality of FaCe."
                },
                "weaknesses": {
                    "value": "1.The introduction contains repetitive statements regarding transferability estimation and its objectives. For clarity and brevity, such redundancy should be avoided.\n2.The meaning of the variable 't' in Equation (6) is not defined in the surrounding context.\n3.When calculating the Variance Collapse, the authors assign equal weight to each category. However, during performance evaluation, categories with larger sample sizes play a more significant role. To ensure FaCe genuinely represents the potential performance of pre-trained models on the target dataset, the current setup seems somewhat flawed. An explanatory note from the authors is sought.\n4.In the process of computing and presenting equidistance, the class fairness score F only explores equal distances of each class to the remaining classes. Due to the domain shift, features don't lie on a unit sphere. Thus, \"equal distance of each class to the other classes\" is not synonymous with \"equal distances amongst all classes.\" The claim \"Due to the domain shift, the features do not lie on the unit sphere\" lacks sufficient justification. A detailed explanation from the authors would be appreciated.\n5.The paper's primary contribution builds upon Variance Collapse by incorporating Class Fairness for a more accurate assessment of model fairness across classes. Yet, the experimental section lacks ablation studies on Class Fairness. To substantiate the effectiveness of the method, the inclusion of relevant experimental evidence is imperative."
                },
                "questions": {
                    "value": "1.While employing FaCe as the criterion to judge the generalizability of pre-trained models in target domains, have the authors considered the impact of differences in class distributions and class counts between source and target domains?\n2.The authors extended the concept of equiangularity to equidistance. In the process of calculating distances between classes, why was the current method chosen? Were alternative approaches contemplated?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission919/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698887641675,
            "cdate": 1698887641675,
            "tmdate": 1699636018825,
            "mdate": 1699636018825,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pLqxqR3Lng",
                "forum": "UDbEpJojik",
                "replyto": "sfV5FxFcBf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for providing valuable comments and address your concerns in the following responses.\n\n> **[Q1]**: The introduction contains repetitive statements regarding transferability estimation and its objectives. For clarity and brevity, such redundancy should be avoided. \n\n**[A1]** Thanks for your suggestion, we have updated the related description in the Introduction.\n\n> **[Q2]**: The meaning of the variable 't' in Equation (6) is not defined in the surrounding context. \n\n**[A2]** Sorry for the typos, the variable t is the temperature of softmax, we have updated the related description in Section 3.2.\n\n> **[Q3]**: In Variance Collapse calculation, equal weight is given to all categories, yet performance evaluation gives more importance to larger sample size categories. This setup may affect the representation of FaCe's performance on the target dataset. \n\n**[A3]** The final fine-tuned accuracy is computed on the test set. In practice, we may not know the class distribution of the test set when calculating the score, so it's not possible to pre-assign weights to certain classes. What we can obtain is the class distribution of the training set. In downstream tasks, to ensure generalization on the test set, the class distribution of the training set is often balanced.\n\n> **[Q4]**: \"equal distance of each class to the other classes\" is not synonymous with \"equal distances amongst all classes.\" The claim \"Due to the domain shift, the features do not lie on the unit sphere\" lacks sufficient justification. \n\n\n**[A4]** When Neural Collapse (NC) occurs, the features of the training data collapse to class means, and the class means, along with the classifier weights, converge to the vertices of a simplex equiangular tight frame (ETF). At this point, the class means of the features can be considered as distributed on a hypersphere [1]. However, the model is pre-trained on the source data. On downstream target data,  domain shift exists, and the class means will not be located on the hypersphere. \n\n\nOur class fairness term is inspired by NC2. A widely-used metric in existing literatures is defined as $$ \\mathcal{NC}_2(W) = \\left\\|\\frac{W W^{\\top}}{\\left\\|{W} {W}^{\\top}\\right\\|_F}-\\frac{1}{\\sqrt{K-1}}\\left({I}_K-\\frac{1}{K} \\mathbf{1}_K \\mathbf{1}_K^{\\top}\\right)\\right\\|_F.$$ Essentially, this metric measures the equiangularity of the classifier weights or class means. To use this metric, it should be under the scenarios where the class means are located on the hypersphere. \n\nHence, we chose not to use the equiangularity measure of NC2 as found in existing work but instead propose to approximate NC2 using the equidistance of each class distribution.\n\nWe apologize for any confusion caused by the unclear description.  We have clarified the relevant description in Section 3.2.\n\n- [1] Neural Collapse: A Review on Modelling Principles and Generalization. TMLR 2023.\n\n\n> **[Q5]**: The experimental section lacks ablation studies on Class Fairness. To substantiate the effectiveness of the method, the inclusion of relevant experimental evidence is imperative.\n\n**[A5]** We agree that the ablation study is crucial. As shown in Section 4.6, we provide the ablation study of two terms of FaCe. The results validate that both terms are effective, and they complement each other to achieve the best average performance.\n\n> **[Q6]**: While employing FaCe as the criterion to judge the generalizability of pre-trained models in target domains, have the authors considered the impact of differences in class distributions and class counts between source and target domains? \n\n**[A6]** In transferability estimation, only the pre-trained source model is available, and the information about the source data is unknown. We believe that the only source model available is a more practical setup. In this setting, we cannot obtain the class distribution of the source or consider differences between the source and target. Your idea is reasonable, and we will consider about it in future work."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700397724018,
                "cdate": 1700397724018,
                "tmdate": 1700397724018,
                "mdate": 1700397724018,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MiwSoletAv",
                "forum": "UDbEpJojik",
                "replyto": "sfV5FxFcBf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> **[Q7]**: The authors extended the concept of equiangularity to equidistance. In the process of calculating distances between classes, why was the current method chosen? Were alternative approaches contemplated?\n\n**[A7]** The most naive approach is to represent a class using its class mean and compute the class mean (CM) distances. However, due to significant differences in the intra-class variances of different classes in the target data, it is more reasonable to fit Gaussian distributions to the feature distributions of different classes and calculate the overlap. When measuring overlap between distributions, the introduction of Bhattacharyya (Bh) distance is a common practice.\n\nWe provide experiments using class mean distances as an alternative to measuring class distribution overlap below. Table (a) (b) and \\(c\\) correspond to Tables 1 2 and 3,  in our paper, respectively (*i.e.*, (a) heterogeneous model zoo with a single source, (b) heterogeneous model zoo with multiple sources, and \\(c\\) homogeneous model zoo with multiple sources and loss functions). The values in the table are the average results. It can be seen that FaCe with Bhattacharyya distance (FaCe W/ Bh) has a better average performance.\n\n\n| (a) | FaCe w/ Bh | FaCe w/ CM |\n|:---:|:---:|:---:|\n| Kendall | 0.56  | 0.32  |\n| Pearson | 0.62  | 0.37  | \n\n| (b) | FaCe w/ Bh | FaCe w/ CM |\n|---|:---:|:---:|\n| Kendall | 0.62  | 0.55  |\n| Pearson | 0.78  | 0.44  |\n\n|\\(c\\)| FaCe w/ Bh | FaCe w/ CM |\n|:---:|:---:|:---:|\n| Kendall | 0.38  | 0.36  |\n| Pearson | 0.37  | 0.73  |"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700397767614,
                "cdate": 1700397767614,
                "tmdate": 1700400405194,
                "mdate": 1700400405194,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "C4BVx0WlZB",
                "forum": "UDbEpJojik",
                "replyto": "sfV5FxFcBf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Invitation to further discussion"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nWe genuinely appreciate the time and effort you've invested in reviewing our paper. We have carefully provided relevant responses and results to your concerns. We are eager to further discuss with you and gain your insights **before the end of the Author/Reviewer phase**. Please let us know if any aspect of our work remains unclear or if you have additional feedback.\n\nThank you."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700573393087,
                "cdate": 1700573393087,
                "tmdate": 1700573393087,
                "mdate": 1700573393087,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yduVT9h26f",
                "forum": "UDbEpJojik",
                "replyto": "sfV5FxFcBf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nSince the discussion deadline is approaching in less than 11 hours, we kindly request your feedback on whether the response adequately addresses your concerns. If you have any more questions, we would be happy to provide further clarification.\n\nYour timely response is greatly appreciated.\n\nThanks."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700702037194,
                "cdate": 1700702037194,
                "tmdate": 1700702037194,
                "mdate": 1700702037194,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "XD0crnG846",
            "forum": "UDbEpJojik",
            "replyto": "UDbEpJojik",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission919/Reviewer_cirw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission919/Reviewer_cirw"
            ],
            "content": {
                "summary": {
                    "value": "Prior studies have revealed that well-trained models exhibit the phenomenon of Neural Collapse (NC). The authors observe a strong correlation between the neural collapse of pre-trained models and their corresponding fine-tuned models. Considering the three characteristics of NC, the authors propose the Fair Collapse (FaCe) metric to help select pre-trained models that perform better after fine-tuning. FaCe consists of two key components: variance collapse term and class fairness term. The second components is the key contribution."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The authors explore the impact of Neural Collapse (NC) in the \"pre-training then fine-tuning\" paradigm and observe that the ranking of NC in the pre-trained models remains mostly consistent during the fine-tuning process.\n- The authors employ a metric Fair Collapse (FaCe) to estimate the transferability of pre-trained models."
                },
                "weaknesses": {
                    "value": "- The first term of NC is common. This idea is commonly used in various classification tasks.\n- The class fairness score F is used to make any class distribution has a similar overlap with the distribution of other classes. This is quite similar to making the distances between these distributions equal. \n- The fine-tuning hyperparameters of different pre-trained models may have a significant impact, and the phenomena observed in the paper might lack persuasiveness.\n- The paper lacks experiments on the relationship between the accuracy of pre-trained models, the accuracy of fine-tuned models, and the proposed FaCe method.\n\nAlthough the authors observed an interesting phenomenon, it may not be solid. They have not clarified the differences between their metric and those presented in other papers. All in all, at this point in time, I would recommend this paper as weak reject."
                },
                "questions": {
                    "value": "see weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission919/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698892276298,
            "cdate": 1698892276298,
            "tmdate": 1699636018761,
            "mdate": 1699636018761,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pU4okzv88X",
                "forum": "UDbEpJojik",
                "replyto": "XD0crnG846",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for providing valuable comments and address your concerns in the following responses.\n\n> **[Q1]**: The first term of NC is common. This idea is commonly used in various classification tasks.\n\n**[A1]** We agree that the first term of NC is commonly used in various classification tasks. However, our work introduces the first term of NC as a metric during the downstream fine-tuning process, as shown in Figure 1. Motivated by the observation that the NC of the pre-trained model is correlated with the corresponding fine-tuned model, we include the first term of NC, i.e., the variance collapse term, for transferability estimation, which could be considered as a baseline method of the proposed FaCe. \n\nEven for this term, we want to clarify the difference between the variance collapse term and several closely related works, Hscore [1] considers between-class variance and feature redundancy; GBC [2] is based on the summation of the pairwise class separability. Our variance collapse term is the magnitude of between-class covariance compared to within-class covariance, which is different from them.\n\n- [1] An information theoretic approach to transferability in task transfer learning\n- [2] Transferability Estimation Using Bhattacharyya Class Separability\n\n\n> **[Q2]**: Class fairness score F is quite similar to making the distances between these distributions equal.\n\n**[A2]** The high-level idea that makes the distances between class distributions equal is indeed used by some classification methods. However, such a perspective has not been explored in the transferability estimation task.\nAlso, we do not directly borrow ideas from other works but design a specific metric for our task.\n\nThe main insight lies in the observation that the NC metrics are robust along the fine-tuning process, motivating us to estimate the degree of NC to estimate the fine-tuned accuracy, i.e., the transferability.\n\nDifferent from the score in NC2, we propose a similar formulation that estimates equidistance based on the distribution overlap matrix entropy. We also provide a comparison with NC2 in Appendix A.2, the results validate that our method is more suitable for transferability estimation problem and achieve a higher performance.\n\n\n\n> **[Q3]**: The fine-tuning hyperparameters of different pre-trained models may have a significant impact, and the phenomena observed in the paper might lack persuasiveness.\n \n**[A3]** We follow existing works [1,2,3] in transferability estimation and select a set of hyperparameters that perform best on the downstream dataset.  In fact, the results are obtained based on different seeds, indicating the robustness of the fine-tuning process. We have clarified this point in the experimental details of Section 4.1.\n- [1] Transferability Estimation using Bhattacharyya Class Separability.\n- [2] LEEP: A New Measure to Evaluate Transferability of Learned Representations.\n- [3] LogME: Practical Assessment of Pre-trained Models for Transfer Learning.\n\n> **[Q4]**: lacks experiments on the relationship between the accuracy of pre-trained models, the accuracy of fine-tuned models, and the proposed FaCe.\n\n**[A4]** In revision, we updated the zip file of supplementary materials, which added a file named \"Acc-FaCe.xlsx.\" This file provides the accuracy and FaCe values of our experiments. Besides, Figure 4 presents the qualitative results of the fine-tuned model accuracy and FaCe Score, along with comparisons to other methods. However, the classifier dimension of the pre-trained model does not match the number of classes in the downstream target data, making it impossible to provide accuracy directly for the pre-trained model.\n\n> **[Q5]**: The authors observed an interesting phenomenon, it may not be solid. \n\n**[A5]** We agree. Our main insight is based on a preliminary study, motivating us to develop a new score FaCe. The two terms of FaCe correspond to two characteristics of NC. To validate the effectiveness, we conducted numerous experiments, and found it works quite well across various model zoos and tasks. We believe the proposed method FaCe would shed some light on future work.\n\n\n> **[Q6]**: They have not clarified the differences between their metric and those presented in other papers.\n\n**[A6]** We feel sorry for any confusion. As written in Section 2, previous works focused on between-class separability and the information of features, which is similar to the high-level idea of our variance collapse term.\n\nCompared to existing methods, we further consider the class fairness of pre-trained models towards the target class, this is a new perspective, which has not been explored by existing methods."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700397080359,
                "cdate": 1700397080359,
                "tmdate": 1700397080359,
                "mdate": 1700397080359,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "y4343M3HJl",
                "forum": "UDbEpJojik",
                "replyto": "XD0crnG846",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Invitation to further discussion"
                    },
                    "comment": {
                        "value": "Dear reviewer, \n\nWe genuinely appreciate the time and effort you've invested in reviewing our paper. We have carefully provided relevant responses and results to your concerns. We are eager to further discuss with you and gain your insights **before the end of the Author/Reviewer phase**. Please let us know if any aspect of our work remains unclear or if you have additional feedback. \n\nThank you."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700573359990,
                "cdate": 1700573359990,
                "tmdate": 1700573359990,
                "mdate": 1700573359990,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Y5K9EHFhX8",
                "forum": "UDbEpJojik",
                "replyto": "XD0crnG846",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nSince the discussion deadline is approaching in less than 11 hours, we kindly request your feedback on whether the response adequately addresses your concerns. If you have any more questions, we would be happy to provide further clarification.\n\nYour timely response is greatly appreciated.\n\nThanks."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700701993710,
                "cdate": 1700701993710,
                "tmdate": 1700701993710,
                "mdate": 1700701993710,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "d33hQ9Wywl",
            "forum": "UDbEpJojik",
            "replyto": "UDbEpJojik",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission919/Reviewer_pEKS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission919/Reviewer_pEKS"
            ],
            "content": {
                "summary": {
                    "value": "Inspired by Neural Collapse, the paper proposes a new metric, FaCe for transferability estimation. In addition to intra-class and iter-class distance, FaCe utilizes the third condition: all classes should be evenly spread in feature spaces. The third condition is evaluated by Bhattacharyya coefficient between class distributions, which is named Class Fairness. FaCe outperforms other methods in diverse benchmarks for transferability estimation."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Motivation is clear and well supported by method design.\n- Paper is well organized and easy to understand\n- The performance of FaCe looks promising."
                },
                "weaknesses": {
                    "value": "- Between-class covariance, $\\Sigma_B$, is defined as the distance between the class avg and the global avg, which does not align with the definition of between-class, a distance between classes.\n\n- Class Fairness term might be related to Variance Collapse term. Class Fairness term uses intra-class and inter-class covariance, which are also used in Variance Collapse term. But, the relationship between the two terms is not studied enough."
                },
                "questions": {
                    "value": "- Why does between-class covariance $\\Sigma_B$ in Variance Collapse use global average $h_G$ instead of class average $h_k$? I believe $\\Sigma_B=\\frac{1}{K} \\Sigma_{k_i} \\Sigma_{k_j} (h_{k_i} - h_{k_j})^2 $ would be more correct for the between-class covariance than $h_G$.\n\n- Bhattacharyya coefficient looks similar to Variance Collapse term. Bhattacharyya coefficient is a multiplication between inverse within-class covariance and between-class covariance, while Variance Collapse is a multiplication of within-class covariance and inverse between-class covariance. How about replacing Variance Collapse with inverse Bhattacharyya coefficient for simplicity of formulation?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission919/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699000476054,
            "cdate": 1699000476054,
            "tmdate": 1699636018704,
            "mdate": 1699636018704,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8tIj1KUniX",
                "forum": "UDbEpJojik",
                "replyto": "d33hQ9Wywl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for providing valuable comments and address your concerns in the following responses.\n\n>  **[Q1]**: Between-class covariance, $\\Sigma_B$, is defined as the distance between the class avg and the global avg, which does not align with the definition of between-class, a distance between classes.\n\n**[A1]** Here, we directly adopt the common definition of variance. Intuitively, the distance between the class avg and the global avg in $\\Sigma_B$ serves the purpose of quantifying the total distance between all class means and the global mean. When the distances between classes are large, the class means will be farther away from the global mean, and when the distances are small, they will be closer to the global mean. Therefore, $\\Sigma_B$ can effectively reflect the distance between classes.\n\n> **[Q2]**: Class Fairness term might be related to the Variance Collapse term. The Class Fairness term uses intra-class and inter-class covariance, which are also used in the Variance Collapse term. However, the relationship between the two terms is not studied enough.\n\n**[A2]** Variance Collapse score (VC) is the magnitude of between-class covariance compared to within-class covariance. Different from that, the covariance in Class Fairness score (CF)  is used to estimate the parameters of Gaussian distributions when modeling class features. These two terms complement each other, and we have conducted ablation experiments in Table 4 to investigate their individual effects.\n\nThanks for your suggestion, we have included some explanations of the relationship between the two terms in Section 4.6.\n\n> **[Q3]**: Why does between-class covariance $\\Sigma_B$ in Variance Collapse use global average $h_G$ instead of class average $h_k$? I believe $$ \\Sigma_B=\\frac{1}{K} \\Sigma_{k_i} \\Sigma_{k_j} (h_{k_i} - h_{k_j})^2 $$ would be more correct for the between-class covariance than $h_G$. \n\n**[A3]** Thanks for your suggestion. $\\Sigma_B$ in Eq. (3) measures the sum of distances between all class means and the global mean, while the $\\Sigma_B$ you mentioned measures the sum of distances between pairwise class means. These two forms may be influenced by class imbalance, but they are equivalent when the classes are balanced. We simplify the notation $k_i$ and $k_j$ as $i$ and $j$. The proof is provided below.\n$$\n\\begin{align}\n\\Sigma_B = &\\frac{1}{K} \\Sigma_{i} \\Sigma_{j} (h_{i} - h_{j})^2 \\\\\n= & \\frac{1}{K} \\Sigma_{i} \\Sigma_{j} (h_{i} - h_G + h_G- h_{j})^2 \\\\\n= & \\frac{1}{K} \\Sigma_{i} \\Sigma_{j} [ (h_{i} - h_G)^2 + (h_G- h_{j})^2 + 2(h_{i} - h_G)(h_G- h_{j}) ] \\\\\n= & \\frac{1}{K} \\Sigma_{i}K(h_{i} - h_G)^2 + \\frac{1}{K}\\cdot K\\cdot \\Sigma_{j} (h_{j} - h_G)^2 + 2 \\cdot \\frac{1}{K} \\Sigma_{i}\\Sigma_{j}(h_{i} - h_G)(h_G- h_{j}) .\n\\end{align}\n$$\nWhen the number of each classes is balanced, we have $h_G = \\frac{1}{K}\\Sigma_{k_j} h_{k_j} = \\frac{1}{K}\\Sigma_{k_i} h_{k_i}$, The third term above can be transformed into:\n$$\n\\begin{align}\n\\frac{2}{K} \\Sigma_{i}\\Sigma_{j}(h_{i} - h_G)(h_G- h_{j})\n& = \\frac{2}{K}\\cdot\\Sigma_{i}(h_{i} - h_G)\\Sigma_{j}(h_G- h_{j}) \\\\\n& = \\frac{2}{K}\\cdot\\Sigma_{i}(h_{i} - \\frac{1}{K}\\Sigma_{j} h_{j} )\\Sigma_{j}(\\frac{1}{K}\\Sigma_{i} h_{i} - h_{j}) \\\\\n& = \\frac{2}{K}\\cdot(\\Sigma_{i}h_{i} - K\\cdot\\frac{1}{K}\\Sigma_{j}h_{j} ) \\cdot (K\\cdot\\frac{1}{K}\\Sigma_{i}h_{i} - \\Sigma_{j}h_{j}) \\\\\n& = 0\n\\end{align}\n$$\nTherefore,\n$$\n\\begin{align}\n\\Sigma_B = \\frac{1}{K} \\Sigma_{i}K(h_{i} - h_G)^2 + \\frac{1}{K}\\cdot K\\cdot \\Sigma_{j} (h_{j} - h_G)^2 = 2 \\Sigma_{i}(h_{i} - h_G)^2  = 2K \\cdot \\frac{1}{K}\\Sigma_{i}(h_{i} - h_G)^2\n\\end{align}\n$$\nIn our task, fine-tuning accuracy is measured on the test set. To ensure generalization, the training set is typically class-balanced.\n\nWe provide the comparisons of these two methods on the heterogeneous model zoo with a single source (Table 1 in our paper) below. Method \"FaCe w/ global cov'' is our $\\Sigma_B$, and FaCe w/ btw-distance is your proposed one, the results show that there is minimal difference between the two.\n\n|  | Method | CIFAR10 | CIFAR100 | Pets | CUB | gtsrb | DTD | STL10 | Avg. |\n|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n| Kendall | FaCe w/ global cov | 0.81  | 0.83  | 0.39  | 0.33  | 0.10  | 0.56  | 0.90  | 0.56  |\n|  Kendall | FaCe w/ btw-distance | 0.83  | 0.83  | 0.39  | 0.33  | 0.10  | 0.57  | 0.90  | 0.57  |\n| pearson | FaCe w/ global cov | 0.89  | 0.85  | 0.64  | 0.39  | -0.05  | 0.71  | 0.91  | 0.62  |\n|  pearson | FaCe w/ btw-distance | 0.89  | 0.85  | 0.63  | 0.39  | -0.06  | 0.71  | 0.91  | 0.62  |"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700398144481,
                "cdate": 1700398144481,
                "tmdate": 1700398438599,
                "mdate": 1700398438599,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cW9SGXcdHn",
                "forum": "UDbEpJojik",
                "replyto": "d33hQ9Wywl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Authors"
                ],
                "content": {
                    "comment": {
                        "value": ">  **[Q4]**: How about replacing Variance Collapse with inverse Bhattacharyya coefficient for simplicity of formulation?\n\n**[A4]** The Bhattacharyya coefficient measures the overlap between class distributions and quantifies the separation between them. The intuitive difference between the Bhattacharyya coefficient and Variance Collapse score is that VC additionally considers the compactness within classes.\n\nYour idea is reasonable as well. We provide the comparisons of these two methods on the heterogeneous model zoo with a single source (Table 1 in our paper) below.  FaCe w/ VC is the original version of FaCe, and FaCe w/ neg-Bh is a variant that replaces our variance collapse term with the sum of the negative Bhattacharyya coefficient between classes. Specifically, we replace the score $C$ in FaCe with: $$ C_{negBh}=- \\sum_{i=1}^{K}\\sum_{j=1\uff0ci\\neq j}^{K} B(k_i,k_j).$$\nThe results are shown below. Our ultimate goal is to consider models that exhibit both large inter-class distances and relatively uniform class distributions as better. While replacing the first term with other forms may have some impact on the final results, the effect is not significant.\n\n|  |  | CIFAR10 | CIFAR100 | Pets | CUB | gtsrb | DTD | stl10 | Avg. |\n|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n| Kendall| FaCe w/ VC | 0.81  | 0.83  | 0.39  | 0.33  | 0.10  | 0.56  | 0.90  | 0.56  |\n| Kendall | FaCe w/ neg-Bh | 0.81  | 0.89  | 0.41  | 0.23  | -0.05  | 0.61  | 0.83  | 0.53  |\n| Pearson | FaCe w/ VC | 0.89  | 0.85  | 0.64  | 0.39  | -0.05  | 0.71  | 0.91  | 0.62  |\n| Pearson  | FaCe w/ neg-Bh | 0.88  | 0.91  | 0.64  | 0.57  | -0.01  | 0.58  | 0.78  | 0.62  |"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700398187988,
                "cdate": 1700398187988,
                "tmdate": 1700398187988,
                "mdate": 1700398187988,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hVvl7SFNrm",
                "forum": "UDbEpJojik",
                "replyto": "cW9SGXcdHn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission919/Reviewer_pEKS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission919/Reviewer_pEKS"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response.\n\nI was stupid about the question related to between-class distance.\nI appreciate your kind correction.\n\nAll of my concerns have been solved by your response.\n\nBut, I'm not familiar with \"Transferability Estimation\". So, I will not strongly defend my rating.\nI hope you solve other reviewers' concerns."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700465836692,
                "cdate": 1700465836692,
                "tmdate": 1700465836692,
                "mdate": 1700465836692,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]