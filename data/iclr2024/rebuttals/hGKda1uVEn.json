[
    {
        "title": "Support Vector-based Shapley Value Estimation for Feature Selection and Explanation"
    },
    {
        "review": {
            "id": "0uyxOASjZz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3322/Reviewer_Ey9T"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3322/Reviewer_Ey9T"
            ],
            "forum": "hGKda1uVEn",
            "replyto": "hGKda1uVEn",
            "content": {
                "summary": {
                    "value": "The paper proposes a computationally efficient method for assessing feature importance, based on a polynomial model. To this end, it leverages a support vector machine, or more generally the kernel trick. The decisive advantage is added flexibility compared with a linear model."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "I very much like that the method is able to take all degrees of variable interactions into account. This is a very good use of the kernel trick.\n\nThe controlled experiments on synthetic data are well designed."
                },
                "weaknesses": {
                    "value": "Eq. (7) is simply a polynomial hypothesis, possibly feeding into a non-linearity, with degree equal to the number of features. This is an unusual but of course viable model. The authors consider the potential computational burden of the exponential feature explosion, but they do not mention the associated learning theoretical risk, namely overfitting. LASSO-style L1-regularization is hinted at. However, standard L2 regularization is applied in eq. (9), as it is common in SVMs. There is no single word about the need to tune the regularization constant. How do I use a method for estimating feature importance if the resulting values depend on a magic parameter?\n\nProvided that the model is a simple polynomial, and provided that the polynomial kernel is among the few standard kernels considered in basically all SVM research (and all non-linear SVM software packages), I am very much surprised by Lemma 1. Why not simply leverage the polynomial kernel as it is used since 25 years or so?\n\nI am even more surprised by the discussion following eq. (14). For prediction making, an SVM never uses $m$ directly, but only $m^T x$, which can be computed efficiently using the kernel. This is an absolutely basic fact about SVMs and kernel methods in general. I can only conclude that the authors don't really know the methods they aim to leverage. It seems to me that Theorem 1 and the whole section 3.2 can be replaced with the standard prediction making scheme of SVMs. If I am mistaken, then I'd be appreciate being corrected in the rebuttal phase.\n\nFor my taste, the paper contains too many references to the appendix for information that is crucial for understanding the proposed method. This essentially amounts to circumventing the page limit. Put differently: ignoring the appending, the paper is not sufficiently self-contained.\n\nThe choice of combinations of methods and data sets in section 5.2 appears unsystematic. Why were these data sets used and not others? In order to be convinced, I'd like to see experiments on an established data set collection. In this case, it is fine to present a representative subset, with complete tables in the appendix.\n\nTable 2 presents results in terms of the MSE. Is this simply the quality of the model prediction, i.e., testing the fit of a polynomial to another predictor like a random forest? If so, what does it have to do with estimating the correct feature importance? Also, how do the authors justify its use as a measure of quality of an \"explanation\"? What if I fit an RF \"explainer\" to an RF model, with an error of zero? Would the authors then conclude that it is a superior explanation?\n\nFigure 2 can be improved in multiple ways. It definitely needs a log scale on the vertical axis! The range of features from 10 to 20 is extremely narrow, and definitely unsuitable for estimating complexity, which is an inherently asymptotic quantity. Please extend at least to a few hundreds. Simply restrict methods that don't scale well (like the Taylor expansion approach) to smaller dimensions.\n\nI appreciate that the authors provide code. Though, it is not sufficiently commented (or even documented). At the very least, please provide a README explaining prerequisites like required packages, data set files (and where to get them), and an overview of which script is supposed to do what. Naively running the scripts, I was not able to do anything useful with the code, and I was far from reproducing any experiments. Furthermore, the provided zip file contains hidden MACOS and PYTHON temporary files, as well as auto-generated html files and some (huge) javascript. It is entirely unclear to me why they are included.\n\nMinor points:\n\nWhen introducing the notation, please consider replacing the verb \"show\" by \"denote\".\n\nMobius -> M\u00f6bius ({\\\"o} in LaTex)\n\nTerminology, between eq. (8) and (9): $w^T \\phi(x) + b$ is not a hyperplane, but a linear function. For $m \\not= 0$, its kernel (zero set) is a hyperplane.\n\nSection 5.1: Please consider replacing the \"*\" symbol commonly used for multiplication in programming by a LaTeX math symbol like \\cdot or \\times.\n\nFigure 1: What does the vertical axis represent? It is in the text, but the information should really be in the figure caption."
                },
                "questions": {
                    "value": "Please comment on my criticism above on section 3.2. Can the method make predictions in the same way a kernel SVM does? If no, why not?\n\nPlease also comment on my understanding of the MSE in table 2. Why do you think that it is a suitable measure of quality?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3322/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697388399194,
            "cdate": 1697388399194,
            "tmdate": 1699636281793,
            "mdate": 1699636281793,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "07R8HGkYAL",
                "forum": "hGKda1uVEn",
                "replyto": "0uyxOASjZz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3322/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3322/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate the reviewer for providing us with feedback. In what follows, we discuss the raised concerns point-by-point. \n\n1. Overfitting\n\nThanks for the nice point. Indeed, tuning the parameter in SVM is important and we will discuss it in more detail in the camera-ready version of the paper. We already tested two hyperparameters (namely: the order of interaction q and the regularization parameter) with the grid search (see the script gridsearch_svsvl.py), but we did not mention it in the manuscript. We can discuss further in the manuscript how they can influence the calculation of the Shapley value.\n \n2. Polynomial kernel & Lemma 1\n\nThe presented kernel in Lemma 1 is different from the polynomial kernel. The polynomial kernel is k_{poly}(x,z) = (x^Tz+c)^r (it is the sum of products of features), while the kernel function in Lemma 1 is k_mul(x,z) = -1 + \\prod 1 + x_iz_i (which is the product of products of features).\nThe presented kernel function is nonetheless similar to the ANOVA kernel. We already explained this in the text ( cf. Footnote 1, page 4,: \u201cThe kernel function is similar to the ANOVA kernel with a linear base kernel (Durrande et al., 2013; Stitson et al., 1999), with a minor difference of having a -1. we provide the proof for completeness and because it helps understand the dynamic programming for q-additive kernel function presented in the following.\u201d) For these two reasons, we provided the result as a lemma.\n  \n3. Prediction with Kernel trick\n\nIt is correct that the prediction with SVM can be made by the dual solution and using the kernel trick, and there is no need to find the primal solution \u2013 which is not even feasible when the mapping to the feature space is not explicit as in the RBF kernel. However, the goal of Section 3.2 is not to make a prediction but rather to calculate the Shapley values and interaction index for the features. By using the multilinear model discussed in Section 2 in detail, the primal solution to the SVM, denoted by m, has the requisite parameters to compute the Shapley value or interaction indices. That is why we need to compute the primal solution, which is feasible since there is an explicit mapping, i.e., the multilinear mapping. The entire Section 3.2 is devoted to developing a method to compute the Shapley value and interaction index from the dual SVM solution, which will be more efficient given that the primal solution has exponentially many parameters.\n \n4. Appendices\n\nWe tried to have a logical storyline in the paper (even without the appendix), and we moved the proofs, algorithms, and discussions on the interpretation of the multilinear model to the appendix. We also tried to be concise in all sections given the page limit. That being said, we are open to any suggestion to shorten the paper and bring the appendices up in the main part of the text, or to clarify the missed points in the article.\n \n5. Data sets and methods\n\nWe conducted experiments on synthesized and real datasets: with the synthesized experiments we can compare the methods based on the \u2018content\u2019 of the explanation, particularly we compare the important features derived by different methods with that of the ground truth. We cannot do the same on the real datasets since the ground truth is not known, and this is why we used the popular measures in explainability (i.e., local fidelity and execution time). We also included several explainable and feature selection methods for the comparative experiments. The used methods are either the most important ones in the literature or the ones that can take into account the interactions of features."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3322/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700058996440,
                "cdate": 1700058996440,
                "tmdate": 1700058996440,
                "mdate": 1700058996440,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qDmHyZkQ1r",
            "forum": "hGKda1uVEn",
            "replyto": "hGKda1uVEn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3322/Reviewer_iYFx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3322/Reviewer_iYFx"
            ],
            "content": {
                "summary": {
                    "value": "In this study, the authors proposed a method for estimating Shapley values (feature importance scores) from the coefficients of polynomial regression.\nThe authors have derived the relationship between Shapley values and marginal contributions, as well as their Mebius transformations, which connects the coefficients of polynomial regression and Shapley values.\nBased on this relationship, the authors propsoed an algorithm for computing Shapley values by learning the coefficients of polynomial regression.\nFurthermore, the authors focused on binary classification problems and propose a method to circumvent the direct computation of exponentially many coefficients of polynomial regression through dual SVM."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The strength of this paper is on the reduction of the computation of Shapley values into a problem solvable in polynomial time through polynomial regression and dual SVM.\n\n**Originality and Quality**\n\nThe use of dual SVM to avoid handling the exponential many coefficients in polynomial regression is the originality of this research.\nFurthermore, the computation of Shapley values without explicitly recovering the coefficients of polynomial regression from the dual SVM solution is intriguing.\n\n**Clarity**\n\nThroughout the paper, the main claims were reasonably well described, contributing to overall clarity.\n\n**Significance**\n\nIn problems where data or models can be adequately approximated using polynomial regression, the proposed method is considered a valuable approach for computing Shapley values.\nProviding an efficient solution for specific class of problems is an important contribution to research in this domain."
                },
                "weaknesses": {
                    "value": "The weakness of this paper lies in the gap between the set function and the polynomial regression model (7).\nIn the context of Shapley values for feature importance, each input feature's presence or absence is represented by binary values.\nThe set function is constructed based on this binary representation.\nIn contrast, each $x_i$ represetns the actual value of each input feature in the polynomial regression model (7).\nThis usage seems to be inappropriate as an analogy to the set function, as it doesn't correspond well with the notion of presence or absence of features.\nIn fact, in (7), the condition \"a feature takes the minimum value of 0\" does not necessarily mean that the feature is absent in the set function.\nThe paper seems to conflate \"presence or absence of features\" and \"actual values of features\" when introducing the multilinear extension.\nThus, Shapley values computed using the \"actual values of features\" in the polynomial regression model may not align with Shapley values calculated in the original set function.\nThe validity of replacing \"presence or absence of features\" with \"actual values of features\" and its consequences should be discussed in the paper.\n\nAdditionally, as a minor weakness, I would like to point out that in Section 5.1, the synthesized datasets seem to have independent features (according to the code in the supplement).\nIn cases where features are independent, feature importances can be well-estimated by fitting models like RandomForest and calculating permutation importance.\nIndeed, in the example below, RandomForest combined with permutation importance ranks important features reasonably well.\n(Because I could not find the reproducible codes for Sectoin 5.1, I implemented it by myself.)\nThe synthesized datasets used in the experiments may be too easy.\n\n```\nimport numpy as np  \nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.inspection import permutation_importance\n\ndef data1(X):\n    return np.prod(X[:, :3], axis=1), [0, 1, 2]\n\ndef data2(X):\n    return np.prod(X[:, :3], axis=1) + np.prod(X[:, 3:5], axis=1), [0, 1, 2, 3, 4]\n\ndef data3(X):\n    return np.exp(np.sum(X[:, :4]**2, axis=1)), [0, 1, 2, 3]\n\ndef gen_data(n, datatype, random_state=0):\n    np.random.seed(random_state)\n    X = np.random.randn(n, 10)\n    if datatype == 1:\n        y, tif = data1(X)\n    elif datatype == 2:\n        y, tif = data2(X)\n    else:\n        y, tif = data3(X)\n    return X, y, tif\n\nseed = 0\nfor dt in range(3):\n    x, y, tif = gen_data(500, dt, seed)\n    rf = RandomForestRegressor(random_state=seed).fit(x, y)\n    r = permutation_importance(rf, x, y, n_repeats=30, random_state=seed)\n    print('datatype:', dt)\n    print('true important features', tif)\n    print('feature ranks', np.argsort(r['importances_mean'])[::-1])\n\n>> datatype: 0\n>> true important features [0, 1, 2, 3]\n>> feature ranks [2 1 0 3 5 7 9 8 6 4]\n>> datatype: 1\n>> true important features [0, 1, 2]\n>> feature ranks [1 2 0 8 9 6 7 5 3 4]\n>> datatype: 2\n>> true important features [0, 1, 2, 3, 4]\n>> feature ranks [3 4 1 0 2 9 5 8 6 7]\n\n```"
                },
                "questions": {
                    "value": "* Are there any justification of replacing \"presence or absence of features\" in the original set function with \"actual values of features\" in (7)?\n* Is Shapley values computed using the \"actual values of features\" in the polynomial regression model identical with Shapley values calculated in the original set function?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3322/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698388326209,
            "cdate": 1698388326209,
            "tmdate": 1699636281709,
            "mdate": 1699636281709,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jIERgGzOjJ",
                "forum": "hGKda1uVEn",
                "replyto": "qDmHyZkQ1r",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3322/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3322/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate the reviewer for providing us with feedback. In what follows, we discuss the raised concerns point-by-point.\n\n1. The relationship between set function and Polynomial Regression, and the presence and absence of a feature\n\nIt is correct that the Shapley value-based feature importance is calculated by constructing coalitions between different sets of features by removing (read \u201cabsence\u201d) different features. For example, if we have three features $(f_1,f_2,f_3)$, then the coalition $(f_1,f_3)$ is modeled as (1,0,1) and the output from a trained model (for explanation) is calculated as the characteristic function. Having all such coalitions would enable us to calculate the Shapley value, though the value is approximated in practice when we have many features (for the obvious computational burdens). \n \nThe main distinction of such an approach with that of the SVSVL is that the latter uses the multilinear extension of games, which transforms the discrete games (as in the presence or absence of a player/feature) into a continuous one. The multilinear extension G of game $\\mu$ is defined as ($\\mu$ is the characteristic function of a game):\n\n$$\nG(\\pmb x) = \\sum_{S \\subseteq F} \\mu(S) \\prod_{i \\in S} x_i \\prod_{j \\in F \\setminus S} (1 - x_j)\n$$\nThe multilinear extension has different interpretations; the probabilistic interpretation (where $x_i \\in [0,1]$) entails that each $x_i$ is the probability that $f_i$  joins the coalition. So, if we have $G([0.2, 0.8, 0.9])$ for three features $F = {f_1,f_2,f_3}$, it means that $f_1$  joins the coalition with a probability of 0.2, $f_2$ with a probability of 0.8, and $f_3$ with a probability of 0.9. Thus, $G(x)$ is deemed a generalization of the games where the players can join the coalition with a probability level. A more general interpretation of the multilinear games is developed in multi-choice games, where $x_i$ is not confined to [0,1] (see [1,2]). \n \nAlso, it is discussed and proved in Owen 1972 [3] that the Shapley value is a special case of the multilinear extension; in particular, they show that the integration of the derivative of G will lead us to the Shapley value (see Section 2 of the paper). So, computing the parameters of the multilinear extension can be used to compute Shapley value-like feature importance. \n\nThat being said, if we get to have binary x\u2019s, as we have for the presence or absence of a feature, then it is easy to prove that $G(x) = \\mu(x)$. For example, $G(1,0,1) = \\mu({f_1,f_3})$ . So, when constructing coalitions by presence and/or absence of features, G boils down to $\\mu$ as expected. \n\nThe challenge of such modeling, however, is that there are exponentially many $\\mu$ when using multilinear extension, as opposed to the linear regression approximation as in Kernel SHAP. \n\nWe have discussed the multilinear extension and the interpretation in Section 2, but we will improve the discussion further to incorporate its meaning when we have binary features (as we have typically in Shapley value-based explanation). \n \n[1] M. Jones et al., Multilinear extensions and values for multichoice games, Mathematical Methods of Operations Research, 2010.\n[2] Borkortoby et al., Fuzzy Bi-cooperative games in multilinear extension form, Fuzzy Sets and System, 2015.\n[3] Owen, Multilinear extension of games, Management Science, 1972.\n\n2. Independent Features \n\nWe distinguish the \u2018correlation\u2019 from \u2018interaction\u2019: the former indicates how one feature varies with another, while the latter involves the combined effect of two or more features on the target variable.  Given this clarification, it is true that the features for the synthesized experiments are not correlated, but the label y is generated based on the interactions of some features, e.g., $y = X1\\times X2\\times X3$. We generate such data sets in \u2018make_data.py\u2019 for different functions discussed in the experiment section, and the reason for such a choice is to highlight the influence of the interaction in generating explanations.\n\nAlso, the random forest can perform very well even when there is strong interaction among features - this is the inherent property of the decision trees. This is also highlighted in our synthesized experiment that includes feature selection with random forest, and the result is plotted in the top row of Figure 1. The code regarding the synthesized experiment is in synthesized_fs.py, which includes the experiment with the random forest as well."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3322/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700059856029,
                "cdate": 1700059856029,
                "tmdate": 1700059877605,
                "mdate": 1700059877605,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IO9LCYVrn2",
                "forum": "hGKda1uVEn",
                "replyto": "qDmHyZkQ1r",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3322/Reviewer_iYFx"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3322/Reviewer_iYFx"
                ],
                "content": {
                    "title": {
                        "value": "Re: Official Comment by Authors"
                    },
                    "comment": {
                        "value": "> 1. The relationship between set function and Polynomial Regression, and the presence and absence of a feature\n\nI understand that the Shapley value and the multilinear extension are related.\nMy point is not on Section 2 but on Section 3.\n\nIn Section 2, each $x$ is $\\\\{0, 1\\\\}$-valued representing the presence and absence, which is extended to real-valued $x \\in [0, 1]$ in multilinear extension.\nHere, even after the extension, $x = 0$ and $x = 1$ still mean that the feature is absent / eixstent.\n\nHowever, the multilinear feature mapping introduced in Section 3 considers the actual feature values.\nHere, $x = 0$ means that the feature takes the minimum value, and it does not mean that the feature is absent.\n\nThus, the paper mixes up the two different meanings of $x = 0$, one representing the feature absenece while the other representing that the actual feature value is minimum.\n\nMy question is what is the meaning of the multilinear extension (which is justified for $x$ representing absense / eixstense) when combined with the actual feature value."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3322/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700703005670,
                "cdate": 1700703005670,
                "tmdate": 1700703026843,
                "mdate": 1700703026843,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZEVO6lHGVU",
                "forum": "hGKda1uVEn",
                "replyto": "qDmHyZkQ1r",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3322/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3322/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the feedback. \n\nWe understand that the interpretation of SVSVL in terms of explanation and its relationship with the SHAP method (and similar approaches) is unclear. In what follows we try to shed light on this part by (1) Reviewing the Kernel Shapley additive explanation (Kernel SHAP) and its associated weighted linear regression; (2) Extending the additive explanation by multilinear models and its associated weighted regression; and Finally, (3) how support vector-based estimation can help us deal with the exponentially many parameters in the weighted linear regression in Step (2).\n\n1. Shapley Additive Explanation (SHAP) and associated weighted linear model\n\nThe Shapley value provides a solution concept to attribute the payout among the players in a coalitional game-theoretic setting. For SHAP, the 'payout' is the prediction of the model and the players are the features. In addition, a player can be an individual feature value, e.g. for tabular data. A player can also be a group of feature values. For example, to explain an image, pixels can be grouped to superpixels and the prediction distributed among them [1]. \n\nKernel SHAP takes the following steps to compute the attribution of each explainable feature, and shows that this attribution is the same as the Shapley value:\n\na) It generates sample coalition $z'_i \\in R^{d'}$ ($d'$ is the number of explainable features, e.g., the number of superpixels used to explain an image classifier)\n\nb) Get the prediction of the model under the explanation for the sample $z'_i, i=1,...,n'$; we need to map each sample $z'_i$ to the original space and then get the prediction from the trained model (this is shown in SHAP by h_x(z'_i) ). The prediction on sample z' could be computed based on the expected value with respect to the marginalized distribution.\n\nc) Compute the weight $\\omega_i$ for each $z_i$; $$ \\omega_i = \\frac{d' -1}{{d' \\choose |z'|} |z'| (d' - |z'|)}  $$\n\nwhere $|z'|$ is the number of features present in $z'$. \n\nd) The additive explanation assumes that the prediction (which plays the role of payout) should be distributed among the features as\n\n$ g(z'_i) = b  + \\Sigma _{j=1}^{d'} \\nu_j z_j$,\n\nwhere g() is the explainable model, b is the bias term, and $\\nu_j$ is the Shapley value of feature j.  The $\\nu_j$ is then estimated based on the following weighted linear model as:\n\n$$ \\min_{m, b} \\Sigma _{i=1}^{n'} \\omega_i  (y_i - (b + \\nu^Tz'_i) )^2 $$\n\nwhere $\\nu = [\\nu_1,...,\\nu_{d'}]$ are the Shapley value of $d'$ features.\n\n2. Multilinear Extension of Games\n\nInstread of using the additive model the associated linear regression, we use the multilinear model and a nonlinear regression. In particular, we assume that the explainable model g is as follows:\n\n$$ g(z') = b + \\Sigma_{S \\subset F, j = u(S)} m_j \\prod_{i \\in S} z'_i  = b + m^T \\phi _{ML}(z'_i) $$\n\nwhere we use function u to transform the subset into an index. The vector $\\phi _{ML}(z'_i) \\in$ {0,1}$^{2^{d'}-1}$ and we have one element for each subset of features. For example, assume we have three features and a coalition that the first and second features are present (i.e., z'=[1,1,0]), and by using $u$ function we have u({1,2}) = 4 and u({1,3}) = 5. Then according to the multlinear extension we have $\\phi _{ML}(z') = [1,1,0,1,0,0,0]$, where the first two elements are one because the two features are present, and the fourth element is the element that indicates both features 1 and 2 are present; in fact, the fourth element that corresponds to m({1,2})  in multilinear formulation, that could be written as m({1,2}) $z'_1z'_2$, and since $z'_1z'_2 =1$, we have the value of one in the fourth element. Similarly, the fifth element is zero because the corresponding term in the multilinear extension is m({1,3}) $z'_1z'_3$, and since $z'_1z'_3 = 0$, we have a zero element in the fifth element. \n\nGiven the multilinear model, the values $m_j$ could be estimated by the following linear regression (the other parameters like $\\omega$ is the same as the one presented above for additive explanation):\n\n$$ min_{\\nu} \\Sigma _{i=1}^{n'} \\omega_i  (y_i - (b + m^T\\phi _{ML}(z'_i)) )^2 $$\n\nwhere $m, \\phi _{ML}(z'_i) \\in R^{2^{d'}-1}$.  Using the multilinear extension would allow us to interpret the coefficients $m$ in the above regression as the Mobius transformation of $\\mu$ in the Shapley value formulation, which allows us to compute the Shaple value accordingly. \n\n[1] Molnar, Christoph. Interpretable machine learning. Lulu. com, 2020."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3322/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700739517082,
                "cdate": 1700739517082,
                "tmdate": 1700740633176,
                "mdate": 1700740633176,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "o0i5KJKoUI",
                "forum": "hGKda1uVEn",
                "replyto": "qDmHyZkQ1r",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3322/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3322/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Minor correction"
                    },
                    "comment": {
                        "value": "3. Support Vector-based estimation of $m$:\n\nThe main challenge in computing the coefficient $m$ in the above formulation is that we have exponentially many parameters. We address this by using the support vector regression and its dual formulation, and computing the Shapley value directly from the dual SVM solution. \n\nThe two steps above are briefly explained in Appendix B, and the third step (SVR formulation) is discussed in detail. Upon the acceptance of the paper, we explain the first two steps more clearly. \n\nMinor correction 1: In Section 2, we did not assume that x is binary and we explicitly mentioned that it is continuous! For binary x, the multilinear extension of games converges to the conventional definition of games. \n\nMinor correction 2: The linear regression used in the SHAP also uses the binary features, but the multiplication of the binary features with the coefficient results in the sum of the attribution of the features in the coalition. For example, if $z'=[1,1,0]$, then $z'^T\\nu = \\nu_1 + \\nu_2$, which means that the prediction (or payout) should be distributed among the first two features. We use the same notion in our regression problem, with a major difference of having a coefficient for each subset of features (as in the example discussed in Step (2) above).\n\n[1] Molnar, Christoph. Interpretable machine learning. Lulu. com, 2020."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3322/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700739894014,
                "cdate": 1700739894014,
                "tmdate": 1700740512209,
                "mdate": 1700740512209,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zb6WeVJ6ek",
            "forum": "hGKda1uVEn",
            "replyto": "hGKda1uVEn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3322/Reviewer_gc9E"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3322/Reviewer_gc9E"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduced a SVM-based method for parameter estimation, and dynamic programing used to compute the shapley value in an efficient way."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Propose to use SVM to mitigate the inefficiency problem of Shapley values, so that the dynamic programming can be used. This solution is novel.\n2. The complexity of the method only relies on data samples."
                },
                "weaknesses": {
                    "value": "1 the advantage of the proposed method is not well presented in this paper, I am not convinced by the effectiveness and efficiency of this method even I have very carefully gone through the related works, introduction, and experimental sections. \n2. I strongly encourage the authors to visualize the high-order feature interactions. To see how the methods capture effective feature interactions. \n3. Based on the results in section 5.2, it's hard to justify the effectiveness of SVSVL. Maybe the author can show the capability to capture feature interactions."
                },
                "questions": {
                    "value": "1. In fig 2, it looks like most of the methods except Shapley taylor perform similarly. Why the time are not changed with the number of features? How does your method perform better than theirs?\n\n2. Understand that the complexity only relies on the number of samples rather than the number of features. Is it a good property? Generally, the number of data samples is much larger than the number of features, right?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N.A"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3322/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3322/Reviewer_gc9E",
                        "ICLR.cc/2024/Conference/Submission3322/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3322/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698918427496,
            "cdate": 1698918427496,
            "tmdate": 1700740975687,
            "mdate": 1700740975687,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4U20FPTKAd",
                "forum": "hGKda1uVEn",
                "replyto": "zb6WeVJ6ek",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3322/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3322/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate the reviewer for providing us with feedback. In the following, we respond to the raised concerns point by point.\n\n1. The advantage of the method\n\nThanks for the comment. Except for the related work section \u2013 which we devoted entirely to the studies related to our method -  we highlighted the research gap we tried to address, and the advantage of the proposed method based on support vector machine and dynamic programming - See Introduction - Paragraph 2 & 3, Section 3, and the beginning of Section 5. However, we would like to further improve the paper in this respect, if you could kindly point out where you think requires more emphasis on the research gap and the novelty of the proposed method.\n \n2. Visualizing higher-order feature interactions\n\nThanks for the suggestion. We admit that it is important to visualize higher-order feature interaction. We do have plots in the appendix highlighting the interactions among features.  In addition, we will add in the final version of the manuscript some multi-level bar charts, each level of which corresponds to the contribution of an order of interaction to the computed Shapley value of a feature.\n \n3. The advantage of SVSVL - Section 5.2\n\nThe advantage of the SVSVL compared to other methods is that it can account for higher-order feature interactions, while the execution time remains the same. We admit that plotting the higher-order feature interactions would give a better intuition of the advantages of the method (we already put some plots in the appendices, but these could be further improved). In essence, keeping the time complexity in order while higher order of interactions are accounted for is the main advantage of the SVSVL. In addition to that, the MSE of SVSVL is lower than other methods, since it uses a nonlinear (yet explainable) model as a local explainer, while other methods like LIME and SHAP use a linear model and have higher MSE as a result (compared to SVSVL).\n \n4. Advantage of SVSVL - Figure 2\n\nThe main point we want to get across by Figure 2 is that the proposed method has very competitive time complexity compared to other additive, linear methods (like SHAP), and is far superior compared to methods that account for higher-order interactions (e.g., Shapley-Taylor and Faith-SHAP). We further improve the figure by plotting the log scale of the execution time (to better compare different methods) and adding datasets with more features (knowing that Shapley-Taylor and Faith-SHAP would not be able to produce results in a reasonable time).\n \n5. Reliance on the number of samples\n\nThe computation of the Shapley value requires an exponential number of parameters in the number of features - the size of the power set of features. So, the improvement we get by using SVSVL is from O(2^d) and O(n3), when d and n are the number of features and samples, respectively. In other words, the fair comparison must be between 2^d and n3.\n \nThat being said, it is true that having a large number of samples makes the SVM training quite expensive. This is indeed an old, known problem of kernel methods like SVM and there are some solutions to it, e.g., approximation methods like Nystroem [1]. We will discuss this point further in the Conclusion and Discussion section.\n \n[1] C. Williams & M Seeger, Using the Nystr\u00f6m Method to Speed Up Kernel Machines, NIPS 2000."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3322/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700058482419,
                "cdate": 1700058482419,
                "tmdate": 1700058512249,
                "mdate": 1700058512249,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Rww3H4OD80",
                "forum": "hGKda1uVEn",
                "replyto": "4U20FPTKAd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3322/Reviewer_gc9E"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3322/Reviewer_gc9E"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the detailed reply, I will slightly adjust my score."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3322/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740674830,
                "cdate": 1700740674830,
                "tmdate": 1700740674830,
                "mdate": 1700740674830,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "SIJwvRbqnT",
            "forum": "hGKda1uVEn",
            "replyto": "hGKda1uVEn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3322/Reviewer_NKAm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3322/Reviewer_NKAm"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an efficient way of computing Shapley value (SV), which is notorious for its combinatorially expensive computational cost. The authors first refer to a known result that the inclusion and exclusion of the variables in SV can be represented as a Mobius transform of a multi-linear form.  \n \nGuided by the formal similarity between the multi-linear form and the ANOVA kernel function, the authors propose to use the dual formulation of SVM to compute SV. Thanks to the duality, the dimensionality of the problem is now the number of samples rather than the size of the power set.\n\n The authors provide theoretical proof of the above conversion and perform comparative empirical studies with alternative attribution methods.\n \nNote: my review is tentative. It may be changed after the discussion period."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- Introduced a very innovative view to the SV.\n- Provides formal proofs."
                },
                "weaknesses": {
                    "value": "- The description tends to jump directly into the conclusion without showing any intuition.\n- The biggest limitation can be that the paper does not provide a direct comparison with the exact SV definition despite the fact that the derived SVM formulation is an approximation, as stated as \"the method has its limitations, including its inability to account for higher moments of features\"."
                },
                "questions": {
                    "value": "- Is the proposed method exact? I mean, does it yield an equivalent attribution value to that from the original definition? \n- Please elaborate on what you mean by not being able to account for r higher moments of features, which suggests approximation. \n- If it is not exact, direct comparison with the exact definition is mandatory. Did you present such a result in this paper?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3322/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3322/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3322/Reviewer_NKAm"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3322/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699093857908,
            "cdate": 1699093857908,
            "tmdate": 1700762676893,
            "mdate": 1700762676893,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "p7rKvGptAF",
                "forum": "hGKda1uVEn",
                "replyto": "SIJwvRbqnT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3322/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3322/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate the reviewer for providing us with feedback. In the following, we respond to the raised concerns point by point.\n\n1. The intuition behind the method\n\nThe intuition behind the proposed multilinear model is straightforward: If we divide the interaction effect equally among the features involved, the sum of such effects would be tantamount to the Shapley value. For example, if we have two features {1,2}, and we compute m_1, m_2, m_12 as the direct and interaction effects of the two features by, say, linear regression, then the Shapley values of the features are v_1 = m_1 + 0.5 m_12, and v_2 = m_2 + 0.5 m_12 (here m_12 is divided equally between the two features).\nTo justify that such a calculation would result in the Shapley value, we provided two theoretical justifications, one based on the multilinear extension and the other based on Harsanyi\u2019s dividends. We explained such an intuition after Definition 1, but if need be, we will clarify this point further in the final version of the manuscript.\n \n2. Direct comparison with the exact SV\n\nThe exact SV in the explainability context means that we calculate the output of the model for each subset of features, and this output plays the role of a characteristic function to compute the Shapley value. For datasets with many features, computing such a function for all subsets of features is computationally expensive, so it is typically estimated by a linear regression model, as in Kernel SHAP for instance.\nWe already compared the SVSVL (which is not an exact method) with the Kernel SHAP, but not with the exact method due to the computational burden. A feasible way of comparison to the exact method would be on datasets with a small number of features. We found it more interesting to compare the approximate methods on datasets with larger amounts of features, than using the exact method on too simple datasets. Nonetheless, if need be, we can include further experiments on comparing the SVSVL with the exact methods.\n \n3. Higher moments of features\n\nThe multilinear model, which means the model is linear in each individual feature, cannot account for higher moments of features. For instance, for feature x, there is no inclusion of x^2, x^3,\u2026. Such moments of features are important for learning, but it is not straightforward to include them in the Shapley value or interaction indices calculation, as we require a new set of axioms and a new Shapley-like function for taking into account higher-order moments. We will mention this as a limitation of the proposed method and a venue for future research."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3322/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700058157530,
                "cdate": 1700058157530,
                "tmdate": 1700470300220,
                "mdate": 1700470300220,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xWfRUgFNhM",
                "forum": "hGKda1uVEn",
                "replyto": "p7rKvGptAF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3322/Reviewer_NKAm"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3322/Reviewer_NKAm"
                ],
                "content": {
                    "title": {
                        "value": "In case of Conditional Expectations Shapley?"
                    },
                    "comment": {
                        "value": "I'm still not very clear about your thought process showing the equivalence. To be specific, let's use a specific definition of SV based on the expected value with respect to the marginalized distributions (or Conditional Expectations Shapley), which has been adopted in many existing works such as \n- Molnar, Christoph. Interpretable machine learning. Lulu. com, 2020.\n- Sundararajan, Mukund, and Amir Najmi. \"The many Shapley values for model explanation.\" International conference on machine learning. PMLR, 2020.\n\nIn this case, how would you apply your argument in terms of equivalence?"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3322/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700671136270,
                "cdate": 1700671136270,
                "tmdate": 1700671136270,
                "mdate": 1700671136270,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IFYU824zSn",
                "forum": "hGKda1uVEn",
                "replyto": "SIJwvRbqnT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3322/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3322/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the feedback. \n\nWe understand that the interpretation of SVSVL in terms of explanation and its relationship with the SHAP method (and similar approaches) is unclear. In what follows we try to shed light on this part by (1) Reviewing the Kernel Shapley additive explanation (Kernel SHAP) and its associated weighted linear regression; (2) Extending the additive explanation by multilinear models and its associated weighted regression; and Finally, (3) how support vector-based estimation can help us deal with the exponentially many parameters in the weighted linear regression in Step (2).\n\n1. Shapley Additive Explanation (SHAP) and associated weighted linear model\n\nThe Shapley value provides a solution concept to attribute the payout among the players in a coalitional game-theoretic setting. For SHAP, the 'payout' is the prediction of the model and the players are the features. In addition, a player can be an individual feature value, e.g. for tabular data. A player can also be a group of feature values. For example, to explain an image, pixels can be grouped to superpixels and the prediction distributed among them [1]. \n\nKernel SHAP takes the following steps to compute the attribution of each explainable feature, and shows that this attribution is the same as the Shapley value:\n\na) It generates sample coalition $z'_i \\in R^{d'}$ ($d'$ is the number of explainable features, e.g., the number of superpixels used to explain an image classifier)\n\nb) Get the prediction of the model under the explanation for the sample $z'_i, i=1,...,n'$; we need to map each sample $z'_i$ to the original space and then get the prediction from the trained model (this is shown in SHAP by h_x(z'_i) ). The prediction on sample z' could be computed based on the expected value with respect to the marginalized distribution (as you mentioned) - see equation 9 in [2].\n\nc) Compute the weight $\\omega_i$ for each $z_i$; $$ \\omega_i = \\frac{d' -1}{{d' \\choose |z'|} |z'| (d' - |z'|)}  $$\n\nwhere $|z'|$ is the number of features present in $z'$. \n\nd) The additive explanation assumes that the prediction (which plays the role of payout) should be distributed among the features as\n\n$ g(z'_i) = b  + \\Sigma _{j=1}^{d'} \\nu_j z_j$,\n\nwhere g() is the explainable model, b is the bias term, and $\\nu_j$ is the Shapley value of feature j.  The $\\nu_j$ is then estimated based on the following weighted linear model as:\n\n$$ \\min_{m, b} \\Sigma _{i=1}^{n'} \\omega_i  (y_i - (b + \\nu^Tz'_i) )^2 $$\n\nwhere $\\nu = [\\nu_1,...,\\nu_{d'}]$ are the Shapley value of $d'$ features.\n\n2. Multilinear Extension of Games\n\nInstread of using the additive model the associated linear regression, we use the multilinear model and a nonlinear regression. In particular, we assume that the explainable model g is as follows:\n\n$$ g(z') = b + \\Sigma_{S \\subset F, j = u(S)} m_j \\prod_{i \\in S} z'_i  = b + m^T \\phi _{ML}(z'_i) $$\n\nwhere we use function u to transform the subset into an index. The vector $\\phi _{ML}(z'_i) \\in$ {0,1}$^{2^{d'}-1}$ and we have one element for each subset of features. For example, assume we have three features and a coalition that the first and second features are present (i.e., z'=[1,1,0]), and by using $u$ function we have u({1,2}) = 4 and u({1,3}) = 5. Then according to the multlinear extension we have $\\phi _{ML}(z') = [1,1,0,1,0,0,0]$, where the first two elements are one because the two features are present, and the fourth element is the element that indicates both features 1 and 2 are present; in fact, the fourth element that corresponds to m({1,2})  in multilinear formulation, that could be written as m({1,2}) $z'_1z'_2$, and since $z'_1z'_2 =1$, we have the value of one in the fourth element. Similarly, the fifth element is zero because the corresponding term in the multilinear extension is m({1,3}) $z'_1z'_3$, and since $z'_1z'_3 = 0$, we have a zero element in the fifth element. \n\nGiven the multilinear model, the values $m_j$ could be estimated by the following linear regression (the other parameters like $\\omega$ is the same as the one presented above for additive explanation):\n\n$$ min_{\\nu} \\Sigma _{i=1}^{n'} \\omega_i  (y_i - (b + m^T\\phi _{ML}(z'_i)) )^2 $$\n\nwhere $m, \\phi _{ML}(z'_i) \\in R^{2^{d'}-1}$.  Using the multilinear extension would allow us to interpret the coefficients $m$ in the above regression as the Mobius transformation of $\\mu$ in the Shapley value formulation, which allows us to compute the Shaple value accordingly. \n\n[1] Molnar, Christoph. Interpretable machine learning. Lulu. com, 2020.\n\n[2] Lundberg and Lee, A Unified Approach to Interpreting Model Predictions, NeurIPS, 2017"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3322/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700739467038,
                "cdate": 1700739467038,
                "tmdate": 1700741192266,
                "mdate": 1700741192266,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]