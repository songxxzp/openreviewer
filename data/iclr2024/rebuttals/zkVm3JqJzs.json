[
    {
        "title": "Conformal Prediction for Deep Classifier via Label Ranking"
    },
    {
        "review": {
            "id": "fYc9hm7pkm",
            "forum": "zkVm3JqJzs",
            "replyto": "zkVm3JqJzs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6778/Reviewer_SVnn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6778/Reviewer_SVnn"
            ],
            "content": {
                "summary": {
                    "value": "This paper mainly proposes a new nonconformity score for classification task. It first identifies that the probability in APS is not that important and the rank instead is important - a rank-based version of the APS nonconformity score makes more efficient prediction sets, the size of which is also more correlated with accuracy. Then, it proposes a new nonconformity score that only keeps the top predicted probability but uses ranks for the remaining classes, and shows in the experiments that such score typically improves efficiency."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This is a well-motivated paper that is very easy to follow. The observation that ranking matters more than the predicted probability (or softmax output) is very interesting (and I'm surprised that it has not been discovered before). The proposed solution also makes sense. Proposition 2 about dominance is a good theoretical result on top of the finite-sample coverage."
                },
                "weaknesses": {
                    "value": "This requires choosing a hyperparameter $\\lambda$, which requires additional data and could affect efficiency in practice."
                },
                "questions": {
                    "value": "In the experiments, choosing $\\lambda$ for SAPS uses a subset of the calibration set. Do all baselines uses the (same) remaining calibration set? That is, is SAPS calibrated on a smaller set due to $\\lambda$?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6778/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6778/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6778/Reviewer_SVnn"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6778/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698354128322,
            "cdate": 1698354128322,
            "tmdate": 1699636782346,
            "mdate": 1699636782346,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "RJfwTgx70k",
                "forum": "zkVm3JqJzs",
                "replyto": "fYc9hm7pkm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6778/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6778/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer SVnn"
                    },
                    "comment": {
                        "value": "Thank you for the recognition. We address specific concerns below.\n\n\n**1. Choice of $\\lambda$.  [Q1]**\n\nFor SAPS and RAPS, we utilize a validation set to tune hyperparameters and the remaining dataset to calibrate the $\\tau$. For APS, we calibrate the threshold $\\tau$ on the whole calibration set."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6778/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700404337542,
                "cdate": 1700404337542,
                "tmdate": 1700404337542,
                "mdate": 1700404337542,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "uFU1xCjTX8",
            "forum": "zkVm3JqJzs",
            "replyto": "zkVm3JqJzs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6778/Reviewer_poFk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6778/Reviewer_poFk"
            ],
            "content": {
                "summary": {
                    "value": "Using all softmax probabilities in the non-conformity score may yield larger prediction sets. Out of this consideration, the authors proposed a method called sorted adaptive prediction sets (SAPS), which discards all the probability values except the maximum softmax probability."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The authors empirically showed that using all probabilities is not necessary in APS.\n* The authors empirically showed that, under different network architectures, the proposed method returns more efficient prediction sets compared to APS and RAPS on three datasets."
                },
                "weaknesses": {
                    "value": "* I have a reservation about the claimed contribution of higher adaption, i.e., the adaption is not that convincing: For the example of Figure 3(b), now that both SAPS and RAPS achieve the same coverage, why should we require a larger prediction set for difficult observations? In general, the smaller the better. RAPS gives more efficient predictions on those observations with higher difficulty, while the proposed SAPS only gives efficient predictions on a shorter interval of difficulty.\n\n* Even though the proposed method has a promising performance compared to several methods, how is the proposed method far away from the ground truth? \n\n* To make it clearly catch the whole scope, it would be better to explicitly outline the calibration and prediction under the frame of a pseudo-algorithm as the one in RAPS. For example, I believe \"We choose the hyper-parameter that achieves the smallest set size on a validation set\" fails to disclose the entire picture because the smallest set size on a validation set cannot secure the desired coverage. How did the authors handle this issue?\n\n* The proofs are not friendly reading (see the section on questions).\n\n* Minor issues:\n  * Do you mean $\\mathcal{C}(\\boldsymbol x_i, y_i, u_i)$ for the definition of coverage rate?\n  * Double-check all the usage of \"i.e.,\"\n  * 0.05 instead of 0.5 in Section 4.2.\n  * In the proof of Lemma 1, did you intend to assume $p_{(k)}\\geq \\frac{1}{k}$? Where will be $\\tilde{k}$ used in the proof?"
                },
                "questions": {
                    "value": "* Is (2) generally correct? In other words, are the prediction results always nested? Particularly in Theorem 2, Since there is a random variable $u$ introduced, why $\\mathcal{C}_{1-\\alpha}(\\boldsymbol{x}, u)$ have the nesting property? \n* Proposition 1: How is $\\mathcal{C}_{1-\\alpha}(\\boldsymbol x, u)$ defined as in Eq. 3? They have totally different notations.\n* I didn\u2019t get the point of the proof for Proposition 1. What is the difference between your proof of proposition 1 and Theorem 2? The conclusion of coverage is for the popped $\\mathcal{C}(\\boldsymbol x_{n+1},u_{n+1})$ but there is no $\\mathcal{C}(\\boldsymbol x_{n+1},u_{n+1})$ during your proof. I think the authors need to well-articulate the proof.\n* Why $\\frac{1}{\\lambda}\\leq1-\\frac{1}{K}$ but previously you require $\\lambda>1-\\frac{1}{K}$?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No."
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6778/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698422026301,
            "cdate": 1698422026301,
            "tmdate": 1699636782226,
            "mdate": 1699636782226,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7vwQfrBfqM",
                "forum": "zkVm3JqJzs",
                "replyto": "uFU1xCjTX8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6778/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6778/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer poFk"
                    },
                    "comment": {
                        "value": "Thanks for your recognition and the valuable suggestions. We give a detailed response to your questions and comments in the following. \n\n\n**1. Adaption of sets.[W1]**\n\nIn the literature of conformal prediction, the size of prediction sets is expected to represent the inherent uncertainty of the classifier's predictions. With a comparable set size, methods with high adaption can reflect instance-wise uncertainty precisely [R1]. Specifically, prediction sets should be larger for hard examples than for easy ones. Adaption is particularly significant in high-stakes scenarios where assessing the model's reliability is necessary. In Figure 3b, we show SAPS preserves more distinguishable information than RAPS, while achieving a smaller average set size and desired coverage rate. This advantage further strengthens the value of the proposed method.\n\n\n\n**2. Gap between SAPS and ground truth [W2]**\n\nWe guess that the \"ground truth\" is the sets produced by APS with the oracle model (correct us if we are mistaken). In Proposition 2, we provide a theoretical result, suggesting that SAPS is capable of producing smaller sets than APS, with the oracle model.\n\n\n**3. The desired coverage [W3]**\n\nThank you for the great suggestion. We have included pseudo-code algorithms in Appendix H of the revised manuscript. \n\nFor the validation set, we would like to clarify that various score functions caused by different values of $\\lambda$ always satisfy the desired coverage. In other words, the value of $\\lambda$ does not affect the coverage guarantee, which is theoretically proved by Proposition 1. This is also supported by the empirical results in Sec 4.2.\n\n\n**4. Minor issues [W4,W5,Q3,Q4]**\n\nWe thanks for pointing out the typos. We have fixed them in the updated version. \n- $\\mathcal{C}\\left(\\boldsymbol{x}\\_{i},y_i,u_i\\right)$ is a typo. In Section 4.1, we revised $\\mathcal{C}\\left(\\boldsymbol{x}\\_{i},y_i,u_i\\right)$ to $\\mathcal{C}\\left(\\boldsymbol{x}\\_{i}\\right)$ representing the  prediction set for $\\boldsymbol{x}\\_{i}$.  \n- In the proof of Lemma 1, we assume that $p_{(k)}>\\frac{1}{k}$ for any $k\\geq 2$. Thus,  for any $\\tilde{k}< k$, it holds that $p_{(\\tilde{k})}>\\frac{1}{k}$.\n- In Proposition 1, the subscript of symbol $\\mathcal{C}\\_{1-\\alpha}(\\boldsymbol{x}\\_{n+1},u\\_{n+1})$  hase been completed. \n- In proof of Proposition 2, the inequality is the $\\frac{1}{\\lambda} \\leq \\frac{1}{1-\\frac{1}{K}}$.\n\n**5. Definition of prediction set in Proposition 1 [Q2]** \n\nThank you for pointing out the ambiguous notation. The prediction set in Proposition 1 is defined as  $$\\mathcal{C}_{1-\\alpha}(\\boldsymbol{x},u) =\\lbrace y\\in\\mathcal{Y} : S(\\boldsymbol{x},y,u;\\hat{\\pi})\\leq \\tau \\rbrace.$$ Thus, it is mathematically equivalent to Eq. 3. To mitigate this confusion, we added a detailed description in Proposition 1.\n\n**6. The nest property [Q1]** \n\nThe nesting property defined by Eq.2 is a common property holding on all prediction sets for any conformal predictor [R2]. Specifically, if a lower error rate is expected, the set will have a larger size for higher coverage. In this work, since the calibrated threshold $\\tau$ is the $1-\\alpha$ quantile of scores, the nesting property of $\\alpha$ is equivalent to a nesting property for $\\tau$, i.e., $$\\alpha_1>\\alpha_2 \\rightarrow \\tau_1\\leq\\tau_2 \\rightarrow \\lbrace y\\in\\mathcal{Y}: S(\\boldsymbol{x},y,u;\\hat{\\pi})\\leq \\tau_1 \\rbrace \\subseteq \\lbrace y\\in\\mathcal{Y}: S(\\boldsymbol{x},y,u;\\hat{\\pi})\\leq \\tau_2\\rbrace,$$ for a test point $\\boldsymbol{x}$ and a random variable $u$. Therefore, we get the nesting property of $\\mathcal{C}_{1-\\alpha}(\\boldsymbol{x},u)$. \n\n\n**7. Difference between proposition 1 and Theorem 2  [Q3]**\n\nProposition 1 is a corollary of Theorem 2. Specifically, Theorem 2 gives a coverage guarantee for CP methods whose prediction set has a general formulation $\\mathcal{C}(\\boldsymbol{x},u,\\tau)$. The prediction set of SAPS defined as $\\lbrace y\\in\\mathcal{Y}:S(\\boldsymbol{x},y,u;\\hat{\\pi})\\leq \\tau \\rbrace$ is a specific instance of $\\mathcal{C}(\\boldsymbol{x},u,\\tau)$. Therefore, Proposition 1 offers a coverage guarantee for SAPS. We apologize for this misunderstanding and have revised  Appendix B to make this clearer.\n\n[R1] Anastasios Nikolas Angelopoulos, Stephen Bates, Michael I. Jordan, and Jitendra Malik. Uncertainty sets for image classifiers using conformal prediction. In 9th International Conference on Learning Representations\n\n[R2] Balasubramanian, V., Ho, S.-S., and Vovk, V. (2014). Conformal prediction for reliable machine learning: theory, adaptations and applications."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6778/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700404309974,
                "cdate": 1700404309974,
                "tmdate": 1700489516785,
                "mdate": 1700489516785,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ELcYDYjtEO",
                "forum": "zkVm3JqJzs",
                "replyto": "uFU1xCjTX8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6778/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6778/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Sincerely expect your further comments"
                    },
                    "comment": {
                        "value": "Dear reviewer poFK,\n   \nSorry to disturb you. We sincerely appreciate your valuable comments. We would like to further provide brief answers here to the issues that might be your primary concerns.\n\t\nWe really appreciate your efforts in identifying the typos and ambiguous descriptions, as well as providing valuable suggestions for method descriptions. In response to your feedback, we have carefully revised the typos and enhanced the clarity of our descriptions. We have provided a specific description of the technique details of our proposed method in Appendix H.\n\nWe guess that you may have concerns about adaption. With a comparable set size, methods with high adaption can discriminately reflect instance-wise uncertainty. In particular, the results show that our method preserves more distinguishable information than RAPS, while achieving a smaller average set size and desired coverage rate. \n\t\nIn addition, we would like to clarify that various score functions caused by different values of $\\lambda$ always satisfy the desired coverage. This concern can be resolved by Proposition 1 and verified by empirical results.\n\nWe sincerely hope that the above answers can address your concerns. We look forward to your response and are willing to answer any questions.\n\nThank you"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6778/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700628793283,
                "cdate": 1700628793283,
                "tmdate": 1700628793283,
                "mdate": 1700628793283,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7JhEN78j1V",
            "forum": "zkVm3JqJzs",
            "replyto": "zkVm3JqJzs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6778/Reviewer_xE2a"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6778/Reviewer_xE2a"
            ],
            "content": {
                "summary": {
                    "value": "Conformal prediction is a widely used framework, which can outputs a confidence set with statistical guarantee. A crucial aspect of this framework is the choice of non-conformity measure. The authors modify the Adaptive Prediction Set (APS) and propose a novel non-conformity measure called Sorted Adaptive Prediction Set (SAPS). The authors theoretically demonstrate that this non-conformity measure maintains finite-sample marginal coverage and dominates APS in terms of prediction set size in some special cases. Empirically, they show the superiority of the proposed method over APS and RAPS across different datasets"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The authors propose a novel non-conformity measure in classification problem, and theoretically show it always dominates APS in the size of prediction sets if $\\hat{\\pi} = \\pi$.\n2. The authors conduct the experiments on three different datasets. They propose a novel metric ESCV to evaluate the performance of methods."
                },
                "weaknesses": {
                    "value": "1. The theoretical contribution of this paper seems limited. Proposition 1 represents a common property of any non-conformity measure. Moreover, the condition in Proposition 2, $\\hat{\\pi} = \\pi$, is challenging to satisfy in practice. As for another condition  $\\lambda \\geq 1 - \\frac{1}{K}$, note that $\\lambda$ used in experiments is searched in the range of 0.001 to 0.5, which conflicts with this condition. Figure 4a shows that when $\\lambda$ exceeds 0.2, the set size increases with $\\lambda$. It is important to address these concerns.\n2. In Equation (8), it is unclear why the authors use 2 instead of another constant in $o(y,\\hat{\\pi}(x)) - 2 + u$. The authors should provide a motivation and explanation for this choice.\n3. The authors only provide theoretical analysis comparing APS and SAPS, and empirical comparisons between RAPS and SAPS. It is necessary to include a detailed comparison with RAPS theoretically, since it is also a modified version of APS."
                },
                "questions": {
                    "value": "Please see the Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6778/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698670338581,
            "cdate": 1698670338581,
            "tmdate": 1699636782113,
            "mdate": 1699636782113,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Aomk6Z9LDW",
                "forum": "zkVm3JqJzs",
                "replyto": "7JhEN78j1V",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6778/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6778/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer xE2a (1/2)"
                    },
                    "comment": {
                        "value": "Thank you for the valuable comments and detailed feedback on our manuscript. Please find our response below.\n\n**1. Proposition 1 represents a common property [W1]**\n\nYes, many existing works have shown their methods possess the property [R1, R2] while some works do not provide theoretical proofs [R3, R4]. In this work, we present the proposition to show that the proposed method also satisfies the finite-sample coverage guarantee from a theoretical perspective. Without the proposition, it becomes ambiguous if our method can obtain the theoretical property. In other words, Proposition 1 enhances the completeness of our work.\n\n\n**2. Calibrated condition of Proposition 2**\n\nIn the literature of conformal prediction, it is a common assumption that the given model is well-calibrated in theoretical analysis [R5, R6, R7]. Based on the assumption, we can then provide the subsequent analysis to show the inherent advantages of SAPS compared to APS. On the contrary, it would be non-trivial to give an in-depth understanding of the proposed method, without the condition. Thus, the theoretical explanation is still valuable to the community. In addition, the empirical results in Section 4 demonstrate the effectiveness of our method with imperfect models.\n\n\n**3. The range of $\\lambda$ in Proposition 2**\n\nWe would like to clarify that the range of 0.001 to 0.5 is for the hyperparameter of RAPS, instead of our method. We tune the $\\lambda$ of SAPS in the range of 0.02 to 0.6. Moreover, the threshold of $\\lambda$ in Proposition 2 is a sufficient condition to show the advantage of SAPS, but it does not reflect that the optimal value of $\\lambda$ must exist in the interval $[1-\\frac{1}{K},\\infty)$ in the experiments.\n\nHere, we conduct an experiment to validate the effectiveness of SAPS with a $\\lambda$ in the interval $[1-\\frac{1}{K},\\infty)$. In particular, we set $\\lambda = 1$. The results on three datasets are shown in the table below. We show that SAPS with $\\lambda=1$ still outperforms APS, which validates the proposition.\n\n|  Method   | APS  |  SAPS($\\lambda=1$) |\n|  :----:  | :----:  | :----:  |\n| ImageNet  | 20.95 | 3.82     |\n| CIFAR-100  | 7.88 | 3.35    |\n| CIFAR-10  | 1.97 | 1.80   |\n\nFinally, we would like to clarify that the set size of SAPS would not maintain the upward trend with the increase of $\\lambda$. Instead, the set size will converge to a specific value, and SAPS is equivalent to the APS without probability value when $\\lambda \\to \\infty$. To demonstrate this, we update Figure 4a in the revised version by extending the value of $\\lambda$ and the updated figure validates the above statement. \n\n \n**4. Clarification of proposed score function [W2]**\n\nThe constant $2$ in Eq. (8) is not a user-guided value. The term $(o(y,\\hat{\\pi}(\\boldsymbol{x}))-2+u)$ contains ranking scores from rank $2$ to rank $(o(y,\\hat{\\pi}(\\boldsymbol{x}))-1)$, and a random ranking score at the rank $o(y,\\hat{\\pi}(\\boldsymbol{x}))$. As the ranking score is defined as a constant $\\lambda$, the sum of ranking scores from rank $2$ to rank $(o(y,\\hat{\\pi}(\\boldsymbol{x}))-1)$ is $(o(y,\\hat{\\pi}(\\boldsymbol{x}))-2) \\cdot \\lambda$. Thus, the formulation of the proposed score function is defined as $\\hat{\\pi}_{max} (\\boldsymbol{x}) + (o(y,\\hat{\\pi}(\\boldsymbol{x}))-2) \\cdot \\lambda$+ $u\\cdot \\lambda$.\n\n[R1] Anastasios Nikolas Angelopoulos, et al. Uncertainty sets for image classifiers using conformal prediction. In 9th International Conference on Learning Representations, ICLR 2021\n\n[R2] Charles Lu, et al. Federated conformal predictors for distributed uncertainty quantification. International Conference on Machine Learning, ICML 2023\n\n[R3] Subhankar Ghosh, et al. Improving uncertainty quantification of deep classifiers via neighborhood conformal prediction: Novel algorithm and theoretical analysis. AAAI 2023\n\n[R4] Henrik Linusson, et al. Classification with reject option using conformal prediction. PAKDD 2018\n\n[R5] Bat-Sheva Einbinder, et al. Training uncertainty-aware classifiers with conformalized deep learning. Advances in Neural Information Processing Systems, 2022b\n\n[R6] Aleksandr Podkopaev, et al. Distribution-free uncertainty quantification for classification under label shift. In Uncertainty in Artificial Intelligence\n\n[R7] Bat-Sheva Einbinder, et al. Conformal prediction is robust to label noise. arXiv preprint arXiv:2209.14295, 2022a"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6778/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700404078628,
                "cdate": 1700404078628,
                "tmdate": 1700404199406,
                "mdate": 1700404199406,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sW767c4NPr",
                "forum": "zkVm3JqJzs",
                "replyto": "7JhEN78j1V",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6778/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6778/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer xE2a (2/2)"
                    },
                    "comment": {
                        "value": "**5. Theoretical comparison with RAPS [W3]**\n\nIn this work, we aim to provide an in-depth understanding of SAPS through the comparison of APS and RAPS. While there might be some new insights in the comparison between SAPS and RAPS, it is challenging to analyze these two methods in a unified framework, as RAPS introduces two hyper-parameters. Instead, we empirically show the superiority of SAPS over RAPS in set size, conditional coverage violation, and adaptation. Furthermore, we compare SAPS with RAPS($k_r=1$) in Sec 5 to further demonstrate the negative effect of probability values. We believe the thorough analysis of RAPS is sufficient to support our conclusion."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6778/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700404150702,
                "cdate": 1700404150702,
                "tmdate": 1700488163402,
                "mdate": 1700488163402,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qicR0nOQs3",
                "forum": "zkVm3JqJzs",
                "replyto": "7JhEN78j1V",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6778/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6778/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Sincerely expect your further comments"
                    },
                    "comment": {
                        "value": "Dear Reviewer xE2a,\n\nSorry to disturb you. We appreciate that you have pointed out some concerns. We believe that we have addressed all your concerns and clarified the misunderstanding part. Would you please kindly check that and consider re-evaluating our work? Please let us know if you have any further concerns and we are open to all possible discussions. \n\nThank you"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6778/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700628704624,
                "cdate": 1700628704624,
                "tmdate": 1700628704624,
                "mdate": 1700628704624,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "whqt7vpIBl",
            "forum": "zkVm3JqJzs",
            "replyto": "zkVm3JqJzs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6778/Reviewer_JXhd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6778/Reviewer_JXhd"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies conformal prediction as applied to classification problems. It shows that one can significantly reduce the size of the set-valued prediction by removing the miscalibrated probability values in the long tail. This is done by discarding all the probability values except for the maximum softmax probability."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "The paper is easy to read. The idea and the solution are both clearly articulated and the results are convincing. There are theoretical justifications."
                },
                "weaknesses": {
                    "value": "See questions."
                },
                "questions": {
                    "value": "1. On page 3, just above (4), it stated \"In the APS method (Romano et al., 2019)\". However, are you sure it's not Romano et al., 2020?  The 2019 paper was Conformalized quantile regression.\n\n2. Page 13, right above equation (9), it stated \"i.e., the calibrated threshold $\\tau$, can be obtained by (an equation)\". It is not obvious to me how this result was obtained and some clarification is appreciated. Moreover, what is the asterisk (*) at the end of that equation?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6778/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698680588914,
            "cdate": 1698680588914,
            "tmdate": 1699636782007,
            "mdate": 1699636782007,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Ww2YwE59uN",
                "forum": "zkVm3JqJzs",
                "replyto": "whqt7vpIBl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6778/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6778/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer JXhd"
                    },
                    "comment": {
                        "value": "Thank you for the recognition and valuable comments. Please find our response below.\n1. **Correction of citation [Q1]**\n\nThank you for the correction. We have fixed the citation in the revised version.\n\n2. **Clarification  of the calibrated threshold [Q2]** \n\nThank you for pointing out the unclear part. Here, we provide a detailed explanation of $\\tau$. The score function is defined as $S(\\boldsymbol{x},y,u;\\hat{\\pi}) =  r -u$ where $r$ is the rank of $\\hat{\\pi}\\_y(\\boldsymbol{x})$ in the sorted vector of $\\hat{\\pi}(\\boldsymbol{x})$. We use $A_{r}$ to denote the proportion of examples in the calibration set that have scores less than $r$. If $k$ satisfies $A_{k}\\geq 1-\\alpha >A_{k-1}$, the $1-\\alpha$ quantile of scores for the calibration set, i.e., the calibrated threshold $\\tau$, falls within the interval $[k-1,k]$. As the scores in the interval $[k-1,k]$ are uniformly distributed, and the proportion of examples with scores in $[k-1,k]$ is $a_k$, $\\tau$ is chosen as the $\\frac{1-\\alpha- A_{k-1}}{a_{k}}$ quantile of $[k-1,k]$. In the revised manuscript, we provide a detailed supplement for the proof in Appendix A. The asterisk (*) is a typo, which is fixed in the revised version."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6778/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700403997334,
                "cdate": 1700403997334,
                "tmdate": 1700403997334,
                "mdate": 1700403997334,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]