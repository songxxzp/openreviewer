[
    {
        "title": "A  Multi-resolution Dataset of Self-consistent Cloth Drapes for Physics-based Upsampling"
    },
    {
        "review": {
            "id": "jfuXD5VMYB",
            "forum": "aAhgJ1fQ4V",
            "replyto": "aAhgJ1fQ4V",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2916/Reviewer_qJGw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2916/Reviewer_qJGw"
            ],
            "content": {
                "summary": {
                    "value": "The research paper introduces and discusses a novel dataset of cloth simulations that interact with various collider objects. The dataset  includes a wide variety of materials, ensuring a comprehensive representation of different cloth types and their behaviors. Furthermore, the authors provide meshes at multiple resolutions, maintaining consistency across these different levels of details.\n\nThe primary objective of this dataset is to facilitate the development and evaluation of deep learning networks, specifically in the context of upscaling cloth meshes. The authors propose such deep learning pipeline and demonstrate its effectiveness over existing baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper uses the Progressive Cloth Simulation (PCS) simulator, which ensures that the cloth meshes are consistent across different resolutions. This is a significant strength as it provides a robust foundation for establishing a training set specifically tailored for upsampling tasks, by providing correspondences between different levels of details.\n\nThe dataset covers a wide variety of cloth materials. This diversity is a major asset, as it allows for the training and testing of models in a multitude of scenarios, ensuring that the resulting models are versatile and robust. \n\nThe paper is well written."
                },
                "weaknesses": {
                    "value": "A primary concern regarding this paper is its relevance in the current landscape of cloth simulation and rendering. The field has seen a significant shift towards self-supervised learning approaches, as evidenced by recent papers such as SNUG (Santesteban et al., CVPR 2022), HOOD (Grigorev et al., CVPR 2023), and DrapeNet (De Luigi et al., CVPR 2023). These works have moved away from traditional supervised learning methods, which stands in contrast to the claim made in Section 2 of the paper that \u201cMost recent approaches for neural garment deformations rely on supervised learning\u201d. This discrepancy raises questions about the paper's alignment with current trends and best practices in the field.\n\nThe paper introduces a dataset for training and testing deep learning models, but there are concerns regarding its generalizability. The dataset includes a limited number of collider objects (100), which may not be sufficient for ensuring that models trained on this data can generalize well to unseen geometries, as indicated by the results in Table 3. Additionally, the dataset and task are focused solely on static clothes subjected to gravity and resting on collider objects. This narrow scope may limit the utility of the dataset, as it does not reflect the dynamic nature of cloth in real-world scenarios.\n\nThe technical contributions of the paper appear to be modest. The proposed network architecture, consisting of a PointNet encoder and Neural Subdivision decoder, is relatively simple. Furthermore, the dataset is generated using a direct application of the PCS simulator, and the \u201cnew metrics\u201d mentioned in the abstract are standard measures such as Euclidean distance and curvature. The use of different curvature computations as metrics for assessing mesh similarity is not clearly justified or explained, leaving the reader uncertain about the soundness and efficacy of these measures.\n\n\nA minor point: the abstract seems too long."
                },
                "questions": {
                    "value": "Why are supervised methods still relevant nowadays for cloth draping? this directly questions the relevance of a dataset for training such methods.\n\nHow and why is a curvature a measure of \"similarity\"? How can it be computed \u201cbetween meshes\u201d as said in the supplementary material?\n\nThe dataset is said to contain \u201cover a million\u201d samples: how many exactly?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2916/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698067250221,
            "cdate": 1698067250221,
            "tmdate": 1699636235214,
            "mdate": 1699636235214,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KCzcH6Mdvh",
                "forum": "aAhgJ1fQ4V",
                "replyto": "jfuXD5VMYB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response (1/2)"
                    },
                    "comment": {
                        "value": "# General answer for clarifying the big picture:\n\nWe value the recognition of our dataset's comprehensiveness and diversity and appreciate the acknowledgment of our objective as a dataset and benchmark paper to aid in the development and evaluation of existing upsampling methods as our contribution.\n\nHowever, we would like to clarify an important aspect that was overlooked in this review: **the primary application of our dataset is specifically focused on cloth detail upsampling**. This task is uniquely defined as the direct enhancement of low-resolution, coarse cloth drapes (which are usually cheap and fast to compute/generate) into high-resolution, detailed, physically realistic versions, which inherently requires a multi-scale hierarchy (as defined in the abstract and introduction and detailed in Section 5 of our paper). **It is crucial to distinguish this cloth upsampling task from neural cloth simulation, a related yet completely different application** where the aim is to train a neural network that does forward time stepping, predicting realistic cloth motion (dynamics) with regression on a single scale. **These two are fundamentally different tasks, and our dataset is tailored to the former, not the latter**. We note that all of the three referenced papers here \u2014 SNUG by Santesteban et al. (CVPR 2022), HOOD by Grigorev et al. (CVPR 2023), and DrapeNet by De Luigi et al. (CVPR 2023) \u2014 all fall into the second category, which is not the task of this benchmark.\n\nIn terms of future trends, since **the task we are tackling is a fundamentally different one from learning garment motions**, it remains to be seen whether self-supervised approaches will be the dominant strategy for cloth detail upsampling. At the same time, we note that, for the state of the art, supervised learning methods, e.g., U-DNN (included in our benchmark), are currently in use. Likewise, benchmarks serve a dual purpose: they are not just tools enabling the development of new methods, but also for evaluating and comparing new and existing methods. It is commonly accepted that the results produced from current neural approaches, including those for learning dynamic garment motions still significantly lag in quality compared to SOTA high-fidelity cloth simulation outputs. Our analysis of existing upsampling methods with the high-fidelity cloth models in our PCS-generated dataset already exposes severe limitations in existing upsampling methods (as demonstrated in Table 1 and Figures 4, 7 and 8). These methods, while claiming various capabilities to generalize, when evaluated on the new dataset, demonstrate underperformance by missing the physically realistic and intricate folding behaviors formed through precise contact resolution across a wide range of real-world materials. This underperformance clearly demonstrates that the quality, complexity and diversity of the new dataset extends well beyond the original scope of the training data with which these methods were initially developed, and so demonstrates the need for both new research to bridge this gap and the utility of our current proposed benchmark."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2916/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700201767074,
                "cdate": 1700201767074,
                "tmdate": 1700202244652,
                "mdate": 1700202244652,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xtTM7Nr7vH",
                "forum": "aAhgJ1fQ4V",
                "replyto": "jfuXD5VMYB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response (2/2)"
                    },
                    "comment": {
                        "value": "# Answers to specific questions:\n\n> These works have moved away from traditional supervised learning methods, which stands in contrast to the claim made in Section 2 of the paper that \u201cMost recent approaches for neural garment deformations rely on supervised learning\u201d. This discrepancy raises questions about the paper's alignment with current trends and best practices in the field.\n\nTo clarify we should have scoped this discussion - currently most approaches for neural physics-based upsampling rely on supervised learning. It's certainly true that neural simulation (please see our discussion of neural physics upsampling vs neural forward simulation) methods more broadly apply a range of both supervised and self-supervised methods. We have adjusted our paper's discussion to reflect this.\n\n---\n\n> The paper introduces a dataset for training and testing deep learning models, but there are concerns regarding its generalizability. The dataset includes a limited number of collider objects (100), which may not be sufficient for ensuring that models trained on this data can generalize well to unseen geometries, as indicated by the results in Table 3. \n\nIn our network design, the PointNet encoder has been pre-trained on a large collection of shapes for learning occupancy fields  [Mescheder et al. 2019] (see Appendix F for details). This network design allows our network to be aware of the collider object geometry. We note that it is expected that a trained network performs better on in-distribution data (in our case, seen collider objects as in Table 1) and has performance degradation on out-of-distribution data (in our case, unseen collider objects as in Table 3). As shown in Table 3, while all methods suffer from performance drops on unseen collider objects, our learning-based baseline method still outperforms all competing methods by a large margin (at least 13% improvement on the Euclidean distance metric d_corr over U-DNN and 18% over Neural Subdivision). We look forward to further enriching our dataset with additional collision geometries, considering it an exciting avenue for future work.\n\n--- \n\n> Additionally, the dataset and task are focused solely on static clothes subjected to gravity and resting on collider objects. This narrow scope may limit the utility of the dataset, as it does not reflect the dynamic nature of cloth in real-world scenarios.\n\nWe reiterate that our focus is on cloth detail upsampling, a task that is fundamentally different from learning neural dynamic garment motions. \n\nPlease see more discussion on the dataset's suitability for cloth detail upsampling within the current scope here (https://openreview.net/forum?id=aAhgJ1fQ4V&noteId=rqISyiyGnu).\n\n---\n\n> The technical contributions of the paper appear to be modest. The proposed network architecture, consisting of a PointNet encoder and Neural Subdivision decoder, is relatively simple. \n\nWe note that **the newly proposed baseline method for cloth upsampling is not the central emphasis of our work** \u2013 our paper's primary contributions, as a dataset and benchmark paper (as marked in the primary area section), lie in collecting high-quality data (currently no similar public datasets exist), benchmarking existing methods for this task and developing evaluation protocols for future research. Moreover, our detailed analysis of existing upsampling methods has unveiled a crucial insight: the diversity and complexity of the cloth drapes in our dataset expose severe limitations in existing upsampling methods. To demonstrate the potential for addressing this gap, we have further developed a learning-based baseline method for cloth upsampling that improves existing upsampling methods. This addition, not claimed as a novelty by us, serves as a valuable contribution we offer. As shown in Figures 4, 7 and 8, none of the existing upsampling methods can predict reasonable results. Our simple yet effective approach of incorporating collision geometries and material properties into the neural network has yielded plausible outcomes featuring detailed wrinkling and fewer intersections. We hope this can inspire future research to dive deeper and make further advancements.\n\n---\n\n> How and why is a curvature a measure of \"similarity\"? How can it be computed \u201cbetween meshes\u201d as said in the supplementary material?\n\nThe details of these curvatures were well explained in the supplemental of the PCS paper. Please see section 1 here (https://pcs-sim.github.io/pcs-supplement.pdf). We are happy to include them in our appendix if considered necessary. We will release the code that computes these metrics.\n\n---\n\n> The dataset is said to contain \u201cover a million\u201d samples: how many exactly?\n\nThere are 100 collider shapes, 3 collider size scalings, 2 cloth shapes, 3 cloth scalings, 24 cloth materials, 5 cloth initial rotations and 5 resolutions. This amounts to 100 x 3 x 2 x 3 x 24 x 5 x 5 = 1,080,000 samples."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2916/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700202236748,
                "cdate": 1700202236748,
                "tmdate": 1700251065731,
                "mdate": 1700251065731,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "bSy4ZStSbi",
            "forum": "aAhgJ1fQ4V",
            "replyto": "aAhgJ1fQ4V",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2916/Reviewer_z6HR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2916/Reviewer_z6HR"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new large-scale dataset for cloth-drape upsampling. The dataset includes multi-resolution clothes with large variations in terms of the materials, shapes, and obstacles. The dataset is also extensively anaylized and evaluated. Some applications of this dataset are cloth drape upsampling."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* High quality of clothes with multi-resolutions.\n* Various materials and obstacles are included.\n* Large-scale dataset of cloth draping.\n* Detailed evaluations of the dataset."
                },
                "weaknesses": {
                    "value": "1. Some details about the dataset are not clear. E.g., does the dataset only include static data, which is the equilibrium state? How to split the coarse mesh into more detailed one? Is it a fixed method to divide the triangle?\n2. Some related work on the cloth dataset is missing: Towards Multi-Layered 3D Garments Animation, ICCV'23."
                },
                "questions": {
                    "value": "Please refer to the weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2916/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2916/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2916/Reviewer_z6HR"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2916/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698501676140,
            "cdate": 1698501676140,
            "tmdate": 1699636235109,
            "mdate": 1699636235109,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jQHHUWeNAc",
                "forum": "aAhgJ1fQ4V",
                "replyto": "bSy4ZStSbi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response"
                    },
                    "comment": {
                        "value": "We thank the reviewer for providing valuable feedback. \n\n> Some details about the dataset are not clear. E.g., does the dataset only include static data, which is the equilibrium state? \n\nYes, our dataset only includes static data of equilibrium states. Please see Section 3 for details.\n\n---\n\n> How to split the coarse mesh into a more detailed one? Is it a fixed method to divide the triangle? \n\nAs mentioned in the problem formulation paragraph in Section 5, we use midpoint subdivision to divide a triangle into four triangles.\n\n---\n\n> Some related work on the cloth dataset is missing: Towards Multi-Layered 3D Garments Animation, ICCV'23.\n\nThank you for pointing this paper out. We note that this paper is published at ICCV 2023, which is **after** the ICLR paper submission deadline. We have now cited this paper in the cloth dataset paragraph of Section 2."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2916/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700195562096,
                "cdate": 1700195562096,
                "tmdate": 1700195562096,
                "mdate": 1700195562096,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Pu605sk9rN",
            "forum": "aAhgJ1fQ4V",
            "replyto": "aAhgJ1fQ4V",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2916/Reviewer_QcF6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2916/Reviewer_QcF6"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a dataset of cloth draped on objects intended to learn a model for physics-based upsampling. The central idea of the dataset is to run Progressive Cloth Simulation (PCS) that generates multi-resolution draped cloth with consistent output across different levels. In addition to using the dataset to benchmark different existing upsampling approaches, the paper also proposes a learning-based upsampling approach which is also evaluated on the dataset."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This paper presents a large-scale (over 1M) dataset of consistent draped cloth across different levels of detail. The authors clearly have spent a lot of effort in the design of variation in the dataset, including cloth material, shape, and size, as well as the colliding object.\n\n- The use of the proposed dataset to benchmark existing geometric and physics-based upsampling methods is interesting in demonstrating the output properties of each method in aspects such as geometric feature, intersection, and physical energy."
                },
                "weaknesses": {
                    "value": "- My major concern with the proposed dataset is the limited variety of cloth drape that is covered within it. It is true that the authors have put efforts into ensuring variation in factors such as different material types and collider objects, but it still spans a quite limited space of possible cloth drapes. For example, the dataset only includes cloth of square and round shapes, while in the real world, many interesting cloth examples do not belong to either of them, especially garments draped on human bodies which are of natural importance due to their applications. As another example, the final state of the draped cloth is significantly influenced by its initialization. For example, a cloth initialized as flat will be draped completely differently from being initialized evenly folded. Let alone all the infinite possibilities of manual interaction, for example in Fig. 1 (teaser) of the PCS paper (Zhang et al. 2022).\n\n- Due to the above limitation, I am concerned about the ability of this dataset to benchmark various upsampling algorithms under **complicated** deformation, let alone training machine learning models for complicated deformation. Notice that the perspective of judging a dataset is different from the algorithm that generates it. In the original PCS paper, even though relatively simple cloth shape and initialization have been demonstrated, it is less of a concern because as a physics-based algorithm, we generally have more confidence that it will work similarly for cloth of other shapes and from different initialization. In contrast, as a dataset intended for learning algorithms generated by this algorithm, its range of samples directly determines its scope of applicability because the common sense in machine learning is that a model cannot learn patterns outside its training distribution. In my own experience, the scenario where we are interested in a **square** cloth draped on an object without additional interaction is extremely rare.\n\n - Although PCS is by itself an excellent algorithm for multi-scale quasistatic cloth simulation, I am wondering to what extent it makes sense to use its output for the evaluation that is conducted in this experiment. On one hand, algorithms such as Loop subdivision or Neural Subdivision (Liu et al. 2020) were designed without physics in consideration at all. On the other hand, PCS is not without its own limitations. For example, the output in different levels still has some noticeable discrepancies, which is most obviously in the upper row of Fig. 9 where the paper cloth may or may not touch the ground depending on its resolution. I am wondering whether the authors have a good response for justification at a methodology level."
                },
                "questions": {
                    "value": "- On page 4, the paper writes that \"researchers end up repeatedly and unnecessarily generating data\". It may be good to avoid saying \"unnecessary\" because its tone may sound less respectful to the authors of the above work.\n- In Section E of the Supplementary document, it should be good to have a more detailed explanation of the quantities used as metrics and list the citations of their sources. The current form reads like plugging in the name of the term into the template of \"we compute [X] between the prediction and the ground truth\".\n- If I understand correctly, each level of upsampling in the dataset follows the midpoint subdivision as in Loop subdivision. Therefore, is it true that all the methods benchmarked in Table 1 should lead to the same topology? Is it possible to, or how can it be used for upsampling schemes that may not produce the same topologies? \n- In Sec. 6.2, it is made clear that the training/test split is performed across cloth material and collision objects. How is the split performed for experiments in Sec 6.1?\n- How does the proposed upsampling method compare with the original PCS method in terms of runtime performance etc.? It should be good to provide an analysis.\n\nI am willing to increase the rating if the above concerns are addressed in the rebuttal."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2916/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2916/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2916/Reviewer_QcF6"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2916/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698557217361,
            "cdate": 1698557217361,
            "tmdate": 1699636235030,
            "mdate": 1699636235030,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rqISyiyGnu",
                "forum": "aAhgJ1fQ4V",
                "replyto": "Pu605sk9rN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response (1/2)"
                    },
                    "comment": {
                        "value": "# General answer for clarifying the big picture:\n\nWe appreciate the recognition of the importance of a high-quality multi-resolution, cloth-drape dataset and benchmark evaluation protocols.\n\nHere we'll focus on the important raised question regarding sufficient variety in our dataset:\n\nOf course, we agreed that for the cloth upsampling task (and likewise generally) further increasing variety is always of benefit. Indeed we are excited to increase the dataset variety moving forward. At the same time, we'd argue that datasets are inherently constrained; a benchmark, in practice, can never comprehensively encompass every conceivable scenario within the environment. A dataset, at its core, is a substantial and well-defined collection of data, carefully scoped for the purposes of training and evaluation. The possibility of \"better\" should not come at the cost of the improvement for SOTA that this dataset provides.\n\nMeanwhile, the natural draping of cloth itself, independent of material, boundary shape, human body draping and seamed garment panels, already produces detailed and complicated deformations. We'd like to disambiguate this important deformation complexity (for which existing learning methods already have significant trouble capturing) from the additional complexities posed by even-richer clothed human scenarios. To be very clear, we do not have confidence nor evidence that any of the evaluated upsampling methods will be applicable in such contexts. However, we want to highlight that **a predicate for new upsampling methods to work in such human-based scenarios is for them to first succeed in the current proposed direct-draping upsampling task for the current benchmark**. As standard in many other grand-challenge learning tasks, we begin with a simpler yet still well-scoped and well-beyond current SOTA benchmark task here. (As we demonstrate in our evaluation, this is a task that current learning-based upsampling methods are still far from able to address, similar to how early image recognition models were tested using MNIST and CIFAR-10 before advancing to more complex ones.) With successful methods developed, we look forward to enhancing the cloth upsampling dataset with even more complex draping and human interaction scenarios. Of course, this comes with significant further investment in time and computation resources. We note that this process is familiar in public datasets like PartNet (Mo et al. 2019) (evolved from ShapeNet (Chang et al. 2015)), Objaverse-XL (Deitke et al. 2023a) (originally Objaverse (Deitke et al. 2023a)), ImageNet (Russakovsky et al. 2015), and PASCAL VOC (Everingham et al. 2009), to name just a few \u2013 all of these started with constrained features and underwent significant expansion following their initial publication. Therefore, taking this initial step is not merely important but crucial for continued advancement in the field."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2916/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700198050838,
                "cdate": 1700198050838,
                "tmdate": 1700204409871,
                "mdate": 1700204409871,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dEEPG45nJm",
                "forum": "aAhgJ1fQ4V",
                "replyto": "Pu605sk9rN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response (2/2)"
                    },
                    "comment": {
                        "value": "# Answers to specific questions:\n\n> As another example, the final state of the draped cloth is significantly influenced by its initialization. For example, a cloth initialized as flat will be draped completely differently from being initialized evenly folded.\n\nYes! To capture a range of initializations, we vary the initial orientation of the cloth by different degrees, which indeed leads to distinct draping behaviors (detailed in Section 4 of our paper). Additionally, we emphasize the absence of a large-scale, high-quality cloth drape dataset and the substantial effort and resources needed to create one. Though initializing the cloth differently, such as by even folding, could further diversify our dataset, we are content with its current state and leave exploiting these variations for future work.\n\n---\n\n> Although PCS is by itself an excellent algorithm for multi-scale quasistatic cloth simulation, I am wondering to what extent it makes sense to use its output for the evaluation that is conducted in this experiment. On one hand, algorithms such as Loop subdivision or Neural Subdivision (Liu et al. 2020) were designed without physics in consideration at all. On the other hand, PCS is not without its own limitations. For example, the output in different levels still has some noticeable discrepancies, which is most obviously in the upper row of Fig. 9 where the paper cloth may or may not touch the ground depending on its resolution. I am wondering whether the authors have a good response for justification at a methodology level.\n\nPCS coarse-level models (or for that matter any coarse-res proxy cloth model) must choose differing approximation tradeoffs; for example between capturing the general curvature of a higher-fidelity model vs. touching ground at the same corresponding points. Here the dataset we generate with PCS makes various such tradeoffs for each coarse-level model. We certainly agree that it would be interesting to consider other possible alternatives (each with their own pros and cons) for coarse-level geometry but here the key and critical point is that the PCS-generated data provides correspondences across resolutions for these proxies all the way up to a finest high-fidelity high-resolution simulated drape. To our knowledge, this was not available in any previous dataset and is clearly an important feature for any physics-based cloth upsampling benchmark.\n\n---\n\n> On page 4, the paper writes that \"researchers end up repeatedly and unnecessarily generating data\". It may be good to avoid saying \"unnecessary\" because its tone may sound less respectful to the authors of the above work.\n\nWe have updated the paper as suggested.\n\n--- \n\n> If I understand correctly, each level of upsampling in the dataset follows the midpoint subdivision as in Loop subdivision. Therefore, is it true that all the methods benchmarked in Table 1 should lead to the same topology?\n\nYes, each level of upsampling follows the midpoint subdivision as in Loop subdivision. All methods in Table 1 will lead to the same topology (genus).\n\n--- \n\n> Is it possible to, or how can it be used for upsampling schemes that may not produce the same topologies?\n\nYes! As long as the method's output is given, we can compute the metrics between them.\n\n---\n\n> In Sec. 6.2, it is made clear that the training/test split is performed across cloth material and collision objects. How is the split performed for experiments in Sec 6.1?\n\nWe shuffle the dataset and randomly split the dataset into the training (80%), validation (10%) and test (10%) sets.\n\n---\n\n> How does the proposed upsampling method compare with the original PCS method in terms of runtime performance etc.? It should be good to provide an analysis.\n\nSee the table below. The unit is second.\n\n|              |      PCS | Ours |\n| :--- | ---: | ---: |\n| Level 0  |    16.40 |       - |\n| Level 1  |      7.96 |  0.69 |\n| Level 2  |      6.92 |  0.75 |\n| Level 3  |  281.61 |  0.81 |\n| Level 4  |    18.34 |  1.15 |\n| Others   |    33.37 |  1.43 |"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2916/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700198596317,
                "cdate": 1700198596317,
                "tmdate": 1700198604047,
                "mdate": 1700198604047,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GAVPAIzcbV",
                "forum": "aAhgJ1fQ4V",
                "replyto": "dEEPG45nJm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2916/Reviewer_QcF6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2916/Reviewer_QcF6"
                ],
                "content": {
                    "comment": {
                        "value": "Can you add a detailed explanation of evaluation metrics in Sec. E as suggested?"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2916/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700336194057,
                "cdate": 1700336194057,
                "tmdate": 1700336194057,
                "mdate": 1700336194057,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "14hQGRltX4",
                "forum": "aAhgJ1fQ4V",
                "replyto": "Pu605sk9rN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response"
                    },
                    "comment": {
                        "value": "Sure! We have included the details of the evaluation metrics and updated the paper. Please see Appendix E for the highlighted text sections. We will release our code for computing these metrics upon acceptance."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2916/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700348593891,
                "cdate": 1700348593891,
                "tmdate": 1700348783778,
                "mdate": 1700348783778,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "bPK4qeQ8LD",
            "forum": "aAhgJ1fQ4V",
            "replyto": "aAhgJ1fQ4V",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2916/Reviewer_L7uF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2916/Reviewer_L7uF"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a multi-resolution dataset of several cloth types developed using state of the art technique, progressive cloth simulation (PCS).  This technique allows a consistent transition from one resolution to another by avoiding self-intersections or artefacts, which are commonly found in other state of the art physics-based upsampling methods.  This dataset is developed by considering the geometry of the collider object into account in order to reduce the cloth-object penetration.\n\n\nOverall, the paper attempts an important problem but the results are incremental to existing methods. It is not clear that how reliable the dataset generated by the proposed methodology is beyond state of the art upsampling methods."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The drapings look realistic and the geometry seems to be consistent across levels. The number of self intersections in table 1 are significantly lower than proposed methods. The performance across other metrics is promising too.\nThe improvement in the Neural subdivision method (Liu et al, 2020) to take into account material properties of the cloth and geometry of collision objects is a plus.\nThe computation time reported in table 9 in the paper indicates the computational simplicity of the method."
                },
                "weaknesses": {
                    "value": "The performance degrades sharply with unseen data (table 2 and 3). It is only slightly better than Neural Subdivision, on which this dataset is based. The unseen material is denim, which does not produce much wrinkles and therefore, does not represent a challenging testing scenario. \nI am curious how ground truth is obtained. At high resolutions, moth physics based methods are prone to creating self-intersections while capturing details. How is this approach making sure that the ground truth is absolutely correct? The authors should comment on its reliability.\nWhy is collider object geometry only taken into account as point net features? Why are there no geometric losses to minimise the intersection between the collider object and the cloth? It could have helped better to improve the results. In most applications related to draping, the collider object is known. Using it directly by minimising the cloth-object interaction is widely popular. It is not clear why the authors did not include this and chose to enforce this additionally."
                },
                "questions": {
                    "value": "See weakness section"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2916/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698747944731,
            "cdate": 1698747944731,
            "tmdate": 1699636234961,
            "mdate": 1699636234961,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "nl2TkYDTty",
                "forum": "aAhgJ1fQ4V",
                "replyto": "bPK4qeQ8LD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Request for clarification"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nThank you for your valuable review. As we prepare a full detailed response, we would like to quickly ask for some clarifications:\n\nIn the summary section, you commented:  \n\n> The paper attempts an important problem but the results are incremental to existing methods. It is not clear that how reliable the dataset generated by the proposed methodology is beyond state of the art upsampling methods.\n\nBy saying \"the results\", are you referring to the multi-resolution mesh tuples generated by PCS (Zhang et al., 2022) or the predicted upsampled cloth results made by our proposed learning-based baseline method? \n\nCorrespondingly, does \"the proposed methodology\" mean the PCS method (Zhang et al., 2022) or our proposed learning-based baseline method for cloth upsampling?\n\n---\n\nIn the strength section, you commented: \n\n> The number of self intersections in table 1 are significantly lower than proposed methods.\n\nWhich methods do \"proposed methods\" here refer to?\n\nThanks,\n\nAuthors"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2916/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699910900530,
                "cdate": 1699910900530,
                "tmdate": 1699910900530,
                "mdate": 1699910900530,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "eseSdp40V3",
                "forum": "aAhgJ1fQ4V",
                "replyto": "nl2TkYDTty",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2916/Reviewer_L7uF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2916/Reviewer_L7uF"
                ],
                "content": {
                    "comment": {
                        "value": "In the summary section, you commented:\n\nThe paper attempts an important problem but the results are incremental to existing methods. It is not clear that how reliable the dataset generated by the proposed methodology is beyond state of the art upsampling methods.\n\nBy saying \"the results\", are you referring to the multi-resolution mesh tuples generated by PCS (Zhang et al., 2022) or the predicted upsampled cloth results made by our proposed learning-based baseline method?\n\n-->  by results, I refer to the predicted upsampled cloth results made by your proposed learning-based baseline method.\n\nCorrespondingly, does \"the proposed methodology\" mean the PCS method (Zhang et al., 2022) or our proposed learning-based baseline method for cloth upsampling?\n\n-->  by proposed methodology in summary, I refer to the your proposed learning-based pipeline that uses PCS.\n\nIn the strength section, you commented:\n\nThe number of self intersections in table 1 are significantly lower than proposed methods.\n\nWhich methods do \"proposed methods\" here refer to?\n\n-->  There is a typo here. The number of self intersections in table 1 are significantly lower than 'existing' methods.\n\n\nIn general, the proposed dataset is built using PCS in a collision-aware context, which is learnt from collider geometries. Since a small number of collider geometries are considered, one cannot guarantee a collision awareness wrt generic geometries. This is why the number of self-interactions (and other metrics) on unseen data (table 2, 3) are much higher than the one in table 1."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2916/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699961533064,
                "cdate": 1699961533064,
                "tmdate": 1699961533064,
                "mdate": 1699961533064,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fMab2zPPkx",
                "forum": "aAhgJ1fQ4V",
                "replyto": "bPK4qeQ8LD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response (1/3)"
                    },
                    "comment": {
                        "value": "# General answer for clarifying the big picture:\n\nWe appreciate the reviewer's acknowledgment of the importance of the physics-based cloth upsampling task in both simulation and learning communities. However, to ensure a fair assessment of our paper\u2019s contributions, we respectfully highlight certain factual misunderstandings in the review:\n\n---\n\n> In general, the proposed dataset is built using PCS in a collision-aware context, which is learned from collider geometries.\n\nTo clarify, our dataset is generated by the PCS algorithm (Zhang et al. 2022) powered by C-IPC (Li et al. 2021), a state-of-the-art cloth simulator with well-evaluated physical accuracy in cloth draping accuracy, contact-force resolution and ensuring intersection-free results. Specifically, the dataset is **not** generated with the application of any learning components. Please see the abstract, introduction, background sections and appendix A of our paper. It seems there might be a significant mix-up by the reviewer, confusing the data generation process with our proposed learning-based baseline method for cloth upsampling.\n\nTo enhance clarity, our paper is structured around two main components: (1) **Data generation** using PCS, and (2) **Benchmarking** existing upsampling methods for cloth upsampling (detail enhancement) using the generated dataset. \n\n- For (1), we employ PCS to create a high-quality dataset, as detailed in the third paragraph of the introduction section, where PCS's effectiveness is discussed in detail. \n\n- For (2), we benchmark five existing upsampling methods and further introduce a new learning-based baseline method for cloth upsampling to foster future research. All these six methods have access to and are tested on the same PCS-generated dataset, enabling a fair comparison of their cloth upsampling performance in a unified testbed.\n\n---\n\n> This dataset is developed by considering the geometry of the collider object into account in order to reduce the cloth-object penetration.\n\nSame as above. We apply PCS to generate data. The data generated by PCS is intersection- and penetration-free. \n\n---\n\n> Since a small number of collider geometries are considered, one cannot guarantee a collision awareness wrt generic geometries. This is why the number of self-interactions (and other metrics) on unseen data (table 2, 3) is much higher than the one in Table 1.\n\nWe respectfully disagree. In our network design, we use the PointNet encoder from [Mescheder et al. 2019] which has been pre-trained on a large collection of shapes for learning occupancy fields (see Appendix F for details). This network design allows our network to be aware of the collider object geometry. \n\nWe note that it is expected that a trained network performs better on in-distribution data (in our case, seen collider objects as in Table 1) and has performance degradation on out-of-distribution data (in our case, unseen collider objects as in Table 3). As shown in Tables 2 and 3, while all methods suffer from performance drops on unseen data (materials and collider objects), our additional new learning-based baseline method still outperforms all competing methods by a large margin (at least 13% improvement on the Euclidean distance metric $d_\\text{corr}$ over U-DNN and 18% over Neural Subdivision). \n\n---\n\n> The computation time reported in Table 9 in the paper indicates the computational simplicity of the method.\n\nWe respectfully disagree. The runtime in Table 9 refers to that of the PCS method (i.e., data generation), and not to our proposed learning-based baseline method for cloth upsampling."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2916/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700194632414,
                "cdate": 1700194632414,
                "tmdate": 1700203478047,
                "mdate": 1700203478047,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sbUNWmlPac",
                "forum": "aAhgJ1fQ4V",
                "replyto": "bPK4qeQ8LD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response (2/3)"
                    },
                    "comment": {
                        "value": "Considering the misunderstandings identified, we note with concern that the majority of the review\u2019s focus\u2014addressing **both strengths and weaknesses**\u2014seems to concentrate predominantly on the performance of our newly proposed baseline method. We would like to clarify that **the newly proposed baseline method is not the central emphasis of our work**. Our paper's primary contributions, as a **dataset and benchmark paper** (marked in the primary area section), lie in generating a large-scale, high-quality dataset of cloth drapes (currently **no similar public datasets exist**), benchmarking existing upsampling methods on our dataset using the same dataset, and developing evaluation protocols for future research. Moreover, our detailed analysis of existing upsampling methods has unveiled a new crucial insight: the diversity and complexity of the cloth drapes in our dataset expose severe limitations in existing upsampling methods (See Table 1 and Figures 4, 7 and 8). To demonstrate the potential of addressing this gap, we further develop a learning-based baseline method for cloth upsampling that improves existing upsampling methods. This addition, though not claimed as a novelty by us, serves as a valuable contribution we offer. As shown in Figures 4, 7 and 8, none of the existing upsampling methods can predict reasonable results. Our simple yet effective approach of incorporating collision geometries and material properties into the neural network has yielded plausible outcomes featuring detailed wrinkling and fewer intersections. We aspire that this insight serves as an inspiration for future research, encouraging deeper exploration and further advancements in the field.\n\nGiven the substantial misunderstandings that have diverged from the principal focus of our paper, we kindly request the reviewer to re-evaluate our submission in light of the clarifications provided."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2916/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700194835556,
                "cdate": 1700194835556,
                "tmdate": 1700195323674,
                "mdate": 1700195323674,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qSyyTEHXtH",
                "forum": "aAhgJ1fQ4V",
                "replyto": "bPK4qeQ8LD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2916/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response (3/3)"
                    },
                    "comment": {
                        "value": "# Answers to specific questions:\n\n> The performance degrades sharply with unseen data (Tables 2 and 3). It is only slightly better than Neural Subdivision, on which this dataset is based. \n\nWe respectfully disagree. Quantitatively, as shown in Tables 2 and 3, our baseline method improves in performance over Neural Subdivision by over 18% in the Euclidean correspondence metric $d_\\text{corr}$. Qualitatively, as shown in Figures 4, 7 and 8, Neural Subdivision fails to predict wrinkles, whereas our baseline method predicts plausible cloth drapes with intricate details. \n\nWe reiterate that as a dataset and benchmark paper, **the newly proposed baseline method is not the central emphasis of our work** \u2013 our baseline method serves as an example to showcase potential improvements that can be realized over existing techniques when analysis is performed with the new benchmark. We look forward to future research building on the foundations of both the benchmark and this new baseline to further enhance physics-based upsampling performance and quality.\n\n---\n\n> The unseen material is denim, which does not produce many wrinkles and therefore, does not represent a challenging testing scenario. \n\nWe respectfully disagree. As shown in Figure 2 and more examples in Figure 1, the denim material produces many intricate wrinkles (with very thin thickness) and thus represents a challenging testing scenario.\n\n---\n\n> I am curious how ground truth is obtained.\n\nAs mentioned in the third paragraph of the introduction section, we use PCS (Zhang et al., 2022) to generate a multi-resolution tuple of corresponding cloth drapes. In each tuple, we treat the lowest-resolution cloth drape as input and the other cloth drapes as the ground truth for the predictions of subsequent resolution levels.\n\n---\n\n> Why is collider object geometry only taken into account as point net features? \n\nOur goal is to let our network be aware of the collider object geometry. As mentioned in Appendix F, we use the pre-trained PointNet encoder from [Mescheder et al. 2019] which has been pre-trained on a large collection of shapes for learning occupancy fields. This allows the PointNet encoder to have a good understanding of the geometry of the input point cloud. While there are certainly other possible design choices, our ablation study experiment in Section 6.3 shows that such a network design allows our network to be aware of the collider object geometry, resulting in significant performance improvement.\n\n---\n\n> Why are there no geometric losses to minimize the intersection between the collider object and the cloth? It could have helped better to improve the results. In most applications related to draping, the collider object is known. Using it directly by minimizing the cloth-object interaction is widely popular. It is not clear why the authors did not include this and chose to enforce this additionally.\n\nWe would like to reiterate that in this paper our focus is on collecting a large-scale, high-quality dataset of cloth drapes, benchmarking existing upsampling methods on our dataset, and developing evaluation protocols for future research. Our results show the limitations of existing upsampling methods. We provide an additional learning-based baseline method for cloth upsampling that improves existing upsampling methods, and we show that such a simple network design results in significant performance improvement. We agree that having geometric losses such as the collision penalty in SNUG (Santesteban et al. 2022) to minimize the collider-cloth intersection could potentially help improve performance. However, given that the proposed learning-based baseline method is not the central focus of our work, we leave it as interesting future work."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2916/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700195312976,
                "cdate": 1700195312976,
                "tmdate": 1700460618493,
                "mdate": 1700460618493,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]