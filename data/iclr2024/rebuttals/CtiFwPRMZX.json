[
    {
        "title": "A simple connection from loss flatness to compressed representations in neural networks"
    },
    {
        "review": {
            "id": "uEDHkq3RFa",
            "forum": "CtiFwPRMZX",
            "replyto": "CtiFwPRMZX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6475/Reviewer_s2iN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6475/Reviewer_s2iN"
            ],
            "content": {
                "summary": {
                    "value": "The idea of the paper is to connect flatness as a generalization metric and representation compression (like in neural collapse phenomena). The authors point out that these two metrics are investigated as indicators of good generalization, but there were not connected to each other before. The authors concentrate on the interpolation regime when a neural network has reached minimal loss and derive a boundary on particular form of volume of the representations with a particular measure of flatness. An empirical investigation on VGG10 and CIFAR10 dataset demonstrated the reduction in volume and (mostly) sharpness."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "Connection of flatness, as well as compression (in a sense of neural collapse conjecture) to the generalization abilities of models is an important research area. Interconnection between possible generalization metrics can prove to be useful in deriving unified understanding of generalization in neural networks."
                },
                "weaknesses": {
                    "value": "The paper gives an impression of an unfinished work. It is not clearly signified which of the derivations are novel contributions and which are reproducing the existing research. The experimental evaluation is very limited and not fully showing the correctness/tightness of the bound presented.\n\nEven with the assumption that trace of the Hessian is indeed a good generalization indicator (which was disproven by Dinh et al.), the discussion in the beginning of section 2 is very imprecise. If the loss indeed reaches the point of zero value and its derivatives are zero, SGD would not change the solution anymore - just by definition. The referenced works take into account label noise for example, that allows for further dynamic of the optimization even after reaching a minimal loss. Therefore the theoretical justification of the bounds is ill-posed and it also does not connect to the experiments performed, since there network there does not achieve 0 loss and 0 gradients (which should effectively stop the changes of the model).\n\nThe observations made in section 4.2 are basically showing that the derived boundary is extremely imprecise, which to some extent diminishes its value.\n\nMinor:\n\n- the positioning of images makes it very hard to follow the text and description of the experiments, they should be moved closer to the part where they are described\n\n- short mention of possible perspective through the lens of entropy (in the end of section3) should be either elaborated more or removed, because currently it is much more confusing\n\n- eq. 14 is introduced in the very end of the paper, while being used in all the experimental section which makes reading unnecessarily hard"
                },
                "questions": {
                    "value": "1 - What model of SGD dynamics do you have in mind when using terms \"second phase\" and \"interpolation regime\"?\n\n2 - How the used volume connects to the representation collapse?\n\n3 - What is the additional metric introduced in the last section of the paper?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6475/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698412567233,
            "cdate": 1698412567233,
            "tmdate": 1699636724854,
            "mdate": 1699636724854,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "EfF6MQxuw7",
                "forum": "CtiFwPRMZX",
                "replyto": "uEDHkq3RFa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6475/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6475/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer\u2019s critiques and suggestions. Below we address the reviewer\u2019s concerns point by point:\n\nWeakness:\n\nNovelty:  While we acknowledge and appreciate the reviewer\u2019s point that our contributions could and should be better described, our impression from other reviewers is that the central novelty of newly connecting the previously separate ideas in parameter and representation space was laid out reasonably.  This said we embrace the criticism and the chance to do better.  First, in our revision, we have now clearly divided the material of the paper into two distinct sections. Sec. 2 is titled \u201cBackground and setup\u201d and Sec. 3 highlights our original contributions in making new connections to neural representation space.  Second, also following the reviewer\u2019s other very on-point suggestions, we have extended these original contributions in Sec. 3 significantly, with three new figures there and the allied appendix D (please see below).  Third, we now enumerate our contributions more explicitly in the introduction.  Overall, we believe that this has significantly improved our paper, and again thank the reviewer for their keen criticism and the chance to respond.\n\nCorrectness/tightness of the bound: We thank the reviewer for their keen and on-target point that the tightness of the bound should be both more fully explored and presented.  In our revision, we have extended our analysis to tackle this important matter in two separate steps. First, we studied very carefully the tightness of our newly derived bound (Sec. 3.2 Eq. 13) in Appendix D.1, including isolating and testing three factors that contribute to this tightness or the lack thereof (with full details given in the new Appendix D.1, with a series of new equations and a new figure). Second, we now clearly connect the relationship between our bound and the insights derived from allied research (Appendix D.3). Third, we carry out and present new experiments on a different network (a fully connected MLP) (Fig D.6, E.7-8). Altogether our extended findings reveal both how our bound can predict that neural representations will be compressed, and also the factors that would limit the success of this prediction.  Further, dedicated future work will be required to assess when and how flatness increases or decreases through network training. We further detail our findings, again inspired by the reviewer's critique, with two new figures (Appendix D.2) that show how in our experiments a decrease in sharpness (and related increase in flatness) significantly correlated with volumetric compression of the neural representation. \n\nImprecise argument in section 2: We thank the reviewer for pointing out the lack of precision of the argument at the start of section 2. We addressed this in two separate ways: 1) We now evaluate in more depth whether sharpness decreases towards the end of training. For example, sharpness does not necessarily decrease after the training error becomes zero (Fig. E.7-8). However, our additional experiments show that our bounds successfully predict the correlation between sharpness and both local volume and maximum local sensitivity (MLS) (Fig. D.5-6). 2) Our theoretical derivation and results do not rely on the specific form of label noise SGD or sharpness-aware minimization (SAM). Both the narrative and results of the paper are largely unaltered. The mathematical argument also has a general form that does not strictly rely on these specific forms of gradient noise ($\\delta\\theta^*$). We believe that it provides a constructive argument towards why flatness may/may not increase at the end of training (sharpness may not decrease when the noise is too small, i.e. the second term $\\delta\\theta^* H\\delta\\theta^*$ is negligible). Nevertheless, we omit this intuition from the paper itself to retain the focus on our main contributions. We believe these two points address the reviewer's concern. \n\nWe believe that our updated Sec 3 and Appendix D now explain the looseness of the original bound that is evidenced by results in Appendix D. In summary, we found that the reason for the looseness in Eq. 12 is due to the sparseness of the eigenspectrum of $C_f^{lim}$. We again observe that in Fig. 3, although log volume is not well correlated with sharpness, the quantity G is much better correlated with sharpness. Exploiting this, we introduce a new, closely related metric, the maximum local sensitivity (MLS), that allows for a much tighter bound (Sec. 3.2). We then newly empirically test and show the correctness and tightness of this bound (Appendix D.1). \n\nMinor:\n1. We have updated the figure positions to where the figure is mentioned. \n2. We have removed the short mention of possible perspective through the lens of entropy as suggested.  \n3. We have moved (previous) Eq. 14 and the corresponding definition of local dimensionality to Sec 3 where all the metrics in the feature space are defined."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6475/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700684108295,
                "cdate": 1700684108295,
                "tmdate": 1700684108295,
                "mdate": 1700684108295,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "r3IlQe3sow",
                "forum": "CtiFwPRMZX",
                "replyto": "uEDHkq3RFa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6475/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6475/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to questions"
                    },
                    "comment": {
                        "value": "Questions:\n1. All of our experiments use vanilla SGD. We would like to reiterate that our main contribution has no dependence on which optimization scheme is used.\n\n2. Neural collapse is a phenomenon that occurs in deep neural networks when the training error reaches zero and the network enters the terminal phase of training. At this point, the within-class variability of final hidden layer outputs becomes infinitesimally small. This means that the distribution collapses down to a point or a very compressed manifold. The volume of the representation in neural space, which we study here, is one of the metrics that can capture the fact that such within-class variability is small. \n\n3. The metric is called participation ratio which is a natural continuous measure of the local dimensionality.  Intuitively if all variance is concentrated in one direction, i.e. the covariance matrix $C_f^{lim}$ only has one non-zero eigenvalue, then the output of the network is locally 1D given input of a small ball B(x) around x. This is a metric that captures the neural compression effect through the lens of the dimensionality of the manifold of within-class representations. The participation ratio overall has been recently applied fairly broadly in the computational neuroscience and neural networks literature, making us confident that its analysis extends the value of the paper; moreover, we have updated the manuscript to include a dedicated subsection 3.1 to more completely describe and discuss this metric."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6475/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700684155195,
                "cdate": 1700684155195,
                "tmdate": 1700684194695,
                "mdate": 1700684194695,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "mq4pk7JaOj",
            "forum": "CtiFwPRMZX",
            "replyto": "CtiFwPRMZX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6475/Reviewer_Km7j"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6475/Reviewer_Km7j"
            ],
            "content": {
                "summary": {
                    "value": "The authors study the interplay between 1) the flatness of the loss landscape at minima found during training, and 2) dimensionality of learned neural representations.  Building on Ying and Ma, the authors prove that flatter minima in the loss imply an upper bound on the volume occupied by neural representations. Experiments on a (simplified) image classification task confirm their analysis."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Originality:\n\nThe authors draw an original connection between two major concepts: flatness of loss landscapes and compression of representations.  These ideas have been studied independently quite thoroughly, but this thread is, to my knowledge, new.  Further, their experimental analysis bolsters support to this thread.\n\nQuality/clarity:\n\nThe proofs and empirical studies were, to my eye, rigorous, clear, and thorough.\nThe paper is clearly structured, easy to follow, and provides intuitive explanations.\nThe authors clearly acknowledge the limitations of their work.\n\nSignificance:\n\nThis work is another solid contribution to the ongoing research thread of trying to understand the connection/interplay between flatness/sharpness and generalization."
                },
                "weaknesses": {
                    "value": "Not that this work is particularly weak, but there could probably be more empirical analysis.  I'd love to see the analysis repeated for additional learning problems, beyond the simple classification problem studied."
                },
                "questions": {
                    "value": "No questions."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6475/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698442455418,
            "cdate": 1698442455418,
            "tmdate": 1699636724731,
            "mdate": 1699636724731,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LwFLNyFgHd",
                "forum": "CtiFwPRMZX",
                "replyto": "mq4pk7JaOj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6475/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6475/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer\u2019s overall assessment of the value of our central contribution in linking flatness and compressed representations.  We also appreciate their stated limitation and suggestion, and next, describe how we have revised and added to our paper in response:\n\nWeakness:\n\nWe agree with the reviewer\u2019s suggestion that more empirical analysis should be included. In our revision, we have added new experiments on a different network (MLP) trained on the FashionMNIST dataset (Fig. D6, E7-8).  We have also added a new experimental Appendix D that comprehensively analyzes the tightness of the derived bound in a new figure, as well as another new figure showing correlations between different metrics introduced in the paper. We also agree that further extensions to other learning problems would be of interest, and added a sentence describing this in the revised discussion; we feel that completing these studies here would go beyond the scope of what we can accomplish within the given paper but are eager to undertake this in future studies."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6475/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700683681293,
                "cdate": 1700683681293,
                "tmdate": 1700684333094,
                "mdate": 1700684333094,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "lwRZVGgsbx",
            "forum": "CtiFwPRMZX",
            "replyto": "CtiFwPRMZX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6475/Reviewer_Hwwc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6475/Reviewer_Hwwc"
            ],
            "content": {
                "summary": {
                    "value": "The paper explores the correlation between the sharpness of minima and the corresponding representation manifold volume. The authors show, theoretically as well as experimentally, that in the last stage of training, when the loss is zero, further training leads to (1) flatter minima, which correspond to (2) a more compressed representation of inputs. As such, authors provide further theoretical and empirical support for an existing understanding of generalisation behaviour in neural networks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This is a well-written paper on a very relevant topic. Authors do not rely on solely the theory or the experiments, but rather bring the two together to build a stronger argument.\n\n**Originality:** Authors propose the idea that flatness of discovered minima correlates with the amount of compression of the inputs. Many studies claim that flatness is correlated with better generalisation, and this paper provides a perspective that may explain this known correlation. Although the idea that compression leads to improved representations is not novel on its own, I have not encountered works that have explicitly linked it to minima flatness.\n\n**Quality and clarity:** The paper is very well-written and easy to follow. The experiments are not extensive, but are well-designed. \n\n**Significance:** I believe the topic of generalisation in NNs to be extremely relevant, thus any insight into the dynamics of training that lead to improved generalisation are significant. The paper brings together a few existing seminal works, and elegantly ties them together. An important contribution is the suggestion to consider parameter space alongside the feature space, which is rarely done in practice."
                },
                "weaknesses": {
                    "value": "The authors consider Hessian eigenvalue magnitudes as the only measure of sharpness. This seems limiting, as recent studies (Yang, L. Hodgkinson, R. Theisen, J. Zou, J. E. Gonzalez, K. Ramchan- dran, and M. W. Mahoney, \u201cTaxonomizing local versus global structure in neural network loss landscapes,\u201d) have shown that Hessian trace may be more closely related to ruggedness of the landscape rather than sharpness of the basin, due to the fact that the Hessian is approximated locally and does not consider the neighborhood of a solution. In fact, the authors state in a few places that sharpness (as measured by the eigenvalues) may not be sufficient to explain the manifold volume reduction.\n\nExperimentation is convincing, although somewhat limited. Only a single CNN architecture is considered. Since fundamental questions are being asked, wouldn\u2019t it make sense to include a standard MLP in the experiments?"
                },
                "questions": {
                    "value": "Formatting: equations are referred to as \u201cequation N\u201d and \u201cEq. (N)\u201d interchangeably. Please use the latter format. Figure references are not always appropriately enclosed in parenthesis.\n\nPlacement of figures: Figures 1 and 2 are placed very early in the document, and the reader is expected to \u201cpage back\u201d to inspect the figures when they are eventually discussed in the text. While this is a minor inconvenience, I still believe the paper would be more pleasant to read if the figures were placed as close to their first mention in the text as possible.\n\nThe paper is written from the standpoint that flatness is an indication of better generalisation. However, this is not a fact, but rather a hypothesis, and should not be treated as an axiom. See, for example, https://arxiv.org/abs/2302.07011, where the relationship between sharpness and generalisation is challenged for modern NN architectures. I would appreciate it if authors could comment on this aspect, and perhaps include a discussion of the open-endedness of sharpness VS generalisation question in the paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6475/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698596327391,
            "cdate": 1698596327391,
            "tmdate": 1699636724595,
            "mdate": 1699636724595,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YC1UUUZlGX",
                "forum": "CtiFwPRMZX",
                "replyto": "lwRZVGgsbx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6475/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6475/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their critiques and suggestions, and their overall assessment of the value of our central contribution in newly linking flatness and compressed representations. \n\nBelow we address the reviewer\u2019s concerns point by point:\n\nWeakness:\n\nWe thank the reviewer for pointing out that sharpness may not fully explain volume compression.  To bring this out, in our revision we note in the updated Sec. 3.2 that the bound in Eq. 11 is indeed loose (L162): \u201cWe observe that the equality condition in the first line of Eq. (11) rarely holds in practice, since to achieve equality, we need all singular values of the Jacobian matrix to be identical.\u201d. This critique has led us to propose a more precise metric that measures the maximum sensitivity along any direction:  we call this maximum local sensitivity (MLS). We show that a tighter bound can be derived for MLS (Eq. 13), and we empirically test the tightness of the bound in Appendix D.1.  We still note, however, that the volume is positively correlated with sharpness in all of our experiments, so that -- while we acknowledge that significant variability remains to be explained -- sharpness does predict an overall trend that aligns with our main message. \n\nWe appreciate the point that more extensive experimentation is needed to make a stronger case.  As the reviewer suggested, we have now added experiments on MLP trained on FashionMNIST dataset (Fig. D.6, E7-8 in the appendix).\n\nQuestions:\nFormatting: We thank the reviewer for spotting this. Equations are now consistently referred to as \"Eq. (N),\" and figure references are now enclosed in parentheses as suggested.\n\nPlacement of figures: we agree, and the positions of figures are now adjusted to be close to where they are mentioned\n\nSharpness vs generalization: We acknowledge the contentious nature of the topic and appreciate this point.  In our revision, we have duly removed or rephrased any overly assertive statement that states sharpness directly leads to generalization. Moreover, we have added substantial additional literature and allied discussion -- including a summary of the mixed and negative results relating sharpness and generalization (second paragraph of Introduction, starting from L37).  Additionally, in Appendix D.1 we newly enumerate conditions that may contribute to such mixed and negative results.  Finally, in Appendix D.2, we empirically test correlations among a wide set of different metrics, further connecting to the broader literature while confirming that our experiments on the VGG10 and MLP networks studied here both do show a positive correlation between sharpness and test loss."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6475/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700683656092,
                "cdate": 1700683656092,
                "tmdate": 1700683656092,
                "mdate": 1700683656092,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "cDcCANZUcw",
            "forum": "CtiFwPRMZX",
            "replyto": "CtiFwPRMZX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6475/Reviewer_Wiq9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6475/Reviewer_Wiq9"
            ],
            "content": {
                "summary": {
                    "value": "The paper tries to connect loss landscape flatness with generalization, along with compression. It has some theoretical results, and some experiments backing it."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper studies an interesting avenue of different effects in neural network dynamics, and tries to connect between them in an interesting way. It has some theoretical guarantees, and presents some experimental results."
                },
                "weaknesses": {
                    "value": "** The paper is not well presented. The text is not clear, and the figures are not well presented**\nThe text has many mistakes, many things are well explained. \n\nBellow are a few of many comments on the text presentation\n1. L73 : The Frobenius norm is defined yet it is not clear for what.\n2. L94: \"Let W be the input weights to the network, and \u03b8\u00af the corresponding set of parameters.\" - it is not clear what W (\"Input Weights\") is.\n3. L112: This amounts to asking whether the transformation of the differential volume around x\u00af is an expansion or a contraction: This is problematic in my opinion, as NN often change the dimensions between layers, and this is not incapsulated in this measure as far as I understand. \n4. \"The interpolation phase\" - is usually used for the phase of zero **error** not zero loss (e.g. Neural Collapse literature).\n5. Figure 1 is extremely not clear. The caption is even misleading, as \"From left to right\" does not include the Train loss. \n\n\n**Missing Literature:**\n\n[1] Ben-Shaul, I. &amp; Dekel, S.. (2022). Nearest Class-Center Simplification through Intermediate Layers. <i>Proceedings of Topological, Algebraic, and Geometric Learning Workshops 2022</i>, in <i>Proceedings of Machine Learning Research</i> 196:37-47 Available from https://proceedings.mlr.press/v196/ben-shaul22a.html.\n\n[2] Ben-Shaul, I., Shwartz-Ziv, R., Galanti, T., Dekel, S., & LeCun, Y.  Reverse Engineering Self-Supervised Learning. In Proceedings of the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023).\n\n[3]  Rangamani, A., Lindegaard, M., Galanti, T. &amp; Poggio, T.A.. (2023). Feature learning in deep classifiers through Intermediate Neural Collapse. <i>Proceedings of the 40th International Conference on Machine Learning</i>, in <i>Proceedings of Machine Learning Research</i> 202:28729-28745 Available from https://proceedings.mlr.press/v202/rangamani23a.html.\n\n[4] Gamaleldin F. Elsayed, Dilip Krishnan, Hossein Mobahi, Kevin Regan, and Samy Bengio. Large margin deep networks for classification. In NeurIPS, 2018.\n\n[5] Galanti, T., Galanti, L., & Ben-Shaul, I. (2023). Comparative Generalization Bounds for Deep Neural Networks. Transactions on Machine Learning Research, (ISSN 2835-8856)."
                },
                "questions": {
                    "value": "I think adding much more experimental evidence of the effects, explaining them more thoroughly, and well would improve the paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "n/a"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6475/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698782630359,
            "cdate": 1698782630359,
            "tmdate": 1699636724482,
            "mdate": 1699636724482,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "soB13iGvhG",
                "forum": "CtiFwPRMZX",
                "replyto": "cDcCANZUcw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6475/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6475/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer\u2019s critiques and suggestions. Below we address the reviewer\u2019s concerns point by point:\n\nWeakness:\n\n1. We thank the reviewer for pointing this out -- the Frobenius norm should be defined for the norm in Eq. 3.  We have now moved the explanation to right after Eq. 3.\n2. Here, \u201cW\u201d are the weights of the linear layer. The setting is the same as Ma & Ying 2021, and as in many deep learning architectures, where the raw features go through a linear layer first. We have updated the text L117 to make this point clearer: \u201cLet W be the input weights (the parameters of the first linear layer) of the network, and (theta bar) the rest of the parameters.\u201d. \n3. We acknowledge that we are not considering the dimension of layers between the input and the output in our work. However, our work applies when we redefine the function f to be the transformation up until any middle layer that may be of interest. We have updated the text at the beginning of Sec. 3 to reflect this: \u201cAlthough we only consider the representations of the output of the network, our results apply to representations of any middle layers by defining f to be the transformation from input to the middle layer of interest.\u201d\n4. We thank the reviewer for pointing out this difference. We have updated the manuscript to note that the solution found by SGD is indeed an \u201capproximate interpolation solution\u201d with zero training error instead of zero training loss due to the gradient noise. Therefore our reference to the interpolation phase in experiments is consistent with those in the neural collapse literature.  In our revision we have also added and proved Lemma A.1, to show that our estimate of the sharpness won\u2019t invalidate our results during the interpolation phase given that the training loss is small enough. \n5. We apologize for the lack of clarity here -- we have fixed the phrasing in the caption. \n\nOverall, thanks to the reviewer comments the presentation has now been substantially improved.\n\nIn addition, we thank the reader for the missing literature, all of which we have cited in the updated version (L24, L29). \n\nQuestion:\nWe thank the reviewer for this suggestion and have added\n\n1) additional experiments on MLP training on FashionMNIST dataset (Fig. D.4, D.6, E7-8) \n2) a new experimental appendix D that comprehensively analyzes the tightness of the derived bound in a new figure\n3) a new analysis, and related figure, for the correlations between different metrics introduced in the paper and accompanying discussion of the connections of our bound to other works. \n\nThe contributions of these additions are:\n1. We identify two representation-space quantities that are bounded by sharpness -- volume compression and the newly added maximum local sensitivity (MLS) -- and give explicit formulas for these bounds (Sec. 3.1, 3.2, Eq. 12-13).\n2. We conduct empirical experiments with both a VGG and an MLP network and find that volume compression and MLS are indeed strongly correlated with sharpness (Figs D.4-6, and Appendix D.2).\n3. We find that sharpness, volume compression, and MLS are also correlated, if more weakly, with test error and hence generalization (Figs D.5-6, and also Appendix D.2).\n4. We carefully inspect the condition when the equality holds for the bounds that we derived, and give a set of conditions that determine when MLS will and will not be tightly correlated with sharpness (Appendix D.1) and, we conjecture, also generalization. We find that when the conditions are (approximately) satisfied, the quantities on both sides of the inequality are highly correlated.  \n\nWe hope that the reviewer will agree with us that these additions and improvements make a substantially stronger case, and thank them for their role in helping us to make it."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6475/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700683603847,
                "cdate": 1700683603847,
                "tmdate": 1700684049067,
                "mdate": 1700684049067,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]