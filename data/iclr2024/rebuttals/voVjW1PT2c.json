[
    {
        "title": "Guaranteed Out-Of-Distribution Detection with Diverse Auxiliary Set"
    },
    {
        "review": {
            "id": "gHITGyAfpu",
            "forum": "voVjW1PT2c",
            "replyto": "voVjW1PT2c",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2473/Reviewer_iVGn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2473/Reviewer_iVGn"
            ],
            "content": {
                "summary": {
                    "value": "The manuscript proposes a new method for improving out-of-distribution detection in the presence of a finite set of auxiliary negative samples. The manuscript bounds generalization error using empirical error, reducible error, and distribution shift error. The latter is caused by the finite auxiliary dataset which cannot represent all possible test outliers. Therefore, the manuscript proposes an augmentation technique based on mixup which increases the variety of auxiliary data.  In practice, negative training samples are a convex combination of different auxiliary negatives. During inference, \n OOD samples are detected based on the classification confidence of K+1st class.\nThe proposed method achieves competitive results on relevant benchmarks for OOD detection."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "S1. The method is well motivated by extensive and sound theoretical analysis. Proofs are mostly easy to follow and seem correct.\n\nS2. The proposed augmentation technique for auxiliary datasets yields competitive results."
                },
                "weaknesses": {
                    "value": "W1. The presented method relies on anomaly score derived as classification confidence for K+1 class. Can the method work in more general settings with arbitrary anomaly scores (such as entropy or energy)? Demonstrating robustness to various anomaly scores would strengthen manuscript contributions.\n\nW2. Mixup-based augmentation techniques are already considered in [a]. The manuscript should clearly outline the differences.\n\nW3. Missing related works which replace auxiliary negatives with properly trained generative models [b,c,d].\n\n[a] Dan Hendrycks, Andy Zou, Mantas Mazeika, Leonard Tang, Bo Li, Dawn Song, Jacob Steinhardt: PixMix: Dreamlike Pictures Comprehensively Improve Safety Measures. CVPR 2022\n\n[b] Kimin Lee, Honglak Lee, Kibok Lee, Jinwoo Shin: Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples. ICLR 2018\n\n[c] Matej Grcic, Petra Bevandic, Sinisa Segvic: Dense Open-set Recognition with Synthetic Outliers Generated by Real NVP. VISIGRAPP 2021\n\n[d] Shu Kong, Deva Ramanan: OpenGAN: Open-Set Recognition via Open Data Generation. ICCV 2021"
                },
                "questions": {
                    "value": "Q1. The error caused by the finite auxiliary negative dataset which cannot cover all possible test outliers is termed distribution shift error.  I suggest renaming the distribution shift error to outlier coverage error.\n\nQ2. Should the first term of Eq. 13 have D_inlier instead of D_aux?\n\nQ3. Proof of Theorem 2, could you elaborate on the equality in the line above the Eq. 16? \n\nQ4. Misspelled \"Theorm 3\" below Eq. 10 in the main text."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2473/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2473/Reviewer_iVGn",
                        "ICLR.cc/2024/Conference/Submission2473/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2473/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698309333535,
            "cdate": 1698309333535,
            "tmdate": 1700726842840,
            "mdate": 1700726842840,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "phcVvFc5jp",
                "forum": "voVjW1PT2c",
                "replyto": "gHITGyAfpu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2473/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2473/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank  you for spending time and providing valuable feedback. We  appreciate all of your suggestions and we have addressed all your  questions below by providing our responses as well as our additional  experimental results.\n## W1. More general setting with arbitrary anomaly scores.\nR1. The form of the anomaly score adopted in this paper, derived as classification confidence for the K+1 class, is a specific case in implementation. We have conducted experiments with more general forms of anomaly scores and provide the corresponding experimental results.  In particular, we chose two distinct anomaly scores, energy and OE, for the application of our method. The experimental results are outlined below:\n\n| Dataset   | method | FPR $(\\downarrow)$    | AUROC $(\\uparrow)$  | AUPR_out $(\\uparrow)$| ID-acc |\n| --------- | ------ | ------ | ------ | ----------- | -------|\n| CIFAR-10 | energy | 3.42 \u00b1 0.55  | 99.15 \u00b1 0.10 | 99.11 \u00b1 0.08 | 93.25 \u00b1 0.03 |\n| CIFAR-10 | energy + promix | **2.01 \u00b1 0.58** | **99.41 \u00b1 0.10** | **99.53 \u00b1 0.07** | 93.11 \u00b1 0.07 |\n| CIFAR-10 | OE | 9.14 \u00b1 0.64  | 98.43 \u00b1 0.07 | 98.60 \u00b1 0.22 | 94.09 \u00b1 0.07 |\n| CIFAR-10 | OE + promix | 8.09 \u00b1 0.28  | 98.54 \u00b1 0.07 | 98.88 \u00b1 0.10 | 94.01 \u00b1 0.13 |\n| CIFAR-100 | energy | 19.02 \u00b1 1.01 | 96.44 \u00b1 0.19 | 96.42 \u00b1 0.22 | 72.61 \u00b1 0.33 |\n| CIFAR-100 | energy + promix |**12.74 \u00b1 1.08** | **97.58 \u00b1 0.11** | 97.99 \u00b1 0.18 | 72.56 \u00b1 0.49 |\n| CIFAR-100 | OE |  19.97 \u00b1 1.27 | 94.89 \u00b1 0.32 | 96.18 \u00b1 0.86 | 74.21 \u00b1 0.07 |\n| CIFAR-100 | OE + promix | 16.43 \u00b1 0.94 | 95.72 \u00b1 0.17 | **98.08 \u00b1 0.15** | 74.35 \u00b1 0.36 |\n\nThe experimental results demonstrate that our method is effective in broader settings, accommodating different  widely-used anomaly scores.\n\n## W2. Differences with PixMix [a]\n**R2.** PixMix stands out as an elegant and  effective data augmentation technique, introducing new complexity information into the training procedure through the utilization of fractals and feature visualizations, which comprehensively improves safety measures. However, there are several key differences between this approach and ours: \n(1) **Different Motivations:** Pixmix approach is introduced for multiple important purposes, e.g., enhancing OOD  robustness, ensuring prediction consistency, enhancing resilience  against adversaries, obtaining well-calibrated uncertainty estimates, and facilitating the detection of anomalous inputs. Our work focuses on theoretical analysis to show why and how the diversity of outliers impacts the OOD detection ability. As a result, we  apply mixup to increase the diversity of outliers and thus improve OOD detection capabilities. \n(2) **Different Mixup Goal:** The main role of mixup in Promix is to fuse the original images with complex fractals and feature visualizations, as fractals and feature visualizations do not belong to any particular class, this method does not change the semantics of the original data. However, mixup in our method is to combine outliers with different semantic information to generate new outliers, and the new outliers have different semantic information with the original data. Moreover, unlike pixmix, we do not perform any operations on the ID data, only on outliers.\n\n## W3. Missing related works which replace auxiliary negatives with properly trained generative models.\n**R3:** We thank the reviewer for pointing out these exciting works that use generative models to synthesize outliers for training OOD detectors. [b] is the first to propose using a generative model to generate outliers on  the classification boundary of ID data for training. [c] obtains the the synthetic outliers by sampling a generative model based on normalized flow that is trained alongside a dense discriminative model in order to produce samples at the border of the training distribution, which produces   better performance. [d] Building a discriminator on features computed by a closed-world  K-way network and carefully selected The GAN discriminators on some real outlier data, augmenting the outlier set with adversarially synthesized \"fake\"  data, which achieves good performance in open-set recognition. We will review these works in the manuscript.\n\n[a] Dan Hendrycks, Andy Zou, Mantas Mazeika, Leonard Tang, Bo Li, Dawn Song, Jacob Steinhardt: PixMix: Dreamlike Pictures Comprehensively Improve Safety Measures. CVPR 2022\n\n[b] Kimin Lee, Honglak Lee, Kibok Lee, Jinwoo Shin: Training  Confidence-calibrated Classifiers for Detecting Out-of-Distribution  Samples. ICLR 2018\n\n[c] Matej Grcic, Petra Bevandic, Sinisa Segvic: Dense Open-set  Recognition with Synthetic Outliers Generated by Real NVP. VISIGRAPP  2021\n\n[d] Shu Kong, Deva Ramanan: OpenGAN: Open-Set Recognition via Open Data Generation. ICCV 2021"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2473/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700398099337,
                "cdate": 1700398099337,
                "tmdate": 1700398099337,
                "mdate": 1700398099337,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pa655ZeSgB",
                "forum": "voVjW1PT2c",
                "replyto": "WVK17QafmA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2473/Reviewer_iVGn"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2473/Reviewer_iVGn"
                ],
                "content": {
                    "title": {
                        "value": "Post rebuttal"
                    },
                    "comment": {
                        "value": "The authors successfully addressed all of my concerns. The manuscript presents an interesting theoretical analysis which leads to practical performance improvements. Even though similar methods already exist, the manuscript includes more comprehensive reasoning behind these approaches. Finally, the response to (pfu4) presents good results on challenging large-scale experiments. Therefore, I vote for the acceptance of the paper and increase my score."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2473/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700726822659,
                "cdate": 1700726822659,
                "tmdate": 1700726822659,
                "mdate": 1700726822659,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "EdnjvCgXAy",
            "forum": "voVjW1PT2c",
            "replyto": "voVjW1PT2c",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2473/Reviewer_aAfD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2473/Reviewer_aAfD"
            ],
            "content": {
                "summary": {
                    "value": "Constrained by limited access to auxiliary outliers and the high cost of data collection, the authors propose Provable Mixup Outlier (ProMix), a simple yet practical approach that utilizes mixup to enhance auxiliary outlier diversity. By training with these diverse outliers, the proposed method achieves superior OOD detection. The authors also provide insightful theoretical analysis to verify that the proposed method achieves better performance than prior works."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is written well and is easy to understand.\n2. The studied problem is very important.\n3. The results seem to outperform state-of-the-art."
                },
                "weaknesses": {
                    "value": "1. The authors are suggested to be more careful and rigorous with the theoretical terms used in the paper, such as the \"generalization risk\" is not rigorous in theory.\n2. What are the assumptions made in theory? It is better to add more discussions on them and the validity of making the assumptions. \n3. For theorem 2, did the authors consider the sample complexity of both the vanilla auxiliary outlier set and the diverse outlier set? The sample complexity and model complexity should play an important role in the bound during analysis for these two cases.\n4. For theorem 3, I am curious how well the h_mix compared with the predictor h_div. \n5. It is still not intuitively making sense to me why does mixup can create diverse outlier examples. It will not change the data distribution much since it is only doing the interpolation work. What if the auxiliary outlier set is very constrained in the convex high-dimensional input space, would mixup increase the diversity of the outlier set significantly?\n6. If possible, the authors are encouraged to provide empirical evidence on large-scale benchmarks. The current setting does not seem to suggest the diversity will create a performance improvement significantly."
                },
                "questions": {
                    "value": "see above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2473/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698534561241,
            "cdate": 1698534561241,
            "tmdate": 1699636183627,
            "mdate": 1699636183627,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hWZ5pLfAZP",
                "forum": "voVjW1PT2c",
                "replyto": "EdnjvCgXAy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2473/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2473/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank you for all the comments, we have addressed all your questions below and  hope they have clarified all confusion you had about our work.\n\n# W1.  more careful and rigorous with the theoretical terms , such as the \"generalization risk\" is not rigorous in theory.\n**R1.** Thank you for the important suggestion. We have changed \"generalization risk\" to \"generalization error.\"\n\n# W2.  Discussion about the assumptions made in theory.\n**R2.** The key assumptions made in the theoretical analysis are: \n(1) Semantic difference under mixup: This assumption states that when two samples belonging to different classes are mixed, the resulting mixed sample may have a semantic meaning different from the original samples. This assumption is grounded in the observation that mixed samples often presents an ambiguous semantic information. The practice of using 'soft labels' in vanilla mixup also supports this assumption, suggesting that the mixup process alters the original semantics of the samples. \n(2) Low error of the ideal OOD detector $\\lambda$: This assumes we can find an ideal detector in the hypothesis class H that achieves a sufficient small or near zero error on the OOD distribution. With powerful deep networks, we can expect to find detectors with small $\\lambda$. As if $\\lambda$ is large, there does not exists a good OOD detectors in the hypothesis classes, which implies that we cannot expect to achieve good OOD detection. \n(3) Equal empirical error when training with more diverse outliers: The assumption is rooted in the over-parameterized setting of deep neural networks. The abundance of trainable model parameters enables these models to achieve near-perfect fitting to a wide range of functions during training, resulting in sufficiently small training losses. This implies that, when well-trained, the model can attain comparable and low empirical errors when exposed to more diverse outliers. \n\n# W3. For theorem 2, did the authors consider the sample complexity of both the vanilla auxiliary outlier set and the diverse outlier set? The sample complexity and model complexity should play an important role in the bound during analysis for these two cases.\n\n**R3.** Thank you for raising questions regarding the complexity of samples and models. In our research, our primary focus lies in addressing the errors induced by distribution shift caused by auxiliary outliers that fail to fully cover the complexity of the real-world out-of-distribution (OOD) scenarios. This limitation stands as a critical factor constraining the performance of OOD detection. Issues related to generalization errors arising from model and sample complexities are more prevalent in traditional machine learning. However, in our specific task, such errors are often overshadowed by the disparities introduced by auxiliary outliers' inability to adequately cover the complexity of real-world OOD data. Therefore, in the context of our paper, we assume the model to be over-parameterized and the training data to be abundant, implying that the model can effectively fit the distribution of the training data [1]. We acknowledge your perspective, we will give a more comprehensive and precise analysis about how sample complexity and model complexity jointly influence the ultimate decision boundaries in future work.\n\n# W4. how well the h_mix compared with the predictor h_div.\n\n**R4.** We conducted experiments to demonstrate the performance comparison between $h_{mix}$, trained with mixed outliers, and $h_{div}$, trained with more diverse outliers. Specifically, we chose CIFAR-100 as the in-domain (ID) dataset. For $h_{mix}$, we extracted data from 250 classes in ImageNet-RC to serve as less diverse outliers, and applied mixup outliers during training. As for $h_{div}$, we utilized the entire set of classes (1000 classes) from ImageNet-RC as more diverse outliers for direct training. Additionally, we trained model $h$ by directly training on data from 250 classes as outliers from ImageNet-RC. The experimental results are as follows:\n\n| model | outlier dataset | FPR $(\\downarrow)$ | AUROC $(\\uparrow)$ | AUPR_out $(\\uparrow)$ | ID-acc $(\\uparrow)$ |\n| ---- | ---- | ---- | ---- | ----  |---- |\n| $h$ | imagenet-RC (250 classes) | 23.01 \u00b1 3.23 | 95.69 \u00b1 0.53 | 96.26 \u00b1 0.79 | 74.49 \u00b1 0.28 |\n| $h_{div} $ | imagenet-RC (1000 classes)| 18.82 \u00b1 1.40 | 96.42 \u00b1 0.28 | 96.45 \u00b1 0.49 | 74.21 \u00b1 0.25 |\n| $h_{mix}$ | imagenet-RC (250 classes) | 18.25 \u00b1 1.81 | 96.11 \u00b1 0.35 | 98.24 \u00b1 0.38 | 74.24 \u00b1 0.33 |\n\nFrom the experiments, it is evident that the model $h_{div}$, trained with more diverse outliers, outperforms the model $h$ trained without such diversity. However, after enhancing the diversity of outliers through mixup, the performance of $h_{mix}$ surpasses that of $h_{div}$. This validates the effectiveness of our approach and the underlying theoretical framework. The more intuitive comparison is illustrated in Figure 2(a) of our paper."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2473/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700397465348,
                "cdate": 1700397465348,
                "tmdate": 1700397465348,
                "mdate": 1700397465348,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZT493auVke",
            "forum": "voVjW1PT2c",
            "replyto": "voVjW1PT2c",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2473/Reviewer_pfu4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2473/Reviewer_pfu4"
            ],
            "content": {
                "summary": {
                    "value": "This work aims to address the challenges in OOD detection, particularly the limitation of current detectors to generalize from the distribution of auxiliary outliers. The authors introduce Provable Mixup Outlier (ProMix), using Mixup to increase the diversity of auxiliary outliers, with insightful theoretical analysis, leading to enhanced OOD detection. Evaluations on benchmarks like CIFAR-10 and CIFAR-100 indicate improved performance over existing techniques."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is well-structured, making it reader-friendly and easy to follow.\n\n2. The theoretical analysis constructed for Mixup is both enlightening and insightful.\n\n3. Extensive ablation studies were conducted, showcasing various experiment setups and results."
                },
                "weaknesses": {
                    "value": "1, Novelty Concerns: Applying mixup for OOD detection is not new. Many other works have explored this concept previously [1][2][3].\n\n2. The minor modification the authors propose to the original Mixup (explicitly using the existing model and selecting Mixup outliers with lower OOD scores) lacks clarity in its effectiveness. There doesn't seem to be theoretical justification or ablation studies to validate the efficacy of the modification.\n\n3. The auxiliary dataset used for training is a downsampled version of ImageNet. Compared to the utilized ID datasets CIFAR-10 and CIFAR-100, its diversity seems significantly higher. Therefore, the OOD detection performance gains achieved with such an auxiliary dataset might not be wholly convincing, even though the methods authors compared against also adopt this approach.\n\n4. I\u2019m a little concerned about the performance of Mixup on OOD detection for high-resolution datasets, such as those in [4], especially when using 224x224 ImageNet as the ID dataset.\n\n\n[1] INTRA-CLASS MIXUP FOR OUT-OF-DISTRIBUTION DETECTION\n\n[2] CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features\n\n[3] MixOOD: Improving Out-of-distribution Detection with Enhanced Data Mixup\n\n[4] OpenOOD: Benchmarking Generalized"
                },
                "questions": {
                    "value": "Please see Weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2473/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698656291108,
            "cdate": 1698656291108,
            "tmdate": 1699636183559,
            "mdate": 1699636183559,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "DJSAEURibd",
                "forum": "voVjW1PT2c",
                "replyto": "ZT493auVke",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2473/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2473/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate your thorough and insightful reviews and will address your concerns one by one.\n# W1. Novelty Concerns.\n**R1.** Our contribution goes beyond employing mixup to improve OOD detection from the following perspectives.\n(1) We first present a theoretical and empirical understanding demonstrating a more diverse set of auxiliary outliers is critical in improving OOD detection by lowering the upper bound of OOD detection error. Our findings could offer fresh theoretical insights for future OOD detection advancements.\n(2) Building on the proposed theory, we develop a simple yet effective method by leveraging mixup to enrich outlier diversity with corresponding theoretical evidence. Note that unlike the previous mixup-based methods, our core motivation for introducing mixup is to improve the diversity of the auxiliary outlier dataset instead of designing novel mixup strategy. \n(3) Unlike the insightful methods proposed in [1, 2, 3] by applying mixup to ood detection, our main contribution is to explore a more diverse auxiliary outlier space. This focus sets our research different from existing ones.\n\n# W2. The effectiveness of the modification to mixup from theoretical and experimental perspectives. \n**R2.** **Theoretical Perspective:** As the potential space for auxiliary outliers data can be excessively large, the majority of outliers uninformative for model regularization, which may lead to inefficient and insufficient exploration and exploitation of these outliers [4][5]. To mitigate this, we strategically select the mixed outlier samples that are closest to the in-distribution boundary. These samples are more likely to be misclassified as in-distribution (ID) data and need to receive more attention. In our theory, mixup can generate new outliers with semantics different from the original data, and this selection strategy can select the newly generated outliers that are easy to be misclassified by the model for training.\n**Empirical Validation:** Ablation experiments were performed on this module in Table 2. We present the results here:\nFor cifar10 dataset:\n\n|method |FPR $(\\downarrow)$|AUROC$(\\uparrow)$|AUPR$(\\uparrow)$|ID-ACC|\n|-|-|-|-|-|\n|only mixup outliers| 3.28|99.23 |**99.45** |94.30 |\n|mixup outliers + greedy sampling |**2.18** | **99.43** | 99.01|94.32 |\n\nFor cifar100 dataset:\n|method |FPR $(\\downarrow)$|AUROC$(\\uparrow)$|AUPR$(\\uparrow)$|ID-ACC|\n|-|-|-|-|-|\n|only mixup outliers| 13.33|97.35 |**98.66** | 74.28|\n|mixup outliers + greedy sampling | **10.37** |**98.03** |98.63 | 74.26|\n\nThese results clearly illustrate that selecting Mixed outliers based on their out-of-distribution (OOD) score consistently enhances OOD detection performance compared to using only Mixup. This underlines the significant benefits of our proposed modification in improving the effectiveness of OOD detection.\n\n# W3. Concerns about experimental settings on auxiliary datasets.\n**R3.** Thank you for the detailed and interesting comments. We would address this concern in the following ways:\n(1) In practical applications, access to a more diverse auxiliary dataset is often possible, such as crawling data from the Internet. This approach allows to train the model with a more diverse auxiliary outlier dataset. Consequently, this setting has been adopted by many related studies within the field.\n(2) While ImageNet-RC offers greater diversity compared to datasets like CIFAR-10/100, it still does not fully represent the vast and complex nature of true open-world out-of-distribution (OOD) data. This limitation highlights the need for even more diverse datasets to truly model the real-world data.\n(3) We also experimentally confirm that our method is still effective even when the diversity of auxiliary outliers is not significantly higher than ID data. In the experiment \"Q2 Reliability\", we tested the effectiveness of our method under the outliers dataset with different diversity. As can be seen from Figure 2, on the cifar-100 dataset, when we restrict the diversity of the outliers dataset (using only 100 classes of the ImagenetRC dataset as outliers, the diversity of the outliers dataset is comparable to that of the ID dataset), the OOD detectors are still able to benefit from outliers. When our method is adopted to improve the diversity of outliers, the performance of the model is significantly improved (The FPR95 metric significantly decreased from 26% to 20%.), which also confirms the effectiveness of our method and theory.\n\n[1] Intra-class Mixup for Out-of-Distribution Detection\n\n[2] CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features\n\n[3] MixOOD: Improving Out-of-distribution Detection with Enhanced Data Mixup\n\n[4] POEM: Out-of-Distribution Detection with Posterior Sampling\n\n[5] ATOM: Robustifying Out-of-distribution Detection Using Outlier Mining"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2473/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700396973042,
                "cdate": 1700396973042,
                "tmdate": 1700396973042,
                "mdate": 1700396973042,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vwv32Uvglg",
                "forum": "voVjW1PT2c",
                "replyto": "ZT493auVke",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2473/Reviewer_pfu4"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2473/Reviewer_pfu4"
                ],
                "content": {
                    "title": {
                        "value": "Further comments"
                    },
                    "comment": {
                        "value": "The authors' responses address most of my concerns\u2014however, the concern regarding the auxiliary dataset remains. Thus, I would like to stand by my original score. However, I would like to note that I will not fight for a rejection."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2473/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700731630897,
                "cdate": 1700731630897,
                "tmdate": 1700731630897,
                "mdate": 1700731630897,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]