[
    {
        "title": "Deterministic Diffusion for Sequential Tasks"
    },
    {
        "review": {
            "id": "fhI4uXpH0U",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3549/Reviewer_X2Za"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3549/Reviewer_X2Za"
            ],
            "forum": "iKd99CYwPX",
            "replyto": "iKd99CYwPX",
            "content": {
                "summary": {
                    "value": "This paper proposes a deterministic diffusion method for video prediction and robotic control. The main claim is that training from a better distribution can lead to faster inference. The authors conduct extensive experiments on the BAIR Robot pushing dataset and PHYRE, which show that their approach can boost generation and policy learning under many conditions.\n\n---\n\nPost rebuttal comments: I think the authors provide a lot of useful responses, and some parts of my initial review are incorrect (have been fixed). However, after the clarification, this paper looks even more like an engineering improvement over the prior work Heiz et al. Therefore, I keep my scores unchanged."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The proposed method is verified on distinctive tasks and the demo videos look cool.\n2. The authors provide a deterministic diffusion model for sequential tasks, which are very general. The idea of utilizing a better initialization makes sense.\n3. The paper introduces various toy examples to illustrate the idea. This is a strong benefit."
                },
                "weaknesses": {
                    "value": "1. This paper is not particularly novel.\n\n(1) The major change of this paper is using a better initialization. Although such an initialization may benefit the diffusion procedure, this may not be a significant change. The main model and workflow are not changed, so the proposed initialization methods look like an engineering trick.\n\n(2) The method of selecting the source distribution seems too trivial. When using perturbed history, the agent might get stuck in the previous information, which may harm the performance. The idea of using DDIM inversion is not novel as well.\n\n(3) This paper does not compare to many works in speeding up diffusion models. The only compared baselines are standard diffusion models without speeding up tricks. It's better to compare to IADB or other works.\n\n2. This paper is extensively based on Heitz et al. (2023), which is not a well-known paper yet. The proposed initialization scheme should be tested in other well-known diffusion schemes and that paper should be presented in a separate section."
                },
                "questions": {
                    "value": "I don't have other questions at this moment."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3549/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3549/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3549/Reviewer_X2Za"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3549/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697257618277,
            "cdate": 1697257618277,
            "tmdate": 1700612404158,
            "mdate": 1700612404158,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "iNVluG8tKp",
                "forum": "iKd99CYwPX",
                "replyto": "fhI4uXpH0U",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3549/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3549/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the valuable input. We address each point separately:\n\nNovelty: See our general comment to all reviewers above. We do believe that our method of using deterministic diffusion to be able to initialize from a source distribution that is not Gaussian, and using this in the context of sequential prediction, is novel. We are not familiar with previous methods which initialize the source distribution using DDIM.\n\nConcern 1.2: The agent getting stuck in the previous information is possible with warm starting where previous information is perturbed only at inference time (see eg. this paper). We, on the other hand, **train** the model to use previous data points to reach the next data point. Thus, the agent will not be stuck, as the model is trained for this scenario. We validate this empirically, showing in Fig. 4 that our algorithm has significantly lower FVD (which is better) than DDIM. In addition, we extended the Fig. 4 experiments in the supplemental rebuttal PDF (Section B.1), adding $DDIM_n$ initialization on the PHYRE dataset. We show that this initialization also provides superior performance than the other baselines (while still being inferior to the history-based initialization).\nDDIM Inversion: With DDIM-based initialization, we use the DDIM result as the initial point for the deblending process which then attempts to reach the original data point (without reversing the order of DDIM sampling).\n\nBaselines: This is a valuable insight, which is expressed by the other reviewers as well. In the experiments described in the general comment with results in the supplementary rebuttal PDF (Sections A and C.2) we address this concern by comparing our approach to Rectified Flow, DPM-Solver++ and Consistency Models.\n\nConcern 2:  We do not understand why the reviewer claims that our approach deteriorates performance. We found performance improvements In **ALL** of our experiments. In Fig. 4 and Fig. 8 we demonstrate our method's superior performance for video prediction and robotic control, respectively. In Fig. 4 our FVD is significantly lower (which is better) and in Fig. 8 our reward is higher and our MSE is notably lower (both better). In addition, we extended our baselines in Fig. 8 and added experiments to Fig. 4 in the rebuttal PDF (Section B.1 and C.2), which show the superiority of our method over additional baselines. See our previous comments regarding baselines and concern 1.2."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700438051895,
                "cdate": 1700438051895,
                "tmdate": 1700438051895,
                "mdate": 1700438051895,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zg9LYjVeqZ",
                "forum": "iKd99CYwPX",
                "replyto": "iNVluG8tKp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3549/Reviewer_X2Za"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3549/Reviewer_X2Za"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response."
                    },
                    "comment": {
                        "value": "My comment 2 refers to Figure 10, and it's my bad not to mention this figure explicitly. The manuscript says, \"We find that adding Gaussian perturbations to the DDIMn source distribution is not beneficial to performance (see Fig. 10a).\" So I say, \"The proposed approach often deteriorates the performance. If it is true that a better initialization may lead to better performance, the authors should find that the accuracies are improving as well. Probably, the deteriorated performance means that the carefully chosen initialization scheme is incorrect.\" in my review. Can you clarify this?\n\nAlso, in Fig.4, what's the score of your model in 1000 steps?"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700443862626,
                "cdate": 1700443862626,
                "tmdate": 1700443862626,
                "mdate": 1700443862626,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PVQvEQ1fWy",
                "forum": "iKd99CYwPX",
                "replyto": "ACqlrwDera",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3549/Reviewer_X2Za"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3549/Reviewer_X2Za"
                ],
                "content": {
                    "title": {
                        "value": "Some points are still pretty unclear. I do not understand over 50% of this paper."
                    },
                    "comment": {
                        "value": "Thanks for your response again. I read this paper again. Honestly speaking, I still don't understand this paper and I think I can only understand <50% contents of this paper, and the writing does not flow well. It seems that this paper is trying to present a simple idea: \"change the Gaussian noise to a better initialization,\" but I have trouble understanding it in many places.\n\n1. Question on Figure 10. Why add noises to your trained model? Your strongest claim seems to be in the introduction, \"SOTA results are still based on Gaussian noise,\" but adding some noise to your trained model cannot prove that current Gaussian noise-based models are not good. I don't quite understand the meaning of Figure 10. I understand $DDIM_n$ + noise is bad, but it does not mean that noise is bad.\n\n2. Question in Figure 4. Why don't you run your model for 1000 steps? Is it because your model runs slowly? Note that the gap between DDIM and ASPeed is becoming smaller, so it's unsure which method performs better at 1000 steps.\n\n3. Question on the main paper:\n\n(1) Why not use some real figures and videos to show the idea? The visualizations are not very accessible. It seems that this paper is trying to say, \"using DDIM is better than Gaussian.\" I think this idea is proven in other works using better visualizations. I cannot directly see the real difference if the visualizations aren't very clear.\n\n(2) How's the target distribution known in practice?\n\n(3) What place should I run the Algorithm 1? In training or testing? Do I need a pre-trained diffusion model? What's the noisy sample used here? How to get the noisy sample? Why use de-blending?  How to evaluate the expectation in a batch or a dataset? What's the function of Algorithm 1 (it's never introduced)? I think it's better not to use any algorithm block in the next version of the manuscript. It's very painful to read and understand the current draft."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700535950042,
                "cdate": 1700535950042,
                "tmdate": 1700535950042,
                "mdate": 1700535950042,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "d5s42818en",
                "forum": "iKd99CYwPX",
                "replyto": "OB4Tzjdvol",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3549/Reviewer_X2Za"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3549/Reviewer_X2Za"
                ],
                "content": {
                    "title": {
                        "value": "Unclear questions."
                    },
                    "comment": {
                        "value": "1. These questions are still not answered. What's the target distribution? How to get it?\n\n2. Authors should not assume that the ICLR reviewer and others should already know a SIGGRAPH23 paper published months ago with <10 citations till now. If the proposed method is extensively based on Heitz et al. (2023), then a self-contained present tation of that paper is required. The method section of the current manuscript only mentions this paper in lines around Theorem 4.1, and these lines are not self-contained. This sentence, \" The only difference from Heitz et al. (2023) is the conditioning on C,\" looks so confusing. If the entire methodology only contains one difference on C, then it's too minor to be a conference paper in ICLR.\n\n3. Authors should learn from Heitz et al. (2023). It's a good paper. All concepts are self-contained, and visualizations are quite direct and good, while experimental results are quite good."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700612168849,
                "cdate": 1700612168849,
                "tmdate": 1700612168849,
                "mdate": 1700612168849,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tjrg3DDEWK",
                "forum": "iKd99CYwPX",
                "replyto": "C1XwIuN8Jp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3549/Reviewer_X2Za"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3549/Reviewer_X2Za"
                ],
                "content": {
                    "title": {
                        "value": "Additional comments."
                    },
                    "comment": {
                        "value": "Thanks for your feedback and for helping me learn something in this domain.\n\n1. I now know what the target distribution is. However, I still don't understand where the target distribution comes from in Eq. (1). I checked Heitz et al. (2023) paper, and there were no words such as \"target\" or \"data distribution\" in their paper. I believe that this is at least an unaddressed writing problem in this paper.\n\n2. This paper needs an extensive rewrite, and authors should try to add their modules to other models, such as consistency models. A personal suggestion is not to present your major contribution as \"improving the source distribution.\" This idea seems quite marginal, and I think this can hardly be accepted to a top-tier ML conference such as ICLR unless such an idea is proven across a wide range of methods/benchmarks or has a unique theory support. It's better to work on a seemingly more important idea in my eyes.\n\n3. I agree with Reviewer 1n8o that this paper does not contain major novelty. I agree with Reviewer HtfP that this paper looks like a workshop paper. I agree with Reviewer eaWM that this proposed module needs to be applied to other methods to get it published."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700701610718,
                "cdate": 1700701610718,
                "tmdate": 1700701610718,
                "mdate": 1700701610718,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "QkQqXaLnsD",
            "forum": "iKd99CYwPX",
            "replyto": "iKd99CYwPX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3549/Reviewer_eaWM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3549/Reviewer_eaWM"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a deterministic diffusion framework that samples (sequential) data more efficiently and effectively than established DDPM / DDIM frameworks.  The framework is based on IDAB, where mixed densities are iteratively deblended from the source to target distribution.   The core idea is to initialize the source distribution with those more closely resembling the target distribution, instead of starting from Gaussian noise.  Such a non-Gaussian distribution can be obtained using the available context or intermediate distributions sampled from a trained DDIM model.  This paper demonstrates better efficiency and stability of sequence predictions than DDIM/DDPM baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The idea of denoising from a source distribution closer to the target makes sense.  Figure 1 and 3 clearly demonstrates the idea.\n2. The paper is well written and easy to follow."
                },
                "weaknesses": {
                    "value": "1. The compared baselines are incomplete.  Diffusion models have sparked great interest in the machine learning community, and there are multiple works focusing on improving the sampling efficiency of diffusion models.  For example, Progressive Distillation[1], DPM-Solver[2], 3-DEIS[3], and Consistency Models[4].  Especially, Consistency Model even requires only 1 diffusion step for sampling. I would expect Consistency Model to be the strong baseline across all experiments.\n\n2. The efficacy of deterministic deblending module is unclear.  One can stack two separate DDIM modules by replacing the IADB with another DDIM.  Probably such a cascade (yet incremental) trick could also good performance and model efficiency.\n\n3. It seems unclear to me when to using DDIM or sequence history to initialize the source distribution.  For video prediction, the authors use deblend from history.  For policy prediction, the authors use DDIM intermediate estimate.  There's no enough ablation study about why the authors choose to use DDIM intermediate estimate for action prediction.  I would expect it's because that using sequence history is more stable, but having troubles with capturing multi-modality.  On the other hand, using DDIM intermediate estimate seems to contradict with the abstract, where authors mentioned \"Drawing on recent work on deterministic denoising diffusion, we initialize the denoising process with a non-Gaussian source distribution obtained using the context available when predicting sequence element\".  DDIM starts denoising from Gaussian noise.\n\n\n[1] Progressive distillation for fast sampling of diffusion models.  Salimans, Tim and Ho, Jonathan.  ICLR 2022.\n\n[2] Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps. Lu et al. NeuRIPS 2022.\n\n[3] Fast sampling of diffusion models with exponential integrator. Zhang et al. ICLR 2023.\n\n[4] Consistency Models. Song et al. ICML 2023."
                },
                "questions": {
                    "value": "1. To clarify my concerns, I would expect the following experiements:\n\n    * On BAIR and PHYRE, compare DDIM & DDPM & ASPeed that deblend previous history or Gaussian noise.  It would be clearer about the choice of deblending history (see Weakness 3).\n    * On Robomimic and Push-T, compare to i) Consistency Model, and ii) two-stage DDIM, which resembles ASPeed but replaces the second-stage deterministic deblending module with another DDIM (see Weakness 1 and 2).  If stacked DDIM works, probably this paper should be positioned as cascade diffusion models instead.\n\n2. One interesting (and I personally think would be more impactful) question is: can we generalize the first-stage distribution to some coarse-semantic / prior-knowledge distribution.  Take a simple example--face reconstruction, can we initialize the source distribution with mixtures of eigen faces (where we can introduce stochasticity)?  So that we can control the whole generation process (either start from some specific prior or randomly perturbed prior to start from pure noise)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3549/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698574695217,
            "cdate": 1698574695217,
            "tmdate": 1699636309097,
            "mdate": 1699636309097,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mzcvaFd4HA",
                "forum": "iKd99CYwPX",
                "replyto": "QkQqXaLnsD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3549/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3549/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their important feedback and their time. We address each point separately:\n\nStacking DDIMs: assuming the suggestion is to run DDIM and use the result for initialization of another DDIM, we believe that this is not possible as DDIM expects a Gaussian source distribution and the output of the first DDIM would not be Gaussian. This is one of the reasons we use deterministic diffusion, which is a central component of our work.\nAn alternative is to simply run DDIM for more steps - we compare with this baseline in Figure 8.\nIf we misunderstood what the reviewer meant by stacked DDIMs, we kindly ask for clarification.\n\n\nBAIR and PHYRE: We thank the reviewer for this suggestion. We added the experiments on PHYRE in the supplemental rebuttal PDF (Section B.1). As mentioned in the general comment above, $DDIM_n$ Initialization in the video prediction domain is inferior to history-based initialization, and the initial approximation accuracy is important as there is a significant difference in the results of initializing with $DDIM_2$ or $DDIM_3$. We will add experiments on BAIR after the rebuttal as they take too long given our available compute resources.  \n\nRobomimic and Push-T: We have added DPM-Solver++ and Consistency Models as baselines in the supplemental rebuttal PDF (Section C.2), which both perform worse compared to ASPeeD. We will update the relevant plots in the final version of the paper.\n\nCoarse Semantic/Prior Knowledge Distribution: Thank you for the interesting suggestion! We will definitely explore this direction in the future, it would be interesting to investigate \u201cdiscrete\u201d distributions as source distributions."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700438014609,
                "cdate": 1700438014609,
                "tmdate": 1700438014609,
                "mdate": 1700438014609,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PXFItXWZYA",
                "forum": "iKd99CYwPX",
                "replyto": "QkQqXaLnsD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3549/Reviewer_eaWM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3549/Reviewer_eaWM"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response.  The followings are my response.\n\n---\n\n**Other strong baselines**\n\nMy concern is addressed\n\n---\n\n**Stacking DDIM**\n\nSorry for the confusion.  Since one variant of the method stacks two diffusion models with separate denoising scheduler, one question is that \"Does the performance gain result from increased model capacity (two networks), or the novel combination of denoising schedulers?\".  A direct ablation study is to compare with a stacking-DDIM baseline, where two networks are trained with separate DDIM denoising schedulers.  My guess is that if the hyper-paramters (e.g. the variance schedule, number of diffusion steps etc) are tuned optimally, stacking-DDIM might achieve comparable performance as the proposed method.\n\n---\n\n**Source distribution**\n\nI think the ablation is somewhat disappointing, since history data is only available for sequential data.  For image generation, information retrieval would be a good solution [1].  I would encourage the authors to tackle this limitation and enrich the experiments.\n\n[1]: Re-Imagegen: Retrieval-augmented text-to-image generator.  Chen et al."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700528629104,
                "cdate": 1700528629104,
                "tmdate": 1700528663651,
                "mdate": 1700528663651,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "UjbvKS0qYV",
            "forum": "iKd99CYwPX",
            "replyto": "iKd99CYwPX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3549/Reviewer_HtfP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3549/Reviewer_HtfP"
            ],
            "content": {
                "summary": {
                    "value": "This paper applies an iterative $\\alpha$-(de)blending approach to generative modelling in sequential tasks (context conditioned video and action prediction). Here, the forward diffusion process is formulated as a linear interpolation between the source distribution in some context and a target distribution given the same context. The core approach is to speed up diffusion processes by drawing data from an improved source distribution, with two options considered. The first takes advantage of temporal similarity and uses a Gaussian noise perturbed prior sequence of states as the source distribution, while the second, more expensive approach, uses a pre-trained DDIM diffusion model. Results on video prediction tasks (BAIR and PHYRE) show improved video prediction quality with fewer diffusion steps, and improved rewards when compared to baseline models."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The core contributions of this work are to show that $\\alpha$-(de)blending (Heitz et al. 23) is effective in the video domain, where stronger sequential priors over source distributions can be exploited. This is a sensible application of this approach, and the empirical evaluations in this work help to justify this.\n\nThe proposed approach produces good results, outperforming baselines.\n\nSection 4.1 nicely explains the motivation behind the choice of improved distributions and how this reduces the number of steps required for generation."
                },
                "weaknesses": {
                    "value": "The strength of the contribution is limited, and to my mind better suited to a workshop paper, particularly given that the proposed approach closely follows Heitz et al. 23.\n\nThe results are not particularly surprising, particularly when the relatively weak baselines used for comparison are considered. As mentioned in 5.1, the DDIM sampling approach starts from Gaussian noise, while the proposed approach bootstraps from the perturbed history. The core idea to bootstrap the diffusion process from a good initial guess has been applied to accelerate diffusion processes previously eg. Lyu et. al., which may be a better baseline to consider.\n\nHowever, the idea of using another trained generative model (in this case DDIM) as a source distribution, while effective, seems extremely expensive, and needs to be justified/ better motivated. The comparisons in Fig 8 seem unfair, as the proposed approach takes 10 steps, but this requires an additional 3 steps for blending step (please correct me if I am wrong). This seems to indicate that 10 DDPM steps is doing comparatively well on this task.\n\nThe paper would benefit from significant levels of polish (proof reading, figure axis labelling, better choices of axis limits - eg. Fig 8a, these axes should reflect maximum and minimum rewards obtainable to put these results into context, figure order, making sure captions fully describe content)."
                },
                "questions": {
                    "value": "Fig 8. Why is 100 DDPM worse than 10 DDPM in push-T/ tool hang? How well does 30 DDIM/ DPPM (I think this is equivalent to 10 Aspeed steps?) steps do in comparison to Aspeed? \n\nFig 10. These ablations don't seem comprehensive enough to answer questions or support the claims. How dependent are these choices on the nature of the task?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3549/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698727392449,
            "cdate": 1698727392449,
            "tmdate": 1699636308987,
            "mdate": 1699636308987,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jgA0HW49X7",
                "forum": "iKd99CYwPX",
                "replyto": "UjbvKS0qYV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3549/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3549/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their feedback and time.\n\nNovelty: See our general comment to all reviewers above. \n\nBaselines: Thank you for this suggestion. In the supplementary rebuttal PDF (Sections A and C.2) we address this concern by comparing our algorithm to Rectified Flow, DPM-Solver++ and Consistency Models, showing that our approach outperforms the latter two on robotic control tasks. As mentioned in the related work section, Lyu et al. [1] (as well as others) only focus on image generation, and have not attempted to extend their work to video prediction or robotic control. In particular, the method proposed by Lyu et al. requires pre-training a different (non-diffusion) generative model, which is avoided in our work by using the insight that deterministic diffusion does not require a Gaussian prior. To our understanding, the new baselines that we added are stronger than Lyu et al.\u2019s ES-DDPM, but we can add an ES-DDPM baseline if the reviewer finds it pertinent. \n\nWe emphasize that our approach can start with a distribution that is *not Gaussian*, which we exploit in the Diffusion Policy experiments. This is made possible by using deterministic diffusion. To our knowledge, this method of using deterministic diffusion to bootstrap from non-Gaussian source distributions is novel.\n\nFig. 8: To clarify, ASPeeD takes a TOTAL of 10 steps. In the Push-T experiment, 2 DDIM steps and 8 deblending steps are taken, while in the Tool-Hang experiment 3 DDIM steps and 7 deblending steps are taken; in both cases the total is 10 which is a fair comparison with 10 DDPM or 10 DDIM steps. If this is unclear in the text, we can update the caption to better convey this point.\n\nRegarding 10 DDPM outperforming 100 DDPM: Inference with 10 steps of DDPM was not attempted by the authors of Diffusion Policy; we conducted this additional experiment for a full fair comparison. We found these results slightly surprising as well. Therefore we\u2019ve re-verified the results during the rebuttal period, and found that 100 DDPM outperforms 10 DDPM on Tool Hang, and performs similarly to 10 DDPM on Push-T. \n\nPolishing: Thank you for your valuable suggestions. We will polish the writing accordingly and clarify the captions for the final version. \n\nAblations: We added ablation studies for the Push-T task in the supplementary rebuttal PDF (Section C.1), in addition to the ablation study on the Tool-Hang task reported in the paper. The DDIM ablation on Push-T shows that the reward is not very sensitive to the ratio of DDIM-deblending steps, unlike the MSE. The perturbation ablation on the Push-T verifies the observation we made based on the Tool-Hang ablations \u2013 that there is no benefit in adding gaussian perturbation to the DDIM approximation. \nAdditionally, we\u2019ve added ablations on the PHYRE dataset with $DDIM_n$ initialization in the supplementary rebuttal PDF (Section B.1). $DDIM_n$ Initialization in the video prediction domain is inferior to history-based initialization, and the initial approximation accuracy is important as there is a significant difference in the results of initializing with $DDIM_2$ or $DDIM_3$.\n\nReferences:\n\n[1] Zhaoyang Lyu, Xudong Xu, Ceyuan Yang, Dahua Lin, and Bo Dai. Accelerating diffusion models via early stop of the diffusion process. arXiv preprint arXiv:2205.12524, 2022."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700437980972,
                "cdate": 1700437980972,
                "tmdate": 1700437980972,
                "mdate": 1700437980972,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Mi8O5St5bB",
                "forum": "iKd99CYwPX",
                "replyto": "jgA0HW49X7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3549/Reviewer_HtfP"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3549/Reviewer_HtfP"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "Thank you for the clarifications in your rebuttal, and for the additional baselines. I think this is a good inclusion and strengthens the paper. I still have significant reservations about the importance of the contribution and paper clarity (eg. as pointed out by Reviewer eaWM - I do not think this paper can be understood with reading Heitz et al. as it stands)"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700650862612,
                "cdate": 1700650862612,
                "tmdate": 1700650862612,
                "mdate": 1700650862612,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7W92nR2VAe",
            "forum": "iKd99CYwPX",
            "replyto": "iKd99CYwPX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3549/Reviewer_1n8o"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3549/Reviewer_1n8o"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors aim to expedite inference by leveraging the properties of the sequence prediction task."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The authors extend the iterative \u03b1-(de)blending approach, applying it to sequential tasks\n2. The model shows improved NFE at inference time"
                },
                "weaknesses": {
                    "value": "1. While the authors' effort to extend a proposed diffusion model to a conditional or sequential generation task is commendable, it lacks a significant degree of innovation. The work does not present any new insights or methods, nor does it offer any architectural advancements that could potentially enhance the performance of conditional generation. The novelty factor of this study could be improved with the introduction of unique approaches or methodologies.\n\n2. The iterative \u03b1-(de)blending method utilized in this research appears to bear a close resemblance to the rectified flow, as detailed in this [paper](https://arxiv.org/pdf/2209.03003.pdf). An important opportunity seems to have been missed by the authors in not acknowledging this significant work. A thorough review of related literature is crucial in any research endeavor to avoid overlooking key contributions in the field.\n\n3. The concept of selecting an appropriate source or prior distribution is indeed valuable. However, it's worth noting that a similar discussion has already been conducted in [PriorGrad](https://openreview.net/pdf?id=_BNiN4IjC5). Furthermore, other methods from VAE research such as [SVG-LP](https://arxiv.org/pdf/1802.07687.pdf) provide more straightforward approaches to learning a source distribution. It is essential to acknowledge these existing methods and differentiate the new work from them.\n\n4. The study's comparative analysis is somewhat lacking, with only DDPM and DDIM used as baseline samplers. The field has seen numerous new samplers designed to enhance sampling speed, such as rectified flow, [DPM-solver](https://arxiv.org/abs/2206.00927), and [Karras et al. 2022](https://arxiv.org/pdf/2206.00364.pdf). It is not necessary to compare the new model with all existing ones, but it would be beneficial to include a broader range of models in the comparison to provide a more comprehensive evaluation.\n\n5. In terms of video prediction, the study could benefit from the inclusion of at least one higher-resolution dataset. A resolution of 128x128 would be sufficient to provide a more challenging and realistic evaluation of the model's performance. This would enable a more robust assessment of the model's capabilities in real-world applications."
                },
                "questions": {
                    "value": "see above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3549/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3549/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3549/Reviewer_1n8o"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3549/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698762116113,
            "cdate": 1698762116113,
            "tmdate": 1700638535146,
            "mdate": 1700638535146,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7QsPrt4m7x",
                "forum": "iKd99CYwPX",
                "replyto": "7W92nR2VAe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3549/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3549/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their suggestions and valuable insights.\n\nNovelty: See our general comment to all reviewers above. \n\nRelated Work:\nRectified flow is indeed a beautiful paper that we were not aware of. Interestingly, it appears that an essentially very similar idea was investigated independently by several authors (Iterative \u03b1-(de)blending [1], Rectified Flow [2], Cold Diffusion [3] and Direct Iteration [4]), with insufficient cross-citations among them, unfortunately. Thank you for pointing out this work and others.  We duly extended our related work section; please refer to the rebuttal PDF (Section D).\n\n\nWe emphasize, however, that our work is complementary to the line of work above - while all said papers investigate how to deterministically map different distributions, NONE OF THEM explore **the choice of the source distribution**, which is the main focus of our research. Our method builds on top of these papers while focusing on sequential settings. We demonstrate the fact that our method is independent of the blending algorithm by running our instructive example experiments (Section 4.2 of the paper) using Rectified Flow. See Section A of the supplementary rebuttal PDF for details.\n\nPriorGrad discusses the importance of the source distribution of the diffusion process in the audio prediction domain. In this work, the authors select the mean and variance of the Gaussian source distribution based on the data. Though they present a novel source distribution, it is still Gaussian and the algorithm is based on the standard diffusion process. In contrast, our approach is based on deterministic denoising models and can start the deblending process from non-Gaussian distributions, eg. $DDIM_n$ in the robotic control tasks, which achieves state-of-the-art results on this domain. Additionally, we focused on different domains - video prediction and robot control - for which it is not clear how to apply the PriorGrad source distribution.   \nSVG-LP explored prior selection for video prediction based on VAE - it is not clear to us how this could be applied to our diffusion-based approach. \nDespite their dissimilarities from our approach, we\u2019ve added both of these papers to the extended related work section; please refer to the supplementary rebuttal PDF (Section D).\n\nBaselines: Thank you again for pointing to additional related work. In the experiments described in the general comment (with results in Sections A and C.2 of the supplementary rebuttal PDF) we address this concern by comparing our algorithm to Rectified Flow, DPM-Solver++ and Consistency Models. Our method outperforms DPM-Solver++ and Consistency Models on the robotic control tasks. \n\n128X128 Resolution video prediction results: We will assess how to extend our evaluation to these datasets - it is not trivial in terms of our available compute resources. Note that our results on the Diffusion Policy domains [5] are state-of-the-art, and evaluated on the most challenging tasks in the original paper.\n\nReferences:\n\n[1] Heitz, Eric, Laurent Belcour, and Thomas Chambon. \"Iterative $\\alpha $-(de) Blending: a Minimalist Deterministic Diffusion Model.\" arXiv preprint arXiv:2305.03486 (2023).\n\n[2] Liu, Xingchao, Chengyue Gong, and Qiang Liu. \"Flow straight and fast: Learning to generate and transfer data with rectified flow.\" arXiv preprint arXiv:2209.03003 (2022).\n\n[3] Bansal, Arpit, et al. \"Cold diffusion: Inverting arbitrary image transforms without noise.\" arXiv preprint arXiv:2208.09392 (2022).\n\n[4] Delbracio, Mauricio, and Peyman Milanfar. \"Inversion by direct iteration: An alternative to denoising diffusion for image restoration.\" arXiv preprint arXiv:2303.11435 (2023).\n\n[5] Cheng Chi, Siyuan Feng, Yilun Du, Zhenjia Xu, Eric Cousineau, Benjamin Burchfiel, and Shuran Song. Diffusion policy: Visuomotor policy learning via action diffusion, 2023."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700437889906,
                "cdate": 1700437889906,
                "tmdate": 1700437889906,
                "mdate": 1700437889906,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1WXUa1iG7A",
                "forum": "iKd99CYwPX",
                "replyto": "7QsPrt4m7x",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3549/Reviewer_1n8o"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3549/Reviewer_1n8o"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "Thank you for your response. While your answer has addressed some of my concerns, there remain significant issues that prevent me from endorsing the paper for acceptance. I have adjusted my recommendation to \"weakly reject\" with the following considerations in mind:\n\n1. The paper would benefit from a more rigorous exploration of video prediction. Given that the authors assert the efficacy of their method in the context of video diffusion, it is imperative that additional experiments be conducted with more challenging datasets, such as the [Cityscapes dataset](https://www.cityscapes-dataset.com/). This would not only strengthen the current claims but also demonstrate the model's robustness and versatility.\n\n2. The selection of the source distribution appears to have notable limitations:\n    - The history-based approach is quite simplistic, relying on a perturbed version of the previous frame for initialization. This method overlooks the dynamics and trajectory inherent in the video history. The perturbation, derived from a standard Gaussian devoid of contextual relevance, could lead to inconsistencies in subsequent predictions. This issue might be exacerbated with more complex datasets. A potential improvement could be integrating techniques from models like SVG-LP, which learns a conditional prior in the context of the data. This learned prior may enhance the perturbation process.\n    - The DDIM-based approach's reliance on an additional pretrained model raises questions about its suitability as a comparable method, especially when compared to other ODE/SDE solvers that do not require such dependencies.\n\n3. The inclusion of non-diffusion methods as additional baselines is crucial. This is particularly pertinent for applications like robot control, where the inherent latency of diffusion models is still considerable when compared to one-step models like VAEs. The paper should provide compelling results that demonstrate the diffusion model's superiority or competitive performance in scenarios where latency is a less critical factor."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3549/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700638519180,
                "cdate": 1700638519180,
                "tmdate": 1700638519180,
                "mdate": 1700638519180,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]