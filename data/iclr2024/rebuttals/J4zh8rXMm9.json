[
    {
        "title": "Flashback: Understanding and Mitigating Forgetting in Federated Learning"
    },
    {
        "review": {
            "id": "1wig1Eswrr",
            "forum": "J4zh8rXMm9",
            "replyto": "J4zh8rXMm9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8786/Reviewer_LiW6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8786/Reviewer_LiW6"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates the catastrophic forgetting issue in FL that occurs in both local training and server aggregation. It provides empirical analysis and insights into the forgetting issue and introduces a new method to mitigate this forgetting issue. The proposed method achieves much better convergence than the compared counterparts."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The forgetting issue in FL is important and the analysis and the introduced method are technically sound.\n- The proposed method achieves much better convergence than the compared counterparts.\n- The paper is generally well-written and easy to follow."
                },
                "weaknesses": {
                    "value": "- Some experimental details seem to be missing. e.g., what is the public dataset that is used for experiments on CIFAR, CINIC, and FEMNIST?\n- The comparison with other methods may not be fair as the proposed method leverages a shared public dataset in the server while compared methods may not use it. Some papers on FL and KD also use a public dataset.  e.g., [1][2].\n    - [1] Ensemble distillation for robust model fusion in federated learning. NeurIPS\u201920\n    - [2] Performance optimization of federated person re-identification via benchmark analysis. ACMMM\u201920\n- A straightforward baseline to consider is fine-tuning with the public dataset in the server, using soft labels from clients or ground truth labels. It would provide more insights into the significance of the proposed method. The reviewer would consider raising the rating if some of the concerns can be addressed."
                },
                "questions": {
                    "value": "- What is the impact of different selection choices of public datasets? Would the method still work if the data distribution of the public dataset is different from the client\u2019s data distribution?\n- What is the backbone used to train CIFAR and CINIC datasets? Is the method robust across different backbones?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8786/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8786/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8786/Reviewer_LiW6"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8786/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698556084059,
            "cdate": 1698556084059,
            "tmdate": 1699637104094,
            "mdate": 1699637104094,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "OynBuYh1nb",
                "forum": "J4zh8rXMm9",
                "replyto": "1wig1Eswrr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8786/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank the reviewer for their time and effort, and appreciate all of their feedback!\n\n\n## Weaknesses\n\n- Some experimental details seem to be missing. e.g., what is the public dataset that is used for experiments on CIFAR, CINIC, and FEMNIST?\n    - We kindly refer the reviewer to section 5.1 and B.1 in the appendix.\n- The comparison with other methods may not be fair as the proposed method leverages a shared public dataset in the server while compared methods may not use it. Some papers on FL and KD also use a public dataset. e.g., [1][2].\n    - This is a valid concern. Indeed, for this reason we compare with [1]. Moreover, FedDF [1] uses the all of CIFAR100 as the public dataset, when experimenting with CIFAR10, while we only use 2.5% of CIFAR10 as the public dataset, and use the remaining 97.5% for the clients. This is a much smaller public dataset.\n- A straightforward baseline to consider is fine-tuning with the public dataset in the server, using soft labels from clients or ground truth labels. It would provide more insights into the significance of the proposed method. The reviewer would consider raising the rating if some of the concerns can be addressed.\n    - This a very good suggestion, we will add such an experiment in the revised manuscript.\n\n## Questions\n\n- What is the impact of different selection choices of public datasets? Would the method still work if the data distribution of the public dataset is different from the client\u2019s data distribution?\n    - We experimented with a very small public dataset, we would report on additional experiments to answer this question in the revised manuscript.\n- What is the backbone used to train CIFAR and CINIC datasets? Is the method robust across different backbones?\n    - We use the same backbone across all the datasets (CIFAR, CINIC, and FEMNIST), and we expect the method to be general across different model architectures. We will do additional experiments to verify the robustness of our method across models."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700222587607,
                "cdate": 1700222587607,
                "tmdate": 1700222587607,
                "mdate": 1700222587607,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "9lhydniwnc",
                "forum": "J4zh8rXMm9",
                "replyto": "OynBuYh1nb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8786/Reviewer_LiW6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8786/Reviewer_LiW6"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "Thank you for addressing some of the reviewer's concerns. \n\nApart from the replies that promise to add new experiments, the reviewer still has a concern about the comparison with FedDF. Although FedDF uses the whole CIFAR100 as a public dataset, the proposed method uses a small fraction of CIFAR10, which is the same dataset as the testing data. It would be more convincing if FedDF also used the CIFAR10 dataset as the public dataset."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700370160155,
                "cdate": 1700370160155,
                "tmdate": 1700370160155,
                "mdate": 1700370160155,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CHujviE8wu",
                "forum": "J4zh8rXMm9",
                "replyto": "1wig1Eswrr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8786/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the reply!\n\nApologies for the confusion I caused by my comment. [1] in their own experiments, they used CIFAR100 as the public dataset, when training on CIFAR10. In our experiments, we used the same public dataset for all the methods that use a public dataset. So for both Flashback and FedDF [1] we used the exact same small fraction of CIFAR10 as the public dataset."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700375214874,
                "cdate": 1700375214874,
                "tmdate": 1700375761765,
                "mdate": 1700375761765,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Z94QhhEd8I",
            "forum": "J4zh8rXMm9",
            "replyto": "J4zh8rXMm9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8786/Reviewer_VJec"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8786/Reviewer_VJec"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the problem of forgetting in FL. Specifically, they show that several standard federated optimization methods can fail in high-heterogeneity settings due to local and global forgetting, which respectively occur during client training and server aggregation. To address this, the authors use distillation at both the server and client during FL. At the server, they distill an ensemble of models from client fine-tuning and the previous server round into a new server model. At the client, they distill the initial (l.e. server) model into the fine-tuned model. The distillation additionally weights the logits based on (aggregated) client label counts."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper makes an interesting point about how prior works focus on making either the global or local step robust but fail to consider both. \n\nThe method outperforms a variety of baselines which use regularization / distillation."
                },
                "weaknesses": {
                    "value": "Please closely examine the claim in Discussion 5.1 about related work. Li et al. 2020 (FedProx) makes no assumptions about public server-side data.\n\nIt would be good if you can include an ablation on using distillation only at the server / clients. The paper claims (page 4, above Fig.2) \"Moreover, local forgetting and global forgetting are intertwined, which means addressing the issue at only one of the phases will not be sufficient, since it will happen at the next phase, and therefore have a cascading effect into the same phase at the next round.\" \nI think this statement intuitively makes sense but it could use more support.\n\nMore generally, an ablation on various components of Flashback would be helpful. Relative to FedDF there are a lot of things going on, i.e. including the previous round teacher, weighting the logits, and local distillation. Based on the story of the paper I would expect adding local distillation to be the most important factor.\n\nFigure 2 would be more helpful if you use the same initial model for all methods. Also consider only showing one row of methods."
                },
                "questions": {
                    "value": "FedDF reports very high numbers on CIFAR10 (Table 1 in https://proceedings.neurips.cc/paper_files/paper/2020/file/18df51b97ccd68128e994804f3eccc87-Paper.pdf). Was the evaluation of FedDF too limited? Why can they reach up to 75% in those experiments?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8786/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8786/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8786/Reviewer_VJec"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8786/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698717615886,
            "cdate": 1698717615886,
            "tmdate": 1699637103990,
            "mdate": 1699637103990,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "19UmxjU8jQ",
                "forum": "J4zh8rXMm9",
                "replyto": "Z94QhhEd8I",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8786/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank the reviewer for their time and effort, and appreciate all of their feedback!\n\n## Weaknesses\n\n- Please closely examine the claim in Discussion 5.1 about related work. Li et al. 2020 (FedProx) makes no assumptions about public server-side data.\n    - Thanks for the observation this is a mistake on our part, indeed FedProx does not assume or use a public dataset, we will fix this typo in the revised manuscript.\n- It would be good if you can include an ablation on using distillation only at the server / clients. The paper claims (page 4, above Fig.2) \"Moreover, local forgetting and global forgetting are intertwined, which means addressing the issue at only one of the phases will not be sufficient, since it will happen at the next phase, and therefore have a cascading effect into the same phase at the next round.\" I think this statement intuitively makes sense but it could use more support.\n    - Indeed we have done further experiments that explore this question, the experimental results do support our statement. We will add this experiment to the revised manuscript.\n- More generally, an ablation on various components of Flashback would be helpful. Relative to FedDF there are a lot of things going on, i.e. including the previous round teacher, weighting the logits, and local distillation. Based on the story of the paper I would expect adding local distillation to be the most important factor.\n    - Yes the combination of doing distillation at both ends of the FL algorithm is an important to addressing forgetting, we will add additional experiments in the revised manuscript that explore the necessity of the additional components of Flashback.\n- Figure 2 would be more helpful if you use the same initial model for all methods. Also, consider only showing one row of methods.\n    - Thanks for the feedback. Indeed, in our methodology we start with the same initial weights, and we deterministically fix the data partitioning and the selected clients for all the methods. We will update the text to reflect this setup.\n\n## Questions\n\n- FedDF reports very high numbers on CIFAR10 (Table 1 in\u00a0https://proceedings.neurips.cc/paper_files/paper/2020/file/18df51b97ccd68128e994804f3eccc87-Paper.pdf). Was the evaluation of FedDF too limited? Why can they reach up to 75% in those experiments?\n    - In FedDF they have a different experimental setup, one of the biggest differences is the number of clients in the experiment, they experiment with only 20 clients for table 1."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700222490730,
                "cdate": 1700222490730,
                "tmdate": 1700222490730,
                "mdate": 1700222490730,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hcRKtC8Kqd",
            "forum": "J4zh8rXMm9",
            "replyto": "J4zh8rXMm9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8786/Reviewer_eqJf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8786/Reviewer_eqJf"
            ],
            "content": {
                "summary": {
                    "value": "The paper targets the problem of data heterogeneity in the federated setting. The authors introduce two sources of performance degradation in non-iid settings: local forgetting and global forgetting. To mitigate the forgettings, they propose FLASHBACK, which employs weighted knowledge distillation on the client and server sides. Clients use the global model as their teacher, and the server uses all the new updates + the last round model as a set of teachers."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "* The evaluations show the superiority of FLASHBACK.\n* The evaluations are comprehensive on different metrics.\n* Using the global/local forgettings improves the understanding of the underlying problem in heterogenous FL, and it should be considered in this area as well."
                },
                "weaknesses": {
                    "value": "* The paper assumes that the distribution of the public data is the same as training data (public data is a part of the original dataset). In other words, in the experiments, representative public data is available, which does not usually happen in reality.\n* It is unclear if the other baseline methods benefit from the public dataset. Their performance can improve if the server can train on the centralized public dataset as well. \n* The algorithm has two parts: local and global KD. An ablation study on each part needs to be included.\n* Using KD in the clients and server and forgetting in federated learning is not new. Plenty of previous works, such as [1], use KD in client and server to mitigate forgetting.\n* Sharing label information with the server is not privacy-preserving.\n\n[1] Ma, Yuhang, et al. \"Continual federated learning based on knowledge distillation.\" IJCAI 2022."
                },
                "questions": {
                    "value": "* How does your method work on more complex datasets or models?\n* How does your paper compare with the federated continual learning papers? \n* Please check out the weakness section for the rest of the questions."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8786/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8786/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8786/Reviewer_eqJf"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8786/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698720697603,
            "cdate": 1698720697603,
            "tmdate": 1699637103879,
            "mdate": 1699637103879,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YwP64rTQAg",
                "forum": "J4zh8rXMm9",
                "replyto": "hcRKtC8Kqd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8786/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank the reviewer for their time and effort, and appreciate all of their feedback!\n\n## Weaknesses\n\n- The paper assumes that the distribution of the public data is the same as training data (public data is a part of the original dataset). In other words, in the experiments, representative public data is available, which does not usually happen in reality.\n    - Response: Addressed in a shared response about the public dataset.\n- It is unclear if the other baseline methods benefit from the public dataset. Their performance can improve if the server can train on the centralized public dataset as well.\n    - Response: We include a comparison against FedDF, which uses a public dataset. FedDF has poorer performance compared to some other baselines (see Figure 3). This indicates that using a public dataset doesn\u2019t necessarily give a performance boost.\n- The algorithm has two parts: local and global KD. An ablation study on each part needs to be included.\n    - Response: We did an additional experiment that explored this question, and we found out that, using both is necessary. And doing KD on one side only doesn\u2019t yield a good performance and training stability. This is experiment will be included in the revised manuscript. Check this image for the result: https://ibb.co/sWdp6JQ\n    \n \n    \n- Using KD in the clients and server and forgetting in federated learning is not new. Plenty of previous works, such as [1], use KD in client and server to mitigate forgetting.\n    - Response: We agree with the reviewer that using KD in FL and forgetting problems are not new. However, the perspective about forgetting and FL and the deeper analysis of forgetting in FL is a new contribution. Moreover, the continual federated learning addresses a different forgetting problem that mainly stems from the change of tasks, exactly like continual learning; however, in our work, we show that forgetting as a stand-alone problem in deep learning, does occur in the federated learning setup. We kindly ask the reviewer to refer to section 3 of the paper, where our analysis of forgetting in FL is new and novel.\n\n## Questions\n\n- How does your method work on more complex datasets or models?\n    - Response: We do use the standard models and datasets used in the literature. It is an interesting question that we could answer as an additional result but is not necessary to support the validity of Flashback.\n- How does your paper compare with the federated continual learning papers?\n    - Response: In Flashback we do not tackle continual learning at all. However, since federated continual learning does training on one task at a time, that specific training on each individual task can be seen as a standard FL training, therefore, the observations we discussed in our paper regarding forgetting apply during the training of the tasks in federated continual learning. Perhaps if the reviewer has a more specific question, we can address and discuss the comparison of our work and federated continual learning.\n- Please check out the weakness section for the rest of the questions.\n    - Response: Addressed"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700222449785,
                "cdate": 1700222449785,
                "tmdate": 1700222449785,
                "mdate": 1700222449785,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "CQm9iM6n97",
            "forum": "J4zh8rXMm9",
            "replyto": "J4zh8rXMm9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8786/Reviewer_YZyz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8786/Reviewer_YZyz"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the problem of forgetting in federated learning, particularly in contexts where statistical heterogeneity across clients in high. To do this, the manuscript proposes a new metric to measure forgetting both at the client level (after local updates) and at the the global level (after aggregation at the server), and a method to alleviate this phenomenon by further distilling the knowledge of the local models plus the last round's model. Results are presented on three benchmark datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- The problem of forgetting in federated learning is important and timely. \n- The paper is presented in such a way that it builds upon simple ideas that are intuitive and easy to follow. \n- The use of distillation to mitigate forgetting seems natural given the connections of distillation to predictive churn [1]. \n\n[1] Jiang, H., Narasimhan, H., Bahri, D., Cotter, A., & Rostamizadeh, A. (2021, October). Churn Reduction via Distillation. In International Conference on Learning Representations."
                },
                "weaknesses": {
                    "value": "- One of the stated contributions of the paper is to \"show how and where forgetting happens in FL\". I'm not convinced this question is answered by the manuscript. In particular, only two possible causes are explored: local training and server aggregation. Other possible factors are not considered, e.g., the ordering of the clients, the ordering of the data in the clients [2]. I believe the manuscript should be more specific in this statement or, hopefully, perform a more systematic exploration of what really affects forgetting in FL.  \n- In the same line, the paper defines, measures and tests local forgetting. Later on, it concludes that some amount of it is necessary for learning. This conclusion is valuable, but this nuance is not reflected in the introduction nor in the motivation of the manuscript. \n- There is little discussion of the public data used by the algorithm until Section 5.1. Even then, I am left with questions regarding how it can affect the forgetting behavior. What distribution does this data need to be drawn from? Can it exacerbate forgetting if drawn from the wrong distribution?\n- I am surprised that several baselines did not converge for FEMNIST in Table 1. This is a fairly simple benchmark that should achieve good performance with a CNN. \n\n[2] Toneva, M., Sordoni, A., des Combes, R. T., Trischler, A., Bengio, Y., & Gordon, G. J. (2018, September). An Empirical Study of Example Forgetting during Deep Neural Network Learning. In International Conference on Learning Representations."
                },
                "questions": {
                    "value": "- I found Figures 2 and 5 confusing. I'm not sure what the colors refer to, and why Flashback is performing better according to these figures. Please clarify. \n- In line with the connections between distillation and algorithmic churn, and with other possible causes of forgetting, future versions of the manuscript would benefit from studying forgetting at the example level (see [2]) for a given test dataset at the server."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8786/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8786/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8786/Reviewer_YZyz"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8786/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699374969455,
            "cdate": 1699374969455,
            "tmdate": 1699637103778,
            "mdate": 1699637103778,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jKBAZ1mDqh",
                "forum": "J4zh8rXMm9",
                "replyto": "CQm9iM6n97",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8786/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank the reviewer for their time and effort, and appreciate all of their feedback!\n\n## Weaknesses\n\n- One of the stated contributions of the paper is to \"show how and where forgetting happens in FL\". I'm not convinced this question is answered by the manuscript. In particular, only two possible causes are explored: local training and server aggregation. Other possible factors are not considered, e.g., the ordering of the clients, the ordering of the data in the clients [2]. I believe the manuscript should be more specific in this statement or, hopefully, perform a more systematic exploration of what really affects forgetting in FL.\n    - *Response*: That is a very interesting point, and can be an additional dimension of exploring forgetting in FL. However, we believe that the first example is implicitly included in the **server forgetting,** where generally given a random order of clients of the rounds forgetting would occur, therefore, constructing a difficult ordering of clients will make the **server forgetting** more severe. This is not to say that this specific example does not need to be studied but to say that our characterization is more general. As an additional supporting material, we will update the manuscript to make this clear and potentially include experiments for other possible causes of forgetting.  We would appreciate it if the reviewer could give advice on how such an experiment can be set up. Regarding the 2nd example, client-local training essentially is a single training process of a deep learning model, therefore, any possible forgetting in a deep learning training can happen during the client local training, which makes it not specific to the intricacy of FL.\n- In the same line, the paper defines, measures and tests local forgetting. Later on, it concludes that some amount of it is necessary for learning. This conclusion is valuable, but this nuance is not reflected in the introduction nor in the motivation of the manuscript.\n    - Thank you for this feedback, we will improve the manuscript, to reflect that.\n- There is little discussion of the public data used by the algorithm until Section 5.1. Even then, I am left with questions regarding how it can affect the forgetting behavior. What distribution does this data need to be drawn from? Can it exacerbate forgetting if drawn from the wrong distribution?\n    - *Response:* Addressed in shared response\n- I am surprised that several baselines did not converge for FEMNIST in Table 1. This is a fairly simple benchmark that should achieve good performance with a CNN.\n    - *Response*: We found that in general FL experiments are tricky and very sensitive to the experiment setup, such as client selection, and number of clients. Can you please refer us to similar experiments with the same setup, where FL algorithms converged to better results?\n\n## Questions\n\n- I found Figures 2 and 5 confusing. I'm not sure what the colors refer to, and why Flashback is performing better according to these figures. Please clarify.\n    - Response: The green color is to distinguish Flashback from the other baselines. The intensity of the color in the heatmap reflects the accuracy. Flashback is performing better in Figure 2 because it shows less drop in accuracy (forgetting) from the first row (global model at round t-1) to the rows in the middle, which represents the accuracy of the clients that participated after their local training. Furthermore, from the rows in the middle to the last row (global model at round t) Flashback shows better aggregation results, with less forgetting than the other baselines.\n    As for Figure 5, we show that Flashback is more consistent across rounds because it has fewer drops of accuracies of the global model per-class accuracy over all the rounds, which indicates forgetting. Thanks for the feedback, we will revise the figure and update the figures for more clarity in the revised manuscript\n- In line with the connections between distillation and algorithmic churn, and with other possible causes of forgetting, future versions of the manuscript would benefit from studying forgetting at the example level (see [2]) for a given test dataset at the server.\n    - Response: That is a good suggestion thanks. But can the reviewer please clarify the question here?"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700222090886,
                "cdate": 1700222090886,
                "tmdate": 1700222090886,
                "mdate": 1700222090886,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]