[
    {
        "title": "Efficient Detection of LLM-generated Texts with a Bayesian Surrogate Model"
    },
    {
        "review": {
            "id": "JC2O2RiRfU",
            "forum": "GRlKzhHl9Z",
            "replyto": "GRlKzhHl9Z",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3826/Reviewer_2wLg"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3826/Reviewer_2wLg"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes using a surrogate to replace the true scoring function $p_{\\theta}(\\mathbf{x})$ for an LLM, due to the high cost of querying the score of a text message $\\mathbf{x}$ through the LLM. The authors construct the surrogate function using the Gaussian process and a kernel function that based on the BertScore. The simulations exhibits performance gain for the proposed method over the baseline with the same number of queries."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "**originality**\\\nTo the best of my knowledge, constructing a surrogate to replace the true score function for LLM to save the expense of LLM queries is novel to me. \n\n**quality**\\\nThe proposed method is simple and straightforward, which is an upside to me. However, there are couple of points that further support the proposed method missing. I will elaborate on those points in the weakness section. \n\n**clarity**\\\nThe paper's presentation is quite clear. \n\n**significance**\\\nIt is significant to propose a method that can reduce the expense of LLM query while maintain high prediction performance for the detection of LLM-generated texts."
                },
                "weaknesses": {
                    "value": "1. The paper establish a scenario that querying LLM is expensive; however, it seems constructing the kernel function with BertScore needs also needs to querying the LLM extensively, and that seems also expensive.\n2. One point has not been discussed is the variance of the $ \\log p_{\\theta} (\\tilde{\\mathbf{X}})$  (also please use uppercase letter to denote the random variable for the mathematical rigorousness). The proposed method replaces $ \\log p_{\\theta} (\\tilde{\\mathbf{X}})$ with a a surrogate function $f$, such that numerous text examples can be used to get the empirical estimation of $E\\left[f\\left(\\tilde{\\mathbf{X}}\\right)\\right]$. On one hand, the variance of such an empirical estimation would be reduced as surrogate function $f$ can be inexpensively accessed; on the other hand, there is bias between $E\\left[ \\log p_{\\theta} (\\tilde{\\mathbf{X}})\\right]$ and $E\\left[f\\left(\\tilde{\\mathbf{X}}\\right)\\right]$. I was hoping to see the analysis of the impact of the variance and bias on the performance of the method, but failed to found them in both methodology and experimental sections."
                },
                "questions": {
                    "value": "Please see the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3826/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698348054250,
            "cdate": 1698348054250,
            "tmdate": 1699636340285,
            "mdate": 1699636340285,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UYc9K1c7r7",
                "forum": "GRlKzhHl9Z",
                "replyto": "JC2O2RiRfU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3826/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3826/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 2wLg"
                    },
                    "comment": {
                        "value": "Thank you for your valuable and comprehensive review. Below we address the detailed comments and hope that you may find our response satisfactory and raise your score.\n\n**Question 1: Constructing the kernel function with BertScore needs also needs to querying the LLM extensively, and that seems also expensive.**\n\nWe respectfully clarify that the numbers of parameters and FLOPs of BERT-base used for calculating BERTScore are 0.11B and $2.9\\*10^{10}$ FLOPs, whereas the GPT-2 for calculating $\\log p$ have 1.5B parameters and $3.4\\*10^{12}$ FLOPs, and the LLaMA for calculating $\\log p$ have 65B parameters and $6\\.6*10^{13}$ FLOPs.\n\nTherefore, the query cost of BERTScore is comparatively negligible in the pipeline. \n\n**Question 2:  Hoping to see the analysis of the impact of the variance and bias on the performance of the method.**\n\nThanks for the constructive comment. \n\nThe probabilistic density function $p_\\theta$ is **deterministic**. Thus, the mentioned \u201cvariance of the $\\log p_\\theta$\u201d must be w.r.t. the perturbation distribution $q$. However, as detailed in (Mitchell et al., 2023), only $E_{q(x)} [\\log p_\\theta (x)]$ connects to the probabilistic curvature, the variance $Var_{q(x)}[\\log p_\\theta (x)]$ is meaningless.\n\nInstead, as suggested by the reviewer, we should care about the variance of **the empirical estimates** of $E_{q(x)} [\\log p_\\theta (x)]$ and $E_{q(x)} [f(x)]$. For the former, the randomness stems from the data sampling process, and its effect is reflected by the error bars in Figure 2. For the latter, the randomness mainly stems from the samples used to assess $f$ at last, because the typical samples are identified in a nearly deterministic way (except for the initialization). As we use 200 samples to assess $f$, the variance caused by this part is minimal.\n\nTo evaluate the bias between $E_{q(x)} [\\log p_\\theta (x)]$ and $E_{q(x)} [f(x)]$, we can regard our current estimation of $E_{q(x)} [f(x)]$ using 200 samples as accurate and also use 200 samples to estimate $E_{q(x)} [\\log p_\\theta (x)]$. In our experience, the latter can usually lead to a detection AUROC of more than 98%. In comparison, the detection AUROC of the former with only 10 queries to the source LLM is less than 96%. Thus, the bias is significant. However, it is certain that we can reduce such a bias by incorporating more queries to the source LLMs for $E_{q(x)} [f(x)]$. This is echoed by the results in Section 4.1: once including enough queries, using $E_{q(x)} [f(x)]$ can catch up with the performance of using $E_{q(x)} [\\log p_\\theta (x)]$."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3826/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700213666175,
                "cdate": 1700213666175,
                "tmdate": 1700213666175,
                "mdate": 1700213666175,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "F14EDZGLqc",
                "forum": "GRlKzhHl9Z",
                "replyto": "UYc9K1c7r7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3826/Reviewer_2wLg"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3826/Reviewer_2wLg"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your reply. Maybe I didn't make my point clearly. For the variance, I meant the variance of $\\frac{1}{N}\\sum_{i=1}^Nf(\\mathbf{X}_i)$,  \n\nwhere $f$ is the regression function used to model $\\log p_{\\theta}$. I do think it is possible to give a quantitative analysis of the variance and the bias of $\\frac{1}{N}\\sum_{i=1}^Nf(\\mathbf{X}_i)$, which can benefit the further understanding of the method."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3826/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700612677005,
                "cdate": 1700612677005,
                "tmdate": 1700612677005,
                "mdate": 1700612677005,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0UwHNXR7JO",
                "forum": "GRlKzhHl9Z",
                "replyto": "JC2O2RiRfU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3826/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3826/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Further reply"
                    },
                    "comment": {
                        "value": "Thanks for your further clarification. We make the following comments:\n\n1) **Variance of $\\frac{1}{N}\\sum_{i=1}^N f(X_i)$.** \n\nIt is minimal as we set $N=200$ (i.e., use 200 rephrased texts around the original text to compute an average score). We have performed an empirical study regarding this. Using the setting corresponding to the results in Figure 2a, at the query time of 16 for estimating $f$, we compute the variance of $\\frac{1}{N}\\sum_{i=1}^N f(X_i)$ over 3 runs for 5 randomly selected texts from the dataset and obtain 0.0006, 0.0003, 0.0011, 0.0013, and 0.0011. In comparison, the mean of $\\frac{1}{N}\\sum_{i=1}^N f(X_i)$ is -2.2376, -2.5655, -2.4450, -2.2474, and -2.5945 respectively. As demonstrated, the mean is orders of magnitude larger than the variance. We will add more detailed results in the revision. \n\n2) **Bias of $\\frac{1}{N}\\sum_{i=1}^N f(X_i)$.** \n\nAs $\\frac{1}{N}\\sum_{i=1}^N f(X_i)$ is an unbiased estimator of $\\mathbb{E}_{q(x)} f(x)$, we speculate the mentioned bias corresponds to the gap between \n\n$\\frac{1}{N} \\sum_{i=1}^N f(X_i) $ and $ \\frac{1}{N}\\sum_{i=1}^N \\log p_\\theta (X_i) $. \n\nIn our experience, using $200$ samples to estimate the latter usually leads to a detection AUROC of more than 98%. In comparison, the detection AUROC of the former with 10 queries to the source LLM $p_\\theta$ for estimating $f$ is less than 96%. Thus, the bias is significant. However, it is certain that we can reduce such a bias by incorporating more queries to the source LLMs for estimating the function $f$. This is echoed by the results in Section 4.1: once including enough queries for estimating $f$, using $\\frac{1}{N} \\sum_{i=1}^N f(X_i) $ can catch up with the performance of using $\\frac{1}{N}\\sum_{i=1}^N \\log p_\\theta (X_i) $."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3826/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700627094990,
                "cdate": 1700627094990,
                "tmdate": 1700627282353,
                "mdate": 1700627282353,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "AO32yFPJU8",
            "forum": "GRlKzhHl9Z",
            "replyto": "GRlKzhHl9Z",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3826/Reviewer_59P9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3826/Reviewer_59P9"
            ],
            "content": {
                "summary": {
                    "value": "This paper aims to address the query inefficiency of methods that detect machine-generated text from Large Language Models (LLMs) by proposing a novel approach that utilizes a Bayesian surrogate model. The proposed approach uses a Gaussian Process model and enhances query efficiency by selecting typical samples based on Bayesian uncertainty and then interpolating scores to other samples."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The proposed approach is quite intuitive and is a relevant step in improving the DetectGPT model proposed previously for detecting LLM generated text.\n- The experimental results are conducted on three different datasets as well as in the more realistic setting when there is a mismatch in the source model LLM and the LLM used for detection.\n- I appreciate the detailed description of the approach and all the choices made in designing it."
                },
                "weaknesses": {
                    "value": "- The biggest drawback of the paper for me is the *evaluation*. I feel that the current evaluation is lacking in many aspects and feels incomplete:\n    - **Limited Open-Source LLMs Considered**: First, only 2 LLMs are utilized, one of which is GPT-2, which is more than 4 years old. The other model used is Llama-1 (65B), although the Llama-2 sets of models have been released for quite some time now. Since there are a number of different open-source LLMs (for obtaining logits in the white-box setting) available with different parameter sizes, the authors should undertake a comprehensive evaluation across many more LLMs: for example, Llama-2, Guanaco, Vicuna, Falcon, MPT, ChatGLM, etc. Even for the experiments of Section 4.3, only smaller models such as GPT-J and GPT-Neo are used. Considering only 2 models (one of which is GPT-2) is not sufficient for evaluation of current performance of the proposed method.\n    - **Trends With Respect to Parameter Size**: An obvious question to ask is (irrespective of query size), as the models considered have an increasing number of parameters, does the proposed method become less efficacious? Compared to DetectGPT, how many queries would be required to successfully detect text generated by a more advanced model such as Llama2-70B? I believe the authors could undertake these experiments given that for a number of LLMs (such as Llama) different parameter size models are available (7B, 13B, 70B). It would be interesting to observe performance curves for different classes (with respect to size) of LLMs.\n    - **Lack of Analysis on Black-box Models**: I feel that the mismatch setting of Section 4.3 should be further augmented with a black-box setting where state-of-the-art black-box LLMs such as GPT-3.5, GPT-4, PaLM-2, Claude, etc. are analyzed. If the goal of the paper is to truly ensure that LLM generated text is detected, the authors should ideally evaluate on these models via proxy models. As these LLMs are the easiest to use due to a user interface, LLM generated text is most likely to stem from these as sources. It would be beneficial to incorporate some evaluation along these lines.\n    - **Overall Lack of Experimental Rigor**: I find some of the claims made in the paper to be hand-wavy and lacking sufficient rigor. For example, on page 7 (Section 4.1 end), the authors state that even under high query budgets, their approach remains effective and comparable to DetectGPT. However, only the WritingPrompts data is used with GPT-2. To clearly make such a point, more experiments should be conducted over all datasets and all LLMs and presented as a table or figure. Then adequate conclusions can be drawn.\n\n- While a minor issue, the paper has many typos and grammatical errors. I believe the authors should go through the paper and correct these in the revision. For example, page 7: \"bedget\" -> \"budget\", and page 4: \"typicity\" means something unrelated to statistics and ML, etc."
                },
                "questions": {
                    "value": "- Why have the authors not considered more LLMs, especially of different parameter size classes in experiments?\n- Is there any limiting factor for evaluation of black-box LLMs available only via APIs?\n- Please feel free to respond to any of the other weaknesses listed above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3826/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698817157773,
            "cdate": 1698817157773,
            "tmdate": 1699636340165,
            "mdate": 1699636340165,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jmaJTnXrKd",
                "forum": "GRlKzhHl9Z",
                "replyto": "AO32yFPJU8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3826/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3826/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 59P9"
                    },
                    "comment": {
                        "value": "Thank you for your constructive comments. Below we address the detailed comments and hope that you may find our response satisfactory and raise your score.\n\n**Question 1: Limited open-source LLMs considered, lack of trends with respect to parameter size and analysis on black-box models.**\n\nThanks. We first clarify that our existing experiment settings align with DetectGPT (Mitchell et al., 2023). Our current empirical comparisons are fair, having proven our contribution to improving the query efficiency of log-curvature-based LLM-generated text detection. As acknowledged by Reviewer 5xFn, our method \u201cshow clear performance improvements over DetectGPT\u201d, and by Reviewer 2wLg, our method \u201dmaintain high prediction performance\u201d. So, we clarify that the lack of the mentioned experiments is not a fundamental limitation of this paper.\n\nBesides, LLaMA-65B is not a trivial LLM, as shown in ([LLaMA 2 paper](https://arxiv.org/pdf/2307.09288.pdf), Table 3), LLaMA-65B can consistently beat LLaMA 2 of 7B, 13B, and 34B across a series of benchmarks (e.g., Commonsense Reasoning, World Knowledge, Reading Comprehension, Math, MMLU, BBH, AGI Eval). As the community of LLM is developing very rapidly, we don\u2019t have enough energy to catch up with all the recent models and *undertake a comprehensive evaluation across many more LLMs: for example, Llama-2, Guanaco, Vicuna, Falcon, MPT, ChatGLM, etc*. \n\nComparing the results on LLaMA-65B to those on GPT-2, we can see that detecting larger or more advanced models is more challenging for both DetectGPT and our method. This implies that more queries are needed to complete the detection on  LLM with a high parameter size. To further verify these claims, we have started a set of experiments with the series of LLaMA models on the XSum dataset and will offer the corresponding results in subsequent updates (if the running finishes before the end of the rebuttal period) or the final version. \n\nAs for black-box detection, our cross-evaluation is sufficient to demonstrate that our method outperforms DetectGPT in black-box scenarios, using the same setting as the DetectGPT paper. We will experiment with the mentioned API-based black-box models in the next version. \n\n**Question 2: Overall Lack of Experimental Rigor**\n\nWe totally understand your concern. However, we argue that it is just a case study to prove the convergence trend of our method. The main focus of our method is still the low-budget regime, where our results are from multiple random runs and are statistically rigorous. We will revise the paper to clarify this point.\n\n**Question 3: Many typos and grammatical errors**\n\nThanks for pointing out this, and we have revised the paper accordingly."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3826/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700213311009,
                "cdate": 1700213311009,
                "tmdate": 1700214092344,
                "mdate": 1700214092344,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8KsM0F06GP",
                "forum": "GRlKzhHl9Z",
                "replyto": "jmaJTnXrKd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3826/Reviewer_59P9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3826/Reviewer_59P9"
                ],
                "content": {
                    "title": {
                        "value": "Response to Rebuttal"
                    },
                    "comment": {
                        "value": "I would like to express my gratitude to the authors for their rebuttal. However, after going through the response, my concerns largely remain. I provide additional details below:\n\n* Unfortunately, my concerns regarding limited LLMs and other experiments still remain (parameter size analysis and black-box models). Despite using the same experimental set-up as DetectGPT, I believe more experiments are mandated. If the authors provide additional results before the discussion period, I am happy to take another look.\n* Llama-2 has been released for quite some time, and as the work aims to generalize results across LLMs, it is important to analyze recent models. A case in point here is that half the experimental evaluation is localized to GPT-2 which is severly outdated. While I understand the authors might face issues with compute, I believe considering more LLMs (and especially recent and more powerful models) is important to judge the efficacy and usefulness of the work.\n\nGiven the points above, I would like to keep my current score."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3826/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700500218796,
                "cdate": 1700500218796,
                "tmdate": 1700500218796,
                "mdate": 1700500218796,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FpvJ7hag1u",
                "forum": "GRlKzhHl9Z",
                "replyto": "AO32yFPJU8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3826/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3826/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your patience regarding the results of the LLaMA2 series. Below, you will find the results for XSum:\n   \n  |   ||DetectGPT| | |Our method | |\n|---|---|---|---|---|---|---|\n|Query time| 5 | 10 |15 | 5| 10 |15|\n|LLaMA2-7B|0.682|0.719|0.728 |0.704|0.732|0.747|\n|LLaMA2-13B|0.649|0.707 |0.712| 0.664|0.722|0.729|\n|LLaMA2-34B|0.633|0.702|0.708| 0.662|0.715|0.719|\n\nDue to time constraints, we only experimented with up to 15 queries to the source LLM. As shown, both DetectGPT and our method exhibit lower detection AUROC scores as the model size increases. However, our method, using 10 queries, outperforms the DetectGPT baseline using 15 queries. This demonstrates the query efficiency of our method in the LLaMA2 case. It is also worth noting that the LLaMA2 models are indeed more challenging to detect compared to GPT-2.\n\nIn the next version, we will investigate if allocating a higher query budget and employing a stronger perturbation model can yield improved AUROC scores. We will also strengthen our cross evaluation of the black-box models. We thank the reviewer again for the constructive feedback!\n\nBest"
                    },
                    "title": {
                        "value": "Further reply"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3826/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700650778749,
                "cdate": 1700650778749,
                "tmdate": 1700660825325,
                "mdate": 1700660825325,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gxZfnbrS23",
                "forum": "GRlKzhHl9Z",
                "replyto": "AO32yFPJU8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3826/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3826/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for reviewing our paper"
                    },
                    "comment": {
                        "value": "Dear reviewer 59P9,\n\nAs the discussion session draws to a close, we would like to inquire if there are any additional comments or clarifications you would like to make. We are more than willing to provide responses to any inquiries and address any feedback you may have.\n\nThank you for your time and consideration!"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3826/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700708985303,
                "cdate": 1700708985303,
                "tmdate": 1700708985303,
                "mdate": 1700708985303,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ntXV95w7Vp",
                "forum": "GRlKzhHl9Z",
                "replyto": "gxZfnbrS23",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3826/Reviewer_59P9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3826/Reviewer_59P9"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the additional results.\n\n> This demonstrates the query efficiency of our method in the LLaMA2 case. It is also worth noting that the LLaMA2 models are indeed more challenging to detect compared to GPT-2.\n\nWhile I understand, my concern still holds. It seems that the method does not work well against newer LLMs, which will most likely be used more often (for example, I am not sure if GPT-2 is being used that much any more). This creates a mismatch between the detection approaches and LLMs being used, which I find that the current work is unable to resolve satisfactorily."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3826/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700720753430,
                "cdate": 1700720753430,
                "tmdate": 1700720753430,
                "mdate": 1700720753430,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "EX6EnzQmWx",
            "forum": "GRlKzhHl9Z",
            "replyto": "GRlKzhHl9Z",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3826/Reviewer_5xFn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3826/Reviewer_5xFn"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a new approach to use a Gaussian Process (GP) surrogate model to learn the sample distribution of LLM output to effectively sample pertrubations to detect text generated by LLM. THey show that their approach outperforms detectGPT approach in in number of queries needed to effectively detect text. They also show impovements in AUROC."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Simple yet effective approach to identify data generated through LLM.\nShow clear performance improvements over DetectGPT."
                },
                "weaknesses": {
                    "value": "Experiments section lacks other baselines. \nMinor: Some Figure label text in experiments can be improved."
                },
                "questions": {
                    "value": "While the experiments are good, Why not have results similar to Detect GPT? The numbers in their paper and here dont match up.\nWhat is the performance like if you used some other model that is not GP as surrogate?\nDid you look result if you used a encoder model as classifier and trained a bit as its easy to generate the data for this? (May be a bit out of scope. just curious)"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3826/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698817712646,
            "cdate": 1698817712646,
            "tmdate": 1699636340090,
            "mdate": 1699636340090,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "07fXPzPQg3",
                "forum": "GRlKzhHl9Z",
                "replyto": "EX6EnzQmWx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3826/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3826/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 5xFn"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer for the positive feedback and the acknowledgment that our method is simple and effective. Below we address the detailed concerns.\n\n**Question 1: Regarding other baselines**\n\nThanks for the comment. As stated in the first paragraph of Section 4, we mainly compare our method to DetectGPT (Mitchell et al., 2023) because (i) both works adopt the same detection measure (probability curvature), and (ii) DetectGPT has proven to defeat prior zero-shot and supervised methods consistently. We recently noted some concurrent works [1, 2] and will add discussions and/or empirical comparisons with them in the final version. \n\n**References:**\n\n[1]  Guo, Biyang, et al. \"How close is chatgpt to human experts? comparison corpus, evaluation, and detection.\" arXiv preprint arXiv:2301.07597 (2023).\n\n[2]  Bao et al. \u201cFastdetectgpt: Efficient zero-shot detection of machinegenerated text via conditional probability curvature.\u201d arXiv preprint arXiv:2310.05130(2023)\n\n\n**Question 2: Why not have results similar to Detect GPT? The numbers in their paper and here dont match up.**\n\nThanks. As our main contribution is to improve the query efficiency of probability curvature-based detectors like DetectGPT, *we are primarily concerned with detecting under a low query budget* (stated in the first paragraph of Section 4). We also *admit that our method would perform similarly to DetectGPT if queries to the source model can be numerous*. \n\nRegarding the numbers, those in the paper of DetectGPT correspond to a query number of 1000, while those in our paper correspond to 1-15 query times. \n\nThe reported numbers prove that the effectiveness of DetectGPT is significantly reduced at a low query budget, and our method addresses this issue.\n\n**Question 3: What is the performance like if you used some other model that is not GP as surrogate?**\n\nThanks for the suggestion. However, we would like to clarify that the specification of the mentioned *other model* is non-trivial. As stated in Sec 3.3, *the surrogate model f is expected to be trained in the low-data regime while being expressive enough to handle non-trivial local curvature and not prone to overfitting. Additionally, the model should inherently incorporate mechanisms for typical sample selection*. Thus, we choose the GP and speculate that parametric models like NNs may not be applicable here. We will continue to explore other choices, such as neural processes and implicit processes, in future work.\n\n\n**Question 4: Did you look result if you used a encoder model as classifier and trained a bit as its easy to generate the data for this?** \n\nThanks for the question. We would like to clarify some key points: 1) The DetectGPT paper has already demonstrated that the original DetectGPT outperforms the RoBERTa encoder-based classifier. Given our superior performance compared to DetectGPT, it can be inferred that our model would also outperform RoBERTa at higher query numbers. 2) Supervised detectors are often susceptible to biases from training data and entail higher training costs. In contrast, our method can better generalize and is training-free."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3826/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700213165774,
                "cdate": 1700213165774,
                "tmdate": 1700213165774,
                "mdate": 1700213165774,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1no095OQZj",
                "forum": "GRlKzhHl9Z",
                "replyto": "07fXPzPQg3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3826/Reviewer_5xFn"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3826/Reviewer_5xFn"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your response"
                    },
                    "comment": {
                        "value": "THank you for the clarifications. It will be good to include some of these details in the paper. Thanks."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3826/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700734963557,
                "cdate": 1700734963557,
                "tmdate": 1700734963557,
                "mdate": 1700734963557,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]