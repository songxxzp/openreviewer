[
    {
        "title": "Domain constraints improve risk prediction when outcome data is missing"
    },
    {
        "review": {
            "id": "FoM7a5mxGG",
            "forum": "1mNFsbvo2P",
            "replyto": "1mNFsbvo2P",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2049/Reviewer_KKGr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2049/Reviewer_KKGr"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the selective labels problem applied to a healthcare context. Specifically, the paper proposes a Bayesian model for the problem and analyzes a special case of this model to show why two sensible constraints (a prevalence constraint, a human expertise constraint) improves inference. The paper also provides experimental results on synthetic and real data to show the effectiveness of the proposed model."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- The paper is very well-written and easy to follow\n- The proposed model is simple and elegant; the authors do a good job explaining why the Heckman correction model is a special case\n- The theoretical result is reassuring and also helps justify why the two suggested constraints help\n- The experiments are well thought-out and I found the results to be compelling"
                },
                "weaknesses": {
                    "value": "I would like to see a more detailed discussion on how the model generalizes to more complex inputs (basically I'd like a more comprehensive discussion of Section 6's last sentence), especially as I think this is a very practically relevant extension. It would be helpful to understand to what extent the theory could explain this more complex setting (and under what assumptions one might need to additionally impose). It seems like a trivial extension would also be a partially linear model where some features are captured by a linear component and the rest are captured by a neural net.\n\nMinor:\n- Page 2: The text currently reads \"Throughout, we generally refer to $Y_i$ as a binary indicator, but our framework extends to non-binary $Y_i$, and we derive our theoretical results in this setting\" --- I would suggest rewording the last part so that it is clear what \"this setting\" refers to."
                },
                "questions": {
                    "value": "See \"weaknesses\"."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2049/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698766846981,
            "cdate": 1698766846981,
            "tmdate": 1699636136600,
            "mdate": 1699636136600,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4kj0zruEFL",
                "forum": "1mNFsbvo2P",
                "replyto": "FoM7a5mxGG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2049/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2049/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their positive review, and are glad that they found that our paper is well-written and easy to follow, that our model is elegant and simple, that the theoretical results justify why the constraints help parameter estimation, and that the experiments are well thought-out and compelling. We will now address the reviewer\u2019s questions and suggestions for improvement. \n\nThe reviewer first asks how the model generalizes to more complex inputs. To show our constraints are useful with more complex inputs, we ran two additional synthetic experiments. First, we demonstrated applicability to higher-dimensional features (Figure S4). Even after quadrupling the number of features (increasing runtime by a factor of three), both constraints still improve precision and accuracy. Secondly, we evaluate a more complex model with pairwise nonlinear interactions between features (Figure S5). Again both constraints generally improve precision and accuracy. We note our implementation relies on MCMC which is known to be less scalable than approaches like variational inference [1]. However, our approach does not intrinsically rely on MCMC (we are pursuing a follow-up paper investigating alternate approaches to fitting our models).\n\nThen the reviewer states, \u201cA trivial extension would be a partially linear model where some features are captured by a linear component and the rest are captured by a neural net.\u201d We thank the reviewer for this comment and agree that this is a natural direction for future work: for example, the neural net could make a prediction from a mammogram while the linear component incorporates clinical or demographic features. Another option is to use a purely linear model, but include features which are precomputed functions of more complex inputs. Indeed, our current model does this through the \u201cgenetic risk score\u201d feature, capturing each patient's polygenic risk score which is a function of many genetic variants. \n\nFinally, the reviewer suggests that we reword the sentence: \u201cThroughout, we generally refer to $Y_i$ as a binary indicator, but our framework extends to non-binary $Y_i$, and we derive our theoretical results in this setting\u201d to make it more clear what \u201cthis setting\u201d is. We thank the reviewer for this comment and will edit our manuscript to make this more clear. To clarify, we derive our theoretical results with the Heckman correction model which assumes a continuous $Y_i$. Some examples of non-binary $Y_i$ are tumor size or cancer stage. \n\n[1] Martin J Wainwright and Michael I Jordan. Graphical models, exponential families, and variational inference. *Foundations and Trends in Machine Learning*, 1(1\u20132):1\u2013305, 2008."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2049/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700593233201,
                "cdate": 1700593233201,
                "tmdate": 1700593233201,
                "mdate": 1700593233201,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "R9olbrvsHj",
            "forum": "1mNFsbvo2P",
            "replyto": "1mNFsbvo2P",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2049/Reviewer_6mUm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2049/Reviewer_6mUm"
            ],
            "content": {
                "summary": {
                    "value": "In this work, the authors introduce the widespread phenomenon that the data lies within the human decision censors that tend to be biased. The authors then proposed a hierarchical Bayesian model that addresses such data distribution mismatch between what has been tested and the underlying true distribution. The authors further proposed two constraints, prevalence constraint and expertise constraint to decrease the uncertainty of parameter estimation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed hierarchical Bayesian model to address the unobservables and connect it with the actual observation to evaluate the risk score and test decision makes sense and is novel. \n\n2. The prevalence constraint and expertise constraint used to shrink the estimation uncertainty is novel. In practice, the two constraints are usually easy to access, making such constraints practically useful. \n\n3. The authors demonstrated in synthetic data that the constraints proposed can effectively reduce the confidence interval and show in real data that the proposed constrained Bayesian model yields more reasonable discovery."
                },
                "weaknesses": {
                    "value": "1. The actual Bayesian model derived from Proposition 3.1 seems too simple in practice. Having the assumption that the unobservable always comes from an independent normal distribution can be too strong. \n\n2. When applying the model to UK Biobank, filtering out individuals whose age is below 45 is not convincing."
                },
                "questions": {
                    "value": "Can you explain in more detail why, without prevalence constraint, the beta_y parameter will decrease when the age variable increases in Figure 4? You mentioned that being tested for breast cancer before age 50 is unusual, but that doesn't completely explain why you observe this trend."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2049/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2049/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2049/Reviewer_6mUm"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2049/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698777053516,
            "cdate": 1698777053516,
            "tmdate": 1700634301950,
            "mdate": 1700634301950,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qZTXExZiBP",
                "forum": "1mNFsbvo2P",
                "replyto": "R9olbrvsHj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2049/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2049/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their positive review and are glad that they found that our model makes sense and is novel, that our constraints are novel and practical, and that we verify the benefit of our constraints in both synthetic and real data.  We will now address the reviewer\u2019s questions and suggestions for improvement. \n\nThe reviewer first comments that the Heckman model introduced in Proposition 3.1 is too simple. We would like to clarify that our work investigates models *beyond* the Heckman model. In our paper we describe a broader class of models (described in equation 1), of which the Heckman model is only one special case (Proposition 3.1), and most of our experiments are run using models beyond the Heckman model. The reviewer also states, \u201cHaving the assumption that the unobservable always comes from an independent normal distribution can be too strong.\u201d Indeed, this highlights a benefit of the general model class we describe, which works with alternate distributions of unobservables: in both our synthetic and real data experiments, we consider *both uniform and normal distributions of unobservables* (see Appendix C and Appendix E.2). Overall, we agree with the reviewer that the Heckman model is simple, and one of the strengths of our work is that we investigate models beyond the Heckman model.  \n\nThen the reviewer states, \u201cWhen applying the model to the UK Biobank, filtering out individuals whose age is below 45 is not convincing.\u201d While we focus on the younger cohort in our main analyses to create a challenging distribution shift, to address the reviewer\u2019s concern we run our model on the entire population. We find that performance when using the full cohort is *better* than when using the younger cohort. Specifically, AUC=0.67 and quintile ratio=4.6 among the tested population; AUC=0.66 and quintile ratio=7.0 among the untested population that attended a follow-up visit. We have added these results to footnote 6 in Appendix D. \n\nFinally, the reviewer asks why, for the model without the prevalence constraint, the $\\beta_Y$ parameter decreases when the age variable increases in Figure 4. The model without the prevalence constraint learns this implausible age trend because it is learning the age trend which occurs among the tested population. Due to the age-based testing policy in the UK, patients under the age of 50 are tested only if they are of very high risk for breast cancer, so tested patients below the age of 50 have a higher risk than tested patients above the age of 50. The model without the prevalence constraint learns this trend, which is why its $\\beta_Y$ decreases as age increases."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2049/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700593069057,
                "cdate": 1700593069057,
                "tmdate": 1700593069057,
                "mdate": 1700593069057,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "u0lWL14xgH",
                "forum": "1mNFsbvo2P",
                "replyto": "qZTXExZiBP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2049/Reviewer_6mUm"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2049/Reviewer_6mUm"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the detailed clarification provided by the authors. The authors have addressed my questions and concerns. Therefore, I would like to increase the score."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2049/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700634287475,
                "cdate": 1700634287475,
                "tmdate": 1700634287475,
                "mdate": 1700634287475,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9Oz8XD7dry",
            "forum": "1mNFsbvo2P",
            "replyto": "1mNFsbvo2P",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2049/Reviewer_26qi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2049/Reviewer_26qi"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a Bayesian model designed to infer risk and evaluate historical human decision-making in settings with selective labels. The authors integrate prevalence and expertise constraints, leading to enhanced parameter inference, as demonstrated both theoretically and empirically."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is well motivated.\n- he constraints introduced are logical and reasonable.\n- Both theoretical and empirical analysis show improved performance."
                },
                "weaknesses": {
                    "value": "- The chosen Bernoulli-sigmoid model may be overly simplistic. Especially in the healthcare field, the intricate relationship between features and labels might not be fully represented by this basic model.\n- The empirical tests were limited to only 7 features, raising questions about the model's scalability with a larger feature set.\n- Section 5.2's results are somewhat ambiguous. For instance, in the subsection \"Inferred risk predicts breast cancer diagnoses,\" it would be beneficial to include a specific predictive metric, such as the F1 score.\n- The paper doesn't specify how the new model's diagnostic prediction performance stacks up against a model that doesn't factor in selective label issues. For instance, how would a straightforward linear model perform (1) by training solely on the tested population or (2) by treating the untested group as negative?"
                },
                "questions": {
                    "value": "- How does the model perform on the older population, where the distribution shift is less severe?\n- Can you elaborate more on why the $\\beta_{\\Delta}$ is negative for genetic risk score?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2049/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2049/Reviewer_26qi",
                        "ICLR.cc/2024/Conference/Submission2049/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2049/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698816656391,
            "cdate": 1698816656391,
            "tmdate": 1700715921970,
            "mdate": 1700715921970,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AI9HQapcR3",
                "forum": "1mNFsbvo2P",
                "replyto": "9Oz8XD7dry",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2049/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2049/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their positive review that our draft was well-written. We now address their comments.\n\nThe reviewer first comments that our model may be overly simplistic. To show our constraints are useful with more complex models, we ran two additional synthetic experiments. First, we demonstrated applicability to higher-dimensional features (Figure S4). Even after quadrupling the number of features (increasing runtime by a factor of three), both constraints still improve precision and accuracy. Secondly, we evaluate a more complex model with pairwise nonlinear interactions between features (Figure S5). Again both constraints generally improve precision and accuracy. We note our implementation relies on MCMC which is known to be less scalable than approaches like variational inference [1]. However, our approach does not intrinsically rely on MCMC (we are pursuing a follow-up paper investigating alternate approaches to fitting our models).\n\nThe reviewer asks for specific predictive metrics for the results in section 5.2. To address this we report the AUC. (We report AUC instead of F1 score to allow comparison to past work.) The AUC amongst the tested population is 0.63 and amongst the untested population that attended a followup visit is 0.63. These AUCs are similar to past predictions which use similar feature sets [2] (and could be improved by using richer feature sets, though that is not the focus of this work). For instance, the Tyrer-Cuzick [3] and Gail [4] models achieved AUCs of 0.62 and 0.59.\n\nThe reviewer asks how our model compares to models trained solely on the tested population. We fit a logistic regression model only on the tested population. (To confirm that non-linear methods did not yield an improvement, we also fit random forest and gradient boosted classifiers; this yielded very similar results to the logistic regression model.) These baselines suffer from the same issue: they learn that cancer risk first increases and then decreases with age which, as discussed in section 5.4, is implausible in light of prior research in oncology (Figure S6). For the tested population, our model achieves similar AUCs to these other models.\n\nThe reviewer also asks how our model compares to treating the untested group as negative; this is equivalent to predicting $p(T=1, Y=1|X)$, an approach used in prior work [5,6]. Though this baseline no longer learns an implausible age trend, it underperforms our model in AUC (for both the tested and untested population AUC is 0.60 vs. 0.63 for our model) and quintile ratio (quintile ratio on the tested population is 2.4 vs. 3.3 for our model; quintile ratio on the untested population is 2.5 for both models). This baseline is a special case of our model with an implausibly low prevalence constraint $p(Y=1|T=0) = 0$. In light of this, it makes sense that this baseline learns a plausible age trend, but underperforms our model overall.\n\nThough the reviewer did not explicitly request this, we also compare to two other selective labels baselines. First, we predict hard pseudo labels [7]: i.e., we train a classifier on the tested population and use its outputs as pseudo labels for the untested population. Due to the low prevalence of cancer, the pseudo labels are all $Y=0$, so this model is equivalent to treating the untested group as negative and similarly underperforms our model. Second, we use inverse propensity weighting [8]: i.e., we train a classifier on the tested population but reweight each sample by $\\frac{1}{P(T=1|X)}$. This baseline learns the implausible age trend because it merely reweights the sample, without encoding that the untested patients are less likely to have cancer via a prevalence constraint. All of the baseline results have been added to Appendix E.1.\n\nThe reviewer asks, \u201cHow does the model perform on the older population?\u201d To address this we run our model on the entire population. We find that performance when using the full cohort is *better* than when using the younger cohort. Specifically, AUC=0.67 and quintile ratio=4.6 among the tested population; AUC=0.66 and quintile ratio=7.0 among the untested population that attended a follow-up visit. We also evaluate this model using only adults over 50 (as opposed to the entire cohort) and performance remains better than our initial analysis.  Specifically, AUC=0.67 and quintile ratio=5.1 among the tested population; AUC=0.80 and the quintile ratio is infinite (4.5% vs. 0%) among the untested population. (Performance for the untested population is noisily estimated because there are relatively few untested adults over 50 due to the testing guideline.) We have added these results to footnote 6 in Appendix D.\n\nFinally, the reviewer asks \u201cwhy is $\\beta_\\Delta$ negative for genetic risk score?\u201d A negative $\\beta_\\Delta$ indicates that, controlling for cancer risk, patients with high genetic risk are under-tested. This is plausible because doctors frequently lack patient genetic information."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2049/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700592682186,
                "cdate": 1700592682186,
                "tmdate": 1700592682186,
                "mdate": 1700592682186,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JmqLgaJBlr",
                "forum": "1mNFsbvo2P",
                "replyto": "H5HghUg4sg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2049/Reviewer_26qi"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2049/Reviewer_26qi"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks to the authors for their reply. I will increase my ratings."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2049/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700715910442,
                "cdate": 1700715910442,
                "tmdate": 1700715910442,
                "mdate": 1700715910442,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "DGwQym1X6A",
            "forum": "1mNFsbvo2P",
            "replyto": "1mNFsbvo2P",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2049/Reviewer_uugS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2049/Reviewer_uugS"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a Bayesian model for disease risk of the patients where only the outcome of the tested patients are observed. The proposed model has linear model for risk and testing decision on the observed variables. The paper introduces two constraints: prevalence constraint -- sets expectation of outcome based on prevalence of the disease and expertise constraint --  fixes some parameters to zero based on domain knowledge . The proposed approach is tested in a synthetic and real breast cancer data."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is very well-written, readers can easily follow the motivation, problem formulation and their experimental design.\n2. I appreciate the experiments trying to run experiments in real breast cancer dataset. The experiments in a setting where outcomes for non-tested patients are missing is a very difficult setting. \n3. The paper addresses a significant problem where the outcomes of the patients that are tested are missing and there is distributional shift between tested and untested patients. There is a variety of applications -- which are also motivated in the paper."
                },
                "weaknesses": {
                    "value": "1. I think the paper has limited novelty. The linear risk setting has been considered before as cited in the paper before [(Hicks, 2021)]. This paper aims to add two more constraints: prevalence constraint and expertise constraint. The expertise constraint sets one of the variables to 0 - could be easily addressed by dropping that feature in the dataset, and prevalence constraint sets the expectation of the outcome -- could be addressed by normalizing the feature space and adding a bias term. I am not convinced that these contributions are significant enough to grant acceptance. \n2. I am not sure what theoretical results bring in the paper. For example, Proposition 3.2 shows that variance on the unknown parameters are less if you condition on the fixed parameters. Isn't this expected ? I am not sure how much value this adds to the paper."
                },
                "questions": {
                    "value": "1. The experimental setting for breast cancer patients are interesting -- you are using patient follow-up to validate the methodology ? What happens if there is no follow-up ? How accurate is it to use follow-up data ?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2049/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699161257929,
            "cdate": 1699161257929,
            "tmdate": 1699636136355,
            "mdate": 1699636136355,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SZFWLI7I7U",
                "forum": "1mNFsbvo2P",
                "replyto": "DGwQym1X6A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2049/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2049/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are glad the reviewer found that the paper was well-written and easy to follow, that we applied our model to real data from a difficult medical setting, and that we addressed a significant distribution shift problem which is applicable to many domains. We will now address the reviewer\u2019s questions and suggestions for improvement. \n\nThe reviewer first comments about the novelty of our work, stating \u201cthe linear risk setting has been considered before as cited in [(Hicks, 2021)].\u201d We clarify that the novelty of our work is twofold. First, (Hicks, 2021) only considers the Heckman correction model; in our paper we describe a *broader* class of models (described in equation 1), of which the Heckman correction model is only one special case (Proposition 3.1). Secondly, we propose two novel constraints \u2014 the prevalence and expertise constraints \u2014 which are *not* considered in the Heckman model. These constraints are straightforward to implement and well-motivated in a medical setting. We validate both empirically and theoretically that these constraints improve parameter estimation. \n\nThe reviewer also provides individual comments for each of our constraints. For the expertise constraint, the reviewer states, \u201cThe expertise constraint sets one of the variables to 0 - this could be easily addressed by dropping that feature in the dataset.\u201d We clarify that the expertise constraint only drops a subset of features when predicting the *testing decision*. Thus, $\\beta_\\Delta$ for these features are set to 0. However, these features are *not* dropped when predicting *disease risk*. Thus we still estimate $\\beta_Y$ for all features (even for the features whose $\\beta_\\Delta$ is set to 0). Therefore the features for which we assume expertise *cannot* be completely dropped from the dataset. For the prevalence constraint, the reviewer states, \u201cthe prevalence constraint sets the expectation of the outcome - this could be addressed by normalizing the feature space and adding a bias term.\u201d While this is correct for a linear model with an identity link, this is *not* true in general (e.g. for a Bernoulli-sigmoid link). Overall, we thank the reviewer for their comments on both constraints, and we will revise the manuscript to clarify these points. We agree with the reviewer that the constraints are straightforward to implement: this is a benefit which makes them compatible with a wide class of models.\n\nThe reviewer also asks what value our theoretical results, such as Proposition 3.2, add to the paper. The significance of the theoretical results is twofold. First, we show that the Heckman model is a special case of our model, providing an important connection to the econometrics literature and providing intuition about model identifiability. Secondly, we provide conditions under which fixing a parameter reduces the variance of the other parameters, improving the precision of parameter inference. While Proposition 3.2 is general, we also provide more specific results for the Heckman model (Proposition A.2). Ultimately, our theoretical results (i) provide a connection to the Heckman model, showing it is a special case of our general model and (ii) provide an explanation for why our constraints improve parameter estimation.\n\nFinally, the reviewer asks what happens if we do not have follow-up data for certain patients. We use follow-up data to validate that our model\u2019s inferred risk predictions indeed predict future breast cancer diagnoses *even among the untested population*, an approach also leveraged by prior work [1]. This is an improvement on merely assessing the model on the tested population, since it allows us to get some sense of whether we are able to accurately predict risk for the untested population, though the reviewer is correct that we are not guaranteed to have follow-up data for all untested patients (and we exclude patients with missing follow-up data from this analysis). To get around this limitation, we conduct three additional validations in section 5.2. Nevertheless, we thank the reviewer for their comment and we will acknowledge the limitations of this validation in the main text.\n\n[1] Sendhil Mullainathan and Ziad Obermeyer. Diagnosing physician error: A machine learning approach to low-value health care. *The Quarterly Journal of Economics*, 137(2):679\u2013727, 2022"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2049/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700592205321,
                "cdate": 1700592205321,
                "tmdate": 1700592205321,
                "mdate": 1700592205321,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]