[
    {
        "title": "From Posterior Sampling to Meaningful Diversity in Image Restoration"
    },
    {
        "review": {
            "id": "i2UivWONai",
            "forum": "ff2g30cZxj",
            "replyto": "ff2g30cZxj",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3436/Reviewer_Fph6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3436/Reviewer_Fph6"
            ],
            "content": {
                "summary": {
                    "value": "The current trend in image restoration methods involves sampling multiple outputs from the posterior distribution rather than generating a single one. This paper has highlighted a fundamental limitation of posterior sampling, specifically in generating semantically distinct possibilities using a reasonably small number of samples. This limitation arises from the heavy-tailed nature of the posterior distribution along semantically relevant directions. As a solution, the paper suggests creating compositions of small but meaningfully diverse outputs. The study also delves into a comprehensive examination of what constitutes a set of reconstructions that are meaningfully diverse. To achieve this, the paper explores various post-processing approaches, including Uniformization, K-Means Centers, and Farthest Point Strategy, to obtain semantically meaningful and diverse outputs using existing image restoration methods. Furthermore, the paper introduces a practical approach for enabling diffusion-based image restoration methods to produce outputs that are meaningfully diverse. The effectiveness of these methods is validated through quantitative measures and user studies, demonstrating their superiority over conventional posterior sampling techniques."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "-  identify an inherent conceptual issue with posterior sampling and elucidate the root cause of this problem\n- conduct an analysis to determine the criteria for meaningful diversity. This analysis involves an exploration of three fundamental strategies for diverse sub-sampling.\n-  introduce a novel diffusion-based generation strategy, which offers a practical means to achieve restoration results that are meaningfully diverse."
                },
                "weaknesses": {
                    "value": "None"
                },
                "questions": {
                    "value": "I have some concerns while reviewing the main paper, but they have been addressed in the supplementary material.\n\nA suggestion for the authors: The discussion on future work could be expanded, e.g., what specific desired variations can be for potential research in the field? This would provide more clarity and guidance for researchers interested in pursuing further work in this area."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3436/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3436/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3436/Reviewer_Fph6"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3436/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698312148959,
            "cdate": 1698312148959,
            "tmdate": 1699636295859,
            "mdate": 1699636295859,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "DC0X77EBIF",
                "forum": "ff2g30cZxj",
                "replyto": "i2UivWONai",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3436/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3436/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer Fph6"
                    },
                    "comment": {
                        "value": "Thank you for your positive feedback. We believe there exist several interesting directions for future research. In particular, in this paper we investigate general meaningful diversity, which focuses on exploring different kinds of diversity at once. For example, in the context of restoration of face images, we aim for our representative set to cover diverse face structures, glasses, makeup, etc.\nHowever, for certain applications it can be desirable to reflect the diversity for a specific property, e.g. covering multiple types of facial hair and accessories while keeping the identity fixed, or covering multiple identities while keeping the facial expression fixed. \nThe ability to achieve diversity in only specific attributes can potentially be important in e.g. the medical domain, for example to allow a radiologist to view a range of plausible pathological interpretations for a specific tumor in a CT scan, or to present a forensic investigator with a representative subset of headwear that are consistent with a low quality surveillance camera footage. \\\nWe included this in the revised manuscript."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3436/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700404704886,
                "cdate": 1700404704886,
                "tmdate": 1700404704886,
                "mdate": 1700404704886,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vFexZgoP7G",
                "forum": "ff2g30cZxj",
                "replyto": "DC0X77EBIF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3436/Reviewer_Fph6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3436/Reviewer_Fph6"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response. I will keep the rating."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3436/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700612406660,
                "cdate": 1700612406660,
                "tmdate": 1700612406660,
                "mdate": 1700612406660,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ep7gWQB1Ad",
            "forum": "ff2g30cZxj",
            "replyto": "ff2g30cZxj",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3436/Reviewer_iJud"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3436/Reviewer_iJud"
            ],
            "content": {
                "summary": {
                    "value": "This paper is concerned with  generating  diverse solutions to ill-posed image restoration problems. Usual random sampling from the heavy tailed posterior distribution will have samples from high density regions with a much higher probability than from low density regions, making it an impractical approach to generate diverse solutions from limited samples. Given a large number of samples from posterior, the paper explores three approaches to extract limited number of samples representing meaningful diversity. Further, the paper proposes a simple guidance mechanism to improve diversity of solutions. This involves running the diffusion process to simultaneously generate multiple images starting from different noise samples, and encouraging dissimilarity between estimates of clean images at every step. This guidance improves diversity of solutions of recent diffusion based restoration methods while  maintaining reconstruction quality."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well motivated and well-written.\n\nThe proposed technique is simple and straightforward to implement and the work is reproducible. \n\nThe proposed method improves the diversity of solutions."
                },
                "weaknesses": {
                    "value": "The observation that random sampling leads to limited diversity for long tailed distributions was also noted in [a] in the context of image generation.  [a] also proposes to modify the sampling process in diffusion models to generate samples from low density regions of a long tailed distribution. Though the focus in [a] is on generation, and not restoration, it is still a relevant work, and could be cited by the authors.\n\nThe authors could also cite {b] which attempts to generate diverse solutions to linear inverse problems using pretrained gans.\n\nWhile the proposed guidance method improves diversity and is useful, the technical contribution  seems rather limited. This is the reason for my rating.\n\n[a] Sehwag et al. \"Generating high fidelity data from low-density regions using diffusion models.\" In CVPR 2022\n\n[b]  Montanaro etal. \"Exploring the solution space of linear inverse problems with gan latent geometry.\" In  IEEE International Conference on Image Processing  (ICIP) 2022"
                },
                "questions": {
                    "value": "Could the authors clarify the following issues:\n\nIt is not clarified what kind of down-sampling is used to obtain degraded images for super-resolution.\n \nFig. 14, degraded input for super-resolution looks wierd, the results of DPS look like down-sampled images.\n\nFigs 28 , 29 super-resolution or inpainting. degraded image looks like a low resolution image, caption says inpainting."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3436/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3436/Reviewer_iJud",
                        "ICLR.cc/2024/Conference/Submission3436/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3436/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698596780412,
            "cdate": 1698596780412,
            "tmdate": 1700556110273,
            "mdate": 1700556110273,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5d3JatgwbS",
                "forum": "ff2g30cZxj",
                "replyto": "ep7gWQB1Ad",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3436/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3436/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer iJud"
                    },
                    "comment": {
                        "value": "Thank you for the constructive review. \n\n1. **Relevant citations:**\\\nThanks for pointing us to these relevant works. In the updated manuscript, we added the papers by Sehwag et al. and by Montanaro et al. into a related work paragraph dedicated to works that enhance perceptual coverage.\n\n2. **Our technical contribution:**\\\nPlease note that the contribution of our paper is broader than the proposed guidance method itself: We are the first to systematically explore what it means for a set of reconstructions to be meaningfully diverse by proposing a thorough analysis backed by human user studies. Moreover, we illustrate the heavy-tailed behavior of the posterior quantitatively, and frame this as an inherent limitation of posterior sampling in achieving meaningful diversity. Of course, we eventually also accompany the observations with a practical method for obtaining a small representative set of solutions to any inverse problem. Our method uses the well established tool of diffusion guidance. But the novelty lies mainly in the context in which we use this tool.\n\n3. **Additional questions/issues:**\\\nThanks for pointing out these issues. We address them below and have revised the manuscript to clarify them:\n\n   a. *Downsampling kernel*: In all super-resolution experiments, we use a bicubic downsampling kernel to obtain the degraded LR image, and add white Gaussian noise to the low-resolution image (with the mentioned noise level) for the noisy SR experiments. We agree that this was not clearly stated. We added this information to Sec. 4.1 and also to App. C.\n\n   b. *Fig. 14 in the supplementary*: We regret the confusion. We have now revised the figure to show, for each example, the degraded image on the left, and its corresponding model output on the right. We updated the caption accordingly.\n\n   c. *Figures 28 & 29 (now 34,35)*: Thanks. We fixed the captions to reflect the correct figure contents."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3436/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700404518705,
                "cdate": 1700404518705,
                "tmdate": 1700404518705,
                "mdate": 1700404518705,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CAoFaLjPDu",
                "forum": "ff2g30cZxj",
                "replyto": "5d3JatgwbS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3436/Reviewer_iJud"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3436/Reviewer_iJud"
                ],
                "content": {
                    "title": {
                        "value": "Response and final rating."
                    },
                    "comment": {
                        "value": "Thank you for your response. I have now updated my rating."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3436/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700556080106,
                "cdate": 1700556080106,
                "tmdate": 1700556080106,
                "mdate": 1700556080106,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Wy4F2CQF3g",
            "forum": "ff2g30cZxj",
            "replyto": "ff2g30cZxj",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3436/Reviewer_ppuX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3436/Reviewer_ppuX"
            ],
            "content": {
                "summary": {
                    "value": "This paper discusses the problem of generating a diverse set of reconstructed samples when solving an imaging inverse problem using a pretrained diffusion model. The traditional setup is to cast the inverse problem as one of posterior distribution sampling. However, as the authors discussed this may lead to a concentrated set of samples where most of them look very similar to each other. The paper discusses different ways of measuring and modeling diversity in image reconstruction and later introduces a method for generating a given number of samples  conditioned on a low-resolution / low-quality image, maximizing diversity and using a pretrained diffusion model. The method is evaluated on popular benchmarks on two restoration tasks: super-resolution (4/16x, noisy and noiseless) and inpainting."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "* The paper is generally well-written, address an interesting and relevant problem with a clear narrative and presentation.\n* The technical contribution of the paper is good: analizes a problem and propose a practical solution. This could lead to more research on this problem (\"meaningfully diverse image restoration\")"
                },
                "weaknesses": {
                    "value": "Not weakness per se, more like observations:\n* Experimental results are interesting but limited. For example, image colorization is one of the main problems where diversity reconstruction could have a significant impact.  \n* Presentation could be a little more balanced. In particular, the experimental section (Sec 6) could be a little longer and maybe show more results, discuss a little more some of the algorithmic decisions (presented in Sec 5). The authors opted to put more content on Sec 3 and 4, which seems also a valid decision."
                },
                "questions": {
                    "value": "The paper is in general well-written, addresses an interesting problem, and present an interesting solution. So I'm in favour of accepting this paper as it is now. However, if the authors would like to make the paper better I list a few questions/comments that could be helpful.\n\n1.  **Analysis of the proposed method**. The method seems to do the job, but I wonder if the authors could provide more insight on their proposed solution. For example, a few alternative designs could be:\n    * Instead of increasing distance with respect to NN, just maximize the sample variance (or average pairwise distance as in the reported LPIPS metric)\n    * What happens with the sample average. In the traditional formulation, the average of the generated samples should be close to the posterior mean (which is also another possible estimator that minimizes distortion). Have you tried to compute and compare the sample means w/wo the diversified guidance ? I guess that the mean wouldn't be as good as in the traditional case, but maybe a more robust mean estimator could lead to a very similar result (an estimator that minimizes distortion) \n\n2. **Other Experiments**. In particular regarding Colorization (e.g., one very relevant practical problem is face colorization, can we generate a meaningful diverse set of reconstructed images when starting from a gray photo of a face?)\n\n3. **Connections to other work on GANs** (and mode collapse which seems related).\n\n    * Mao, Q., Lee, H.Y., Tseng, H.Y., Ma, S. and Yang, M.H., 2019. Mode seeking generative adversarial networks for diverse image synthesis. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 1429-1437).\n\n   * Yu, N., Li, K., Zhou, P., Malik, J., Davis, L. and Fritz, M., 2020. Inclusive gan: Improving data and minority coverage in generative models. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XXII 16 (pp. 377-393). Springer International Publishing.\n  \n4. **Training**. This paper is not about training models that allow to generate a diverse set of reconstructions. But, I wonder if the authors could give a comment on wether we could incorporate the idea of diverse sample generation also during training. In particular I wonder if the authors could comment on wether this is an interesting thing to consider, for example in the context of conditional generation ([SR3](https://iterative-refinement.github.io/), [Palette](https://iterative-refinement.github.io/palette/)) or current Bridge restoration models ([InDI](https://openreview.net/forum?id=VmyFF5lL3F), [I2SB](https://i2sb.github.io/))"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3436/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698696032187,
            "cdate": 1698696032187,
            "tmdate": 1699636295700,
            "mdate": 1699636295700,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kWW1jO2Xxg",
                "forum": "ff2g30cZxj",
                "replyto": "Wy4F2CQF3g",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3436/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3436/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer ppuX"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the insightful comments and questions.\n1. **Analysis of the proposed method:**\n\n   a. *Alternatives to increasing distance w.r.t. Nearest Neighbor*: Thanks for this good point. We actually experimented with several alternatives for increasing diversity, but found them all to lead to similar results. This is the reason we eventually decided to go with the simple nearest-neighbor (NN) solution. In the updated manuscript, we added to App. F a few comparisons between NN guidance and guidance that pushes the samples away from their average. As can be seen, both lead to good results, and the differences between them are small.\n\n   b. *The effect on the sample average*: Following your question, we compared the RMSE of the average of our diversity-guided samples to the RMSE of the average of the vanilla samples. We found that the former is only 0%-2% larger than the latter (e.g. an increase of 0.63% in RMSE for SR with DDRM on the CelebA-HQ dataset). This relates to the previous point you raised, as it implies that although our samples are more spread than the vanilla samples, they are still spread roughly around the same point as the vanilla sample  \u2013 the posterior mean. \n\n2. **Other experiments:**\\\nThanks. Following your suggestion, we applied our diversity guided process (using DDNM) to image colorization for the CelebA-HQ and Imagenet datasets. We added example results to App. I.1 in the updated manuscript, where we indeed see a significant diversity gain with our method compared to the vanilla reconstruction.\n\n3. **Connections to other work on GANs:**\\\nThese GAN papers are indeed relevant. We added a discussion in the related work section about these and other related works, under a paragraph titled \u201cEnhancing perceptual coverage\u201d.\n\n4. **Training:**\\\nIncorporating a diversity encouraging loss within a (conditional) diffusion model is actually a very interesting theoretical research avenue. We do not currently have a concrete direction for how this should be done. But we should note that achieving the diversification effect using guidance, as we do here, has certain advantages over training. In particular, it allows the same diffusion model to be used at test time either with or without guidance. Although the latter is not optimal for communicating uncertainty (as we show), it may be needed in certain specific applications, e.g. for unbiased quantitative analysis of the posterior, like computing confidence intervals along the principal components of the posterior (as done in [R1]).\n\n[R1] Belhasin, Romano, Freedman, Rivlin, Elad, \u201cPrincipal Uncertainty Quantification with Spatial Correlation for Image Restoration Problems\u201d, arXiv:2305.10124, 2023"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3436/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700404361172,
                "cdate": 1700404361172,
                "tmdate": 1700404361172,
                "mdate": 1700404361172,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rfA8U7CYBk",
                "forum": "ff2g30cZxj",
                "replyto": "kWW1jO2Xxg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3436/Reviewer_ppuX"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3436/Reviewer_ppuX"
                ],
                "content": {
                    "title": {
                        "value": "Re: Response to reviewer ppuX"
                    },
                    "comment": {
                        "value": "Thank you for your response. I think this is a good paper so I'm keeping my score."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3436/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700613054719,
                "cdate": 1700613054719,
                "tmdate": 1700613054719,
                "mdate": 1700613054719,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]