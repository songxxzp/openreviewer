[
    {
        "title": "Search and Retrieval in Semantic-Structural Representations of Novel Malware"
    },
    {
        "review": {
            "id": "l2UZjNqGUO",
            "forum": "51cjeYcXjs",
            "replyto": "51cjeYcXjs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2932/Reviewer_5Qou"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2932/Reviewer_5Qou"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a methodology for retrieving malware from a large corpus of data through a kNN algorithm applied on a novel feature extraction set, leveraging on Data Dependancy Graphs (DDG). Each program of the corpus is then expressed as a set of hashes that describe them, and that they can be used to be retrieved at need.\nThe authors describe some cherry-picked results to clarify how their methodology work, also showing an example of the first 7 neighbours of the Sekoia Rootkit."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Interesting retrieval approach that could be used to understand similarities between malware.\n2. The approach is easy to understand."
                },
                "weaknesses": {
                    "value": "**Missing a clear evaluation of the results.** The authors show one example retrieval, but all the discussion of Sect.3 is not enough to clarify the optimality and soundness of the proposal. In particular, how a practitioner could validate that the algorithm is picking up from the corpus of data meaningful neighbours? Also, the authors do no specify *why* the results of Fig.7 are relevant. What have these in common? The authors should provide some ground truth, trying to explain why they achieved those results.\nOtherwise, if the methods would have retrieved other 7 samples, what would have been the conclusion?\n\n**Possible errors in disassembly.** The authors state that they leverage *objdump* as disassembler. However, there are plenty of techniques that malware programs use to avoid reverse engineering. Usually, practitioners leverage other tools like IDA and Ghidra that are better in disassembly than objdump. Thus, the results might be biased towards the representation that is tool is providing, rather than capturing the indended functionality and graph shapes.\n\n**Confused paper structure.** The manuscript would benefit for a re-arrangement of its structure. First, the abstract starts directly with the problem to solve, making it for newcomers to understand what is the problem to solve and why. Then, the introduction is missing which are the core contribution of the paper (hinted in Sect.2, but in a confused way). Most of the discussion is focused on just one cherry-picked example. There are no limitations, and no code is provided (that would have removed the need for Sect 4.1)."
                },
                "questions": {
                    "value": "1. Which are the advantage of using this method, and not other retrieval methods? The paper states the presence of related work, but none is compared to the proposed technique.\n2. How this technique can be validated?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2932/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697730935052,
            "cdate": 1697730935052,
            "tmdate": 1699636236890,
            "mdate": 1699636236890,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tqAUMOh7Uh",
                "forum": "51cjeYcXjs",
                "replyto": "l2UZjNqGUO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2932/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2932/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for reviewing our work, and for your thoughtful comments and questions. Please see our responses below:\n\nWe would be happy to re-order the manuscript based on structural changes.\n\nThe question of reverse engineering refers to \"techniques malware programs use to avoid reverse engineering\".  Our discussion of the term reverse engineering refers to the process of translation from binary opcode to assembly during static analysis.  This is unrelated from other techniques that may be referred to as reverse engineering.  This is unrelated to dynamic analysis or obfuscation at runtime.  Objdump as a tool cannot perform control flow graph extraction, unlike Ghidra and IDA, so a comparison the recovered control flow graphs was not performed in this work, since control flow graphs were not used in the data set.  No intermediate representations were used, such a bytecode or LLVM IR.  As to the question of graph properties, we describe a method of data dependency graph extraction in detail, and our graphs were extracted from the direct static mapping of the binary.\n\nAs to the evaluation of results, this method was only claimed to demonstrate the validity of the hypothesis, and better interpretability as a representation, not optimality of search performance.  A practitioner would be able to perform analysis on a more fine-grained level once specific functional overlap has been identified.  This overlap can be measured by the Jaccard coefficient as described in section 3.1 on quantifying functional overlap.  The conclusion presented is that functional overlap exists between the set of neighbors.  This is relevant because it provides a description of a malware sample as a collection of behaviors in relative terms.  This could be expanded to a comparison of other malware to find larger classes and their decision boundaries.  More specific details would require a fine-grained analysis of the behavioral properties, which we have shown through the measurement of similarity and the distance metric in the Hamming Space.  The correlation of the set of behaviors with the result can be measured by the Hamming Code of the sample.  If there is complete structural overlap with a behavior, we can begin to say that these are equivalent, a relation we intend to explore in future work.  Ground truth is verified through domain knowledge of the binaries included in the data set, so the results of search and retrieval will be accurate if the data has been collected, this is similar to a search engine indexing documents.  We have composed a library of benign examples and compared them to specific exemplars of malicious programs."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2932/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700441354115,
                "cdate": 1700441354115,
                "tmdate": 1700441690969,
                "mdate": 1700441690969,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oak0B5QfwG",
                "forum": "51cjeYcXjs",
                "replyto": "tqAUMOh7Uh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2932/Reviewer_5Qou"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2932/Reviewer_5Qou"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the response"
                    },
                    "comment": {
                        "value": "I personally thank the authors for replying to my comments.\nHowever, I am still doubtful on basing all the data dependancy graph computation on the disassembler results given by objdump alone. Also, I think the paper needs to address clearly all the issues in a more systematic way.\nFor this reason, I am not changing my score."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2932/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700471919075,
                "cdate": 1700471919075,
                "tmdate": 1700471919075,
                "mdate": 1700471919075,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KLlWQMjmRk",
            "forum": "51cjeYcXjs",
            "replyto": "51cjeYcXjs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2932/Reviewer_Qcjm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2932/Reviewer_Qcjm"
            ],
            "content": {
                "summary": {
                    "value": "The author proposes a novel representation method for binary programs. First, reverse engineering is employed to extract data dependency graphs (DDGs) from each program. Subsequently, a set of graph hashes is utilized to represent the distinct basic block segments within a DDG. By comparing the DDG Fingerprint of an unknown program with existing programs, the author employs k-Nearest Neighbors to determine its functionality. This approach enables the identification of the functionality of unknown programs through the comparison of DDGs."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The topic of searching and retrieving novel malware is both intriguing and significant. \nThe paper's structure and logic are lucid. \nThe discovery of a similarity between ZeusGameover Feb2014 and the Client/Server Runtime Subsystem is interesting."
                },
                "weaknesses": {
                    "value": "The novelty of this method is limited, as it builds upon existing methods such as DDG, graph hash, and knn.\nThe experimental setup is overly simplistic, hindering the ability to effectively demonstrate the method's efficacy."
                },
                "questions": {
                    "value": "1.The novelty of the proposed method is limited as it heavily relies on existing methods, thus the innovation of this paper is considered to be constrained.\n\n2.The motivation behind selecting DDG as a feature is not adequately explained. Specifically, it is unclear what advantages this feature offers compared to other features such as control flow graphs or function call graphs in the context of software search and retrieval tasks.\n\n3.The definition of Feature Resolution is excessively abstract, making it difficult to comprehend. It would be beneficial to provide an early explanation of this concept in the introduction section.\n\n4.The DDG Fingerprint constructed by the authors appears to have a very high dimensionality, resulting in sparse data. Although the authors mention that \u201cthe feature resolution can be adjusted once the specific characteristics of the search have been refined\u201d, I still struggle to understand how these specific characteristics are determined.\n\n5.The experimental section is overly simplistic. 1), constructing a benign sample library with only 500 data is insufficient. 2), quantitative experiments are lacking. The authors only conducted qualitative analyses without providing accuracy metrics for identifying similarities between samples. 3), the use of only two selected samples in Figure 6 does not sufficiently establish the credibility of the results."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2932/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2932/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2932/Reviewer_Qcjm"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2932/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698594108992,
            "cdate": 1698594108992,
            "tmdate": 1699636236809,
            "mdate": 1699636236809,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "IF6Gjys466",
                "forum": "51cjeYcXjs",
                "replyto": "KLlWQMjmRk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2932/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2932/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for reviewing our work, and for your thoughtful comments and questions. Please see our responses below:\n\nAnswer to Q1 (novelty of the proposed method): While the method makes use of existing algorithms, the method is used to demonstrate the hypothesis, which is that isomorphism of data dependency graphs is reflective of similarity of operational semantics, and the representation is also tied to structural properties. This is a novel claim, and validated by experimental results.\n\nAnswer to Q2 (motivation behind using DDGs): There are several advantages of basing the representation of programs on data dependency graph features. They are directly representing operational semantics and structural properties of binary programs by definition. They can be observed at the lowest level in the architectural hierarchy, and constructed in a bottom up approach. The focus of this work is to measure semantic similarity with features tied to structural properties. We intend to demonstrate that this semantics persists across architectural layers in subsequent studies. This is not possible with function call graphs, which are not constructed in a bottom up approach but top-down.  Higher level language representations of functions may have many possible representations of a given binary. Prior work has studied isomorphism in control flow graphs, but this representation does not allow for increases in fine grained resolution, and all possible combinations of subgraphs must be enumerated for increased feature resolution. Control flow graphs can be used in labeled data sets, but the class labels are at the level of whole program, and this is the lowest level of detail. An efficient method to increase the feature resolution when using CFG-based representations has not been proposed yet. \n\nAnswer to Q3: We are happy to re-organize the structure of the presentation. Resolution refers to the trade-off between scope of search at a coarse grained level, and accuracy of comparing samples at a fine grained level. Two programs that perform similar behaviors may appear to be similar when viewed at the level of all programs in the dataset, and based on all dimensions of the search space. However, they may have different goals, e.g. malicious vs benign \u2013 where the malicious sample obfuscates itself by using part of the benign code, and this could only be discovered upon closer inspection at a fine-grained level, and upon reduction of dimensionality of the search space, by removal of dimensions that do not contribute to differentiating the two samples. This is what was meant by \u201can increase in feature resolution.\u201d However, this requires the search space to be reduced. This is analogous to image resolution, which is why the term was used. \n\nAnswer to Q4: Refinement of search is based on a library of examples.  Based on examples of behavior to search for in a data set, the search space is refined by removing unnecessary examples from the search.  Similarity can be determined by the distance metric.  This can be used to answer the question, does the unknown program with an unknown class share any behavioral characteristics with known malware?  This can be used to answer the question of behavioral overlap, when programs are represented as a collection of behavioral or semantic characteristics. We have shown that the question of overlap can be answered for fine-grained analysis, and intend to explore the implications for larger classes of programs.\n\nAnswer to Q5: Our dataset includes specific class exemplars of malicious programs, and compares them to a library of known benign programs. A single program contains thousands of basic block segments. While there were 500 benign programs in our library of behaviors, the total library of patterns of data dependency through DDG extraction was over 40,000 graphs, which were used for the relative comparison of a single class exemplar.\n\nReporting the accuracy of a classifier on labeled data implies that the class label is correlated to a specific set of behaviors.  We have shown the degree of overlap between sets of behaviors, and that whether these are labeled as secure is a contextual question.  Accuracy requires increasing the level of feature resolution, and we have provided a representation to accomplish this task.  This question can be answered through the metric of similarity.\n\nThe static reverse engineering process is a translation from the binary instruction which is mapped to the corresponding assembly instruction, no other transformation is required. This mapping is defined by the instruction set. There is no loss of data at this stage, it is a 1-1 translation.  This is a separate process from DDG graph extraction."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2932/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700141936101,
                "cdate": 1700141936101,
                "tmdate": 1700143442445,
                "mdate": 1700143442445,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hocIhuuNYd",
            "forum": "51cjeYcXjs",
            "replyto": "51cjeYcXjs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2932/Reviewer_PPca"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2932/Reviewer_PPca"
            ],
            "content": {
                "summary": {
                    "value": "The work presents an approach to generate malware representation using static analysis. That is, pieces of dependency graphs are built based on the assembly instructions of a given malware sample and then hashed using the Weisfeiler-Lehman graph hashing algorithm to retain the semantics of the dependency graphs and graph isomorphism. Finally, the hash values can be used to compute with Hamming Distance and KNN clustering. Only few evaluations with limited samples demonstrated the potential of the work."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- Clear presentation"
                },
                "weaknesses": {
                    "value": "It mainly lacks novelty and supportive arguments.\nThis work only adopts well-developed methods, including the Weisfeiler-Lehman graph hashing algorithm, Hamming Distance, and KNN, rather than developing a solution. Also, transforming static features of a given sample into hash values for further analysis is similar to some related work (Wu, et. al, 2021; Sun, et. al., 2022;), which also considers graph-based static features and maps to a representation for malware detection. \n\nWu, Chia-Yi, Tao Ban, Shin-Ming Cheng, Bo Sun, and Takeshi Takahashi. \"IoT malware detection using function-call-graph embedding.\" In 2021 18th International Conference on Privacy, Security and Trust (PST), pp. 1-9. IEEE, 2021.\n\nSun, Qirui, Eldor Abdukhamidov, Tamer Abuhmed, and Mohammed Abuhamad. \"Leveraging spectral representations of control flow graphs for efficient analysis of windows malware.\" In Proceedings of the 2022 ACM on Asia Conference on Computer and Communications Security, pp. 1240-1242. 2022."
                },
                "questions": {
                    "value": "Questions:\n- Is it possible to show the semantic preserving when assembly codes were transformed into blocks of dependency graphs and hash values?\n\nSuggestion:\n- A clear contribution can be shown with comprehensive evaluations of large-scale samples and compared with other approaches, such as control-flow malware variant detection (Cesare et. al., 2013)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2932/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2932/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2932/Reviewer_PPca"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2932/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698761229335,
            "cdate": 1698761229335,
            "tmdate": 1699636236734,
            "mdate": 1699636236734,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "TBv8EMayp3",
            "forum": "51cjeYcXjs",
            "replyto": "51cjeYcXjs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2932/Reviewer_pKB5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2932/Reviewer_pKB5"
            ],
            "content": {
                "summary": {
                    "value": "The author introduces a novel method for representing binary program features. This method utilizes data dependency to express the operational semantics and structural characteristics of the program, effectively capturing its semantic and functional aspects. Furthermore, the author introduces a bottom-up feature construction approach, enabling additional reasoning based on existing knowledge."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This article addresses a crucial field, considering the rapid proliferation of malware. Swift detection of zero-day malware and the identification of code reuse in zero-day malware present intriguing and formidable challenges. \n\nThe article introduces the DDG Fingerprinting method for detecting malware similarity, significantly enhancing the interpretability of detection outcomes."
                },
                "weaknesses": {
                    "value": "In the Data Collection section, why were those two categories chosen, and other categories not considered? Are the malicious categories up-to-date?\n\nImportant terms should be further clarified, such as the frequently references ``resolution''. I couldn't find a clear and detailed definition or explanation of this term.\n\nHow are the issues encountered in reverse engineering addressed, such as code obfuscation and anti-debugging techniques? I believe reverse engineering is not a trivial matter, yet it is only briefly discussed.\n\nIn the Data Dependency Graph Extraction section, it isclaimed to be an undirected graph, yet Figure 1 shows a directed graph. Moreover, there is no explanation about 'ai' in Figure 1. Why is the 'mov' instruction singled out as capturing most changes without any data or experimental support to back this claim?\n\nFigure 5 lacks detailed information on the horizontal and vertical axes, making it difficult to understand. More detailed analysis would be better."
                },
                "questions": {
                    "value": "Please see the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2932/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699005546814,
            "cdate": 1699005546814,
            "tmdate": 1699636236656,
            "mdate": 1699636236656,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FIvbZt6Cxf",
                "forum": "51cjeYcXjs",
                "replyto": "TBv8EMayp3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2932/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2932/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for reviewing our work, and for your thoughtful comments and questions.  Please see our responses below:\n\nThe goal of this study was to develop a description of program behavior in an adversarial environment, where behavioral descriptions are not available. This requires representing a program in relative terms to known behaviors and known programs, since neither the behavioral description or class are known. Programs that are not designed to be malicious may also have dangerous behaviors depending on context. The goal of this study was to analyze a program that was written with harmful intentions, and provide a description of the unknown behavior, and its similarity to known programs in relative terms. In this case two Trojan samples that had a large impact historically were selected as class exemplars to develop a description. So the samples under investigation were chosen as representatives of the class of Trojan malware to demonstrate the method, but this could be changed depending on search criteria and closer inspection of the behavioral description of a sample in the dataset.\n\nRegarding up-to-date malware samples, malware is changing rapidly, but these changes are at a syntactic level. The goal of this study was to provide a similarity of program semantics which is not sensitive to the underlying changes in syntax. So identifying semantic similarities in new malware is one of the primary goals. This was accomplished by providing a behavioral description of malware that has not previously been seen by the system. Expanding the dataset by adding malicious samples to the library of examples would increase the accuracy, and is not an impediment.\n\nResolution refers to the trade-off between scope of search at a coarse grained level, and accuracy of comparing samples at a fine-grained level. Two samples that perform similar behaviors may appear to be similar when viewed at the level of all programs in the dataset, and based on all dimensions of the search space. However, they may have different goals, e.g. malicious vs benign, and this could only be discovered upon closer inspection at a fine-grained level, and upon reduction of dimensionality of the search space, by removal of dimensions that do not contribute to differentiating the two samples. This is what was meant by \u201can increase in feature resolution.\u201d However, this requires the search space to be reduced.\n\nCode obfuscation is highly relevant to this work. We use similarity of graph isomorphism of data dependency to represent operational semantics. So the degree of obfuscation would be dependent upon the degree of semantic similarity preserved. We have selected to analyze a malicious sample which uses obfuscation to hide its behavior, and have shown that the behavior can be identified through program\u2019s similarity to known samples. \n\nAnti-debugging techniques are used for dynamic analysis, and we have focused on static analysis. Dynamic analysis techniques would not prevent our method of static analysis to detect the behavior. This is because the pattern of data movement would be recognizable before execution at runtime in the static features. Although the values at runtime cannot be predicted, the structure of dependency allows for this analysis and comparison of similarity of behavior, and this was a primary goal of the study.\nThe static reverse engineering process is a translation from the binary instruction which is mapped to the corresponding assembly instruction, no other transformation is required.\n\nFigure 1 is representing the extraction of a data dependency graph. The selection of a_i in Figure 1 is based on the set of operands in the instruction. Each instruction is composed of operands, and an edge between operands represents a dependency. We have shown a directed graph for the purposes of explanation because it illustrates the mapping of data dependencies in the example. Also, we included a short explanation of a_i and A_operand in Figure 1 caption.\nUndirected graphs were chosen in our dataset for the purposes of graph isomorphism, this was included as an area for increased accuracy in future work. \n\nThe prevalence of the mov instruction was performed as part of previous studies. This can be shown easily through a histogram of term frequency of assembly instructions for a program.  We are happy to provide this figure as supplemental material for our data.  \n\nFigure 5 is a projection of a high dimensional space constructed from the Hamming Distance. Each vector in the space represents a single sample and the associated Hamming Codes. This projection is used for visualization purposes, and quantitative analysis is used for accuracy. The axes shown in two dimensions are projections of a high dimensional space.  The metric space shown is to represent the distance metric in the constructed Hamming Space.  The distance metric is used to demonstrate similarity between samples."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2932/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700011124450,
                "cdate": 1700011124450,
                "tmdate": 1700011124450,
                "mdate": 1700011124450,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]