[
    {
        "title": "Double Momentum Method for Lower-Level Constrained Bilevel Optimization"
    },
    {
        "review": {
            "id": "bHHqWivV2g",
            "forum": "K98byXpOpU",
            "replyto": "K98byXpOpU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3454/Reviewer_RgCX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3454/Reviewer_RgCX"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers bi-level optimization problems with constrained lower-level problems (LCBO). A single-loop method is proposed to solve the LCBO, which returns an approximately stationary point with a non-asymptotic convergence rate. The main technique is to use the Gaussian smoothing to approximate the hypergradients. Moreover, momentum methods are applied to update both the upper and lower-level variables. Numerical experiments show the superiority of the proposed method."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed method is a single-loop algorithm, which is more efficient than the existing methods.\n2. The application of the Gaussian smoothing is new to me. This provides new insights for solving the LCBO."
                },
                "weaknesses": {
                    "value": "1. The technical analysis is not sound. It is not clear why $F$ is differentiable (e.g., in Lemma 5) and how Assumption 3 works. Indeed, for a simple example of LCBO, $F$ can be non-differentiable at some points. For example, $F(x)=|x|$ in the following problem is not differentiable at $x=0$\n$$\n\\min_{x,y} -xy \\text{ s.t. } y\\in\\arg\\min_{z\\in[-1,1]}xz.\n$$ \nHowever, these kinds of cases are not discussed in the paper. As a consequence, Lemma 5 and (10) are not convincing.\n\n2. Assumption 4 is also strange to me. More discussions are needed for this kind of boundedness assumption."
                },
                "questions": {
                    "value": "1. Why is the convergence rate only related to $d_2$ but not $d_1$?\n\n2. In the experiments, are the lower-level constraints active at the solution returned by the proposed algorithm?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "Non"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3454/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697683448867,
            "cdate": 1697683448867,
            "tmdate": 1699636298099,
            "mdate": 1699636298099,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Vrbc2Ig8Vo",
                "forum": "K98byXpOpU",
                "replyto": "bHHqWivV2g",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3454/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3454/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Respone to reviewer RgCX"
                    },
                    "comment": {
                        "value": "We sincerely appreciate the time you dedicated to reviewing our paper, and we are grateful for the valuable insights you provided. In the sections below, we address each of your questions with careful consideration and thorough responses. \n\n**Q1: It is not clear why is differentiable (e.g., in Lemma 5) and how Assumption 3 works.**\n\nA1: We acknowledge that the assumptions made in our study might have been overly stringent, potentially affecting the applicability of our research. The reason for employing these assumptions was to simplify the problem and facilitate theoretical analysis. However, we recognize that these strong assumptions may pose limitations in specific contexts.  We have modified Assumption 3 in our new version as follows,\n>**Assumption 3.** a) If projection operator has a closed-form solution and **$z^\\*=y^\\*(x)-\\eta \\nabla_y g(x,y^\\*(x))$ is not on the boundary of the constraint**, then $P_Y(z^*)$ is continuously differentiable in a neighborhood of $z^*$. In addition, in the neighborhood of $z^*$, $P_Y(z^*)$ has Lipschitz continuous gradient with constant $L$. **b) $y^\\*(x)$ is continuously differentiable on a neighborhood of $x$**.\n\nIn many complicated machine learning problems, the probability that $z^*$ falls exactly on the constraint boundary is very low. $z^*$ primarily reside either within or outside the boundary, i.e., a) the constraint is not active and $\\nabla_y g(x,y^*)=0$; b) $y^*$ is on the boundary and $||\\nabla_y g(x,y^*)||>0$. In these two cases,  the projection operator could be differentiable in the neighborhood of $z^*$, since we have the closed form of the projection operator and $z^*$ is not on the nonsmooth point.\n\nThis assumption is used in [1,2] and [1,2] use this assumption derive the hypergradient (6). Even [1,2] assume $y^*(x)$ and $\\mathcal{P}_ {\\mathcal{Y}}(z^*)$ are differentiable in a small neighborhood, [1,2] cannot give a convergence analysis. Because they need $||\\nabla \\mathcal{P}_ {\\mathcal{Y}}(z_1^*)-\\nabla \\mathcal{P}_ {\\mathcal{Y}}(z_2^*)||\\leq L_ P||z_1^*-z_2^*||$, which is not satisfied. Using the new Assumption 3, we can obtain the gradient of $F$ and ignore the non-differentiable point.\n\nMost importantly, the main purpose and contribution of our paper is to propose a single-loop method with convergence analysis based on [1,2], instead of proposing a new method to calculate the hypergradient. Therefore, even if the hypothesis is relatively strong, we believe that the proposal of this method is still meaningful.\n\n**Q2: Assumption 4 is also strange to me. More discussions are needed for this kind of boundedness assumption.**\n\nA2: For the hypergradient estimation $\\nabla f_{\\delta}(x,y)$, we have\n>$$\n|| \\nabla f_ {\\delta}(x,y)|| \\\\\n    \\leq || \\nabla_x f(x,y)||+ \\eta ||\\nabla_ {xy}^ 2 g(x,y) || \\cdot||\\nabla\\mathcal{P}_ {\\mathcal{Y}\\delta}(z)^ {\\top}||\\cdot ||\\sum_ {i=0}^ {Q-1}\\left((I_ {d_2}-\\eta\\nabla_ {yy}^2 g(x,y))\\nabla\\mathcal{P}_ {\\mathcal{Y}\\delta}(z)^{\\top}\\right)^i||\\cdot||\\nabla_yf(x,y)||\\\\\n    =C_{fx}+\\eta C_{gxy}C_{fy}\\sum_ {i=0}^ {Q-1}||I_ {d_2}-\\eta\\nabla_ {yy}^ 2g(x,y)||^i\\\\\n    \\leq C_ {fx}+\\dfrac{C_ {gxy}C_ {fy}}{\\mu_ g} \n$$\n\nThen, using the variance in Lemma 4, we can bound the norm of stochastic estimation, i.e.,  $||\\bar{\\nabla} f_{\\delta}(x,y;\\bar{\\xi})||\\leq C$. Therefore, we can easily obtain $||w||$ is bounded, since $w_{k+1}=(1-\\alpha)w_{k}+\\alpha\\bar{\\nabla} f_{\\delta}(x_{k+1},y_{k+1};\\bar{\\xi}_{k+1})$ and $0<\\alpha<1$. Similarly, we can bound $v$. Even if the norm of the gradient estimation is not bounded, we can also use the clipping method to make the norm of $v$ and $u$ bounded and finally make Assumption 4 hold."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3454/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699978661568,
                "cdate": 1699978661568,
                "tmdate": 1700477094513,
                "mdate": 1700477094513,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qUCCmLi7wW",
                "forum": "K98byXpOpU",
                "replyto": "bHHqWivV2g",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3454/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3454/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Respone to reviewer RgCX part 2"
                    },
                    "comment": {
                        "value": "**Q3: Why is the convergence rate only related to $d_2$ but not $d_1$?**\n\nA3: Since we use the zeroth order method to approximate the Jacobian matrix of the projection operator, the Lipschitz constant and variance of the approximation of the hypergradient is related to $d_2$. In addition, from our analysis, we can find that the convergence rate highly depends on these constants which make the convergence rate related to $d_2$. However, these constant does not affect these constants in the approximation of the hypergradient and therefore the convergence rate is not related to $d_1$.\n\n**Q4: Are the lower-level constraints active at the solution returned by the proposed algorithm?**\n\nA4: Since the dimension of the lower-level variable is relatively large and the constraint parameter $r=1$ is relatively small,  using gradient update in $y$ will easily make $y$ get out of the constraint and lead to the projection on the boundary of the constraints. This makes the lower-level constraints active at the solution return by our method. We can easily check the constraint at the end of our algorithm.\n\n[1] Blondel M, Berthet Q, Cuturi M, et al. Efficient and modular implicit differentiation[J]. Advances in neural information processing systems, 2022, 35: 5230-5242.\n[2] Bertrand Q, Klopfenstein Q, Massias M, et al. Implicit differentiation for fast hyperparameter selection in non-smooth convex learning[J]. The Journal of Machine Learning Research, 2022, 23(1): 6680-6722.\n[3] Guo Z, Xu Y, Yin W, et al. On stochastic moving-average estimators for non-convex optimization. ArXiv e-prints[J]. arXiv preprint arXiv:2104.14840, 2021.\n[4] Shi W, Gao H, Gu B. Gradient-Free Method for Heavily Constrained Nonconvex Optimization[C]//International Conference on Machine Learning. PMLR, 2022: 19935-19955.\n[5] Guo Z, Xu Y, Yin W, et al. A novel convergence analysis for algorithms of the adam family and beyond[J]. arXiv preprint arXiv:2104.14840, 2021."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3454/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251035335,
                "cdate": 1700251035335,
                "tmdate": 1700418421059,
                "mdate": 1700418421059,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LO1wDKtfmU",
                "forum": "K98byXpOpU",
                "replyto": "H3q5vi82Li",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3454/Reviewer_RgCX"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3454/Reviewer_RgCX"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your reply. Most of my concerns are addressed. However, the assumptions are still not satisfactory to me. The new assumptions are not easy to verify, either. For example, how can we ensure that $y^*(x)$ is differentiable? I think this is one of the core problems in Bi-level optimization and assuming the differentiability of $y^*(x)$ is improper. As a consequence, the developed theoretical results seem not to be solid. Hence, I maintain my score. \n\nIt is suggested that the authors build their theory on standard conditions in existing literature, e.g., the PL condition. This may improve the theoretical contributions of this paper."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3454/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700665660221,
                "cdate": 1700665660221,
                "tmdate": 1700665660221,
                "mdate": 1700665660221,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hWsbI4pbrx",
            "forum": "K98byXpOpU",
            "replyto": "K98byXpOpU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3454/Reviewer_voeq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3454/Reviewer_voeq"
            ],
            "content": {
                "summary": {
                    "value": "To address lower-level constrained bilevel optimization problem, the authors leverage the Gaussian smoothing to approximate the hypergradent. Furthermore, the author proposes a single-loop single-timescale algorithm and theoretically prove its convergence rates. Two experimental settings have been tested to demonstrate the superiority of proposed algorithm."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The experimental results are great for proposed algorithm."
                },
                "weaknesses": {
                    "value": "1. The proposed algorithm DMLCBO is based on double momentum technique. In previous works, e.g., SUSTAIN[1] and MRBO[2], double momentum technique improves the convergence rate to $\\mathcal{\\widetilde O}(\\epsilon^{-3})$ while proposed algorithm only achieves the $\\mathcal{\\widetilde O}(\\epsilon^{-4})$. The authors are encouraged to discuss the reason why DMLCBO does not achieve it and the theoretical technique difference between DMLCBO and above mentioned works.\n\n2. In the experimental part, the author only shows the results of DMLCBO in early time, it will be more informative to provide results in the later steps.\n\n3. In Table 3, DMLCBO exhibits higher variance compared with other baselines in MNIST datasets, the authors are encouraged to discuss more experimental details about it and explain the behind reason.\n\n\n[1] A Near-Optimal Algorithm for Stochastic Bilevel Optimization via Double-Momentum\n[2] Provably Faster Algorithms for Bilevel Optimization"
                },
                "questions": {
                    "value": "Check the weakness part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3454/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3454/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3454/Reviewer_voeq"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3454/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698700990965,
            "cdate": 1698700990965,
            "tmdate": 1699636297939,
            "mdate": 1699636297939,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7DDozpzQR1",
                "forum": "K98byXpOpU",
                "replyto": "hWsbI4pbrx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3454/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3454/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Respone to reviewer voeq"
                    },
                    "comment": {
                        "value": "We sincerely appreciate the time you dedicated to reviewing our paper, and we are grateful for the valuable insights you provided. In the sections below, we address each of your questions with careful consideration and thorough responses. \n\n**Q1: The authors are encouraged to discuss the reason why DMLCBO does not achieve $\\tilde{O}(\\epsilon^{-3})$ and the theoretical technique difference between DMLCBO and SUSTAIN[1] and MRBO[2].**\n\nA1: Your comments are greatly appreciated. SUSTAIN[1] and MRBO[2] using the Variance Reduction methods, i.e., STORM and SPIDER, both on the gradient estimation of $x$ and $y$.  These methods need stochastic gradient to be Lipschitz continuous. However, this condition is not satisfied in our method. Therefore, we can only use the traditional moving average method which leads to a different convergence rate. Similar results can be found (i.e., $\\tilde{\\mathcal{O}}(\\epsilon^{-4})$) in [3,4] if the stochastic gradient is Lipschitz continuous.  \n\n**Q2: The author only shows the results of DMLCBO in early time, it will be more informative to provide results in the later steps.**\n\nA2: We highly value your feedback and comments. Please be aware that we've already included results in subsequent sections within our appendix. We extended the iteration count of our method to 100,000 to illustrate its convergence performance. Thank you for your consideration!\n\n**Q3: DMLCBO exhibits higher variance compared with other baselines in MNIST datasets.**\nA3: Your comments are greatly appreciated. In our method, we use the zeroth order method which may have a large variance. This makes the poison data points found by our methods have high variance in different turns. And MNIST is a simple dataset and easily to be attacked which will increase the variance in the poison data points. Finally, these variances will highly affect the retrained model and lead to a large variance in the test accuracy.\n\n[1] A Near-Optimal Algorithm for Stochastic Bilevel Optimization via Double-Momentum \n\n[2] Provably Faster Algorithms for Bilevel Optimization\n\n[3] Dagr\u00e9ou M, Ablin P, Vaiter S, et al. A framework for bilevel optimization that enables stochastic and global variance reduction algorithms[J].\n\n[4] Chen X, Xiao T, Balasubramanian K. Optimal Algorithms for Stochastic Bilevel Optimization under Relaxed Smoothness Conditions[J]."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3454/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699978296450,
                "cdate": 1699978296450,
                "tmdate": 1700418353579,
                "mdate": 1700418353579,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5RKiRQ1qx7",
            "forum": "K98byXpOpU",
            "replyto": "K98byXpOpU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3454/Reviewer_VJdq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3454/Reviewer_VJdq"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies a bilevel optimization problem in which the lower-level problem has a convex set constraint which is independent of the upper-level variable. Using Gaussian smoothing to approximate the gradient of the projection operator, the authors propose an approximation to the hypergradient and a single-loop algorithm. Theoretical analysis and numerical experiments are provided."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The proposed algorithm is a single-loop single-timescale approach."
                },
                "weaknesses": {
                    "value": "1. Assumption 3 is restrictive to satisfy. Furthermore, even the problems examined in the numerical experiments fail to meet this assumption.\n\n2. In order to achieve a stationary point with $\\|| \\nabla F (x) \\|| \\le \\epsilon$, as outlined in Remark 2, the proposed algorithm necessitates a choice of the smooth parameter on the order of $O(\\epsilon d_2^{-3/2})$. Consequently, the algorithm would require a minimum of approximately $\\tilde{O}(d_2^8/\\epsilon^8)$ iterations. It appears, however, that the authors aim to obscure this fact within their paper and retain the smooth parameter in their complexity result.\n\n3. The problems explored in the numerical experiments may not necessarily adhere to the strongly convex assumption for the lower-level problem stipulated in Assumption 2 (3). Moreover, the selection of values for the parameters $Q$ and $\\eta$ does not align with the theoretical requirements specified in Theorem 1."
                },
                "questions": {
                    "value": "see above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3454/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3454/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3454/Reviewer_VJdq"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3454/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698829352046,
            "cdate": 1698829352046,
            "tmdate": 1699636297836,
            "mdate": 1699636297836,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jGL4rQJ0AD",
                "forum": "K98byXpOpU",
                "replyto": "5RKiRQ1qx7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3454/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3454/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Respone to reviewer VJdq"
                    },
                    "comment": {
                        "value": "We sincerely appreciate the time and effort you dedicated to reviewing our paper, and we are thankful for your constructive comments. In the sections below, we address each of the questions you raised.\n\n**Q1: Assumption 3 is restrictive to satisfy.**\n\nA1: We acknowledge that the assumptions made in our study might have been overly stringent, potentially affecting the applicability of our research. The reason for employing these assumptions was to simplify the problem and facilitate theoretical analysis. However, we recognize that these strong assumptions may pose limitations in specific contexts.  We have modified Assumption 3 in our new version as follows,\n>**Assumption 3.** a) If projection operator has a closed-form solution and **$z^\\*=y^\\*(x)-\\eta \\nabla_y g(x,y^\\*(x))$ is not on the boundary of the constraint**, then $P_Y(z^*)$ is continuously differentiable in a neighborhood of $z^*$. In addition, in the neighborhood of $z^*$, $P_Y(z^*)$ has Lipschitz continuous gradient with constant $L$. **b) $y^\\*(x)$ is continuously differentiable on a neighborhood of $x$**.\n\nIn many complicated machine learning problems, the probability that $z^*$ falls exactly on the constraint boundary is very low. $z^*$ primarily reside either within or outside the boundary, i.e., a) the constraint is not active and $\\nabla_y g(x,y^*)=0$; b) $y^*$ is on the boundary and $||\\nabla_y g(x,y^*)||>0$. In these two cases,  the projection operator could be differentiable in the neighborhood of $z^*$, since we have the closed form of the projection operator and $z^*$ is not on the nonsmooth point. \n\n\nThis assumption is used in [1,2] and [1,2] use this assumption derive the hypergradient (6). However, these methods do not have the convergence analysis. The main purpose and contribution of our paper is to design a single-loop method with convergence analysis based on [1,2], instead of proposing a new method to calculate the hypergradient. Therefore, even if the hypothesis is relatively strong, we believe that the proposal of our method is still meaningful.\n\n**Q2:the algorithm would require a minimum of approximately $\\mathcal{O}(d_2^8\\epsilon^{-8})$ iterations.**\n\nA2:  Thank you very much for pointing out our mistake. We have modified the proof in the new version, hope you can check it again.\n\nIn our new proof of Theorem 1, we use the following new function,\n>$$\n\\Phi_{k+1}\\\\\n        =\\mathbb{E}[F_{\\delta}(x_{k+1})+\\dfrac{10L_0^a c_l}{\\tau\\mu_g c_u}||y_{k+1}-y^*(x_{k+1})||^2 + c_l(\\|w_{k+1}-\\bar{\\nabla} f_{\\delta}(x_{k+1},y_{k+1})-R_{k+1}\\|^2\\\\\n        +\\|\\nabla_y g(x_{k+1},y_{k+1})-v_{k+1}\\|^2)]\n$$\n\nwhere $0\\leq a$ is a constant. We can obtain the following result. \n>$$\n\\dfrac{1}{K}\\sum_{k=1}^ K\\mathbb{E}[\\dfrac{1}{2}\\mathcal{M}_ k]\n        \\leq\\dfrac{2m^{1/4}\\sqrt{G}}{\\sqrt{Kt}}+\\dfrac{2\\sqrt{G}}{(Kt)^{1/4}}+\\dfrac{\\delta L}{4\\mu_g} C_ {gxy}(d_2+3)^{3/2}C_ {fy}(1+\\dfrac{1}{\\mu_g}(1-\\eta\\mu_g)).\n$$\n\nwhere $G=\\dfrac{\\Phi_1-\\Phi^*}{\\gamma c_l}+\\dfrac{17t}{4K^2}(m+K)^{1/2}+\\dfrac{4}{3tK^2}(m+K)^{3/2}+(m\\sigma_{f}^2(d_2))t^2\\ln (m+K)$. \nThen, setting $a=0$, we have $\\sqrt{G}=\\tilde{\\mathcal{O}}(\\sqrt{d_ 2})$.  Let $\\delta=\\mathcal{O}(\\epsilon d_2^ {-3/2})$, $r$ randomly sampled from $\\{0,1,\\cdots,K\\}$, we have $\\mathbb{E}[\\dfrac{1}{2}\\mathcal{M}_ r]=\\dfrac{1}{K}\\sum_ {k=1}^ K\\mathbb{E}[\\dfrac{1}{2}\\mathcal{M}_k]=\\tilde{\\mathcal{O}}(\\dfrac{\\sqrt{d_2}}{ K^{1/4}})\\leq \\epsilon$. Therefore, we have $K=\\tilde{\\mathcal{O}}(\\dfrac{d_2^2}{ \\epsilon^{4}})$. This is the first method with convergence analysis for LCBO with general constraints, which directly solves the BO problem. Comparatively, in [6], for the single-level nonsmooth problem, the authors derived an iteration number of $\\mathcal{O}(d^{3/2}\\delta^{-1}\\epsilon^{-4})$. This outcome demonstrates that, even within the LCBO context, our method achieves results akin to those in the **single-level** problem setting.\""
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3454/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699978191877,
                "cdate": 1699978191877,
                "tmdate": 1700478170921,
                "mdate": 1700478170921,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "NJFGjDIsJg",
            "forum": "K98byXpOpU",
            "replyto": "K98byXpOpU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3454/Reviewer_AArG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3454/Reviewer_AArG"
            ],
            "content": {
                "summary": {
                    "value": "The authors introduce a novel hypergradient approximation method for lower-level constrained bilevel optimization problems with non-asymptotic convergence analysis, utilizing Gaussian smoothing. This method incorporates double-momentum and adaptive step size techniques. The experimental results, in the context of data hyper-cleaning and training data poisoning attacks, showcase the efficiency and effectiveness of the proposed approach."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "S1. The work is well motivated. Finding a simple yet effective method for lower-level constrained bilevel optimization problems is both interesting and important.  \n\nS2. The paper is well written and easy to follow. The algorithm design is new and non-asymptotic convergence is provided.\n\nS3. The authors conduct numerous experiments to showcase the efficiency and effectiveness of the proposed approach. Additionally, the paper includes several ablation studies in the Appendix."
                },
                "weaknesses": {
                    "value": "W1. By Remark 2 on page 7, $\\tilde{\\mathcal{O}}(\\frac{\\sqrt{d_2}}{\\delta K^{1/4}})\\leq \\epsilon$ implies that $K=\\tilde{\\mathcal{O}}(\\frac{d_2^2}{\\delta^4 \\epsilon^4})$, NOT $\\tilde{\\mathcal{O}}(\\frac{\\sqrt{d_2}}{\\delta \\epsilon^4})$. Additionally, since $\\delta=\\mathcal{O}(\\epsilon d_2^{-3/2})$ by (11), the iteration number $K=\\tilde{\\mathcal{O}}(\\frac{d_2^8}{\\epsilon^8})$.\n\nW2. The authors should consider comparing their method with closely related papers addressing lower-level constrained bilevel optimization problems, including:\n\n[1] Han Shen, Tianyi Chen. \u201cOn Penalty-based Bilevel Gradient Descent Method.\u201d ICML 2023.\n\nW3. Since there is an additional loop to approximate the matrix inverse, it can be noted that the proposed algorithm DMLCBO is not fully single-loop."
                },
                "questions": {
                    "value": "Q1. Could you provide some representative class of problems that satisfy Assumption 3? Consider the simple example: $g(x,y)=(y-x)^2/2$, $\\mathcal{Y}=[-1,1]$ and $\\mathcal{X}=[-3,3]$. The projection operator $P_Y$ has a closed-form solution, but $\\mathcal{P}_{\\mathcal{Y}}(z^*)$ is not continuously differentiable in a neighborhood of $z^*$ when $x=1$ or $x=-1$.\n\nQ2. Is Assumption 3 satisfied for all small values of $\\eta$? \n\nQ3. What measures can be taken to verify that Assumption 4 is satisfied, or are there specific checkable sufficient conditions to ensure its validity?\n\nMinor Comments:\n\n(1)On page 3, in Equation (4): The minus sign in the expression of $\\nabla y^*(x)$ was omitted.\n\n(2)On page 4, in Remark 1: What is $F_{\\delta}(x)$?\n\n(3)On page 5, in Lemma 2: \u201c$\\| A \\| \\leq 1$\u201d should be \u201c$\\| A \\| < 1$\u201d. Make similar changes after Lemma 2. \n\n(4)On page 5, in Equation (9): By the definition $c(Q)$, the term $u^Q$ in $\\bar{\\xi}$ is not used.\n\n(5)On page 6, in Algorithm 1: swap the positions of $v_1$ and $w_1$. Should \u201c$g(x_1,y_1)$\" be replaced with \u201c$\\nabla_y g(x_1,y_1)$\"? Make similar changes in Section 3.3. \n\n(6)On page 6, in line 3 from below: Should \u201c$\\nabla F_{\\delta}(x_k)$\u201d be replaced with \u201c$\\nabla F (x_k)$\u201d?\n\n(7)On page 7, Lemma 5: The absolute value symbol for $\\mathcal{G}$ in Equation (10) was omitted. Should \u201c$\\nabla f(x_k, y_k)$\u201d be replaced with \u201c$\\nabla_x f(x_k, y_k)$\u201d? Additionally, what is $\\tilde{x}_{k+1}$?\n\n(8)On page 8, in line 3 from below: correct the sum within the max part.\n\n(9)On page 9, Do the bilevel optimization problems related to training data poisoning attacks satisfy the smoothness and convexity assumptions?Note that \u201ca network with two convolution layers and two fully-connected-layer layers for MNIST and a network with three convolution layers and three fully-connected-layer layers for Cifar10, where the Relu function is used in each layer.\u201d"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3454/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3454/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3454/Reviewer_AArG"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3454/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699251851759,
            "cdate": 1699251851759,
            "tmdate": 1699636297765,
            "mdate": 1699636297765,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4pESvlU72o",
                "forum": "K98byXpOpU",
                "replyto": "NJFGjDIsJg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3454/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3454/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Respone to Reviewer AArG"
                    },
                    "comment": {
                        "value": "We are grateful for your time dedicated to reviewing our paper, as well as your constructive comments. Below we address each question.\n\n**Q1: By Remark 2 on page 7, the iteration number $K=\\mathcal{O}(\\dfrac{d_2^8}{\\epsilon^8})$**.\n\nA1: Thank you very much for pointing out our mistake. We have modified the proof in the new version, hope you can check it again.\n\nIn our new proof of Theorem 1, we use the following new function,\n>$$\n\\Phi_{k+1}\\\\\n        =\\mathbb{E}[F_{\\delta}(x_{k+1})+\\dfrac{10L_0^a c_l}{\\tau\\mu_g c_u}||y_{k+1}-y^\\*(x_{k+1})||^2 + c_l(\\|w_{k+1}-\\bar{\\nabla} f_{\\delta}(x_{k+1},y_{k+1})-R_{k+1}\\|^2\\\\\n        +\\|\\nabla_y g(x_{k+1},y_{k+1})-v_{k+1}\\|^2)]\n$$\n\nwhere $0\\leq a$ is a constant. We can obtain the following result. \n>$$\n\\dfrac{1}{K}\\sum_{k=1}^ K\\mathbb{E}[\\dfrac{1}{2}\\mathcal{M}_ k]\n        \\leq\\dfrac{2m^{1/4}\\sqrt{G}}{\\sqrt{Kt}}+\\dfrac{2\\sqrt{G}}{(Kt)^{1/4}}+\\dfrac{\\delta L}{4\\mu_g} C_ {gxy}(d_2+3)^{3/2}C_ {fy}(1+\\dfrac{1}{\\mu_g}(1-\\eta\\mu_g)).\n$$\n\nwhere $G=\\dfrac{\\Phi_1-\\Phi^*}{\\gamma c_l}+\\dfrac{17t}{4K^2}(m+K)^{1/2}+\\dfrac{4}{3tK^2}(m+K)^{3/2}+(m\\sigma_{f}^2(d_2))t^2\\ln (m+K)$. \nThen, setting $a=0$, we have $\\sqrt{G}=\\tilde{\\mathcal{O}}(\\sqrt{d_ 2})$.  Let $\\delta=\\mathcal{O}(\\epsilon d_2^ {-3/2})$, $r$ randomly sampled from $\\{0,1,\\cdots,K\\}$, we have $\\mathbb{E}[\\dfrac{1}{2}\\mathcal{M}_ r]=\\dfrac{1}{K}\\sum_ {k=1}^ K\\mathbb{E}[\\dfrac{1}{2}\\mathcal{M}_k]=\\tilde{\\mathcal{O}}(\\dfrac{\\sqrt{d_2}}{ K^{1/4}})\\leq \\epsilon$. Therefore, we have $K=\\tilde{\\mathcal{O}}(\\dfrac{d_2^2}{ \\epsilon^{4}})$. This is the first method with convergence analysis for LCBO with general constraints, which directly solves the BO problem. Comparatively, in [13], for the single-level nonsmooth problem, the authors derived an iteration number of $\\mathcal{O}(d^{3/2}\\delta^{-1}\\epsilon^{-4})$. This outcome demonstrates that, even within the LCBO context, our method achieves results akin to those in the **single-level** problem setting.\"\n\n\n**Q2: Could you provide some representative class of problems that satisfy Assumption 3? Is Assumption 3 satisfied for all small values of $\\eta$?**\n\nA2: We acknowledge that the assumptions made in our study might have been overly stringent, potentially affecting the applicability of our research. The reason for employing these assumptions was to simplify the problem and facilitate theoretical analysis. However, we recognize that these strong assumptions may pose limitations in specific contexts.  We have modified Assumption 3 in our new version as follows,\n>**Assumption 3.** a) If projection operator has a closed-form solution and **$z^\\*=y^\\*(x)-\\eta \\nabla_y g(x,y^\\*(x))$ is not on the boundary of the constraint**, then $P_Y(z^*)$ is continuously differentiable in a neighborhood of $z^*$. In addition, in the neighborhood of $z^*$, $P_Y(z^*)$ has Lipschitz continuous gradient with constant $L$. **b) $y^\\*(x)$ is continuously differentiable on a neighborhood of $x$**. \n\nIn many complicated machine learning problems, the probability that $z^*$ falls exactly on the constraint boundary is very low. $z^*$ primarily reside either within or outside the boundary, i.e., a) the constraint is not active and $\\nabla_y g(x,y^*)=0$; b) $y^*$ is on the boundary and $||\\nabla_y g(x,y^*)||>0$. In these two cases,  the projection operator could be differentiable in the neighborhood of $z^*$, since we have the closed form of the projection operator and $z^*$ is not on the nonsmooth point. \n\n\n\nIn addition, this assumption has been used in [4,5] to derive the hypergradient (6). The main contribution of this paper is not to use Assumption 3 to derive the hypergradient. The main purpose and contribution of our paper is to design a single-loop method with convergence analysis based on [4,5]. Therefore, even if the hypothesis is relatively strong, we believe that the proposal of our method is still meaningful. Specifically, we propose a single loop method for the LCBO and our method achieves convergence results akin to that in the **single-level** problem setting."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3454/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699977857246,
                "cdate": 1699977857246,
                "tmdate": 1700478197894,
                "mdate": 1700478197894,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nersEccCgw",
                "forum": "K98byXpOpU",
                "replyto": "NJFGjDIsJg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3454/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3454/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Respone to Reviewer AArG part2"
                    },
                    "comment": {
                        "value": "**Q3: What measures can be taken to verify that Assumption 4 is satisfied, or are there specific checkable sufficient conditions to ensure its validity?**\n\nA3:  For the hypergradient estimation $\\nabla f_{\\delta}(x,y)$, we have\n\n>$$\n|| \\nabla f_ {\\delta}(x,y)|| \\\\\n    \\leq || \\nabla_x f(x,y)||+ \\eta ||\\nabla_ {xy}^ 2 g(x,y) || \\cdot||\\nabla\\mathcal{P}_ {\\mathcal{Y}\\delta}(z)^ {\\top}||\\cdot ||\\sum_ {i=0}^ {Q-1}\\left((I_ {d_2}-\\eta\\nabla_ {yy}^2 g(x,y))\\nabla\\mathcal{P}_ {\\mathcal{Y}\\delta}(z)^{\\top}\\right)^i||\\cdot||\\nabla_yf(x,y)||\\\\\n    =C_{fx}+\\eta C_{gxy}C_{fy}\\sum_ {i=0}^ {Q-1}||I_ {d_2}-\\eta\\nabla_ {yy}^ 2g(x,y)||^i\\\\\n    \\leq C_ {fx}+\\dfrac{C_ {gxy}C_ {fy}}{\\mu_ g} \n$$\n\nThen, using the variance in Lemma 4, we can bound the norm of stochastic estimation, i.e.,  $||\\bar{\\nabla} f_{\\delta}(x,y;\\bar{\\xi})||\\leq C$. Therefore, we can easily obtain $||w||$ is bounded, since $w_{k+1}=(1-\\alpha)w_{k}+\\alpha\\bar{\\nabla} f_{\\delta}(x_{k+1},y_{k+1};\\bar{\\xi}_{k+1})$ and $0<\\alpha<1$. Similarly, we can bound $v$. Even if the norm of the gradient estimation is not bounded, we can also use the clipping method to make the norm of $v$ and $u$ bounded and finally make Assumption 4 hold.\n\n**Q4: Since there is an additional loop to approximate the matrix inverse, it can be noted that the proposed algorithm DMLCBO is not fully single-loop.**\n\nA4: In bilevel optimization, the algorithm that alternately updates two variables is referred to as a single-loop algorithm even if it needs to approximate the matrix inverse, such as [1,2,3]. \n\n**Q5: Do the bilevel optimization problems related to training data poisoning attacks satisfy the smoothness and convexity assumptions?**\n\nA5: \nThank you for bringing to our attention the issue in our paper. We acknowledge that our assumption regarding convexity and smoothness does not align with the lower-level problem in the training data poisoning attacks, particularly due to the use of DNNs with ReLU functions. Consequently, the theoretical analysis provided may not be directly applicable in this scenario. Nevertheless, it's essential to note that while our theoretical framework might not directly apply, it doesn't invalidate the capability of our algorithm to address this specific problem.\n\nFor other typos, we have corrected in our new version, and $\\tilde{x}_ {k+1}=P_X(x_k-\\dfrac{\\gamma}{\\sqrt{||w_{k}||}+G_0}w_k)$.\n\n\n[1] Khanduri P, Zeng S, Hong M, et al. A near-optimal algorithm for stochastic bilevel optimization via double-momentum[J]. Advances in neural information processing systems, 2021, 34: 30271-30283.\n\n[2] Chen T, Sun Y, Xiao Q, et al. A single-timescale method for stochastic bilevel optimization[C]//International Conference on Artificial Intelligence and Statistics. PMLR, 2022: 2466-2488.\n\n[3] Hong M, Wai H T, Wang Z, et al. A two-timescale stochastic algorithm framework for bilevel optimization: Complexity analysis and application to actor-critic[J]. SIAM Journal on Optimization, 2023, 33(1): 147-180.\n\n[4] Blondel M, Berthet Q, Cuturi M, et al. Efficient and modular implicit differentiation[J]. Advances in neural information processing systems, 2022, 35: 5230-5242.\n\n[5] Bertrand Q, Klopfenstein Q, Massias M, et al. Implicit differentiation for fast hyperparameter selection in non-smooth convex learning[J]. The Journal of Machine Learning Research, 2022, 23(1): 6680-6722.\n\n[6] Guo Z, Xu Y, Yin W, et al. On stochastic moving-average estimators for non-convex optimization. ArXiv e-prints[J]. arXiv preprint arXiv:2104.14840, 2021.\n\n[7] Shi W, Gao H, Gu B. Gradient-Free Method for Heavily Constrained Nonconvex Optimization[C]//International Conference on Machine Learning. PMLR, 2022: 19935-19955.\n\n[8] Guo Z, Xu Y, Yin W, et al. A novel convergence analysis for algorithms of the Adam family and beyond[J]. arXiv preprint arXiv:2104.14840, 2021.\n\n[9] Mehra A, Hamm J. Penalty method for inversion-free deep bilevel optimization[C]//Asian Conference on Machine Learning. PMLR, 2021: 347-362.\n\n[10] Shi W, Gu B. Improved Penalty Method via Doubly Stochastic Gradients for Bilevel Hyperparameter Optimization[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2021, 35(11): 9621-9629.\n\n[11] Yuanzhi Li and Yang Yuan. Convergence analysis of two-layer neural networks with relu activation.\nIn Advances in Neural Information Processing Systems, pp. 597\u2013607, 2017\n\n[12] Charles Z, Papailiopoulos D. Stability and generalization of learning algorithms that converge to global optima[C]//International conference on machine learning. PMLR, 2018: 745-754.\n\n[13] Lin T, Zheng Z, Jordan M. Gradient-free methods for deterministic and stochastic nonsmooth nonconvex optimization[J]. Advances in Neural Information Processing Systems, 2022, 35: 26160-26175."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3454/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699977915595,
                "cdate": 1699977915595,
                "tmdate": 1700417812024,
                "mdate": 1700417812024,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]