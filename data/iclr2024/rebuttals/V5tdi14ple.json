[
    {
        "title": "Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with Autoformalization"
    },
    {
        "review": {
            "id": "6cdkqXgqfe",
            "forum": "V5tdi14ple",
            "replyto": "V5tdi14ple",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8001/Reviewer_1bgq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8001/Reviewer_1bgq"
            ],
            "content": {
                "summary": {
                    "value": "This paper combines large language models (LLMs) and theorem provers to improve the symbolic reasoning capabilities of the former. Basically, LLMs translate mathematical statements into Isabelle code, which is then used to check for correctness.\nThe proposed approach is evaluated experimentally with favourable results compared to the state-of-the art."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1) The proposed translation includes both symbolic and neural filters to improve the statement translation reliability.\n\n2) The related work is discussed in detail."
                },
                "weaknesses": {
                    "value": "1) The originality and theoretical contribution of this paper is rather limited, as this is mainly the clever combination of two existing tools.\n\n2) The experimental comparison is mainly wrt vanilla voting methods. Also, there is no explanation about the reasons of the particular approached selected for comparison, and there is no comparison with the numerous other methods mentioned in the related work."
                },
                "questions": {
                    "value": "p. 3: Is it the case that every yes/no question is translated into a request for proof?\nWhat if I ask \"Is there a proof that \\pi is irrational?\""
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8001/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8001/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8001/Reviewer_1bgq"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8001/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698487477204,
            "cdate": 1698487477204,
            "tmdate": 1699636986099,
            "mdate": 1699636986099,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jrhC3SmVJT",
                "forum": "V5tdi14ple",
                "replyto": "6cdkqXgqfe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8001/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8001/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1bgq"
                    },
                    "comment": {
                        "value": "Thank you for your constructive feedback and we address individual points below.\n\n> The originality and theoretical contribution of this paper is rather limited, as this is mainly the clever combination of two existing tools.\n\nThank you for your thoughts and we would like to provide some clarifications. Although the core components of DTV are indeed large language models and theorem provers in the formal environment, we disagree with the conclusion that the contribution of the paper is limited. Several other reviewers have expressed and liked the originality and simplicity of our approach. We also note that using theorem provers as a tool allows us to solve challenging problems with the rich formal math libraries that go beyond simple calculators. Additionally, we are the first to demonstrate it is possible to automatically verify correct informal solutions with autoformalization.\n\n> The experimental comparison is mainly wrt vanilla voting methods. Also, there is no explanation about the reasons of the particular approached selected for comparison, and there is no comparison with the numerous other methods mentioned in the related work.\n\nSorry it seems like there was a miscommunication. The main contribution of DTV is that we can select a correct solution from a set of candidates via verification with a theorem prover (and the LLM as \u201ctranslator\u201d). We obtain the candidates by sampling multiple solutions. A natural baseline is therefore to aggregate the candidates through majority voting (which is very competitive). Other methods [1,2,3,4], different from majority voting, would also benefit from DTV verification if they provide multiple candidates. We therefore consider such methods complementary to our contribution.\n\n> p. 3: Is it the case that every yes/no question is translated into a request for proof? What if I ask \"Is there a proof that \\pi is irrational?\"\n\nThanks for raising this question. In this paper, we primarily work on quantitative reasoning problems from standard benchmarks that typically have well-defined numerical answers rather than ask if there is a proof for X.\n\nIf there is a yes/no question or a question similar to \"Is there a proof that \\pi is irrational?\", we will translate it to either \"Show that there is a proof that \\pi is irrational\" or \"Show that there is no proof that \\pi is irrational\" depending on the answer from LLMs. Although proving these meta-logic statements automatically without human guidance could be difficult, the statements can still be translated and grounded to a theorem proving environment such as Isabelle. For example, the Isabelle library has a formal statement (and a proof) of G\u00f6del's Incompleteness Theorems at https://www.isa-afp.org/entries/Incompleteness.html.\n\n[1] Fu, Yao, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. \"Complexity-based prompting for multi-step reasoning.\" arXiv preprint arXiv:2210.00720 (2022).\n\n[2] Zhang, Zhuosheng, Aston Zhang, Mu Li, and Alex Smola. \"Automatic chain of thought prompting in large language models.\" arXiv preprint arXiv:2210.03493 (2022).\n\n[3] Creswell, Antonia, Murray Shanahan, and Irina Higgins. \"Selection-inference: Exploiting large language models for interpretable logical reasoning.\" arXiv preprint arXiv:2205.09712 (2022).\n\n[4] Khot, Tushar, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sabharwal. \"Decomposed prompting: A modular approach for solving complex tasks.\" arXiv preprint arXiv:2210.02406 (2022)."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8001/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700086449826,
                "cdate": 1700086449826,
                "tmdate": 1700086449826,
                "mdate": 1700086449826,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "THX7LgBLNd",
                "forum": "V5tdi14ple",
                "replyto": "jrhC3SmVJT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8001/Reviewer_1bgq"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8001/Reviewer_1bgq"
                ],
                "content": {
                    "title": {
                        "value": "Follow up"
                    },
                    "comment": {
                        "value": "Dear authors,\nthanks for your rebuttal and sorry for low reactivity.\n\nOriginality: please point to the elements of originality in your paper, rather than mentioning the others reviewers' comments.\n\nComparison: if I understand correctly, your approach is not fairly comparable to other frameworks. But I am afraid that this might also mean that its interest is rather limited.\n\nOverall, this looks like a nice paper but I am afraid that the actual technical contribution and its relevance are not up to the standards of a major conference like ICLR."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8001/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700637319563,
                "cdate": 1700637319563,
                "tmdate": 1700637319563,
                "mdate": 1700637319563,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "4012kKFi9h",
            "forum": "V5tdi14ple",
            "replyto": "V5tdi14ple",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8001/Reviewer_HYaT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8001/Reviewer_HYaT"
            ],
            "content": {
                "summary": {
                    "value": "This paper provides a methodology, DTV, whereby LLMs can leverage libraries of formal mathematics and theorem provers to generate sound mathematical solutions.  This approach outperforms a 'majority voting' benchmark by about 12% on the GSM8K (grade school math questions), and 7% on the full test suite.\n\nDTV operates as follows: given an informal (natural language) problem statement, an LLM produces an informal solution.  The LLM then translates both of these into formal statements.  Manually developed filters then eliminate some of the proposed solutions, whose steps are then checked in a theorem prover.  An answer is selected by majority voting over verified solutions."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "**originality**\n\nThe paper is, to my knowledge, original.  Better yet, it is obvious in retrospect.\n\n**quality**\n\nThe paper is well executed.\n\n**clarity**\n\nThe paper is well written.\n\n**significance**\n\nOne of the most obvious drawbacks of LLMs is their lack of soundness.  At the same time their power and flexibility are very impressive.  This paper presents a method for capitalizing on the strength of LLMs while reducing their weaknesses.  I am very confident that the autoformalization literature will continue to gain importance, and that this paper contributes to that literature."
                },
                "weaknesses": {
                    "value": "Minor typos:\n1. \"treated unverified\" -> \"treated as unverified\"\n1. \"autoforamlization\" -> \"let's see if authors will blindly make any crazy edit a reviewer suggests\""
                },
                "questions": {
                    "value": "1. Figure 1, caption: how would results change if, instead of majority voting over all verified solutions, the 'smallest' solution was selected?\n\n1. is it meaningful to run a head-to-head comparison of DTV and Jiang et al.?\n\n1. very minor curiosity (not necessary for the paper): what's the most impressive result that DTV was able to derive?\n\n1. is it possible to estimate how much of a performance improvement there might be if GPT3.5 ran the solution formalization and self-critique filter?  How much extra time this would cost?\n\n1. again, out of curiosity (rather than for the paper): is there a branch of the autoformalization project working on extending the formal libraries?  I'm wondering whether Gowers' Polymath, or Tao's recent interest in Lean could help plug gaps in formal libraries.\n\n1. relatedly, could DTV help with Hales' Formal Abstracts project, https://formalabstracts.github.io/ ?  (This seems to have been dormant.)\n\n1. Figure 3: to clarify the caption - the generated formal statement is too high level for Isabelle to solve in a single step; however, the formalized individual steps are granular enough to allow proof and verification?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8001/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8001/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8001/Reviewer_HYaT"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8001/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698735798744,
            "cdate": 1698735798744,
            "tmdate": 1700278091290,
            "mdate": 1700278091290,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HJhhmgP7cv",
                "forum": "V5tdi14ple",
                "replyto": "4012kKFi9h",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8001/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8001/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer HYaT"
                    },
                    "comment": {
                        "value": "Thank you for your encouraging review and comments! We respond to your individual questions below.\n\n> Figure 1, caption: how would results change if, instead of majority voting over all verified solutions, the 'smallest' solution was selected?\n\nThanks for the question. Selecting the \"smallest\" solution could negatively impact the performance. As discussed in the Limitations section, the autoformalization process is not perfect and therefore selecting the majority answer over all verified solutions is more robust.\n\n> is it meaningful to run a head-to-head comparison of DTV and Jiang et al.?\n\nDTV and Jiang et al. are not directly comparable since the former only assumes access to natural language problem statements rather than the ground truth formal statements. Given ground truth formal statements, one can evaluate the performance simply using pass@k instead of majority voting (maj@k). Therefore, DTV assumes a much more difficult but realistic setting.\n\n> very minor curiosity (not necessary for the paper): what's the most impressive result that DTV was able to derive?\n\nIn Figure 2, 4 (3, 5), we showcase some of the statements (proofs) formalized correctly by DTV and are not solved correctly by majority voting. Many of the problems require a good understanding of the natural language text to arrive at a correct formalization.\n\n> is it possible to estimate how much of a performance improvement there might be if GPT3.5 ran the solution formalization and self-critique filter? How much extra time this would cost?\n\nThanks for the great suggestion. We have additionally conducted the experiment on Number Theory where we equip baseline methods and DTV fully with GPT-3.5. The results show consistent improvement upon baselines for both Minerva 62B and GPT-3.5.\n\n|   \t  Problem Solve Rate   \t  | Minerva 62B |  GPT-3.5  |\n|:----------------------------------:|:-----------:|:---------:|\n|  \t\t  Single Sample \t\t  |\t12.2%\t|   25.0%   |\n| \t\t  Majority Voting    \t  |\t23.7%\t|   41.0%   |\n| DTV Formalization with Minerva 62B |\t31.9%\t| \t- \t|\n|   DTV Formalization with GPT-3.5   |  **36.1%**  | **49.4%** |\n\n> again, out of curiosity (rather than for the paper): is there a branch of the autoformalization project working on extending the formal libraries? I'm wondering whether Gowers' Polymath, or Tao's recent interest in Lean could help plug gaps in formal libraries.\n\n> relatedly, could DTV help with Hales' Formal Abstracts project, https://formalabstracts.github.io/ ? (This seems to have been dormant.)\n\nThank you for the great idea and interest in formalization. In this paper, we restrict our scope to quantitative reasoning problems. We believe our work can be extended to formalizing more advanced topics as LLMs and automated theorem provers continue to improve. Specifically, natural language theorem statements can be translated into their formal counterparts and then proved. The filters we propose in the paper could help filter out many unfaithful translations.\n\n> Figure 3: to clarify the caption - the generated formal statement is too high level for Isabelle to solve in a single step; however, the formalized individual steps are granular enough to allow proof and verification?\n\nYes, this is fully correct.\n\n> Minor typos:\n\nThank you for the note and we have updated our paper pdf with fixed typos in blue."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8001/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700086341586,
                "cdate": 1700086341586,
                "tmdate": 1700086341586,
                "mdate": 1700086341586,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7oa2VVm1Uc",
            "forum": "V5tdi14ple",
            "replyto": "V5tdi14ple",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8001/Reviewer_HDyn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8001/Reviewer_HDyn"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a technique to improve the performance of LLM in solving mathematical reasoning problems. Although it is reported that LLMs show high performance on \nthese problems, they still make errors in their reasoning steps. The proposed method, Don't trust, verify (DTV), tries to improve the performance of LLMs by leveraging external automated theorem provers. Given a problem written in an informal statement, DTV generates both an informal solution and a formal statement by using an LLM. Then, DTV uses an automated theorem prover to verify the answer. Finally, DTV decides its output by performing majority voting among verified answers. Experimental results show that the proposed method\ncan improve the performance of an LLM in multiple reasoning benchmarks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "**A clearly written paper:** T his paper is very clearly written. I feel no difficulty reading the paper.\nThe background and related work section are good enough to make the position of the paper clear.\n\n**Tuckles to a well-motivated problem by a simple method:** To improve the performance of the LLM by combining it with external tools is an important research topic.\nThe proposed method requires less additional cost. Therefore, it has the potential to be a handy tool for this kind of problem.\n\n**The proposed method is original and carefully designed:**\nAlthough some ideas of DTV come from DTP (Jiang et al., 2023), there are a considerable amount of differences between DTP and DTV. DTV seems carefully designed for the reasoning \ntask."
                },
                "weaknesses": {
                    "value": "**Experimental results are not strong:**\nExperimental results show that the proposed method can improve the performance compared with majority voting. However, there are some concerns.\n1. The results in Table 1. compare DTV with GPT-3.5 with baseline methods using Minerva 62B. It is an unfair comparison since the performance improvement comes\nfrom the power of GPT-3.5, and we should compare the results of baseline methods using GPT-3.5. Without GPT-3.5, the improvement by DTV seems marginal.\n2. The paper claims that DTV improves the performance of LLMs and sets simple baseline methods using just LLMs. To prove the claim true, the paper should show experimental results\nwhen we combine DTV with multiple LLMs, as is reported in (Wang et al., 2022).\n\n**Concerns about the number of samples and the efficiency of the DTV:**\nCompared with majority voting, the proposed method needs at least three times more queries to an LLM to obtain a sample solution (informal solution generation, formal statement generation, and formal sketch generation, and I think the self-critique filter needs more queries per sample). As reported in (Wang et al., 2022), the performance of majority voting improves as we generate more samples. Therefore, the paper should report how the performance of DTV and majority voting changes when we change the number of samples n, and should \ndiscuss whether such additional cost of DTV pays off. That is, if we need $m$ queries to obtain a sample solution of DTV, then I think the performance of the proposed method\nshould be compared with the majority voting of $nm$ samples."
                },
                "questions": {
                    "value": "1. Could you please show how the performance of DTV and Wang 2022 changes with number of samples $n$?\n2. How many queries to an LLM does the proposed method need to obtain a sample solution? \n1. Could you please show how the performance changes if we use different LLMs?\n\n## Minor comment \nThe paper should use \\citet{} command to avoid statements like \"(Cobbe et al., 2021) explores training informal ... (page 1) \""
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8001/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8001/Reviewer_HDyn",
                        "ICLR.cc/2024/Conference/Submission8001/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8001/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698807269717,
            "cdate": 1698807269717,
            "tmdate": 1700196529409,
            "mdate": 1700196529409,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jxQ2j4dCoq",
                "forum": "V5tdi14ple",
                "replyto": "7oa2VVm1Uc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8001/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8001/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer HDyn (Part 1)"
                    },
                    "comment": {
                        "value": "Thank you for your valuable and detailed review on our paper. We address individual points below.\n\n> The results in Table 1. compare DTV with GPT-3.5 with baseline methods using Minerva 62B. It is an unfair comparison since the performance improvement comes from the power of GPT-3.5, and we should compare the results of baseline methods using GPT-3.5. Without GPT-3.5, the improvement by DTV seems marginal.\n\nThank you for the great suggestion. We have additionally conducted the experiment on Number Theory where we equip baseline methods and DTV fully with the stronger GPT-3.5. The improvement from using DTV maintains very significant on GPT-3.5 compared to Minerva 62B.\n\n|     \tProblem Solve Rate     \t| Minerva 62B |  GPT-3.5  |\n|:----------------------------------:|:-----------:|:---------:|\n|        \tSingle Sample       \t|\t12.2%\t|   25.0%   |\n|       \tMajority Voting      \t|\t23.7%\t|   41.0%   |\n| DTV Formalization with Minerva 62B |\t31.9%\t| \t- \t|\n|   DTV Formalization with GPT-3.5   |  **36.1%**  | **49.4%** |\n\n> The paper claims that DTV improves the performance of LLMs and sets simple baseline methods using just LLMs. To prove the claim true, the paper should show experimental results when we combine DTV with multiple LLMs, as is reported in (Wang et al., 2022).\n\n> Could you please show how the performance changes if we use different LLMs?\n\nThank you for the question. In Table 2 of the paper, we show that DTV can be combined with multiple LLMs of different sizes and reasoning capability. Specifically, we experiment with all three sizes of the Minerva model: 8B, 62B and 540B. The results show that DTV consistently outperforms majority voting baselines. Additionally, as seen in the table above with GPT-3.5, DTV can also improve upon vanilla GPT-3.5 reasoning, suggesting DTV is applicable to diverse LLMs.\n\n> Concerns about the number of samples and the efficiency of the DTV: Compared with majority voting, the proposed method needs at least three times more queries to an LLM to obtain a sample solution (informal solution generation, formal statement generation, and formal sketch generation, and I think the self-critique filter needs more queries per sample)...\n\n> Could you please show how the performance of DTV and Wang 2022 changes with number of samples n?\n\nThank you for the thoughtful question. We first discuss the sampling efficiency comparison between majority voting and DTV.\n\nIt has been observed in AlphaCode and Minerva papers [1,2] that majority voting performance scales in a log-linear fashion as a function of number of samples (please see the Figure 6 for both papers for the visualization). That is, the performance improvement from 100 to 1000 samples is roughly the same as from 10 to 100 samples. Therefore, majority voting performance can saturate quickly with diminishing return.\n\nOn the contrary, DTV can greatly boost majority voting performance with less compute. In this [Figure](https://drive.google.com/file/d/15s2pI1p5YP1glrwdJHLo9eCFZdCzX2Z1/view?usp=sharing), we plot the performance comparison between DTV and majority voting as a function of the number of samples. It can be seen that majority voting saturates as the number of samples increases and DTV significantly outperforms majority voting.\n\nFurthermore, the additional inference cost of DTV can be reduced. As shown in Table 3 of the paper, without formal solution sketch and self-critique filter, the performance of DTV is not greatly impacted. Besides, compared to generating full-blown informal solutions, statement formalization is relatively inexpensive since the formal statements are much shorter than informal solutions to generate.\n\nLastly, we would like to mention in certain domains and applications such as tutoring and education, spending additional compute to verify solutions for better performance could be desirable. Verifying solutions in the formal theorem proving environments opens up the possibility of mitigating inherent limitations of LLM on certain problems."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8001/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700086156624,
                "cdate": 1700086156624,
                "tmdate": 1700086156624,
                "mdate": 1700086156624,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PIISia4yEq",
                "forum": "V5tdi14ple",
                "replyto": "tNzgsR35LS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8001/Reviewer_HDyn"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8001/Reviewer_HDyn"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the response. I will raise my score."
                    },
                    "comment": {
                        "value": "Thank you for the response! I will raise my score since the authors address my concerns appropriately.\n\n- New results with GPT-3.5 show the effectiveness of DTV.\n- The new figure shows that DTV significantly outperforms majority voting when we use many samples."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8001/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700196503158,
                "cdate": 1700196503158,
                "tmdate": 1700196503158,
                "mdate": 1700196503158,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Q7MHKuqzx7",
            "forum": "V5tdi14ple",
            "replyto": "V5tdi14ple",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8001/Reviewer_wLE8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8001/Reviewer_wLE8"
            ],
            "content": {
                "summary": {
                    "value": "The paper advocates using theorem provers to verify answers generated by language models for quantitative mathematical problems. One starts with a problem in natural language, use language models to generate potential solutions, extract the solutions together with the problem statement and send them to another language model for autoformalization. If the formalized proof is verified by the target theorem prover, then we are sure that one solution is correct without the need of techniques such as majority voting. Additionally, we obtain a rigorous mathematical proof with all gaps closed.\n\nAlthough the big framework of this work is similar to what has been proposed in previous works such as Draft, Sketch, and Prove: Guiding formal theorem provers with informal proofs, the experiments conducted here is much more comprehensive, and a few extra mechanisms to help with the performance have also been introduced, such as the filters for faithful translations."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Comprehensive empirical evaluation and analysis. The results establish the effectiveness of the approach.\n- Excellent section of limitations addressing my concerns that otherwise would have gone into the weakness section below.\n- It is good that this is not merely a large scale version of DSP \u2014 new mechanisms such as filters for faithful translations are good to have.\n- The paper is well written and easy to follow."
                },
                "weaknesses": {
                    "value": "Since the authors already included many of my potential criticisms into the section of limitation (which I really like), only a few ones sit here:\n\n- While DTV consistently outperforms baselines at different model sizes as seen in Table 2, the benefits from using DTV seem to be decreasing as the model size scale up (i.e, Minerva 8B -> 540B).\n\n- It would be good if there is a paragraph describing how a solution is extracted from an informal answer provided by an LLM. If possible, a discussion on \u201cextraction based on the final answer\u201d versus \u201cextraction based on the informal reasoning\u201d would also be nice."
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8001/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698829283993,
            "cdate": 1698829283993,
            "tmdate": 1699636985592,
            "mdate": 1699636985592,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rWONDuFSq3",
                "forum": "V5tdi14ple",
                "replyto": "Q7MHKuqzx7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8001/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8001/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer wLE8"
                    },
                    "comment": {
                        "value": "Thank you for your thoughtful review and suggestions. We address individual points below.\n\n> While DTV consistently outperforms baselines at different model sizes as seen in Table 2, the benefits from using DTV seem to be decreasing as the model size scale up (i.e, Minerva 8B -> 540B).\n\nThank you for the comment and analysis. Table 2 shows that we use the same autoformalization model, either Minerva 64B or GPT-3.5, across each row to ensure autoformalization ability and cost are kept constant. Consequently, we see more improvement compared to the majority voting baseline in the second column, where Minerva 8B, a weaker reasoning model, is used for creating informal solutions, as opposed to a stronger Minerva 540B model in the fourth column.\n\nWe have additionally conducted the experiment on Number Theory where we equip baseline methods and DTV fully with the stronger GPT-3.5. The improvement from using DTV maintains very significant on GPT-3.5 compared to Minerva 62B.\n\n|     \tProblem Solve Rate     \t| Minerva 62B |  GPT-3.5  |\n|:----------------------------------:|:-----------:|:---------:|\n|        \tSingle Sample       \t|\t12.2%\t|   25.0%   |\n|       \tMajority Voting      \t|\t23.7%\t|   41.0%   |\n| DTV Formalization with Minerva 62B |\t31.9%\t| \t- \t|\n|   DTV Formalization with GPT-3.5   |  **36.1%**  | **49.4%** |\n\n> It would be good if there is a paragraph describing how a solution is extracted from an informal answer provided by an LLM. If possible, a discussion on \u201cextraction based on the final answer\u201d versus \u201cextraction based on the informal reasoning\u201d would also be nice.\n\nThank you for the great point! We include the following answer format in the few-shot prompt examples: \"The final answer is [placeholder].\u201d and use regular expressions to extract the informal answer. We agree with the reviewer that in certain scenarios, extraction might be more challenging and not only restricted to the final answer. In this case, we could leverage various semantic parsing methods [1] and possibly use a language model to extract the informal reasoning as seen in [2] as well. We have included the above discussion in our updated paper pdf in blue.\n\n> It is good that this is not merely a large scale version of DSP \u2014 new mechanisms such as filters for faithful translations are good to have.\n\nThank you for your comment and supporting our work. We would like to add that our work which aims to ground LLM reasoning with formal theorem proving environments is distinct from DSP that improves theorem proving performance with LLM. DTV assumes a much more difficult but realistic setting where only natural language data is given. To improve the reliability of autoformalization of statements, we introduce new mechanisms such as filters for faithful translations.\n\n[1] Kamath, Aishwarya, and Rajarshi Das. \"A survey on semantic parsing.\" arXiv preprint arXiv:1812.00978 (2018).\n\n[2] Kojima, Takeshi, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. \"Large language models are zero-shot reasoners.\" Advances in neural information processing systems 35 (2022): 22199-22213."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8001/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700085898666,
                "cdate": 1700085898666,
                "tmdate": 1700085898666,
                "mdate": 1700085898666,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NKj8XGfFOR",
                "forum": "V5tdi14ple",
                "replyto": "Q7MHKuqzx7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8001/Reviewer_wLE8"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8001/Reviewer_wLE8"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response. Regarding the first point, I understand that the autoformalization models for these were kept the same. What I was trying to say was that, as the model (that generates informal solutions) gets bigger, the benefits from using DTV become smaller. For example, for number theory, majority voting gains 13% by going from Minerva 62B to 540B, while DTV only gains 8%. This observation is consistent on all the three domains in Table 2 (and it is even more noticeable when one looks at the numbers of going from Minerva 8B to 540B).\n\nThat is what I was trying to say. It is possible that with even larger models (that generate informal solutions), majority voting might be just as good as DTV."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8001/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700401424133,
                "cdate": 1700401424133,
                "tmdate": 1700401555451,
                "mdate": 1700401555451,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]