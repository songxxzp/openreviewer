[
    {
        "title": "On the Over-Memorization During Natural, Robust and Catastrophic Overfitting"
    },
    {
        "review": {
            "id": "pg0UUaYmgD",
            "forum": "2V1Z0Jdmss",
            "replyto": "2V1Z0Jdmss",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2120/Reviewer_uFwf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2120/Reviewer_uFwf"
            ],
            "content": {
                "summary": {
                    "value": "This paper analyzes three types of overfitting (natural, robust, and catastrophic) observed during the training process of deep neural networks and introduces methodologies to mitigate these phenomena. The authors are particularly motivated by the observation that, during periods of learning decay of standard training, the training loss for certain datasets sharply decreases. They designate these specific datasets as \"transformed data\" to differentiate them from the rest. When this transformed data is excluded from training, a reduction in the generalization gap is observed. This trend is similarly noted in settings where both robust and catastrophic overfitting are evident. Drawing from these observations, it is inferred that the transformed data might be excessively memorized, leading to overfitting. To counteract this, the authors propose the \"distraction over memorization (DOM)\" methodology, which emphasizes data augmentation specifically for the transformed data. Experimental results suggest that models trained using this approach exhibit a superior generalization gap compared to those trained with data augmentation applied across the entire dataset."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper demonstrates that natural overfitting can be mitigated by removing data characterized by a rapid decrease in training loss, termed \"transformed data.\" Through this analysis, the authors highlight the occurrence of overfitting in standard settings due to such data and propose a method to distinguish data that has been excessively memorized. Furthermore, the properties of transformed data are not limited to natural overfitting; they exhibit similar trends in other types of overfitting, namely robust and catastrophic overfitting. The authors suggest a universal overfitting mitigation method by applying various data augmentation techniques to the transformed data. Experimental results are presented to validate the efficacy of this approach."
                },
                "weaknesses": {
                    "value": "The motivation behind this paper, specifically the analysis of transformed data, has already been explored in a paper that introduced the MLCAT methodology [1]. The distinction is that the previous study limited its analysis to robust overfitting, whereas the current paper expands the analysis to three types of overfitting, demonstrating that these phenomena manifest commonly across all three. However, given that there isn't much difference in the learning algorithms or model structures between the standard, adversarial, and fast adversarial settings, one could easily anticipate that the characteristics of transformed data in the adversarial setting, as delineated in MLCAT [1], would manifest similarly in both the standard and fast adversarial settings. Therefore, the current analysis does not offer much novelty beyond the findings of the previous study. While the proposed methodology of applying data augmentation specifically to transformed data does have the advantage of being universally applicable to various types of overfitting, it only demonstrates an improved generalization gap in comparison to the baseline model. Given the inherent differences in training data for the standard, adversarial, and fast adversarial settings, one might question the necessity of a universally applicable overfitting mitigation method. To bolster this claim, the authors should compare the proposed method against methodologies in individual overfitting studies (natural, robust, catastrophic) and demonstrate that their approach offers competitive performance.\n\n[1] Chaojian Yu, Bo Han, Li Shen, Jun Yu, Chen Gong, Mingming Gong, and Tongliang Liu. Understanding robust overfitting of adversarial training and beyond. In International Conference on Machine Learning, pp. 25595\u201325610. PMLR, 2022b."
                },
                "questions": {
                    "value": "- When compared to the analysis performed in the previously cited study (MLCAT) mentioned under weaknesses, are there notable strengths in this paper that I might have missed, aside from the observation that similar phenomena manifest across standard, adversarial, and fast adversarial settings?\n- In the \"distraction over memorization\" methodology, is there a specific reason for applying data augmentation iteratively rather than in a straightforward manner?\n- Has the study investigated whether similar phenomena occur with learning rate scheduling methods that decrease at a more gradual pace, such as cosine, as opposed to the step learning decay?\n- Are there any experimental results comparing the proposed approach to traditional methodologies under the same settings?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Privacy, security and safety"
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2120/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2120/Reviewer_uFwf",
                        "ICLR.cc/2024/Conference/Submission2120/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2120/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698136562967,
            "cdate": 1698136562967,
            "tmdate": 1700542116852,
            "mdate": 1700542116852,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mg0eVn1sYc",
                "forum": "2V1Z0Jdmss",
                "replyto": "pg0UUaYmgD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer uFwf"
                    },
                    "comment": {
                        "value": "We sincerely appreciate your time and effort in reviewing our manuscript. After careful consideration, please find our responses to your comments below.\n\n>**Q1: Different From MLCAT** \n\nA1: \n**Different research perspective.**\nMLCAT investigates RO by examining adversary strength, whereas our work explores different types of overfitting by focusing on the memorization effect.\nWhile MLCAT found that RO is mainly due to the transformed small-loss data, they did not provide further explanation for why these data negatively impact the model generalization.\nDifferent from them, our research delves deeper into the model's memory capacity for different training patterns and uncovers a notable persistent memory for transformed high-confidence patterns.\nThis discovery suggests that the model's brute-force memorization of these patterns detrimentally affects its ability to generalize.\nTo this end, we propose the concept of over-memorization characterized by the model demonstrating both high-confidence prediction and persistent memory.\n\n**Different research object.**\nMLCAT explores the RO phenomenon through the observation of adversarial examples, whereas our research investigates different types of overfitting by concentrating solely on natural patterns.\nSpecifically, we find that the AT-trained model, which does not encounter natural patterns, exhibits a similar memory tendency between natural and adversarial patterns in the over-memorization sample.\nThis tendency manifests as: when the model over-memorizes certain adversarial patterns, it will simultaneously display high-confidence predictions for the corresponding natural patterns.\nBy leveraging this tendency, we can reliably and consistently identify the over-memorization pattern by exclusively focusing on the natural training loss, regardless of the training paradigm.\n\n\n**Different research problem.**\nMLCAT is designed to specifically address RO problems, whereas our study is dedicated to holistically understanding and alleviating different types of overfitting.\nDespite NO, RO and CO all demonstrating reduced model generalization and having similar aspects (e.g., learning algorithms and model structures), previous studies have revealed that they exhibit unique manifestations and mechanisms, thereby requiring independent solutions [1,2].\nTo bridge the gap among different types of overfitting, we introduce the shared behaviour over-memorization, which first-time adopts a unified perspective in understanding and addressing overfitting across various training paradigms.\n\n>**Q2: Iterative Data Augmentation** \n\nA2: \nOur approach employs data augmentation to prevent the model from over-memorizing training patterns, thereby alleviating overfitting.\nHowever, due to the inherent randomness of the original data augmentation, straightforward use cannot reliably and consistently prevent over-memorization.\nTo overcome this issue, our method $DOM_{DA}$ applies iterative data augmentation, which is strategically designed to maximize the likelihood of hindering over-memorization.\n\n>**Q3: Gradually Learning Rate** \n\nA3: \nWe have validated the effectiveness of our method within single-step AT, where the cyclical learning rate is the standard setting.\nTo further assess our method, we conducted experiments using a gradual learning rate schedule in natural training. \nWe set the cyclical learning rate schedule with 300 epochs, reaching the maximum learning rate of 0.2 at the midpoint of 150 epochs.\nWe report the natural training test error at both the best and last checkpoint on CIFAR 10 using PreactResNet-18.\n\n|Method|Best($\\downarrow$)|Last($\\downarrow$)|Diff($\\downarrow$)|\n|:-----|:----:|:----:|:----:|\n|Baseline|4.80|4.89|-0.09|\n|Baseline + $DOM_{RE}$|**4.79**|**4.79**|**-0.00**|\n|Baseline + AUGMIX|4.75|4.79|-0.02|\n|Baseline + AUGMIX + $DOM_{DA}$|**4.49**|**4.49**|**-0.00**|\n|Baseline + RandAugment|4.41|4.42|-0.01|\n|Baseline + RandAugment + $DOM_{DA}$|**4.25**|**4.25**|**-0.00**|\n\nFrom the above table, it is apparent that although the cyclical learning rate reduces the model's generalization gap, it also leads to a reduction in performance compared to the step learning rate.\nNevertheless, our method consistently showcases its effectiveness in improving model performance and completely eliminating the generalization gap by mitigating over-memorization.\nWe have included this experimental result in Appendix H of the rebuttal revision."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2120/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700201807786,
                "cdate": 1700201807786,
                "tmdate": 1700201807786,
                "mdate": 1700201807786,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Gh7GYJkuaE",
                "forum": "2V1Z0Jdmss",
                "replyto": "pg0UUaYmgD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer uFwf"
                    },
                    "comment": {
                        "value": ">**Q4: Comparison With Traditional Methodologies**\n\nA4:\nWhile a range of traditional methodologies exist to separately address NO, RO and CO, the understanding and solutions for these overfitting types remain isolated from each other.\nThis study first-time adopts a unified perspective on different types of overfitting by analyzing the memorization effect on each training pattern.\nTherefore, we primarily compare our method with both universal and data-centric approaches, such as baseline and data argumentation technologies.\nAlthough our method may not achieve the performance of specially tailored approaches, it stands out for holistically mitigating overfitting across various training paradigms.\nAs a general framework, DOM can consistently achieve notable improvements over the baseline with a subset of training samples or data augmentation, which successfully supports our perspective.\n\nIf you have any further questions or concerns, please do not hesitate to contact us. We are willing and available to provide additional information you may need.\n\n[1] Leslie Rice, Eric Wong, and Zico Kolter. Overfitting in adversarially robust deep learning. In International Conference on Machine Learning, pp. 8093\u20138104. PMLR, 2020.\n\n[2] Maksym Andriushchenko and Nicolas Flammarion. Understanding and improving fast adversarial training. Advances in Neural Information Processing Systems, 33:16048\u201316059, 2020."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2120/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700201831022,
                "cdate": 1700201831022,
                "tmdate": 1700201831022,
                "mdate": 1700201831022,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SweRZNSPXS",
                "forum": "2V1Z0Jdmss",
                "replyto": "pg0UUaYmgD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer uFwf"
                    },
                    "comment": {
                        "value": "Dear Reviewer uFwf:\n\nWe hope this message finds you well.\nWe are sincerely thankful for your effort in reviewing our manuscript.\nAs a gentle reminder, we have submitted a rebuttal and a revised manuscript to address your mentioned concerns.\nGiven the constraints of the discussion period, your prompt response would enable us to provide further clarification and explanation.\n\nBest regards, \n\nAuthors"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2120/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700516985638,
                "cdate": 1700516985638,
                "tmdate": 1700516985638,
                "mdate": 1700516985638,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Jhfm4f3xqs",
                "forum": "2V1Z0Jdmss",
                "replyto": "SweRZNSPXS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2120/Reviewer_uFwf"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2120/Reviewer_uFwf"
                ],
                "content": {
                    "comment": {
                        "value": "In response to the review and upon reevaluating the paper, it appears that there are no instances where I misunderstood the content. Clarification is needed regarding the statement, \"our research delves deeper into the model's memory capacity for different training patterns and uncovers a notable persistent memory for transformed high-confidence patterns.\" The removal experiments of Trans-HC (small-loss data) and Ori-HC have already been conducted in the prior work (MLCAT [1] Fig. 2). If we can confirm the results of alleviating overfitting when Trans-HC data is removed, without explicitly checking the training loss when it is present or absent, it can be inferred that the model excessively memorizes Trans-HC data. To assert that we have \"explained\" something not covered in the MLCAT [1] paper, a theoretical analysis of such phenomena or results is necessary.\n\nAs mentioned earlier, the occurrence of this phenomenon in NO, RO, and CO, given their commonality, can be reasonably anticipated considering the nature of overfitting. There seems to be no issue with the proposed methodology to address the problem by utilizing an approach applying natural loss-based data augmentation uniformly across three types of overfitting. However, there appears to be a lack of contributions related to novelty beyond this."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2120/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700533297423,
                "cdate": 1700533297423,
                "tmdate": 1700533297423,
                "mdate": 1700533297423,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TUbbVlU3mL",
                "forum": "2V1Z0Jdmss",
                "replyto": "pg0UUaYmgD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer uFwf"
                    },
                    "comment": {
                        "value": "Thank you for your timely response, which has helped us address your concerns promptly.\nWe are pleased to offer the following clarification to your concerns.\n\n* Firstly, our paper (Fig. 2) provides an analysis of the model's memory capacity, which is not conducted in the MLCAT.\nThis analysis offers deeper insight into why Trans-HC patterns negatively impact model generalization but Ori-HC does not, even though both of them are characterized as HC.\nWe found that the model exhibits persistent memory for Trans-HC patterns, indicating that the brute-force memorization of these patterns hinders its generalization.\n\n* Secondly, the MLCAT identify small-loss data based on the model's loss on adversarial examples.\nDifferent from them, our method uncovers the model's memory tendency between natural and adversarial patterns, allowing us to detect over-memorization adversarial examples solely based on the natural training loss.\n\n* Finally, we respectfully disagree with the notion that the commonality between NO, RO, and CO can be reasonably anticipated.\nIn contrast, to the best of our knowledge, all prior research has regarded them as completely distinct phenomena, with each research having own understanding and solutions that are incompatible with other types of overfitting.\nTo bridge this gap among different types of overfitting, our study introduces the shared behaviour over-memorization that first-time adopts a unified perspective in understanding and addressing overfitting.\n\nWe appreciate your prompt feedback and are always open to further discussion.\nIf you have any further concerns, please feel free to contact us.\nWe are committed to providing any further clarifications you may need."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2120/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700540031369,
                "cdate": 1700540031369,
                "tmdate": 1700540592034,
                "mdate": 1700540592034,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aUwKW2EHC2",
                "forum": "2V1Z0Jdmss",
                "replyto": "pg0UUaYmgD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2120/Reviewer_uFwf"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2120/Reviewer_uFwf"
                ],
                "content": {
                    "comment": {
                        "value": "While there may not be significant differences in the causes or solutions between NO and RO, I partially agree with the author's opinion that there could be distinctions with CO. Therefore, I acknowledge the contribution of identifying commonalities in these gaps and proposing a universal solution in a context where such distinctions are considered. However, I still find the analysis lacking novelty, as the methodology seems to be a mere transformation of the previous study, shifting the focus from AEs to clean ones.\n\nAdditionally, if different types of overfitting methodologies are distinctly addressed, as mentioned earlier, there should have been a demonstration of better or comparable performance compared to existing methodologies for each type of overfitting through a comparison with the existing approaches. Considering the level of contribution, given the current low score, I reevaluate the contribution by excluding the deficient areas and adjusting the score accordingly."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2120/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700542185878,
                "cdate": 1700542185878,
                "tmdate": 1700542771423,
                "mdate": 1700542771423,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "10Es8yxA2K",
            "forum": "2V1Z0Jdmss",
            "replyto": "2V1Z0Jdmss",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2120/Reviewer_mcnh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2120/Reviewer_mcnh"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a general framework for explicitly preventing over-memorization by either removing or augmenting the high-confidence natural patterns. It is based on the observation that the model suddenly exhibits high confidence in predicting certain training patterns, which subsequently hinders the DNNs\u2019 generalization capabilities."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "**Strength:**\n\n-   This paper is overall well-structured and easy to follow.\n-   Extensive empirical evaluation with various training paradigms, baselines, datasets, and network architectures demonstrates its effectiveness. Results are reported with the standard deviation.\n- Significant performance improvements are demonstrated."
                },
                "weaknesses": {
                    "value": "**Weakness**\n\n-   According to Figure 5, the proposed method may require careful hyper-parameter (i.e. loss threshold) selection, which could be a significant drawback.\n-   The proposed method might result in repeated gradient computation and extensive extra computation. It is also interesting to include a detailed analysis of the introduced extra computation.\n-   The terminology \"pattern\" might be confusing and could be further explained. Does it refer to specific samples in datasets?\n-   Lack of results on large-scale datasets. It will be convincing to have some on Tiny-ImageNet or ImageNet\n-   Lack of results on diverse network backbone architectures beyond ResNets.\n-   As discussed in the related works, there are various techniques for mitigating the overfitting issues. Comparisons with other techniques like dropout, ensemble, smoothing, etc. can be helpful."
                },
                "questions": {
                    "value": "Refer to the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2120/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698536386139,
            "cdate": 1698536386139,
            "tmdate": 1699636144647,
            "mdate": 1699636144647,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Fl6MRlj5AT",
                "forum": "2V1Z0Jdmss",
                "replyto": "10Es8yxA2K",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer mcnh"
                    },
                    "comment": {
                        "value": "We sincerely appreciate your time and effort in reviewing our manuscript. After careful consideration, please find our responses to your comments below.\n\n>**Q1: Hyperparameter Selection** \n\nA1: \nBy utilizing the DOM framework, we have effectively verified and mitigated over-memorization, which negatively impacts DNNs' generalization ability.\nHowever, as a general framework, finding optimal hyperparameters for different paradigms and datasets can be cumbersome.\nWhile some hyperparameters exhibit a degree of universality (e.g. data argumentation strength $\\beta$ and iteration $\\gamma$), the primary challenge lies in establishing an appropriate loss threshold.\nTo address this challenge, we propose to use a general and unified loss threshold applicable across all experimental settings.\nSpecifically, we utilize an adaptive loss threshold [1], whose value is dependent on the loss of the model's current training batch.\nFor all experiments, we set this adaptive loss threshold $\\mathcal{T}$ to 40%, maintaining other hyperparameters as the original settings.\nWe report the natural and PGD-20 test errors for natural training (NT) and adversarial training (AT) using PreactResNet-18, respectively.\n\n|Dataset|Paradigm|Method|Best($\\downarrow$)|Last($\\downarrow$)|Diff($\\downarrow$)|\n|:-----|:----|:----|:----:|:----:|:----:|\n|CIFAR10|NT|Baseline|4.70|4.84|-0.14|\n|CIFAR10|NT|Baseline + $DOM_{RE}$| **4.60** | **4.67**|**-0.07**|\n|CIFAR10|NT|Baseline + AUGMIX|4.35|4.52|-0.17|\n|CIFAR10|NT|Baseline + AUGMIX + $DOM_{DA}$|**4.22**|**4.37**|**-0.15**|\n|CIFAR10|NT|Baseline + RandAugment|4.02|4.31|-0.29|\n|CIFAR10|NT|Baseline + RandAugment + $DOM_{DA}$|**3.85**|**3.94**|**-0.09**|\n|CIFAR100|NT|Baseline|21.32|21.59|**-0.27**|\n|CIFAR100|NT|Baseline + $DOM_{RE}$|**21.20**|**21.47**|**-0.27**|\n|CIFAR10|Multi-step AT|Baseline|47.67|54.84|-7.17|\n|CIFAR10|Multi-step AT|Baseline + $DOM_{RE}$|**46.55**|**52.87**|**-6.32**|\n|CIFAR10|Single-step AT|Baseline|57.83|100.00|-42.17|\n|CIFAR10|Single-step AT|Baseline + $DOM_{RE}$|**54.56**|**55.38**|**-0.82**|\n\nThe above table demonstrates the effectiveness of the adaptive loss threshold across different paradigms and datasets.\nThis threshold can not only consistently identify over-memorization patterns and mitigate overfitting, but also be easily transferable without the need for hyperparameter tuning.\nWe have included this experimental result in Appendix B of the rebuttal revision.\n\n>**Q2: Computational Overhead** \n\nA2: \nWe analyze the extra computational overhead incurred by the DOM framework.\nNotably, both $DOM_{RE}$ and $DOM_{DA}$ are implemented after the warm-up period (half of the training epoch).\nWe report the before warm-up, after warm-up, and overall training time (epoch/second) on CIFAR10 using PreactResNet-18 with a single NVIDIA RTX 4090 GPU.\n\n|Method |Before warm-up($\\downarrow$)|After warm-up($\\downarrow$)|Overall($\\downarrow$)|\n|:-----|:----:|:----:|:----:|\n|Baseline|6.28|6.26|6.27|\n|Baseline + $DOM_{RE}$|6.28|6.28|6.28|\n|Baseline + AUGMIX|12.55|12.76|12.66|\n|Baseline + AUGMIX + $DOM_{DA}$|6.28|28.45|17.37|\n|Baseline + RandAugment|8.29|8.27|8.28|\n|Baseline + RandAugment + $DOM_{DA}$|6.24|12.75|9.50|\n\nBased on the above table, we can observe that $DOM_{RE}$ does not involve any additional computational overhead.\nAlthough $DOM_{DA}$ require iterative forward propagation, its overall training time does not significantly increase, because the data augmentation is only applied to a limited number of epochs and training samples.\nAdditionally, the multi-step and single-step AT inherently have a higher basic training time (generate adversarial perturbation), but the extra computational overhead introduced by the DOM framework is relatively consistent. \nAs a result, our approach has a relatively smaller impact on the overall training overhead in these scenarios.\nWe have included this experimental result in Appendix G of the rebuttal revision.\n\n\n>**Q3: Pattern Definition** \n\nA3: \nEach training sample in the dataset has two patterns: the natural pattern corresponds to the original sample, and the adversarial pattern corresponds to the adversarial example (original sample plus the adversarial perturbation).\nIn this work, we identify over-memorization samples by exclusively focusing on the natural pattern loss, regardless of the training paradigm."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2120/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700201711208,
                "cdate": 1700201711208,
                "tmdate": 1700201711208,
                "mdate": 1700201711208,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "48XR1x1U49",
                "forum": "2V1Z0Jdmss",
                "replyto": "10Es8yxA2K",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer mcnh"
                    },
                    "comment": {
                        "value": ">**Q4: Larger-scale Dataset**\n\nA4: \nWe also verified the effectiveness of our method on the larger-scale dataset Tiny-ImageNet.\nWe set the loss threshold $\\mathcal{T}$ to 0.2, and other hyperparameters remain as the original settings.\nWe report the natural training test error at both the best and last checkpoint using PreactResNet-18.\n\n|Method|Best($\\downarrow$)|Last($\\downarrow$)|Diff($\\downarrow$)|\n|:-----|:----:|:----:|:----:|\n|Baseline|35.03|35.24|-0.21|\n|Baseline + $DOM_{RE}$|**34.89**|**34.99**|**-0.10**|\n|Baseline + AUGMIX|34.98|35.15|-0.17| \n|Baseline + AUGMIX + $DOM_{DA}$|**34.56**|**34.77**|**-0.21**|\n|Baseline + RandAugment|33.45|33.89|-0.44|\n|Baseline + RandAugment + $DOM_{DA}$|**33.40**|**33.59**|**-0.19**|\n\nThe above table illustrates the effectiveness of our method, $DOM_{RE}$ and $DOM_{DA}$, on the Tiny-ImageNet dataset.\nThese results indicate that preventing over-memorization can improve model performance and reduce the generalization gap on large-scale datasets.\nWe have included this experimental result in Appendix F of the rebuttal revision.\n\n>**Q5: Transformer-based Architecture**\n\nA5: \nWe have validated the effectiveness of our method within CNN-based architectures, demonstrating its ability to alleviate overfitting by preventing over-memorization.\nTo further substantiate our perspective, we verify our method on the Transformer-based architecture.\nConstrained by computational resources, we trained a ViT-small model, initializing it with pre-trained weights from the Timm Python library.\nThe training spanned 100 epochs, starting with an initial learning rate of 0.001 and divided by 10 at the 50th and 75th epochs.\nWe set the batch-size to 64 and the loss threshold $\\mathcal{T}$ to 0.1, maintaining other hyperparameters as the original settings.\nWe report the natural training test error at both the best and last checkpoint on CIFAR 10.\n\n|Method|Best($\\downarrow$)|Last($\\downarrow$)|Diff($\\downarrow$)|\n|:-----|:----:|:----:|:----:|\n|Baseline|1.49|1.75|-0.26|\n|Baseline + $DOM_{RE}$|**1.47**|**1.67**|**-0.20**|\n|Baseline + AUGMIX|1.24|1.29|**-0.05**|\n|Baseline + AUGMIX + $DOM_{DA}$|**1.20**|**1.28**|-0.08|\n|Baseline + RandAugment|1.21|1.29|-0.08|\n|Baseline + RandAugment + $DOM_{DA}$|**1.15**|**1.22**|**-0.07**|\n\nThe above table shows the effectiveness of our method on the Transformer-based architecture.\nBy mitigating over-memorization, both $DOM_{RE}$ and $DOM_{DA}$ not only improve model performance at both the best and last checkpoints, but also contribute to alleviating overfitting.\nWe have included this experimental result in Appendix E of the rebuttal revision.\n\n>**Q6: Compare With Other Techniques**\n\nA6: \nWhile a range of techniques exist to separately address NO, RO and CO, the understanding and solutions for these overfitting types remain isolated from each other.\nThis study first-time adopts a unified perspective on different types of overfitting by analyzing the memorization effect on each training pattern.\nTherefore, we primarily compare our method with both universal and data-centric approaches, such as baseline and data argumentation technologies.\nAlthough our method may not achieve the performance of specially tailored approaches, it stands out for holistically mitigating overfitting across various training paradigms.\nAs a general framework, DOM can consistently achieve notable improvements over the baseline with a subset of training samples or data augmentation, which successfully supports our perspective.\n\nIf you have any further questions or concerns, please do not hesitate to contact us. We are willing and available to provide additional information you may need.\n\n[1] Berthelot, D., Roelofs, R., Sohn, K., Carlini, N., & Kurakin, A. (2021, October). AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation. In International Conference on Learning Representations."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2120/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700201749810,
                "cdate": 1700201749810,
                "tmdate": 1700201749810,
                "mdate": 1700201749810,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Rsu4EWrMjS",
                "forum": "2V1Z0Jdmss",
                "replyto": "10Es8yxA2K",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer mcnh"
                    },
                    "comment": {
                        "value": "Dear Reviewer mcnh:\n\nWe hope this message finds you well.\nWe are sincerely thankful for your effort in reviewing our manuscript.\nAs a gentle reminder, we have submitted a rebuttal and a revised manuscript to address your mentioned concerns.\nGiven the constraints of the discussion period, your prompt response would enable us to provide further clarification and explanation.\n\nBest regards, \n\nAuthors"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2120/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700516950699,
                "cdate": 1700516950699,
                "tmdate": 1700516950699,
                "mdate": 1700516950699,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8wEKCZRvp5",
                "forum": "2V1Z0Jdmss",
                "replyto": "10Es8yxA2K",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer mcnh"
                    },
                    "comment": {
                        "value": "Dear Reviewer mcnh,\n\nThanks a lot for your valuable efforts in reviewing our manuscript.\nJust a kind reminder that the discussion stage is closing soon.\nIf there are any unclear explanations or descriptions, we can clarify them further.\n\nBest regards, \n\nAuthors"
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2120/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700689534289,
                "cdate": 1700689534289,
                "tmdate": 1700689534289,
                "mdate": 1700689534289,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "daWwPiD9UZ",
            "forum": "2V1Z0Jdmss",
            "replyto": "2V1Z0Jdmss",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2120/Reviewer_3ew1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2120/Reviewer_3ew1"
            ],
            "content": {
                "summary": {
                    "value": "The paper provides an empirical investigation into the generalization capabilities of deep neural networks (DNNs), focusing on understanding various facets of overfitting. The authors introduce the concept of over-memorization, a phenomenon where DNNs excessively retain specific training patterns, leading to diminished generalization. To mitigate this issue, the paper suggests techniques such as the removal of high-confidence natural patterns and the application of data augmentation. The effectiveness of these strategies is demonstrated through a series of experiments.\n\nThis paper makes a valuable contribution to the field by shedding light on the over-memorization behavior in DNNs and its implications for generalization. By addressing the highlighted areas for improvement, the authors have the potential to further enhance the significance and applicability of their work."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Clarity and Structure: The paper is commendable for its well-organized structure and clear exposition. The authors have provided a thorough background and review of related work, successfully setting the stage for their empirical analysis.\n\n2. Robust Experimental Design: The experimental setup is meticulously designed, encompassing various types of overfitting and delving into the over-memorization behavior of DNNs. This comprehensive approach enhances the validity of the findings.\n\n3. Novel Insight into Overfitting: The identification of over-memorization as a common thread linking different types of overfitting is an innovative contribution. This insight adds depth to our understanding of how overfitting impacts the generalization abilities of DNNs."
                },
                "weaknesses": {
                    "value": "1. Limited Scope of Empirical Analysis: The paper's empirical analysis predominantly focuses on a specific network architecture and dataset. Expanding the analysis to include a wider array of cases or providing a theoretical framework to support the observed behaviors would bolster the generality and impact of the findings.\n\n2. Partial Improvement on Overfitting Types: According to the results presented in Tables 2-4, the proposed strategies seem to predominantly ameliorate Class Overfitting (CO), with only marginal improvements on Natural Overfitting (NO) and Random Overfitting (RO). A more detailed exploration of why these discrepancies occur would provide valuable insights.\n\n3. Need for Larger-Scale Evaluation: The experiments are confined to relatively simple datasets (CIFAR-10/100) and ResNet-based architectures. Extending the evaluation to encompass larger-scale datasets and alternative architectures, such as transformers, would enhance the representativeness of the results and the applicability of the findings."
                },
                "questions": {
                    "value": "1. Expand Empirical Analysis: To strengthen the paper's contributions, the authors should consider conducting additional empirical analyses across diverse network architectures and datasets.\n\n2. Deepen Analysis on Overfitting Types: A more nuanced exploration of the varying impacts on different types of overfitting would provide a richer understanding of the phenomena at play.\n\n3. Consider Larger-Scale and Diverse Architectures: Incorporating experiments with larger datasets and a variety of neural network architectures would ensure that the findings are more widely applicable and representative of the broader deep learning landscape."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2120/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698727863752,
            "cdate": 1698727863752,
            "tmdate": 1699636144579,
            "mdate": 1699636144579,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PSqZp0MNeO",
                "forum": "2V1Z0Jdmss",
                "replyto": "daWwPiD9UZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 3ew1"
                    },
                    "comment": {
                        "value": "We sincerely appreciate your time and effort in reviewing our manuscript. After careful consideration, please find our responses to your comments below.\n\n>**Q1: Transformer-based Architecture**\n\nA1: \nWe have validated the effectiveness of our method within CNN-based architectures, demonstrating its ability to alleviate overfitting by preventing over-memorization.\nTo further substantiate our perspective, we verify our method on the Transformer-based architecture.\nConstrained by computational resources, we trained a ViT-small model, initializing it with pre-trained weights from the Timm Python library.\nThe training spanned 100 epochs, starting with an initial learning rate of 0.001 and divided by 10 at the 50th and 75th epochs.\nWe set the batch-size to 64 and the loss threshold $\\mathcal{T}$ to 0.1, maintaining other hyperparameters as the original settings.\nWe report the natural training test error at both the best and last checkpoint on CIFAR 10.\n\n|Method|Best($\\downarrow$)|Last($\\downarrow$)|Diff($\\downarrow$)|\n|:-----|:----:|:----:|:----:|\n|Baseline|1.49|1.75|-0.26|\n|Baseline + $DOM_{RE}$|**1.47**|**1.67**|**-0.20**|\n|Baseline + AUGMIX|1.24|1.29|**-0.05**|\n|Baseline + AUGMIX + $DOM_{DA}$|**1.20**|**1.28**|-0.08|\n|Baseline + RandAugment|1.21|1.29|-0.08|\n|Baseline + RandAugment + $DOM_{DA}$|**1.15**|**1.22**|**-0.07**|\n\nThe above table shows the effectiveness of our method on the Transformer-based architecture.\nBy mitigating over-memorization, both $DOM_{RE}$ and $DOM_{DA}$ not only improve model performance at both the best and last checkpoints, but also contribute to alleviating overfitting.\nWe have included this experimental result in Appendix E of the rebuttal revision.\n\n>**Q2: Larger-scale Dataset**\n\nA2: \nWe also verified the effectiveness of our method on the larger-scale dataset Tiny-ImageNet.\nWe set the loss threshold $\\mathcal{T}$ to 0.2, and other hyperparameters remain as the original settings.\nWe report the natural training test error at both the best and last checkpoint using PreactResNet-18.\n\n|Method|Best($\\downarrow$)|Last($\\downarrow$)|Diff($\\downarrow$)|\n|:-----|:----:|:----:|:----:|\n|Baseline|35.03|35.24|-0.21|\n|Baseline + $DOM_{RE}$|**34.89**|**34.99**|**-0.10**|\n|Baseline + AUGMIX|34.98|35.15|-0.17| \n|Baseline + AUGMIX + $DOM_{DA}$|**34.56**|**34.77**|**-0.21**|\n|Baseline + RandAugment|33.45|33.89|-0.44|\n|Baseline + RandAugment + $DOM_{DA}$|**33.40**|**33.59**|**-0.19**|\n\nThe above table illustrates the effectiveness of our method, $DOM_{RE}$ and $DOM_{DA}$, on the Tiny-ImageNet dataset.\nThese results indicate that preventing over-memorization can improve model performance and reduce the generalization gap on large-scale datasets.\nWe have included this experimental result in Appendix F of the rebuttal revision.\n\n\n>**Q3: Marginal Improvement**\n\nA3: \nThe impact of DOM is associated with the overfitting's degree in various training paradigms.\nFor instance, the CO shows a significant decline in model generalization ability, and as a result, the DOM can provide a substantial improvement in this scenario.\nOn the other hand, the NO shows a slight generalization gap between the best and last checkpoints, which leads to a relatively modest performance improvement by DOM.\nHowever, it's important to emphasize that, our study is dedicated to holistically understanding and alleviating different types of overfitting.\nAs a general framework, DOM can consistently achieve notable improvements over the baseline with a subset of training samples or data augmentation, which successfully supports our perspective.\n\nIf you have any further questions or concerns, please do not hesitate to contact us. We are willing and available to provide additional information you may need."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2120/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700201629863,
                "cdate": 1700201629863,
                "tmdate": 1700201629863,
                "mdate": 1700201629863,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IhJRhoAuz5",
                "forum": "2V1Z0Jdmss",
                "replyto": "daWwPiD9UZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 3ew1"
                    },
                    "comment": {
                        "value": "Dear Reviewer 3ew1:\n\nWe hope this message finds you well.\nWe are sincerely thankful for your effort in reviewing our manuscript.\nAs a gentle reminder, we have submitted a rebuttal and a revised manuscript to address your mentioned concerns.\nGiven the constraints of the discussion period, your prompt response would enable us to provide further clarification and explanation.\n\nBest regards, \n\nAuthors"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2120/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700516928608,
                "cdate": 1700516928608,
                "tmdate": 1700516928608,
                "mdate": 1700516928608,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nl3MgxEAoL",
                "forum": "2V1Z0Jdmss",
                "replyto": "daWwPiD9UZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 3ew1"
                    },
                    "comment": {
                        "value": "Dear Reviewer 3ew1,\n\nThanks a lot for your valuable efforts in reviewing our manuscript.\nJust a kind reminder that the discussion stage is closing soon.\nIf there are any unclear explanations or descriptions, we can clarify them further.\n\nBest regards, \n\nAuthors"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2120/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700689501770,
                "cdate": 1700689501770,
                "tmdate": 1700689501770,
                "mdate": 1700689501770,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "d2eJfnRX9I",
            "forum": "2V1Z0Jdmss",
            "replyto": "2V1Z0Jdmss",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2120/Reviewer_2dX7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2120/Reviewer_2dX7"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers a unified perspective on various overfitting, including NO (natural overfitting), RO (robust overfitting), and CO (catastrophic overfitting). On top of this, the authors discover the \"over-memorization\" phenomenon that the overfitted model tends to exhibit high confidence in predicting certain training patterns and retaining a persistent memory for them. Unlike previous methods, this paper proposes a general framework called DOM (Distraction Over-Memorization) to alleviate the unified over-fitting issue. Experiments show that the proposed method outperforms other baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The discovery of the behavior \"over-memorization\" unifies different types of overfittings, which is of great help when analyzing the cause of overfitting.\n2. The paper is generally well-written, and the motivation is stated clearly.\n3. The proposed DOM framework seems promising."
                },
                "weaknesses": {
                    "value": "1. In the DOM framework, the loss threshold is set with a fixed value. However, with different datasets and loss functions, the optimal threshold could be different. Therefore, the given threshold may not be general on other occasions. The authors should further conduct ablation studies about this and discuss how to overcome this issue.\n2. The experiment settings are not precisely introduced in 3.1 and 3.2, making these conclusions challenging to reproduce. \n3. In section 3.2, the authors claim, \u201cthe AT-trained model never actually encounters natural patterns.\u201d However, methods like TRADES do encounter natural patterns. What will happen in this case? Are the conclusions observed in this paper still applicable?\n4. Why are there many 0.00 in Table 4? The authors need to give more explanation."
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2120/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2120/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2120/Reviewer_2dX7"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2120/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698766910927,
            "cdate": 1698766910927,
            "tmdate": 1699636144494,
            "mdate": 1699636144494,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "nr2mCXI7XM",
                "forum": "2V1Z0Jdmss",
                "replyto": "d2eJfnRX9I",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 2dX7"
                    },
                    "comment": {
                        "value": "We sincerely appreciate your time and effort in reviewing our manuscript. After careful consideration, please find our responses to your comments below.\n\n>**Q1: Loss Threshold Selection**  \n\nA1: \nBy utilizing the fixed loss threshold DOM, we have effectively verified and mitigated over-memorization, which negatively impacts DNNs' generalization ability.\nHowever, as a general framework, finding an optimal loss threshold for different paradigms and datasets can be cumbersome.\nTo address this challenge, we propose to use a general and unified loss threshold applicable across all experimental settings.\nSpecifically, we utilize an adaptive loss threshold [1], whose value is dependent on the loss of the model's current training batch.\nFor all experiments, we set this adaptive loss threshold $\\mathcal{T}$ to 40%, maintaining other hyperparameters as the original settings.\nWe report the natural and PGD-20 test errors for natural training (NT) and adversarial training (AT) using PreactResNet-18, respectively.\n\n|Dataset|Paradigm|Method|Best($\\downarrow$)|Last($\\downarrow$)|Diff($\\downarrow$)|\n|:-----|:----|:----|:----:|:----:|:----:|\n|CIFAR10|NT|Baseline|4.70|4.84|-0.14|\n|CIFAR10|NT|Baseline + $DOM_{RE}$| **4.60** | **4.67**|**-0.07**|\n|CIFAR10|NT|Baseline + AUGMIX|4.35|4.52|-0.17|\n|CIFAR10|NT|Baseline + AUGMIX + $DOM_{DA}$|**4.22**|**4.37**|**-0.15**|\n|CIFAR10|NT|Baseline + RandAugment|4.02|4.31|-0.29|\n|CIFAR10|NT|Baseline + RandAugment + $DOM_{DA}$|**3.85**|**3.94**|**-0.09**|\n|CIFAR100|NT|Baseline|21.32|21.59|**-0.27**|\n|CIFAR100|NT|Baseline + $DOM_{RE}$|**21.20**|**21.47**|**-0.27**|\n|CIFAR10|Multi-step AT|Baseline|47.67|54.84|-7.17|\n|CIFAR10|Multi-step AT|Baseline + $DOM_{RE}$|**46.55**|**52.87**|**-6.32**|\n|CIFAR10|Single-step AT|Baseline|57.83|100.00|-42.17|\n|CIFAR10|Single-step AT|Baseline + $DOM_{RE}$|**54.56**|**55.38**|**-0.82**|\n\nThe above table demonstrates the effectiveness of the adaptive loss threshold across different paradigms and datasets.\nThis threshold can not only consistently identify over-memorization patterns and mitigate overfitting, but also be easily transferable without the need for hyperparameter tuning.\nWe have included this experimental result in Appendix B of the rebuttal revision.\n\n\n>**Q2:Detailed Experiment Settings** \n\nA2: \nIn Section 3, we conducted all experiments on the CIFAR-10 dataset using PreactResNet-18.\nWe analyzed the proportion of natural and adversarial patterns by examining the respective natural and adversarial training loss.\nIn Section 3.1, we categorized between original and transformed high-confidence patterns using an auxiliary model, which was saved at the first learning rate decay (150th epoch).\nIn Section 3.2 Fig. 4, we grouped adversarial patterns based on their corresponding natural training loss, employing a loss threshold of 1.5.\nWe have included this explanation in Appendix C of the rebuttal revision.\n\n>**Q3: TRADES Result** \n\nA3: \nOur study investigated the prediction behaviour of the PGD-trained model, which does not encounter natural patterns during the training process.\nIn PGD, we observed a similar memory tendency between natural and adversarial patterns within a single over-memorization sample.\nWe further explored this observation in the TRADES-trained model, which encounters natural patterns during the training process.\nFrom Fig. 6 in the rebuttal revision, we can observe that TRADES demonstrates a consistent memory tendency with PGD in the over-memorization samples.\nThis tendency manifests as, when DNNs over-memorize certain adversarial patterns, they tend to simultaneously exhibit high-confidence in predicting the corresponding natural patterns.\nWe have included this result in Appendix D of the rebuttal revision.\n\n>**Q4: CO Results** \n\nA4: \nOur approach employs data augmentation to prevent the model from over-memorizing training patterns, thereby alleviating overfitting.\nHowever, due to the inherent randomness of the original data augmentation, it cannot reliably and consistently prevent over-memorization.\nTo overcome this issue, our method $DOM_{DA}$ applies iterative data augmentation, which is strategically designed to maximize the likelihood of hindering over-memorization.\nNonetheless, the effectiveness of our proposed method is dependent on the quality of the original data augmentation technique, which could still be incapable of disrupting over-memorization even after the iterative operation.\nWe have discussed this concern in the limitations of the original submission.\n\nIf you have any further questions or concerns, please do not hesitate to contact us. We are willing and available to provide additional information you may need.\n\n[1] Berthelot, D., Roelofs, R., Sohn, K., Carlini, N., & Kurakin, A. (2021, October). AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation. In International Conference on Learning Representations."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2120/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700201552309,
                "cdate": 1700201552309,
                "tmdate": 1700201552309,
                "mdate": 1700201552309,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cFbQStu9rS",
                "forum": "2V1Z0Jdmss",
                "replyto": "d2eJfnRX9I",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 2dX7"
                    },
                    "comment": {
                        "value": "Dear Reviewer 2dX7:\n\nWe hope this message finds you well.\nWe are sincerely thankful for your effort in reviewing our manuscript.\nAs a gentle reminder, we have submitted a rebuttal and a revised manuscript to address your mentioned concerns.\nGiven the constraints of the discussion period, your prompt response would enable us to provide further clarification and explanation.\n\nBest regards, \n\nAuthors"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2120/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700516888624,
                "cdate": 1700516888624,
                "tmdate": 1700516888624,
                "mdate": 1700516888624,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "K42bwBkIEU",
                "forum": "2V1Z0Jdmss",
                "replyto": "d2eJfnRX9I",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2120/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 2dX7"
                    },
                    "comment": {
                        "value": "Dear Reviewer 2dX7,\n\nThanks a lot for your valuable efforts in reviewing our manuscript.\nJust a kind reminder that the discussion stage is closing soon.\nIf there are any unclear explanations or descriptions, we can clarify them further.\n\nBest regards, \n\nAuthors"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2120/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700689437258,
                "cdate": 1700689437258,
                "tmdate": 1700689437258,
                "mdate": 1700689437258,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]