[
    {
        "title": "MultiIoT: Towards Large-scale Multisensory Learning for the Internet of Things"
    },
    {
        "review": {
            "id": "i7Tsnctb78",
            "forum": "eS5zjXvxf8",
            "replyto": "eS5zjXvxf8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission758/Reviewer_4SPn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission758/Reviewer_4SPn"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes MultiIOT which includes over 1.15 million samples from 12 modalities and 8 tasks. This paper summarizes the recent developments and key challenges in the field. Then, the authors benchmark the different model architectures for processing multi-modal sensory signals and propose some insights."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- I like the author's efforts in incorporating more modalities in understanding the scenes and human behaviors. This work is in general well-motivated and I believe this work would be interesting for future ML research from an application standpoint. \n- Discussions on current situations in the field and outstanding challenges are well-written and easy to follow."
                },
                "weaknesses": {
                    "value": "The main weaknesses of this work are the technical contribution and experimental evaluation.\n- For dataset and benchmark, in Sec. 2.2 the authors claim 'We collected diverse data from IoT devices, such as Inertial Measurement Units (IMU), Thermal sensors, Global Positioning Systems (GPS), capacitance, depth, gaze, and pose.' However, from my understanding, it consists of solely existing datasets while most of them contain only several modalities.\n- The experiments section contains no quantitative comparison with existing methods. There are other methods proposed for these individual tasks, and it would be difficult to evaluate the performance of the evaluated model variants without comparing them with the existing baselines."
                },
                "questions": {
                    "value": "1. Can the authors discuss if there is extra effort in consolidating the different datasets? e.g. how to unify the data format and make them really 'one' benchmark and convenient for the research community to benchmark their algorithms on all the tasks easily.\n2. What are the implementation details for each task? In Sec. B there is some brief explanation like 'Network Architecture: Distinct neural architectures optimized for each modality type, such as CNNs for images and RNNs for sequential data', but it is not enough. More experimental details are needed to understand and replicate the experiments.\n\nMinor Issues:\n- No qualitative results were provided. Authors could consider including data points and visualizations for the dataset, benchmark, and method. \n- Fig. 3 is of low visual quality. Authors could design more and better charts to illustrate the model comparisons."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission758/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission758/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission758/Reviewer_4SPn"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission758/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698565477780,
            "cdate": 1698565477780,
            "tmdate": 1699636003033,
            "mdate": 1699636003033,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "EXxmqfq36n",
            "forum": "eS5zjXvxf8",
            "replyto": "eS5zjXvxf8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission758/Reviewer_18YP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission758/Reviewer_18YP"
            ],
            "content": {
                "summary": {
                    "value": "This paper provides an extensive benchmark, MultiIoT, for machine learning of IoT applications, that contains a large amount of data samples from 12 modalities and 8 different downstream tasks. Experiments are provided to compare the performance of machine learning models trained on different learning objectives and sensory modalities on each task. The conclusion was made that multi-modal and multi-task learning is beneficial in learning useful semantics from each modality."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The coverage of the sensory modalities and downstream tasks in the paper is fairly comprehensive.\n\n2. Some of the observations made in the paper are interesting and can motivate future research in the IoT domain. For example, the authors found that the interaction of different tasks can facilitate single-task performance"
                },
                "weaknesses": {
                    "value": "1. As a benchmark, the authors did not provide a new dataset with comprehensive modality and task coverage that can be used for general IoT machine-learning models. Instead, the datasets evaluated in the benchmark all come from public resources, which only contain a subset of sensory modalities. For this reason, I feel it is actually an overclaim to address that the benchmark consists of over 1.15M samples, which comes from the sum of different datasets.\n\n2. The paper lacks a thorough comparison of how different DNN architectures, e.g., CNN, RNN, and Transformer, differ in processing the IoT sensing tasks, which in my opinion, is also an important perspective in such a benchmark.\n\n3. As an important perspective of IoT applications, the benchmark did not mention any efficiency results or considerations."
                },
                "questions": {
                    "value": "1. What is the main difference between the \"adapter models\" and \"unimodal multi-task models\"? Do they only differ in the training paradigm, where the adapter models use self-supervised pretraining, while the multi-task models simultaneously optimize for multiple downstream tasks? In my opinion, they are similar because they both utilize a shared encoder to extract the general semantics of a single sensory modality signal.\n\n2. In section 4.2, what are the scales, w.r.t the number of parameters, of each compared model? Do you guarantee that the comparison between different models is fair, by avoiding comparing the performance between models with significantly different scales?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission758/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission758/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission758/Reviewer_18YP"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission758/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698597051159,
            "cdate": 1698597051159,
            "tmdate": 1699636002944,
            "mdate": 1699636002944,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "EtoTDI9JEk",
            "forum": "eS5zjXvxf8",
            "replyto": "eS5zjXvxf8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission758/Reviewer_S9aC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission758/Reviewer_S9aC"
            ],
            "content": {
                "summary": {
                    "value": "This paper claims to present a large multi modality benchmark for Internet-of-things (IoT). There are data present from 12 modalities and 8 tasks are defined to be solved with models trained with this data. The paper further evaluates various different types of architectures to asses how best to combine the various modalities to attain the best accuracy for the various tasks. The motivation for proposing this dataset is because of the claimed need to address various challenges with multimodal data IoT data including \"High-modality multimodal learning\", \"Temporal interactions\",\"Heterogeneity\" and \"Real-time\". Overall the authors find that multi-modality multi-task networks result in the best accuracy on the tasks."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "Multimodal IoT seems like a potentially interesting under-explored topic."
                },
                "weaknesses": {
                    "value": "The paper is significantly below the acceptance level of ICLR for the following reasons.\n\n1. The paper is poorly written and lacks a clear structure, premise or narrative.\n2. It is unclear what the claimed contribution of the work is and how it advances scientific research. It reads more like an opinion piece on the topic of multimodal IoT, rather than offering any concrete scientific insights.\n3. Many of the datasets in the collection of 1.115M samples presented in this work are publicly available datasets from other research projects and not ones curated by the authors.\n4. The experiments are poorly described and simply not reproducible.\n5. The experiments have no clear conclusion or insights."
                },
                "questions": {
                    "value": "I would strongly recommend that the authors review existing published works in ICLR and other AI and computer vision conferences to understand how to improve their papers' presentation, experiments, contributions and style, etc. In its current form the paper is not acceptable as a scientific article."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission758/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699429826596,
            "cdate": 1699429826596,
            "tmdate": 1699636002879,
            "mdate": 1699636002879,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]