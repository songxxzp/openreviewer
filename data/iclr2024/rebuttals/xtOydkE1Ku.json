[
    {
        "title": "TACTiS-2: Better, Faster, Simpler Attentional Copulas for Multivariate Time Series"
    },
    {
        "review": {
            "id": "nGunQK30CT",
            "forum": "xtOydkE1Ku",
            "replyto": "xtOydkE1Ku",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6303/Reviewer_GAmJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6303/Reviewer_GAmJ"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes an improvement of TACTiS, which is a permutation-based non-parametric copulas, by adopting transformers and a two-stage training for multi-variate probabilistic time series prediction. This allows to avoid the expensive permutation-based objective, resulting in the number of distributional parameters scaling linearly in the number of variables. The authors numerically show that the resulting model can better train dynamics and achieve state-of-the-art performance, while keeping the flexibility of prior work."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "\u2022\tThe author skillfully merges statistical time series analysis with deep learning, estimating the marginal pdfs and attentional copula using autoencoders. This innovative combination results in a more efficient and rapid estimation of probability distributions compared to traditional statistical learning.\n\u2022\tThe proposed model appears highly flexible, accommodating heterogeneous datasets with uneven sampling frequencies. It also demonstrates state-of-the-art accuracies and visually impressive interpolation performance.\n\u2022\tThe author showcases a profound understanding of time series analysis by mathematically defining research problems, propositions, and definitions, accompanied by essential proofs."
                },
                "weaknesses": {
                    "value": "\u2022\tWhile the author elucidates the statistical aspects comprehensively, a more detailed explanation of the autoencoder's use would have been beneficial. For instance, discussing the motivations behind its selection, why it's deemed the best choice, or testing its performance against alternatives like variational autoencoders.\n\u2022\tIn the experiment section, the author evaluates the results using five datasets from the Monash Time Series Forecasting Repository based on dimensions, frequencies, and length. The chosen samples appear to be of a small size. Merely calculating the average rank might not provide an unbiased and comprehensive evaluation. The results would be more persuasive if the author utilized a broader range of datasets and presented a critical difference plot.\n\u2022\tThe author might consider employing other techniques, such as artificially creating uneven sampling frequencies, to garner more samples."
                },
                "questions": {
                    "value": "\u2022\tWhy using autoencoders rather than other deep learning models such as CNN to estimate the probability distributions?\n\u2022\tHow to capture the dimensional dependency using this architecture?\n\u2022\tWhy do we take this particular subset of datasets?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6303/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6303/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6303/Reviewer_GAmJ"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6303/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698673426038,
            "cdate": 1698673426038,
            "tmdate": 1699636692595,
            "mdate": 1699636692595,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mxGy2u3ZmI",
                "forum": "xtOydkE1Ku",
                "replyto": "nGunQK30CT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the very positive assessment of our work and for taking the time to highlight its strengths. Please find a response to your comments and questions below.\n\n**W1 / Q1: Choice of architecture rather than other deep learning models such as CNN to estimate the probability distributions**\n\nThe reviewer correctly states that alternative architectures, such as CNNs have been successful in time series tasks. Notable examples are included among our baselines. For instance, GPVar [1] and TimeGrad [2], which use LSTM-based architectures, and SPD [3] which uses a CNN-based architecture. In this work, our choice of using the transformer architecture is based on the added flexibility that it brings to the model [4].\n\nIn fact, a key feature of the transformer in TACTiS and TACTiS-2 is how the tokenization is performed for multivariate time series (as described in Sec 2 of our paper). We represent each value in the time series as a token paired with a timestamp and arbitrary stochastic covariates. We define our learning tasks with a mask that indicates which values are observed and which values are to be predicted. Note that this allows any learning task to be defined on the data based on the pattern of the mask. For instance, for forecasting, the values to be predicted would be at the end, while for interpolation, the values to be predicted will be in arbitrary positions in the data, and appropriate masks can be used for these tasks based on the pattern of the observed and predicted values. Arbitrary and more complex tasks can be defined using this approach. Further, as the tokenization does not impose any constraints on the data, this allows the architecture to consume arbitrarily uneven or unaligned data which often occur in the real-world. Thereby, adopting the transformer architecture in TACTiS-2 enables it as a general-purpose model satisfying the five desiderata for real-world time series problems as described in our introduction. We stress that these properties are enabled due to the flexibility of the transformer architecture.\n \n[1] Salinas, D., Bohlke-Schneider, M., Callot, L., Medico, R., and Gasthaus, J. High-dimensional multivariate forecasting with low-rank Gaussian copula processes. Advances in Neural Information Processing Systems, 32: 6827\u20136837, 2019.\n\n[2] Rasul, K., Seward, C., Schuster, I., & Vollgraf, R. (2021, July). Autoregressive denoising diffusion models for multivariate probabilistic time series forecasting. In International Conference on Machine Learning (pp. 8857-8868). PMLR.\n\n[3] Marin Bilos, Kashif Rasul, Anderson Schneider, Yuriy Nevmyvaka, and Stephan Gunnemann. Modeling temporal data as continuous functions with stochastic process diffusion. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett (eds.), Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pp. 2452\u20132470. PMLR, 23\u201329 Jul 2023.\n\n[4] Wen, Q., Zhou, T., Zhang, C., Chen, W., Ma, Z., Yan, J., & Sun, L. (2022). Transformers in time series: A survey. arXiv preprint arXiv:2202.07125."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700262960298,
                "cdate": 1700262960298,
                "tmdate": 1700264346483,
                "mdate": 1700264346483,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JmXKDRI8Ru",
                "forum": "xtOydkE1Ku",
                "replyto": "nGunQK30CT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**W2 / Q3: Justify the choice of datasets; a broader range of datasets may be utilized**\n\nWe take the opportunity to further explain why we used the five datasets - electricity, fred-md, kdd-cup, solar-10min, traffic. These were chosen due to their ubiquity in probabilistic forecasting benchmarks [1, 2, 3, 4]. TimeGrad [1] and TempFlow [2] use Solar, Electricity, Traffic in addition to two others, SPD [3] uses Electricity and Solar, and TACTiS [5] those five.\n\nNevertheless, we agree that the addition of more datasets will undoubtedly strengthen our contribution. In the short time available, we were able to evaluate the forecasting performance of TACTiS and TACTiS-2 on two new datasets, namely covid-deaths and rideshare, from the Monash Time Series Forecasting Repository [5]. We present these new results below, and add them to Appendix D.1 of the paper. As seen below, the NLL of TACTIS-2 is significantly better than that of TACTIS in both of the added datasets. \n\nTable: Mean NLL values on forecasting. Lower is better.\n| Model    | covid-deaths | rideshare |\n|----------|--------------|-----------|\n| TACTiS   | -1.605 +- 0.121 | 14.815 +- 1.101 |\n| TACTiS-2 | **-4.859 +- 0.093** | **10.451 +- 0.250** |\n\n[1] Rasul, K., Seward, C., Schuster, I., & Vollgraf, R. (2021, July). Autoregressive denoising diffusion models for multivariate probabilistic time series forecasting. In International Conference on Machine Learning (pp. 8857-8868). PMLR.\n\n[2] Rasul, K., Sheikh, A. S., Schuster, I., Bergmann, U. M., & Vollgraf, R. (2020, October). Multivariate Probabilistic Time Series Forecasting via Conditioned Normalizing Flows. In International Conference on Learning Representations.\n\n[3] Marin Bilos, Kashif Rasul, Anderson Schneider, Yuriy Nevmyvaka, and Stephan Gunnemann. Modeling temporal data as continuous functions with stochastic process diffusion. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett (eds.), Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pp. 2452\u20132470. PMLR, 23\u201329 Jul 2023.\n\n[4] Alexandre Drouin, Etienne Marcotte, and Nicolas Chapados. TACTiS: Transformer-attentional copulas for time series. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (eds.), Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pp. 5447\u20135493. PMLR, 17\u201323 Jul 2022.\n\n[5] Rakshitha Godahewa, Christoph Bergmeir, Geoffrey I. Webb, Rob J. Hyndman, and Pablo Montero-Manso. Monash time series forecasting archive. In Neural Information Processing Systems Track on Datasets and Benchmarks, 2021."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700263159431,
                "cdate": 1700263159431,
                "tmdate": 1700267545160,
                "mdate": 1700267545160,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "z4MNlu476U",
                "forum": "xtOydkE1Ku",
                "replyto": "nGunQK30CT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**W3: The author might consider employing other techniques, such as artificially creating uneven sampling frequencies, to garner more samples.**\n\nWe thank the reviewer for the suggestion. We point to the reviewer that we have added new results to the paper in Appendix D.2 validating the ability of TACTiS-2 to work with uneven and unaligned data, artificially creating uneven and unaligned data from real-world datasets. We agree with the reviewer that it would be interesting to leverage the flexibility of using artificially created samples of unaligned and uneven data as a data augmentation method when training models. Such a method would be orthogonal to TACTiS and can potentially improve its performance.  \n\n**Q2: How to capture the dimensional dependency using this architecture?**\n\nOne notable property of the TACTiS and TACTiS-2 models is that the multivariate dependencies are guaranteed to be captured by the copula component of the model, not in the others. Hence, if one is interested in inspecting dimensional dependencies to facilitate downstream decision-making tasks, one only needs to focus on the copula. For instance, one could draw samples from the copula and measure the statistical association between all dimensions. This technique was employed to inspect the learned associations in Drouin et al. (2022) [1]. Another interesting fact is that, in this work, we show that TACTiS-2 captures multivariate dependencies much better than TACTiS, as indicated by its significantly lower negative log likelihoods. Hence, this new model is poised to produce more accurate insights into multivariate dependencies, which could in turn lead to more accurate decision-making.\n\n[1] Alexandre Drouin, Etienne Marcotte, and Nicolas Chapados. TACTiS: Transformer-attentional copulas for time series. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (eds.), Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pp. 5447\u20135493. PMLR, 17\u201323 Jul 2022."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700263410753,
                "cdate": 1700263410753,
                "tmdate": 1700264375603,
                "mdate": 1700264375603,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Qsy3OFIYpp",
            "forum": "xtOydkE1Ku",
            "replyto": "xtOydkE1Ku",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6303/Reviewer_s9Tw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6303/Reviewer_s9Tw"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes TACTIS-2, a model for multivariate time series forecasting. TACTIS-2 builds upon TACTIS which uses neural networks to parameterize copulas for multivariate time series forecasting. To ensure the validity of learned copulas, TACTIS trains the model with random permutations of the variables which leads to problems with high-dimensional time series. To address this limitation, TACTIS-2 uses two stage training. In the first stage, marginal distributions are learned without any dependency between them. Later, the copula parameters are learned given the optimal marginal parameters. Forecasting and interpolation results on 5 datasets from Monash time series repository show that TACTIS-2 improves over TACTIS in terms of the prediction performance and training time."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper addresses a key limitation in the existing TACTIS model which involves $d!$ factorization of the copula density, in theory. In this work, the authors utilize existing work on copulas to transform the optimization into a two stage problem which scales linearly with the dimensionality.\n- The paper is very well written and easy to understand. It discusses the TACTIS model sufficiently for the reader to be able to understand the main contribution. \n- The proposed model performs better than TACTIS while being simpler and faster to train."
                },
                "weaknesses": {
                    "value": "- The main weakness of this work is its limited significance. The key contribution is an incremental modification of the existing TACTIS model. While the work may be interesting for individuals specifically focusing on TACTIS, its significance for the broader time series community is unclear. One may argue on the basis of the empirical results; however, in their current form, the results are not exciting and comprehensive enough to fully support this argument (see below).\n- In the absence of enough methodological contributions, the empirical contribution needs to be comprehensive. However, the experiments have only been conducted on 5 datasets from the Monash repository. The baseline selection also needs improvement for the _state of the art_ claim. CSDI and SSSD would be better baselines for the empirical comparison. \n\nTo improve the paper, consider:\n- Adding better baselines such as CSDI and SSSD.\n- Comparing on a larger set of datasets from the Monash repository.\n- Highlighting other aspects of the model. For instance, the \"flexibility to handle unaligned/unevenly-sampled series\" is mentioned multiple times in the related work but has only been studied is a toy setting."
                },
                "questions": {
                    "value": "See above.\n\n- Is there a reason why the numbers for electricity and traffic datasets differ so significantly from existing works [1]?\n\n[1] Tashiro, Yusuke, et al. \"Csdi: Conditional score-based diffusion models for probabilistic time series imputation.\" Advances in Neural Information Processing Systems 34 (2021): 24804-24816."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6303/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699039742749,
            "cdate": 1699039742749,
            "tmdate": 1699636692474,
            "mdate": 1699636692474,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JL9Gj9yguX",
                "forum": "xtOydkE1Ku",
                "replyto": "Qsy3OFIYpp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the constructive feedback and for highlighting the strengths of our work. We address the raised concerns point-by-point and hope that our responses will be satisfactory.\n\n**S1: Addressing the reviewer\u2019s comment that we utilize existing work on copulas**\n\nThe reviewer is correct in that we utilize existing work on copulas to transform the optimization into a two-stage problem. However, we re-emphasize that we do not merely apply existing work from the copula literature. We contribute to it by proving that the two-stage approach is still valid in the fully non-parametric setting, where non-parametric estimators are used for the marginal and copula distributions. This result consists of Proposition 2 and its proof in App. B.2. Section 3.2 has been edited to emphasize this point. This result is then used to propose a new optimization problem and architecture to learn attentional copulas (in Sec 4).\n\n**W1: Limited significance, incremental modification of TACTiS, significance to the broader time series community is unclear, absence of enough methodological contributions**\n\nWe respectfully disagree. Our work introduces new theoretical results on two-stage optimization of non-parametric copulas, followed by a complete change of the optimization problem in TACTiS (along with necessary architectural changes), and much better predictive performance and training dynamics across a variety of tasks. Our work makes the desirable properties of TACTiS actually usable in practice, leading to what is currently the most accurate general-purpose model for multivariate probabilistic time series prediction. We kindly ask the reviewer to refer to the \u201cSignificance of Contribution\u201d section of the general comment for an extended response to their comments and hope that they will reconsider their position.\n\n**W2: Results are not that exciting and comprehensive, empirical contribution needs to be comprehensive**\n\nWe have broadened our empirical evaluation following each of the reviewer\u2019s suggestions, as follows."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700262016421,
                "cdate": 1700262016421,
                "tmdate": 1700266446390,
                "mdate": 1700266446390,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6R1fKSGbPq",
                "forum": "xtOydkE1Ku",
                "replyto": "Qsy3OFIYpp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**W2-a: Adding CSDI and SSSD as baselines**\n\nWe thank the reviewer for the suggestion. We planned to include CSDI [2] as part of our baselines, but our results did not reach the level of performance found in their paper despite our best efforts, and hence we decided to not include it in our forecasting baselines. However, as per the reviewer\u2019s request, we present the results of CSDI and discuss them with respect to those of TACTiS-2 below. We are happy to add this comparison to the final revision of the paper. Regarding SSSD, we agree that it would make a meaningful baseline. It has been left out of our study as the published codebase [4] does not support forecasting out-of-the-box. However, we are happy to revisit this and include it in the final revision of our work. \n\nWe hereby present results that compare the CRPS-Sum, CRPS, and Energy Score of CSDI with all other methods on 4 datasets of the forecasting benchmark. We were not able to include the largest dataset (traffic) due to limited time, but we are happy to add it to the final revision of the paper.\n\nTable: Mean CRPS-Sum values for the forecasting experiments. Lower is better.\n| Model      \t| electricity \t| fred-md \t| kdd-cup \t| solar-10min \t|\n|-----------------|----------------|-----------|-----------|----------------|\n| Auto-ARIMA \t| 0.077 +- 0.016\t| 0.043 +- 0.005\t| 0.625 +- 0.066\t| 0.994 +- 0.216      \t|\n| ETS        \t| 0.059 +- 0.011\t| 0.037 +- 0.010\t| 0.408 +- 0.030 | 0.678 +- 0.097    \t|\n| TempFlow   \t| 0.075 +- 0.024\t| 0.095 +- 0.004 | 0.250 +- 0.010\t| 0.507 +- 0.034    \t|\n| SPD        \t| 0.062 +- 0.016\t| 0.048 +- 0.011\t| 0.319 +- 0.013\t| 0.568 +- 0.061    \t|\n| TimeGrad   \t| 0.067 +- 0.028  | 0.094 +- 0.030\t| 0.326 +- 0.024\t| 0.540 +- 0.044    \t|\n| GPVar      \t| 0.035 +- 0.011  | 0.067 +- 0.008\t| 0.290 +- 0.005\t| 0.254 +- 0.028   \t|\n| CSDI       \t| 0.165 +- 0.009 \t| 0.043 +- 0.005\t| 0.388 +- 0.038\t| 1.063 +- 0.081   \t|\n| TACTiS     \t| 0.021 +- 0.005 \t| 0.042 +- 0.009\t| 0.237 +- 0.013\t| 0.311 +- 0.061\t|\n| TACTiS-2   \t| **0.020 +-  0.005**\t| **0.035 +- 0.005** \t| **0.234 +- 0.011** | **0.240 +- 0.027**   \t|\n\nTable: Mean CRPS values for the forecasting experiments. Lower is better.\n\n| Model      \t| electricity \t| fred-md \t| kdd-cup \t| solar-10min \t|\n|----------------|-----------------|-----------|-----------|----------------|\n| ETS        \t| 0.094 +- 0.014 \t| 0.050 +- 0.011 \t| 0.560 +- 0.028 \t| 0.844 +- 0.119      \t|\n| Auto-ARIMA \t| 0.129 +- 0.015\t| 0.052 +- 0.005 \t| 0.477 +- 0.015 \t| 0.636 +- 0.060      \t|\n| TempFlow   \t| 0.109 +- 0.024 \t| 0.110 +- 0.003 \t| 0.451 +- 0.005 \t| 0.547 +- 0.036     \t|\n| TimeGrad   \t| 0.101 +- 0.027 \t| 0.142 +- 0.058 \t| 0.495 +- 0.023 \t| 0.560 +- 0.047      \t|\n| SPD        \t| 0.099 +- 0.016 \t| 0.058 +- 0.011 \t| 0.465 +- 0.005 \t| 0.585 +- 0.050       \t|\n| GPVar      \t| 0.067 +- 0.010 \t| 0.086 +- 0.009\t| 0.459 +- 0.009 \t| 0.298 +- 0.034       \t|\n| CSDI       \t| 0.182 +- 0.011 \t| 0.055 +- 0.006 \t| 0.527 +- 0.028 \t| 1.053 +- 0.067      \t|\n| TACTiS     \t| 0.052 +- 0.006 \t| 0.048 +- 0.010 \t| 0.420 +- 0.007 \t| 0.326 +- 0.049      \t|\n| TACTiS-2   \t| **0.049 +- 0.006** \t| **0.043 +- 0.006**\t| **0.413 +- 0.007** \t| **0.256 +- 0.029**       \t|\n\nTable: Mean Energy Score values for the forecasting experiments. Lower is better.\n| Model      | electricity (x 10000) | fred-md (x 100000) | kdd-cup (x 1000) | solar-10min (x 100) |\n|------------|-----------------------|--------------------|-----------------|---------------------|\n| Auto-ARIMA | 44.59 +- 8.56         | 8.72  +- 0.81      | 18.76  +- 3.31  | 19.42 +- 3.37      |\n| TempFlow   | 10.25 +- 2.03         | 20.16 +- 0.74      | 3.30   +- 0.19  | 4.25 +- 0.16         |\n| ETS        | 7.94  +- 0.93         | 7.90  +- 1.88      | 3.60   +- 0.24  | 4.74  +- 0.17      |\n| TimeGrad   | 9.69  +- 2.62         | 19.87  +- 7.23     | 3.30   +- 0.19  | 4.31 +- 0.23         |\n| SPD        | 8.90  +- 1.18         | 8.94  +- 1.82      | 3.13   +- 0.24  | 3.68  +- 0.31      |\n| GPVar      | 6.80  +- 0.62         | 11.43 +- 1.60      | 3.18  + 0.20    | 2.60 +- 0.10         |\n| CSDI       | 19.96 +- 0.93         | 7.97  +- 0.01      | 3.37 +- 0.21    | 7.74 +- 0.66         |\n| TACTiS     | 5.42  +- 0.57         | 8.18  +- 1.83      | 2.93 +- 0.22    | 2.88 +- 0.23         |\n| TACTiS-2   | **4.91  +- 0.52**         | **6.72  +- 0.10**      | **2.81  +- 0.19**  | **2.37 +- 0.14**         |"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700262123889,
                "cdate": 1700262123889,
                "tmdate": 1700267506071,
                "mdate": 1700267506071,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "AkgkouRhvg",
                "forum": "xtOydkE1Ku",
                "replyto": "Qsy3OFIYpp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "As the three tables above show, CSDI is far from all the other baselines in the electricity and solar-10min datasets, whereas in the fred-md and kdd-cup datasets, TACTiS-2 surpasses it by a large amount.\n\nFinally, we would like to point out that the baseline SPD [1], which we compare with, is more recent than both CSDI [2] and SSSD [3], and that it is the only one, apart from the TACTiS models, that satisfies all of the five desiderata for a general-purpose model mentioned in the introduction. Our claim that TACTiS-2 is state-of-the-art is supported by its significant improvements over a variety of classical methods, transformer-based approaches, copula-based ones, and the recent and flexible SPD. We are nevertheless happy to add CSDI and SSSD in the final revision of the paper.\n\n[1] Marin Bilos, Kashif Rasul, Anderson Schneider, Yuriy Nevmyvaka, and Stephan Gunnemann. Modeling temporal data as continuous functions with stochastic process diffusion. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett (eds.), Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pp. 2452\u20132470. PMLR, 23\u201329 Jul 2023.\n\n[2] Yusuke Tashiro, Jiaming Song, Yang Song, and Stefano Ermon. CSDI: Conditional score-based diffusion models for probabilistic time series imputation. In Advances in Neural Information Processing Systems, volume 34, 2021.\n\n[3] Juan Lopez Alcaraz and Nils Strodthoff. Diffusion-based time series imputation and forecasting with structured state space models. Transactions on Machine Learning Research, 2023. ISSN 2835-8856.\n\n[4] AI4HealthUOL, Codebase of Diffusion-based Time Series Imputation and Forecasting with Structured State Space Models (SSSD), 2023, GitHub repository, https://github.com/AI4HealthUOL/SSSD"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700262317227,
                "cdate": 1700262317227,
                "tmdate": 1700267315330,
                "mdate": 1700267315330,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fuqNhWI62b",
                "forum": "xtOydkE1Ku",
                "replyto": "Qsy3OFIYpp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**W2-b: Comparing on a larger set of datasets from the Monash repository.** \n\nFollowing the reviewer\u2019s suggestion, we conduct experiments on two additional datasets from the Monash repository. Preliminary results are reported below, which reinforce that the performance of TACTiS-2 is superior to that of TACTiS.\n\nHowever, let us start by motivating the choice of five datasets considered in the paper: electricity, fred-md, kdd-cup, solar-10min, traffic. These were chosen due to their ubiquity in probabilistic forecasting benchmarks [1, 2, 3, 4]. TimeGrad [1] and TempFlow [2] use Solar, Electricity, Traffic in addition to two others, SPD [3] uses Electricity and Solar, and TACTiS [5] those five. We further point out that these datasets cover a wide range of dimensionality (n \u2208 [107, 826]), sampling frequencies (monthly, hourly, and 10 min.), and prediction lengths (\u2113 \u2208 [12, 72]) that contributes to a comprehensive evaluation in our work. \n\nNevertheless, we agree that the addition of more datasets will undoubtedly strengthen our contribution. In the short time available, we were able to evaluate the forecasting performance of TACTiS and TACTiS-2 on two new datasets, namely covid-deaths and rideshare, from the Monash Time Series Forecasting Repository [5]. We present these new results below, and add them to Appendix D.1 of the paper. As seen below, the NLL of TACTIS-2 is significantly better than that of TACTIS in both of the added datasets. \n\nTable: Mean NLL values on forecasting. Lower is better.\n| Model    | covid-deaths | rideshare |\n|----------|--------------|-----------|\n| TACTiS   | -1.605 +- 0.121 | 14.815 +- 1.101 |\n| TACTiS-2 | **-4.859 +- 0.093** | **10.451 +- 0.250** |\n\n[1] Rasul, K., Seward, C., Schuster, I., & Vollgraf, R. (2021, July). Autoregressive denoising diffusion models for multivariate probabilistic time series forecasting. In International Conference on Machine Learning (pp. 8857-8868). PMLR.\n\n[2] Rasul, K., Sheikh, A. S., Schuster, I., Bergmann, U. M., & Vollgraf, R. (2020, October). Multivariate Probabilistic Time Series Forecasting via Conditioned Normalizing Flows. In International Conference on Learning Representations.\n\n[3] Marin Bilos, Kashif Rasul, Anderson Schneider, Yuriy Nevmyvaka, and Stephan Gunnemann. Modeling temporal data as continuous functions with stochastic process diffusion. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett (eds.), Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pp. 2452\u20132470. PMLR, 23\u201329 Jul 2023.\n\n[4] Alexandre Drouin, Etienne Marcotte, and Nicolas Chapados. TACTiS: Transformer-attentional copulas \u00b4 for time series. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (eds.), Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pp. 5447\u20135493. PMLR, 17\u201323 Jul 2022.\n\n[5] Rakshitha Godahewa, Christoph Bergmeir, Geoffrey I. Webb, Rob J. Hyndman, and Pablo Montero-Manso. Monash time series forecasting archive. In Neural Information Processing Systems Track on Datasets and Benchmarks, 2021."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700262381777,
                "cdate": 1700262381777,
                "tmdate": 1700267162413,
                "mdate": 1700267162413,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XRweRdynGr",
                "forum": "xtOydkE1Ku",
                "replyto": "Qsy3OFIYpp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**W2-c: Highlight other aspects of the model. For instance, flexibility to handle unaligned/uneven data is only done on toy datasets.**\n\nWe thank the reviewer for suggesting the use of real-world data to evaluate the flexibility properties of TACTiS-2, as it rightfully improves the experimental quality of the work. We here report results on forecasting for real-world datasets where the observations have been rendered unevenly spaced and unaligned.\n\n**Protocol and Results**: The datasets used in these experiments have been derived from real-world datasets with aligned and evenly sampled observations. To create uneven sampling, we randomly skipped the observations at some time steps in the original data. To create unalignment, we randomly selected a sampling frequency for each series in the dataset. The datasets resulting from such corruptions are faithful to real-world scenarios. Due to time constraints, we perform experiments on the kdd-cup and solar-10min datasets. These were chosen since they have the longest prediction horizon (48 and 72, respectively). A detailed discussion of the setting and implementational details has been added to the Appendix in Section D.2, and we will add results on the other datasets in the final version of the paper. As shown below, TACTiS-2 outperforms TACTiS in forecasting in real-world datasets where the data is uneven or unaligned.\n\nTable: Mean NLL values of forecasting on uneven data. Lower is better.\n| Model    | kdd-cup     | solar-10min   |\n|----------|---------|---------|\n| TACTiS   | 2.858 +- 0.476| 1.001 +- 0.783 |\n| TACTiS-2 | **1.866 +- 0.230**| **0.261 +- 0.011** |\n\nTable: Mean NLL values of forecasting on unaligned data. Lower is better.\n| Model    | kdd-cup     | solar-10min   |\n|----------|---------|---------|\n| TACTiS   | 1.527 +- 0.072 | -0.038 +- 0.220 |\n| TACTiS-2 | **0.722 +- 0.163** | **-3.218 +- 0.249** |\n\n**Q1: Why do numbers for electricity and traffic differ from existing work like in CSDI?**\n\nIn CSDI [1] the training protocol consists in using all data prior to a fixed date for training and testing on rolling windows over the subsequent data, adopting the protocol from GPVar [2]. Our work instead uses the backtesting protocol of TACTiS [3], which combines rolling-window evaluation with periodic retraining on a series of timestamps, averaging the results across these timestamps. Such a procedure mimics the use of the model in a real-world setting.\n\n[1] Yusuke Tashiro, Jiaming Song, Yang Song, and Stefano Ermon. CSDI: Conditional score-based diffusion models for probabilistic time series imputation. In Advances in Neural Information Processing Systems, volume 34, 2021.\n\n[2] Salinas, D., Bohlke-Schneider, M., Callot, L., Medico, R., and Gasthaus, J. High-dimensional multivariate forecasting with low-rank Gaussian copula processes. Advances in Neural Information Processing Systems, 32: 6827\u20136837, 2019.\n\n[3] Alexandre Drouin, Etienne Marcotte, and Nicolas Chapados. TACTiS: Transformer-attentional copulas \u00b4 for time series. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (eds.), Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pp. 5447\u20135493. PMLR, 17\u201323 Jul 2022."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700262651832,
                "cdate": 1700262651832,
                "tmdate": 1700267419616,
                "mdate": 1700267419616,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3FXbKd7dqI",
                "forum": "xtOydkE1Ku",
                "replyto": "XRweRdynGr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Reviewer_s9Tw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Reviewer_s9Tw"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your comprehensive response and for the new results. Overall, my opinion of the paper has improved and I won't oppose the acceptance of this paper. However, my main concerns on the significance and the empirical evaluation still exist to some degree. Hence, I cannot recommend acceptance confidently."
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700656951739,
                "cdate": 1700656951739,
                "tmdate": 1700657767279,
                "mdate": 1700657767279,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Ag1fn9XQOQ",
                "forum": "xtOydkE1Ku",
                "replyto": "6R1fKSGbPq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Reviewer_s9Tw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Reviewer_s9Tw"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for posting these results. I have some concerns regarding this evaluation. I have worked with the CSDI model in the past and CSDI being significantly worse than all these baselines is difficult to believe. Could there be an issue with the training and evaluation of CSDI?"
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700657219140,
                "cdate": 1700657219140,
                "tmdate": 1700657595838,
                "mdate": 1700657595838,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "g25gzbdWmd",
                "forum": "xtOydkE1Ku",
                "replyto": "AkgkouRhvg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Reviewer_s9Tw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Reviewer_s9Tw"
                ],
                "content": {
                    "comment": {
                        "value": "Based on a quick look at the SSSD repo, they seem to have configs for missing value setups but it should not be difficult to use it for forecasting. This would definitely improve the quality of the experiments. Also, check out the conditional model proposed in [1] which is similar to SSSD.\n\n[1] Kollovieh, Marcel, et al. \"Predict, refine, synthesize: Self-guiding diffusion models for probabilistic time series forecasting.\" arXiv preprint arXiv:2307.11494 (2023)."
                    }
                },
                "number": 27,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700657532024,
                "cdate": 1700657532024,
                "tmdate": 1700657532024,
                "mdate": 1700657532024,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZgX797KjK6",
            "forum": "xtOydkE1Ku",
            "replyto": "xtOydkE1Ku",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6303/Reviewer_sGoi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6303/Reviewer_sGoi"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a new model for multivariate probabilistic time series prediction. Specifically, it improves the (parameter and computation) efficiency of the previous method TACTiS by introducing a simplified objective and the corresponding learning algorithms and neural network architectures. Experiments show that the proposed method can achieve state-of-the-art performance with less computation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The proposed technique is well-motivated. It identifies the drawbacks and the reasons for the previous method TACTiS and designs specific methods to address that. \n- The paper is well-written."
                },
                "weaknesses": {
                    "value": "- Although TACTiS-2 is generally well motivated, it is still unclear how the two-stage solution in Sec 3.2 is derived. It should be clarified whether it is derived based on any assumptions/theorem or directly constructed. \n- Can the two-stage optimization achieve the optimal solution of the optimization problem in Eq. (7) and (8)? Although the optimal solution of each sub-problem in Eq (7) and (8) can be achieved, the gap between the theoretical optimal solution and the two-stage method should be discussed clearly. \n- The gap between TACTiS and TACTiS-2 can be further discussed. \n- May the author explain more about the difference between the task \u201csolar-10min\u201d and others, considerin the different behavior on it, as shown in Figure 1."
                },
                "questions": {
                    "value": "Please clarify the questions mentioned in \"Weaknesses\"."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6303/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699102455997,
            "cdate": 1699102455997,
            "tmdate": 1699636692322,
            "mdate": 1699636692322,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fe2cMweqsQ",
                "forum": "xtOydkE1Ku",
                "replyto": "ZgX797KjK6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the positive evaluation of our work. We are glad to clarify the points brought up in the review.\n\n**W1: Unclear how the two-stage solution in Sec 3.2 is derived. Any assumptions/theorem or is directly constructed.**\n\nOur proposed approach to learning non-parametric copulas is theoretically supported by Proposition 2 (Validity), which shows that any non-parametric copula learned using the proposed two-stage approach is valid. As stated in Sec. 3.2, the proof of this proposition is in App B.2. This proof relies heavily on Sklar's theorem [1]. It assumes that the random variables have continuous marginals and that the marginal and copula estimators have infinite expressivity (capacity in practical terms).\n\n[1] Abe Sklar. Fonctions de r\u00e9partition \u00e0 n dimensions et leurs marges. Publications de l\u2019Institut Statistique de l\u2019Universit\u00e9 de Paris, 8:229\u2013231, 1959.\n\n**W2: Can the two-stage optimization achieve the optimal solution of (7) and (8)? Although the optimal solution of each sub-problem in Eq (7) and (8) can be achieved, the gap between the theoretical optimal solution and the two-stage method should be discussed clearly.**\n\nYes, Proposition 2 shows that, given estimators with sufficient capacity and continuous random variables, the two-stage procedure is guaranteed to attain the optimum for both Problems (7) and (8) and that this also corresponds to the minimum of Problem (4). We refer the reviewer to App. B.2 for a detailed proof.\n\nBeyond the theoretical guarantee provided by Proposition 2, Section 5.1 brings empirical evidence that the optimal solution can even be attained in conditions of finite amounts of data, model capacity, and training time. Using a distribution where the ground-truth copula is known, Fig 3 shows that our two-stage approach leads to a learned copula density that closely matches the ground truth. Fig 14 in the Appendix Section B.3 further shows that the learned marginal distributions closely match the ground truth. Hence, this experiment confirms that our two-stage procedure can reach the optimal solution of Problems (7) and (8), respectively, in a practical setting.\n\nAs for real-world datasets where the ground-truth copula is not known, we remark that it is not possible to verify that a solution is optimal. Yet, we now provide evidence that the two-stage procedure reaches solutions that are closer to the optimum (i.e., the minimum of Problem (4)) than alternative approaches: \n\n1. Using the permutation-based approach of Drouin et al. (2022) [1] (denoted as TACTiS), and \n\n2. Optimizing Problem (4) directly without the two-stage procedure (denoted as TACTiS-2 without the curriculum). \n\nThis can be observed in the following table, which shows that, out of all considered approaches, the two-stage curriculum used in TACTiS-2 leads to the smallest negative log-likelihoods, indicating that TACTiS-2's solutions are the closest to optimality.\n\nTable: Mean NLL values on forecasting. Results are over a single backtesting timestamp. Lower is better.\n| Model                           | KDD      | Solar  |\n|-----------------------------|----------|--------|\n| TACTiS                          | 0.489 +- 0.095 | -1.458 +- 0.278 |\n| TACTiS-2 without the curriculum | -0.086 +- 0.206| -2.654 +- 0.192 |\n| TACTiS-2                        | **-1.343 +- 0.055**| **-5.107 +- 0.287** |"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700261143914,
                "cdate": 1700261143914,
                "tmdate": 1700267030039,
                "mdate": 1700267030039,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MtbnWNSKSX",
                "forum": "xtOydkE1Ku",
                "replyto": "ZgX797KjK6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**W3: The gap between TACTiS and TACTiS-2 can be further discussed.**\n\nIn addressing this comment, we interpret \u201cthe gap\u201d as \u201cthe empirical performance gap\u201d. If it was meant as \u201cmethodological gap\u201d, we invite the reviewer to refer to the \u201csignificance of contribution\u201d paragraph in the general comment for a detailed exposition of the differences between TACTiS and TACTiS-2. We will be glad to further discuss any other interpretation.\n\nTACTiS-2\u2019s superior performance is mainly due to its improved optimization procedure, which ultimately allows it to reach better solutions, in particular better values for the copula parameters. In contrast, the convergence of TACTiS is significantly slower (see Fig. 4). This likely results from: i) optimizing a much more complex objective, with a factorial parameter complexity (see Sec. 3.1), ii) jointly optimizing the marginal and copula components, and iii) from the difficulty of achieving permutation invariance, which is essential to its convergence and for the validity of the copula. Additionally, the performance of TACTiS-2 is further enhanced by its use of a dual-encoder that learns representations specialized for each distributional component.\n\nWe added this valuable discussion on the empirical gap in the revised Section 7.\n\n[1] Alexandre Drouin, Etienne Marcotte, and Nicolas Chapados. TACTiS: Transformer-attentional copulas for time series. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (eds.), Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pp. 5447\u20135493. PMLR, 17\u201323 Jul 2022.\n\n**W4: The difference between solar-10min and others:**\n\nWe thank the reviewer for the opportunity to discuss this difference. The solar-10min dataset taken from Lai et al. [1], contains solar power production records sampled every 10 minutes from 137 PV plants in Alabama. Among the considered datasets (see Appendix C.1 Table 6), this is the one with the highest sampling frequency (10 minutes). Therefore, such a dataset is rich in statistical dependencies due to the observations being very close in time. In addition, the geographical proximity of the PV plants leads to non-negligible correlations between the series due to shared factors, such as weather conditions. \n\nIndeed, the largest improvement in NLL is observed on the solar-10min dataset, as seen in Figure 1. We explain this observation by TACTiS-2\u2019s improved ability to model multivariate dependencies. As for the drop in FLOPs, as shown in Table 2, TACTiS-2 still reduces the FLOPs by a significant amount. However the drop in FLOPs in less compared to other datasets, possibly because TACTiS was already quite efficient in FLOPs for this dataset, leaving less room for improvements by TACTiS-2. \n\n[1] Lai, Guokun, et al. \"Modeling long-and short-term temporal patterns with deep neural networks.\" The 41st international ACM SIGIR conference on research & development in information retrieval. 2018."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700261215625,
                "cdate": 1700261215625,
                "tmdate": 1700335359953,
                "mdate": 1700335359953,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "GX3vSV6EXs",
            "forum": "xtOydkE1Ku",
            "replyto": "xtOydkE1Ku",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6303/Reviewer_NV8k"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6303/Reviewer_NV8k"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents an advanced model for multivariate time series prediction that excels in forecasting and interpolation tasks. By applying copula theory, the authors propose a scalable transformer-based model with linear parameterization growth and a new training curriculum. This model outperforms existing benchmarks in real-world forecasting while adeptly managing irregularly sampled data. The paper details a modification of an existing approach named TACTiS, reducing computational complexity with a linear-scaling parameterization and a new training curriculum, enhancing performance on forecasting tasks and handling irregular data."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper addresses the challenging problem of estimating joint predictive distributions for high-dimensional time series data, which has broad applicability across numerous fields.\n- It introduces a universal model framework that transcends the need for domain-specific models, potentially streamlining predictive analysis in various applications.\n- The Two-stage curriculum approach simplifies the optimization process, which is beneficial for practical implementations."
                },
                "weaknesses": {
                    "value": "- The core innovation claimed by the paper is the reduction in computational complexity through a two-stage solution, first estimating marginals and then dependencies. However, this approach isn't novel, as seen in references [1,2]. The paper would benefit from a clearer distinction of how its methodology differs significantly from these existing methods.\n- The paper's primary contribution seems to be an incremental advancement in efficiency over the TACTiS approach. More substantial evidence or arguments are needed to establish this as a significant contribution to the field.\n- When evaluating the model's efficacy, the improvement in terms of Negative Log-Likelihood (NLL) is notable. However, the Mean Continuous Ranked Probability Score (CRPS) metric indicates that these improvements are only marginal when compared to the TACTiS model.\n\n[1] Andersen, Elisabeth Wreford. \"Two-stage estimation in copula models used in family studies.\" Lifetime Data Analysis 11 (2005)\n\n[2] Joe, Harry. \"Asymptotic efficiency of the two-stage estimation method for copula-based models.\" Journal of Multivariate Analysis 94.2 (2005)."
                },
                "questions": {
                    "value": "- The core innovation claimed by the paper is the reduction in computational complexity through a two-stage solution, first estimating marginals and then dependencies. However, this approach isn't novel, as seen in references [1,2]. The paper would benefit from a clearer distinction of how its methodology differs significantly from these existing methods.\n- The paper's primary contribution seems to be an incremental advancement in efficiency over the TACTiS approach. More substantial evidence or arguments are needed to establish this as a significant contribution to the field.\n- When evaluating the model's efficacy, the improvement in terms of Negative Log-Likelihood (NLL) is notable. However, the Mean Continuous Ranked Probability Score (CRPS) metric indicates that these improvements are only marginal when compared to the TACTiS model.\n\n[1] Andersen, Elisabeth Wreford. \"Two-stage estimation in copula models used in family studies.\" Lifetime Data Analysis 11 (2005)\n\n[2] Joe, Harry. \"Asymptotic efficiency of the two-stage estimation method for copula-based models.\" Journal of Multivariate Analysis 94.2 (2005)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6303/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699327845915,
            "cdate": 1699327845915,
            "tmdate": 1699636692196,
            "mdate": 1699636692196,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dRBkyhTxui",
                "forum": "xtOydkE1Ku",
                "replyto": "GX3vSV6EXs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the thorough review of our work and for taking the time to acknowledge its strengths. In the following response, we carefully address the raised concerns. We hope that our answers are satisfactory and that the original rating will be reconsidered.\n\n**W1: The core innovation is reduction in computational complexity through a two-stage solution. However this approach isn\u2019t novel as seen in references [1] and [2].**\n\nThe reviewer is correct that such a two-stage procedure has previously been studied in the copula literature. In fact, we had attributed this approach to Joe and Xu (1996) [3] in the paper and have now added the relevant references that you suggested in the revision of the paper. As for the novelty component, we would like to emphasize that, to the best of our knowledge, previous work [1, 2, 3] has shown the validity of this approach in the context of parametric and semi-parametric copula estimation. In contrast, the use of neural networks for both the copula and marginals places us in the fully non-parametric setting. For this reason, we contribute Proposition 2 (and its proof in App. B.2), which shows that this approach is still valid in the non-parametric setting. We then proceed to using this result to make significant improvements over known approaches to learning transformer-based non-parametric copulas, constituting an additional element of novelty. We refer the reviewer to the \u201cSignificance of Contribution\u201d in the General Comment for a detailed discussion of the significance of our work.\n\n[1] Andersen, Elisabeth Wreford. \u201cTwo-stage estimation in copula models used in family studies.\u201d Lifetime Data Analysis 11 (2005)\n\n[2] Joe, Harry. \u201cAsymptotic efficiency of the two-stage estimation method for copula-based models.\u201d Journal of Multivariate Analysis 94.2 (2005).\n\n[3] Joe, Harry, and James Jianmeng Xu. 1996. \u201cThe Estimation Method of Inference Functions for Margins for Multivariate Models.\u201d R. Faculty Research and Publications. October 31.\n\n**W2: Incremental advancement in efficiency over TACTIS. More substantial evidence or arguments are needed to establish this as a significant contribution to the field.**\n\nThe reviewer is correct that our contributions result in an improvement in efficiency in comparison with TACTiS. However, the main outcome of this work is not merely a minor speedup in model training. Theoretically, the reduced parameter complexity (from factorial to linear) is a strong result in itself. Empirically, Figure 4 and App. A.3 show that TACTiS-2 converges using a fraction of the compute required by TACTiS to converge over a period of **three days**. This fact has significant practical implications (much less wasted compute, enabling more frequent retrainings, among others). Further, in addition to being more efficient, TACTiS-2 converges to much better solutions. This is reflected by improved test metrics across all tasks, which have been acknowledged by all reviewers. In conclusion, our work addresses the drawbacks (sGoi) and key limitations (s9Tw) of TACTiS, making significant progress toward unlocking the full potential of such architectures for such general-purpose modeling of time series distributions. Rightly as the reviewer points out in the strengths, such a contribution is bound to have a broad applicability across numerous fields."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700260545962,
                "cdate": 1700260545962,
                "tmdate": 1700265625100,
                "mdate": 1700265625100,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "T3rkFXrbT5",
                "forum": "xtOydkE1Ku",
                "replyto": "GX3vSV6EXs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**W3: The improvement in NLL is notable, but the mean CRPS indicates that the improvement is only marginal when compared to TACTIS.**\n\nWe agree with the reviewer that TACTiS-2 is only marginally better than TACTiS in terms of CRPS(-Sum), while still largely outperforming other baselines. This is not surprising given that both models share the same architecture for modeling marginal distributions. In fact, by definition, the CRPS only measures errors in marginal distributions. The CRPS-Sum was introduced as an alternative that accounts for multivariate dependencies and has since been established as a community standard. However, recent work emphasized that this metric is more sensitive to errors in marginal distributions than multivariate dependencies [1, 2]. Our contributions mostly affect the learning of multivariate dependencies (copula), which explains the reviewer\u2019s observation.\n\nThe NLL is known to be much more sensitive to errors in multivariate dependencies [2] and thus, we use it to further compare the models. As expected, TACTiS-2 achieves much smaller NLLs, indicating that it significantly outperforms TACTiS in learning the copula.\n\n[1] Koochali, A., Schichtel, P., Dengel, A., and Ahmed, S. Random noise vs. state-of-the-art probabilistic forecasting methods: A case study on CRPS-Sum discrimination ability. Applied Sciences, 12(10) :5104, 2022.\n\n[2] \u00c9tienne Marcotte, Valentina Zantedeschi, Alexandre Drouin, and Nicolas Chapados. Regions of reliability in the evaluation of multivariate probabilistic forecasts. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett (eds.), Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pp. 23958\u201324004. PMLR, 23\u201329 Jul 2023."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700260576438,
                "cdate": 1700260576438,
                "tmdate": 1700263618524,
                "mdate": 1700263618524,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ckDdTtFduF",
                "forum": "xtOydkE1Ku",
                "replyto": "GX3vSV6EXs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Reviewer_NV8k"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Reviewer_NV8k"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors R#NV8k. (1/2)"
                    },
                    "comment": {
                        "value": "Thanks to the authors for their efforts in preparing the response. \n\n**Novelty Concern**:\nConcerning the novel aspects of your study, my understanding is that its primary innovation lies in the application of a two-stage procedure within non-parametric settings. To enhance the clarity and impact of your contribution, it would be beneficial to explicitly detail the specific modifications you made to this procedure. Transitioning it from a parametric to a non-parametric context is advantageous, but it might be viewed as a relatively incremental advancement. Highlighting your distinct changes would better underscore the novelty of your approach.\n\n**effiency contribution**: \"The reduced parameter complexity (from factorial to linear) is a strong result in itself.\" I agree with the authors, however, I would like to clarify whether this improvement is primarily attributed to the two-stage approach, which was pre-existing?"
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700635203036,
                "cdate": 1700635203036,
                "tmdate": 1700635846556,
                "mdate": 1700635846556,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VHvevlKysH",
                "forum": "xtOydkE1Ku",
                "replyto": "GX3vSV6EXs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Reviewer_NV8k"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Reviewer_NV8k"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors R#NV8k. (2/2)"
                    },
                    "comment": {
                        "value": "Thanks to the authors for your comprehensive response, which I found clear and convincing. However, there remains one aspect I'd like to understand better. You mentioned, 'This is not surprising given that both models share the same architecture for modeling marginal distributions.' Could you clarify how the models, despite having identical architecture, differ in their performance, especially in terms of CRPS (-sum)? This clarification would be greatly appreciated.\""
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700635801422,
                "cdate": 1700635801422,
                "tmdate": 1700638930414,
                "mdate": 1700638930414,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bugRnYf5SJ",
                "forum": "xtOydkE1Ku",
                "replyto": "GX3vSV6EXs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Regarding the Novelty Concern**: We take the opportunity to stress that our primary innovation lies in the finding that, when the two-stage procedure is applied, the permutation-based objective of TACTiS [1] (Eqn (6)) is not needed to obtain valid attentional copulas, leading us to develop an objective with linear complexity (Eqn (7)). To detail the specific modifications to the underlying theory of the two-stage procedure, we remove all hypotheses about distributional assumptions and show that the two-stage procedure yields a valid solution to Problem (4): see Proposition 2 (proof in App. B.2). Further, we prove a new result showing the necessity of the two-stage approach (or an alternative method) for the non-parametric case: see Proposition 1. We will strive to make this very clear in the final revision and thank the reviewer for this feedback.\n\n**Regarding the Efficiency Contribution**: We agree with the reviewer that the efficiency improvement comes from the two-stage procedure.\nHowever, as for the improvements in the negative log likelihood, as shown in Figure 4, this is primarily attributed to the reduced parameter complexity (from factorial to linear) and the architectural innovation.\n\n\n[1] Alexandre Drouin, Etienne Marcotte, and Nicolas Chapados. TACTiS: Transformer-attentional copulas for time series. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (eds.), Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pp. 5447\u20135493. PMLR, 17\u201323 Jul 2022."
                    }
                },
                "number": 28,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700677866084,
                "cdate": 1700677866084,
                "tmdate": 1700689967661,
                "mdate": 1700689967661,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wDYdxOH028",
                "forum": "xtOydkE1Ku",
                "replyto": "bugRnYf5SJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Reviewer_NV8k"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Reviewer_NV8k"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "Thanks to the authors for their response. \n- Novelty: I recommend emphasizing your contribution separately from the two-stage approach, this would be more clear. \n\n- Efficiency: as you agree that efficiency improvement comes mainly from the two-stage approach, then you should not claim it is your contribution, as the two-stage procedure is not originally done by your side. I will suggest revising these claims on the paper, or mentioning that thanks to the two-stage approach, you have an efficiency improvement."
                    }
                },
                "number": 33,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700698234998,
                "cdate": 1700698234998,
                "tmdate": 1700698234998,
                "mdate": 1700698234998,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iU2MNd4wcK",
                "forum": "xtOydkE1Ku",
                "replyto": "wPJFg337Hy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Reviewer_NV8k"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Reviewer_NV8k"
                ],
                "content": {
                    "title": {
                        "value": "Response to the authors"
                    },
                    "comment": {
                        "value": "Thank you for your response. If the hyperparameter difference is cited as a reason for CRPS metric improvement, does this not raise concerns about a fair evaluation? Shouldn't the baseline be optimized similarly for a more equitable comparison?"
                    }
                },
                "number": 34,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700698451599,
                "cdate": 1700698451599,
                "tmdate": 1700698451599,
                "mdate": 1700698451599,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vwT1hn5eIQ",
                "forum": "xtOydkE1Ku",
                "replyto": "iU2MNd4wcK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Reviewer_NV8k"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Reviewer_NV8k"
                ],
                "content": {
                    "title": {
                        "value": "Overall review"
                    },
                    "comment": {
                        "value": "I would like to thank the authors for their efforts in the response, which clarified many points for me. While I see the potential for the work, I still have concerns regarding overclaiming for novelty and efficiency part that is mainly attributed to the two-stage approach which is not new. More efforts need to be made to clarify their novelty over just adopting a two-stage approach to non-parametric settings. I would raise my score to 6."
                    }
                },
                "number": 35,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700698832893,
                "cdate": 1700698832893,
                "tmdate": 1700698832893,
                "mdate": 1700698832893,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "h1M2QfaJWY",
                "forum": "xtOydkE1Ku",
                "replyto": "GX3vSV6EXs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6303/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> If the hyperparameter difference is cited as a reason for CRPS metric improvement, does this not raise concerns about a fair evaluation? Shouldn't the baseline be optimized similarly for a more equitable comparison?\n\nTo clarify, we use exactly the same hyperparameter search protocol for both TACTiS and TACTiS-2 (see Appendix C.3). Of course, this does not guarantee that the optimal hyperparameters will be the same for both. \n\n> While I see the potential for the work, I still have concerns regarding overclaiming for novelty and efficiency part that is mainly attributed to the two-stage approach which is not new.\n\nSec 3.2 in the paper has been revised to make it explicit that the two-stage approach has been previously studied in the copula literature (see text in blue above Eqn. 7). Of course, if the reviewer can point us to any specific lines in the paper which contain overclaims, we would be more than happy to rectify them."
                    }
                },
                "number": 36,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6303/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700705768048,
                "cdate": 1700705768048,
                "tmdate": 1700713843792,
                "mdate": 1700713843792,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]