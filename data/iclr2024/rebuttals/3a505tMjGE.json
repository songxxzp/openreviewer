[
    {
        "title": "AVOID: Alleviating VAE's Overestimation in Unsupervised OOD Detection"
    },
    {
        "review": {
            "id": "qTsYQEt3k8",
            "forum": "3a505tMjGE",
            "replyto": "3a505tMjGE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2226/Reviewer_F6GH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2226/Reviewer_F6GH"
            ],
            "content": {
                "summary": {
                    "value": "The paper discusses the over-estimation problem in VAEs: VAEs often assign a higher likelihood to OOD datapoints than ID datapoints. In analyzing this issue, the paper brings forth two different possible reasons, namely (1) the prior choice $p(z)$ being Gaussian, (2) the entropy of ID data being much higher than OOD data. The paper does this analysis by decomposing the ELBO, and then proposes two approaches to mitigate these two factors. Combining these two approaches give an unified way of handling a VAE\u2019s overestimation problem, and the authors evaluate their approach in a suite of unsupervised OOD detection tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The decomposition of the ELBO, and the two factors given for VAEs over-estimation, is novel to the best of my knowledge. It is also a clever way of analyzing the problem.\n2. Section 3.2, further analysis on Factor I. I like the simple to complex examples provided to show how $p(z)$ being a standard normal distribution can be an improper choice of prior when modeling a complex distribution.\n3. The paper is well written and easy to read.\n4. The authors have conducted a thorough set of experiments and ablations."
                },
                "weaknesses": {
                    "value": "**(Motivation)** Could the authors explain the motivation behind choosing unsupervised OOD detection and specifically VAEs? Typically, there are no shortage of labeled datapoints from the training distribution, so a few use-cases would be helpful. Also is there a particular reason for focusing on VAEs? Some prior successful unsupervised OOD detection method, such as DoSE [1], works on both VAEs and Glow, and LMD [2] uses diffusion models for OOD detection (diffusion models being the typical generative model of choice over VAEs these days).\n\n**(Notation, section 2.1)** Why is $x = \\textrm{ID}$ or $x = \\textrm{OOD}$? A better notation is $D(x) = \\textrm{ID}$ if $S(x) > T$, and so on, where $D$ is the ID-OOD classifier.\n\n**(Definition 1, VAE\u2019s overestimation)** The authors define over-estimation when the expected ELBO over the OOD distribution is larger than that on the ID distribution. This however, is a weak definition in the sense that it gives no guarantee about arbitrary samples from these distributions. For example, it is quite possible that due to overlaps between ELBO on ID and OOD data, there is no overestimation but a big fraction of the ID/OOD samples are misclassified.\n\nFor example, assume that the score function on the ID distribution has a distribution $N(10, 5)$, and that on the OOD distribution has a distribution of $N(9, 5)$. Then by definition 1, there is no overestimation issue in this case. However, it is easy to see that if we choose the threshold $T$ such that 95% of ID samples are classified as ID, then a big percentage of OOD samples would also be classified as ID. A better definition of over-confidence would take into account the threshold $T$, $P(S(x) < T | x \\sim p_{id})$ and $P(S(x) < T | x \\sim p_{ood})$.\n\nWhile I understand that this definition is chosen to facilitate the theoretical discussion/make the proofs easier, it is important to acknowledge this weakness in the paper. \n\n**(More notations)** I am assuming $p_{\\theta}(x|z)$ is the decoder distribution, and $p(x)$ represents the true distribution of $x$. This needs to be clearly stated and used in a careful manner. \n\n**(Equation 5)** Could the authors clarify the term $H_{q, p}(z|x) = -E_{p(x)q_{\\phi}(z|x)} [log(p_{\\theta}(z|x)]$ (equation 5)? The expectation is taken over the true distribution $p(x)$ but the term inside is the model distribution $p_{\\theta}(z|x)$. This is not the conditional entropy of the variable $z|x$ in the usual sense, and some explanation/clarification of notation would be useful. It is possible the model distribution is not close to the true distribution. Is there some sort of assumption that they are?\n\n**(Contribution 1 in introduction: dataset entropy mutual integration)** In the introduction, dataset entropy mutual integration is coined as:\n\n>> \u201csum of the dataset entropy and the mutual information terms between the inputs and latent variables\u201d\n\nHowever, in page 4, we see that:\n\n$$\\textrm{Ent-mut} = H_p(x) + I_q(x, z) - I_{q, p}(x, z)$$\n\nSo it is not technically a sum of entropy and mutual information, as we subtract $I_{q, p}(x, z)$ in the expression. Also what is the relevance/meaning of $I_q(x, z) - I_{q, p}(x, z)$?\n\n**(Table 1 and 2)** No error bar or uncertainty estimation is given. A lot of the methods have similar numbers, and without an error bar, it is hard to discern the results. I would request the authors to \n\nRun the experiments for 3 seeds, for each baseline, and report the standard error.\nBold the top performing method, and also any method whose average performance > lower bound on the top performing method\u2019s performance. Any equivalent formulation is also good.\n\n**I see that Table 10 and 11 in the appendix have the associated error bars**, but mentioning/referencing them in the main paper would be important. \n\n**(Lack of self-containedness)**\n\nI was looking for limitations of the paper, and it is mentioned in the appendix K. I would request this to be moved to the conclusion section to make the paper more self-contained.\n\n\n**(Nit: overclaiming)**\n\nSection 3.2\n>> the prior distribution $p(z) = N(0, I)$ is an improper choice for VAE when modeling a complex data distribution $p(x)$\n\nThis is overclaiming: \n1. what is the measure of complexity of $p(x)$? Its entropy/differential entropy? \n2. We have seen some examples when the prior being $p(z) = N(0, I)$ leads to a bad outcome. This does not prove this statement in a general sense. Better way to say this, use \u201cmay be an improper choice\u201d instead of \u201cis an improper choice\u201d, unless the authors have a more specific theorem to present.\n\n[1] Density of States Estimation for Out-of-Distribution Detection, https://arxiv.org/abs/2006.09273\n\n[2] Unsupervised Out-of-Distribution Detection with Diffusion Inpainting, https://openreview.net/forum?id=HiX1ybkFMl"
                },
                "questions": {
                    "value": "**(Understanding Post-Hoc prior)**\n\nJust to make sure I understand the method correctly: for PHP, one first trains a VAE using ELBO from equation 2:\n\n$$ELBO(x) = E_{q_{\\phi}(z|x)} [\\text{log}p_{theta}(x|z)] - D_{KL}(q_{\\phi}(z|x)||p(z))$$\n\nAnd only once this is done, PHP trains a second LSTM to learn $\\hat{q_{id}}(z)$ to match the learned $q_{id}(z)$ from the regular VAE training?\n\n**(Error related to LSTM estimation)**\n\nDoes the method assume that the LSTM learned distribution $\\hat{q_{id}}(z))$ matches $q_{id}(z)$? What happens when this match is not well, or $D_{KL}(\\hat{q_{id}}(z)||q_{id}(z))$ is high? Then it seems that PHP should not work. This seems like a key assumption for PHP to work well.\n\n**(Table 1)** \n\nWhy are the methods in supervised/auxiliary column different between FashionMNIST/MNIST and CIFAR-10/SVHN?\n\n\n**(Table 10 and 11)**\n\nWhy are the error rates of DEC 0 in table 10 and 11?\n\n\n**(Additional experimental results)**\n\nWould it be possible to produce table 1, but with CIFAR-100 used as the ID dataset? Most OOD detection papers report numbers on CIFAR-100, and it is regarded as a harder task than CIFAR-10.\n\n\n**(Computational resources)**\n\nHow much additional computation time is required for this method, including training a separate LSTM for PHP? How does this compare with other baselines?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2226/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2226/Reviewer_F6GH",
                        "ICLR.cc/2024/Conference/Submission2226/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2226/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697953212178,
            "cdate": 1697953212178,
            "tmdate": 1700673265852,
            "mdate": 1700673265852,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1pbLO9VxqD",
                "forum": "3a505tMjGE",
                "replyto": "qTsYQEt3k8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2226/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2226/Authors"
                ],
                "content": {
                    "title": {
                        "value": "(Part 1) Thanks for your insightful and constructive feedback!"
                    },
                    "comment": {
                        "value": "**Motivation:** Thanks for giving us this chance to explain our motivation for focusing on unsupervised OOD detection.\n\n1) A **real-world use case** could be autonomous driving and we want to identify whether the current driving state is similar or strange to the training set for ensuring the safety of decision-making. \nAlthough we could collect a lot of images or videos of driving in different scenarios, it would cost huge manual efforts to annotate each frame with a proper label. \nIn that case, unsupervised OOD detection could avoid the labeling process and directly model the training set's distribution. Actually, under the setting of offline RL, a core direction of research focus is to identify the out-of-distribution state-action pairs and assign them a lower reward [1]. Moreover, as the RL setting always has a lot of states, e.g., millions of time steps, it could be impossible to label every state.\n\n2) **Motivation for VAE**: VAE is estimating a lower bound (ELBO) of the marginal data log-likelihood unlike exact likelihood models like flow models and autoregressive models, thus the analyses on the relationship between ELBO and OOD detection performance are challenging and lacking. We tried to fill this research gap by identifying the two factors that contribute to the overestimation issue in ELBO-based OOD detection.\nBesides, we need to highlight that the training objective of diffusion models is also based on ELBO [2, 3], thus our analysis and proposed methods could be directly applied to diffusion models, where we have included the experiments on diffusion models in Appendix K.4.\n\n   [1] Fujimoto, Scott, David Meger, and Doina Precup. \u201cOff-policy deep reinforcement learning without exploration.\u201d ICML, 2019.\n\n   [2] Ho, Jonathan, Ajay Jain, and Pieter Abbeel. \"Denoising diffusion probabilistic models.\" NeurIPS 2020.\n\n   [3] Luo, Calvin. \"Understanding diffusion models: A unified perspective.\" arXiv preprint arXiv:2208.11970 (2022).\n\n**Notation:** Thanks for your suggestion and we have revised the notation with blue color.\n\n**Definition 1:**\nThanks for your thoughtful suggestions. \nWe highly agree with your statement that even if $\\mathcal{G}=\\mathbb{E}\\_{x\\sim p_{id}}[\\text{ELBO(x)}] - \\mathbb{E}\\_{x\\sim p_{ood}}[\\text{ELBO(x)}]>0$, there is still a certain chance that the overestimation issue could still happen on some OOD data samples.\nHowever, if $\\mathcal{G}\\leq 0$, most of the OOD data samples will be assigned unexpectedly higher ELBO values, which could be seen as **a worst case** of the failures for ELBO-based OOD detection.\nThus, we propose to address this issue $\\mathcal{G}\\leq 0$ at first to develop a promising detection method for ELBO-based generative models, which is our focus in this paper.\n\nThanks for your constructive suggestions. We agree that a definition of over-confidence would be a stricter definition and we will add it in our revision.\nWe also appreciate your understanding that the original definition is to make our theoretical analysis easier to understand, but we need to highlight that the conclusion of theoretical analysis in our paper still holds even if the definition is changed.\n\n**More notations:** Yes, $p_\\theta(x|z)$ denotes the decoder distribution paramterized with $\\theta$ and $p(x)$ is the true distribution of $x$. \nWe will highlight their definitions in our revision, and we need to highlight that the estimated data distribution $p_\\theta(x)=\\int_z p_\\theta(x|z)p(z)$ may not be equal to $p(x)$ if the VAE is not a perfect generative model."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700671254902,
                "cdate": 1700671254902,
                "tmdate": 1700671254902,
                "mdate": 1700671254902,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "goqYRq36Vh",
                "forum": "3a505tMjGE",
                "replyto": "6sk6wgk9fp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2226/Reviewer_F6GH"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2226/Reviewer_F6GH"
                ],
                "content": {
                    "title": {
                        "value": "Further comment to authors"
                    },
                    "comment": {
                        "value": "Dear authors,\n\nThanks for taking the time to go through my comments and addressing them. I have two more questions/suggestions:\n\n**(Further Question 1)**\n> Thanks for your constructive suggestions. We agree that a definition of over-confidence would be a stricter definition and we will add it in our revision. We also appreciate your understanding that the original definition is to make our theoretical analysis easier to understand, but we need to highlight that the conclusion of theoretical analysis in our paper still holds even if the definition is changed.\n\nCould you clarify what you mean by the conclusion of theoretical analysis remains the same? Could you highlight the modified definition according to what I said, the conclusion of the analysis precisely, and some argument for why it would remain the same? Sorry to be strict about this, I just want to make sure we differentiate between what holds strictly/formally (if this, then that), and what is more of an intuitive understanding (if this, then intuitively this makes sense).\n\n**(Further Question 2)**\n> Wow, we sincerely appreciate your efforts in reviewing and improving the quality of our paper. And we have modified this sentence to \"may be an improper choice\" to make the statement more rigorous.\n\nI think a more formal statement here, with some simplified toy setup, would make the paper really strong. Maybe assume that the true distribution $p(x)$ is a mixture of Gaussians, and in this case the prior distribution $p(z) \\sim N(0, I)$, and we result in over-estimation. I believe you currently show this empirically, but some proof in a simplified toy setup may give the reader a better understanding of the dynamics.\n\nI hope the authors will add these to the final version. Other than that, the authors have addressed all my concerns, and I have increased the score from 5 to 6."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700673249905,
                "cdate": 1700673249905,
                "tmdate": 1700673249905,
                "mdate": 1700673249905,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "E55QSCAF6G",
            "forum": "3a505tMjGE",
            "replyto": "3a505tMjGE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2226/Reviewer_jWXz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2226/Reviewer_jWXz"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a new anomaly score for OOD detection with VAEs: rather than use the ELBO, the paper proposes to \n1. replace the prior $p(\\mathbf{z})$ in the KL divergence term in the ELBO with the aggregated posterior $\\hat{q}_{id}(\\mathbf{z})$, which they call the post-hoc prior (PHP) method, and \n2. add a term $\\mathcal{C}(\\mathbf{x}) = \\mathbb{E}_{p_{id}}[PHP(\\mathcal{x})] \\frac{\\mathcal{C}_{non}(\\mathbf{x})}{\\mathbb{E}_{p_{id}}[\\mathcal{C}_{non}(\\mathbf{x})]}$, which they call the dataset entropy-mutual calibration (DEC) method.\n\nOn the two most classic OOD detection failures for DGMs (i.e., FMNIST vs. MNIST, CIFAR-10 vs. SVHN), using just one of PHP or DEC succeeds on one benchmark but fails on the other, while using both PHP and DEC combined (which they call AVOID) succeeds on both benchmarks. On the Celeb-A vs. CIFAR-10 and Celeb-A vs. CIFAR-100 tasks, PHP, DEC, and AVOID perform better than other VAE-based detection methods. The authors also show that AVOID performs better than the ELBO on various OOD detection tasks with FMNIST, CIFAR-10, or Celeb-A as the in-distribution dataset."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Originality: To my knowledge, the proposed method is novel.\n2. Quality: The experiments consider a wide range of baseline methods and ablations. \n3. Clarity: The paper does a good job of breaking down the presentation particularly for factor 1, e.g. from analysis to proposed method.\n4. Significance: The paper tackles the important question of understanding and improving failures in OOD detection by VAEs. In particular, I find it interesting that OOD detection with VAEs improves when substituting in the aggregate posterior for the prior in the ELBO. This result seems to provide a good example of how accounting for estimation error can improve OOD detection."
                },
                "weaknesses": {
                    "value": "1. The motivation behind DEC is unclear, and its presentation is a bit circuitous. For instance, why is the non-scaled calibration function defined as it is in Eq 19, especially when $n_i \\geq n_{id}$? There are many definitions that could satisfy property 1 (Eq 15). Also, if the point of the scaling is to be comparable to the Ent-Mut terms, why scale by Ent-Mut of the ID distribution plus a KL term rather than just the Ent-Mut term directly? It would help if, for instance, the authors can show that the performance is robust to various choices in DEC (or motivate the specific choices made).\n2. The experiments show that PHP and DEC by themselves each only minimally improve OOD detection performance in some cases. In addition, the experiments only consider certain pairs but not their reverse (e.g., FMNIST vs. MNIST but not MNIST vs. FMNIST). Considering the latter can increase confidence that the proposed solution is not overfitting on a particular type of OOD detection task.\n\nA few smaller comments:\n1. The use of \"counterfactual\" in the third paragraph in the intro seem incorrect.\n2. Eq 24 in the appendix looks wrong (though I think just due to typo; not something I noticed to affect any other part of the paper)."
                },
                "questions": {
                    "value": "1. (Repeated from above) Why is the non-scaled calibration function defined as it is in Eq 19, especially when $n_i \\geq n_{id}$? There are many definitions that could satisfy property 1 (Eq 15). Also, if the point of the scaling is to be comparable to the Ent-Mut terms, why scale by Ent-Mut of the ID distribution plus a KL term rather than just the Ent-Mut term directly? \n2. Do the authors have any hypotheses as to why PHP and DEC by themselves each only minimally improve OOD detection performance in some cases?\n3. What are the results of this method on \"reverse\" dataset pairs (e.g. ID MNIST vs. OOD FMNIST)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2226/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2226/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2226/Reviewer_jWXz"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2226/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698720870182,
            "cdate": 1698720870182,
            "tmdate": 1699636156053,
            "mdate": 1699636156053,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YvXz47wJJ2",
                "forum": "3a505tMjGE",
                "replyto": "E55QSCAF6G",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2226/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2226/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the thoughtful insights and constructive comments!"
                    },
                    "comment": {
                        "value": "We are deeply grateful for the time and effort you've dedicated to reviewing our work. Your thoughtful insights and constructive comments are immensely valuable to us!\n\n--------\n\n**W1 & Q1:**\nWe much appreciate your deep thinking of the DEC method. Yes, we acknowledge that there could be many definitions that could satisfy property 1. \nEq. 15 is only one of these definitions and is based on the SVD compressor. \"$n_i \\geq n_{id}$\" means when a data sample is more complex than the in-distribution data measured by SVD, it would need more singular values to achieve the reconstruction error $|x_{recon}-x|<\\epsilon$ with the SVD method. The \"$(n_{id} - (n_i -n_{id}))/n_{id}$\" guarantees that if and only if when $n_i=n_{id}$, $\\mathcal{C}\\_{\\text{non}}(x)=1$, and for either $n_i>n_{id}$ or $n_i < n_{id}$, the $\\mathcal{C}\\_{\\text{non}}(x)<1$. In that case, we could make sure the in-distribution data samples own a large $\\mathcal{C}_{\\text{non}}(x)$.\nWe have also included the experiments of replacing the SVD method with other image compressors, JPEG and PNG compressors, to implement the DEC method in Appendix K.6.\n\nWe acknowledge that DEC based on the data compressors could have limitations. For instance, it could have no effect in alleviating the overestimation when detecting a vertically flipped in-distribution data as OOD, in which case we could only rely on the PHP method as shown in Table 7.\n\nFor concerns of \"**why scale by Ent-Mut of the ID distribution plus a KL term**\", we may guess it could be a misunderstanding since you cannot scale to Ent-Mut term directly, which is intractable. \nRecall $$\\text{Ent-Mut}(\\theta, \\phi, p) = \\mathcal{H}\\_p(x)+\\mathcal{I}\\_{q}(x,z)-\\mathcal{I}\\_{q,p}(x,z)$$, to our knowledge, we cannot accurately estimate $\\mathcal{H}\\_p(x)$ without knowing the underlying ground truth distribution of a dataset. Besides, $\\mathcal{I}\\_{q}(x,z)-\\mathcal{I}\\_{q,p}(x,z)$ is an error term that related to the non-perfect VAE and this term is also unknown as we do not know the expression of the distribution of $p_\\theta(z|x)$ in Eq. (5).\n\nHowever, we can estimate the Ent-Mut term with the PHP method. As explained in Eq. (20), when $q_{id}(x)$ could be estimated by $\\hat{q}\\_{id}(z)$, the expectation on the ELBO becomes the Ent-Mut term. We admit with your potential underlying concern about the KL term $D_{\\text{KL}}[q_{id}(x)||\\hat{q}_{id}(z)]$ may still not be equal to 0. Our analysis for the overestimation issue appeals for further advanced methods in estimating it, and there are already existing works focusing on it, [1, 2] claims that a high-dimension input data is actually supported on a low-dimension manifold of $z$ and we could estimate it well if we find a proper dimension for $z$. Thus, our analysis could pave the way for further improvement in VAE-based OOD detection methods.\n\n[1] Dai, Bin, and David Wipf. \u201cDiagnosing and Enhancing VAE Models.\u201d International Conference on Learning Representations. 2018\n\n[2] Loaiza-Ganem, Gabriel, et al. \"Diagnosing and fixing manifold overfitting in deep generative models.\" arXiv preprint arXiv:2204.07172 (2022).\n\n**W2 & Q3:**\nThanks for your suggestion and we have added the \"**reverse experiments**\" to Appendix K.2. Results show that our method could still work well in these cases.\n\n\n**Smaller comments**:\nThanks for your careful reading and we have revised them in the paper noted with blue color.\n\n**Q2:**\nYes, we could provide an explanation for it.\nFor the PHP method, we add an experiment on Appendix K.1, where we can find the $q_{fashion}(z)$ is very distinguishable to $q_{mnist}(z)$ but the $q_{cifar10}(z)$ is not that distinguishable to $q_{svhn}(z)$, this could explain why PHP works better in FashionMNIST(ID)/MNIST(OOD) dataset pair but not that well in CIFAR10(ID)/SVHN(OOD) dataset pair. This provides an insight that learning a dataset-specific semantic latent space could achieve better OOD detection performance with the PHP method.\n\nFor the DEC method, we have previously conducted a \"VFlip\" experiment in Table 7 of Appendix F. In this experiment, the OOD data is set as the vertically flipped in-distribution data. Thus, the DEC method based on compressors cannot work at all, but our method could still rely on the PHP method to achieve promising performance on OOD detection."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700668481484,
                "cdate": 1700668481484,
                "tmdate": 1700673028483,
                "mdate": 1700673028483,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "xF1lL27ELA",
            "forum": "3a505tMjGE",
            "replyto": "3a505tMjGE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2226/Reviewer_G5ek"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2226/Reviewer_G5ek"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses the problem of generative models, specifically VAEs, when applied to OOD detection tasks. It is based upon the observation that the ELBO used in VAEs, even though it is a reasonable candidate, is an unreliable metric for OOD detection. Moreover, it tries to change the metric to come to a more reliable score to perform OOD detection.\n\nThe paper breaks down the ELBO of a dataset (being in- or out-of-distribution) into two components: (i) a negative KL divergence between the aggregate posterior $q(z)$ and the prior $p(z)$, and (ii) a negative term related to dataset entropy and mutual information between inputs and latent variables. \nIt identifies the cause of ELBO's poor performance in OOD detection, noting that the KL divergence in (i) is often overestimated and the negative entropy term in (ii) is often inflated for simpler datasets that we perform OOD detection on (for example doing OOD detection on MNIST when a model is trained on FashionMNIST). The work proposes a post-hoc correction to adjust the former (PHP) and it introduces a method (DEC) to correct the small OOD entropies by utilizing a complexity measure inspired by Serra et al. (2020).\nImplementing these adjustments successfully improves OOD detection for VAEs in challenging scenarios, such as differentiating between datasets like FashionMNIST and MNIST, or CIFAR10 and SVHN.\n\nAll in all, the study tries to address an intriguing problem, but at this stage, I cannot accept it and I will explain why in the following. I would be willing to increase my score to above the acceptance threshold if the authors can address all the important issues and suggestions that I have written in the following."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1) The paper is well-written and easy to follow.\n2) The problem of DGMs failure in OOD detection is intriguing and has been observed not only in VAEs, but almost all the likelihood-based deep generative models. Therefore, any contribution in this field is valuable.\n3) Breaking down the ELBO term is interesting from a theoretical standpoint. Although this observation is not entirely novel, as I will explain in the weaknesses, the theory is certainly sound and the method improves the OOD detection performance by large for the tasks it has considered.\n4) The toy examples are very informative and interesting."
                },
                "weaknesses": {
                    "value": "1) **(Important)** The OOD detection pathology is one-sided, meaning that it happens when you train a model on a relatively complex dataset and test it for OOD on a simpler one. However, it usually does not hold the other way around. An important feature that a good OOD detection method should have is that even though it fixes the pathological direction, it does not hinder the performance in the reverse direction. That being said, please provide the results when running the framework in the reverse direction where a VAE is trained on MNIST and tested for OOD on FashionMNIST. Similarly, when a model is trained on SVHN and tested for OOD on CIFAR10. It is well-known that many such methods hinder the performance in the other direction, one would need to make sure this does not happen for the current algorithm.\n2) **(Important)** Although the entropy and KL divergence breakdown is touted as novel, it is not entirely novel! Caterini et al. (2022) have considered breaking down the likelihood term into an entropy and a KL divergence term. In fact, in the special case where ELBO equals the likelihood and the encoder and decoder provide perfect mappings, the mutual information terms cancel out and the entropy term is pointed out in Caterini et al. (2022). However, this paper is not mentioned at all. It should most certainly be added to the next iteration of the paper.\n3) The PHP method needs to train an entirely new model which can be time-consuming. Ideally, your generative model already has a good understanding of what in-distribution means and should be able to perform OOD detection even without additional training.\n4) The DEC method is tested specifically on image data and the SVD-based algorithm also seems like a sort of \u201coutside help\u201d. Even though similar methods have been proposed in the past to fix the entropy term, such as Serra et al. (2020), I still believe that the DGM should already have the information required for OOD detection without the need for any extra model training or running modality dependent algorithms.\n5) Performing OOD detection requires adjusting an $n_{id}$ hyperparameter which is task-dependent, and there is no guarantee that one setting of this hyperparameter generalizes to all.\n6) Please cite the relevant study by Schirrmeister et al. (2020) on the reason behind the OOD detection anomaly for invertible networks.\n7) This study only considers VAEs. It would be interesting to see how the method acts in a broader context when a latent space is involved. For example, latent diffusion models are such examples. Even though other generative models might be out of the scope of the paper, it should be pointed out as a limitation of this study.\n\n**References**\n\nCaterini, Anthony L., and Gabriel Loaiza-Ganem. \"Entropic issues in likelihood-based ood detection.\" I (Still) Can't Believe It's Not Better! Workshop at NeurIPS 2021. PMLR, 2022.\n\nSchirrmeister, Robin, et al. \"Understanding anomaly detection with deep invertible networks through hierarchies of distributions and features.\" Advances in Neural Information Processing Systems 33 (2020): 21038-21049."
                },
                "questions": {
                    "value": "1) **(Important)** Although the PHP method is quite novel, it reminds me of the studies where an extra flow model is trained on the latent space of a VAE to alleviate the bias that the aggregate posterior should be Gaussian. Loaiza-Ganem et al. (2022) (which has not been referenced in this paper) show that a VAE model that has been trained again with a flow on top can perform much better in OOD detection. Could you provide some discussion on the connections between your study and theirs? And how yours is novel?\n\n2) **(Important)** Could you please generate a figure similar to Figure 3 for the CIFAR10 (vs) SVHN OOD detection task where the PHP method does not improve the performance by large?\n\n3) The computation of $C_{non}$ seems rather contrived! I might have missed it but what is the rationale behind the formula when $n_i \\ge n_{id}$? Why not choose a simple fix such as the compression scores proposed by Serra et al. (2020)? I am referring to an ensemble of FLIF, JPEG, and PNG compressions and computing the bit count for the compressed images.  Also, can I ask for a runtime analysis of computing $C(x)$? This is more of a suggestion, but I believe you can improve algorithm 1 (in Appendix D) for computing $n_i$ by performing a binary search rather than iterating over all the possible values. Since the number of potential singular values $N$ can be as high as the number of pixels, it is important to be efficient.\n\n**References**\n\nLoaiza-Ganem, Gabriel, et al. \"Diagnosing and fixing manifold overfitting in deep generative models.\" arXiv preprint arXiv:2204.07172 (2022)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2226/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2226/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2226/Reviewer_G5ek"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2226/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698805365104,
            "cdate": 1698805365104,
            "tmdate": 1700700377005,
            "mdate": 1700700377005,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "iLTEZxiCr8",
                "forum": "3a505tMjGE",
                "replyto": "xF1lL27ELA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2226/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2226/Authors"
                ],
                "content": {
                    "title": {
                        "value": "(Part 1) Thanks for the valuable comments!"
                    },
                    "comment": {
                        "value": "We sincerely appreciate the time and effort you've put into reviewing our work. Your comments are incredibly valuable to us! We have taken your concerns into consideration and hope our responses effectively address your concerns.\n\n-------------------\n\n**W1:**\nWe absolutely agree with your suggestion that an ideal OOD detection model should be bidirectionally effective.\nActually, the property you mentioned is one of the advantages of our method and we highlight the results of bidirectional comparison has been included in **Figure 5(c-d)** of first-time submission, indicating that our method can still be effective in detecting FashionMNIST as OOD when trained on MNIST as you suggest.\nOn the contrary, the previous SOTA method $\\mathcal{LLR}^{ada}$ tends to perform even worse than the basic OOD method with ELBO.\nTo make a more comprehansive comparison, we have added more experimental results to demonstrate our method's **bidirectional effectiveness in the Table 12** of Appendix K.2.\nThe key insight is that, unlike baselines like HVK and $\\mathcal{LLR}^{ada}$, the PHP and DEC are calibrations on the ELBO directly, which could improve or at least not hurt the performance of applying ELBO. Thus, when ELBO could already work well in some cases, our method could also perform well.\n\n**W2:**\nThanks for your recommendation of this interesting paper (Caterini et al. [1]) and we will cite this paper in our revision.\n\n\nFirstly, we admit that the paper you recommend is relevant to ours, but we also need to highlight that **the breakdown target of our method is different from the paper [1]**, which will be discussed below:\n\n1) Caterini et al. breakdown the expectation on the **log-likelihood $\\log p_\\theta(x)$** into two terms\n$$\\mathbb{E}\\_{x\\sim P}[\\log p_\\theta(x)]=-D_{\\text{KL}}[P||P_\\theta]-\\mathcal{H}[P]$$, which is not specified to VAEs.\n\n2) In our work, we directly breakdown the expectation on the **ELBO (lower bound of $\\log p_\\theta(x)$)** as shown in Eq. (7):\n$$\\mathbb{E}\\_{x\\sim P}[\\text{ELBO}(x)]=-D_{\\text{KL}}[q(z)||p(z)] - [\\mathcal{H}[P]+\\mathcal{I}\\_q(x,z)-\\mathcal{I}\\_{q,p}(x,z)]$$\n, which provides a lens to see what is happening in $D_{\\text{KL}}[P||P_\\theta]$ and thus operatable methods would be inspired.\n\nAdditionally, we want to show our sincereest gratitude for your insightful thinking of our paper as you claim the **\"special case\"** where ELBO equals the likelihood.\nYes, it is correct that $\\text{ELBO}(x)=\\log p_\\theta(x) =\\log P_{ID}(x)$ when there is a perfect generative model to mimic the data distribution, and there could be \n\n$$\\mathbb{E}\\_{x\\sim P_{ID}}[\\log p_\\theta(x)]-\\mathbb{E}\\_{y \\sim P_{OOD}}[\\log p_\\theta(y)]$$\n$$=\\mathbb{E}\\_{x\\sim P_{ID}}[\\text{ELBO}(x)]-\\mathbb{E}\\_{y \\sim P_{OOD}}[\\text{ELBO}(y)]$$\n$$=[-D_{KL}(P_{ID}(x)||p_\\theta(x))-\\mathcal{H}(P_{ID})] - [-D_{KL}(P_{OOD}(y)||p_\\theta(y)) - \\mathcal{H}(P_{ood})]$$\n$$=-\\mathcal{H}(P_{ID}) + \\mathcal{H}(P_{OOD}) + D_{KL}[P_{OOD}(y)||p_\\theta(y)].$$\n\nIn that case, we agree with you that calibration on the entropy term could further improve the OOD detection performance.\n\nPaper [1] also provides insights of the likelihood-ratio methods for removing the influence of entropy term, but that relies on an assumption of a perfect VAE model satisfying $P_\\theta=P_{ID}$ and find a reference model $R_\\phi$ to satisfy $D_{KL}[P_{OOD}||R_\\phi]\\leq D_{KL}[P_{ID}||R_\\phi]$. \n\nHowever, we feel very sad to emphasize that **acquiring a perfect model $P_\\theta=P_{ID}$ could be difficult and even impossible** for a long time in the future though it is theoretically possible [2,3]. \nTherefore, further **breaking down the $D_{\\text{KL}}[P||P_\\theta]$ for ELBO-based methods is extreamly necessary**. \n\nIn summary, **the novelty of our analysis is to inspire an operatable way to alleviate the overestimation issue with a theoretical guarantee for a non-perfect ELBO-based generative model, e.g., VAE,**\nwhich could be shorted as:\n1) We could further investigate which factor will lead to a bad $D_{\\text{KL}}[P||P_\\theta]$, i.e., the mismatch between the aggerated posterior $q(z)$ and prior $p(z)$ or the mutual information gap $\\mathcal{I}\\_q(x,z)-\\mathcal{I}\\_{q,p}(x,z)$;\n2) Our analysis provides a tracable way to fix the overestimation of VAEs even when it is not a perfect model to estimate $P_{ID}$, i.e., using the PHP method to replace the $p(z)$ with approximated $q_{id}(z)$ and DEC method to calibrate the Ent-Mut term. \n\n\n[1] Caterini, Anthony L., and Gabriel Loaiza-Ganem. \"Entropic issues in likelihood-based ood detection.\" I (Still) Can't Believe It's Not Better! Workshop at NeurIPS 2021. PMLR, 2022.\n\n[2] Dai, Bin, and David Wipf. \"Diagnosing and Enhancing VAE Models.\" International Conference on Learning Representations. 2018.\n\n[3] Dai, Bin, Li Kevin Wenliang, and David Wipf. \"On the Value of Infinite Gradients in Variational Autoencoder Models.\" Advances in Neural Information Processing Systems. 2021."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700669246983,
                "cdate": 1700669246983,
                "tmdate": 1700669246983,
                "mdate": 1700669246983,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "P75rCpMHcL",
                "forum": "3a505tMjGE",
                "replyto": "xF1lL27ELA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2226/Reviewer_G5ek"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2226/Reviewer_G5ek"
                ],
                "content": {
                    "title": {
                        "value": "Thank you!"
                    },
                    "comment": {
                        "value": "I appreciate the considerable effort the authors have put into revising the manuscript. My primary concerns, identified as (W1) and (W2), have been adequately addressed. Additionally, the revised compression algorithms for estimating DEC are more practical compared to the previous SVD-based method, which necessitated setting a $n_{\\text{id}}$ for each model. Consequently, I will raise my review score.\n\nThe addition of experiments involving diffusions is a noteworthy enhancement. I suggest, for further improvement, to consider formulating a diffusion as a probability flow ODE, rather than a VAE. This approach enables the actual computation of data likelihood $ p_\\theta(\\cdot)$ as mentioned in Song et al. [A]. For the comparisons in Table 17 of your final paper version, it would be beneficial to include this likelihood value as an OOD score and compare it against your method as a baseline. Please check [B] for reference, they perform the likelihood ratio on top of the ODE formulation of the diffusions. Although the model in Goodier and Campbell [B] differs from yours, they do report significantly higher AUC-ROC values.\n\n**References:**\n\n[A] Song, Yang, et al. *Maximum likelihood training of score-based diffusion models*. Advances in Neural Information Processing Systems 34 (2021): 1415-1428.\n\n[B] Goodier, Joseph, and Neill DF Campbell *Likelihood-based Out-of-Distribution Detection with Denoising Diffusion Probabilistic Models.* arXiv preprint arXiv:2310.17432 (2023)."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700700339715,
                "cdate": 1700700339715,
                "tmdate": 1700700480166,
                "mdate": 1700700480166,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "GamSr0Qbwi",
            "forum": "3a505tMjGE",
            "replyto": "3a505tMjGE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2226/Reviewer_ms1o"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2226/Reviewer_ms1o"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a new approach to address overestimation in unsupervised Out-Of-Distribution (OOD) detection using Variational Autoencoders (VAEs). In their investigation, they found two main factors that contribute to overestimation in OOD, (1) improper design of the prior, and (2) gap in entropy-mutual integration between in-distribution and out-distribution. The proposed approach uses a new score function to address the two problems. \nThe paper presents extensive experiments to validate the effectiveness of the proposed method, suggesting a competitive performance compared to literature methods. An ablation study is also presented to evaluate the behavior of the main components of the proposed approach: post-hoc prior and dataset entropy-mutual calibration."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "I found the performed evaluation of the factors that cause overestimation in OOD detection very interesting. The unsupervised approach using VAEs seems promising and robust.\nThe authors also designed a comprehensive and extensive set of experiments, including ablation studies, to evaluate the contributions of individual components of the proposed method.\nThe paper is well-organized, I liked the approach of breaking down the problem, its causes, the solution, and the experimental validation in a logical sequence.\nI believe that OOD detection represents a significant challenge in the field of machine learning. This is especially true for safety-critical applications as we are every day more dependent on automatic decision-making."
                },
                "weaknesses": {
                    "value": "Besides the large number of experiments, I think the main experiments are centered on or in variations of specific datasets like FashionMNIST and CIFAR-10.\n \nI agree with the authors that the ablation study provides insights, but I don't think the contributions of the PHP and DEC components are still clear, especially when combined.\n\nThe authors should clearly address the computational efficiency of the proposed method compared to standard VAEs and other literature approaches to the problem.\n\nI don't like to rely on t-SNE plots to make claims about the differences between in-distribution and out-of-distribution data.  While it is a popular choice for high-dimensional data visualization, I think UMAP offers several advantages as it preserves more of the global structure of the data and is more reproducible as it offers more intuitive hyperparameters. \n\nI was wondering, as the authors separate ensemble methods from non-ensemble methods in the \"Unsupervised\" category, it would be interesting to understand how the proposed method performs against ensemble methods. I was considering the performance in terms of performance and computational cost.\n\nI do believe the authors benefit from a discussion on scenarios where the proposed method might not work well. This gives readers a more balanced view and sets expectations correctly. I suggest the authors explore more of that."
                },
                "questions": {
                    "value": "Would the method work with more complex architectures, or is it specifically tailored to standard VAEs?\n\nHave the authors evaluated the robustness of the proposed idea against adversarial examples or noisy datasets?\n\nHow does overestimation influence real-world decisions or systems that rely on OOD detection? I think contextualizing that in the paper will help the reader to understand better the proposed approach."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2226/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698862466513,
            "cdate": 1698862466513,
            "tmdate": 1699636155886,
            "mdate": 1699636155886,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dh3HuyjBE0",
                "forum": "3a505tMjGE",
                "replyto": "GamSr0Qbwi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2226/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2226/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your valuable suggestions!"
                    },
                    "comment": {
                        "value": "Thanks for your valuable suggestions! To better address your concerns about our method, please allow us to interchange the order of weaknesses in your comments.\n\n**W1: UMAP Visualization**\n\nThanks for the suggestion of replacing t-SNE with UMAP visualization, and we have included the UMAP visualization of latent representations on FashionMNIST(ID) /MNIST(OOD) and CIFAR-10(ID)/SVHN(OOD) dataset pairs as shown in Fig.9 of Appendix K.1.\n\n**W2: When would the method not work well**\n\nCombining the results shown in Table 2 and also the visualization of latent representations in Fig.9, we can find that the PHP method works well in FashinMNIST(ID)/MNIST(OOD), but does not work well in CIFAR-10(ID)/SVHN(OOD).\nThe underlying reason is that the aggregated posterior q(z) of FashionMNIST is quite distinguishable from that of MNIST, but there is a significant portion of the regions overlap between the aggregated posteriors of CIFAR-10(ID) and SVHN(OOD), which leads to the performance gains brought by PHP method is not very noticeable as shown in Table 2.\n\nFor the DEC method, it will not work well when the image complexity of ID/OOD datasets is similar, e.g. FashinMNIST(ID)/MNIST(OOD) shown in Table 2 and a special case in Table 7. For the special case of Table 7 that we detect the vertically flipped in-distribution data as OOD data, the DEC method based on SVD or other image compressors does not work, but we can still rely on the PHP method to work in this special case.\n\n**W3: Contribution of PHP and DEC**\n\nContinue analyzing the experimental results in Table 2, for CIFAR-10(ID)/SVHN(OOD), we can find that the DEC method can bring about an improvement in OOD detection performance, especially when PHP is not working well. \nConversely, for FashinMNIST(ID)/MNIST(OOD), when the DEC method is not working well because of the relatively similar image complexity between ID/OOD datasets, the PHP method can bring about performance benefits.\n\nTherefore, the complementarity between PHP and DEC methods can ensure that our combined approach works well in the majority of OOD detection scenarios.\n\n**W4: Computational efficiency of the proposed method**\n\nThanks for your suggestion! We need to emphasize that both PHP and DEC methods are post-hoc methods with trained VAEs, which will not cause too many additional computation burdens.\nTo make an intuitive efficiency comparison with performing OOD detection on VAEs with ELBO, we testify to the computation efficiency from two perspectives: training time and inference time, in Table 18 and Table 19 of Appendix K.5.\nResults show that the average computation time in scoring a data point on an A100 GPU is approximately 1.5x computation time than vanilla ELBO, which is still a very small number and could be much faster if we change the SVD to other image compressors or a binary search version. The additional time for training the LSTM of the PHP method is also very fast, taking about 30 min to converge.\n\n**W5: Comparison with ensemble methods**\n\nThanks for your suggestions, we reproduce the ensemble method WAIC with an ensemble of 5 VAEs to test their performance (added to Table 2) and computation efficiency (in Table 18 and Table 19 of Appendix K.5).\n\n**Q1: Complex architecture**\n\nTo demonstrate that our method can also work well on generative models with more complex architectures, we have included the experimental results of applying our method to the recently popular diffusion model in Table 17 of Appendix K.4.\nFrom the results, we can find that our method still works well on OOD detection with trained diffusion models, demonstrating the generalizability of our approach. More experimental details can be found in K.4.\n\n**Q2: Robustness on noisy data**\nTo evaluate the robustness of the proposed method on noisy datasets, we manually introduce varying scales of random noise into input data samples to create OOD datasets at different noise levels. Then, we apply our method to these noisy datasets and obtain the experimental results as shown in Table 21 and Table 22 of Appendix K.7. We can find that our method still works well on these noisy datasets.\n\n**Q3: Influence on real-world decisions or systems that rely on OOD detection**\n\nA real-world use case could be autonomous driving we hope to identify whether the current driving state is strange to the training set for ensuring the safety of decision-making.\nIn this case, we should give lower confidence to the strange (OOD) states, otherwise, incorrect high confidence may hurt the safety.\nActually, this could be the setting of offline RL, where a core direction of research focus is to identify the out-of-distribution state-action pairs and assign them a lower reward [1]. Moreover, as the RL setting always has a lot of states, e.g., millions of steps, it could be impossible to label every state, which appeals to unsupervised OOD detection.\n\n[1] Fujimoto et al. \"Off-policy deep reinforcement learning without exploration.\" ICML, 2019."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700664605903,
                "cdate": 1700664605903,
                "tmdate": 1700672917552,
                "mdate": 1700672917552,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]