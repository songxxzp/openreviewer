[
    {
        "title": "ACES: Generating Diverse Programming Puzzles with Autotelic Language Models and Semantic Descriptors"
    },
    {
        "review": {
            "id": "10WNWRouUe",
            "forum": "hqUznsPMLn",
            "replyto": "hqUznsPMLn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7893/Reviewer_XBPq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7893/Reviewer_XBPq"
            ],
            "content": {
                "summary": {
                    "value": "The paper presented their approaches to generate diverse and solvable programming questions leveraging LLMs."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The writing is easy to follow and the entire generation and evaluation process are presented with adequate details."
                },
                "weaknesses": {
                    "value": "The contribution of this paper is pretty poor. There are several severe problems: \n\n1. The observation that LLMs can generate tasks outside the P3 dataset (the training set that is used for prompting), is basically because the LLM has been pre-trained on many larger scale coding question datasets. For example, the combination of string and grid question on page 21 is a canonical programming task. Even if it's not in P3 dataset, it's highly likely that LLM has seen this during pretraining. \n\n2. The semantic descriptor is sort of defined arbitrarily. It's fine if only used to prompt the LLM, but not quite reasonable in measuring interesting-ness and diversity. For example, solely from the human labeled P3 dataset, what's the correlation coefficients between each pairs of labels? As far as the reviewer can see, many labels are highly related, e.g. sorting and searching -> stacks and queues or tree or recursion. Using Hamming distance over those highly correlated field is problematic. Similarly, in the diversity measurement, the grid of labels is reasonable only if categories are almost independent and orthogonal to each other.\n\n3. The process relies on LLM to label the generated tasks and add them into the prompt example pool. View from the Figure 3, this labelling accuracy is far from satisfactory, especially the generation process is iterative and accumulates the errors."
                },
                "questions": {
                    "value": "1. What does the first contribution bullet in the introduction section mean? **We define the notion of semantic descriptors to leverage LLMs for the encoding of high-dimensional textual data into hard-to-compute, abstract and interpretable features of interest**\n\n2. What does the first sentence in Figure 1 caption mean?\n\n3. The page limit of 9 suggests that the reproducibility and ethics should be put after the references. \n\n4. The reviewer agrees that interesting-ness and diversity measurement itself could be a good contribution if they had been well developed."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7893/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697873740423,
            "cdate": 1697873740423,
            "tmdate": 1699636968349,
            "mdate": 1699636968349,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wz6MuYTFJb",
                "forum": "hqUznsPMLn",
                "replyto": "10WNWRouUe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7893/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7893/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer"
                    },
                    "comment": {
                        "value": "We thank Reviewer XBPq for their detailed and helpful comments and questions. \n\n>\u201cThe observation that LLMs can generate tasks outside the P3 dataset (the training set that is used for prompting), is basically because the LLM has been pre-trained on many larger scale coding question datasets. For example, the combination of string and grid question on page 21 is a canonical programming task. Even if it's not in P3 dataset, it's highly likely that LLM has seen this during pretraining.\u201d\n\nThis is true for any generative algorithm based on an LLM. Whether puzzles exist somewhere in the world or not, we\u2019re asking whether we can build an algorithm able to generate a diversity of such puzzles along a predefined set of dimensions of interest, and whether this diversity is greater than the one produced by existing algorithms. This is what this paper shows. We make no claim about the historical novelty of the generated problems. \n\n>\u201cThe semantic descriptor is sort of defined arbitrarily. It's fine if only used to prompt the LLM, but not quite reasonable in measuring interesting-ness and diversity. For example, solely from the human labeled P3 dataset, what's the correlation coefficients between each pairs of labels? As far as the reviewer can see, many labels are highly related, e.g. sorting and searching -> stacks and queues or tree or recursion. Using Hamming distance over those highly correlated field is problematic. Similarly, in the diversity measurement, the grid of labels is reasonable only if categories are almost independent and orthogonal to each other.\u201d\n\nWe agree with the concern about the selection of descriptor features for evaluation and, for this reason, include measures of diversity computed in three embedding spaces that were not used during training. This point is addressed in the general answer as it was raised by other reviewers as well.\n\nWe\u2019re not sure to understand the concern about hamming distance and the diversity measurement (entropy over cells, cell count), could you be more specific?\n\n\n> \u201cThe process relies on LLM to label the generated tasks and add them into the prompt example pool. View from the Figure 3, this labelling accuracy is far from satisfactory, especially the generation process is iterative and accumulates the errors.\u201d\n\nThis point is similar to the one above and is also answered in the general answer. The concern about the accumulation of errors is only valid for the evaluation using semantic descriptors but cannot possibly explain increased diversity in the three embedding spaces. Based on these three latter metrics alone, we can reasonably argue that our method generates a stronger diversity than existing ones. Furthermore, the bias introduced by the imperfect labeling is constant across algorithms (it should impact baselines in the same way). \n\n>\u201cWhat does the first contribution bullet in the introduction section mean? We define the notion of semantic descriptors to leverage LLMs for the encoding of high-dimensional textual data into hard-to-compute, abstract and interpretable features of interest\u201d\n\nOne contribution of our paper is to give experimenters the possibility to define abstract and interpretable features of interest that best capture the dimensions of the type of diversity they want to generate. Whereas before they could only define features they could hand-code a function for, leveraging LLM gives them more expression power. \n\n> \u201cWhat does the first sentence in Figure 1 caption mean?\u201d\n\n\u201cACES maintains an archive of discovered puzzles grouped into cells indexed by their semantic representation (skill combination)\u201d means that ACES stores and accumulates valid generated puzzles into an archive organized into different cells, where each cell corresponds to a particular semantic representation. Each representation is a binary vector describing whether skill i is required (1) or not (0) to solve the puzzle. \n\n>\u201cThe page limit of 9 suggests that the reproducibility and ethics should be put after the references.\u201d\n\nThis has been updated."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7893/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700234742987,
                "cdate": 1700234742987,
                "tmdate": 1700234742987,
                "mdate": 1700234742987,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ibDxbe8JY5",
            "forum": "hqUznsPMLn",
            "replyto": "hqUznsPMLn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7893/Reviewer_ufAe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7893/Reviewer_ufAe"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the task of automatically generating python programming puzzles.\n\nFirst, it proposes to use high-dimensional 0-1 vectors (referred to as \u201csemantic descriptors\u201d) to describe different semantic features of programming puzzles, measure the distance between puzzles and diversity of puzzle sets.\n\nSecond, it introduces an algorithm ACES that uses these semantic descriptors to generate diverse programming puzzles. Specifically, this algorithm\n\n- randomly samples a descriptor as the goal for generation,\n- retrieves similar puzzles according to the hamming distance between the goal descriptor and the descriptor of the known puzzles,\n- prompts a language model with the goal descriptor and the retrieved puzzles to generate new puzzles.\n\nThe authors evaluate the validity of LLM-labeling for the descriptors and the diversity of ACES-generated puzzles measured by semantic descriptors and other representations. They also examine whether a diversity of generated puzzles can train better code models."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. Automatic generation of programming puzzles (and more broadly, other tasks) is an interesting problem and could be very useful for the purposes the paper mentions.\n2. The paper\u2019s evaluation of diversity is multidimensional and extensive. I am convinced that the proposed algorithm does improve the diversity of generated puzzles.\n3. The qualitative analysis and the examples in the appendix show that ACES was able to generate some very non-trivial puzzles."
                },
                "weaknesses": {
                    "value": "### 1. There is a lack of discussion on literature related to diverse data generation.\n\nIn my opinion, there are important previous studies that are not cited and discussed in your paper. Therefore, I am not sure about the novelty of your algorithm.\n\nAs I understand, the proposed ACES algorithm achieves diversity with two approaches:\n\n- Specifying diverse goals with random \u201csemantic descriptors\u201d. In other words, you randomly sample a set of features (like \u201cgraph theory\u201d, \u201coptimization algorithm\u201d) and ask the model to make sure the generated puzzles include these features.\n- Mutating randomly sampled puzzles from the archive to generate new samples. Since the randomly sampled puzzles are diverse, their mutations will be diverse.\n\nThe same two approaches have been extensively used in recent studies on diverse data generation and curation that try to create more data to train and fine-tune language models. Here are some examples.\n\n**Mutation for diversity.** Unnatural Instructions [1] starts with 15 seed examples of (instruction, input, constraints) tuples and mutates a 3-example demonstration to generate new examples. Self-Instruct [2] also does similar things with (instruction, input, output) tuples and it randomly samples instructions from both the initial pool (like your P3 train set) and the generated pool (like your generated puzzle-solution pairs) to start their mutation. Evol-Instruct [3] uses an even more complicated evolutionary algorithm to mutate and generate complex instruction samples.\n\n********************************************************************Goal specification for diversity.******************************************************************** The authors claim that the semantic descriptor (binary vector that indicates which features to include) of ACES is novel and easy to interpret. I agree with the interpretability argument but not the novelty argument. TinyStories [4] also tries to create diverse stories to train language models by creating a list of story features and asking language models to include randomly sampled features from the list each time. Evol-Instruct [3] also involves rewriting and evolving the prompts towards different goals.\n\nMore importantly, even in the domain of generating coding tasks, these two approaches (mutation and goal specification) have been used to generate diverse coding tasks (though not programming puzzles). Gunasekar, Suriya, et al. [5], Code Llama [6], and WizardCoder [7] all use these approaches to instruction-tune language models.\n\nI would love to see more discussions on these related works and how ACES is different from (and better than) them.\n\n### 2. ChatGPT labeled semantic descriptor isn\u2019t good enough for measuring semantic diversity.\n\nFirst, I\u2019m not sure the confusion matrices in Figure 3 support the claim that \u201cpuzzle labeler demonstrates high true positive rates\u201d because only 3 among the 10 dimensions have true positive rates over 0.6. Could you be saying it demonstrates high true negative rates? Even so, I\u2019m a bit concerned about the accuracy of the labeler.\n\nSecond, I agree with you that \u201cthe classification does not need to be perfect to drive diversity.\u201d However, I do think it needs to be more accurate to *******measure******* diversity.\n\nYour entire claim about \u201cdiversity in semantic space\u201d is supported by a not-so-accurate labeler of semantic descriptors. Although I think it might be true, the supporting evidence you gave isn\u2019t strong.\n\n### 3. There is a lack of evaluation beyond diversity.\n\nI appreciate your efforts in evaluating diversity with multiple different metrics. However, I think there\u2019s more to data quality than diversity. While the validity check of puzzles `f(g())==True` does say something about the generated puzzles, they could still be meaningless. Therefore, I would love to see more evaluations or arguments about the quality of the generated data.\n\nSpecifically, in your qualitative analysis, you mentioned that the generation processes \u201cshift the algorithmic load from g to f, in which case g only provides arguments for f.\u201d I wonder if there were other shifts in the generation processes and if these shifts could lead to degraded puzzles. For example, could f ignore what g is doing or what the algorithmic part in itself is doing and just return True?\n\nAnother worry I have is that your goal specification could lead to an infeasible combination of features. Randomly sampled semantic descriptors could involve semantic labels that hardly appear together and create absurd problems.\n\nAs demonstrated by your section 4.4, diversity does not entail performance gain. Even though that is the case, I would love to see more evaluation and discussion about the quality of the generated puzzles beyond diversity because quality is important for education, data augmentation, and scientific discovery.\n\n### Reference\n\n[1] Honovich, Or, et al. \"Unnatural instructions: Tuning language models with (almost) no human labor.\"\u00a0*arXiv preprint arXiv:2212.09689*\u00a0(2022).\n\n[2] Wang, Yizhong, et al. \"Self-instruct: Aligning language model with self generated instructions.\"\u00a0*arXiv preprint arXiv:2212.10560*\u00a0(2022).\n\n[3] Xu, Can, et al. \"Wizardlm: Empowering large language models to follow complex instructions.\"\u00a0*arXiv preprint arXiv:2304.12244*\u00a0(2023).\n\n[4] Eldan, Ronen, and Yuanzhi Li. \"TinyStories: How Small Can Language Models Be and Still Speak Coherent English?.\"\u00a0*arXiv preprint arXiv:2305.07759*\u00a0(2023).\n\n[5] Gunasekar, Suriya, et al. \"Textbooks Are All You Need.\"\u00a0*arXiv preprint arXiv:2306.11644*\u00a0(2023).\n\n[6] Roziere, Baptiste, et al. \"Code llama: Open foundation models for code.\"\u00a0*arXiv preprint arXiv:2308.12950*\u00a0(2023).\n\n[7] Luo, Ziyang, et al. \"WizardCoder: Empowering Code Large Language Models with Evol-Instruct.\"\u00a0*arXiv preprint arXiv:2306.08568*\u00a0(2023)."
                },
                "questions": {
                    "value": "I would appreciate your answers to the questions raised in the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7893/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698335735526,
            "cdate": 1698335735526,
            "tmdate": 1699636968224,
            "mdate": 1699636968224,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "EWuSqFqSqj",
                "forum": "hqUznsPMLn",
                "replyto": "ibDxbe8JY5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7893/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7893/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer (part 1)"
                    },
                    "comment": {
                        "value": "We thank Reviewer ufAe for their detailed and helpful comments and questions. \n\n**Comparison to related works:**\n> \u201cMutation for diversity. Unnatural Instructions [1] starts with 15 seed examples of (instruction, input, constraints) tuples and mutates a 3-example demonstration to generate new examples. Self-Instruct [2] also does similar things with (instruction, input, output) tuples and it randomly samples instructions from both the initial pool (like your P3 train set) and the generated pool (like your generated puzzle-solution pairs) to start their mutation. Evol-Instruct [3] uses an even more complicated evolutionary algorithm to mutate and generate complex instruction samples.\n\n>Goal specification for diversity. The authors claim that the semantic descriptor (binary vector that indicates which features to include) of ACES is novel and easy to interpret. I agree with the interpretability argument but not the novelty argument. TinyStories [4] also tries to create diverse stories to train language models by creating a list of story features and asking language models to include randomly sampled features from the list each time. Evol-Instruct [3] also involves rewriting and evolving the prompts towards different goals.\n\n>More importantly, even in the domain of generating coding tasks, these two approaches (mutation and goal specification) have been used to generate diverse coding tasks (though not programming puzzles). Gunasekar, Suriya, et al. [5], Code Llama [6], and WizardCoder [7] all use these approaches to instruction-tune language models.\u201d\n\nWe thank the reviewer for extensive pointers to relevant prior work and agree additional discussion of code data augmentation methods is needed. We updated the related work section of the manuscript to include this. A general comment here is that these methods, coming from the synthetic training data generation literature, do not aim to optimize for diversity as a goal; usually when they include diversity promoting mechanisms it is for the sake of downstream performance only. As another general note, in addition to the semantic descriptors we introduce, there are two important aspects of our method which are goal selection (which the reviewer points out) and the evolutionary search aspect (which is different from mutation only). All algorithms we evaluate in our experiments except the static-generation are non-stationary since they add their generated data back into the candidates one can sample from. The generative process evolves over time by reusing discoveries for further discoveries. Unnatural instructions simply generates novel instructions from few-shot examples and is neither autotelic, nor diversity-maximizing or non-stationary. Self-Instruct uses both seed examples and generated examples so does display non-stationarity. However it does not maximize diversity, and it is not autotelic. Evol Instruct (as is used both in WizardLM and WizardCoder) is not autotelic, even if it is non-stationary; in any case there is no explicit diversity-maintaining mechanism and additionally there are absolutely no evaluations of the diversity of the produced dataset which prevents any conclusion.\n\nWe thank the reviewer for pointing out TinyStories to us, a work we were unaware of that is quite relevant. The proposed goal-generating process is indeed autotelic but it is not evolutionary; the generated stories are never put back in the pool. It is probably totally satisfactory for their domain because they have many different nouns to combine and the requirements to produce a valid story with an LLM are pretty low. The goals they use are a mixture of concrete words (we explicitly want to foster diversity in a space of abstract), and story features such as good or bad endings, which is very much similar to what we do and we find very interesting; they only have one abstract feature per story however (and do not measure the diversity of generated stories with respect to these features, even if we can guess that GPT4 will do fine at capturing them in their generated data). Evol-Instruct, on the other hand, has different prompts with categories of mutations but as mentioned earlier they do not attempt to measure the diversity of the actually generated samples.\n\n(the rest of the answer is in the part 2)"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7893/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700234381484,
                "cdate": 1700234381484,
                "tmdate": 1700234381484,
                "mdate": 1700234381484,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FrZHaSx8b4",
                "forum": "hqUznsPMLn",
                "replyto": "ExAcDYDhEZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7893/Reviewer_ufAe"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7893/Reviewer_ufAe"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response. It has addressed some of my concerns. I'm more convinced about ACES being able to actually improve the diversity of generated puzzles.\n\nHowever, my primary concern about this paper remains: what does it offer beyond diversity?\n\nIn terms of novelty, other than combining the features of existing works, the main novelty claimed by the authors in the response is \"optimizing diversity as a goal\". I would be ok with this novelty as long as it gets us more than diversity.\n\nAs the authors have admitted themselves in the response:\n\n> Evaluation of data quality is probably the main limitation of the proposed approach\n\nThis contradicts what the authors proposed in the introduction regarding applications:\n\n> education (generating problems for students to solve), data augmentation (generating problems and solutions for AI model training), or automated scientific discoveries (e.g. discovering new scientific problems and their solutions)\n\nI would really appreciate seeing examples or quantitative results demonstrating how ACES can serve these purposes (or other similar purposes).\n\nI think the idea mentioned in the last part of the response about discovering surprising combinations could be intriguing:\n\n> it could be that the experimenter does not see any generation that could fit a particular cell a priori, but gets surprised as the diversity search finds one. Eventually, we\u2019d like to observe such behavior where the diversity producing algorithm actually surprises us by its generations. \n\nBut is there any concrete example that the authors can provide to convince me that this is indeed the case?\n\nI would consider raising my rating if I can be convinced that ACES truly contributes more than diversity."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7893/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700490700388,
                "cdate": 1700490700388,
                "tmdate": 1700490700388,
                "mdate": 1700490700388,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZCVpItca5E",
                "forum": "hqUznsPMLn",
                "replyto": "ibDxbe8JY5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7893/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7893/Authors"
                ],
                "content": {
                    "comment": {
                        "value": ">>This contradicts what the authors proposed in the introduction regarding applications:\n\n>education (generating problems for students to solve), data augmentation (generating problems and solutions for AI model training), or automated scientific discoveries (e.g. discovering new scientific problems and their solutions)\n\n\nThank you for your feedback. While we could have devoted more effort to evaluating the data quality, this does not necessarily conflict with the proposed applications, particularly in education. For more details, see 'Answer (part 4)' in our response to reviewer AUHG (https://openreview.net/forum?id=hqUznsPMLn&noteId=6FIypHHOgY).\n\n>But is there any concrete example that the authors can provide to convince me that this is indeed the case?\n\nIn our experiment, we utilized an LLM proficient in programming, though not the most advanced in recent coding model releases. Despite this, our goal-directed methodology enabled the LLM to create creative and novel coding puzzles not found in archives from other baselines. For instance, consider this example puzzle (docstring of the puzzle): \"Given a grid of 0s and 1s, determine if there exists a path from the top-left corner to the bottom-right corner, where you can only move down, right, or diagonally down-right. Additionally, the sum of the numbers along the path must be a prime number.\"\n\nWhile this combination might not be overly surprising to an expert, it is nonetheless non-trivial. It shows the potential of our approach. Furthermore, it's worth noting that employing a more advanced LLM could potentially lead to even more creative and surprising combinations. This suggests that as AI models continue to evolve, the scope for generating intricate and intellectually stimulating puzzles in educational settings may expand significantly, offering further evidence of the practical applications of our proposed methods."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7893/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740397861,
                "cdate": 1700740397861,
                "tmdate": 1700740643475,
                "mdate": 1700740643475,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "YlaeRaQ0rg",
            "forum": "hqUznsPMLn",
            "replyto": "hqUznsPMLn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7893/Reviewer_AUHG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7893/Reviewer_AUHG"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces ACES (autotelic code exploration with semantic descriptors), a prompting-based algorithm that uses an LLM (ChatGPT) to produce a diverse set of programming puzzles. The algorithm first uses the LLM to label an existing base set of puzzles (P3, the Python Programming Puzzles dataset) as to which of ten skills (aka semantic descriptors) they require. It then proceeds iteratively to generate new puzzles. To generate each new puzzle it uses a nearest neighbor approach to construct a few-shot prompt using existing puzzles, aimed at generating a puzzle requiring a particular subset of the ten skills. It uses this prompt with an LLM to generate a puzzle-solution pair, which it keeps if the puzzle-solution pair passes. The resulting set of puzzles exhibits high diversity both according to the semantic descriptors and according to an embedding based measure of diversity. Despite the diversity of the puzzles produced, fine-tuning using the produced puzzle set does not help on the test puzzle set compared with fine-tuning on a less diverse set of puzzles produced by a baseline approach."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The approach is quite simple, and given access to an instruction-following LLM like ChatGPT, it would be straightforward to reproduce a comparable approach to ACES. The prompts included in the Appendix and the algorithm provided in the text aid in this reproducibility meaningfully. (The reliance on gpt-3.5-turbo-0613 unfortunately time-limit precise reproducibility, but other models will slot into the algorithm without issue even once gpt-3.5-turbo-0613 is no longer available.)\n* The approach leads to greater diversity in programming puzzles compared to the static gen, ELM semantic, and ELM baselines. The diversity is evident both in the number of cells covered (the objective the algorithm is designed for) and through an embedding based similarity metric.\n* The qualitative inspection of the samples generated by the ACES approach is welcome and informative. Thank you for including this.\n* The approach seems readily generalizable from the 10 selected semantic descriptors for programming puzzles to other domains where characteristics of examples can be represented as a set of features or properties present/not-present."
                },
                "weaknesses": {
                    "value": "* ACES relies on a manually crafted set of semantic descriptors that is specific to the task of generating programming puzzles. The paper does not explore the role that the selection of these semantic descriptors plays on the resulting set of programming puzzles, and does not provide insight into how the approach works in non-programming puzzle domains where these pre-selected semantic descriptors would not be appropriate.\n  * The semantic descriptor based metric is tailored specifically for the semantic descriptors selected for the approach. If the set of semantic descriptors used in the approach were to change, it's not clear the current semantic descriptor approach (holding the set of semantic descriptors fixed to allow comparing across the change) to measuring diversity would remain meaningful.\n* One weakness of this manually crafted set of semantic descriptors is that it places a kind of constraint on the diversity that the approach can produce, and it shifts the burden of identifying this diversity from the ACES algorithm itself to the human seeding the algorithm with semantic descriptors.\n* The 2**10 size grid of sets of semantic descriptors is (a) in my opinion quite small. P3 has 636 train puzzles spanning ~60-80 cells, but there are only 1024 cells in total to try to cover (using 45000 generated programs to do so). (b) I expect that many of these cells aren't meaningful, e.g. it doesn't seem that important to identify a programming puzzle that is simultaneously a Sorting and Searching, Counting and Combinators, Tree and Graph, Bit manipulation, string manipulation, recursion, and dynamic programming problem (7 semantic descriptors), and a full 38% of the cells represent the goal of having 6 or more semantic descriptors. Indeed Figure 7 confirms generating programming puzzles with 6+ semantic descriptors is quite rare, yet the algorithm spends significant time trying to do so.\n* The primary measure of diversity (number of cells covered in the archive) is both an imperfect measure (the labels used to determine which cell is covered are determined by ChatGPT) and also the same model producing the puzzles (where generation is conditioned on the desired label) is the one predicting the label. Since puzzle generation is conditioned on the goal label and the same model then predicts those labels, there is real risk of the model overestimating the amount of diversity produced. As a toy example of how this overestimation could occur, we could imagine the model adds a comment to each generated puzzle saying what labels that puzzle should have. Then during labeling, the model ignores the code and simply reports the labels indicated by the comment. If this were to occur, the semantic descriptor metric would report all cells get covered (despite not actually achieving the desired diversity). I trust that this precise mechanism is not taking place here, but something directionally similar could easily evade notice and I don't think is being checked or controlled for.\n\n* And of course there is the significant weakness, readily acknowledged and discussed by the paper, that the diversity of puzzles identified by ACES did not help in fine-tuning for the downstream task of puzzle solving on the test set compared with the static gen baseline. I applaud the frank discussion of this weakness in Section 4.4 and the discussion of the paper."
                },
                "questions": {
                    "value": "# Questions and Suggestions\n\nYou present two key use cases for generating diverse programs: education and LLM training. You evaluate the latter and find that the diversity provided by ACES is not helpful for the downstream puzzles test task you evaluate on. I am curious to get your thoughts on the former, which you do not evaluate. What properties of diversity do you think are important for the education use case, and how do you think these would be the same/different from the properties of diversity that would lead to positive effects of fine-tuning on a downstream task (like the puzzle test set you work with)?\n\nWhy do you select the grid of 2^10 sets of semantic descriptors as your set of possible goals to induce diversity? I ask this question with the following thoughts in mind. First, it seems like many of the cells in this grid don't actually represent diversity of interest (e.g. 38% of cells have 6 or more semantic descriptors which seems an unwieldy amount). Second, it seems like there are more dimensions of diversity not being considered. I brainstorm a few here to make the point: complexity/difficulty, domain, number of inputs, reliance on data dependencies, libraries used, and wall clock runtime.\n\nI am curious to hear any observations you may have made about the embedding based similarity measure. Does its measure correspond to your intuitive sense of similarity? Did you notice any qualitative differences across the three embedding models that you used?\n\nIn Section 3.2 you introduce a notion of interestingness, saying that functions R will map all uninteresting samples to the same point. This R notation is then never used, and the notion of interestingness is not further explored. What is meant by interesting, and how do the two representation functions (cosine distance and semantic descriptors) send uninteresting examples to the same point?\n\nIn \"What's new?\" you claim ACES is the first algorithm to use an autotelic LLM to generate diverse artifacts via in-context learning. In seeking to evaluate this claim, I am reminded first of EvoPrompting: Language Models for Code-Level Neural Architecture Search\n (https://arxiv.org/abs/2302.14838) (which is not autotelic, instead optimizing an objective) and I subsequently find concurrent work LLMatic: Neural Architecture Search via Large Language Models and Quality-Diversity Optimization (https://arxiv.org/abs/2306.01102). This concurrent work is also not autotelic. Another such concurrent work is Quality-Diversity through AI Feedback (https://arxiv.org/abs/2310.13032). Finally, does not Colas 2023 Augmenting Autotelic Agents with Large Language Models (https://arxiv.org/abs/2305.12487) also have all of these properties?\n\nI have collected some typographic suggestions for you below. These issues did not meaningfully harm the readability of the paper.\n\nTypo: Figure 1 caption \"an archive of dcreate figure from tcolorboxiscovered\" is a typo.\nTypo: Section 3.2 \"the example of 2\" -> \"the example in Figure 2\"\nTypo: Section 3.2 \"Counting and Combinatoris\" -> \"Counting and Combinatorics\"\nNotation: Section 3.2 \"k \\in [1 : 10]\" -> \"k \\in [1..10]\" or \"k \\in [1, 10]\"\nFormatting: In Algorithm 1, consider consistent formatting for \"LLM\" across lines 5 and 8\nTypo: Section 3.3 Puzzle labeler. \"the generate puzzle\" -> \"the generated puzzle\"\nTypo: Section 4.2 Figure -> Figures\nTypo: Section 4.2 \"more cell\" -> \"more cells\""
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7893/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698792396278,
            "cdate": 1698792396278,
            "tmdate": 1699636968111,
            "mdate": 1699636968111,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jJ0BQ0PF0K",
                "forum": "hqUznsPMLn",
                "replyto": "YlaeRaQ0rg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7893/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7893/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer (part 1)"
                    },
                    "comment": {
                        "value": "We thank Reviewer AUHG for their detailed and helpful comments and questions. \n\nThere were several questions and comments about the choice of semantic descriptors and its impact on the generated diversity:\n\n> \u201cACES relies on a manually crafted set of semantic descriptors that is specific to the task of generating programming puzzles. The paper does not explore the role that the selection of these semantic descriptors plays on the resulting set of programming puzzles, and does not provide insight into how the approach works in non-programming puzzle domains where these pre-selected semantic descriptors would not be appropriate.\u201d\n\n\n> \u201cOne weakness of this manually crafted set of semantic descriptors is that it places a kind of constraint on the diversity that the approach can produce, and it shifts the burden of identifying this diversity from the ACES algorithm itself to the human seeding the algorithm with semantic descriptors.\u201d\n\n\nWe answer these in the general answer as these questions came up for other reviewers as well.\n\n> \u201cThe semantic descriptor based metric is tailored specifically for the semantic descriptors selected for the approach. If the set of semantic descriptors used in the approach were to change, it's not clear the current semantic descriptor approach (holding the set of semantic descriptors fixed to allow comparing across the change) to measuring diversity would remain meaningful.\u201d\n\nWe are not sure to understand this comment, do you point at the fact that the metric we optimize for it is the same we use for evaluation? If so, note that we evaluate the competing methods with diversity metrics computed in three distinct embedding spaces as well (see General Answer). \n\n> \u201cWhy do you select the grid of 2^10 sets of semantic descriptors as your set of possible goals to induce diversity? I ask this question with the following thoughts in mind. First, it seems like many of the cells in this grid don't actually represent diversity of interest (e.g. 38% of cells have 6 or more semantic descriptors which seems an unwieldy amount). Second, it seems like there are more dimensions of diversity not being considered. I brainstorm a few here to make the point: complexity/difficulty, domain, number of inputs, reliance on data dependencies, libraries used, and wall clock runtime.\u201d\n\nAs discussed in the general answer, we can always think of other representation features and their choice will influence the produced diversity. The definition of the representation function is necessarily subjective because it is precisely the means through which experimenters define what type of diversity they care about. The suggested representation features are all valid and adding them would result in the generation of a different type of diversity along these dimensions as well. We made the choice of not including them but could have. \nComplexity and difficulty are definitely good candidates, especially in educational contexts (see our comment about education below). Including it would require an extra measure of complexity, e.g. by asking GPT or another LLM to solve the problem several times and using the negative success rate as a measure of difficulty. Note that we use a binary measure of difficulty (valid vs invalid) for filtering puzzles that enter the archive. Including the number of inputs or wall clock time may not lead to the production of interesting diversity (e.g. adding time.sleep() instructions, or useless inputs). \nThis point is interesting because it illustrates a contribution of our approach. The definition and use of semantic descriptors, by making explicit the space in which the diversity is produced, allows us to discuss the inclusion/exclusion and careful definition of the dimensions of interest. We can thus debate about whether sets A or B of semantic descriptors would allow us to generate the kind of diversity we care the most about for application X. This is not possible with embedding representation functions which, by making these choices implicit, restrict our ability to discuss and debate them. We answer the concern about parts of the representation space being hard or impossible to reach in the following answer."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7893/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700233321268,
                "cdate": 1700233321268,
                "tmdate": 1700233935315,
                "mdate": 1700233935315,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5HNGCoXMGc",
                "forum": "hqUznsPMLn",
                "replyto": "YlaeRaQ0rg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7893/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7893/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer (part 2)"
                    },
                    "comment": {
                        "value": "> \u201cThe 2**10 size grid of sets of semantic descriptors is (a) in my opinion quite small. P3 has 636 train puzzles spanning ~60-80 cells, but there are only 1024 cells in total to try to cover (using 45000 generated programs to do so). (b) I expect that many of these cells aren't meaningful, e.g. it doesn't seem that important to identify a programming puzzle that is simultaneously a Sorting and Searching, Counting and Combinators, Tree and Graph, Bit manipulation, string manipulation, recursion, and dynamic programming problem (7 semantic descriptors), and a full 38% of the cells represent the goal of having 6 or more semantic descriptors. Indeed Figure 7 confirms generating programming puzzles with 6+ semantic descriptors is quite rare, yet the algorithm spends significant time trying to do so.\u201d\n\nIn the most interesting cases, it may be hard to imagine solutions that would end up in some of the cells our semantic descriptors define. This is fine. We invent many descriptors for movies, music or poetry, it doesn\u2019t mean that we expect specific movies, songs or poems to have any arbitrary conjunction of these features. What\u2019s important is to \u2018spread out\u2019 interesting objects by defining axes of variation we care about while \u2018conflating\u2019 irrelevant objects together. Assuming a perfect feature description function, if a cell cannot be reached it will never be, but maybe it will be, and then we will have learned something new. There exists a paper full of anecdotes from evolutionary search where the system found creative ways to reach points of a representation space that was thought to be impossible to reach (e.g. a robot found a way to walk without having either of its feet touch the floor by crawling on its back), see The Surprising Creativity of Digital Evolution: A Collection of Anecdotes from the Evolutionary Computation and Artificial Life Research Communities (Lehman et al., 2018).\n\n\n> \u201cThe primary measure of diversity (number of cells covered in the archive) is both an imperfect measure (the labels used to determine which cell is covered are determined by ChatGPT) and also the same model producing the puzzles (where generation is conditioned on the desired label) is the one predicting the label. Since puzzle generation is conditioned on the goal label and the same model then predicts those labels, there is real risk of the model overestimating the amount of diversity produced. As a toy example of how this overestimation could occur, we could imagine the model adds a comment to each generated puzzle saying what labels that puzzle should have. Then during labeling, the model ignores the code and simply reports the labels indicated by the comment. If this were to occur, the semantic descriptor metric would report all cells get covered (despite not actually achieving the desired diversity). I trust that this precise mechanism is not taking place here, but something directionally similar could easily evade notice and I don't think is being checked or controlled for.\u201d\n\nThis is a fair argument. The current evaluation metric based on semantic descriptors isn\u2019t very reliable, and although this is fine for the purpose of guiding the diversity search, it poses problems when used for evaluation. This is precisely for this reason that we propose other diversity metrics computed from three different embedding spaces that were not used in the training procedure. On its own, the fact that our method outperforms others on these unbiased evaluation metrics should be sufficient to make the argument that our method allows to generate more diversity than existing ones. The semantic descriptor evaluation, in addition to the exploration of generated puzzles, brings additional elements to the study of the generated diversity, although it is not a definitive argument as such for the reason mentioned above. The reviewer is right to point that this evaluation could be in principle hijacked by the puzzle generator. Although we did not implement any mechanism to prevent this from happening, we can have a look at the difference of performance between ELM semantic and ELM in embedding space. These two do not aim for semantic goals, which means that the generator is unaware of the labeling procedure. Therefore, the noise in the semantic diversity metric is the same for both algorithms. Yet, ELM semantic still outperforms ELM in terms of semantic diversity."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7893/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700233481560,
                "cdate": 1700233481560,
                "tmdate": 1700233908693,
                "mdate": 1700233908693,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "OCZMdVru6R",
                "forum": "hqUznsPMLn",
                "replyto": "YlaeRaQ0rg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7893/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7893/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer (part 3)"
                    },
                    "comment": {
                        "value": "> \u201cAnd of course there is the significant weakness, readily acknowledged and discussed by the paper, that the diversity of puzzles identified by ACES did not help in fine-tuning for the downstream task of puzzle solving on the test set compared with the static gen baseline. I applaud the frank discussion of this weakness in Section 4.4 and the discussion of the paper.\u201d\n\nThis result should not be seen as a weakness per se. As discussed in the introduction and the discussion, data augmentation is only one of several possible motivations for diversity-producing algorithms. Other possible motivations include: the generation of diverse problems for training and evaluating human learners, scientific discovery (eg automatic theorem proving), but also artistic projects (eg generating an interesting diversity of visual artefacts, where the notion of interestingness can be highly subjective: eg beautiful from the point of view of the artist). Our paper only studies quality with respect to the data-augmentation application as it is the one that is easiest to automate. Studying quality for educational or artistic purposes would require extensive and careful human studies, which could be the subject of a stand-alone paper. In general, automating measures of quality or interestingness remain a central challenge in AI (e.g. see an attempt in OMNI: Open-endedness via Models of human Notions of Interestingness, Zhang et al., 2023)"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7893/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700233579906,
                "cdate": 1700233579906,
                "tmdate": 1700233889685,
                "mdate": 1700233889685,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DcRIwA29h2",
                "forum": "hqUznsPMLn",
                "replyto": "YlaeRaQ0rg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7893/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7893/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer (part 5)"
                    },
                    "comment": {
                        "value": "> \u201cIn Section 3.2 you introduce a notion of interestingness, saying that functions R will map all uninteresting samples to the same point. This R notation is then never used, and the notion of interestingness is not further explored. What is meant by interesting, and how do the two representation functions (cosine distance and semantic descriptors) send uninteresting examples to the same point?\u201d\n\nR is the \u2018representation function\u2019 mapping a generated object (here a programming puzzle) into a given representation space (here the embeddings, or the semantic descriptors). In the case of semantic descriptors, R \u201cspreads out\u201d programming puzzles we care about: the ones that are valid and that require various programming skills to get solved and \u201cconflates\u201d uninteresting ones: invalid puzzles are not even represented, and all puzzles that require no skill get mapped to the same unique cell (coordinates [0]^10). Conducting the diversity search in the semantic space is thus expected to be more efficient than conducting it in the original representation space (eg space of token sequences), or even in the embedding space which may not have such properties (ie all puzzles that require no skill to be solved may be mapped to different areas of the embedding space and thus be judged novel). As discussed in the general answer, the choice of the representation function directly influences the produced diversity precisely for this reason. \n\n> \u201cIn \"What's new?\" you claim ACES is the first algorithm to use an autotelic LLM to generate diverse artifacts via in-context learning. In seeking to evaluate this claim, I am reminded first of EvoPrompting: Language Models for Code-Level Neural Architecture Search (https://arxiv.org/abs/2302.14838) (which is not autotelic, instead optimizing an objective) and I subsequently find concurrent work LLMatic: Neural Architecture Search via Large Language Models and Quality-Diversity Optimization (https://arxiv.org/abs/2306.01102). This concurrent work is also not autotelic. Another such concurrent work is Quality-Diversity through AI Feedback (https://arxiv.org/abs/2310.13032). Finally, does not Colas 2023 Augmenting Autotelic Agents with Large Language Models (https://arxiv.org/abs/2305.12487) also have all of these properties?\u201d\n\nYou are right to point out that other works have begun to consider LLMs as mutation operators in evolutionary and related algorithms. EvoPrompting is an example of this where the authors mutate the Python code for designing neural architectures and use the negative generalization error as fitness. However, that method does not perform any diversity optimization. LLMatic follows this path by applying a QD algorithm powered by LLM-based generation. Their approach is not autotelic as you have mentioned, but more importantly, the archive they use for their Map-Elites implementation is based on very simple surface-level descriptors (FLOPS, width-to-depth), and does not capture the human-relevant diversity we seek to achieve in this work. QDAIF is the work closest in spirit to ours, even if they perform their experiments in poem and movie review domains that are quite different from the coding domain, mainly because the solvability of programming puzzles can be done by a python interpreter. Note that both LLMatic and QDAIF are under review at this same conference and should not be considered prior work. And finally, the work of Colas et. al. does not maximize for any form of diversity and, let alone define its diversity through AI feedback.\n\nWe have updated the appendix to include an \"Additional Related Work\" section to include a discussion of these works and the crucial aspects in which they differ from ours to make the novelty of our contribution easier to evaluate.\n\n>\u201cI have collected some typographic suggestions for you below. These issues did not meaningfully harm the readability of the paper.\u201d\n\nThank you, these were all fixed."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7893/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700234062226,
                "cdate": 1700234062226,
                "tmdate": 1700256977290,
                "mdate": 1700256977290,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DlnYuz7w2c",
                "forum": "hqUznsPMLn",
                "replyto": "jJ0BQ0PF0K",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7893/Reviewer_AUHG"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7893/Reviewer_AUHG"
                ],
                "content": {
                    "title": {
                        "value": "Explanation of observation about the semantic descriptor metric of diversity"
                    },
                    "comment": {
                        "value": ">> \u201cThe semantic descriptor based metric is tailored specifically for the semantic descriptors selected for the approach. If the set of semantic descriptors used in the approach were to change, it's not clear the current semantic descriptor approach (holding the set of semantic descriptors fixed to allow comparing across the change) to measuring diversity would remain meaningful.\u201d\n>\n> We are not sure to understand this comment, do you point at the fact that the metric we optimize for it is the same we use for evaluation? If so, note that we evaluate the competing methods with diversity metrics computed in three distinct embedding spaces as well (see General Answer).\n\nMy observation is that the semantic descriptor metric of diversity is not a metric that would allow you to fairly compare against very different methods of producing diversity. If you were to try a very different approach (say, a new clever sampling algorithm that is not conditioned on descriptors at all), then even if that new approach were much more effective at producing diversity, it is quite likely that ACES would score higher on the metric. This is because the metric and ACES both use the same notion of diversity and the same descriptors. Even the effect of a small change to ACES, such as increasing the number of descriptors and leaving everything else unchanged, cannot be meaningfully measured with the semantic-descriptor metric. I think this is a key challenge and a real weakness of the metric. I acknowledge that you are also using additional measures of diversity other than this one metric, which is good. My comment was specifically about this one metric."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7893/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700665896292,
                "cdate": 1700665896292,
                "tmdate": 1700665896292,
                "mdate": 1700665896292,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7LF3HHdInD",
                "forum": "hqUznsPMLn",
                "replyto": "DlnYuz7w2c",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7893/Reviewer_AUHG"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7893/Reviewer_AUHG"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your responses"
                    },
                    "comment": {
                        "value": "Thank you for your response to my review.\n\nI appreciate the exploration of the education context that you gave in Part 4. I can definitely imagine a system like ACES being useful for generating educational content in the future.\n\n>> \u201cAnd of course there is the significant weakness, readily acknowledged and discussed by the paper, that the diversity of puzzles identified by ACES did not help in fine-tuning for the downstream task of puzzle solving on the test set compared with the static gen baseline. I applaud the frank discussion of this weakness in Section 4.4 and the discussion of the paper.\u201d\n>\n> This result should not be seen as a weakness per se.\n\nRespectfully, I think one of the bigger limitations of the paper is that it does not make a case for the usefulness of the type of diversity it produces. As a curious person and a lover of puzzles myself, I can appreciate the intrinsic value of exploration. And I can certainly see the appeal of a method like this for the education settings you describe. But making a case that the diversity measurements you're making actually reflect useful diversity, for some definition of useful, in my opinion needs to be part of the picture. As is, for the application you actually consider, the particular kind of diversity your algorithm induces was unfortunately not helpful. At the very least it would be important to understand why. (And I expect such an investigation would lead immediately to new ideas for producing different forms of diversity.)\n\n>> You claim ACES is the first algorithm to use an autotelic LLM to generate diverse artifacts via in-context learning. In seeking to evaluate this claim [...]\n>> Finally, does not Colas 2023 Augmenting Autotelic Agents with Large Language Models (https://arxiv.org/abs/2305.12487) also have all of these properties?\u201d\n>\n> And finally, the work of Colas et. al. does not maximize for any form of diversity and, let alone define its diversity through AI feedback.\n\nSmall note: the claim I was seeking to evaluate was \"ACES is the first algorithm to use an autotelic LLM to generate diverse artifacts via in-context learning\", not that Colas et. al and your work don't differ in meaningful ways; they most certainly do! Maximizing for diversity is not a prerequisite for producing diverse samples though, and so I think your claim as is might not be literally correct (though with a small tweak could be made true.)"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7893/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700667791566,
                "cdate": 1700667791566,
                "tmdate": 1700667791566,
                "mdate": 1700667791566,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]