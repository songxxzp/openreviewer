[
    {
        "title": "Robust prediction under missingness shifts"
    },
    {
        "review": {
            "id": "l07lJtrhuh",
            "forum": "o4Uheo6nR1",
            "replyto": "o4Uheo6nR1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission202/Reviewer_ExJF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission202/Reviewer_ExJF"
            ],
            "content": {
                "summary": {
                    "value": "This paper examines theoretically and empirically the problem of missingness shift. It characterizes missingness shifts to which an optimal Bayes model would be robust, introduces an iterative imputation strategy for joint imputation and outcome modelling, and concludes with an empirical assessment of performance under missingness shifts."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper presents an excellent yet simple theoretical characterization of the missingness shift problem. The Bayes optimal formalisation is clearly described, and the connection with current approaches to missingness is appreciated. The paper is impeccably written, clear and well-motivated."
                },
                "weaknesses": {
                    "value": "While the paper presents a strong and clear theoretical case, I believe addressing the following points would strengthen the paper, particularly concerning the empirical aspects:\n\n- Existing works have studied the problem of missingness/observation shifts [1, 2]. One paper formalizes missingness shifts, while the other focuses on empirical studies. The authors should consider discussing the distinctions with their proposed formalization and approach.\n- Equation (2) relies on the assumption: $\\mathbb{E}[\\epsilon \\mid X_{obs}, M] = 0$. Authors should detail this assumption, its meaning and its real-world relevance. Particularly, does it not imply some independence of Y upon the missing data?\n- In Section 4, there is an implicit assumption of no covariate or concept shift. Making this explicit would enhance clarity for readers.\n- The paper would be strengthened by detailing NeuMISE and why this modelling would better approximate the conditional expectations and a Bayes optimal model. \n- It would be beneficial to delve further into the discussion of Appendix F, particularly in addressing the unclear aspects of why the model performs less effectively when uncertainty increases.\n- While the empirical results employ real-world covariates, the analysis lacks a study of real-world missingness shifts. Considering a dataset with changing missingness processes would strengthen the experimental analysis.\n- Comparing the proposed approach with an end-to-end neural network that uses zero imputed data and mask as input seems a natural comparison to demonstrate the superiority of the proposed NeuMICE.\n\n\n[1] Zhou, H., Balakrishnan, S., & Lipton, Z. (2023, April). Domain adaptation under missingness shift. In International Conference on Artificial Intelligence and Statistics (pp. 9577-9606). PMLR.\n[2] Jeanselme, V., Martin, G., Peek, N., Sperrin, M., Tom, B., & Barrett, J. (2022). Deepjoint: Robust survival modelling under clinical presence shift. In NeurIPS Learning from Time Series for Health Workshop."
                },
                "questions": {
                    "value": "I consider the paper to be a valuable theoretical contribution, my current rating is only hurt by the limitations outlined earlier."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission202/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698619684532,
            "cdate": 1698619684532,
            "tmdate": 1699635946003,
            "mdate": 1699635946003,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qkfLMBRWm1",
                "forum": "o4Uheo6nR1",
                "replyto": "l07lJtrhuh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission202/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission202/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer ExJF"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their time and constructive feedback! We would like to take the opportunity to address the points raised in the review. Since they were requested by multiple reviewers, a discussion of Zhou et al. (2023) as well as further details regarding NeuMISE are provided in a joint response above. \n\\\n\\\n\\\n**Related work**\nFor a detailed discussion of [1] Zhou et al. (2023), please see our joint response. We further added  [2] Jeanselme et al. (2022) to the related work section.\n\\\n\\\n\\\n**Assumptions on the noise**\n\nThe assumptions in Equation (2) are primarily needed for the formulation of the Bayes predictor in Equation (3), which under those assumptions simplifies to the expected value of a deterministic function of $X_{obs}$ and $X_{mis}$. However, all results still hold for weaker assumptions about the noise. We regret that this was not clear in our original submission and have revised the section accordingly.\n\n**Action:** We added additional text following Equation (2) as well as an intermediate step to Equation (3) to make the role of our assumptions clearer.\n\\\n\\\n\\\n**Real-world data**\n\nWe agree with the reviewer that real-world data that contains a missingness shift would further strengthen our results. Unfortunately, it is impossible to ascertain whether any observed shifts are ignorable or not. We therefore opted to focus on (semi-)simulated datasets with known missingness shifts, leaving the benchmarking of models on a wide range of real-world data for future work.\n\\\n\\\n\\\n**Comparison to MLP with zero imputation**\n\nWe included an MLP model with zero imputation in our early experiments. However, results from those early experiments showed such a model to be a weaker baseline than an MLP with ICE imputation. In the interest of manuscript space, a direct comparison of ICE and MICE, as well as already strained computational resources, we opted to omit zero imputation in favour of ICE. We believe that the most meaningful comparison of NeuMICE is to NeuMiss and ICE.\n\\\n\\\n\\\n**Additional points**\n\n*Explicit assumption of no covariate/label shift:* We added an explicit statement of $p(Y, X) = q(Y, X)$ to the beginning of Section 4.\n\n*Extended discussion of results:* We further agree with the reviewer regarding Appendix F and have added some more interpretation to the results section, particularly related to the decreased performance of NeuMISE.\n\\\n\\\n\\\nWe believe that the above changes have strengthened the overall quality and contribution of the paper. We would like to kindly request that you reconsider the score assigned to our paper in light of the revisions. We believe the changes made have effectively addressed the issues you raised, and we hope this will be reflected in an updated evaluation.\n\nIf you have any further questions or if there are specific areas you would like us to clarify, please do not hesitate to let us know."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission202/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700612576881,
                "cdate": 1700612576881,
                "tmdate": 1700612576881,
                "mdate": 1700612576881,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cBumOkVF4u",
                "forum": "o4Uheo6nR1",
                "replyto": "qkfLMBRWm1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission202/Reviewer_ExJF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission202/Reviewer_ExJF"
                ],
                "content": {
                    "title": {
                        "value": "Maintain score"
                    },
                    "comment": {
                        "value": "Thank you very much for your answers and clarifications. Despite some of the results being previously known, I believe the paper remains an interesting contribution and I would like to maintain my score."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission202/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700669972607,
                "cdate": 1700669972607,
                "tmdate": 1700669972607,
                "mdate": 1700669972607,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "CGlVfaY7r7",
            "forum": "o4Uheo6nR1",
            "replyto": "o4Uheo6nR1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission202/Reviewer_ntEa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission202/Reviewer_ntEa"
            ],
            "content": {
                "summary": {
                    "value": "This work studies the problem of developing a robust predictive model in cases where the pattern through which covariates are missing changes between a source and target domain. The theoretical contributions of the work are a formalization of the problem, a proof that the optimal predictor is stable in case that the missingness pattern is ignorable in both environments (e.g. the missingness pattern depends only observed covariates), and an argument that predictors that leverage informative missingness can still be robust under missingness shift. They also introduce a new neural network architecture NeuMISE that builds off of the NeuMiss architecture for learning with missing data. Experiments with synthetic and real-world and data are conducted with injected missingess shift."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* This work tackles an important but under-emphasized problem with simple but powerful theoretical results. The core contribution regarding the formalization of missingness shift and discussion of ignorable shifts is a strong contribution and has potential for broad use in applications.\n* The experiments are broad and cover a number of data generating processes, shift mechanisms, and comparator methods."
                },
                "weaknesses": {
                    "value": "* The motivation for the NeuMISE method is not presented clearly enough or with enough detail to tie it to the rest of the core claims of the work. It is primarily not clear why modifying the masking of NeuMiss is well-motivated to address the issue of generalizing across unobserved missingness patterns.\n* I have several concerns regarding the clarity of the work, which are elaborated on in the Questions section below."
                },
                "questions": {
                    "value": "* Related to clarity:\n  * Important aspects of the experiments are not presented clearly enough or with enough detail in the main text. For example, it is not explained what \u201clow correlation\u201d and \u201chigh correlation\u201d corresponds to in the experiments.\n  * Section 5 on the role of Y is interesting, but is not presented particularly clearly. In particular, please elaborate on how adjusting for Y in a source domain can induce missingness shift, but omitting Y results in a stable estimator.\n  * The discussion focuses strongly on the comparing methods that leverage informative missingness vs. \u201cunbiased\u201d estimators that do not. This seems to be a critical point for the paper overall (e.g. related to the second of the three contributions listed in the introduction section), but it did not come through clearly to me in the writing. Furthermore, it is not clear how (or if) this was evaluated in the experiments. This could perhaps be improved with additional exposition earlier in the paper that sets up this argument more clearly with specific hypotheses to be evaluated.\n* Can the results be generalized to binary outcomes? Naively, it seems like the additive noise model limits the direct applicability of this framework to binary outcomes.\n* Is the assumption that the error term in equation (2) depends only on the observed X and M limiting the generalizability of this work? Which aspects of the results would no longer hold if the error term were to depend on the full X?\n* Please comment on the relationship of the results of this work to Zhou et al 2023 \u201cDomain Adaptation under Missingness Shift\u201d and adjust claims regarding novelty and prior work, if appropriate."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission202/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission202/Reviewer_ntEa",
                        "ICLR.cc/2024/Conference/Submission202/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission202/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698627664365,
            "cdate": 1698627664365,
            "tmdate": 1700683338722,
            "mdate": 1700683338722,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "OBHFD2vwT8",
                "forum": "o4Uheo6nR1",
                "replyto": "CGlVfaY7r7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission202/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission202/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer ntEa"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their time and constructive feedback. We would like to take the opportunity to address the points raised in the review. Since they were requested by multiple reviewers, a discussion of Zhou et al. (2023) as well as further details regarding NeuMISE are provided in a joint response above. \n\\\n\\\n\\\n**Experimental detail in the main text**\n\nDue to the rather stringent space limitations, we limited the description of experiments to the minimum judged necessary to understand the results, providing the details required for full reproducibility in the appendix. We acknowledge that the final version may have allocated too little space to experimental description. We moved some of the experimental details back into the main text. In particular, we define exactly what we mean by \u201chigh\u201d and \u201clow\u201d correlation in our experiments. We hope that we were able to strike the right balance between concision and detail.\n\n**Action:** We revised Section 7.1 to include additional details on the experimental setup.\n\\\n\\\n\\\n**Clearer explanations of the role of Y**\n\nThe Bayes predictor $\\tilde f_m = E[Y \\mid X_{obs}, M=m]$ is still well-defined for $Y$-dependent missingness. Furthermore, in the absence of a missingness shift, the Bayes predictor in source and target environment remain the same, i.e., $\\tilde f_m = \\tilde g_m$. Any method that successfully estimates $\\tilde f_m$ without using $Y$ (i.e., omits $Y$) will therefore have unchanged performance in the target environment.\n\nHowever, the circumstances change, once we adjust for $Y$ by including it in an impute-then-regress model: we learn an estimator $\\int \\hat f (X_{mis}, X_{obs})p(X_{mis} \\mid X_{obs}, Y)dX_{mis}$ that gives an unbiased estimate $\\hat f$ of the complete data model $f^\\star$ but requires knowledge about $Y$ \u2014 the outcome we want to predict. This is obviously problematic. To overcome this, others have proposed to learn $\\hat f$ as above through the use of $p(X_{mis} \\mid X_{obs}, Y)$ but then replace the imputation with $p(X_{mis} \\mid X_{obs})$ in the target environment. We argue here that this does not estimate the Bayes predictor $\\tilde g_m$.\n\nPlease also see our reply to reviewer tBPA for some further explanations.\n\n**Action:** We revised the text in Section 6.1 (formerly 5.1) to clarify our argument.\n\\\n\\\n\\\n**Informative missingness vs. \u201cunbiased\u201d estimation**\n\nOne of the primary motivations for this research was indeed a common claim that unbiased estimation is preferable for clinical prediction modelling, usually implying that it leads to more robust models. However, we find that Theorem 1 does not provide an a priori reason why unbiased methods should be preferred for robust prediction. Instead, robust prediction under ignorable missingness shifts depends on the precise estimation of the Bayes predictors in the source environment, which may depend on both the method (e.g., impute-then-regress vs. end-to-end learning) and the data (e.g., levels of missingness).\n\n**Action:** We followed the advice of the reviewer and added a Section 4.1 that introduces the above argument. We further revised our section on \u201cLearning under missingness shifts\u201d to discuss certain conditions that may influence the estimation of the Bayes predictor.\n\\\n\\\n\\\n**Additive noise and its independence of missing covariates**\n\nThe reviewer is correct that neither the additive nature of the noise nor the assumption on its conditional mean are strictly necessary. We opted for this formulation, as it leads to a simple and clear expression of the optimal predictor given complete data in the form of $f^\\star(X)$. However, our results remain valid for binary outcomes as well as non-additive noise that depends on the entire $X$.\n\n**Action:** We added additional text following Equation (2) in order to clarify the role of our assumptions. We also added Appendix A.2 to discuss the generality of our results.\n\\\n\\\n\\\nWe believe that the above changes have strengthened the overall quality and contribution of the paper. We would like to kindly request that you reconsider the score assigned to our paper in light of the revisions. We believe the changes made have effectively addressed the issues you raised, and we hope this will be reflected in an updated evaluation.\n\nIf you have any further questions or if there are specific areas you would like us to clarify, please do not hesitate to let us know."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission202/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700612270220,
                "cdate": 1700612270220,
                "tmdate": 1700612270220,
                "mdate": 1700612270220,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "amDTGmINxY",
                "forum": "o4Uheo6nR1",
                "replyto": "OBHFD2vwT8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission202/Reviewer_ntEa"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission202/Reviewer_ntEa"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarifications and revisions. I will update my score to 8."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission202/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700683325669,
                "cdate": 1700683325669,
                "tmdate": 1700683325669,
                "mdate": 1700683325669,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "bGcN5h4yP8",
            "forum": "o4Uheo6nR1",
            "replyto": "o4Uheo6nR1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission202/Reviewer_P8Mn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission202/Reviewer_P8Mn"
            ],
            "content": {
                "summary": {
                    "value": "This work is motivated by the observation that the source of missingness (missing values in covariates) may differ in the train and deployment populations. The paper studies conditions under which the optimal predictor does not change in the presence of missingness shifts. It also analyzes the extent to which methods that utilize informative missingness generalize well in the presence of missingness shifts. They introduce a method called NeuMISE that aims to be robust across a range of missingness mechanisms."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Finding ways to cope with non-ignorable distribution shifts (shifts in the conditional distribution of Y|X) is an important and challenging problem and has not received as much attention as covariate distribution shift, so it\u2019s great that this work points out that methods for dealing with missingness and ignorable missingness shift are insufficient in the presence of non-ignorable missingness shift.\n\n2. The paper is clear and well-written."
                },
                "weaknesses": {
                    "value": "1. The main weakness of this work is that it does not cite or discuss its connection to [1], which is another work that studies robustness to missingness shift. This paper describes that when missing data indicators are available, domain adaptation under missingness shift reduces to a covariate shift problem. This finding seems to be related to one of the central contributions of this paper, which is that the optimal predictor remains unchanged if missingness only depends on observables in both the training and test environment.\n\n\n2. It\u2019s not clear to me what advantage NeuMISE (the authors\u2019 proposed method) has compared to the existing baseline in the presence of non-ignorable missingness shift. While the authors have some empirical results that NeuMISE performs outperforms other methods in the presence of non-ignorable missingness shift, I\u2019m skeptical that such a result holds in general. To my understanding, generalizing well to non-ignorable missingness shift should only be possible if the model is in some sense robust to a variety of non-ignorable missingness shift, and I would presume that such a model may trade off some performance on the source data for better generalization across target environments. Is that the type of result that we observe for NeuMISE? What is the reason that NeuMISE is more robust? Furthermore, what benefit does NeuMISE offer compared to existing baselines.\n\n3. It would be helpful to add a few concrete examples where missingness shifts occur in the real-world to motivate the research.\n\nImprovements:\n\n1. It would be helpful if the authors emphasize in their abstract/introduction that they focus on missingness in covariates, not labels. There is an extensive literature on learning with missing labels and it is somewhat unclear what type of missingness the authors are focusing on until the problem definition in Section 3.\n\n2. It would be nice to draw a connection between ignorable / non-ignorable missingness to ignorable / non-ignorable sample selection. \n\n[1] Zhou, Helen, Sivaraman Balakrishnan, and Zachary Lipton. \"Domain adaptation under missingness shift.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2023."
                },
                "questions": {
                    "value": "1. It would be helpful if the authors add a line after Equation 2 that explains what the assumption $\\mathbb{E}[ \\epsilon \\mid X_{obs}, M] = 0$ means concretely \u2013 i.e., to what extent can the noise $\\epsilon$ depend on the missingness $M$? The current presentation does not require $\\epsilon$ to be independent of $M$ \u2013 is that the desired interpretation? To the best of my understanding, in the current presentation, the variance of the noise $\\epsilon$ could depend on the missingness mechanism.\n\n2. Could the authors explain why the following is true: ``If $Y$ only influences missingness in the source environment, shifts may still be ignorable.\u201d"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission202/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission202/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission202/Reviewer_P8Mn"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission202/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698795989271,
            "cdate": 1698795989271,
            "tmdate": 1699635945839,
            "mdate": 1699635945839,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3IfPEjDSDQ",
                "forum": "o4Uheo6nR1",
                "replyto": "bGcN5h4yP8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission202/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission202/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer P8Mn"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their time and constructive feedback. We would like to take the opportunity to address the points raised in the review. Since they were requested by multiple reviewers, a discussion of Zhou et al. (2023) as well as further details regarding NeuMISE are provided in a joint response above. \n\\\n\\\n\\\n**Assumptions about noise**\n\nIn our formulation, the noise may indeed depend on the missingness. That is, missingness may actively (and even causally) influence Y. Consider for example a situation in which a biomarker A is used by doctors to decide whether another test B should be performed, which requires referral to a specialist laboratory. If the patient is referred, the laboratory also measures Y. If the patient isn\u2019t referred, the doctor themselves measures Y. If the laboratory has a more precise machine than the doctor then $Var(\\epsilon \\mid A, M_B=0) < Var(\\epsilon \\mid A, M_B=1)$ but $E(\\epsilon \\mid A, M) = 0$ may still be true. Our theory would allow for such a scenario.\n\nWe would further like to point out that the assumptions in Equation (2) are primarily needed for the formulation of the Bayes predictor in Equation (3), which under those assumptions simplifies to the expected value of a deterministic function of $X_{obs}$ and $X_{mis}$. Please also refer to our reply to reviewer ntEa regarding the possibility of non-additive noise or noise that depends on $X_{mis}$.\n\n**Action:** We added additional text following Equation (2) as well as an intermediate step to Equation (3) to clarify the role of our assumptions.\n\\\n\\\n\\\n**Ignorability of Y-dependent missingness in the source environment**\n\nSince Y is observed at training time, Y-dependent missingness in the source environment can be MAR if the imputation model conditions on $Y$. The source missingness is thus ignorable. If a shift occurs through which the target missingness no longer depends on Y and only depends $X_{obs}$, then the target missingness is also ignorable. By Definition 2, the missingness shift is therefore ignorable.\nThe main difficulty then lies in how to derive an $\\tilde{f}^\\star_m$ that does not require $Y$ in order to be used in the target environment (since we will not have $Y$ when we want to predict). Mathematically speaking, we need to find a way to derive $q(X_{mis} \\mid X_{obs})$ from $p(X_{mis} \\mid X_{obs}, Y)$. We added a sketch of how this might be achieved to the appendix, although we would like to stress that we haven\u2019t been able to verify it empirically.\n\n**Action:** We revised Section 6.2 (formerly 5.2) of our paper to make this argument clearer. We further outlined a simple two-step impute-then-regress approach in the Appendix that may be used to derive a Bayes estimator for the target environment from the source data.\n\\\n\\\n\\\n**Additional points**\n\n*Real-world examples:* Our original introduction contained two examples of real-world missingness shifts: 1) a reduction in a test\u2019s costs may increase its use, making it more readily available for a larger share of patients and 2) the deployment of the model in clinical practice may change how doctors collect data, for example by more commonly collecting the variables that are used by the model. We\u2019ve added a third example: a change in clinical guidelines that govern how and when doctors ought to perform clinical examinations. Each of these cases changes the missingness in the data and represents an example of real-world missingness shift. All examples focus on healthcare, as this is our main domain of expertise. We believe that the importance of medical applications \u2014 and the role that AI can play within it \u2014 serve as sufficient motivation but we are certain similar examples could be found for other domains.\n\n*Focus on covariate shift:* We added a clarification to the abstract and introduction, highlighting that our work focuses on missingness in covariates.\n\\\n\\\n\\\nWe believe that the above changes have strengthened the overall quality and contribution of the paper. We would like to kindly request that you reconsider the score assigned to our paper in light of the revisions. We believe the changes made have effectively addressed the issues you raised, and we hope this will be reflected in an updated evaluation.\n\nIf you have any further questions or if there are specific areas you would like us to clarify, please do not hesitate to let us know."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission202/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700611947842,
                "cdate": 1700611947842,
                "tmdate": 1700611947842,
                "mdate": 1700611947842,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "e1BmsvqLW8",
            "forum": "o4Uheo6nR1",
            "replyto": "o4Uheo6nR1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission202/Reviewer_tBPA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission202/Reviewer_tBPA"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers a prediction problem with missing shift settings, which is an important practical task.  The paper first provides an overall review of missing mechnisms and related literature. It further discusses the equivalence of Bayes predictors under ignorable missing shift and the effects of shifts in Y-dependence. It also proposes a NeuMISE to handle this challenging task."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well-written and has a very clear organization. The proposed method, NeuMISE, seems to be simple but effective and outperform other baselines. The results are relatively complete and solid."
                },
                "weaknesses": {
                    "value": "The paper uses quite a lot space to discuss the missingness shift. Although such descriptions are complete and clear, it seems to be relatively elementary and do not provide enough new intelletucal insights. Under ignorable condition, Theorem 1 \"equivalence\" is also straightforward and hence is not surprising, at least to me.\n\nLast few sentences in Section 5.1 confuse me. what is \"adjusting Y\", \"omitting Y\" and definition of \"stable estimator\"?\n\nSection 6 is rather short. It should be expanded to explain why NeuMISE is more effective from a deeper viewpoint."
                },
                "questions": {
                    "value": "See weakness points."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No Ethic Concerns."
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission202/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698903942319,
            "cdate": 1698903942319,
            "tmdate": 1699635945773,
            "mdate": 1699635945773,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fB1MO2ofVr",
                "forum": "o4Uheo6nR1",
                "replyto": "e1BmsvqLW8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission202/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission202/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer tBPA"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their time and constructive feedback. We would like to take the opportunity to address the points raised in the review. Since it was requested by multiple reviewers, further details regarding NeuMISE are provided in a joint response above. \n\\\n\\\n\\\n**Too much detail in descriptions**\n\nWe aimed for maximum clarity in our description of the problem setting and background. We appreciate the reviewer\u2019s feedback and tried to remove some of the detail in favour of other, more insightful, sections.\n\n**Action:** We removed some of the detail in Section 3. However, due to additional content requested by other reviewers, the section is only marginally shorter in the revised manuscript.\n\\\n\\\n\\\n**Adjusting/omitting Y**\n\nIn Section 5.1, we used \u201cadjusting Y\u201d to refer to the inclusion of the outcome in the imputation model $p(X_{mis} \\mid X_{obs}, Y)$. This is standard practice in statistical inference under Y-dependent missingness, as it results in a MAR setting and allows for unbiased estimation. In contrast, by \u201comitting Y\u201d we mean an imputation model $p(X_{mis} \\mid X_{obs})$ that does not include $Y$ in the conditioning set.\n\nWe consider an estimator to be stable if it works equally well in the source and target environment. In the absence of a missingness change, $\\tilde f_m = \\tilde g_m$ is trivially true and any estimator that applies the function it learned from the source distribution to the target distribution will be stable. However, a method that tries to adjust for $Y$ during training will learn $\\int \\hat{f}(X_{mis}, X_{obs})p(X_{mis} \\mid X_{obs}, Y)dX_{mis}$ but \u2014 since $Y$ cannot be observed in the target environment \u2014 would need to apply $\\int \\hat{f}(X_{mis}, X_{obs})q(X_{mis} \\mid X_{obs})dX_{mis}$ at deployment. These two functions differ in general. The unobservable nature of $Y$ therefore introduces an \u201cartificial\u201d missingness shift, rendering a setting that is MAR at training time MNAR at deployment time.\n\n**Action:** We revised the text in Section 6.1 (formerly 5.1) to clarify our argument.\n\\\n\\\n\\\nWe believe that the above changes have strengthened the overall quality and contribution of the paper. We would like to kindly request that you reconsider the score assigned to our paper in light of the revisions. We believe the changes made have effectively addressed the issues you raised, and we hope this will be reflected in an updated evaluation.\n\nIf you have any further questions or if there are specific areas you would like us to clarify, please do not hesitate to let us know."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission202/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700611603334,
                "cdate": 1700611603334,
                "tmdate": 1700611603334,
                "mdate": 1700611603334,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]