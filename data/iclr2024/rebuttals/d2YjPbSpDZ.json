[
    {
        "title": "Understanding the Theoretical Generalization Performance of Federated Learning"
    },
    {
        "review": {
            "id": "FpiNKEu99v",
            "forum": "d2YjPbSpDZ",
            "replyto": "d2YjPbSpDZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8031/Reviewer_snNy"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8031/Reviewer_snNy"
            ],
            "content": {
                "summary": {
                    "value": "The paper analyzes the convergence of models in federated learning to the optimum in a convex scenario with standard normal features and Gaussian noise."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- generalization bounds for Federated Learning are an interesting and largely open problem (the only existing generalization bound for FL for deep learning I know relies on the NTK framework [6]).\n- the paper analyzes both stationary and non-stationary targets"
                },
                "weaknesses": {
                    "value": "- the contribution beyond existing results is unclear\n- relevant related work is not discussed\n- the results are presented in a convoluted and unintelligible way with an unnecessary function $\\mathcal{F}$ that hides the actual result and is not interpretable to me\n- there are no experiments (e.g., on simulated data) to evaluate the tightness of the bounds\n- the proofs provided in the Appendix are not well presented"
                },
                "questions": {
                    "value": "**Questions:**\n\n- How do the results for $K>1$ in this paper relate to the results on model averaging for linear regression in [5]?\n- Why do you need the assumption of standard normal features? While Gaussian noise is a common assumption in the analysis of linear regression, this assumption appears to strong to me. Even the analysis in [1] only assumes that data is generated by a process using a covariance operator and a random variable whose components are independent and subgaussian. Shouldn't such an already strong assumption suffice?\n- Why do you not use (a variant of) the notion of (shifting-)regret to analyse the non-stationary case? For this case (i.e., online learning), the (shifting-)regret is typically used as a success measure, since it captures the nature of the task better than the loss [3].\n\n**Detailed Comments:**\n\n- the paper uses a myriad of newly defined symbols which makes it very hard to follow the writing, if one hasn't learned the symbols by heart. The presentation could be greatly improved by reminding the reader what certain symbols stand for.\n- The K=1 case of FL is equivalent to simple distributed SGD, i.e., it can be considered to be a centralized SGD with larger batch size and smaller learning rate  [cf. Prop. 2 in 8]. For convex problems, this has been extensively studied [2]. How does the case in this paper differ?\n- Since the paper investigates convex problems, standard convergence results even for non-convex FL (where, e.g., it is shown that $||\\nabla L|| = 0$) imply that $w^* = w$. This includes, e.g., [4, 12, 14]. Please elaborate on the contribution beyond these works.\n- The problem of heterogeneous local data in FL and its impact on convergence has also been extensively studied [7, 11, 15]. Please elaborate on the contribution beyond these works, in particular to Lemma 3 in [6] which seems to be a generalization of the results in this paper for deep learning.\n- The results for the overparameterized case are not discussed wrt. benign overfitting for linear models [1]. The results of [1] should at least be discussed for the K=1 case, where FL boils down to distributed SGD. \n- model averaging for stationary and non-stationary models in convex environments have been studied extensively [9, 10, 13]. How do the results in this paper relate to this previous work?\n\n\n\n[1] Bartlett, Peter L., et al. \"Benign overfitting in linear regression.\" Proceedings of the National Academy of Sciences 117.48 (2020): 30063-30070.\\\n[2] Boyd, Stephen P., and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2004.\\\n[3] Cesa-Bianchi, Nicolo, and G\u00e1bor Lugosi. Prediction, learning, and games. Cambridge university press, 2006.\\\n[4] Charles, Zachary, and Jakub Kone\u010dn\u00fd. \"Convergence and accuracy trade-offs in federated learning and meta-learning.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2021.\\\n[5] Edgar Dobriban. Yue Sheng. \"Distributed linear regression by averaging.\" Ann. Statist. 49 (2) 918 - 943, April 2021. https://doi.org/10.1214/20-AOS1984\\\n[6] Huang, Baihe, et al. \"Fl-ntk: A neural tangent kernel-based framework for federated learning analysis.\" International Conference on Machine Learning. PMLR, 2021.\\\n[7] Li, Xiang, et al. \"On the convergence of fedavg on non-iid data.\" arXiv preprint arXiv:1907.02189 (2019).\\\n[8] Kamp, Michael, et al. \"Efficient decentralized deep learning by dynamic model averaging.\" Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2018.\\\n[9] Kamp, Michael. Black-box parallelization for machine learning. Diss. Universit\u00e4ts-und Landesbibliothek Bonn, 2019.\\\n[10] Kamp, Michael, et al. \"Communication-efficient distributed online prediction by dynamic model synchronization.\" Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2014.\\\n[11] Karimireddy, Sai Praneeth, et al. \"Scaffold: Stochastic controlled averaging for federated learning.\" International conference on machine learning. PMLR, 2020.\\\n[12] Koloskova, Anastasiia, Sebastian U. Stich, and Martin Jaggi. \"Sharper convergence guarantees for asynchronous sgd for distributed and federated learning.\" Advances in Neural Information Processing Systems 35 (2022): 17202-17215. \\\n[13] Mcdonald, Ryan, et al. \"Efficient large-scale distributed training of conditional maximum entropy models.\" Advances in neural information processing systems 22 (2009).\\\n[14] Yu, Hao, Sen Yang, and Shenghuo Zhu. \"Parallel restarted SGD with faster convergence and less communication: Demystifying why model averaging works for deep learning.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 33. No. 01. 2019.\\\n[15] Yuan, Xiaotong, and Ping Li. \"On convergence of FedProx: Local dissimilarity invariant bounds, non-smoothness and beyond.\" Advances in Neural Information Processing Systems 35 (2022): 10752-10765."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "no ethics concerns."
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8031/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698684165829,
            "cdate": 1698684165829,
            "tmdate": 1699636991343,
            "mdate": 1699636991343,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NaNAyxRD12",
                "forum": "d2YjPbSpDZ",
                "replyto": "FpiNKEu99v",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8031/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8031/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review. We have addressed the concerns in the following clarification and incorporated related discussions into the paper, with the main changes highlighted in blue text.\n>the contribution beyond existing results is unclear; relevant related work is not discussed\n\nGeneral Response about contribution: We appreciate the author\u2019s comments on numerous existing papers in online learning, model averaging, and classic convex optimization. However, it is essential to highlight that federated learning constitutes an independent subarea due to its intricate interplay between heterogeneous data and local update steps throughout the learning process. The distinctive settings of federated learning, characterized by the diversity of data sources and the incorporation of local update steps, differ significantly from other contexts. Our objective is to explicitly quantify the influence of data heterogeneity, local update steps, and the total number of communication rounds on the generalization performance of FL. This area remains under-explored in federated learning. More specifically:\n\n1). The unique setting of federated learning in deep learning (over-parameterization) is significantly different compared to works in online learning, model averaging, and classic convex optimization [2, 5, 8, 9, 10, 13].\n\n2). While many works study the convergence of federated learning, including those mentioned by the reviewer [4, 7, 11, 12, 14, 15], our focus is on *generalization*. \n\n3). The only paper mentioned by the reviewer that includes generalization analysis is [6]. This generalization extends from centralized learning using the Probably Approximately Correct (PAC) framework, which falls into the first class of related works in our paper. Please see Page 1 in our paper (\u201cFrom a theoretical perspective, there has been relatively limited studies in addressing this question. We can categorize existing explorations into two classes. The first line of work employs the traditional analytical tools from statistical learning, such as the \u201cprobably approximately correct\u201d (PAC) framework. These works focus on the domain changes due to the data and system heterogeneity\u2026\u201d). However, it's important to note that these works, including [6], do not provide an explicit relationship showing how critical factors in FL, such as the local update process, the number of communication rounds, and data heterogeneity, collectively affect FL's generalization. In other words, existing works have not fully explored the influence of these factors on the generalization performance of FL, which is the primary goal of our paper.\n\nRelated works: We appreciate the reviewer\u2019s comment for various previous works studying the convergence of federated learning, and we will include them in the revision for a self-contained introduction of federated learning. It is essential to note, however, that our primary emphasis lies on the generalization of federated learning, for which we have meticulously presented an in-depth exploration of related works in our submission.\n>there are no experiments (e.g., on simulated data) to evaluate the tightness of the bounds\n\nResponse: Our Figs. 1, 2, and 3 are the numerical results for three cases to verify our three theorems. As shown in these figures, each marker is the average of 20 simulation runs and the curves are theoretical values from corresponding theorems. All these experiments show the tightness of our theoretical results.\n>the results are presented in a convoluted and unintelligible way with an unnecessary function $\\mathcal{F}$ that hides the actual result and is not interpretable to me\n\nResponse: We explain the meaning of  $\\mathcal{F}$ in Section 2.5. In short,  $\\mathcal{F}$ corresponds to the general-term formula for a linear recurrence relation. Notice that we consider FL in multiple rounds, which is essentially a recurrence relation. Meanwhile, to help the readers understand our results, we provide expressions of the results in the simple case that does not contain $\\mathcal{F}$.\n>the proofs provided in the Appendix are not well presented\n\nResponse: Thanks for your comments. However, it is unclear to us which parts of the proofs in the Appendix the reviewer referred to are not well presented. We would highly appreciate it if the reviewer can pinpoint to a certain proof, and we would be more than happy to make improvements."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8031/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700666934788,
                "cdate": 1700666934788,
                "tmdate": 1700666934788,
                "mdate": 1700666934788,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DhUjKzSoPS",
                "forum": "d2YjPbSpDZ",
                "replyto": "NaNAyxRD12",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8031/Reviewer_snNy"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8031/Reviewer_snNy"
                ],
                "content": {
                    "title": {
                        "value": "Reply to authors"
                    },
                    "comment": {
                        "value": "Dear authors,\n\nIn your reply 1) you claim that federated deep learning is significantly different to [8] and [9]. Both of them cover federated deep learning. \n\nIn your reply 2) you claim that your focus is on generalization, whereas the cited papers focus on convergence. Generalization is defined as the difference between the risk and empirical risk. Your main results are about the distance to the optimal model in convex settings, though. As mentioned, such results on distance to the optimum are either directly or trivially covered by the mentioned works."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8031/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700669651030,
                "cdate": 1700669651030,
                "tmdate": 1700669651030,
                "mdate": 1700669651030,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Ny2QrQMQuY",
            "forum": "d2YjPbSpDZ",
            "replyto": "d2YjPbSpDZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8031/Reviewer_ocpm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8031/Reviewer_ocpm"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the generalization error of the Federated Learning algorithm under a simple linear model and i.i.d. data. The results characterize the behavior of the generalization error in FL with respect to many factors, including the heterogeneity of the data, the number of local updates and communication, and by considering the model size, in under-parametrized and over-parametrized regime."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Very little is known about the theoretical understanding of generalization performance in FL. This paper is one of the first to address this issue. The authors provide several interesting insights into the generalizability of FL and study the effects of various parameters, such as the heterogeneity of the data, the number of local updates and communication, etc. Moreover, the authors provided the first explanation of the double-descent behavior in FL setup. The technical level of the paper also looks high, although I have not verified it carefully."
                },
                "weaknesses": {
                    "value": "Despite its clear strengths, the paper suffers from several problems, which are listed below. I would increase my rating if the major concerns can be addressed, as the paper is among the few works that provides insight into the generalization performance of FL.\n\n1.\tThe model, i.e. the consideration of a linear model with i.i.d. Gaussian data, is very simple and unrealistic. However, as mentioned by the authors, this is now a commonly used model as a first step in understanding the theory.\n\n2.\tIn particular, there is an inherent alignment between empirical risk and generalization error in the considered setup. That is, they are somehow simultaneously minimized, which is in sharp contrast to most real-world scenarios. In fact, throughout the paper, the authors study \"model error,\" a quantity that one would also study for empirical risk. For this reason, I am not sure if the findings on generalization behavior using this setup can be extended or useful for realistic setups.\n\n\n3.\tIn addition, the authors stated that the model error can be shown to be equal to the expected test error for noise-free data. What happens if the data is not noise free? (I guess this is the interesting case, right?). How does the \"model error\" relate to the generalization performance in this case?\n\n4.\tContinuing the point 2, a good \u201cgeneralization bound\u201d typically decreases with the total number of used symbol (here, it would be $m\\times n \\times t$ at the end of iteration $t$, in the simple case). How does the provided bounds behave with these quantities?\n\n\n5.\tIt was observed and partially shown in previous papers (e.g. Gu et al. 2022 or arXiv:2306.05862) that the generalization error of the federated learning is smaller than that of centralized one (i.e. if we keep $m\\times n$ fixed). Do authors observe similar phenomena using these theoretic results?\n\n6.\tAll plots provide the numerical evaluation of the bounds on the model errors. It would be useful to plot the estimated model error as well as the estimated generalization error in the plots to observe how well the provided bounds capture the correct behavior of both the model error and the generalization error.\n\n7.\tSome relevant references are missing, e.g. arXiv:2306.03824 and arXiv:2306.05862.\n\n8.\tThe constants defined in equations (10) to (12) require some explanation and intuition. What is each term made of and what do they represent? In its current form, it's very hard to parse and understand. Similarly, theorem 1 is very hard to parse (except for the simple form of (14)). Similarly, for other theorems.\n\n9.\tTheorem 1 (and other results) suggest that increasing the learning rate $\\alpha$ increases the model error. While this behavior makes sense from an empirical risk point of view, it's often the opposite for generalization behavior: larger learning rates, at least in some cases and for the classical centralized setup, lead to better generalization performance.\n\n10.\tFurthermore, Theorem 1 suggests that more heterogeneity leads to higher generalization error. This is also counterintuitive to me. After all, this is exactly what I would expect for empirical risk, but I would expect the opposite for generalization. \n\n11.\tIf I'm not mistaken, equation (16) (and Proposition 1) is developed for the \"constant learning rate\" scenario. While for this scenario the existence of an optimal $K$ makes sense, I was wondering what would be the behavior with respect to $K$ for the carefully tuned decreasing learning rates?\n\n12.\tThe bound of Theorem 3 interestingly suggests a double descent phenomenon. However, the paper would greatly benefit from a numerical verification of this.\n\n\n13.\tIt is written that \"In Figure 3, we plot the model error against p...\". However, the caption of Figure 3 states that \"The curves are theoretical values from Theorem 3\". It is a bit confusing whether the exact \"model error\" is plotted or the established bound on it? It would be useful to plot both (as well as the generalization error).\n\n14.\tThe proofs are very long and technical, and it takes a lot of time to go through them. I think it would be helpful (and perhaps even necessary) to give a proof sketch in the main text, explaining the main steps, ideas, and tools used from the literature, and what the authors have added. In the current format, it is not clear what technical novelty the authors bring to this work.\n\n15.\tThe supplementary material (in particular Appendix A) may be more appropriately organized, with a table of contents to guide the reader to the various sections.\n\n16.\tIt would be good to summarize the provided insights in the contribution part of the introduction."
                },
                "questions": {
                    "value": "Mentioned above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8031/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698756999439,
            "cdate": 1698756999439,
            "tmdate": 1699636991225,
            "mdate": 1699636991225,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "DxxiVcdj2P",
                "forum": "d2YjPbSpDZ",
                "replyto": "Ny2QrQMQuY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8031/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8031/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review. We have addressed the concerns in the following responses and incorporated related discussions into the paper, with the main changes highlighted in blue text.\n>1. The model, i.e. the consideration of a linear model with i.i.d. Gaussian data, is very simple and unrealistic. However, as mentioned by the authors, this is now a commonly used model as a first step in understanding the theory. 2. In particular, there is an inherent alignment between empirical risk and generalization error in the considered setup. That is, they are somehow simultaneously minimized, which is in sharp contrast to most real-world scenarios. In fact, throughout the paper, the authors study \"model error,\" a quantity that one would also study for empirical risk. For this reason, I am not sure if the findings on generalization behavior using this setup can be extended or useful for realistic setups.\n\nResponse: Thanks for your insightful comments regarding our model setting. For better readability, we also structure our response to your question accordingly as follows:\n\n**Simultaneously minimized risk and generalization erros:** We respectfully disagree that both empirical risk and the generalization error are simultaneously minimized. In the cases of $K=1$ and $K<\\infty$, the empirical risk is not minimized because the SGD/GD update is stopped after K steps (i.e., early stop). In the case of $K=\\infty$, the empirical risk is minimized but the generalization error is not, since Eq. (6) suggests a zero empirical risk but the generalization error shown by Theorem 3 is still positive.\n\n**\u201cModel error\u201d:** As we explained in the footnote of Page 4, the model error is equal to the expected test error for noise-free test data. This quantity is widely used to indicate the generalization performance in a linear model setup.\n\n>3. In addition, the authors stated that the model error can be shown to be equal to the expected test error for noise-free data. What happens if the data is not noise free? (I guess this is the interesting case, right?). How does the \"model error\" relate to the generalization performance in this case?\n\nResponse: Thanks for your question. The difference in the expected test error between the case of noise-free test data and the case of noisy test data is only the noise level (a constant that is irrelevant to the learning process). In the revision, we added Lemma 6 to make this claim rigorous.\n\n>4. Continuing the point 2, a good \u201cgeneralization bound\u201d typically decreases with the total number of used symbols (here, it would be $m\\times n \\times t$ at the end of iteration $t$, in the simple case). How does the provided bounds behave with these quantities?\n\nResponse: Thanks for your question. It appear sthat there are some misunderstandings in here. First, we want to clarify that our characterization of the generalization error is not a bound. Rather, it is the **exact value** of the expected generalization error. The correctness of our characterization is also validated by Figs. 1-3 that analytical values perfectly match simulation values. Second, the expressions in Theorems 1~3 contain $m$, $n$, and $t$ explicitly. For example, in Eq. (14), both H and G have $mn$ in their denominator and thus decrease with respect to $mn$. When the learning rate is small, we have $H<1$, which suggests the first term of Eq. (14) also decreases with $t$. The second term of Eq. (14) (noise term) increases with $t$ due to the accumulation of the noise effect over time.\n>5. It was observed and partially shown in previous papers (e.g. Gu et al. 2022 or arXiv:2306.05862) that the generalization error of the federated learning is smaller than that of centralized one (i.e. if we keep $m\\times n$ fixed). Do authors observe similar phenomena using these theoretic results?\n\nResponse: Thanks for your question. Yes, we do observe similar phenomena in the case of $K=\\infty$. As mentioned in our Insight 4, compared to the centralized one, the \u201cnull risk\u201d can be alleviated and can achieve a smaller generalization error."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8031/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700665928386,
                "cdate": 1700665928386,
                "tmdate": 1700665928386,
                "mdate": 1700665928386,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wp8mocqjF7",
            "forum": "d2YjPbSpDZ",
            "replyto": "d2YjPbSpDZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8031/Reviewer_uk5o"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8031/Reviewer_uk5o"
            ],
            "content": {
                "summary": {
                    "value": "This work investigates how data heterogeneity and the number of local update steps affects the performance of federated learning. The authors study the problem using a linear model with possibly time-varying ground truths. They quantify the $\\ell_2$-estimation error in three different regimes: $K=1, K<\\infty$, and $K=\\infty$, where $K$ denotes the number of local update steps. The results characterize the optimal choice of $K$ in some cases and validate the \u201cdouble descent\u201d phenomena when $K = \\infty$."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This work considers a very general setting where the ground truth parameter of each agent may vary with time.\n- This paper brings novel theoretical results of the effect of local update steps on federated learning. There is not much existing literature on this problem. \n- The results provide insights on the optimal choice of local update steps for FL.\n- The presentation is clear and well-organized, with plenty of discussion after each theoretical result."
                },
                "weaknesses": {
                    "value": "- A major concern is the parameter defined by Equation (3). It does not seem like a suitable measurement for heterogeneity.  \n  Consider the case where $w_{(i), t} = w_{(j),t} = w^* + v$ with $\\Vert v \\Vert$ very large. In this case, all agents\u2019 ground truth are the same, *i.e.* the data are homogeneous. However, the *level of heterogeneity* is very large by the definition in the paper."
                },
                "questions": {
                    "value": "**Major**  \nPlease see the Weaknesses section.\n\n**Minor**  \nIs there a reference for Equation (25)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8031/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8031/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8031/Reviewer_uk5o"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8031/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698828312341,
            "cdate": 1698828312341,
            "tmdate": 1699661758124,
            "mdate": 1699661758124,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kEYVQBkdpb",
                "forum": "d2YjPbSpDZ",
                "replyto": "wp8mocqjF7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8031/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8031/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review. We have addressed the concerns in the following clarification and incorporated related discussions into the paper, with the main changes highlighted in blue text.\n>A major concern is the parameter defined by Equation (3). It does not seem like a suitable measurement for heterogeneity.\nConsider the case where $w_{(i), t} = w_{(j),t} = w^* + v$ with $\\Vert v \\Vert$ very large. In this case, all agents\u2019 ground truth are the same, i.e. the data are homogeneous. However, the level of heterogeneity is very large by the definition in the paper.\n\nResponse: Thanks for the comments. We note, however, that if every agent shares a very large and common $v$, then this quantity $v$ should be considered part of $w^*$ to accommodate such bias. Indeed, the choice of $w^*$ depends on all $w_{(i),t}$ (e.g., their average). In general, $w^*$ should be regarded as the \u201clargest\u201d overlapped part of $w_{(i),t}$. Therefore, our measurement for heterogeneity is still suitable.\n\n>Is there a reference for Equation (25)?\n\nResponse: Thanks for your question. Yes, Eq. (25) can be found in [R1] (with changes of notations). Eq. (25) is also a special case of Eq. (23) in our Theorem 3 by letting $m=1$ and $t=1$. \n\n[R1] Mikhail Belkin, Daniel Hsu, and Ji Xu. Two models of double descent for weak features. SIAM Journal on Mathematics of Data Science, 2(4):1167\u20131180, 2020."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8031/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700665445336,
                "cdate": 1700665445336,
                "tmdate": 1700665445336,
                "mdate": 1700665445336,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "3HecNj3c5B",
            "forum": "d2YjPbSpDZ",
            "replyto": "d2YjPbSpDZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8031/Reviewer_Rcvy"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8031/Reviewer_Rcvy"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies optimizing a distributed linear regression problem with local SGD. The aim is to capture the effect of data heterogeneity and provide upper bounds on the $L_2$ estimation error of the ground truth predictor shared across the clients. To do so, the paper considers three settings: $K=1$ (i.e., MB-SGD update on the average objective), $K<\\infty$ (i.e., vanilla local SGD), and $K=\\infty$ (i.e., convergence on each machine between communication rounds). The first two settings are considered with a single pass on the data, while the third setting converges to the ERM solution on the machine. Closed-form upper bounds are provided in each of these settings for both \n- **the online/non-stationary setting** (when the predictor on each machine changes across time); and \n- **the stationary setting** (when the predictor on each machine is fixed over time but is potentially different across the machines).  \n\nSeveral insights are drawn from these closed-form expressions in a more straightforward setting, where the shared solution concept across the machines is the average of the machines' model for that communication round."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper is clearly written, making it easy to follow the mathematical details. All the expressions are fully worked out and the proofs are also easy to verify."
                },
                "weaknesses": {
                    "value": "The paper claims to be general enough to provide results for the non-stationary setting. However, it is unclear if measuring the distance from $w^\\star$ is useful in the non-stationary setting. In particular, it is never discussed what $w^\\star$ is and why the machines would want to recover it in a general setting, as opposed to minimizing regret with respect to a fixed best model in hindsight. Due to this reason, it seems that the simple setting for presenting results, where $w^\\star$ is the average optimum of different machines, is the only reasonable setting. As a result, the generality of the results in this paper is not very useful, without further motivation. \n\nThere are some issues even if we consider all the results in the simple setting. In the most challenging setting, that is, for a general $K<\\infty$, $\\bar{||\\gamma||}^2$ is conveniently assumed to be zero. This implies that all the machines have the same optimum as $w^\\star$. We already know the min-max optimal algorithms for quadratic functions in the homogeneous setting due to [Woodworth et al.](https://arxiv.org/abs/2002.07839). Thus, theorem 2 is not interesting. Similarly, Theorem 1 is not interesting as without any local update steps, there is no consensus error, and the update looks exactly like the mini-batch SGD update on the averaged objective across the machines. Resultwise, insights 1-3 are not interesting either. Finally, Theorem 3 is interesting but it is very easy to obtain using standard arithmetic. \n\nOverall, I do not believe this paper is novel enough, and adds to the existing theory of local update methods."
                },
                "questions": {
                    "value": "- How are the step sizes tuned in all the experiments? In particular, in Figure 2, are step sizes tuned separately for each experiment? \n\n- (23) also has null risk, depending on the order of taking limits. For instance if $p\\to \\infty$ before $t\\to\\infty$, then there is a residual null risk. As a result, Insight 4 seems wrong. Figure 3 also seems to show this. What is the insight here then?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8031/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699508407086,
            "cdate": 1699508407086,
            "tmdate": 1699636990985,
            "mdate": 1699636990985,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VfyfTe4Yh7",
                "forum": "d2YjPbSpDZ",
                "replyto": "3HecNj3c5B",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8031/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8031/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate the reviewer's feedback. We would like to point out that the concerns are mostly due to misunderstanding and we have made corresponding modifications to the paper, which are highlighted in blue text in the revision. Our response is outlined below.\n>The paper claims to be general enough to provide results for the non-stationary setting. However, it is unclear if measuring the distance from w^* is useful in the non-stationary setting. In particular, it is never discussed what w^* is and why the machines would want to recover it in a general setting, as opposed to minimizing regret with respect to a fixed best model in hindsight. Due to this reason, it seems that the simple setting for presenting results, where w^* is the average optimum of different machines, is the only reasonable setting. As a result, the generality of the results in this paper is not very useful, without further motivation.\n\nResponse: Thanks for your comments and suggestions. While letting $w^*$ be the average of different machines seems to be the most reasonable choice, there are some other possibilities in reality. For example, we may want to let $w^*$ to be the \u201csmallest\u201d (in certain criteria such as l2 norm) among different machines when the whole system\u2019s performance depends on the machine with the smallest $w$.\n\n>There are some issues even if we consider all the results in the simple setting. In the most challenging setting, that is, for a general $K<\\infty, \\bar{||\\gamma||}^2$ is conveniently assumed to be zero. This implies that all the machines have the same optimum as w^*. We already know the min-max optimal algorithms for quadratic functions in the homogeneous setting due to Woodworth et al.. Thus, theorem 2 is not interesting. Similarly, Theorem 1 is not interesting as without any local update steps, there is no consensus error, and the update looks exactly like the mini-batch SGD update on the averaged objective across the machines. Resultwise, insights 1-3 are not interesting either. Finally, Theorem 3 is interesting but it is very easy to obtain using standard arithmetic.\n\nResponse: Thanks for your comments. It appears that there are some misunderstandings. First, our paper focuses on offering a theoretical understanding of the generalization performance of FL, not min-max optimal algorithms for quadratic functions. Second, Theorem 2 not only provides the results for the simple setting but also provides the general results with heterogeneity and non-stationarity. Third, we believe that results in Theorem 3 are non-trivial and the key part of the proof is Eqs. (78)~(80), which depends on our Lemma 5. The proof of Lemma 5 is complex and novel, which by no means can be obtained by standard arithmetic. We also use Figure 4 to give a geometric interpretation of the proof.\n\n>Overall, I do not believe this paper is novel enough, and adds to the existing theory of local update methods.\n\nResponse: We would like to clarify and highlight that the main contribution and novelty of this paper is to derive exact expressions (instead of upper or lower bounds) of the generalization performance of FL for various settings of $K$, which provide meaningful insights. To the best of our knowledge, our work is the first of its kind in literature. That being said, we would highly appreciate it if the reviewer provides pointers to existing works that we are unaware of, and we would be happy to include and compare them in the revision of this paper.\n\n>Questions:\nHow are the step sizes tuned in all the experiments? In particular, in Figure 2, are step sizes tuned separately for each experiment?\n\nResponse: Thanks for the question. The (fixed) step sizes are set to 0.02 in all experiments.\n\n>(23) also has null risk, depending on the order of taking limits. For instance if $p\\to\\infty$ before $t\\to\\infty$, then there is a residual null risk. As a result, Insight 4 seems wrong. Figure 3 also seems to show this. What is the insight here then?\n\nResponse: Thanks for your question. Again, it appears that there are some misunderstandings in how to interpret Insight 4. We note that Insight 4 only says the null risk is *alleviated* (not completely removed) by using more communication rounds and we explicitly discuss the issue of the speed w.r.t. $t$ and $p$ in the paragraph below Eq. (25). Hope this clarifies the confusion."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8031/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700664570298,
                "cdate": 1700664570298,
                "tmdate": 1700665251435,
                "mdate": 1700665251435,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pvU2hOyawm",
                "forum": "d2YjPbSpDZ",
                "replyto": "VfyfTe4Yh7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8031/Reviewer_Rcvy"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8031/Reviewer_Rcvy"
                ],
                "content": {
                    "comment": {
                        "value": "I am not satisfied with the author's response and have decided to retain my score. \n\nRegarding the choice of $w^\\star$ in the stationary but non-simple setting, the authors do not offer a convincing interpretation of $w^\\star$ and why we should not care about a regret notion in the online setting. I am not sure why anything beyond the simple setting makes intuitive sense. \n\nI have checked again, and theorem 2 in the simple setting with $\\gamma=0$ absolves to the homogenous setting, so the results are very incremental. \n\nFixing the step size across experiments while varying the problem parameters or the number of machines makes little sense. \n\nDue to limited technical novelty and new insights, I do not believe the paper is fit for publication."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8031/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700712819804,
                "cdate": 1700712819804,
                "tmdate": 1700712819804,
                "mdate": 1700712819804,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]