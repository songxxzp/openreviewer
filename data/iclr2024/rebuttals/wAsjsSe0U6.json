[
    {
        "title": "Visual Semantic Learning via Early Stopping in Inverse Scale Space"
    },
    {
        "review": {
            "id": "ohZzRvIdaJ",
            "forum": "wAsjsSe0U6",
            "replyto": "wAsjsSe0U6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4693/Reviewer_xer1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4693/Reviewer_xer1"
            ],
            "content": {
                "summary": {
                    "value": "This work adapted \u201cTotal Variation\u201d which has been extensively applied in areas such as image denoising for data preprocessing in neural networks, seeking to augment the network's ability to focus on low-frequency information. Through rigorous experimentation, it has been observed that this strategy markedly enhances the network's robustness, rendering it more adept at managing suboptimal input data that is either low-resolution, unclear, or highly noisy. Additionally, the approach improves the network's reliability against adversarial assaults."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThis paper is well-written and clear, especially with its formulas and rules, making it easy for readers to get the theory and how things are done.\n2.\tThe paper introduces a brand new method using graph algorithms for sparse projections, which ensures the efficiency of the algorithm's execution. \n3.\tThis approach incorporates previously extensively studied Total Variation for data preprocessing in neural networks, seeking to augment the network's ability to focus on low-frequency information. \n4.\tExtensive experiments prove the proposed method in dealing with substandard data, such as those of low resolution, blurriness, high noise levels and adversarial attacks."
                },
                "weaknesses": {
                    "value": "1.\tWhile this method serves as a preprocessing measure for input data, there is a notable absence of comparative validation against the performance of similar procedures (for instance, applying varying degrees of Gaussian blur or color perturbation to input images \u2014 a data augmentation approach that is, in fact, quite prevalent in network training, rather than solely introducing original clean images). The comparative analysis in Supplementary Material Fig.17 is overly subjective.\n2.\tNumerous studies, such as those found in reference [1,2], have delved into enhancing networks' capacity to process low-frequency information through a series of methods including image denoising and high-frequency noise injection. However, this paper lacks a comparative analysis with the findings of these studies or an exploration of whether there is room for further improvement building on their foundations.\n3.\tThe paper proposes three training methodologies utilizing Total Variation operations, all of which yield certain results, while differing in effectiveness (for example, the method \u201cFixed Training\u201d appears suitable for low-resolution scenarios, whereas \u201cFinetune\u201d is more applicable for adversarial attacks). However, the paper lacks an analysis explaining these variances, specifically a discussion on the applicable domains for each of the three methods. \n4.\tThe paper lacks a discussion concerning certain parameters, especially an analysis and empirical representation of \"early stopping,\" as mentioned in the title. Additionally, there is an absence of explanation as to why a sparsity of 0.8 was chosen for the Fixed training method, an aspect that could be elucidated with experimental demonstration and analysis\n5.\tThe image in Fig.7 (b) is blurred. The differences in Fig.5 are not very discernible except for the first column, suggesting there's no need for so many repetitive visuals.\n\n[1]Xie, Cihang, et al. \"Feature denoising for improving adversarial robustness.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019.\n[2] He, Zhezhi, Adnan Siraj Rakin, and Deliang Fan. \"Parametric noise injection: Trainable randomness to improve deep neural network robustness against adversarial attack.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019."
                },
                "questions": {
                    "value": "It is hoped that the aforementioned issues can be addressed as comprehensively as possible. Additionally, it would be beneficial to have a more clear and intuitive description of the graph constructed in the \"Sparse Projection via Graph Algorithm\" section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4693/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698638561627,
            "cdate": 1698638561627,
            "tmdate": 1699636450939,
            "mdate": 1699636450939,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kaTddTdMqb",
                "forum": "wAsjsSe0U6",
                "replyto": "ohZzRvIdaJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4693/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4693/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer xer1"
                    },
                    "comment": {
                        "value": "Thank you for your feedback and valuable suggestions regarding our work. We appreciate your comments on the clarity and novelty of our work. We address your concerns in the following. \n\n\n**Q1: While this method serves as a preprocessing measure for input data, there is a notable absence of comparative validation against the performance of similar procedures.**\n\n**A1**: Our method is not as simple as a data augmentation method, for we do not use any of the original data during our training procedure. A data augmentation method is to use noisy or corrupt image to urge the model to learn more robust information. However, our method directly discovers the most important and robust information, including structural and low-frequency information, and smooths out other suspicious information. It is much different from the data augmentation method and we do not compare the result with them.\n\n\n**Q2: Numerous studies, such as those found in reference [1,2], have delved into enhancing networks' capacity to process low-frequency information through a series of methods including image denoising and high-frequency noise injection. However, this paper lacks a comparative analysis with the findings of these studies or an exploration of whether there is room for further improvement building on their foundations.**\n\n**A2**: We have implemented [1,2] as you suggested, added comparisons with [2,3,4] in Tab.2,7, on the adversarial robustness tasks on CIFAR-10 using ResNet18. [1] performed poorly in our implementations on CIFAR-10, possibly due to its primary focus on ImageNet.\n\nIt can be demonstrated that our method outperforms other methods, whether using FGSM or PGD attacks. Also, using our method as preprocessing method, our method can further improve those methods, though it is not a specially designed defence method.\n\n**Q3: Lack of analysis explaining variances among three training methodologies.**\n\n**A3**: For iterative method, it can help the model learn the structural information in the images smoothly. For Fixed method, it can learn the information in images with specific sparsity. For Finetune method, it can refine the vanilla model and help it learn more shape information. \n\nThe finetune method outperform others in the adversarial robustness task because through fine-tuning, the model will learn richer information and become less susceptible to attacks, especially white-box attacks (FGSM, PGD). When a sparsity is fixed, the smooth images are very similar to low resolution images, so the fixed model trained on them performs well in low-resolution classification task. As illustrated in Fig.5, the iterative model learns low-frequency information first and then iteratively gains high-frequency information, so it can gain more stable low frequency information. Therefore, it performs well in the classification on low frequency components.\n\n\n**Q4: Lack of discussion concerning certain parameters.**\n\n**A4**: For the early stopping parameter \"sparsity\", in experiments we have compared the standard classification results of models trained with different sparsity levels in Tab.4, indicating that the outcome remains robust and consistent across varying levels of sparsity, provided it exceeds 0.6. This suggests a relative insensitivity to changes in\nsparsity, leading us to focus on a threshold of 0.6 for optimal balance in most of our experiments. \n\n**Q5: The image in Fig.7 (b) is blurred. The differences in Fig.5 are not very discernible except for the first column, suggesting there's no need for so many repetitive visuals.**\n\n**A5**: Thank you for pointing out the issue with Fig.7 (b). We have revised this figure for improved clarity. Regarding Fig.5, we want to show the whole training process of our iterative model, in which we can see the change in the frequency domain of feature map.\n\n\n**Q6: More clear and intuitive description of Graph algorithm.**\n\n**A6**: Thanks for the advice. We have refined this part by summarizing it in a pseudo-code format and providing an additional flowchart of the algorithm in Appendix.A. Hope these information can make it more readable.\n\n[1]Xie, Cihang, et al. \"Feature denoising for improving adversarial robustness.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019. \n\n[2] He, Zhezhi, Adnan Siraj Rakin, and Deliang Fan. \"Parametric noise injection: Trainable randomness to improve deep neural network robustness against adversarial attack.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.\n\n[3] Wang, Haohan, et al. \"High-frequency component helps explain the generalization of convolutional neural networks.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.\n\n[4] Raymond A. Yeh, Yuan-Ting Hu, Zhongzheng Ren, and Alexander G. Schwing. Total variation\noptimization layers for computer vision. In 2022 IEEE/CVF Conference on Computer Vision and\nPattern Recognition (CVPR), pp. 701\u2013711, 2022a."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4693/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700663773885,
                "cdate": 1700663773885,
                "tmdate": 1700663773885,
                "mdate": 1700663773885,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8srQyiWCHX",
            "forum": "wAsjsSe0U6",
            "replyto": "wAsjsSe0U6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4693/Reviewer_NN23"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4693/Reviewer_NN23"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an image preprocessing approach where they disentangle the semantic structure from the details of the image to avoid textual bias in deep learning. The paper proposes to leverage the structure of the Total Variation (TV) regularization matrix in the Inverse Scale Space (ISS) to generate a regularized image path from large-scale with semantic information to fine-scale with detailed information. This approach also incorporates an early stopping mechanism for the generated image path, which is computed with high efficiency using Nesterov acceleration. They demonstrate their method on various image tasks, including robustness against noise, adversarial attacks, and low-resolution images."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "It is reasonable and valuable to explore how to disentangle the large-scale semantic information from the fine-scale detailed information to conduct the high-level information from the image to the neural networks.\n\nThe idea of leveraging the graph algorithm to accelerate the sparse projection is interesting. \n\nThe experiments widely demonstrate their proposed algorithm on a variety of image tasks."
                },
                "weaknesses": {
                    "value": "The writing and presentation are not clear enough. It is not easy to follow for the reader who is not familiar with the related theory [1][2]. A more detailed background introduction is recommended to add to the Appendix. Due to the presentation issues, the connection and difference between the existing theory and the method introduced in [1][2] is not clear. \n\nMany notations are not explained well. The role of \\beta, \\gamma is unclear. In Section 3.1, the claim \"with t playing a similar role as 1/\\lambda in Eq1.\" is confusing. And the definition of ||D\\beta|| seems has typo. \n\nIn experiments, the compared methods are not enough. The authors only compare with the vanilla and the TV layer methods. Some related preprocessing can filter out the high frequency, or the detailed contents should also be evaluated and compared.\n\n[1] Huang et al. \"Boosting with structural sparsity: A differential inclusion approach.\"\n\n\n[2] Fu et al. \"Exploring Structural Sparsity of Deep Networks via Inverse Scale Spaces\""
                },
                "questions": {
                    "value": "I believe this paper needs to be refined to fix the above issues."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4693/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698992634730,
            "cdate": 1698992634730,
            "tmdate": 1699636450814,
            "mdate": 1699636450814,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "cMGx2ZGQbq",
                "forum": "wAsjsSe0U6",
                "replyto": "8srQyiWCHX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4693/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4693/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer NN23"
                    },
                    "comment": {
                        "value": "Thank you for your valuable time and constructive feedback. We are glad you find our method interesting and have corrected typos and clarify explanations to enhance readability. We address your concerns in the following. \n\n**Q1: The connection and difference between the existing theory and the method introduced in [1][2] is not clear.**\n \n**A1**: In [1], a method which can generate a sparse regularization path for $l_1$ regularization is proposed. In [2], the method is used to prune neural networks by generating a sparse regularization path for network parameters. In this work, we use this similar method to generate sparse regularization path on image data, to discover and make use of the structural sparsity in them. Using it, we can smooth the image and help improve the robustness of model by training them on smooth images. Also, we propose an acceleration algorithm using Graph algorithm to make the instance smoothing algorithm tractable. More detail can be found in the introduction part.\n\n**Q2: Many notations are not explained well.The role of $\\beta$, $\\gamma$ is unclear. In section 3.1, the claim \"with t playing a similar role as $1/\\lambda$ in Eq1.\" is confusing. And the definition of $\\Vert D\\beta \\Vert$ seems has typo.**\n\n**A2**: We have clarified our notations in section 3.1. $\\beta$ represents the TV-regularized image obtained by minimizing the loss function in Equation 1. $\\beta_t$ denotes the regularized image at the $t$th iteration step. $\\gamma$ serves as the variable splitting term for this regularization to control the Total Variation of images. For further clarity, each element of $\\gamma$ refers to an edge of Total Variation graph, which consists of pixels as nodes and $D$ as edge adjacency matrix. Regarding the role of $t$, as mentioned in Section 3.1, the path $\\gamma_t$ transitions from sparsity to density as $t$ increases. Additionally, we have corrected the typo identified in your review.\n\n**Q3: In experiments, the compared methods are not enough.**\n\n**A3**: Addition to TV-layer [3], we've added comparisons with PNI [4] and the best results presented in [5], which involve smoothing the kernel (filter out high frequency components) and adversarial training to improve the robustness. \nIt can be seen in Tab.2,7 that with FGSM attack, our method can outperform them without preprocessing. With PGD attack, our method can outperform them with preprocessing with a large gap when the attack strength is large.\n\n[1] Huang et al. \"Boosting with structural sparsity: A differential inclusion approach.\"\n\n[2] Fu et al. \"Exploring Structural Sparsity of Deep Networks via Inverse Scale Spaces\"\n\n[3] Raymond A. Yeh, Yuan-Ting Hu, Zhongzheng Ren, and Alexander G. Schwing. Total variation\noptimization layers for computer vision. In 2022 IEEE/CVF Conference on Computer Vision and\nPattern Recognition (CVPR), pp. 701\u2013711, 2022a.\n\n[4] He, Zhezhi, Adnan Siraj Rakin, and Deliang Fan. \"Parametric noise injection: Trainable randomness to improve deep neural network robustness against adversarial attack.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.\n\n[5] Wang, Haohan, et al. \"High-frequency component helps explain the generalization of convolutional neural networks.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4693/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700663169739,
                "cdate": 1700663169739,
                "tmdate": 1700663169739,
                "mdate": 1700663169739,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "P4vHYdN7ez",
            "forum": "wAsjsSe0U6",
            "replyto": "wAsjsSe0U6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4693/Reviewer_5hKV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4693/Reviewer_5hKV"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an instance smoothing algorithm that disentangles structural information from detailed ones via early stopping on generating a regularized image path from large-scale to fine-scale. Then different training procedures are proposed to incorporate this algorithm into the training process. Extensive experiments are conducted on robustness tasks to verify the effectiveness of the proposed model."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThis paper is the first to investigate the inverse-scale-space (ISS) property at the image level.\n2.\tThe experiments section provides convincing visualization and frequency analysis."
                },
                "weaknesses": {
                    "value": "1.\tThe symbols in formulas need to be specified, e.g., the meaning of \u03b2.\n2.\tThe authors claim that they propose an efficient sparse projection method. In addition to superiority in computation and time complexity compared with SVD and LSQR, is there any advantage for performance improvement?\n3.\tThe choice of early stopping time is unclear. Since early stopping is an important operation to disentangle structural information from detailed ones, it\u2019s crucial to illustrate the choice of early stopping time.\n4.\tThe comparison between this method and existing methods is missing. The authors only compare their method with baseline ones, i.e., Vanilla Model and TV Layer."
                },
                "questions": {
                    "value": "Please refer to weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4693/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699375175197,
            "cdate": 1699375175197,
            "tmdate": 1699636450742,
            "mdate": 1699636450742,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "assOPepGPq",
                "forum": "wAsjsSe0U6",
                "replyto": "P4vHYdN7ez",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4693/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4693/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 5hKV"
                    },
                    "comment": {
                        "value": "We express our gratitude to the reviewer for your efforts and valuable insights provided for our work.  We are glad that you appreciate our novelty, and we address your other concerns below. \n\n**Q1: The symbols in formulas need to be specified.**\n\n**A1**: We have improved the explanations for symbols in section 3.1. Specifically, $\\beta$ represents the dense parameter for the loss function in Eq. 1. When $\\beta$ minimizes the loss, it represents the TV-regularized image. Meanwhile, $\\tilde{\\beta}$ in Eq. 4 denotes the sparse TV-regularized image derived by projecting $\\beta$ onto the subspace formed by the support set of $\\gamma$.\n\n**Q2: Other improvements of our projection method compared with SVD and LSQR.**\n\n**A2**: Our main contribution is to propose the instance smoothing method, and the efficient sparse projection method is to make the time cost tractable. For performance, since our method can derive the analytical solution just as SVD, so theoretically no difference, even results in smaller loss in practice due to numerical issue. LSQR may struggle with convergence speed or precision, relying on iterative solutions.\n\n\n**Q3: The choice of early stopping time.**\n\n**A3**: In experiments, we have tried several sparsity levels as the criterion for early stopping, and compared the standard classification results in Tab.4, indicating that the outcome remains robust and consistent across varying levels of sparsity, provided it exceeds 0.6. This suggests a relative insensitivity to changes in sparsity, leading us to focus on a threshold of 0.6 for optimal balance in most of our experiments.\n\n**Q4: The comparison between this method and existing methods is missing.**\n\n**A4**: TV-layer [1] is a TV regularization method in which we have compared our methods in Tab.1, Tab.2. We also provide new results with [2,3] in Tab.2,7 in the adversarial robustness task. It can be seen that our method can outperform it in adversarial robustness tasks with FGSM and PGD attacks on the CIFAR10 dataset. Also, as a preprocessing method, our method can further improve the accuracy of adversarial images. These results show the effectiveness of our method, though it is not a specially designed defense method. Additionally, we have incorporated LRP [4] visualizations in Appendix M.\n\n\n[1] Raymond A. Yeh, Yuan-Ting Hu, Zhongzheng Ren, and Alexander G. Schwing. Total variation\noptimization layers for computer vision. In 2022 IEEE/CVF Conference on Computer Vision and\nPattern Recognition (CVPR), pp. 701\u2013711, 2022a.\n\n[2] He, Zhezhi, Adnan Siraj Rakin, and Deliang Fan. \"Parametric noise injection: Trainable randomness to improve deep neural network robustness against adversarial attack.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.\n\n[3] Wang, Haohan, et al. \"High-frequency component helps explain the generalization of convolutional neural networks.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.\n\n[4] Bach S, Binder A, Montavon G, Klauschen F, M\u00fcller K-R, Samek W (2015) On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation. PLoS ONE 10(7): e0130140. https://doi.org/10.1371/journal.pone.0130140"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4693/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700662826136,
                "cdate": 1700662826136,
                "tmdate": 1700662826136,
                "mdate": 1700662826136,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hOB6v9RFxh",
            "forum": "wAsjsSe0U6",
            "replyto": "wAsjsSe0U6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4693/Reviewer_bFfP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4693/Reviewer_bFfP"
            ],
            "content": {
                "summary": {
                    "value": "This article proposes a novel method for visual semantic learning based on early stopping in inverse scale space. The method can disentangle structural information from detailed information in images, and incorporate it into neural network training. The method improves the robustness and explainability of the models on various tasks, such as noisy images, adversarial attacks, and low-resolution images."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1\u3001The paper proposes a novel instance smoothing algorithm that can disentangle semantic and detailed information in images using Total Variation regularization and Inverse Scale Space. This is a creative combination of existing ideas from image processing and sparse recovery. The paper also applies this algorithm to neural network training, which is a new domain for this kind of technique.\n\n2\u3001The paper provides theoretical analysis and empirical evidence to support the effectiveness and efficiency of the proposed algorithm. The paper also compares the algorithm with several baselines and demonstrates its advantages in various robustness tasks, such as noisy images, adversarial attacks, and low-resolution images.\n\n3\u3001The paper is well-written and organized, with clear definitions, notations, and explanations."
                },
                "weaknesses": {
                    "value": "1\u3001The authors have not validated the effectiveness and scalability of their method on larger datasets, such as Imagenet.\n\n2\u3001The authors have not explored the possibility of applying TV regularization on feature maps, which may further improve the robustness and explainability of the models.\n\n3\u3001The authors have not compared with other structure-based methods, such as shape-biased models or edge detection-based models.\n\n4\u3001The authors have not conducted a sensitivity analysis on different TV regularization parameters, which may affect the performance and results of the instance smoothing algorithm."
                },
                "questions": {
                    "value": "Here are some concerns and questions that I have for the authors:\n\n1\u3001How do you choose the optimal sparsity level for different tasks and datasets? Is there a general criterion or guideline for selecting the sparsity parameter?\n\n2\u3001How do you compare your method with other methods that also use TV regularization or other forms of regularization to enhance robustness and interpretability, such as TVM (Yeh et al., 2022b) or LRP (Bach et al., 2015)?\n\n3\u3001How do you evaluate the quality and diversity of the generated image path? Do you have any quantitative or qualitative measures to show the trade-off between structural and detailed information along the path?\n\n4\u3001How do you handle the cases where the structural information is not sufficient or reliable for the task, such as when the shape is distorted or occluded by noise or other objects? Do you have any strategies to incorporate other sources of information, such as texture or context, to improve the performance?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4693/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699434751996,
            "cdate": 1699434751996,
            "tmdate": 1699636450657,
            "mdate": 1699636450657,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xme9afsseu",
                "forum": "wAsjsSe0U6",
                "replyto": "hOB6v9RFxh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4693/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4693/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer bFfp"
                    },
                    "comment": {
                        "value": "Thank you for your efforts and positive assessment of our paper. We address your concerns in the following.\n\n**Q1: Validation on larger datasets.**\n\n**A1:** We have extended our training to include ImageNet100, with the results presented in Tab.5 and achieving consistent results in standard classification.\n\n**Q2: Applying TV regularization on feature maps.**\n\n**A2:** Exploring TV regularization on feature maps is one of our future goals. To date, preliminary trials using TV regularization with our method on feature maps have been made. We train ResNet18 on CIFAR-10 with TV regularization on feature map of the first convolution layer. Evaluate the model using the same experiments in Sec 4.3, we get the results in the following table. As illustrated, the model with TV regularization on the feature map exhibits higher accuracy in capturing low-frequency components while demonstrating lower accuracy in high-frequency components. This observation suggests its capability to effectively learn low-frequency information.\n\n| Model                            | high frequency component | low frequency component |\n|------------------|---------------------------|--------------------------|\n| Vanilla                          | 30%                      | 43%                     |\n| TV regularization on feature map | 20%                      | 65%                     |\n\n**Q3: Comparison with other structure-based/TV regularization methods, such as TVM (Yeh et al., 2022b) or LRP (Bach et al., 2015)?**\n\n**A3:** We have compared our method with TVM [1] in Tab.1,2 (named as \"TV layer\") for noisy and adversarial robustness tasks. Our approach applies TV regularization to image data, distinguishing it from TVM, which requires alterations to the model's structure. For further comparison, we have added comparative analyses with [2,3] in Tab.2,7, focusing on adversarial robustness tasks using CIFAR-10. Additionally, we have incorporated LRP [4] visualizations in Appendix M, as per your suggestion.\n\n**Q4: Sensitivity analysis on different TV regularization parameters.**\n\n**A4:** We've compared the standard classification results of models trained with different sparsity levels in Tab.4, indicating that the outcome remains consistent across different levels of sparsity, particularly when it exceeds a threshold of 0.6.\n\n**Q5: How do you choose the optimal sparsity?**\n\n**A5:** We clarify that our study did not specifically aim to identify the optimal sparsity for each task. Our method has shown robust performance across various sparsity levels, indicating that the experimental outcomes we observed are largely independent of the chosen sparsity. While most of our experiments were conducted with sparsity settings of 0.6 and 0.8, we anticipate similar results with other levels, such as 0.7.\n\n**Q6: How do you evaluate the quality and diversity of the generated image path?**\n\n**A6:** Qualitatively, the visualizations of image paths in Fig.1 and Fig.9 illustrate the trade-off between structural and detailed information. With lower sparsity, structural information, such as shape, dominates. While with higher sparsity, more detailed information such as texture shows up.  Quantitatively, we observed that higher sparsity correlates with enhanced accuracy in standard classification tasks, while our experiments in section 4 reveal a decrease in robustness, indicating the trade-off between them. With incomplete information such the lack of detailed information when sparsity is low, the model cannot achieve high accuracy. With excessive detail learned, as in the vanilla model, the model lacks robustness.\n\n**Q7: How do you handle the cases where the structural information is not sufficient or reliable for the task?**\n\n**A7:** Sections 4.1, 4.2, and 4.4 detail experiments demonstrating the resilience of our approach in these challenging conditions with noisy images, adversarial attacks, or low-resolution data. It is shown that structural information is robust in these cases and can help improve the model's robustness.\n\n\n[1] Raymond A. Yeh, Yuan-Ting Hu, Zhongzheng Ren, and Alexander G. Schwing. Total variation\noptimization layers for computer vision. In 2022 IEEE/CVF Conference on Computer Vision and\nPattern Recognition (CVPR), pp. 701\u2013711, 2022a.\n\n[2] He, Zhezhi, Adnan Siraj Rakin, and Deliang Fan. \"Parametric noise injection: Trainable randomness to improve deep neural network robustness against adversarial attack.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.\n\n[3] Wang, Haohan, et al. \"High-frequency component helps explain the generalization of convolutional neural networks.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.\n\n[4] Bach S, Binder A, Montavon G, Klauschen F, M\u00fcller K-R, Samek W (2015) On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation. PLoS ONE 10(7): e0130140. https://doi.org/10.1371/journal.pone.0130140"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4693/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700663388715,
                "cdate": 1700663388715,
                "tmdate": 1700663388715,
                "mdate": 1700663388715,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]