[
    {
        "title": "Learning from Fragmentary Multivariate Time Series Data with Scalable Numerical Embedding"
    },
    {
        "review": {
            "id": "C93OEGhplX",
            "forum": "Ztt6V7Lgo5",
            "replyto": "Ztt6V7Lgo5",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission978/Reviewer_St5P"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission978/Reviewer_St5P"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a transformer-based model for irregular multivariate time-series data with missingness. They use scalable numerical embedding to deal with the missingness with a revised calculation of attention considering the missingness. They also modify the rollout attention method so that it is still able to provide interpretation given missingness."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "They come up with revised rollout attention that can exclude the impact of missing values, which sounds interesting in terms of interpretation."
                },
                "weaknesses": {
                    "value": "1. Lack of baselines in the experiment. The baselines the authors compare their proposed method are very limited. A lot of transformer-based methods have been proposed recently since the original transformer was proposed in the literature of multivariate irregular time-series, specifically in the field of model EHR data. Yet the only transformer-based model that the authors compare to is the original transformer.  Many of those methods are able to deal with the missingness. For example, Zhang et al. 2023 and many more.\n2. I don\u2019t think what the authors call \u201cSummarization\u201d in Section 3.1 is new. In fact, what they described is actually what a lot of people call \u201cmissingness imputation\u201d and is already commonly used in the literature. For example, Section 3.2.1 of the same paper I mentioned earlier describes something very similar things - discretize the time into different intervals and fill each interval with some values.\n3. Looking at Table 1, their proposed method does not seem to be strong enough compared to the other baseline models.\n\nReference:\\\n[1] Zhang, X., Li, S., Chen, Z., Yan, X., & Petzold, L. R. (2023, July). Improving medical predictions by irregular multimodal electronic health records modeling. In International Conference on Machine Learning (pp. 41300-41313). PMLR."
                },
                "questions": {
                    "value": "I have included some of the questions in the part of Weakness. Other than that:\n1. How to choose the length of the interval p? Does the choice of p have any impact on prediction? For example, a larger p would lead to a shorter summarization and a lower missing rate.\n2. In Section 3.4, when flattening and transposing the SCANE tensor with the shape of $k \\times (n+1) \\times d$, why do you choose to convert into a $k(n+1) \\times d$ matrix instead of a $k \\times d(n+1)$ one? The latter makes more sense to me as $k$ is from the temporal dimension, and both $d$ and $(n+1)$ are related to embedding size.\n3. Why do the authors claim their proposed method is able to \u201ccapture both temporal and spatial (feature-wise) relation between variables\u201d? Isn\u2019t this just the advantage of any transformer-based and RNN-based methods? Basically, I don\u2019t believe other MTS models only capture temporal relationships as they claimed in the related work part.\n4. In Section 4.4, I don\u2019t quite understand the takeaways from the 2nd and 3rd analyses. Why are we imputing the missing entries with different values and what is the point of doing random shuffling? People are not going to do noisy imputation and random shuffling in practice anyway.  Also, since only AUPRC is reported in Table 3, I wonder whether the results from other metrics like AUROC, c-index, and accuracy are consistent."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission978/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission978/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission978/Reviewer_St5P"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission978/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698728976160,
            "cdate": 1698728976160,
            "tmdate": 1699636023891,
            "mdate": 1699636023891,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "TVK3TqF7jB",
            "forum": "Ztt6V7Lgo5",
            "replyto": "Ztt6V7Lgo5",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission978/Reviewer_GLth"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission978/Reviewer_GLth"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a method to process the Multivariate time series (MTS) data, especially for data that contains missing features due to irregularly sampling and asynchronous characteristics.\nIn order for the SCANE pipeline to work, the authors first propose to use summarization techniques to aggregate features from misaligned time points. The time series data will be summarized into a matrix where NaN represents no value, and its corresponding masking $M$ will contain 0 for that position. Then, SCANE will try to create a feature embedding just like each word getting a vector in NLP tasks. After flattening, the data is fed into a transformer, where the masking mechanism is used to avoid paying attention to missing values. In the attention calculation,  the weights associated with missing values approaches 0 after the softmax. To achieve interpretability, the authors apply a revised rollout attention , where the missing values are not considered during the rollout. During the experiments, the authors showcase the effectiveness of SCANE through its prediction power, and provide an example that improves model interpretability."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "S1. The paper is presented in a fairly clear manner, the proper notations are used and the authors provide extensive explanations to each step of the pipeline.\n\nS2. In the experiments, all of the dataset are well-documented. The evaluation metrics for the time series prediction sees reasonable. The authors have also considered AUPRC, AUROC, concordance index (c-index) for different evaluation metrics. The authors have also provided detailed hyperparameter searching on transformers\u2019 architectures and learning rates.\n\nS3. The Attention Weights Visualization provides a good example of model interpretation for MTS data, and demonstrate the effectiveness of the model."
                },
                "weaknesses": {
                    "value": "W1. The reviewer\u2019s main concern is the novelty. The summarization strategy to align time-series data is not a novel practice and have been used heavily in resolving missing values due to asynchronization. Also, transformers with the masking mechanism and rollout attention is nothing new in the community.\n\nW2. The summarize window length P should also be an important hyperparameter to consider. If the P is too short, the summarization step can capture unique time-dependent characteristics, but may leave out more NaN values due to irregularly sampling and asynchronous characteristics. However, if the P is very long, summerization is behaving like a \u201cmax pooling\u201d and may lose local information for that particular window. The authors have not provided any ablation study in how to resolve different P. Nor is P mentioned in the hyperparmeter grid search.\n\nW3. In terms of writing, there are too many redundant contents in the main text. For example, fixed positional encoding measure should be excluded from the main text since people know the positional encoding formulas. In addition, the dataset descriptions are way too long to for people to read through without seeing the experimental results yet. Such contents should be removed from the main text and leave rooms for additional experiments.\n\nW4. The experiments have only compared SCANE with Random Forest, XGBoost (with summerization strategies). GRU and transformers are the only deep learning models. The authors should have considered other MTS forecasting and prediction models, some with GNNs and some with transformers. For example, check [1], [2] and a survey paper [3].\n\n[1]Zhang, Yunhao, and Junchi Yan. \"Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting.\" In The Eleventh International Conference on Learning Representations, 2023. https://openreview.net/forum?id=vSVLM2j9eie.\n\n[2]Wu, Zonghan, Shirui Pan, Guodong Long, Jing Jiang, Xiaojun Chang, and Chengqi Zhang. \"Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks.\" CoRR abs/2005.11650 (2020). https://arxiv.org/abs/2005.11650.\n\n[3]Wen, Qingsong, Tian Zhou, Chaoli Zhang, Weiqi Chen, Ziqing Ma, Junchi Yan, and Liang Sun. \"Transformers in Time Series: A Survey.\" Preprint, submitted February 2023. arXiv:2202.07125 [cs.LG]. https://arxiv.org/abs/2202.07125."
                },
                "questions": {
                    "value": "Q1. In the attention weight visualization, the authors have only provided visualization with one positive sample. The reviewer is wondering whether the positive sample is cherry picked? If not, could the authors provide more samples (more of ones with missing values) to demonstrate the interpretability feature?\n\nQ2. The reviewer is wondering how the authors select the P as the summarize window length. Have the authors considered building multiple levels of summarizations, and incorporate multiple levels to better capture the time-dependent characteristics?\n\nQ3.  Have the authors considered to use a MTS dataset that do not have any missing features, and then generate different percentages of missing values within the dataset to demonstrate SCANE\u2019s effectiveness in low missing data ratio and high missing data ratio scenarios?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/a"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission978/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission978/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission978/Reviewer_GLth"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission978/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698772237286,
            "cdate": 1698772237286,
            "tmdate": 1699636023819,
            "mdate": 1699636023819,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "9FkC2LVgHG",
            "forum": "Ztt6V7Lgo5",
            "replyto": "Ztt6V7Lgo5",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission978/Reviewer_9DJ5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission978/Reviewer_9DJ5"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a scalable numerical embedding (SCANE) method, which has three key contributions as featured in the paper: (i) it can handle missing values by masked attention; (ii) it allows spatial-temporal interactions along both the feature and time dimension; (iii) it utilizes the revised rollout attention to add interpretability of the model. The proposed SCANE is evaluated on one private patient hospital visit dataset and two public ICU visit datasets."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This paper is very practical and the technical steps are explained clearly. The data processing techniques could be useful for processing similar data.\n2. The experimental evaluation on three datasets looks comprehensive and the results also show marginal improvements over baselines."
                },
                "weaknesses": {
                    "value": "1. Technical contributions are not significant and some model designs need more motivations.\n    - Sec 3.1: Similar techniques have been proposed in earlier papers.\n    - Sec 3.2: Why this design works better? It would be better to add more justifications.\n    - Sec 3.4: A very similar techinique is proposed in this recent NeurIPS2023 paper https://openreview.net/forum?id=c2LZyTyddi (the authors in the neurips paper has flattened multi-channel medical signals into a sequence and then use transformer to learn spatial-temporal relations, which is similar to the practice of flattening feature matrix in this manuscript).\n2. Complexity of the model is a big concern. In Sec 3.4, the proposed model flattens and transposes the $SCANE(X', M)$ into a $k(n+1)\\times d$ matrix and then applies the transformer model. Since the original transformer model has quadratic complexity, it seems that the overall model complexity will be increased a lot after this step, from O(n^2) to O(n^2k^2), which can be the major drawback of the proposed model. \n3. Many important baselines are missing for the mortality prediction prediction task on two public ICU datasets. For example,\n\n[1] Choi, Edward, Zhen Xu, Yujia Li, Michael Dusenberry, Gerardo Flores, Emily Xue, and Andrew Dai. \"Learning the graphical structure of electronic health records with graph convolutional transformer.\" In Proceedings of the AAAI conference on artificial intelligence, vol. 34, no. 01, pp. 606-613. 2020.\n\n4. The \"Accuracy\" metric seems not suitable in this extremely imbalanced setting (if the model predicts all negative, the accuracy can be more than 95%, higher than any model in the Table~1). Maybe using balanced or weighted accuracy is a better practice."
                },
                "questions": {
                    "value": "1. Could you report the model running time comparison and memory usage? The flattening procedure has significantly increase the sequence length and could incur huge memory load for transformer encoder. \n\n2. In fact, the reviewer would like to hear about the authors' opinions on the effectiveness of missing value imputation in the EHR prediction tasks. This is something related to the problem setting. As far as the reviewer knows, EHR data have a lot of missing values if we formulate them as a temporal matrix (feature cross timeline). Sometimes the missing values can be much more than the existing values, meaning that the matrix $X$ can be a sparse matrix. In these common cases, should we still formualte EHR data as a temporal matrix? Why the proposed techniques work better in this case?\n\n3. More baselines (from the recent papers not hand-crafted by the authors) should be employed in the evaluation."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission978/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698789089962,
            "cdate": 1698789089962,
            "tmdate": 1699636023755,
            "mdate": 1699636023755,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "SzjT0VB37F",
            "forum": "Ztt6V7Lgo5",
            "replyto": "Ztt6V7Lgo5",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission978/Reviewer_USDM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission978/Reviewer_USDM"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents the SCAlable Numerical Embedding (SCANE) method, designed to address the challenge of missing values in Electronic Health Record (EHR) data. This approach involves converting each observed variable within a given time step into a vector. These individual variable vectors are then collectively processed using a Transformer architecture. The effectiveness of SCANE was assessed using three distinct EHR datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The addressed problem is relevant for EHR data."
                },
                "weaknesses": {
                    "value": "a. The concept proposed in the paper lacks novelty. The technique of numerical embedding for EHR, particularly in the context of imputation, has already been explored in several publications featured at reputable conferences and journals  [1, 2].  Furthermore, the application of the Transformer encoder, as described in the paper, is not an original concept [3, 4]. A significant oversight in the study is the lack of consideration and citation of established papers that have previously applied this approach to similar problems [1, 2, 4]. However, the well-established papers for this problem were not considered as a baseline, nor cited. Additionally, for a more rigorous baseline, the paper should have benchmarked against more established methods, such as those based on Ordinary Differential Equations (ODEs) [5]. Overall, this paper is basically reaping the idea, presented in 3, but with the mask. However, the mask idea also is not novel [6,7] before.\n\nb. The evaluation lacks ablation studies, particularly examining the separate impacts of the variable encoding step and Transformer aggregation on performance. Additional experiments also should be considered, i.e how approach behaves with different ration of missing values.\n\nc. The paper does not include a complexity analysis of the model, which is particularly relevant since aggregation is performed across entire (binned) time-series. This raises questions about the model's scalability and efficiency, especially when dealing with very long time-series data. Online tasks also should be considered.\n\nd. The authors employed focal loss in their model but did not present results using cross-entropy loss for comparison. The recent studies show that it does not help [8]; so the results should be provided for all losses, if it was helpful, otherwise it is not clear.\n\n1. Zhang et. al. \"Graph-Guided Network for Irregularly Sampled Multivariate Time Series.\" International Conference on Learning Representations. 2021.\n2. Tipirneni et. al. \"Self-supervised transformer for sparse and irregularly sampled multivariate clinical time-series.\" ACM Transactions on Knowledge Discovery from Data (TKDD) 16.6 (2022): 1-17.\n3. Horn et. al. \"Set functions for time series.\" International Conference on Machine Learning. PMLR, 2020.\n4. Shukla et. al. \"Multi-Time Attention Networks for Irregularly Sampled Time Series.\" International Conference on Learning Representations. 2020.\n5. Rubanova et. al. Latent ordinary differential equations for irregularly-sampled time series. In Advances in Neural Information Processing Systems 32, pp. 5320\u20135330. Curran Associates, Inc., 2019.\n6. Tomasev et al. A clinically applicable approach to continuous prediction of future acute kidney injury. Nature, 572(7767):116\u2013119, 2019.\n7. Tomasev et al. Use of deep learning to develop continuous-risk models for adverse event prediction from electronic health records. Nature Protocols, 16(6):2765\u20132787, 2021.\n8. Y\u00e8che et al. Temporal Label Smoothing for Early Event Prediction, International Conference on Machine Learning. PMLR, 2023."
                },
                "questions": {
                    "value": "1. More baselines [1,3,4,5,6,7] and ablation studies should be considered, see a, b, d in Weakness;\n2. Complexity analisys and performance on the online tasks."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission978/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission978/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission978/Reviewer_USDM"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission978/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698861161581,
            "cdate": 1698861161581,
            "tmdate": 1699636023682,
            "mdate": 1699636023682,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]