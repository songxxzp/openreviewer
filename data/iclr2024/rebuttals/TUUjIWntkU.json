[
    {
        "title": "Explainable medical image clustering"
    },
    {
        "review": {
            "id": "LbhmezeYvs",
            "forum": "TUUjIWntkU",
            "replyto": "TUUjIWntkU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3713/Reviewer_ig3J"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3713/Reviewer_ig3J"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies medical microwell images containing cancerous and healthy cells, which are annotated in the provided data set.\n\nThe goal of the paper is to cluster the images in an informative way, in the absence of ground-truth labels for clustering, and provide a human-interpretable explanation for the clustering.\n\nThe proposed method can be separated into four modules: first, a feature extractor is trained, which consists of a u-net architecture combined with a multi-head attention module.  The images are then clustered based on the extracted features using affinity propagation.  A visual explanation of the clusters is given by adopting grad-cam and taking the cluster labels as the target concepts.  A text explanation is provided based on auxiliary predictions of cell density and proliferation."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper examines an interesting and important question, with relevance to cancer/immunotherapy research.  In this context, the idea of studying the problem with an emphasis on explainable learning is well-motivated, in order to gain more insight on what is being learned by the network and to have more confidence in the predictions made by the network."
                },
                "weaknesses": {
                    "value": "weaknesses can be grouped into four categories as follows, in order of importance:\n\n1. novelty\n\nEach module in the proposed framework is largely leveraging existing work, with basic adaptation to the studied image data.  Feature extraction seems to be u-net with multi-head attention and some hand-designed features.  Clustering is T-SNE followed by affinity propagation.  Visual explanation is GradCam using assigned cluster labels as target concepts.  Text explanation is looking at the output of auxiliary image classification models.\n\n2. clarity of details\n\nImportant details in the paper are not clearly conveyed and/or missing.  As examples: The description of the feature extractor is unclear in multiple respects - what are the specifics of the architecture, what are the specifics of the pseudo-labels, what are the specifics of the hand-designed features and how are these features integrated, what is the loss function, what is the training data.  What is the dimensionality of the feature extractor output?  How are the cancer and healthy cell annotations obtained, are they dense (complete) labelings, are they noisy?  In the result tables, the headings are not explained - SE, SP, PC, JS, DC.  \n\n3. experimental validation\n\nVery limited quantitative evaluation and comparisons against existing baselines are given, particularly for the main goal of the paper which is the clustering of the images.  As far as qualitative evaluation, there are not concrete examples of interesting findings or observations that can be derived from the final clustering.  \n\n4. clarity of writing\n\nI would encourage the authors to focus on clear, simple writing, with the goal of communicating information in a clear and concise manner.  As a practical specific example, many adjectives and adverbs can be dropped.  For instance, \"comprehensive\" is used 11 times in the paper, \"meticulously\" is used 4 times in the paper; simply dropping these terms has no impact on the meaning but makes the writing more concise."
                },
                "questions": {
                    "value": "See weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3713/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698688721024,
            "cdate": 1698688721024,
            "tmdate": 1699636327545,
            "mdate": 1699636327545,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "H0gsotmS2Y",
            "forum": "TUUjIWntkU",
            "replyto": "TUUjIWntkU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3713/Reviewer_5T7W"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3713/Reviewer_5T7W"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a cell dataset for cancer and healthy cells. The paper follows a sequential process of feature extraction, clustering, and visual and textual explanations of the clustering algorithm. Authors also provide ablation study of different modules of the proposed method and evaluate on the proposed dataset."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Authors provide a new dataset for cancer and healthy cells. However, they do not discuss the availability of dataset to use for research community. Authors use clustreing to overcome the issue of ground truth and use explanation modules to get the validity of the generated clusters. Authors also give a detailed ablation and evaluation."
                },
                "weaknesses": {
                    "value": "The paper is not easy to follow. There are many parts missing which makes the paper hard to understand fully. My detailed comments are as follows.\n\n1> The paper proposes a new cell dataset, however, it does not discuss the drawbacks of previous datasets. Authors should provide a comparative study and explain why a new dataset is necessary. It is not clear if annotations are available for the dataset. If yes, how annotations are prepared should be mentioned. In Fig. 3 cancer cell and healthy cell annotations are given, however, they overlap. For example, in \u2018Day0\u2019 image, the same cell is marked as both healthy and cancer cell.\n2> Fig.2 is not clearly explained. Forward pass and backpropagation is not clear. Also, loss function is not defined. \n3> \u2018Preprocess\u2019 mentioned in Fig. 2 is not explained in the paper. \n4> Network architecture and training are not clearly mentioned. \n5> How are human-designed features computed and why can't neural networks capture these features?\n6> Are explanations generated using Grad-Cam and text modules verified by humans?"
                },
                "questions": {
                    "value": "please see the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3713/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698755386565,
            "cdate": 1698755386565,
            "tmdate": 1699636327467,
            "mdate": 1699636327467,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "z1o4Yj1Zl2",
            "forum": "TUUjIWntkU",
            "replyto": "TUUjIWntkU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3713/Reviewer_peGV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3713/Reviewer_peGV"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a temporal dataset of microscopy cell images. Each set of images is taken over 5 day period and contains annotations for healthy and cancerous cells under different medication experiments. The authors propose a deep learning model that consists of a U-Net encoder (feature extractor) in addition to manual features representing density and rate of change in cancer and T-cells. These features are extracted for each image and passed to multi-head attention to capture attention over the temporal data. The resulting features are used to perform clustering. To explain the resulting clusters, Grad-cam is used to visualize important parts of the images. Text explanations based on transforming manual features into text are also proposed."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- The author create a public temporal microscopy dataset with cancer and healthy cells annotations. \n- The paper proposes a pipeline for processing the temporal data."
                },
                "weaknesses": {
                    "value": "- The method is not clear. For instance:\n  - It is not clear how the pseudo labels for live/dead cells are derived and how they are used. Later there is only mention of using HSV to separate foreground and background.\n  - How is the feature extractor trained on and what is the loss function?\n\n- The text explanation is based on manual features such as density where a model is trained to predict them. They don't have anything to do with the features used in the clustering. So they really don't explain the clustering.\n\n- In Fig 3, the annotations for cancer and healthy cells overlap. This is especially obvious in the day 9 images.\n\n- In Table 1, the authors compare unet encoder with other architectures including resnet. Without the skip connections, a UNet encoder is basically a large CNN.\n\n- The authors present the dataset as temporal sequences based on variation in treatment. However, the results do not show the clustering correlate with any outcome or treatment.\n\n\n- Minor:  In page 2:\n  - Typo in the sentence \"However, owing to the absence of ground truth-remove\"\n  - Typo in the sentence \"a text explanation module-remove sentence.\""
                },
                "questions": {
                    "value": "- In Fig 2 caption: \"then we will use a clustering algorithm to label each image into a cluster.\" Does that mean each individual image is clustered? I thought it was each temporal sequence.\n- In the section 3.2 Cluster Module, does group refer to a cluster or a temporal sequence?\n- The scores presented in Table 1, what do the abbreviations mean? and what is the task?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3713/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3713/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3713/Reviewer_peGV"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3713/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698906330529,
            "cdate": 1698906330529,
            "tmdate": 1699636327371,
            "mdate": 1699636327371,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "NlrcZtmWmN",
            "forum": "TUUjIWntkU",
            "replyto": "TUUjIWntkU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3713/Reviewer_ENtk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3713/Reviewer_ENtk"
            ],
            "content": {
                "summary": {
                    "value": "The authors introduce a cell dataset that captures the developmental trend of cancer cells and T Cells under the influence of diverse experimental conditions . The authors also present an approach to both cluster input images and elucidate the rationale behind their grouping. They leverage a U-net encoder for individual microwell image information encoding and multihead attention for information encapsulation across different time points"
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The introduction of a novel dataset with unique acquisition protocols relative to what is encountered usually in the community, coupled with the proposal of an architectural framework adept at extracting vital information from input microwell images. A multihead attention layer is incorporated to rationalise U-net-extracted features and human-designed features. The experimental design and the engineering of different off-the-shelf components to work on microwell data, while not novel from a methodological lens, is an appreciable contribution to the ML for healthcare community."
                },
                "weaknesses": {
                    "value": "There is very little offered in terms of methodological novelty. The paper is a collection of existing (and widely used) ideas in literature glued together in a manner to address the proposed application. As such, this would be a nice contribution in a more focused venue that brings together practitioners in the domain addressed by the paper (and the introduction of the dataset would indeed be a great addition). \n\nThe writing and elucidation of ideas needs reworking. Several sections are not clearly written. One issue that crops up is whether there is sufficient clarity with regards to the biological concepts described in relation to the dataset proposed, assuming the typical ICLR audience. The machine learning methods used can be described more clearly. Clarity of the images used needs improvement as well -  this is important since a new dataset rich in imaging features and artifacts is being introduced as a key contribution.\n\nThe ablation studies need to be more detailed and described better. Currently, the section is written in a manner that is not particularly informative or helpful in discerning the key messages of the paper. Please consider using Supplementary materials to address content that doesn't fit within page limits.\n\nTypo: 4.2.1 'IMPLEMENT' DETAILS --> IMPLEMENTATION DETAILS"
                },
                "questions": {
                    "value": "Please describe the actual methodological novelties pursued in this problem?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3713/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699007023315,
            "cdate": 1699007023315,
            "tmdate": 1699636327292,
            "mdate": 1699636327292,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]