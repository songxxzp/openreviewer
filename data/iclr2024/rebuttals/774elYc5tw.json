[
    {
        "title": "Unlocking Anticipatory Text Generation: A Constrained Approach for Faithful Decoding with Large Language Models"
    },
    {
        "review": {
            "id": "XiHDp5C8jd",
            "forum": "774elYc5tw",
            "replyto": "774elYc5tw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9116/Reviewer_h9Ue"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9116/Reviewer_h9Ue"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes formalizing text generation as a future-constrained generation problem to minimize undesirable behaviors and enforce faithfulness to instructions. The estimation of future constraint satisfaction, accomplished using LLMs, guides the text generation process."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The paper tackles an important problem of controlling undesirable behaviors like toxicity and hallucination in large language model text generation. This is a key challenge as models scale up. \n* The method seems generic enough to handle different types of constraints like keywords, toxicity, factual correctness etc. as evidenced by the diverse experimental tasks.\n* Results across the three tasks demonstrate improved constraint satisfaction and control over text generation with modest tradeoffs to fluency. \n* Analysis of the proposed satisfaction score on constructed benchmarks provides useful insights."
                },
                "weaknesses": {
                    "value": "* The satisfaction score estimation is currently limited and may not be robust or accurate enough for all constraints. More investigation into refining this estimation would be beneficial.\n* It is not clear if the gains will sustain for very long text generation where error accumulation could occur. More analysis on larger generation tasks could help.\n* There is no human evaluation of the quality and naturalness of outputs. Automatic metrics have limitations.\n* The factual correctness results are quite noisy and could benefit from more tuning and robustness testing."
                },
                "questions": {
                    "value": "N/A"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9116/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698555767825,
            "cdate": 1698555767825,
            "tmdate": 1699637147320,
            "mdate": 1699637147320,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KgOoFiC5p7",
                "forum": "774elYc5tw",
                "replyto": "XiHDp5C8jd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9116/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9116/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to express our gratitude for your detailed review and feedback.\n\n***\u201cThe satisfaction score estimation is currently limited.\u201d***\n\nIn this work, we use a scoring mechanism to identify if a constraint has not been satisfied yet to guide the future generation for LLMs. Our work highlights the demonstrated effectiveness of the current constraint score function. Additionally, the appendix, particularly in Figure 5, presents supplementary results using the score function with binary Yes/No prompts. While acknowledging the potential exploration of other scoring functions, we posit that tuned models or the utilization of smaller models with more robust or accurate future satisfaction score functions may prove more beneficial.\n\n***\u201cnot clear if the gains will sustain for very long text generation.\u201d***\n\nWe present the model outputs of different decoding methods for the long-form QA task in Table 10. Notably, there is a reduction in error accumulation, with a significant decrease in the number of typos for the word '401k.' Additionally, the human evaluation results in Table 7 further underscore the improvements across three dimensions: Fluency, Informativeness, and Correctness.\n\n***\u201cAutomatic metrics is limited.\"***\n\nIn our study, we surpass traditional n-gram-based evaluation metrics by integrating constrained satisfaction measures. These include the Coverage score for CommonGen, toxicity score from the Perspective API for the toxicity task, and correctness for the ALCE benchmark. Moreover, our research extends to human evaluations across three dimensions: Fluency, Informativeness, and Correctness. The combined outcomes from these diverse evaluations consistently emphasize the benefits of constraint satisfaction, ultimately leading to faithful generation.\n\n\n***\u201cThe factual correctness results are quite noisy\u201d***\n\nSignificantly, we observed that answers are truncated by the first newline in the ALCE's script, impacting our findings. Consequently, we present updated results on faithful question-answering generation. The new results indicate the superiority of our proposed method."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9116/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700593537397,
                "cdate": 1700593537397,
                "tmdate": 1700593537397,
                "mdate": 1700593537397,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hKOlPCNdX2",
            "forum": "774elYc5tw",
            "replyto": "774elYc5tw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9116/Reviewer_Ht7A"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9116/Reviewer_Ht7A"
            ],
            "content": {
                "summary": {
                    "value": "This paper points out that language model suffer from undesired behaviors such as toxicity or hallucinations and proposes a approach called future constraint satisfaction to tackle this issue. This method forces the model to take constraints into account when generating texts. The constraints here can be expressed directly in natural language. Specifically, it controls the probability of the next generated token by adding a score in the decoding stage. This score is obtained by prompt $x$ and prefix $y_{\\leq}t$, using the log-likelihood. Experiments on three tasks: keyword-constrained generation, toxicity reduction, and factual correctness in question answering field show that this method can effectively improve efficiency and effectiveness compared to the baselines."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper excels in its clarity and succinctness in explaining the proposed method\u2019s core idea, namely future constraint score. The subsequent formula provides a direct method for computing this score.\n- The experimental section is well-structured and comprehensive. The authors has conducted experiments on three different QA tasks, using multiple backbone models. Moreover, the impact of hyperparameters on the experimental results has also been thoroughly investigated.\n- The entire paper is well-articulated, ensuring a smooth reading experience without any obscure sections."
                },
                "weaknesses": {
                    "value": "- The definition of future Constraint Satisfaction is somewhat ambiguous to me. According to the formula at the bottom of page 2, your $R(y_{\\leq t}, C(x))$ is used to approximate $\\log p(C(x)|y _{\\leq t})$, yet this is similar to the definition of $R$ provided in formula 1 on page 3. Could you please elaborate on the benefits of such a definition and why |SEP| token is added? This aspect lacks a comprehensive analysis.\n- The approach considers the impact of prompt and prefix on the next token during the generation stage, with calculations only utilizing maximum likelihood estimation. The essence of future Constraint Satisfaction appears to revolve around the next token\u2019s compatibility with the constraint. This similar idea is reflected in many controllable text generation methods, and the authors does not specifically compare these differences (only the different forms of control are mentioned in the related work section), which makes the paper seem like an incremental contribution.\n- While the proposed method is relatively straightforward, it lacks robust experimental evidence to highlight its superiority over conventional decoding strategies. Moreover, the existing experimental results suggest that the improvements are rather limited.\n- The paper would benefit greatly from the inclusion of a case Study and human evaluation. This would provide tangible examples of how this method improves issues like hallucinations. However, the authors solely provided results for some indicators (like BLEU) that have been proven to lack reliability.\n- All the figure are not in the form of vector images, which results in distortion when the images are enlarged."
                },
                "questions": {
                    "value": "na"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9116/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698658276000,
            "cdate": 1698658276000,
            "tmdate": 1699637147214,
            "mdate": 1699637147214,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "glwxxN19Al",
                "forum": "774elYc5tw",
                "replyto": "hKOlPCNdX2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9116/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9116/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to express our gratitude for your detailed review and feedback. We have updated our submission with more details on experiments, decoding time, human evaluation results, etc.\n\n***\u201cwhy |SEP| token is added?\u201d***\n\nWhen calculating the future constraint satisfaction score R with the given prefix $y_{<=t}$\u200b , the use of <SEP> is employed to delineate the prefix from the language description constraint C. This separation is crucial; otherwise, the logistic score on the first token of C conditioned on the prefix $y_{<=t}$  lacks meaningful interpretation. Our preliminary experiments indicate that this setting is more effective. Further details will be expounded upon in the upcoming version.\n\n***\u201cdifferences forms of work\u201d***\n\nIndeed, there is other related work on guided generation, but the forms of control differ significantly. In our approach, we verbalize the constraint and estimate future satisfaction scores using LLMs. Our motivation stems from our belief in the expressive power of language. Several distinctions set our work apart from previous endeavors. Firstly, we do not require additional fine-tuning for tasks. Secondly, our guidance is integrated into the token-level generation process as opposed to post-generation refinement. Thirdly, we employ natural language constraints, providing flexibility to incorporate various constraints. Lastly, our approach includes self-interpretation of these partial prefix outputs, among other unique features.\n\n***\u201cAll the figure are not in the form of vector images.\u201d***\n\nThank you for bringing this to our attention. We have revised all figures, and we hope the updated versions meet your expectations. Your feedback is valuable, and if you have any further questions or need additional assistance, please don't hesitate to let us know.\n\n***\u201crobust experimental evidence, one would expect more significant improvements.\u201d***\n\nWe have achieved notable results, particularly in the context of CommonGen, with substantial improvements in coverage scores (e.g., Falcon-7B-Instruct: 88.7% -> 93.3%, LLaMa-2-13B-Chat: 93.6% -> 95.2%, Falcon-40B-Instruct: 88.7% -> 97.6%). Furthermore, we provide updated results on QA faithful generation on LLaMa-2-13B-Chat, addressing the issue of answer truncation caused by the first newline in the ALCE\u2019s script. In addition to quantitative outcomes, human evaluations confirm superior improvements across three dimensions: Fluency, Informativeness, and Correctness. We believe that future gains can be achieved with a more robust or accurate future-constrained score, potentially through the refinement or tuning of models.\n\n\n***\u201cWhat is the tradeoff between time complexity and generated text quality?\u201d***\n\nOur method incurs a linear slowdown of approximately $k$ times, primarily attributable to the overhead associated with computing future satisfaction scores on candidates. A detailed breakdown of decoding times for each example in our experiments is provided in Table 6.\n\nIt is worthwhile to note that the increase in decoding time is a reasonable trade-off for achieving faithful generation. To mitigate this, several strategies can be employed to maintain generation quality while reducing time, such as selecting a smaller $k$ and opting for smaller yet finely tuned LLMs capable of efficiently computing the future constraint satisfaction score $R(\\y_{<=t}, C(\\x))$."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9116/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700593431927,
                "cdate": 1700593431927,
                "tmdate": 1700593431927,
                "mdate": 1700593431927,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "sJnSL4J3f6",
            "forum": "774elYc5tw",
            "replyto": "774elYc5tw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9116/Reviewer_eM49"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9116/Reviewer_eM49"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes future-constrained generation as a way to improve faithful decoding with large language models. This essentially introduces, in the beam search, a function of both the generated sequence (at a certain time step) and the future constraint also in the form of a natural language (e.g., \"the sentence will have these concepts: run team field drill\"). The function is implemented as the likelihood of generating the concatenation of both sequences using a pretrained language model. The paper shows multiple empirical results showing that the method is effective in following the constraints, even improving over a larger language model."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "* The use of future constraints is interesting and intuitive since they act as (self-)evaluation, ensuring that the model is still following the constraints.\n\n* The method is quite flexible in terms of the constraints that can be put in."
                },
                "weaknesses": {
                    "value": "* While the method has been empirically shown to better perform than baselines in terms of n-gram overlap and correctness, there are other dimensions that are not reported. Firstly, since the method essentially introduces a call to a language model for each beam and for each timestep in the beam search, we expect that the decoding time is slow. How much is the tradeoff between this and \"text quality\"? Secondly, evaluation metrics based on n-gram overlap are not usually good rankers when the models are already very strong (which in this case they are since they are based on LLMs). Human evaluation should have been conducted. Thirdly, the authors used ALCE as a benchmark, however they did not evaluate on the QAMPARI dataset which is also part of ALCE. Finally, since the focus is on \"faithful decoding\", the paper should have focused on those evals as well (and not on metrics based on n-gram overlap).\n\n* Parts of the paper are difficult to understand. For example, since there is no mention of how the experiments are set up, it was very difficult to comprehend what the authors wanted to convey in Figure 2 since it showed a bunch of previously unintroduced models and mentioned terms not defined (e.g., Ranking accuracy). This issue is repeated in Figures 4 and 5. I think overall the paper needs proofreading.\n\n* Overall, the results do not seem convincing as most improvements (focusing on correctness which is mostly related to faithful decoding) are marginal and sometimes fail to improve over a greedy/beam search baseline. Given the complexity of the method, one would expect more significant improvements."
                },
                "questions": {
                    "value": "* What is the tradeoff between time complexity and generated text quality?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9116/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698803891833,
            "cdate": 1698803891833,
            "tmdate": 1699637147092,
            "mdate": 1699637147092,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZFdjPAQ44u",
                "forum": "774elYc5tw",
                "replyto": "sJnSL4J3f6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9116/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9116/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We extend our sincere appreciation for your thorough review and constructive feedback. In response, we have enhanced our submission by including additional details on experiments, decoding time, human evaluation results, and other relevant aspects. Thank you for your valuable insights.\n\n***\u201cDecoding time, tradeoff between time complexity and generated text quality \u201d***\n\nOur method incurs a linear slowdown of approximately $k$ times, primarily attributable to the overhead associated with computing future satisfaction scores on candidates. A detailed breakdown of decoding times for each example in our experiments is provided in Table 6.\n\nIt is worthwhile to note that the increase in decoding time is a reasonable trade-off for achieving faithful generation. To mitigate this, several strategies can be employed to maintain generation quality while reducing time, such as selecting a smaller $k$ and opting for smaller yet finely tuned LLMs capable of efficiently computing the future constraint satisfaction score $R(\\y_{<=t}, C(\\vx))$.\n\n***\u201cEvaluation metrics\u201d***\n\nWe not only present evaluation metrics based on n-grams but also include constrained satisfaction scores, such as the Coverage score for CommonGen, toxicity score from Perspective API for the toxicity task, and correctness for the ALCE benchmark. Additionally, illustrative outputs are showcased in Table 9 and Table 10. Our study encompasses human evaluations across three dimensions: Fluency, Informativeness, and Correctness. Collectively, these findings highlight the benefits of constraint satisfaction, contributing to faithful generation.\n\n***\u201cLack experiments setup details\u201d***\n\nWe update the experiment setup and add more details on these models in Section A.1."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9116/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700593209654,
                "cdate": 1700593209654,
                "tmdate": 1700593209654,
                "mdate": 1700593209654,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UUeDYQW8CL",
                "forum": "774elYc5tw",
                "replyto": "ZFdjPAQ44u",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9116/Reviewer_eM49"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9116/Reviewer_eM49"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response. I still feel that the evaluation lack focus on faithfulness whilst introducing a method to improve such. All datasets should have been measured with metrics that measure \"faithfulness\". An example of such metrics is one that checks entailment of output given the input as context."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9116/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700729881665,
                "cdate": 1700729881665,
                "tmdate": 1700729881665,
                "mdate": 1700729881665,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "e1ZsZegig6",
            "forum": "774elYc5tw",
            "replyto": "774elYc5tw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9116/Reviewer_cGVr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9116/Reviewer_cGVr"
            ],
            "content": {
                "summary": {
                    "value": "This work define a decoding staretgy where the future tokens are constrained based on some lexical constraints which are defined in the prompt. The idea is to have generation that remain faithuful to the prompt and do not violate lexical constraint defined in the prompt. The authors define a novel LM scoring mechanism to identify if a constraint has not been satisfied yet to guide the future generation. The authors show performance of their methods on thress tasks: CommonGen, Toxicity reduction and Factual QA. Their method improves faithfulness to the prompt in most cases."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.) The paper is well written and evaluation is well thought out."
                },
                "weaknesses": {
                    "value": "1.) The novelty of the new constraint scoring function is fairly limited.\n2.) Overall performance gains are not large and only help small sized LLMs."
                },
                "questions": {
                    "value": "1.) Does the <SEP> token seperate the prompt and continuation? Is it same across all the LLMs? Is it repurposed from one of the special tokens during pre-training?\n2.) Does the inference mechanism ever lead to degenerate sequences? If yes, how often does that occur?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9116/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698818354378,
            "cdate": 1698818354378,
            "tmdate": 1699637146967,
            "mdate": 1699637146967,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "u2J5EgJdKl",
                "forum": "774elYc5tw",
                "replyto": "e1ZsZegig6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9116/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9116/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to express our gratitude for your detailed review and feedback.\n\n ***\u201cThe novelty of the new constraint scoring function\u201d***\n\nIn this work, we use a scoring mechanism to identify if a constraint has not been satisfied yet to guide the future generation for LLMs. Our work highlights the demonstrated effectiveness of the current constraint score function. Additionally, the appendix, particularly in Figure 5, presents supplementary results using the score function with binary Yes/No prompts. While acknowledging the potential exploration of other scoring functions, we posit that tuned models or the utilization of smaller models with more robust or accurate future satisfaction score functions may prove more beneficial. \n\n\n\n***\u201cOverall performance gains and only help small sized LLMs\u201d***\n\nWe have achieved notable results, particularly in the context of CommonGen, with substantial improvements in coverage scores (e.g., Falcon-7B-Instruct: 88.7% -> 93.3%, LLaMa-2-13B-Chat: 93.6% -> 95.2%, Falcon-40B-Instruct: 88.7% -> 97.6%). Furthermore, we provide updated results on QA faithful generation on LLaMa-2-13B-Chat, addressing the issue of answer truncation caused by the first newline in the ALCE\u2019s script. In addition to quantitative outcomes, human evaluations confirm superior improvements across three dimensions: Fluency, Informativeness, and Correctness. We believe that future gains can be achieved with a more robust or accurate future-constrained score, potentially through the refinement or tuning of models. \n\n\n\n***\u201cDoes the <SEP> token seperate the prompt and continuation?\u201d***\n\nNo, the <SEP> token is specifically employed when calculating the future constraint score to separate the prefix and verbalized constraint. It's important to note that there is no <SEP> token used to separate the prompt and continuation.\n \n\n\n***\u201cDoes the inference mechanism ever lead to degenerate sequences? If yes, how often does that occur?\u201d***\n\nWe did not observe any degenerate sequences. The hyperparameters $k$ and $\\lambda$ in Formula (2) can be adjusted to control the generation behavior."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9116/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700593022720,
                "cdate": 1700593022720,
                "tmdate": 1700593022720,
                "mdate": 1700593022720,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]