[
    {
        "title": "Exploring the Limitations of Graph-based Logical Reasoning in Large Language Models"
    },
    {
        "review": {
            "id": "rq6bjGXWPn",
            "forum": "S9YfP4rsfX",
            "replyto": "S9YfP4rsfX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7761/Reviewer_WkiA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7761/Reviewer_WkiA"
            ],
            "content": {
                "summary": {
                    "value": "The paper reviews the power of widespread LLMs with respect to several graph-traversal or related problems. The authors propose a benchmark of 10 problems, for which several graphs are created. Each graph in each problem is submitted to LLMs, and authors provide details. on the resulting accuracy, compared to the ground truth (minus some error because authors use LLM themselves to compare the response of models against the ground truth). The result point out to limited power of LLMs, and authors show that branching truly creates complications on the way LLMs process the results."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "* Good standardized benchmark provides unbiased evaluation of each LLM. \n* Interesting insights relating the degrees of freedom of each problem."
                },
                "weaknesses": {
                    "value": "* The scope of the paper is somewhat limited, and these results are expected to what one understands of LLMs through general knowledge. This feels more like a workshop paper with respect to the scope and impact. \n* The benchmark always assume graphs are given as adjacency matrices. Yet, in real life, most graphs are not stored in this way, but rather as adjacency lists (or, equivalently, storing adjacency matrices as sparse matrices). \n* Authors claim \"... that a greater number of average degrees of freedom for traversal per node has an inverse correlation with LLM reasoning capability\". but they get this out of comparing an experiment with 10 nodes and an experiment of 20 nodes. This is not enough to conclude the aforementioned claim, as there could be several other explanations for the decreased performance, such as more complexity out of trying to decode the matrix with more nodes, or failure to work with more total memory. At least, to verify this claim, authors should maintain total number of nodes but increase the level of branching encountered in the traversal (for example in problem 1.2)."
                },
                "questions": {
                    "value": "I would be interested in previous motivation for this paper in the literature, or some previous evidence that the impact of these results merit publication in ICLR."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7761/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7761/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7761/Reviewer_WkiA"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7761/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698713561182,
            "cdate": 1698713561182,
            "tmdate": 1699636948245,
            "mdate": 1699636948245,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "iVjfzZkF8P",
            "forum": "S9YfP4rsfX",
            "replyto": "S9YfP4rsfX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7761/Reviewer_eQSj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7761/Reviewer_eQSj"
            ],
            "content": {
                "summary": {
                    "value": "This paper evaluates the logical reasoning depth of five LLMs (GPT-4, GPT-3.5, Claude-2, Llama-2, and Palm-2) for graph traversal problems. It presents 10 complex graph problems and assesses the models' performance. Results show that most LLMs lack strong reasoning abilities, with performance declining as graph complexity increases. The use of more k-shot prompts also negatively impacts reasoning."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper evaluates the complex reasoning ability of LLMs from the perspective of graph reasoning, which is rational."
                },
                "weaknesses": {
                    "value": "1. This empirical paper focuses on evaluating the capabilities of LLMs. However, the analyzed properties of LLMs are unsurprising and do not provide new insights to the research community.\n2. The paper suggests a negative impact on reasoning abilities with an increase in the number of k-shot examples. However, the authors only tested experiments with 1-2-3 shots, and more experiments are needed to support this conclusion and provide explanations.\n3. The summary section of the paper remains incomplete and the paper requires further improvement before publication."
                },
                "questions": {
                    "value": "Please refer to weakness point 2."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7761/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698836521824,
            "cdate": 1698836521824,
            "tmdate": 1699636948131,
            "mdate": 1699636948131,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "49jo8KFL5S",
            "forum": "S9YfP4rsfX",
            "replyto": "S9YfP4rsfX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7761/Reviewer_aBCN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7761/Reviewer_aBCN"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a method that uses graphs to evaluate the reasoning ability of large language model. The authors evaluate 5 different LLMs and get some observations."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "* The topic of reasoning ability of LLMs is interesting."
                },
                "weaknesses": {
                    "value": "* The bad written and missed material. The summary of the article is not written. In section 2.2, the authors mentioned that the format of prompts is included in the Appendix, but they fail to submit any supplemental material.\n* Limited novelty. There are several works and benchmarks which can be used to evaluate the reasoning ability and other ability of LLMs, such as PIQA[1], ARC[2] and Plan[3]. And the authors should have a section to introduce these related works and analysis the differences between the proposed method and these existing papers.\n* There are some strange definitions which counter to the common ones. In figure1. the example graph in 1.3. and 1.4. represent some tree-based traversal problem but tree is exactly a kind of acyclic graph.\n* The difference of proposed problem1 and problem2 is not obvious. Because both the graph of problem1 and problem2, the representation in a computer is similar, which consists of a adjacency matrix and an edge weights list.\n* The section 3.4 mentioned that it is clear that few-shot prompts does not contribute towards logical providing any reasoning context. My main concern is that there seems to be no clear trend proving this from the experimental results. For example, in table 1, there are 36% of results that 3-shot get the best score and 50% regardless the special cases such as out of the context window. \n\n\n\n[1] Bisk Y, Zellers R, Gao J, et al. Piqa: Reasoning about physical commonsense in natural language[C]//Proceedings of the AAAI conference on artificial intelligence. 2020, 34(05): 7432-7439.\n\n[2] Clark P, Cowhey I, Etzioni O, et al. Think you have solved question answering? try arc, the ai2 reasoning challenge[J]. arXiv preprint arXiv:1803.05457, 2018.\n\n[3] Valmeekam K, Olmo A, Sreedharan S, et al. Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change)[J]. arXiv preprint arXiv:2206.10498, 2022."
                },
                "questions": {
                    "value": "see weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7761/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698839231208,
            "cdate": 1698839231208,
            "tmdate": 1699636947999,
            "mdate": 1699636947999,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "NQKAqZ8VL1",
            "forum": "S9YfP4rsfX",
            "replyto": "S9YfP4rsfX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7761/Reviewer_HHfy"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7761/Reviewer_HHfy"
            ],
            "content": {
                "summary": {
                    "value": "The authors examine the sophistication of path discovery capabilities for 5 different LLMs (GPT-4, GPT-3.5, Claude-2, Llama-2 and Palm-2), a computational foundation of graph reasoning. Ten (10) distinct problems in graph traversal are examined using synthetically generated graphs; each problem represents an increasing levels of complexity in graph reasoning."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Originality: A competed and well documented experimental study of this type would be a contribution to the community understanding of the ability of large language models.\n\nQuality: the study design seems sound, although experiments are not documented sufficiently for evaluation.  Some experiments seem incomplete.  The paper is incomplete, with some sections missing.\n\nClarity: The authors describe their intent clearly.\n\nSignificance: This experiment would provide an interesting comparison point on LLM as graph-solver."
                },
                "weaknesses": {
                    "value": "The work is incomplete.\n\nThe literature review may be incomplete, depending on the final conclusions of the paper.\n\nThe Quality, Clairty, and Significance of a final paper are hard to judge in its current state."
                },
                "questions": {
                    "value": "1. Do these experiments uncover interesting behavior of transformers in general, or just the models studied?\n\nI can envision a completed version of this paper that would result in a higher rating, but in its current incomplete form I'm going to recommend rejection."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7761/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7761/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7761/Reviewer_HHfy"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7761/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699137561267,
            "cdate": 1699137561267,
            "tmdate": 1699636947890,
            "mdate": 1699636947890,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]