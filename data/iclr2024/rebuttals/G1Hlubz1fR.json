[
    {
        "title": "Customizable Combination of Parameter-Efficient Modules for Multi-Task Learning"
    },
    {
        "review": {
            "id": "yjllqJrLf4",
            "forum": "G1Hlubz1fR",
            "replyto": "G1Hlubz1fR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7467/Reviewer_ZWwD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7467/Reviewer_ZWwD"
            ],
            "content": {
                "summary": {
                    "value": "The paper mixes different ideas from the multi-task learning and parameter-efficient mixture of experts literature: Methods such as `MoLora` introduced the idea of using low-rank LoRA modules as \"experts\". Methods such as `Poly` or `MHR` show that a new task can be learned as a combination of adapters modules (~ mixture of experts) where the combination weights are task-specific.\n\nThis paper additional proposes to explicitly capture the fact that each task can have shared knowledge (shared across all tasks) as well as task-specific knowledge at the adapters level. In this setting, a new task is now learned as a soft combination of **(i)** $A$ LoRa modules shared across all tasks and **(ii)** $B$ task-specific LoRA modules ($B$ separate modules for each task). In this case, all combination weights are task-specific, and when $B = 0$, we recover previous approaches such as `Poly`. \n\nIn the proposed framework, every adapter is a LoRA module and the combination weights are binary, i.e. each expert can be activated or not. During training, the binary decisions are approximated with Gumbel-sigmoids to allow for backpropagation.\n\nThe proposed approach is evaluated on `T5-Large` and `GLM-10B` as backbone, on the SuperGlue and Super Natural Instructions datasets, and compared to a set of recent baselines (LoRa, MoE-LoRA, Poly and MHR)"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- **interesting research direction:** I think the overall goal of the paper is clear and interesting. Parameter-efficient Mixture-of-experts with LoRA modules is a recent and interesting research direction, and generalizing this framework to multi-task/domain learning as was done for other \"adapters\" type of work seems very natural. Similarly, the idea of separating task-specific and shared knowledge has shown some success in multi-task learning literature, and makes a lot of sense in that setup.\n\n- **Diversity of the experimental setup:** The experiments consider two backbones, as well as two multi-task benchmarks with quite different number of tasks. The proposed method is also compared to several recent baselines\n\n- **Experimental improvement**: While the improvement in experiments is not always consistent, it does show significant gains in some benchmarks, in particular with the decoder-only `GLM` backbone."
                },
                "weaknesses": {
                    "value": "- **Explicit vs Implicit separation of task-specific and shared modules**: To my understanding,  the proposed method can be seen as subcase of some of the baselines mentioned : If the number of adapters in `Poly` is set to $A + BT$, then in theory the model could learn to make certain modules task-specific by setting $w_i^t$ to 1 for only certain pairs of $(i, t)$. In contrast, the proposed method makes this structure explicit by defining task-specific modules; However, this still requires additional $BT$ task-specific adapter modules, hence an increased number of parameters. From the experiments, it is not clear to me if the number of parameters/modules used by the baselines and the proposed method are comparable.\n\n- **Experimental analysis**: In general, I find the proposed idea interesting, but I lack some experimental insights to better understand the proposed method. For instance, some points I found unclear are the following:\n  -  1) For instance, the number of task-specific modules $B$ for each task seems to be an important parameter, but I did not see a lot of discussion/ablation about it; It seems that $B$ is set to 1 throughout the paper\n  - 2) Similarly, the proposed method can use $A + B$ modules per task, while baselines only consider $A$ task-shared modules: It is not clear to me if the setup is fair to the baselines. Considering other  configurations would be interesting.\n  - 3) From the results in **Table 2**, it seems that the performance improvement is not consistent: For instance with the encoder-decoder `T5` model, improvement mainly comes from the `WiC` task, which could mean this task is more likely to interfere with others. However for the decoder-only `GLM`, we see that adding a task-specific module yield significant improvement across all tasks. It is not clear to me why that is the case: Since the tasks are the same in both case, it does not seem to be directly related to the multi-task setup; could it be related to the number of LoRA modules with respect to the architecture (*see point 2*) ?\n\n**Note post-rebuttal:** I still have some reserves about the method's robustness and sensitivity to the task specific/shared setup ratio, but in light of the rebuttal addressing my main concerns and added ablation experiments, I'll raise my score from 5 to 6"
                },
                "questions": {
                    "value": "- **Minor suggestion on writing:** \n  * I found the introduction hard to read as it mixes introduction with some related work towards the end, and introduces several concepts without really contextualizing them (e.g. in two paragraphs, the text jumps from MoLora $\\rightarrow$ Poly $\\rightarrow$ MHR $\\rightarrow$ CGC and PLE).\n  * Using $A$ and $B$ in Equation 5 is a bit confusing as these were introduced earlier as the number of shared and task-specific modules"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7467/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7467/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7467/Reviewer_ZWwD"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7467/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698749432490,
            "cdate": 1698749432490,
            "tmdate": 1700607208950,
            "mdate": 1700607208950,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oKJ6KW5OWt",
                "forum": "G1Hlubz1fR",
                "replyto": "yjllqJrLf4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "content": {
                    "title": {
                        "value": "W1/W2.1/W2.2\uff1aExplicit vs Implicit separation of task-specific and shared modules"
                    },
                    "comment": {
                        "value": "Thank you for your interest in our work and for pointing out areas where further experimental insights are needed. We appreciate your observations and would like to address them as follows:\n\n1. **Number of Task-Specific Modules (B)**\n\nOur initial choice of B=1 for task-specific modules was made to streamline the model's configuration and facilitate analysis. However, in response to your suggestion, we revisited this aspect in Ablation Study 1. We explored and demonstrated the performance variations with different allocations of task-specific modules, providing insights into the impact of varying B on our model's effectiveness.\n\n2. **Fairness in Experimental Setup**\n\nWe understand the importance of ensuring a fair comparison with baselines, particularly regarding our use of A+B modules versus the A task-shared modules in baseline methods. Initially, our goal was to highlight the significance of adding task-specific modules. Furthermore, we presented an analysis of the number of trainable parameters in Figure 3 to elucidate this aspect. To foster a more equitable comparison, as mentioned in our general comment, we modified our experimental setup to (A\u2212B + B) modules. This adjustment aligns the number of modules with baseline configurations, ensuring a more appropriate and rigorous comparison."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700127178807,
                "cdate": 1700127178807,
                "tmdate": 1700127430493,
                "mdate": 1700127430493,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "X07PWgukEi",
                "forum": "G1Hlubz1fR",
                "replyto": "yjllqJrLf4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Q: Minor suggestion on writing"
                    },
                    "comment": {
                        "value": "**Clarification on Concept Introduction:**\n\nYour observation about the introduction section is well-received. Our intention was to draw parallels between existing PEFT methods (MoLoRA, Poly, MHR) and MoE concepts (MoE, MMoE, CGC, PLE) to provide a quick overview of how our method (CPoly) aligns with and differs from these approaches. We will ensure that each concept is introduced more gradually and is clearly contextualized.\n\n**Clarification on Equation Notation:**\n\nRegarding your point about the notation in Equation 5, we acknowledge the confusion caused by using $A$ and $B$, and have changed it to $W_{down}$ and $W_{up}$ for clarification."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700127250304,
                "cdate": 1700127250304,
                "tmdate": 1700127250304,
                "mdate": 1700127250304,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "duJm4X5Q8A",
                "forum": "G1Hlubz1fR",
                "replyto": "yjllqJrLf4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "content": {
                    "title": {
                        "value": "W2.3: From the results in Table 2, it seems that the performance improvement is not consistent"
                    },
                    "comment": {
                        "value": "Thank you for your professional insight. We have also noticed this point. Considering the significant difference in parameter size between FLAN-T5-Large and GLM-10B, we believe that when the parameter size is large, the ability to learn representations is stronger, which can support better fitting of more tasks. \n\nHowever, the parameter size of FLAN-T5-Large is insufficient to support effective optimization of all tasks. In the Appendix, we have added comparative experiments on different PEFT methods on FLAN-T5-XL on SuperGLUE. \n\nThe experimental results have confirmed that after expanding the parameter size, the model's ability to fit multiple tasks becomes stronger, and our method effectively reduces negative transfer phenomena, achieving robust improvements in average and subtasks.\n\nThe appendix table is shown as: \n|             | **avg** | **boolq** | **cb** | **copa** | **multirc** | **rte** | **wic** | **wsc.fixed** |\n|-------------|---------|-----------|--------|----------|-------------|---------|---------|---------------|\n| lora        | 82.10   | 89.57     | 78.57  | 96.00    | 79.62       | 87.36   | 67.65   | 75.96         |\n| moe-lora    | 82.97   | 89.32     | 78.57  | 96.00    | 83.76       | 89.16   | 68.02   | 75.96         |\n| poly-lora   | 84.29   | 89.51     | 80.35  | 96.00    | 84.63       | 90.97   | 68.80   | 79.80         |\n| mhr-lora    | 84.39   | 89.51     | 80.35  | 97.00    | 84.61       | 90.97   | 68.49   | 79.80         |\n| cpoly-lora  | **84.94**   | 89.55     | **82.14**  | **97.00**    | **84.96**       | **91.69**   | 68.50   | **80.76**         |"
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700328434511,
                "cdate": 1700328434511,
                "tmdate": 1700328502987,
                "mdate": 1700328502987,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wcoswMKVP4",
                "forum": "G1Hlubz1fR",
                "replyto": "oKJ6KW5OWt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Reviewer_ZWwD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Reviewer_ZWwD"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response"
                    },
                    "comment": {
                        "value": "Dear authors, thanks for your responses!\n- The new tables solve my concern about fairness wrt to baselines and the $A$ and $B$ hyperparameters\n- The added results varying $(A, B)$ configurations are also very interesting though they do raise the important question of tuning the ratio between these two parameters as it clearly has an impact on performance\n\nI still have some reserves about the method's robustness and sensitivity to the task specific/shared setup ratio, but in light of the rebuttal addressing my main concerns and added ablation experiments, I'll raise my score to 6"
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700607168861,
                "cdate": 1700607168861,
                "tmdate": 1700607168861,
                "mdate": 1700607168861,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qcB1dtM0v8",
            "forum": "G1Hlubz1fR",
            "replyto": "G1Hlubz1fR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7467/Reviewer_WuXZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7467/Reviewer_WuXZ"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a new multi-task learning architecture based on LoRA finetuning framework. They propose the task-common skill sets and task-specific skill sets. Also they learn the task-specific combination weights of task common skill sets using Gumbel-Sigmoid. In the experiment, they adopt two different architectures (encoder-decoder -- T5 and decoder-only -- GLM) and show their performance on several multi-task benchmark in NLP."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper clearly states the difference between their model architecture and previous baseline models.\n2. With GLM model, their proposed method outperforms the baseline models for a significant gap.\n3. They compare to other baseline models in a fair way.\n4. The paper is well-written and easy to follow."
                },
                "weaknesses": {
                    "value": "1. The method does not achieve significant improvement with T5 architecture.  (But I am not expert in NLP tasks and I am open to other reviewers' opinions regarding the performance.)\n2. The model design seems incremental to the previous methods Poly and MHR. \n3. It is unclear about the optimization loss function and the main paper does not discuss this."
                },
                "questions": {
                    "value": "1. Since you have used Gumbel Sigmoid to optimize the w_i, what is the distribution of all w_i's learnt in the model? Is there any specific loss to force w_i to be close to 0 or 1? What is the performance variance if you need sample the w_i based on Bernouli distributions in the final evaluation?\n\n2. In the experiment results, it is clear that the method with GLM-10B outperforms baselines a lot and the method with T5 stands close to the baselines. In the paper, the authors claim the difference is due to the different model architecture. However, GLM-10B and T5_large also differ a lot in the model capacity. How do you know the difference of performance compared to the baselines is due to the architecture instead of model capacity?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7467/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7467/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7467/Reviewer_WuXZ"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7467/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698892870179,
            "cdate": 1698892870179,
            "tmdate": 1700675873248,
            "mdate": 1700675873248,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2K7CtlHOd1",
                "forum": "G1Hlubz1fR",
                "replyto": "qcB1dtM0v8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "content": {
                    "title": {
                        "value": "W1/Q2: \u2012 The method does not achieve significant improvement with T5 architecture. \u2012 How do you know the difference of performance compared to the baselines is due to the architecture instead of model capacity?"
                    },
                    "comment": {
                        "value": "Thank you for your observations regarding the performance improvements with the T5 architecture and the distinction between the performance with GLM-10B and T5 models.\n\nTo discern the impact of architecture versus model capacity, we conducted **Ablation Study 3**, which included a range of T5 and FLAN-T5 models with varying capacities (Large/0.78B , XL/3B, XXL/11B) - the XXL version is comparable with GLM-10B. The results demonstrated that our method consistently outperforms other methods across these scales. For instance, with T5-XXL, our method achieved significant gains in performance, suggesting that while model capacity plays a role, the architecture of our method effectively utilizes this additional capacity. On the other hand, the performance saturation observed, especially with FLAN-T5, might partly stem from an overlap between its training dataset and the SuperNI tasks."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700126996529,
                "cdate": 1700126996529,
                "tmdate": 1700127124566,
                "mdate": 1700127124566,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Ke0hsdz7Wl",
                "forum": "G1Hlubz1fR",
                "replyto": "qcB1dtM0v8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "content": {
                    "title": {
                        "value": "W2: The model design seems incremental to the previous methods Poly and MHR."
                    },
                    "comment": {
                        "value": "Thank you for your comment regarding the comparison of our model design with previous methods like Poly and MHR. While our approach builds upon the foundations laid by these methods, it also introduces significant advancements that distinguish it from its predecessors.\n\nA key innovation in our method is the strategic integration of task-specific skills alongside task-common skills. This dual-skill framework is not just an extension but a significant departure from methods like Poly and MHR, which predominantly focus on shared skills across tasks. Our approach enables a more nuanced and targeted application of skills to specific tasks, enhancing overall performance and adaptability.  \n\nOur ablation studies demonstrate the efficacy of this approach. For example, **Ablation Study 1** showed notable improvements in performance with the optimal balance of task-common and task-specific skills, highlighting the effectiveness of our model's unique configuration.\n\nIn summary, while our model design is inspired by earlier methods, it offers a more flexible and scalable solution for complex multi-task environments."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700127033129,
                "cdate": 1700127033129,
                "tmdate": 1700127033129,
                "mdate": 1700127033129,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vUfN7TNjIu",
                "forum": "G1Hlubz1fR",
                "replyto": "qcB1dtM0v8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "content": {
                    "title": {
                        "value": "W3: It is unclear about the optimization loss function and the main paper does not discuss this."
                    },
                    "comment": {
                        "value": "Thank you for bringing to our attention the lack of the optimization loss function in our manuscript. We apologize for this oversight. In our method, we have employed the cross-entropy loss function, a standard and widely used choice for language models. The language model predicts next tokens autoregressively. It's essentially a multi classification problem, where the classes are the choices of tokens in the sequence."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700127060844,
                "cdate": 1700127060844,
                "tmdate": 1700127060844,
                "mdate": 1700127060844,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "z5dpMGGd8a",
                "forum": "G1Hlubz1fR",
                "replyto": "qcB1dtM0v8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Q1: Since you have used Gumbel Sigmoid to optimize the w_i, what is the distribution of all w_i's learnt in the model? Is there any specific loss to force w_i to be close to 0 or 1? What is the performance variance if you need sample the w_i based on Bernouli distributions in the final evaluation?"
                    },
                    "comment": {
                        "value": "During training, we utilize the Gumbel Sigmoid, or Relaxed Bernoulli in binary cases, to smooth the logits derived from w_i. This method enables differentiable sampling from a Bernoulli distribution, crucial for gradient-based optimization in neural networks. In the evaluation phase, we apply a Sigmoid function for smoothing. It's noteworthy that we didn't implement a specific loss function to directly influence this sampling phase. Recognizing the potential impact of such a loss function, we see this as a valuable direction for future research."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700127080829,
                "cdate": 1700127080829,
                "tmdate": 1700127080829,
                "mdate": 1700127080829,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "MuOsFWZo0k",
            "forum": "G1Hlubz1fR",
            "replyto": "G1Hlubz1fR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7467/Reviewer_soi2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7467/Reviewer_soi2"
            ],
            "content": {
                "summary": {
                    "value": "The paper tackles the task of parameter efficient fine-tuning via Low-Rank Adapter (LoRA) which parametrized the weight updates as low-rank composition to significantly reduce the number of learnable parameters and computation. \nThe work proposes a novel approach, called Customized Polytropon, which extends LoRA to Multi-Task Learning setup by learning multiple LoRA adapter corresponding to different tasks.\nThe key insight is to decompose the learnable parameter into Task-Common adapters, which is shared among all tasks, and Task-Specific adapters specifically trained for different tasks.\nGiven this set of adapters, the proposed framework would learn to combine them for different task, thus enable knowledge transfer among tasks while efficiently learning these adapters.\nThe paper conducts experiments on SuperCLUE and Super Natural Instruction datasets as well as on T5-Large and GLM-10B models to show its effectiveness."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "+ The paper is self-contained which makes it accessible to a wide range of reader. Moreover, the paper is also easy to follow.\n+ The proposed method of decomposing learnable parameter into a task-common and task-specific portions is sensible as well as easy to develop in practical setting.\n+ The problem of parameter efficient finetuning is impactful which helps to democratize LLM technology on consumer device."
                },
                "weaknesses": {
                    "value": "+ As the adapter in LORA are low-rank linear projection of parameters in attention modules, a combination of task-common and task-specific LORA adapters seems to be equivalent to just Mixture of LORA as addition of linear transformations is still a linear transformation (rows 2 and 3). Thus, it is unclear why decomposing learnable parameters would improve performance.\n \n+ The experimental section misses some studies to show the effective of hyper-parameters in the model. For examples, what is the how number of adapters in task-common and task-specific modules effect the performances? What is the impact of rank or the number of tasks toward final performance? These experiments would offer better insight into how robust the proposed method is under different setting.\n\n+ The performance seems to saturate when being applied to strong base model such as T5-Large. It seems to suggest that the effect of task-common components vanish when the base model can generalize well toward different downstream tasks. This could be an interesting phenomena can be study using stronger base model such as llama and llama2."
                },
                "questions": {
                    "value": "+ Could the authors clarify on how they combine different adapters? This would help with understanding as well as reproducibility.\n+ Experiments on the effects of the number of adapters/ranks/tasks could provide better insight on the robustness and limitations of the proposed methods\n+ Stronger base model can be used to stress-test the generalizability of the proposed framework."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7467/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698962120275,
            "cdate": 1698962120275,
            "tmdate": 1699636899373,
            "mdate": 1699636899373,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6f45UChEI6",
                "forum": "G1Hlubz1fR",
                "replyto": "MuOsFWZo0k",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "content": {
                    "title": {
                        "value": "W1: As the adapter in LORA are low-rank linear projection of parameters in attention modules, a combination of task-common and task-specific LORA adapters seems to be equivalent to just Mixture of LORA as addition of linear transformations is still a linear transformation (rows 2 and 3). Thus, it is unclear why decomposing learnable parameters would improve performance."
                    },
                    "comment": {
                        "value": "Thank you for your insightful observation about the linear nature of these transformations. However, the key advantage of our approach lies in the strategic weighting and targeted application of these adapters.\n\n1. **Task-Specific Tailoring**: The introduction of task-specific adapters enables our model to customize its responses to the unique requirements of individual tasks, a level of specificity and nuance that general, task-agnostic adapters may not achieve. This allows the model to effectively address task-specific features and variations.\n\n2. **Dynamic Updating of Components**: The task-common adapters are updated based on the entire multi-task dataset, providing a broad base of learning, while each task-specific adapter is fine-tuned using only data from its respective individual task. This dual approach ensures both generalization and specialization in the model's learning process.\n\n3. **Evidence from Experiments**: Our experimental results demonstrate that this method of decomposing and dynamically recombining parameters leads to measurable performance improvements.\n\nIn conclusion, our model's performance gains stem from the thoughtful combination of task-common and task-specific adapters. This approach not only leverages the strengths of each adapter type but also ensures a more nuanced and effective adaptation to a diverse array of tasks."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700126663543,
                "cdate": 1700126663543,
                "tmdate": 1700126663543,
                "mdate": 1700126663543,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HvOjNETTh5",
                "forum": "G1Hlubz1fR",
                "replyto": "MuOsFWZo0k",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Q1: Could the authors clarify on how they combine different adapters? This would help with understanding as well as reproducibility."
                    },
                    "comment": {
                        "value": "To clarify, we employ linear combinations for combining the output of different adapters in our model, as detailed in equation (1) of our manuscript. To further aid in understanding and reproducibility, we are planning to open-source our code."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700126891341,
                "cdate": 1700126891341,
                "tmdate": 1700126891341,
                "mdate": 1700126891341,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EQfZnbtJDu",
                "forum": "G1Hlubz1fR",
                "replyto": "MuOsFWZo0k",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "content": {
                    "title": {
                        "value": "W2/Q2: The experimental section misses some studies to show the effective of hyper-parameters in the model; Experiments on the effects of the number of adapters/ranks/tasks could provide better insight on the robustness and limitations of the proposed methods"
                    },
                    "comment": {
                        "value": "Thank you for pointing out the necessity of further experimental insights into the effectiveness of various hyper-parameters in our model. We agree that understanding the impact of the number of adapters, tasks, and rank is crucial for assessing the robustness and limitations of our approach. In response to your concerns, we refer to **Ablation Studies 1 and 2**, which delve into these aspects:\n\n**Ablation Study 1**: This study explored how the number of adapters in task-common and task-specific modules affects performance. For instance, in our experiments with all 3 models, we observed a notable performance increase when using 3 common and 1 task-specific skill compared to 4 common skills. However, further increasing the number of task-specific skills showed diminishing returns.\n\n**Ablation Study 2**: Our method consistently outperformed others across these varying task numbers, demonstrating robust scalability.\n\nRegarding the impact of rank on our model's performance, we based our experimental setup on insights from the [original LoRA paper](https://arxiv.org/abs/2106.09685). In selecting LoRA as our adapter unit, we were guided by the findings in their study, which indicated that variations in rank might not have a significant impact on model performance for each individual LoRA."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700127092040,
                "cdate": 1700127092040,
                "tmdate": 1700127092040,
                "mdate": 1700127092040,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7ukbeqSlr5",
                "forum": "G1Hlubz1fR",
                "replyto": "MuOsFWZo0k",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "content": {
                    "title": {
                        "value": "W3/Q3:The performance seems to saturate when being applied to strong base model such as T5-Large. It seems to suggest that the effect of task-common components vanish when the base model can generalize well toward different downstream tasks; \u25cf Stronger base model can be used to stress-test the generalizability of the proposed framework."
                    },
                    "comment": {
                        "value": "As mentioned in our general comment, the base model used in our original manuscript was FLAN-T5-Large. The performance saturation noted may be partly due to the overlap between FLAN-T5's training dataset and the tasks in the SuperNI dataset. To mitigate this and improve comparability, we expanded our ablation studies, particularly **Ablation Study 3**, to encompass a broader range of models including T5-Large (0.78B), T5-XL (3B), and stronger one T5-XXL (11B), and their FLAN-T5 counterparts. These studies demonstrate that as the model scale increases, our method continues to outperform others, indicating its effectiveness across different model capacities.\n\nRegarding the suggestion to use models like Llama and Llama2 for stress-testing our framework, we find it intriguing. Our choice to focus on T5 and GLM was to enable direct comparison with existing results in the manuscript. Exploring our approach with advanced model is an important direction for our future research to further understand and enhance our methodology."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700127384885,
                "cdate": 1700127384885,
                "tmdate": 1700127384885,
                "mdate": 1700127384885,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "3NEMVvJpL0",
            "forum": "G1Hlubz1fR",
            "replyto": "G1Hlubz1fR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7467/Reviewer_yvMZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7467/Reviewer_yvMZ"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an approach called Customized Polytropon (C-Poly) for multi-task learning using parameter-efficient modules. The key idea is to explicitly separate task-common skills that can be shared across tasks, and task-specific skills that are unique to each task.  Note that this augments the previously published Poly method (by introducing task-specific adapters, combining subsets of shared and specific tasks, and can allow better interpretation by the parameters learned for selection and weighting).\n\nThe model consists of components related to task-common skills (shared low-rank across tasks), and low-rank adapters for each task.  Low-rank adapters (E.g. LoRA) are used to improve param efficienty also.  This approach appears to mitigate negative transfer effects, and improve learning over compared methods.  \n\n\n//Having read the responses: I think its a nice idea, the results are good, but some more analysis / polishing of the paper could be useful before this paper is published (See also response to comments).  To be frank I`m still borderline about this.  I will however increase my score to reflect the authors effort in responses and updates."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- this paper presents an intuitive approach to combine shared and specialized skills\n\n- results are good in comparison to previous methods\n\n- sample efficiency is improved; the approach of explicitly separating task-common and task-specific skills to mitigate negative transfer\n\n- offers some more interpretability due to selecting particular skills"
                },
                "weaknesses": {
                    "value": "The method introduces additional hyperparameters like number of common/task-specific skills which may require tuning\n\nIt is not clearly analyzed if certain tasks benefit more from common or specialized skills\n\nThe interpretability via learned task hierarchies is not explored much in experiments\n\nResults are comparable largely to previous work\n\nThis paper is an extension of a previous work, with some (nice) but perhaps small increments."
                },
                "questions": {
                    "value": "How is the number of common and task-specific skills determined? Is there a systematic way to set these hyperparameters?\n\nHow does performance scale with increasing number of tasks?\n\nHow are skills initialized?  does this affect selection?\n\nCan you provide ablation studies controlling for common vs task-specific skills? \n\nMore in-depth discussion / results on interpretability\n\nIf new tasks appear after training, can the model adapt?\n\nResults are comparable largely to previous work"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7467/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7467/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7467/Reviewer_yvMZ"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7467/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699002994401,
            "cdate": 1699002994401,
            "tmdate": 1700658965582,
            "mdate": 1700658965582,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0mnnDjB1M8",
                "forum": "G1Hlubz1fR",
                "replyto": "3NEMVvJpL0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "content": {
                    "title": {
                        "value": "W1+W2, Q1+Q4: The method introduces additional hyperparameters like number of common/task-specific skills which may require tuning. It is not clearly analyzed if certain tasks benefit more from common or specialized skills. How is the number of common and task-specific skills determined? Is there a systematic way to set these hyperparameters? Can you provide ablation studies controlling for common vs task-specific skills?"
                    },
                    "comment": {
                        "value": "Thank you for highlighting the concerns regarding the number of task-common and task-specific skills. Your query is directly addressed in our **Ablation Study 1**, which provides empirical evidence for the effective allocation of these skills.\n\nHeuristically, we proposed that the total number of skills should be significantly less than the number of tasks to maintain efficiency. For the allocation of two sets of skills, our Ablation Study 1 revealled an optimal balance between common and task-specific skills.\n\nFor instance, in the T5-Large model, shifting from 4 common + 0 task-specific skills to a configuration with 3 common and 1 task-specific skill improved the ROUGE-L score from 42.05 to 48.50. However, increasing task-specific skills further (2 common and 2 task-specific) actually resulted in a lower ROUGE-L score of 47.94."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700126235681,
                "cdate": 1700126235681,
                "tmdate": 1700126896596,
                "mdate": 1700126896596,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RgRMCOezlV",
                "forum": "G1Hlubz1fR",
                "replyto": "3NEMVvJpL0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Q2: How does performance scale with increasing number of tasks?"
                    },
                    "comment": {
                        "value": "In response to your question on scalability, **Ablation Study 2** demonstrates that our model robustly scales with an increasing number of tasks. We observed consistent superior performance across different task volumes - from 10 to 100 tasks - irrespective of the base model used. This underscores our method's adaptability and effectiveness in diverse multi-task learning environments, maintaining high performance even as task complexity increases."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700126284830,
                "cdate": 1700126284830,
                "tmdate": 1700126284830,
                "mdate": 1700126284830,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aDBR8OhcCH",
                "forum": "G1Hlubz1fR",
                "replyto": "3NEMVvJpL0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Q3: How are skills initialized? does this affect selection?"
                    },
                    "comment": {
                        "value": "Thank you for your question regarding the initialization of skills in our model. The initialization process for our model aligns with the standard [LoRA](https://arxiv.org/abs/2106.09685):\n\n- Matrix A is initialized using the default method for nn.Linear, specifically `nn.init.kaiming_uniform_`.\n\n- Matrix B is initialized to zero using `nn.init.zeros_`.\n\nWe recognize that the impact of different initialization strategies on model performance is an important area. However, our core contribution is independent of this, if necessary, we can provide additional information."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700126357302,
                "cdate": 1700126357302,
                "tmdate": 1700126357302,
                "mdate": 1700126357302,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cHAHxsxyOk",
                "forum": "G1Hlubz1fR",
                "replyto": "3NEMVvJpL0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Q6: If new tasks appear after training, can the model adapt?"
                    },
                    "comment": {
                        "value": "Thank you for raising an important question about the adaptability of our model to new tasks introduced after training. You're correct in noting that transfer learning for new tasks is a significant and distinct area of study, differing considerably from multi-task learning in its approach and challenges. While your question is indeed relevant, it falls outside the current scope of our discussion, which is focused on multi-task learning. We recognize the importance of this aspect and agree that it merits further exploration in future research."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700126541872,
                "cdate": 1700126541872,
                "tmdate": 1700126541872,
                "mdate": 1700126541872,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KPB6KqARCD",
                "forum": "G1Hlubz1fR",
                "replyto": "3NEMVvJpL0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Authors"
                ],
                "content": {
                    "title": {
                        "value": "W3/Q5: The interpretability via learned task hierarchies is not explored much in experiments. More in-depth discussion / results on interpretability"
                    },
                    "comment": {
                        "value": "We appreciate your professional insights on the experimental discussion. For the interpretability aspect of the experiment, we supplemented the router visualization comparison of GLM-10B on NI-10, NI-50, and NI-100 in **Appendix A.5**, and the results showed that the allocation vectors we learned had significant discrimination. \n\nMeanwhile, in **Appendix A.5**, we also added a dendrogram for obtaining hierarchy information based on router allocation weights on NI-100 and compared it with the original poly. The results show that after adding custom skills, the learned allocation vectors can make the differentiation of multiple tasks more reasonable, the number of tasks in each implicit category is more balanced, and more pairwise correlations are learned. Improved the data learning efficiency and generation ability of specific tasks."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700415904956,
                "cdate": 1700415904956,
                "tmdate": 1700415904956,
                "mdate": 1700415904956,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6Z3z7CVyHF",
                "forum": "G1Hlubz1fR",
                "replyto": "KPB6KqARCD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7467/Reviewer_yvMZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7467/Reviewer_yvMZ"
                ],
                "content": {
                    "title": {
                        "value": "thanks to the authors for the responses"
                    },
                    "comment": {
                        "value": "thanks to the authors for the responses - I agree on most points, and indeed the results look quite promising and good - although at times they can be minimal\n\nI do still think that some more explanations or intuitions in the main paper on the points that were mentioned above could be helpful, e.g. to ensure that overfitting by selecting too-specific tasks etc. is avoided and generalization is not hindered.  ,\n\nFor the figures added (e.g., 7,8,9) - I m not sure that they are helpful without an explanation (E.g, fig 7 shows basically 100 column matrix which is difficult to decipher without some explanation provided by the authors) \n\nthanks again for the detailed responses!"
                    }
                },
                "number": 27,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7467/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700658741381,
                "cdate": 1700658741381,
                "tmdate": 1700658741381,
                "mdate": 1700658741381,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]