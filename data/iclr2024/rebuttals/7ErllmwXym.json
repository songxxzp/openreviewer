[
    {
        "title": "Interpreting and improving diffusion models using the Euclidean distance function"
    },
    {
        "review": {
            "id": "DQcsziefBA",
            "forum": "7ErllmwXym",
            "replyto": "7ErllmwXym",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4037/Reviewer_LpGF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4037/Reviewer_LpGF"
            ],
            "content": {
                "summary": {
                    "value": "This paper is focused on presenting an interpretation of diffusion models, in which each iteration interpreted as a non-linear projection onto the data manifold. They define a Euclidian distance function from noisy image to the manifold, and interpret the denoising step as the gradient descent on this distance function. On the empirical side, the paper proposes a modified update line based on the theory, with the goal of minimizing and correcting the score prediction error. When number of iterations are limited to small numbers, this method achieved better performance in FID compared to other methods, on CIFAR10 and celebA."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The writing is clear and the math is reasonably easy to follow. \nThe derivations are generally sound and well written."
                },
                "weaknesses": {
                    "value": "The main weakness of this work is that theorem 3.1 rests on a strong assumption that is violated in the case of image manifolds. Up to this theorem, the math is not novel and is borrowed from other sources. The contribution of this work is in Theorem 3.1, where the existing math about non-linear projection is used to interpret backward diffusion/denoising. This theorem is the foundation for the rest of the paper, and the derivations about the bounds sit on top of this theorem. The problem is that the theorem rests on a strong assumption on the reach of the image manifold: $reach(K) \\geq \\sigma \\sqrt{n}$ which does not necessarily hold. This assumes the curvature of the manifold is small compared to $\\sigma$. This greatly simplifies the geometry of the assumed manifold but the problem is such manifold is too simplistic to approximate *image* manifold. If images lie on manifold, those manifolds must be complex with high curvatures.  \n\nTo make it clear as to why image manifolds must contain high curvature (or small reach) it is enough to run a simple mental experiment. Consider an image, which represents a single point on the manifold. All the invariances of that image, such as local translations, also exist within this manifold. The geometry of local translations is well understood in the Fourier domain. When an image is translated, its Fourier amplitude remains constant, while its Fourier phases vary. Consequently, translated versions of an image lie on circles, with the circle's radius equivalent to the Fourier amplitude. It's a widely known empirical observation that the power spectrum of images adheres to a $1/f$ law, where $f$ represents the frequency, stating that higher frequencies exhibit smaller amplitudes. Therefore, the circles on the manifold, due to the translation invariance of image details (higher frequencies), have small radii. The $1/f$ phenomenon is an empirical but firmly established characteristic of images.\n\nThe reach(K) of image manifold is not a constant and depends on the image (i.e. the curvature varies across the manifold). But as long as the image is not blank and contains details, the $reach(K)$ will be small. For a typical image, the reach can be as small as the quantization precision of the images in the dataset, due to the $1/f$ property: the highest frequencies create small circles around a given image.\n\nThe analysis in the paper does not hold unless for very small sigma (in the vicinity of the manifold), where we can assume the sigma is smaller than the radius of the curvature. But the paper claims this analysis can be used for denoising in diffusion models which always start with very large noise, and the noise stays large throughout the intermediate steps until towards the very end of the trajectory.\n\nMoreover, the claim that the gradient doesn't change does not hold if the assumption on reach is violated. In other words, when the curvature is larger than sigma, the gradient does change direction at each step (up to a point where sigma is small enough where the manifold is locally flat relative to sigma level)."
                },
                "questions": {
                    "value": "Please see weaknesses section for comments."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4037/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698727696472,
            "cdate": 1698727696472,
            "tmdate": 1699636366754,
            "mdate": 1699636366754,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gszDqYx8EJ",
                "forum": "7ErllmwXym",
                "replyto": "DQcsziefBA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4037/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4037/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the critical review. The main objection raised in this review is the dependence on reach in Theorem 3.1. The reviewer claims that the reach assumption is unrealistic for image manifolds. \n\nOur main theoretical contribution is Theorem 4.2, which depends only on the existence of a unique projection and Assumption 2, which states that the denoiser is an approximate projection in a relative sense. In Sections 3 and 4 we outlined the reasons for why we believe this is a reasonable assumption, using Theorem 3.1 when the noise level is small and arguing that for large noise levels both the denoising and projection vectors approximately point in the same direction.\n\nNote that Assumption 2 can be tested empirically (see the experiments in Appendix E), and Theorem 4.2 does not require any condition on the reach of the manifold. Theorem 3.1, which requires a condition on reach, is only used to motivate the definition of Assumption 2."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4037/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700102682637,
                "cdate": 1700102682637,
                "tmdate": 1700102682637,
                "mdate": 1700102682637,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "tA5iig4qp1",
            "forum": "7ErllmwXym",
            "replyto": "7ErllmwXym",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4037/Reviewer_dfzc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4037/Reviewer_dfzc"
            ],
            "content": {
                "summary": {
                    "value": "The authors reinterpret denoising diffusion models as approximate gradient descent applied to the Euclidean distance function under manifold hypothesis. In the interpretation, they establish rigorous connection between denoising function and the projection to data manifold, which is equivalent to the gradient of squared distance function to the manifold. They also reframe the convergence analysis of diffusion models using the new interpretation, providing a justification for the well-known log-linear noise schedule used in diffusion models.\n\nBuilding on these insights, the authors introduce a higher-order sampler of diffusion models. This sampler leverages the invariant properties of projection (projection is invariant along line segments between a point and the its projection), regularizing that the direction at one point in one step is similar to the direction at the point of next step. Their new sampler does not require additional evaluation of denoising (score) function and achieves SOTA FID scores on pretrained CIFAR-10 and CelebA models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper offers a novel interpretation of DDIM samplers, framing them as approximate gradient descent applied to the squared distance from data manifold. The convergence analysis of DDIM with Euclidean distance function instead of divergence over probability space adds to its novelty.\n\nThe authors propose improved schedules and samplers for DDIM based on their theoretical findings, which enhances the practical applicability of proposed theory. This improvement upon previous models based on theoretical foundations is notable."
                },
                "weaknesses": {
                    "value": "The proposed schedules and samplers are tested on a limited number of small-scale datasets\n\nImplications of lemma/theorem are unclear\n- Thm4.2: In rea settings, is final sample error (dist_K(x_0)) bounded?\n- Thm4.3: Why does beta star suddenly appear?\n- Thm4.4: Can we adopt beta for achieving convergence to zero? And how does it related to the schedule showcased in Section 6\n- Section5: What are the meaning of a positive definite metric and the implications of the metric with gamma equal to 2?"
                },
                "questions": {
                    "value": "It would be beneficial for the authors to relate their work to existing research regarding to geometry of diffusion models, such as \"Score-Based Generative Models Detect Manifolds,\" \"A Geometric Perspective on Diffusion Models,\" and \"Understanding the Latent Space of Diffusion Models through the Lens of Riemannian Geometry"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4037/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4037/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4037/Reviewer_dfzc"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4037/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698835356468,
            "cdate": 1698835356468,
            "tmdate": 1699636366671,
            "mdate": 1699636366671,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "DVzP04nwNx",
                "forum": "7ErllmwXym",
                "replyto": "tA5iig4qp1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4037/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4037/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the helpful comments and references. Regarding the comment on only testing the schedules and samplers on small-scale datasets, we also conducted experiments on high-resolution latent-diffusion models such as Stable diffusion. The text-to-image FID scores on 30k samples using the MS-COCO dataset are stated in Fig. 1, with more details in Section 6.2. \n\nBelow we provide some clarifications on the implications of the theorems:\n\n* Thm 4.2: Under our relative-error Assumption 2, Theorem 4.2 characterizes the noise schedules that would enable convergence of the DDIM algorithm, as measured by the distance to the data manifold. Intuitively, if the noise schedule has too large steps, the premise of Assumption 2 would be violated during the sampling process and convergence may not be guaranteed. This motivates our definition of admissible schedules and the theorem justifies the need for multiple steps of denoising in diffusion models. \nRegarding bounds of $\\text{dist}(x_0)$ in practice, this is possible when the error parameters ($\\nu$, $\\eta$) can be computed.  For this, one can use ground truth projections (if available). It may also be possible to bound ($\\nu$, $\\eta$) using denoiser training error, but we defer this to future research.\n* Thm 4.3: We apologize if the theorem as stated is unclear.  $\\beta^*$ is defined in the statement of Theorem 4.3.  As the theorem establishes, it equals the largest admissible step-size for constant sigma schedules.  Equivalently, it defines the fastest log-linear decrease of sigma.\n* Thm 4.4: This is an excellent question. Unfortunately, we must defer its answer to future research given the short rebuttal period.\n* Section 5: This weighting matrix can be interpreted as the inverse covariance matrix of positively correlated denoiser error. See appendix D."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4037/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700102641182,
                "cdate": 1700102641182,
                "tmdate": 1700102641182,
                "mdate": 1700102641182,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1PZYPjbMKy",
                "forum": "7ErllmwXym",
                "replyto": "DVzP04nwNx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4037/Reviewer_dfzc"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4037/Reviewer_dfzc"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for addressing my questions. However, I still believe the proof of concept in this paper falls short when compared to concurrently accepted papers. Moreover, considering the concerns raised by reviewer LpGF, it is essential to highlight a critical theoretical flaw in the paper. The mathematical concept of \u201creach\u201d remains unexplored in the context of data manifolds and requires thorough investigation before being employed to derive new implications about diffusion models. Given these reservations, I have developed skepticism regarding to the acceptance of this work at ICLR."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4037/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700586569356,
                "cdate": 1700586569356,
                "tmdate": 1700586569356,
                "mdate": 1700586569356,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "FFGbxHk9O4",
            "forum": "7ErllmwXym",
            "replyto": "7ErllmwXym",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4037/Reviewer_gUw5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4037/Reviewer_gUw5"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors offer a novel perspective by interpreting denoising diffusion models as an approximation of gradient descent applied to the Euclidean distance function. Furthermore, the paper includes a comprehensive convergence analysis of DDIM. The experimental results underscore the effectiveness of the proposed sampler, as it attains state-of-the-art FID scores and consistently generates high-quality samples."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper presents a compelling blend of theoretical interpretation and practical enhancements. While the projection interpretation of diffusion models is not entirely novel, the authors provide a more concrete example by framing sampling as an approximation of gradient descent on the distance function to the training dataset."
                },
                "weaknesses": {
                    "value": "."
                },
                "questions": {
                    "value": "Q1.The results presented in Table 2 appear to be incomplete, with certain experiments seemingly omitted. It would be beneficial to provide a more comprehensive set of results to ensure a thorough evaluation.\n\nQ2. Additionally, the comparison with DPM suggests that DPM performs comparably to the proposed sampler. It might be helpful to provide further insights or analysis regarding the similarities and differences between the two methods to clarify their relative strengths and weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4037/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699355487346,
            "cdate": 1699355487346,
            "tmdate": 1699636366601,
            "mdate": 1699636366601,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fZ1H7sOXvy",
                "forum": "7ErllmwXym",
                "replyto": "FFGbxHk9O4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4037/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4037/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the feedback. As for the questions raised:\n1. The results in the second half of the table are taken from the respective papers and thus some values are missing because they are not originally reported. \n2. Compared to the DPM sampler, our sampler performs better when using fewer sampling steps (i.e. using $N=5,10$ function evaluations), and also has the advantage of being much simpler to describe and implement."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4037/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700102370803,
                "cdate": 1700102370803,
                "tmdate": 1700102370803,
                "mdate": 1700102370803,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]