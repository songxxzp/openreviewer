[
    {
        "title": "BECLR: Batch Enhanced Contrastive Unsupervised Few-Shot Learning"
    },
    {
        "review": {
            "id": "SaCy9AIJ9k",
            "forum": "k9SVcrmXL8",
            "replyto": "k9SVcrmXL8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1421/Reviewer_wMvt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1421/Reviewer_wMvt"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a framework that comprises several part to better extract representations from images under the assumption that one single image in a batch corresponds to just one unique class. And also to address the issue of sample bias when few examples are playing crucial role even in cases where the sample is way higher. \n\\\nThe main contributions are: \\\n\na) the end-to-end framework terms BECLR that incorporates the modules that address sample bias and expands single image instance discrimination \\\n\nb) Very good results in a number of benchmarks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is detailed and relatively easy to follow. The underlying method is well explained and motivated and is substantiated by several experiments and ablations. \\\n\nThe results are promising and impressive and the method is well grounded."
                },
                "weaknesses": {
                    "value": "The evaluation should have considered the various components in separation and with respect to other methods.\nE.g. is OPTA that improves performance or perhaps adding another base line method might have had a similar performance. \\\nI think in such multi-component frameworks this is an issue usually. \\"
                },
                "questions": {
                    "value": "a) are the results presented throughout the paper are primarily based on the end-to-end process that involves all components, including OPTA? \\\nb) To be fair we need to see how other baselines work when replacing OPTA, e.g. other methods and/or linear evaluation principles for FSL. OPTA seems to have a considerable effect but is that down to the method itself or other baseline methods added to this framework could have a similar effect? \\\nc) Is there a reason why you did not consider running on the entire imagenet?\n\nTypos: \\\nthere are several typos throughout the paper - e.g. abstract \"Critical\" not \"Clinical\", \"downstream\" not \"downstrea\" and others."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1421/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1421/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1421/Reviewer_wMvt"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1421/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698659930733,
            "cdate": 1698659930733,
            "tmdate": 1700638182438,
            "mdate": 1700638182438,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pM1IyYApj0",
                "forum": "k9SVcrmXL8",
                "replyto": "SaCy9AIJ9k",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer wMvt (1/3)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their elaborate and constructive feedback. We are pleased to note that the reviewer finds the key proposed ideas grounded, the motivations behind $\\texttt{BECLR}$ and its narrative well explained, and our extensive experimentation and ablation studies impressive and promising. We recognize the reviewer's suggestions around further experimentation by adding our novel proposed module (called $\\texttt{OpTA}$) on top of other baselines, which nicely aligns with our broader impact statements, to substantiate the significance of its impact. Intrigued by these insightful suggestions, we have run new experimentation and address the reviewer's remarks in a point-to-point fashion in the following, as well as in the (updated) revised draft in $\\textcolor{blue}{blue}$.\n\n---\n\n**[W]**: The evaluation should have considered various components in separation and with respect to other methods. Adding $\\texttt{OpTA}$ on other baselines. \\\n**[AW]**: Thank you for this insightful comment, and indeed you are right, this is usually what happens in multi-component approaches. Let us first explain a few points and address your concerns. \n\n- First of all, please note that $\\texttt{OpTA}$ **is not an existing module we adopt, but a key component** (see Key Idea II, in Section 1) and part of the novelty in the end-to-end U-FSL pipeline of $\\texttt{BECLR}$. Even though in our broader impact and concluding remarks we actually propose $\\texttt{OpTA}$ becoming an essential part of any FSL approach (regardless of being supervised or unsupervised), adding it on top of other prior art, cannot then be considered the same baseline anymore but **an enhanced version of it using part of our proposition**. \n\n- Related to this, we already have an **ablation study exactly dedicated to your point regarding component-wise analysis**. Please have a look at  Table $5$ in Section 5.2 (Ablation Studies) in the main text, where we study the robustness of $\\texttt{BECLR}$ by sequentially adding essential components (including $\\texttt{OpTA}$) and how this affects our end-to-end performance. This already allows us to compare against other baselines in term of performance.\n    \n- Next to that, we also already take the opposite route in Fig. 5 in Section 5.1 (Evaluation Results) and **demonstrate that removing $\\texttt{OpTA}$ from $\\texttt{BECLR}$ still gives us state-of-the-art performance** compared to prior art. In this setting, both $\\texttt{BECLR}$ and competing baselines **follow identical training and testing settings**, without applying $\\texttt{OpTA}$ in the inference stage, thus further ensuring fairness in our comparisons. \n    \n- We will build on this direction in the following **[AQb]** to thoroughly address your interesting point.   \n \n---\n\n**[Qa]**: Are the results, presented throughout the paper, based on the end-to-end process including $\\texttt{OpTA}$?\n\n**[Aa]**: Yes they are, as $\\texttt{BECLR}$ is an end-to-end U-FSL approach that encompasses both $\\texttt{DyCE}$ and $\\texttt{OpTA}$ as its key components. It should be mentioned, that this is the case for all competing baselines out there, since the U-FSL problem is solved in two sequential stages: pretraining and inference (or testing if you will), as discussed in Section 3 (Problem Statement: U-FSL). Therefore **any reported results for $\\texttt{BECLR}$ and other baselines are based on the end-to-end process**. However, as we discussed earlier, to further study the robustness and versatility of $\\texttt{BECLR}$, we also present its downstream performance without some of its key components, including $\\texttt{OpTA}$ (see Table $5$ and Fig. $5$), also compared against the end-to-end performance of other baselines. More on this in the following."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1421/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700177650560,
                "cdate": 1700177650560,
                "tmdate": 1700177650560,
                "mdate": 1700177650560,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Vi5gMwBf54",
                "forum": "k9SVcrmXL8",
                "replyto": "SaCy9AIJ9k",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer wMvt (2/3)"
                    },
                    "comment": {
                        "value": "**[Qb]**: To be fair we need to see how other baselines work when replacing $\\texttt{OpTA}$. Adding $\\texttt{OpTA}$ on other baselines, still an effective approach? \\\n**[Ab]**: This is a great suggestion.\n- With all due respect, however, we do not think adding our innovative module on other baselines helps fairness in comparisons, but we totally agree that this substantiates the effectiveness of $\\texttt{OpTA}$ and solidifies our claim on its broader impact. To address your insightful suggestion, we have put tremendous effort to conduct additional experiments, during this rebuttal period.\n- We picked a suite of recent prior art in U-FSL [1-4], along with two established SSL baselines [5-6] and reproduced their results, comparing to $\\texttt{BECLR}$ without $\\texttt{OpTA}$, as well as per your suggestion **produced new results by plugging in $\\texttt{OpTA}$** in the inference stage **for all these competing baselines**. The results (see table below) demonstrate three important points: (i) **$\\texttt{BECLR w/o OpTA}$ still outperforms all those prior art**, and (ii) **$\\texttt{OpTA}$ is in fact agnostic to the choice of pretraining method**, since adding it on top of prior art has considerable impact on their enhanced methodology. We argue that this is a significant point in favor of our claim that $\\texttt{OpTA}$ should become an integral part of all (U-)FSL approaches. (iii) There still exists a margin between enhanced prior art and $\\texttt{BECLR}$, corroborating that **it is not just $\\texttt{OpTA}$ that has a meaningful effect but also $\\texttt{DyCE}$ and our pretraining methodology**. Notably, in Fig.7 in the main text we already demonstrate that $\\texttt{DyCE}$ and $\\texttt{OpTA}$ are heavily inter-dependent and significantly affect each other's impact. To address your concern, we have included these additional empirical results and discussion in the main text in Section 5 (Evaluation Results) of the revised manuscript.\n\n\\begin{array}{l|c|cc|cc}\n\\hline&& \\text{miniImageNet}& \\text{miniImageNet} & \\text{tieredImageNet}& \\text{tieredImageNet}\\newline \\hline\n\\text{Method}& \\text{Backbone}& \\text{5 way 1 shot}& \\text{5 way 5 shot}& \\text{5 way 1 shot}& \\text{5 way 5 shot}\\newline \\hline  \t\t\t\n\\texttt{NNCLR}& \\text{ResNet-18} & 63.33 \u00b1 0.53& 80.75 \u00b1 0.25& 65.46 \u00b1 0.55 & 81.40 \u00b1 0.22 \\newline\n\\texttt{SwAV}& \\text{ResNet-18} & 59.84 \u00b1 0.52& 78.23 \u00b1 0.26& 65.26 \u00b1 0.53 & 81.73 \u00b1 0.24 \\newline\n\\texttt{CPNWCP}& \\text{ResNet-18}& 53.81 \u00b1 0.65& 69.61 \u00b1 0.56 & 47.63 \u00b1 0.19 & 64.18 \u00b1 0.17\\newline\n\\texttt{HMS}& \\text{ResNet-18} \t& 58.20 \u00b1 0.23& 75.77 \u00b1 0.16 & 58.42 \u00b1 0.25& 75.85 \u00b1 0.18\\newline\n\\texttt{PsCo}& \\text{ResNet-18}& 47.24 \u00b1 0.56& 65.48 \u00b1 0.28 & 54.33 \u00b1 0.54& 69.73 \u00b1 0.49\\newline\n\\texttt{UniSiam}& \\text{ResNet-18}& 63.26 \u00b1 0.36& 81.13 \u00b1 0.26 & 65.18 \u00b1 0.39 & 82.28 \u00b1 0.29\\newline\n\\texttt{BECLR w/o OpTA} & \\text{ResNet-18} & \\bf{66.14 \u00b1 0.43}& \\bf{84.32 \u00b1 0.27} & \\bf{67.86 \u00b1 0.50} & \\bf{84.16 \u00b1 0.36}\\newline \\hline\n\\texttt{NNCLR+OpTA} & \\text{ResNet-18} & 72.62 \u00b1 0.64 & 82.19 \u00b1 0.35& 73.16 \u00b1 0.62& 82.82 \u00b1 0.33 \\newline\n\\texttt{SwAV+OpTA}& \\text{ResNet-18} & 70.36 \u00b1 0.61 & 81.68 \u00b1 0.36 & 73.60 \u00b1 0.63& 82.37 \u00b1 0.34 \\newline\n\\texttt{CPNWCP+OpTA}& \\text{ResNet-18} & 60.45 \u00b1 0.81 & 75.84 \u00b1 0.56 & 55.05 \u00b1 0.31& 72.91 \u00b1 0.26 \\newline\n\\texttt{HMS+OpTA}& \\text{ResNet-18} & 69.85 \u00b1 0.42 & 80.77 \u00b1 0.35& 71.75 \u00b1 0.43& 81.32 \u00b1 0.34\\newline\n\\texttt{PsCo+OpTA}& \\text{ResNet-18} & 52.89 \u00b1 0.71 & 67.42 \u00b1 0.54& 57.46 \u00b1 0.59& 70.70 \u00b1 0.45 \\newline\n\\texttt{UniSiam+OpTA}& \\text{ResNet-18} & 72.54 \u00b1 0.61 & 82.46 \u00b1 0.32 & 73.37 \u00b1 0.64& 82.64 \u00b1 0.64 \\newline\n\\texttt{BECLR}& \\text{ResNet-18}& \\bf{75.74 \u00b1 0.62} & \\bf{84.93 \u00b1 0.33}& \\bf{76.44 \u00b1 0.66} & \\bf{84.85 \u00b1 0.37}\\newline \\hline\n\\end{array}\n\n[1] Lu et al., Self-supervision can be a good few-shot learner, ECCV 2022 \\\n[2] Wang et al., Contrastive prototypical network with Wasserstein confidence penalty, ECCV 2022 \\\n[3] Li et al., Unsupervised few-shot image classification by learning features into clustering space,  ECCV 2022 \\\n[4] Jang et.al., Unsupervised Meta-learning via Few-shot Pseudo-supervised Contrastive Learning, ICLR 2023 \\\n[5] Dwibedi et al., With a little help from my friends: Nearest-neighbor contrastive learning of visual representations, ICCV 2021 \\\n[6] Caron et al., Unsupervised learning of visual features by contrasting cluster assignments, NeurIPS 2020"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1421/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700177677630,
                "cdate": 1700177677630,
                "tmdate": 1700177677630,
                "mdate": 1700177677630,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lEHNa5tMmN",
                "forum": "k9SVcrmXL8",
                "replyto": "SaCy9AIJ9k",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer wMvt (3/3)"
                    },
                    "comment": {
                        "value": "**[Qc]**: Running experiments on the entire ImageNet? \\\n**[Ac]**: This is a great question! \n- To the best of our knowledge, no existing U-FSL baseline reports results on full ImageNet. FSL benchmarks define specific FSL-oriented samplers and settings which are tailored towards miniImageNet, tieredImageNet, CIFAR-FS, and FC-100 (in-domain) and miniImagenet \u2192 CDFSL and miniImagenet \u2192 CUB (cross-domain). These are **THE benchmarks adopted by $99.9$**% **of the U-FSL approaches** out there. Notably, in a separate study dedicated to SSL (and not U-FSL anymore) we are exploring the capacity of $\\texttt{BECLR}$ on the entire ImageNet, but that is outside the scope of this paper. If you strongly advise, we can include some of those preliminary results in the Appendix.  \n\n---\n**[C]**: There are several typos throughout the paper. \\\n**[AC]**: Thank you for these astute observations. Regarding the word \"clinical\" in the Abstract we meant that the problem of sample bias is inherent to (U-)FSL, yet we agree that critical would be a better choice of word. Regarding the typo in \"downstream\", this is indeed a typo that has happened on the last revision of the paper (it is not present in previous versions). Following your comment, we have carefully reviewed the revised manuscript multiple times to ensure the absence of typos."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1421/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700178546745,
                "cdate": 1700178546745,
                "tmdate": 1700178546745,
                "mdate": 1700178546745,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7wMwBUVBTc",
                "forum": "k9SVcrmXL8",
                "replyto": "pM1IyYApj0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1421/Reviewer_wMvt"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1421/Reviewer_wMvt"
                ],
                "content": {
                    "title": {
                        "value": "Please elaborate"
                    },
                    "comment": {
                        "value": "Can you please elaborate on the second bullet point above?\nMy point was exactly this; Table 5 in section 5.2 (by the way Table 6 appears first in the text) shows at the very last step how adding OPTA affects performance....one can interpret that as adding 13% of extra performance on 1-shot...however that cannot be a baseline comparison as this result merely shows what the benefit of OPTA is but not how a difference method in lieu of OPTA as a fourth stage in the process would compare.\n\nSay you replace OPTA, and performance still goes up at the same rate then what's the point of having OPTA. Is this ablation included somewhere? To me this type of ablation would involve freezing the first three steps, i.e. Masking, EMA teacher, and DyCE, and then testing various components alongside OPTA"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1421/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700638080955,
                "cdate": 1700638080955,
                "tmdate": 1700638080955,
                "mdate": 1700638080955,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tPcQuPlwMV",
                "forum": "k9SVcrmXL8",
                "replyto": "7wMwBUVBTc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1421/Reviewer_wMvt"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1421/Reviewer_wMvt"
                ],
                "content": {
                    "title": {
                        "value": "increase score"
                    },
                    "comment": {
                        "value": "Having said the above, I am happy with the rest of the responses so will increase my score....but table 5 still remains unclear to me."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1421/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700638169154,
                "cdate": 1700638169154,
                "tmdate": 1700638169154,
                "mdate": 1700638169154,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "L2nXaBXuol",
            "forum": "k9SVcrmXL8",
            "replyto": "k9SVcrmXL8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1421/Reviewer_WH4q"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1421/Reviewer_WH4q"
            ],
            "content": {
                "summary": {
                    "value": "In the presented paper, the authors identify two primary limitations in the existing Unsupervised Few-Shot Learning (U-FSL) methods and introduce an integrated solution named BECLR. BECLR incorporates two novel components: a dynamic clustered memory module named DyCE, designed to improve positive sampling in contrastive learning, and an efficient distribution alignment strategy termed OpTA, devised to counteract sample bias in U-FSL. While BECLR is tailored for U-FSL, the authors highlight DyCE's potential broader applications in general self-supervised learning, noting its superior performance even without OpTA, and advocate for the inclusion of OpTA in all U-FSL methods, particularly in low-shot scenarios."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "**Originality**: The paper showcases a distinct approach by addressing recognized limitations in U-FSL and introducing the BECLR solution, merging existing concepts innovatively and presenting fresh modules like DyCE and OpTA. \n\n**Quality**: The research is robust, with DyCE and OpTA being methodically developed and their effectiveness demonstrated through comparisons with established methods like SwaV, SimSiam, and NNCLR.\n\n**Clarity**: The authors articulate their findings and methodologies clearly, ensuring that readers can grasp the intricacies of BECLR, DyCE, and OpTA without ambiguity. \n\n**Significance**: With its potential to redefine self-supervised learning and its implications for U-FSL, especially in few-shot scenarios, the paper holds substantial importance in advancing the field and offers a direction for future research."
                },
                "weaknesses": {
                    "value": "1. The overarching idea and structure of BECLR bear a striking resemblance to PsCo, particularly when observing Figure 2. It appears that the primary distinction is the concatenation of different views of 'X' from PsCo and the addition of a dynamic clustered memory. To differentiate their work more effectively, the authors should provide a comprehensive comparison with PsCo in both the introduction and related work sections, highlighting the unique aspects of their approach.\n\n2. The notation used in the algorithmic section needs elucidation. Clearly defining each symbol would make it more accessible and allow readers to follow the content with greater ease.\n\n3. The experimental section could benefit from an additional test: an evaluation of performance without merging 'X'. It would also be insightful to see results when PsCo is merged and when masking is applied, offering a more comprehensive understanding of the method's robustness and versatility."
                },
                "questions": {
                    "value": "1. **Model Parameter Updates during Testing:** During the testing phase, are there any updates required for the model's parameters? If yes, how many times is the model updated?\n\n2. **Comparison with PsCo in Terms of Model Size and Inference Time:** How does BECLR compare to PsCo regarding the number of parameters in the model and the inference time? A direct comparison would provide clarity on the efficiency and scalability of BECLR.\n\n3. **Data Utilized for MiniImagenet Pretraining:** When pretraining with miniImagenet, which specific datasets were employed? Was the entire miniImagenet dataset utilized for this purpose?\n\nSuggestions:\n\n- **Enhanced Clarity on Parameter Update Mechanism:** A deeper dive into the model's updating mechanism during testing would be valuable. This would provide insights into the adaptability and robustness of the model, especially in real-world scenarios where data dynamics may vary.\n\n- **Detailed Comparative Analysis with PsCo:** Given the similarities noted between BECLR and PsCo, a side-by-side comparison in terms of model parameters and inference time would offer readers a clearer perspective on the advantages and potential trade-offs of adopting BECLR."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1421/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1421/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1421/Reviewer_WH4q"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1421/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698675400692,
            "cdate": 1698675400692,
            "tmdate": 1700656973811,
            "mdate": 1700656973811,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Wdqj5KN4Xd",
                "forum": "k9SVcrmXL8",
                "replyto": "L2nXaBXuol",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer WH4q (1/3)"
                    },
                    "comment": {
                        "value": "We truly appreciate the reviewer's elaborate and constructive feedback. We are delighted to note that the reviewer accentuates on the novelty of the key ideas, clarity and coherence of the narrative, effectiveness of $\\texttt{BECLR}$ demonstrated through extensive experimentation (defining it as SoTA across all existing FSL benchmarks), as well as on the significance of the work potentially \"redefining self supervised learning'' and U-FSL. We recognize the reviewer's constructive suggestions around more elaborate comparison with PsCo (in terms of performance, complexity, and inference time) as well as further clarity on parameter update mechanism. To address these remarks, we have put tremendous effort in running new experimentation and providing a point-to-point response, which in turn is reflected in the (updated) revised draft in $\\textcolor{blue}{blue}$.\n\n---\n**[W1-a]**: Resemblance to PsCo, unique aspects of $\\texttt{BECLR}$, and providing comparison with PsCo in the introduction and related work. \\\n**[AW1-a]**: Thank you for this helpful pointer.\n- First of all, we dove deeper into PsCo and set up its pipeline for reproducing its reported results and conducting additional experiments. $\\texttt{BECLR}$ and PsCo indeed share some similarities, in that both methods utilize a student-teacher momentum architecture, a memory module of past representations, some form of contrastive loss, and optimal transport (even though for different purposes). Note that none of these components are unique to neither PsCo nor $\\texttt{BECLR}$ and can be found in the overall SSL literature [1-3].\n- Let us now expand on their discrepancies and **unique aspects of $\\texttt{BECLR}$**: (i) PsCo is based on meta learning, constructing few-shot classification (i.e., $N$-way $K$-shot) tasks, during meta-training and relying on fine-tuning for rapidly adapting to novel tasks during meta-testing. In contrast, $\\texttt{BECLR}$ is a **contrastive framework based on metric/transfer learning**, which focuses on representation quality and relies on $\\texttt{OpTA}$ for transferring to novel tasks (no few-shot tasks during pretraining, no fine-tuning during inference). (ii) PsCo utilizes a simple FIFO memory queue (oblivious to class-level information), while $\\texttt{BECLR}$ maintains a **clustered highly-separable** (see Figure 6) **memory module** in $\\texttt{DyCE}$, which (after an adaptation period) is used for sampling meaningful positives. (iii) PsCo applies optimal transport for creating pseudo-labels (directly from the unstructured memory) for $N*K$ support embeddings, in turn used as a supervisory signal to enforce consistency between support (drawn from teacher) and query (student) embeddings. In contrast, $\\texttt{BECLR}$ artificially enhances the batch with additional positives and applies an instance-level contrastive loss to enforce consistency between the original and enhanced positive pairs. After each training iteration, optimal transport is applied to **update the stored clusters within $\\texttt{DyCE}$ in an equipartitioned fashion** with embeddings from the current batch. (iv) Finally, $\\texttt{BECLR}$ **also incorporates optimal transport (in $\\texttt{OpTA}$) for aligning the distributions between support and query sets**, during inference, which shares no similarity with the pipeline of PsCo. Following your suggestion, we added further discussion on the comparison with PsCo both in Sections 2 (Related Work) and 4.1 (Unsupervised Pretraining) of the revised draft.\n\n[1] Wang et al., Contrastive prototypical network with Wasserstein confidence penalty, ECCV 2022 \\\n[2] Grill et al. Bootstrap your own latent-a new approach to self-supervised learning, NeurIPS 2020 \\\n[3] Dwibedi et al. With a little help from my friends: Nearest-neighbor contrastive learning of visual representations, ICCV 2021 \n\n---\n**[W1-b]**: It appears that the primary distinction is the concatenation of different views of $X$ from PsCo and the addition of a dynamic clustered memory. \\\n**[AW1-b]**: Great remark. Let us expand further on this point:\n- The reasoning behind the concatenation of different views of $X$, is to pass both views to both student/teacher networks to accommodate our symmetric contrastive loss (i.e., infoNCE loss between $Z_1^{S}$-$Z_2^{T}$ and $Z_2^{S}$-$Z_1^{T}$). The symmetricity in the loss has been shown to yield a minor performance boost [1], but does not constitute the primary distinction between PsCo and $\\texttt{BECLR}$ as explained in **[AW1-a]**. The effect of adding a symmetric loss to PsCo is also discussed in greater detail in the following **[AW3]**.\n- **The main novelty** and distinction lies indeed in our **dynamic clustered memory** ($\\texttt{DyCE}$) and our **distribution alignment module** ($\\texttt{OpTA}$), which are the two Key Ideas of our work, both contributing to the overall U-FSL performance of $\\texttt{BECLR}$ (see Table 5).  \n\n[1] Chen et. al. Exploring simple siamese representation learning, CVPR 2021"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1421/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700177375131,
                "cdate": 1700177375131,
                "tmdate": 1700177375131,
                "mdate": 1700177375131,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mZ3dmWcXqx",
                "forum": "k9SVcrmXL8",
                "replyto": "L2nXaBXuol",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer WH4q (2/3)"
                    },
                    "comment": {
                        "value": "**[W2]**: Elucidation of the notation in the Algorithm. \\\n**[AW2]**: Thank you for the constructive recommendation.\n - We did our best to define every variable in the main text and also included a step-by-step walk-through for Algorithm 2. However, we agree this could have been done better. Per your suggestion, we (i) **now include a thorough walk-through of Algorithm 1**, (ii) have made **modifications in both Algorithm 2 and its explanation** to provide more elucidation on the inner mechanics of $\\texttt{DyCE}$, and (iii) made sure that **every single variable and symbol (for both algorithms) are properly defined** in the main text. These revisions are included in Section 4.1 (Unsupervised Pretraining) of the updated manuscript.\n\n- Please also have a look at Algorithms 3 and 4, already existing in Appendix E, where we also provide PyTorch-like pseudocodes for Algorithms 1 and 2 for further elucidation.\n\n---\n**[W3]**: Additional test by including/ exlcuding masking and concatenating augmented views of the input $X$. \n\n**[AW3]**: This is a fabulous remark and intrigued us to run new experimentation to fully address your concern here.\n\n- Before we dive in, note that PsCo reports performance with a Conv5 backbone, even though in exploring the codebase we understood it can readily accept ResNet-18, as well. So, in the below table we present an interesting experiment. We first mark the original reported performance of PsCo with a Conv5 backbone as well as its reproduction with ResNet-18. We then modify the **loss for PsCo to be symmetric** (allowing both augmentations of $X$ to pass through both branches) similar to $\\texttt{BECLR}$, (this is denoted as $\\texttt{PsCo+}$). Next, we **also add patch-wise masking** to PsCo (denoted as $\\texttt{PsCo++}$) and as an additional step we have **also added our novel module $\\texttt{OpTA}$** on top of all these models ($\\texttt{PsCo w/ OpTA}$), during inference. We observe that neither the symmetric loss nor masking are offering meaningful improvements in the performance of PsCo. On the contrary $\\texttt{OpTA}$ yields a significant performance boost (up to $6.5$% in the $1$-shot setting that sample bias is most severe). This corroborates our claim that our proposed $\\texttt{OpTA}$ should be considered as an add-on module to every FSL approach out there (Key Idea II). \n    \n- **As an additional robustness study** we take the opposite steps for $\\texttt{BECLR}$, first **removing the patch-wise masking** (denoted as $\\texttt{BECLR-}$) and then **also the symmetric loss** (denoted as $\\texttt{BECLR--}$), noticing that both degrade the performance slightly (see table below), which confirms our design choices to include them. Similarly, we also remove $\\texttt{OpTA}$ from $\\texttt{BECLR}$'s inference stage. The most important takeaway here: **the most degraded version of $\\texttt{BECLR}$** ($\\texttt{BECLR-- w/o OpTA}$) **still outperforms the best enhanced version of PsCo**( $\\texttt{PsCo++ w/ OpTA}$), even without $\\texttt{OpTA}$, which we think offers additional perspective on the advantages of adopting $\\texttt{BECLR}$ over PsCo. \n\n- To reiterate, we believe $\\texttt{BECLR}$ defines the new SoTA over ALL U-FSL baselines across all existing benchmarks dedicated to FSL (to the best of our knowledge). We have added this table and discussion in Appendix F (In-Depth Comparison with PsCo), as this study really focuses on a detailed comparison with a single baseline, but we are happy to pull this up into the main text of the revised version, in case you strongly advise to do so. We do hope this addresses your concern. \n\\begin{array}{l|c|cc}\n\\hline\n\\text{Method}& \\text{Backbone}& \\text{5 way 1 shot} & \\text{5 way 5 shot} \\newline \\hline\n\\texttt{PsCo}& \\text{Conv5}& 46.70 \u00b1 0.42& 63.26 \u00b1 0.37 \\newline\n\\texttt{PsCo}& \\text{ResNet-18}& 47.24 \u00b1 0.46& 65.48 \u00b1 0.38\\newline\n\\texttt{PsCo+}& \\text{ResNet-18}& 47.86 \u00b1 0.44& 65.95 \u00b1 0.37\\newline\n\\texttt{PsCo++}& \\text{ResNet-18}& 47.58 \u00b1 0.45& 65.74 \u00b1 0.38\\newline \\hline\n\\texttt{PsCo w/ OpTA}& \\text{ResNet-18} & 52.89 \u00b1 0.61& 67.42 \u00b1 0.51\\newline\n\\texttt{PsCo+ w/ OpTA}& \\text{ResNet-18}& 54.43 \u00b1 0.59& 68.31 \u00b1 0.52\\newline\n\\texttt{PsCo++ w/ OpTA}& \\text{ResNet-18}& 54.35 \u00b1 0.60& 68.43 \u00b1 0.52\\newline \\hline\n\\texttt{BECLR}& \\text{ResNet-18}& \\bf{75.74 \u00b1 0.62} & \\bf{84.93 \u00b1 0.33}\\newline\n\\texttt{BECLR-}& \\text{ResNet-18} & 74.37 \u00b1 0.61 & 84.19 \u00b1 0.31\\newline\n\\texttt{BECLR--}& \\text{ResNet-18} & 73.65 \u00b1 0.61& 83.63 \u00b1 0.31\\newline \\hline\n\\texttt{BECLR w/o OpTA} & \\text{ResNet-18}& 66.14 \u00b1 0.43& 84.32 \u00b1 0.27\\newline\n\\texttt{BECLR- w/o OpTA} & \\text{ResNet-18}& 65.26 \u00b1 0.41 & 83.68 \u00b1 0.25\\newline\n\\texttt{BECLR-- w/o OpTA}& \\text{ResNet-18} & 64.68 \u00b1 0.44& 83.45 \u00b1 0.26\\newline \\hline\n\\end{array}"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1421/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700177420315,
                "cdate": 1700177420315,
                "tmdate": 1700208332638,
                "mdate": 1700208332638,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PpM0L4lKWK",
                "forum": "k9SVcrmXL8",
                "replyto": "L2nXaBXuol",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer WH4q (3/3)"
                    },
                    "comment": {
                        "value": "**[Q1]**: Model parameter updates during test phase. \\\n**[A1]**: Again, an important remark. \n\n- **We do not have any model updates nor any fine-tuning at test time.** Neither $\\texttt{DyCE}$ nor $\\texttt{OpTA}$ impose any extra learnable parameters, and that we believe is part of the beauty of $\\texttt{BECLR}$. Following your suggestion, we have added a sentence to address this in Section 4.2 (Supervised Inference) of the revised draft.\n\n---\n\n**[Q2**: Model size and inference time comparison against PsCo.  \\\n**[A2]**: Yet another interesting recommendation.\n\n- Following your suggestion, during this rebuttal period **we have compared $\\texttt{BECLR}$ and PsCo in terms of model size** (total number of parameters in M) **and inference times** (in sec/episode), when using the same ResNet-18 backbone architecture. The results are summarized in the table below. We notice that $\\texttt{BECLR}$'s total parameter count is in fact lower than that of PsCo. Regarding inference time, $\\texttt{BECLR}$ is slightly slower in comparison, yet this difference is negligible in real-time inference scenarios. This comparison has also been added in Appendix F (In-Depth Comparison with PsCo) of the revised draft, since it constitutes a comparison against a single U-FSL baseline. Please let us know if this sufficiently addresses your concern.\n    \n- Please also have a look at Table 13 already existing in Appendix D (Complexity Analysis), where we compare $\\texttt{BECLR}$ with different SSL contrastive approaches in terms of computational complexity (model size, training time, inference time)\n\n\n\\begin{array}{lccc}\n\\hline\n\\text{Method} \t\t& \\text{Backbone} \t& \\text{Total Parameter Count (M)} \t& \\text{Inference Time (sec/episode)} \t\\newline \\hline\n\\texttt{PsCo}            \t& \\text{ResNet-18}     \t& 30.766                        \t& 0.082                               \t\\newline\n\\texttt{BECLR}           \t& \\text{ResNet-18}     \t& 24.199                        \t& 0.216                               \t\\newline \\hline\n\\end{array}\n\n---\n\n**[Q3]**: Data used for miniImageNet pretraining. \\\n**[A3]**: Thank you for this helpful comment.\n\n- First of all, please have a look at Section B.1 (Dataset Details) already in Appendix B. Therein, we expand on the datasets that were used as part of the experimental process of $\\texttt{BECLR}$, in terms of selected splits used for training, validation, and testing, number of classes and dataset size.\n    \n- For miniImageNet in particular, out of its $100$ classes, we select $64$, $16$, and $20$ classes for training, validation, and testing, respectively, following the **predominantly adopted settings** [1-4]. The training, validation, and testing splits and classes are mutually exclusive, as is standard practice in (U-)FSL, to test the adaptation of the model to novel tasks (unseen during training). To explicitly address your question, **when pretraining $\\texttt{BECLR}$ on miniImageNet, only the training split is employed and not the entire miniImageNet dataset, nor any additional datasets.**\n\n[1] Ravi et.al., Optimization as a model for few-shot learning, ICLR 2016 \\\n[2] Jang et.al., Unsupervised Meta-learning via Few-shot Pseudo-supervised Contrastive Learning, ICLR 2023 \\\n[3] Lu et al., Self-supervision can be a good few-shot learner, ECCV 2022 \\\n[4] Li et al., Unsupervised few-shot image classification by learning features into clustering space, ECCV 2022\n\n---\n\n**[SG1 & 2]**: Suggestions on clarity about model parameter updating, and detailed comparative analysis with PsCo. \n\n**[ASG1 & 2]**: Thank you for the detailed suggestions. We have already addressed both thoroughly as discussed earlier, and reflections are inserted in the (updated) revised manuscript."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1421/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700177494197,
                "cdate": 1700177494197,
                "tmdate": 1700177494197,
                "mdate": 1700177494197,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "v388gpZJya",
                "forum": "k9SVcrmXL8",
                "replyto": "mZ3dmWcXqx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1421/Reviewer_WH4q"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1421/Reviewer_WH4q"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response."
                    },
                    "comment": {
                        "value": "I greatly appreciate your thorough response, which has addressed all my initial concerns. However, I still have one question. Is there a high-level intuition as to why your method significantly outperforms supervised few-shot learning? I understand the contributions and the implementation details of your paper, but I'm interested in any intuitive explanation you might have.\n\nAdditionally, you mentioned comparisons with MetaOptNet and Transductive CNAPS. Could you possibly provide a comparison with some of the supervised few-shot learning methods that have emerged in the past year?\n\nLooking forward to your insights."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1421/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700345184249,
                "cdate": 1700345184249,
                "tmdate": 1700345184249,
                "mdate": 1700345184249,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xV6GjuaO8G",
                "forum": "k9SVcrmXL8",
                "replyto": "N8NZcUCI0a",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1421/Reviewer_WH4q"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1421/Reviewer_WH4q"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your reply!"
                    },
                    "comment": {
                        "value": "I am very satisfied with the author's response and the additional references provided, so I have increased my score to 6. I hope that in the new version, the author can include discussions of the experiments and literature."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1421/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700656950451,
                "cdate": 1700656950451,
                "tmdate": 1700656950451,
                "mdate": 1700656950451,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "efEX2dJTxl",
                "forum": "k9SVcrmXL8",
                "replyto": "L2nXaBXuol",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Last Remarks or Suggestions?"
                    },
                    "comment": {
                        "value": "We are delighted to know that you are **very satisfied** with our efforts and responses. We thank you for all your constructive comments and greatly appreciate you increasing the score. Please note that the current version of the paper is **already updated twice** per your instructions, please kindly have a look. As you rightfully stated, we also do believe that _\"$\\texttt{BECLR}$ has the potential to redefine self-supervised learning and its implications for U-FSL, especially in few-shot scenarios, and holds substantial importance in advancing the field\"_. In that light, we are determined to ensure that you are fully convinced about the impact of our work. \n\nIs there any last step we can take, any last remark or suggestion for us to further improve the draft accotdingly, so that you would support our paper more strongly? We are more than happy to do so. Please let us know."
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1421/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700658962284,
                "cdate": 1700658962284,
                "tmdate": 1700672317623,
                "mdate": 1700672317623,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "kmYA8aFrnY",
            "forum": "k9SVcrmXL8",
            "replyto": "k9SVcrmXL8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1421/Reviewer_msQP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1421/Reviewer_msQP"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed an Unsupervised few-shot learning method (BECLR). The key idea is to extend the memory queue concept to dynamically updated memory clusters (DyCE). The second key idea is to address sample bias issue (distribution shift between the unlabeled Query set and the labeled support set) by introducing OpTA at inference time. BECLR is the name of the overall method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper tried to address several issues within a single framework. It benefits from contrastive pre-training, tries to address and distribution shift and address some of the issues around the memory queue concept. \nIt seems that empirical results are strong."
                },
                "weaknesses": {
                    "value": "-SAMPTransfer (Shirekar et al 2023) is also based on membership but its performance is reported only on the miniImageNet-->CDFSL task (Table 3). It is missing from other experiments. \n-Prior FSL works that are related to the distribution shift (sample bias) issue are not discussed. \n-Table 1: For ResNet-50 and Wide ResNet backbones, some of the comparison methods are missing. Again, in Table 3 some of the comparison methods are missing. It seems that the subset of methods used in each experiment is an arbitrary subset of the available pool of the previous methods."
                },
                "questions": {
                    "value": "See above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1421/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698714149180,
            "cdate": 1698714149180,
            "tmdate": 1699636070193,
            "mdate": 1699636070193,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "F0iwJhZO3h",
                "forum": "k9SVcrmXL8",
                "replyto": "kmYA8aFrnY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their positive and constructive feedback. We are pleased to note that the reviewer finds our extensive experimentation results strong, which define $\\texttt{BECLR}$ as the new SoTA across all existing U-FSL baselines. Following a thorough analysis of the reviewer's suggestions, we address the reviewers concerns and questions in a point-to-point fashion. The modifications applied to the (updated) revised draft are marked in $\\textcolor{blue}{blue}$ for convenience.\n\n---\n**[Q1]**: SAMPTransfer performance missing. \\\n**[A1]**: Thanks for your insightful observation and remark. \n- First of all, please have a look at Tables $9$, $10$ and $11$, already existing in the Appendix C. **SAMPTransfer's performance on miniImageNet and tieredImageNet is reported in Table $9$ and its performance on miniImageNet \u2192 CDFSL in Table $11$** (extended versions of Tables $1$ and $3$ in the main text). \n- Regarding SAMPTransfer [1], following your suggestion, we setup the end-to-end pipeline to reproduce its results. We now know all its bells and whistles well. As we discussed already in Section 2 (Related Work to U-FSL) in the main text, SAMPTransfer's performance is hindered by its graph-based membership exploration unit and thus its performance can even degrade with larger backbones. We speculate that this is the reason why its performance is not reported on larger backbones in the original paper. To substantiate this and address your concern, we have conducted an additional experiment during this rebuttal period, comparing the performance of $\\texttt{BECLR}$ and SAMPTransfer for different backbones. As seen in the table below: (i) SAMPTransfer indeed performs better with a shallower backbone (Conv4b) and (ii) $\\texttt{BECLR}$ shows a superior end-to-end performance, regardless of the choice of backbone. Finally, **we have included the performance of SAMPTransfer on Table $1$ of the revised draft, following your remark**. \\\nWould you also advise including the below Table in the Appendix of the revised draft?\n\n\\begin{array}{lccccc}\n\\hline\n&& \\text{miniImageNet}& \\text{miniImageNet}\\newline \\hline\n\\text{Method}& \\text{Backbone}& \\text{5 way 1 shot}& \\text{5 way 5 shot}\\newline \\hline\n\\texttt{SAMPTransfer}& \\text{Conv4}& 55.75 \u00b1 0.77& 68.33 \u00b1 0.66\\newline\n\\texttt{SAMPTransfer}& \\text{Conv4b}& 61.02 \u00b1 1.05& 72.52 \u00b1 0.68\\newline\n\\texttt{BECLR}& \\text{Conv4b}& \\textbf{69.54 \u00b1 0.63}& \\textbf{80.61 \u00b1 0.29}\\newline \\hline\n\\texttt{SAMPTransfer}& \\text{ResNet-18}& 45.64 \u00b1 0.73& 56.82 \u00b1 0.65\\newline\n\\texttt{BECLR}& \\text{ResNet-18}& \\textbf{75.74 \u00b1 0.62} & \\textbf{84.93 \u00b1 0.33}\\newline \\hline\n\\end{array}\n\n\n[1] Shirekar et al., Self-Attention Message Passing for Contrastive Few-Shot Learning, WACV 2023"
                    },
                    "title": {
                        "value": "Response to Reviewer msQP (1/3)"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1421/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700177138567,
                "cdate": 1700177138567,
                "tmdate": 1700177541658,
                "mdate": 1700177541658,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QM4JzRu2Hi",
                "forum": "k9SVcrmXL8",
                "replyto": "kmYA8aFrnY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer msQP (2/3)"
                    },
                    "comment": {
                        "value": "**[Q2]**: Prior FSL works that are related to the distribution shift (sample bias) are not discussed. \\\n**[A2]**: Great suggestion. \n- Let us first set the scene a bit better: as we articulate in the paper, the problem of sample bias (distribution shift between query and support sets) is _overlooked_ by almost every U-FSL baseline and the vast majority of the supervised FSL prior art. This is the very reason behind our Key Idea II in Section 1 (Introduction) and the proposition of the novel module called $\\texttt{OpTA}$. \n- Following your suggestion, we have delved deeper in the FSL literature and found related work that attempts to alleviate the effects of sample bias. In particular, [1] proposes to enhance the support set by drawing additional base-class images via class-competitive attention maps, [2] highlights that sample bias is most severe when support embeddings are in the vicinity of the task centroid, whereas [3] utilizes a calibrated distribution for sampling more support embeddings, yet these methods explicitly rely on base-class characteristics. [4,5] follow a different perspective and tackle sample bias directly on the logistic classifier-level by using Firth bias reduction [6] techniques. These methods, however, are prone to overfitting of the classifier and pretrained encoder during fine-tuning. In contrast, our proposed $\\texttt{OpTA}$ module requires no fine-tuning (and no additional trainable parameters) and does not depend on the pretraining dataset. Instead, we utilize optimal transport [7] for aligning the distributions of the _biased_ support set with that of the query set at the inference stage. **We have included this discussion in Section 2 (Related Work) of the revised version, along with further elaboration on the distribution shifts and biases that are present in the U-FSL setting.** We are happy to also include any specific references from the (U-)FSL literature you might find relevant and want us to refer to, please just advise and we will include.\n\n[1] Chen et al., Few-Shot Learning with Part Discovery and Augmentation from Unlabeled Images, IJCAI 2021 \\\n[2] Xu et al., Alleviating the sample selection bias in few-shot learning by removing projection to the centroid, NeurIPS 2022 \\\n[3] Yang et al., Free Lunch for Few-shot Learning: Distribution Calibration, ICLR 2021 \\\n[4] Ghaffari et al., On the importance of firth bias reduction in few-shot classification, ICLR 2022 \\\n[5] Wang et al., Revisit Finetuning strategy for Few-Shot Learning to Transfer the Emdeddings, ICLR 202 \\\n[6] Firth, David, Bias reduction of maximum likelihood estimates. \\\n[7] Cuturi et al., Computational optimal transport: With applications to data science."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1421/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700177262910,
                "cdate": 1700177262910,
                "tmdate": 1700177556366,
                "mdate": 1700177556366,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "g4Rt4ypFzg",
                "forum": "k9SVcrmXL8",
                "replyto": "kmYA8aFrnY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer msQP (3/3)"
                    },
                    "comment": {
                        "value": "**[Q3-a]**: Some comparisons are missing in Table 1 and 3. It seems that the subset of methods used in each experiment is an arbitrary subset of the available pool of the previous methods.\\\n**[A3-a]**: Thank you for this observation and remark. Let us further expand on this. \n\n- First of all, it is _virtually impossible_ for us to reproduce all existing baselines on all benchmarks. We did reproduce a good group of most recent ones, but for some we either could not even find an authentic repository or could not reproduce their reported results. As such, we naturally have to constrain ourselves to the performances and FSL benchmarks reported in the original paper, trusting the authors. \n\n- Secondly, FSL benchmarks have very specific, built-in data samplers allowing the baselines to precisely report their performances following those guidelines. For both our reproductions of existing baselines and $\\texttt{BECLR}$'s reported results, **we have taken every measure to ensure fairness in our comparisons** by following the most commonly adopted pretraining and evaluation settings in the U-FSL literature in terms of pretraining/inference benchmark datasets (for both in-domain and cross-domain experiments), pretraining data augmentations, ($N$-way, $K$-shot) inference settings and number of query set images per tested episode.\n\n- We, nonetheless, report results of $\\texttt{BECLR}$ on ALL existing FSL benchmarks out there, which is not the case for most baselines. **As such, if a certain baseline does not report performance on those benchmarks, and we could not find an authentic codebase nor reproduce their reported results, we had to exclude them from our reported results in the corresponding benchmark.** By the way, this is the case in most studies out there. Consequently, the reported subset of methods in each experiment is not arbitrary but rather dependent on these limitations.\n\n- Please also have a look at Tables $9$, $10$ and $11$, already existing in Appendix C. Therein, **we cover essentially ALL existing baselines on U-FSL** (to the best of our knowledge) as well as some from supervised FSL (just for bench-marking purposes). We are happy to also include additional results, in case you feel we have omitted any relevant U-FSL baseline, please feel free to share.\n\n---\n\n**[Q3-b]**: For ResNet-50 and Wide ResNet backbones, some of the comparison methods are missing.\\\n**[A3-b]**: Thank you for the remark and for observing this.\n- Given the inherent data scarcity in the U-FSL setting, most baselines report results on shallower backbones (e.g., Conv4, Conv5, ResNet-12, ResNet-18). Among these backbones, ResNet-18 has been most commonly adopted across the recent U-FSL literature [1-5], as such is the main backbone for our analysis, ensuring fairness in our comparisons. The reported results with a ResNet-50 backbone are provided in order to assess whether $\\texttt{BECLR}$ can scale to deeper backbones. In this setting, we similarly had to limit the pool of of comparing methods to those, which report their performance with a ResNet-50 feature extractor.\n\n- The focus of our work is on U-FSL, and not supervised FSL. Vast majority of U-FSL approaches do not present results with Wide ResNet (WRN) backbones and some supervised FSL approaches do. The comparison against the selected supervised baselines is our best effort to present their _top performing_ models. Nevertheless, we understand this might create some inconsistency as you rightfully indicated. As such, **following your suggestion, we have (i) excluded supervised methods, trained with WRN, from our comparisons in Table 1 (ii) refactored Table 1, now comparing all baselines with identical backbone configuration (ResNet-18 and ResNet-50, when applicable) to ensure consistency and fairness in our comparisons.**\n\n[1] Lu et al., Self-supervision can be a good few-shot learner, ECCV 2022 \\\n[2] Chen et al., Shot in the dark: Few-shot learning with no base-class labels, CVPR 2021 \\\n[3] Wang et al., Contrastive prototypical network with Wasserstein confidence penalty, ECCV 2022 \\\n[4] Li et al., Unsupervised few-shot image classification by learning features into clustering space,  ECCV 2022 \\\n[5] Chen et al., Few-Shot Learning with Part Discovery and Augmentation from Unlabeled Images, IJCAI 2021"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1421/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700177302239,
                "cdate": 1700177302239,
                "tmdate": 1700177302239,
                "mdate": 1700177302239,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pPi9mP9HW6",
                "forum": "k9SVcrmXL8",
                "replyto": "kmYA8aFrnY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1421/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Last Remarks or Suggestions?"
                    },
                    "comment": {
                        "value": "Dear reviewer msQP,\n\nAs the author-reviewer engagement window is closing out soon, and since we haven not heard back from you, we wanted to make a kind follow up to see if our elaborate responses and revisions address all your concerns. Notably, our tremendous effort and active engagement with the other two reviewers have already led to an increase in their overall score. **We are determined to ensure that you are also fully satisfied with our work and its impact**. As such, we would be more than happy to provide further clarifications and revisions if you have any more questions or concerns, and if not we would greatly appreciate it if you please re-evaluate our paper's final score. \n\nThank you so much for all your constructive recommendations and insightful comments. \\\nAuthors"
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1421/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700686719982,
                "cdate": 1700686719982,
                "tmdate": 1700686719982,
                "mdate": 1700686719982,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]