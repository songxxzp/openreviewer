[
    {
        "title": "Incentive-Aware Federated Learning with Training-Time Model Rewards"
    },
    {
        "review": {
            "id": "K8b2W34Uje",
            "forum": "FlY7WQ2hWS",
            "replyto": "FlY7WQ2hWS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5535/Reviewer_EksS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5535/Reviewer_EksS"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes Incentive-Aware Federated Learning (IAFL), an FL algorithm which is generally applicable to varying measures of client contribution such as participation rate or local update steps. To incentive client contribution, IAFL takes a personalized FL approach where the server shares higher-quality model updates with clients with higher contribution. Additionally, the paper ensures that all clients, despite limited contribution, are able to reach the optimal model by stochastically synchronizing client models with a common reference model. The paper shows that IAFL outperforms various FL baselines in terms of IPR in several heterogeneous settings."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This work appears novel in the sense that it personalizes the outcome of each round to individual clients, whereas earlier approaches attempt to produce a single global model that is compatible with multiple clients' incentives.\n\nAs mentioned in the paper, it is applicable to settings where earlier incentive-aware FL works are not, such as partial participation and lack of server-side data."
                },
                "weaknesses": {
                    "value": "The behavior of IAFL is not clearly explained in the experiments. \n- What is client contribution here? Is it number of local updates? How is this set / varied across clients / time?\n- How is incentivization determined? Do you compare a locally trained model to the (fully trained) server model?\n\n6.1: \" We measure the performance of a model using the test loss and the test accuracy, denoting them as IPR_loss and IPR_accu, respectively.\" This doesn't make sense to me. Doesn't IPR_accu (Table 1) refer to the fraction of clients who are \"incentived\" to participate, and not an accuracy metric?\n\nBased on the results in Table 3 it is surprising to see that IAFL achieves much better accuracy than non-IR methods. However, shouldn't the other methods have an advantage when comparing raw accuracy, as they distribute a high-quality model to all clients without considering incentives? What exactly does this accuracy metric refer to?"
                },
                "questions": {
                    "value": "Reading through this paper, I assumed that client contribution is not being adjusted in response to the rewards. Please clarify if this is inaccurate.\n\nAssuming contribution is participation rate, wouldn't there already be a disadvantage to partial participation if the server broadcasts an update (rather than the updated model) to the participating clients, as the local model could become desynchronized? Or does the paper assume the server is sending an updated model?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5535/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5535/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5535/Reviewer_EksS"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5535/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698755789401,
            "cdate": 1698755789401,
            "tmdate": 1699636568023,
            "mdate": 1699636568023,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "q17wOffg8s",
                "forum": "FlY7WQ2hWS",
                "replyto": "K8b2W34Uje",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the reviews (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for taking the time to review our paper and for recognizing our novel work that personalizes client model outcomes that are compatible with client incentives.\n\nWe earnestly hope addressing the concerns as follows will improve your opinion of our work.\n\n>W1(a): \"What is client contribution here\" and \"How is this set/varied across clients/time?\"\n\nTo clarify the experimental settings, as described in Section 6.1, one way to measure client contribution is to \"use standalone accuracies as a surrogate for the client contributions in FL\". In this way, the client contributions vary across clients.\n\nAs an alternative way to measure client contribution, we also adopted CGSV (Xu et al., 2021) as the contribution measure in Appendix E.8. For CGSV, it not only considers variances of contribution values across clients, but also takes into account the changes occurring over time or iteration steps.\n\n>W1(b): \"How is incentivization determined? Do you compare a locally trained model to the (fully trained) server model?\"\n\nTo clarify the metrics that we use to evaluate incentivization performance, we carefully utilize three distinct metrics covering different aspects of desired behaviors of IAFL in experiments. They are (1) incentivized participation rate (IPR), (2) correlation to contribution $\\rho$, and (3) average/highest predictive performance. These three metrics are described in detail and thoroughly studied in Section 6.1. We do not compare to the fully trained server model because IAFL does not output any server global model.\n\nAs for the (fully trained) server model, it actually corresponds to the highest predictive performance (point 3 above). The tables of results are pushed to Table 5 of Appendix E.3 and Table 10 of Appendix E.9 due to space constraints. This is because the best client in our experimental setting receives the best model updates aggregated from all clients in all training iterations, therefore, the highest predictive performance corresponds to the (fully trained) server model.\n\n>W2: About \"IPR$_\\text{accu}$\"\n\nwe apologize for the confusion in the quoted sentence. We need to associate the sentence with the two sentences before it and hence refer the reviewer to the rephrased version here:\n\n\"We let IPR$\\_\\text{loss}$ be the percentage of clients receiving a model not worse than his standalone model in terms of the test loss. Likewise, We define IPR$\\_\\text{accu}$ but in terms of the test accuracy. Here, a standalone model refers to the model trained only with the client's local dataset. IPR therefore indicates IR (Definition 1).\""
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5535/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699973992414,
                "cdate": 1699973992414,
                "tmdate": 1699973992414,
                "mdate": 1699973992414,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oYZ7F2fT28",
                "forum": "FlY7WQ2hWS",
                "replyto": "K8b2W34Uje",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the reviews (2/2)"
                    },
                    "comment": {
                        "value": ">W3: About Table 3, \"better accuracy than non-IR methods\"\n\nThe \u201cacc.\u201d metric in Table 3 refers to \u201cPredictive performance\u201d explained in the corresponding paragraph in Section 6.1.\n\nNow, we explain the results in Table 3. Other baseline methods yield low accuracies as they neglect the individual rationality (IR) of clients in their design in achieving fairness and personalization goals. As seen in the table below,\n\n| Methods  | IPR$\\_\\text{accu}$ | acc. (highest) |\n| -------- | --------- | ------- |\n| FedAvg Finetune | 0.28 | 0.12 (0.16) |\n| LG\\-FedAvg      | 0.60 | 0.13 (0.15) |\n| CGSV            | 0.00 | 0.06 (0.07) |\n| Rank            | 0.94 | 0.24 (0.31) |\n| IAFL            | 1.00 | 0.44 (0.53) |\n\nthe incentivized participation rates (IPR) achieved by baseline methods are low, indicating that the clients did not receive high-quality models (even lower than what they can achieve on their own), reflected as poor model performance in terms of predictive accuracies.\n\n>Q1: \"I assumed that client contribution is not being adjusted in response to the rewards\"\n\nGenerally speaking, in the same iteration, the rewards are adjusted in response to the current client contributions. However, provided that the contribution evaluation measure uses models at previous iterations, it is possible that iterative contribution measurements are affected by previous reward models. For example, when using CGSV (Xu et al., 2021), since CGSV measures contribution iteratively, the reward model $\\theta_{i,t}$ of iteration $t$ could affect the gradient updates and thus contributions $p_{i,t+1}$ of the next iteration $t+1$.\n\n>Q2: \"partial participation\" $\\rightarrow$ \"disadvantageous\" since \"the local model could become desynchronized?\"\n\nTo clarify, we assume that clients are always available to receive **model updates** of varying quality commensurate to their contributions (not an updated model) from the server in all training iterations, and the participation rate only reflects the client's rate of computing and sending the local updates to the server. Therefore, the client model quality varies mainly because of the quality of the updates the server sends to the client depending on the client's contribution, rather than issues caused by synchronization.\n\nIn the event that it is impractical to assume the client's availability to receive model updates in every iteration, we can alternatively keep a database on the server side to store the cumulative model updates for clients until they become available.\n\n>To conclude\n\nWe hope that we have clarified the questions about the experimental setups, better explained the empirical results, and sufficiently addressed your concerns. We hope that we could improve your opinion about our paper."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5535/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699974078621,
                "cdate": 1699974078621,
                "tmdate": 1699974078621,
                "mdate": 1699974078621,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nd9X98GIjk",
                "forum": "FlY7WQ2hWS",
                "replyto": "K8b2W34Uje",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow-up"
                    },
                    "comment": {
                        "value": "Dear Reviewer EksS,\n\nThank you again for your time in reviewing our paper and for your particular interest in our experimental setups and empirical results.\n\nPlease let us know whether our replies have sufficiently addressed your concerns. We will be happy to engage further within the discussion period.\n\nBest regards,\n\nAuthors of Paper 5535"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5535/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700619608540,
                "cdate": 1700619608540,
                "tmdate": 1700619608540,
                "mdate": 1700619608540,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4b5lYB4HDR",
                "forum": "FlY7WQ2hWS",
                "replyto": "K8b2W34Uje",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A summary and kind reminder"
                    },
                    "comment": {
                        "value": "Dear Reviewer EksS,\n\nThank you again for your time in reviewing our paper. In the rebuttal, we have made the following major clarifications to your questions:\n\n- We clarified the determination of client contributions and metrics for client incentivization in the experimental setting that aligns with your suggestion.\n- We rephrased the defition of IPR$_\\text{accu}$ to clear the unintended confusion.\n- We explained for the results in Table 3.\n- We clarified our experimental settings for the case of partial participation.\n\n\nAs today is the last day of the discussion period, please let us know whether our replies have sufficiently addressed your concerns. We will be happy to engage further within the discussion period.\n\nBest regards,\n\nAuthors of Paper 5535"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5535/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700707403372,
                "cdate": 1700707403372,
                "tmdate": 1700707403372,
                "mdate": 1700707403372,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ofVi4ET1qO",
            "forum": "FlY7WQ2hWS",
            "replyto": "FlY7WQ2hWS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5535/Reviewer_xzxw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5535/Reviewer_xzxw"
            ],
            "content": {
                "summary": {
                    "value": "In federated learning, each client contributes the gradient updates computed with its own local data and then shared with the center. The center aggregates the updates from clients to update the model, and then share the model to the clients to start the next round. In this process, selfish clients may get the most up-to-date model by free-riding, and hence hurt the overall performance of the system. Prior work proposes to incentivize the clients with monetary transfers, while this work focuses on designing an incentive mechanism to share the model in a way such that the more a client contributes, the better model it will receive.\n\nThe proposed mechanism includes two key features to incentive each client to contribute more:\n* Sharing the model updates from a subset of the other clients, the size of the subset is proportional to this client\u2019s contribution;\n* With some probability, give the client the most up-to-date model to prevent the client\u2019s local model being too off.\n\nTheoretical results:\n* All clients have strictly positive incentive to contribute more\n* Each client is better off to participate in the federated learning (individually rational)\n* The bound on the performance loss of the client models (against the optimal benchmark not suffering from any free-ride challenge), which converges to zero with additional assumptions.\n\nExperiments:\n* Partition training data to simulate the distributed data in the federated learning setting\n* Evaluate the percentage of clients where the IR condition is respected\n* Evaluate how the hyperparameters influence the performance of client models at different contribution levels."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* Very interesting idea to an important problem\n* Solid results"
                },
                "weaknesses": {
                    "value": "* The incentive guarantee is weak in the sense that only a positive incentive is guaranteed, which might not be enough when the clients do suffer certain costs to contribute more to the center. When the cost is higher than the incentive, one may still not contribute 100% effort in the federated learning.\n* The tradeoff between the strength of incentive and the loss of (center) model accuracy is not established, which might be more important in practice. In particular, if I understand correctly, this work assumes all clients contribute 100% of its effort given the constructed incentives. Hence the performance loss of the center model is considered as zero and not measured. However, I can see at least two reasons for the clients to not contribute at its full capacity:\n  * Contribution already exceeds the threshold parameter $p_\\mathsf{ceil}$\n  * When maintaining a certain level of incentive is necessary, one may have to limit the sharing of the gradients, i.e., sufficiently low $\\kappa$ and $q$. In this case, the performance loss of the center model should emerge as the client model might be quite off from the center model and lead to low quality of the gradient updates from local models.\n* I would suggest the authors to at least discuss the above limitations"
                },
                "questions": {
                    "value": "* What is the tradeoff between the strength of incentive and the loss of (center) model accuracy?\n* Is there a fairness concern that for small clients, even if they contribute to their best, they still cannot receive a high quality model? Yet the large clients only need to contribute above some threshold to receive the best model?\n* It seems to me that the small clients may have incentive to cooperate to pretend as one big client to receive a better model without a significant cost overhead? Will this lead to exchange platforms where one can first send their gradient updates to the platform, then the platform aggregates the gradient updates from many small clients together, and finally pretend as one big client to cheat in the proposed incentive mechanism? (maybe good to call out the limitation of incentive mechanisms without monetary transfers)"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5535/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5535/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5535/Reviewer_xzxw"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5535/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698814424373,
            "cdate": 1698814424373,
            "tmdate": 1699636567902,
            "mdate": 1699636567902,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pmSLYKKgDk",
                "forum": "FlY7WQ2hWS",
                "replyto": "ofVi4ET1qO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the reviews (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for taking the time to review our paper and for acknowledging the significance of the problem we studied and our solid results.\n\nWe hope addressing the concerns as follows will improve your opinion of our work.\n\n>W1: \"A positive incentive ... might not be enough\" with \"costs\", not \"100% effort\"\n\nWe indeed only have a relative guarantee for the proposed mechanism instead of absolute ones, i.e., clients have more incentives to contribute to IAFL as compared to FL.\n\nWe assumed that your \"positive incentive\" refers to **the increase in utility**. In our paper, the utility is defined as \"rewards minus costs\". Therefore, our incentives design already takes cost $c_i$ of client $i$ into consideration. With that, incentivizing clients to contribute 100% effort is indeed the most ideal, but might not be achievable because costs are incurred by the clients to contribute more. A more practical perspective we have adopted in the paper is that a client will increase his contribution to a point where the gradient of utility is 0, i.e., the increment in reward balances the increment in cost. More specifically, in Proposition 1, we measure the gradient of the utility w.r.t. contribution $p_i$ to determine the client contribution level and show that a practical incentive guarantee with the consideration of client costs.\n\n>W2 & Q1: \"Tradeoff between the strength of incentive and the loss of (center) model accuracy\"\n\nBy \"strength of incentives\", we assume you mean the **incentivization performance** in the paper. As for the \"loss of (center) model accuracy\", we understand it as the loss of client v.s. the (center) model, reflected as client model accuracies.\n\nThen, the two observations mentioned in the review align with our discussion in the paper in a slightly different form.\n\n- About \"$p_{ceil}$\"\n\nThe reviewer's comments on $p_{ceil}$ is valid. It is worth noting that we have discussed the issue in the paragraph after Equation (1):\n\u201cOne limitation of this design is that the clients lose incentive for $p_i > p_{ceil}$. The server can mitigate this by setting a high $p_{ceil}$ upper limit (to keep incentivizing high contributors) while setting a larger $\\kappa$ (to even out the fractions $(p_i/p_{ceil})^{1-\\kappa}$ towards 1 to motivate low contributors).\u201d Please let us know whether the discussion is sufficient.\n\n- About \"$\\kappa$\" and \"$q$\"\n\nWe would like to stress the importance of $\\kappa$ and $q$ in the trade-off identified by the reviewer. We have discussed them in Section 6.1 of the main paper and we additionally have a dedicated section Appendix E.7 to discuss the **trade-off between model performance and client incentivization** (directly affected by $\\kappa$ and $q$). In essence, decreasing $\\kappa$ and $q$ results in stronger incentives. When the strength of incentives is stronger, we have higher incentivization performance (measured as IPR and $\\rho$ defined in the paper) and lower client model accuracies (equivalent to higher loss of model accuracy).\n\nIn summary, we have established the trade-off in another form in the paper, which can relate to the loss of center model and strength of incentives trade-off. We will add this discussion to the revised paper."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5535/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699973449838,
                "cdate": 1699973449838,
                "tmdate": 1699973449838,
                "mdate": 1699973449838,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BNSAwaH8fU",
                "forum": "FlY7WQ2hWS",
                "replyto": "ofVi4ET1qO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the reviews (2/2)"
                    },
                    "comment": {
                        "value": ">Q2: \"Fairness concern for small and large clients\"\n\nThere are two prevalent concepts of fairness in literature: (a) collaborative fairness [1] (i.e., contribute more get back more), and (b) equality [2]. To be fair, people from one of the camps will not view the other as fair.\n\nIn our paper, we have demonstrated results for the collaborative fairness view. Specifically, the contributions of clients are fairly evaluated by a contribution evaluation measure, e.g., CGSV (Xu et al., 2021), and then used to fairly reward the clients with a model that has performance commensurate with their contributions.\n\nIf the designer of the FL process views fairness more towards equality such that \"if everyone puts in their best efforts, they should be treated equally\", it is possible to use \"individual efforts percentage\" (e.g., how many percentages a client contributes to his/her best effort, as suggested by the reviewer) as a contribution evaluation measure (assuming that individual efforts of clients can be measured). This measure can be seamlessly combined with the IAFL framework, too. However, we would like to clarify that \"individual efforts percentage\" is not commonly used as a contribution measure in literature.\n\nThank you for the interesting insights and unique perspectives.\n\nReferences:\n\n[1] L. Lyu, X. Xu, Q. Wang, and H. Yu. Collaborative fairness in federated learning. In Q. Yang, L. Fan, and H. Yu, editors, Federated Learning, volume 12500 of Lecture Notes in Computer Science, pages 189\u2013204. Springer, Cham, 2020.\n\n[2] T. Li, M. Sanjabi, A. Beirami, and V. Smith. Fair resource allocation in federated learning. In Proc. ICLR, 2020.\n\n>Q3: \"Small clients may have the incentive to cooperate to pretend as one big client to receive a better model\"\n\nOur framework does not cater to the scenario raised by the reviewer and it may require further work to incorporate this.\n\nWithout further assumptions (e.g., there are clients who are not self-interested, the clients have easy access to the platform, etc.), it will be challenging to establish these platforms. Questions will arise: How will the participants of the platform split the rewards? Is the platform solely non-profit seeking? One may argue that such a platform does not require friendly clients to work together. However, if the participants are indeed self-interested, setting up such a platform reduces to our self-interested problem setting to begin with.\n\nWe acknowledge the validity of the useful point raised by the reviewer and anticipate further investigation in future work.\n\n>To conclude\n\nTo conclude, we would like to thank the reviewer for the interesting insights and perspectives. We will include the necessary contents discussed in the revised paper and hope that our clarifications have improved your opinion about our work."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5535/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699973527977,
                "cdate": 1699973527977,
                "tmdate": 1699973527977,
                "mdate": 1699973527977,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pd5CASovfJ",
                "forum": "FlY7WQ2hWS",
                "replyto": "ofVi4ET1qO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow-up"
                    },
                    "comment": {
                        "value": "Dear Reviewer xzxw,\n\nThank you again for your time in reviewing our paper and for the interesting insights and perspectives with regard to our work.\n\nPlease let us know whether our replies have sufficiently addressed your concerns. We will be happy to engage further within the discussion period.\n\nBest regards,\n\nAuthors of Paper 5535"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5535/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700619383353,
                "cdate": 1700619383353,
                "tmdate": 1700619383353,
                "mdate": 1700619383353,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0UmZpxkyVR",
                "forum": "FlY7WQ2hWS",
                "replyto": "ofVi4ET1qO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A summary and kind reminder"
                    },
                    "comment": {
                        "value": "Dear Reviewer xzxw,\n\nThank you again for your time in reviewing our paper. In the rebuttal, we have made the following major clarifications to your questions:\n\n- We have a relative guarantee for the proposed mechanism which already considers the role of costs in the client incentives.\n- The trade-off between incentivization and model performance is discussed in the paper in a slightly different form.\n- The paper demonstrated fairness results for the collaborative fairness view.\n\nAs today is the last day of the discussion period, please let us know whether our replies have sufficiently addressed your concerns. We will be happy to engage further within the discussion period.\n\nBest regards,\n\nAuthors of Paper 5535"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5535/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700707342814,
                "cdate": 1700707342814,
                "tmdate": 1700707342814,
                "mdate": 1700707342814,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8XBnpo1O4s",
            "forum": "FlY7WQ2hWS",
            "replyto": "FlY7WQ2hWS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5535/Reviewer_dsGp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5535/Reviewer_dsGp"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes an incentive-aware federated learning algorithm that encourages client contribution by training-time rewards. Concretely, the authors propose a local reward scheme to ensure that a higher-contributing client receives a better final model."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The scope of the experiment is extensive. The authors experiment with different data partition methods, different metrics for measuring incentives, and benchmark against various baselines."
                },
                "weaknesses": {
                    "value": "See questions."
                },
                "questions": {
                    "value": "The problem this paper studies is interesting. However, it could be that I'm missing something, in Theorem 1 and Theorem 2, does convergence speed become faster as the number of agents $N$ grows? It would be helpful to simplify the bound and make the dependence on $N$ explicit. Does adding more clients lead to a faster convergence rate? I would happily increase my score if the question is addressed."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5535/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699022610925,
            "cdate": 1699022610925,
            "tmdate": 1699636567803,
            "mdate": 1699636567803,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "g3EfQ0u123",
                "forum": "FlY7WQ2hWS",
                "replyto": "8XBnpo1O4s",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the reviews"
                    },
                    "comment": {
                        "value": "We greatly appreciate the reviewer's time and effort in providing constructive feedback on our paper, and we are encouraged by the high scores assigned to the soundness and presentation of our paper. We are also delighted to see that our scope of experiments is extensive.\n\nWe hope that our responses to your concerns as follows will further enhance your perception of our work.\n\n>Q1: \"Does convergence speed become faster as the number of agents $N$ grows?\"\n\nThe simple answer is, adding clients that **\"help than hurt\"** is going to improve the convergence speed.\n\nTo elaborate, we first observe that it might be difficult to further simplify the bound because it has a dependence on every single client's contribution $\\gamma_{m,t}'$ for $m \\in [N]$. However, we can derive some insights on the convergence speed as $N$ grows.\n\nThe effect depends on the **contribution levels of the clients**.\nWe can look at the term $C_T = \\frac{H_T}{N} \\sum_{m=1}^N \\sum_{t=1}^{T} \\left(\\frac{T+\\alpha}{t+\\alpha}\\right)^2 \\left(\\frac{1}{\\gamma_{m,t}'} + \\frac{1}{\\gamma_{i,t}'} -2 \\right)$, when $N$ increases, the denominator becomes bigger but at the same time there are additional terms in the summation.\n\nWe can consider a case where we increase $N=n$ to $N=n+1$. Abstracting away the constants $H_T$, $T$ and $\\alpha$ for simplicity, we can make a comparison for $C_T = \\frac{1}{n} \\sum_{m=1}^{n} \\left(\\frac{1}{\\gamma_{m,t}'} + \\frac{1}{\\gamma_{i,t}'} - 2 \\right)$ when $N=n$ against the case for $C_T = \\frac{1}{n+1} \\sum_{m=1}^{n+1} \\left(\\frac{1}{\\gamma_{m,t}'} + \\frac{1}{\\gamma_{i,t}'} - 2\\right)$ when $N=n+1$. Note that $\\gamma_{i,t}'$ can also be treated as a constant here.\n\nInformally speaking, we observe that when $N$ increases, the term $C_T$ generally decreases in its scale if the added client has contribution $\\gamma_{m,t}'$ at least the **\u201caverage contribution\u201d** of the existing clients $\\frac{1}{n} \\sum_{m=1}^{n} \\gamma_{m,t}'$. Therefore, the decrease in $C_T$ tightens the performance bound in Theorem 1 and makes the convergence faster.\n\nAn exception that we can derive from the above is that when the added clients contribute badly with a very low $\\gamma_{m,t}'$, it could slow down the convergence despite the increase in $N$. In practice, this implies that the model update provided by the added client is bad, harmful, or even adversarial, and is detected by the contribution evaluation measure. Theoretically, the convergence is adversely affected if we add \"harmful\" clients. However, we could easily implement client selection methods based on this insight on contribution evaluation to filter such clients during the training process to ensure faster convergence when $N$ grows.\n\nConcluding, we hope our discussion above about the impact of $N$ on convergence speed will improve your opinion about our work."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5535/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699973354834,
                "cdate": 1699973354834,
                "tmdate": 1700426093126,
                "mdate": 1700426093126,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "U4SPeoYc92",
                "forum": "FlY7WQ2hWS",
                "replyto": "8XBnpo1O4s",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow-up"
                    },
                    "comment": {
                        "value": "Dear Reviewer dsGp,\n\nThank you again for your time in reviewing our paper and for asking an insightful question about the convergence speed with respect to the number of clients.\n\nPlease let us know whether our replies have sufficiently addressed your concerns. We will be happy to engage further within the discussion period.\n\nBest regards,\n\nAuthors of Paper 5535"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5535/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700619198261,
                "cdate": 1700619198261,
                "tmdate": 1700619198261,
                "mdate": 1700619198261,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DETBmJGbMr",
                "forum": "FlY7WQ2hWS",
                "replyto": "8XBnpo1O4s",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A summary and kind reminder"
                    },
                    "comment": {
                        "value": "Dear Reviewer dsGp,\n\nThank you again for your time in reviewing our paper. In the rebuttal, we have made the following major clarifications to your questions:\n\n- The convergence speed can relate well with the number of agents. Adding clients that \"help than hurt\" is going to improve the convergence speed. We also provide detailed case studies in the response above.\n\nAs today is the last day of the discussion period, please let us know whether our replies have sufficiently addressed your concerns. We will be happy to engage further within the discussion period.\n\nBest regards,\n\nAuthors of Paper 5535"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5535/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700707288975,
                "cdate": 1700707288975,
                "tmdate": 1700707288975,
                "mdate": 1700707288975,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wXZcV47Y45",
            "forum": "FlY7WQ2hWS",
            "replyto": "FlY7WQ2hWS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5535/Reviewer_LXR6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5535/Reviewer_LXR6"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies incentive mechanism for federated learning. Existing works in this direction typically incentive clients via post-training monetary rewards. The authors argue that, clients may anticipate timely rewards during FL process, and may decide to quit when not being properly incentivized. Moreover, monetary rewards may be infeasible in some situations, e.g., when revenue is unclear or budget is limited. Therefore, the authors propose a new formulation, where the clients are reward during the FL process in the form of global model updates of varying quality, depending on the contribution of each client. The authors derive a convergence guarantee of the proposed method, where the convergence rate of each client depends on its reward rate $\\gamma_{i,t}$."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The idea of providing incentives during the FL process instead of postponing to the end of FL is novel and well-motivated."
                },
                "weaknesses": {
                    "value": "1. What it means for a client to be incentivized is not well-defined in this paper.\n\nFrom Proposition 1, it seems as long as the gradient of client $i$'s utility w.r.t. its contribution $p_{i}$ is higher than that under standard FL mechanism, we say the client $i$ is incentivized. It is not clear why we, as the designer of the mechanism, cares about whether the gradient of utility for each client is higher than what the client gets under a standard FL mechanism. Instead, a more natural goal is to incentivize the clients to contribute to FL using their full capacity in order to get the best learning outcome. \n\nIn this regard, the intrinsic cost $c_{i}$ of each client also plays an important role, i.e., it is possible that the cost value is high, such that we end up with a negative gradient of the utility (contributing more leads to even lower utility). Therefore, a rational client will decide to contribute $p=0$ in this case, which affects the convergence of the FL process.\n\n2. Current convergence analysis over-simplifies the effect of contribution level on local gradients\n\nDue to the simplification of the \"contribution measurement\" mentioned in Section 4.2, the current convergence result given in Theorem 2 is independent from client's behavior model. Currently, the only place that contribution level of a client plays a role in the convergence result, is the reward rate $\\gamma_{i,t}$ (the quality of the global model that the server decides to give to this client). However, the contribution level should also affect the quality of the local gradient that client provides to the server, e.g., lower contribution means computing the local gradient using smaller portion of its local data (Other than simply saying the client will always faithfully compute the full local gradient w.r.t. the given global model). \n\nIn the extreme case mentioned in my first comment, where the client decides to make zero contribution, then the server will not get the local gradient from this client. However, in the current analysis, the authors assume that the server can always get the local gradients of all the clients no matter what, which does not seem to be reasonable."
                },
                "questions": {
                    "value": "Can the authors elaborate on, in Theorem 1, why $o(1/\\gamma_{i,T}^{\\prime})$ suffices to make the convergence hold? Where did the $(T+\\alpha)^{2}$ in the numerator go?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5535/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699150460083,
            "cdate": 1699150460083,
            "tmdate": 1699636567708,
            "mdate": 1699636567708,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ciaEcySEOu",
                "forum": "FlY7WQ2hWS",
                "replyto": "wXZcV47Y45",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the reviews (1/2)"
                    },
                    "comment": {
                        "value": "We would like to express our gratitude to the reviewer for taking the time to review our paper and for acknowledging that our training-time incentive during FL is novel and well-motivated.\n\nWe hope addressing the raised concerns as follows will improve your opinion of our work.\n\n>W1(a): \"What it means for a client to be incentivized\"\n\nIn game theory, incentives are typically based on the potential for gaining a benefit or circumventing a cost. Consequently, a rational client is incentivized to perform an action when there is a positive gain in utility for doing so. We formalize this as Individual Rationality (IR) in Definition 1, implying that clients are incentivized to participate in our IAFL scheme, because every client will receive a reward at least as good as what they can achieve on their own. IR is an established concept for player incentivization in game theory.\n\n>W1(b): \"A more natural goal is to incentivize the clients to contribute to FL using their full capacity\"\n\nIncentivizing clients to contribute to the \"full capacity\" for the best learning outcome is indeed the most ideal, like the reviewer has said. However, every client incurs costs to contribute and the actual contribution of clients depends on the interplay between rewards and costs for different contribution levels.\n\nHence, in our work, we propose the next achievable alternative: To incorporate the goal of **\"incentivizing clients to contribute as much as possible\"** on top of satisfying IR. To this end, we designed IAFL such that Theorem 1 and 2 are fulfilled. These theorems suggest that clients will be rewarded with better models if they contribute more. This will incentivize clients to further contribute to their full capacity for improved model performance received, of course, subject to their marginal utility increment in the presence of a cost $c_i$. Clients will contribute up till the marginal increment in reward still surpasses the associated cost.\n\nThis is **important to the FL designer** because higher contributions from clients (e.g., in the form of better gradient updates, more frequent participation, etc.) could potentially lead to improved model performance for all clients (i.e., a better learning outcome).\n\n>W1(c): \"The intrinsic cost $c_i$ of each client also plays an important role\"\n\nThe reviewers' observations regarding the critical role of $c_i$ are indeed accurate. As specified by Proposition 1, in the presence of a cost $c_i$, our IAFL incentivizes more than the standard FL.\n\nWhen $c_i$ is indeed high, our IAFL is still better than standard FL, since this cost is borne by both IAFL and standard FL. A client with a high cost $c_i$ will not participate in either IAFL or standard FL. Likewise, in the event of a strictly $p=0$ contribution, we can simply leave the client out of the collaboration to avoid detrimental effects on collaborative model training and convergence. Alternatively, the sharing parameter $\\kappa$ presented in Equation (1) of the paper could be raised to enhance the convergence of the client models.\n\nTherefore, this weakness is not exclusive to our framework, and notably, our IAFL even offers potential remedies. In practice, if a rational client finds it possible to benefit from standard FL, they will definitely benefit more from our framework. Hence, our framework is deemed reasonable."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5535/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699973095837,
                "cdate": 1699973095837,
                "tmdate": 1699973095837,
                "mdate": 1699973095837,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gbJjYVL5Kr",
                "forum": "FlY7WQ2hWS",
                "replyto": "wXZcV47Y45",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the reviews (2/2)"
                    },
                    "comment": {
                        "value": ">W2(a): \"Current convergence result is independent from client's behavior model\" and \"the contribution level should also affect the quality of the local gradient\"\n\nThe contribution measures we refer to in Section 4.2 captures the quality of the local gradient as contributions, e.g., FedSV (Wang et al., 2020b), ComFedSV (Fan et al., 2022), CGSV (Xu et al., 2021), FedFAIM (Shi et al., 2022).\n\nThus, the relationship might need to be turned the other way around. The client's behavior model decides the quality of the local gradient being computed (e.g., using different portions of its local data). Then, the quality of the local gradient affects the client contribution level (as assessed by the contribution evaluation measures mentioned above), which in turn affects the reward rate in IAFL. Subsequently, the reward rates of clients affect the model convergence.\n\nHence, the current convergence results capture the client's decision on the contribution level through deciding the quality of their local gradients.\n\n>W2(b): \"Other than simply saying the client will always faithfully compute the full local gradient\"\n\nIn the current analysis, we hope to clarify that we do not place an assumption on what kind of gradients we can obtain from the clients. We do not assume that clients faithfully compute and upload the full local gradients.\n\n>W2(c): \"Extreme case\" about \"zero contribution\"\n\nIf a client decides to make zero contribution, this will be **captured by the contribution evaluation measure**. Then, the client does not need to upload gradients and it will not affect our IAFL algorithm.\n\nThis is a simple fix for people with zero contribution: If the client is withdrawing, he/she should not be in the analysis to begin with. As a result, the extreme case does not affect the current analysis. We would like to thank the reviewer for the insightful observation, we will add a discussion on this matter in the revised paper.\n\n>Q1: \"Why $o(1/\\gamma_{i,T}')$ suffices to make the convergence hold\" and \"where did the $(T+\\alpha)^2$ go\"\n\n\nWe are sorry that there is an unintentional typo that occurred while organizing the formula to make it more concise, the term $T^2$ was accidentally omitted.\n\nReferring to the paragraph on \"error propagation and non-convergence\", instead of $(H_T/T)\\sum_{t=1}^T 1/t^2=O(T)$, it should be $(H_T/T)\\sum_{t=1}^T T^2/t^2=O(T)$.\n\nWith $H_T T^2/T = H_T T = O(T)$ and $1/{\\gamma_{i,T}'}= o(1/T)$, they are jointly required for the convergence to 0. This typo does not affect any theoretical results in Theorem 1 or any subsequent theoretical results, and we hope to seek understanding from the reviewer for any unintentional confusion caused.\n\n> To conclude\n\nOverall, we hope that we have convinced you that our framework is reasonable. By clarifying the misunderstandings, the issues about (1) the incentivization goal and (2) the effect of client contribution on the convergence should have been resolved.\n\nWe really hope that we have addressed your concerns and improved your opinion of our work."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5535/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699973227474,
                "cdate": 1699973227474,
                "tmdate": 1699973227474,
                "mdate": 1699973227474,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WGUDt8AUOx",
                "forum": "FlY7WQ2hWS",
                "replyto": "wXZcV47Y45",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow-up"
                    },
                    "comment": {
                        "value": "Dear Reviewer LXR6,\n\nThank you again for your time in reviewing our paper and for asking many insightful questions.\n\nPlease let us know whether our replies have sufficiently addressed your concerns. We will be happy to engage further within the discussion period.\n\nBest regards,\n\nAuthors of Paper 5535"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5535/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700618830138,
                "cdate": 1700618830138,
                "tmdate": 1700618830138,
                "mdate": 1700618830138,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gVcAGI0HFS",
                "forum": "FlY7WQ2hWS",
                "replyto": "wXZcV47Y45",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5535/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A summary and kind reminder"
                    },
                    "comment": {
                        "value": "Dear Reviewer LXR6,\n\nThank you again for your time in reviewing our paper. In the rebuttal, we have made the following major clarifications to your questions:\n\n- The goal of incentivization is already defined and discussed with the consideration of client costs in the paper. We adopt the next most pragmatic goal of \"incentivizing clients to contribute as much as possible\" on top of satisfying IR.\n- Our current convergence analysis captures the client's decision on the contribution level through deciding the quality of their local gradients, hence affecting the model convergence.\n\n\nAs today is the last day of the discussion period, please let us know whether our replies have sufficiently addressed your concerns. We will be happy to engage further within the discussion period.\n\nBest regards,\n\nAuthors of Paper 5535"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5535/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700707244762,
                "cdate": 1700707244762,
                "tmdate": 1700707244762,
                "mdate": 1700707244762,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]