[
    {
        "title": "GraphMaker: Can Diffusion Models Generate Large Attributed Graphs?"
    },
    {
        "review": {
            "id": "74WlUIWVYg",
            "forum": "ledQ1BCrwc",
            "replyto": "ledQ1BCrwc",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5919/Reviewer_4wGq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5919/Reviewer_4wGq"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a diffusion-based graph generative model which aims to learn a distribution of a *large, attributed* graph from a single sample. This differs from past work in that other diffusion-based graph generative models either learn (1) a distribution of a small, attributed  graph from many samples (such as molecules) or (2) a distribution of a large unattributed graph from a single sample. The authors argue that learning a large graph from a single sample is plausible because the nodes are statistically exchangable, thus the joint distribution of nodes can be effectively learned in this setting (logic which also underlies classical graph statistical models such as the SBM)\n\nThe authors propose GraphMaker, a denoising model learned from a sequence of data corruptions that are applied to the adjacency matrix and attribute matrix. GraphMaker-Sync denoises the adjacencies and attributes simultaneously, while GraphMaker-Async denoises the adjacencies after the attributes have been denoised.\n\nThe authors propose three evaluation aspects for their approach and competitors:\n\n1) Graph property: how well do graph/attribute measures computed on the generated graph match the same measures on the source data\n\n2) Discriminative: how well does a GNN trained on the generated graph perform on the source data\n\n3) Benchmarking: how closely does the *rank* of GNN models benchmarked on the generated graph compare to the same ranks on the source data."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The main strength of this paper is that there are few graph generative models that can learn attributed-graph distributions in the large-graph setting. The only existing one (that I know of, which the authors cite) is Yoon et al. 2023 and appears to not actually generate the whole graph, but rather only batch-level training samples of rooted trees on which GNNs can be trained effectively. The fact that GraphMaker can generate a real graph sample with attributes at the same scale as the input data makes it a valuable contribution to the community."
                },
                "weaknesses": {
                    "value": "The main weakness of the paper is that the empirical results show that the proposed method only marginally outperforms the SBM in the evaluation aspects (graph property, discriminative, benchmarking). While the GraphMaker graphs seem to match graph statistics slightly better (in aggregate), and also better align ranks in benchmarking, the discriminative aspect (Table 2) shows that GNN models trained on synthetic graphs from GraphMaker vs those from SBM do about the same when trained on the source data.\n\nThe fact that SBM is a powerful baseline is interesting, and could be due to a number of factors:\n\n(1) the graphs used in the empirical study are too homophilous, and thus the label-conditioning aspect of GraphMaker could essentially be copying what the SBM is already doing.\n\n(2) GraphMaker's noise injection is uniform over all edges / attribute dimensions: this could be too simple to go beyond the i.i.d. edge generation of SBM.\n\nA related weakness is that the authors did not benchmark against the EDGE graph diffusion model (Chen et al. 2023), which would be an interesting baseline alongside the SBM, which similarly does not generate the attributes.\n\nI elaborate on the above in my questions to the authors."
                },
                "questions": {
                    "value": "Q1: Did you consider benchmarking on datasets that have less edge/attribute-level homophily? We should expect the performance of SBM to go down in this case, but potentially not for GraphMaker.\n\nQ2: Why not include EDGE + attribute diffusion as a baseline, as you did for SBM and other graph-only models? I think the relative contribution of this work is hard to assess without this comparison.\n\nQ3: From the description in Section 3.5, I cannot understand what GraphMaker-E is doing, and how it differs from GraphMaker-Async. Can you elaborate?\n\nI am willing to raise my score if the authors can provide more info along these lines."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5919/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698190785152,
            "cdate": 1698190785152,
            "tmdate": 1699636629431,
            "mdate": 1699636629431,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "J3WTphHSNp",
                "forum": "ledQ1BCrwc",
                "replyto": "74WlUIWVYg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5919/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5919/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 4wGq"
                    },
                    "comment": {
                        "value": "We highly appreciate your detailed and insightful feedback. We address the individual questions as follows.\n\n> 1. The manuscript presents an evaluation that examines how well models trained on the generated training data align with the models trained on the original training data, when applied to the original test data. The evaluation result shows that stochastic block model (SBM), when equipped with the empirical distribution computed from the original data $P(Y)\\prod_v\\prod_f P(X_{v, f} | Y_v)$, is a strong baseline. The proposed GraphMaker models only marginally outperform SBM. One possible explanation is that the graphs used in the empirical study are too homophilous, and thus the label-conditioning mechanism of GraphMaker could be essentially learning inter-cluster and intra-cluster edge densities employed by SBM. A natural question is then if the authors considered benchmarking on less homophilous graphs, where GraphMaker is more likely to have an edge in performance.\n\nThis is indeed a critical insight. Various homophily measures have been developed to measure the similarity between nodes and their neighbors in a graph [1-3], in particular the proportion of nodes that have the same label as their neighbors. These papers have pointed out that Cora and Citeseer are highly homophilous, and it\u2019s likely that Amazon Photo and Amazon Computer also have this issue. When we apply SBM to such graphs, with high probability the generated nodes will be connected to neighbors that have the same label. In addition, the node attributes can also be approximately conditionally independent of each other given the node label, as shown in Table 8 in the Appendix. These two factors may explain the competitive performance achieved by SBM for MPNNs, which perform localized smoothing.\n\nWe agree that more heterophilous datasets with more complicated attribute, label, and structure correlations can be better testbeds. We plan to include such datasets in the next version of the paper.\n\n> 2. Lack of performance comparison against recent diffusion-based graph generative models like EDGE \n\nAs mentioned in the above unified response, we agree that a direct comparison will help us better understand the strengths and limitations of the proposed model. We plan to include some previous diffusion-based graph generative models as additional baselines in the next version of the manuscript.\n\n> 3. What is GraphMaker-E doing? How does it differ from GraphMaker-Async?\n\nWe apologize for not well articulating the presentation for this variant. As elaborated in the above unified response, we replace the trained attribute diffusion model with $P(Y)\\prod_v\\prod_f P(X_{v, f} | Y_v)$, the empirical distributions computed from the original data, as explained in section 4.1. This allows a direct comparison of the structure generation capability of GraphMaker against baselines without attribute generation capability.\n\n[1] Pei et al. Geom-GCN: Geometric Graph Convolutional Networks.\n\n[2] Zhu et al. Beyond Homophily in Graph Neural Networks: Current Limitations and Effective Designs.\n\n[3] Lim et al. Large Scale Learning on Non-Homophilous Graphs: New Benchmarks and Strong Simple Methods."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700202922343,
                "cdate": 1700202922343,
                "tmdate": 1700202922343,
                "mdate": 1700202922343,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BfeuV3Is44",
                "forum": "ledQ1BCrwc",
                "replyto": "J3WTphHSNp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5919/Reviewer_4wGq"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5919/Reviewer_4wGq"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the time taken in your response. I would like to see the proposed edits to the paper actually implemented before raising my score. Please feel free to upload a revision."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700704386252,
                "cdate": 1700704386252,
                "tmdate": 1700704386252,
                "mdate": 1700704386252,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vt2A8ZAJk5",
            "forum": "ledQ1BCrwc",
            "replyto": "ledQ1BCrwc",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5919/Reviewer_muBL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5919/Reviewer_muBL"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents GraphMaker, a diffusion model for generating large attributed graphs. They presented three types of diffusion models that couple or decouple graph structure and node attribute generation, and that utilizes label conditions. Also, they present a new evaluation pipeline for graph generation."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. A neat figure to describe the method GraphMaker-Sync and GraphMaker-Async, which helps the easier understanding of the method.\n2. Presented a method for the generation of large attributed graphs given node labels."
                },
                "weaknesses": {
                    "value": "1. The task that predicts the node labels and edge existence given the node attributes is more like a link prediction task, not a graph generation task. Is there any specific reason or reference that defines the task as a graph generation task?\n2. What is the novelty of the proposed model? Diffusion-based graph generative models such as GDSS can also deal with attributed graphs. Also, for scalability, simple usage of MPNN for the encoder seems not to be a critical novelty point.\n3. Hard to understand Section 3.4. What does it mean to learn from a single graph? Is it right that the model trains from only one graph and generates many graphs that fit with the training graph? When do we need such circumstances in the real world practically?\n4. Lack of performance comparison for recent diffusion-based graph generative models such as GDSS, DiGress, and GraphARM. Need more recent baselines for the evaluation part."
                },
                "questions": {
                    "value": "1. What about the cases with only one type of node attribute like molecular graphs? Do we treat node attributes and node labels to be the same or GraphMaker cannot deal with it?\n2. What is the time complexity of GraphMaker? As the model is diffusion-based, it seems that the inference and training time may be long. How does GraphMaker benefit from large attributed graph generation? Hard to understand what a minibatch strategy is which is introduced in the introduction part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5919/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5919/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5919/Reviewer_muBL"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5919/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698812263262,
            "cdate": 1698812263262,
            "tmdate": 1699636629322,
            "mdate": 1699636629322,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "BFti2HwpQX",
                "forum": "ledQ1BCrwc",
                "replyto": "vt2A8ZAJk5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5919/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5919/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer muBL"
                    },
                    "comment": {
                        "value": "Again, we thank the reviewer for the efforts in providing valuable feedback. We address the individual questions as follows.\n\n> 1. What\u2019s the difference between link prediction and graph generation?\n\nLink prediction considers the scenario of inferring additional edges from an existing incomplete graph [1, 2]. In contrast, graph generation requires creating a graph from scratch without leveraging an existing incomplete graph [3, 4].\n\n> 2. What is the time complexity of GraphMaker for edge generation? What is the minibatch strategy introduced in the introduction part?\n\nGraphMaker first samples a noisy graph from the prior distribution, and then repeatedly refines it. At each timestep, it computes node representations with an MPNN, and then performs binary classification for all node pairs. This yields a time complexity of $O(TN^2)$, where $T$ is the number of diffusion steps and $N$ is the number of nodes. While this appears to be costly, we only need to perform node representation computation once per diffusion step, which can be used for all node pairs. Besides, binary classification for multiple node pairs given node representations can be performed in parallel. In addition, the optimal $T$ is less than 10 based on empirical studies. In terms of wall clock time, generating the largest graph (13K nodes) considered in the paper with the most costly GraphMaker model takes less than 10 minutes on an NVIDIA RTX A6000 GPU during inference.\n\nAnother issue is the space complexity of $O(N^2)$, which prevents us from performing binary classification for all node pairs at once on a single GPU. Hence we adopt the minibatch strategy. During training, we use a minibatch of node pairs for a gradient update. During inference, we generate the whole graph structure by iterating over minibatches of node pairs.\n\nFor larger graphs, we agree that $O(N^2)$ indeed will be problematic, and we may leverage methods for approximate nearest neighbor. For example, locality sensitive hashing [5] hashes similar data points into the same bucket with high probability, and therefore it avoids all pair comparisons.\n\n> 3. Lack of performance comparison against recent diffusion-based graph generative models\n\nAs mentioned in the above unified response, we agree that a direct comparison will help us better understand the strengths and limitations of the proposed model. We plan to include some previous diffusion-based graph generative models as additional baselines in the next version of the manuscript.\n\n> 4. What are the application scenarios of large attributed graph generation?\n\nAs mentioned in the above unified response, this task can benefit the understanding of attributed complex networks for network science and the sharing of sensitive networked data for public usage.\n\n[1] Liben-Nowell & Kleinberg. The Link Prediction Problem for Social Networks.\n\n[2] Zhang & Chen. Link Prediction Based on Graph Neural Networks.\n\n[3] You et al. GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models.\n\n[4] Yoon et al. Graph Generative Model for Benchmarking Graph Neural Networks. \n\n[5] Indyk & Motwani. Approximate nearest neighbors: towards removing the curse of dimensionality."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700202471288,
                "cdate": 1700202471288,
                "tmdate": 1700202471288,
                "mdate": 1700202471288,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "K5kMT9ELDU",
                "forum": "ledQ1BCrwc",
                "replyto": "BFti2HwpQX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5919/Reviewer_muBL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5919/Reviewer_muBL"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the kind response.\n\n Despite your kind responses, I still cannot fully understand the novelty of GraphMaker and its superiority compared to other diffusion-based graph generative models. For instance, the authors have not answered my question about the novelty of GraphMaker as other baselines such as GDSS generate attributed graphs with diffusion models. In addition, the authors simply answer that \u201cWhile these models may have various limitations for handling large attributed graphs\u201d without providing any time complexity analysis or performance analysis compared to other diffusion-based models. \n\n Moreover, I still cannot understand the exact setting that learns from a single graph. This seems similar to the setting of GVAE which provided the link prediction task as the node attributes are given and predicts the node labels and edge existence. However, the authors simply explain the difference between link prediction and graph generation, without enough explanation on why GraphMaker is targeting graph generation tasks. \n\nTherefore, I keep the score. Thank you for the detailed response again."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700458347950,
                "cdate": 1700458347950,
                "tmdate": 1700458347950,
                "mdate": 1700458347950,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "A5oBAQnJCC",
            "forum": "ledQ1BCrwc",
            "replyto": "ledQ1BCrwc",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5919/Reviewer_xCEF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5919/Reviewer_xCEF"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents GraphMaker, a new diffusion model proposed for creating large attributed graphs. Large-scale graphs with node attributes are crucial in real-world contexts like social and financial networks. Generating synthetic graphs that mirror real ones is essential in graph machine learning, especially when original data is confidential. While traditional graph generation models have limitations, recent diffusion models excel in specific areas but face challenges with large attributed graphs. It explores diffusion models focusing on the relationship between graph structure and node attributes and introduces techniques for scalability. The paper also offers a different evaluation method using models trained on synthetic data. Experiments demonstrate GraphMaker's proficiency in producing realistic and diverse large-attributed graphs for subsequent applications."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- S1. Generation of large attributed graph presents significant technical challenges that are worth investigation.\n\n- S2. Writing is generally clear, although there are some clarity or motivational issues (see W1 and W2). But overall, it is easy to read and follow.\n\n- S3. I like the evaluation methodology using ML models, which can be more expressive than traditional statistics, yet is general without requiring domain-specific knowledge."
                },
                "weaknesses": {
                    "value": "- W1. Some technical details are not clearly introduced, especially in 3.5. \n\nIt was only mentioned that \"which generates node attributes\nthrough an external approach conditioned on node labels.\" How does this external approach/node label conditioning work exactly? What kind of label is suitable for this purpose? How are these node labels related to Y in 3.2? \n\nThese are not clearly explained.\n\n- W2. Motivation of the decoupled approach is not well articulated, and the choice of the word \"decoupled\" is misleading.\n\nFirst, the explanation/motivation of why GraphMaker-Asyn is better is not laid out convincingly. From the experiments, the results are also quite mixed. Essentially, together with GraphMaker-E, there are three alternative versions proposed, but there are no clear insight on why each version plays to its strength in certain scenarios.\n\nSecondly, I think GraphMaker-Asyn is not really decoupled, as both edge and attribute generation are still trained together. \n\n- W3. What is the difference between node attributes and labels? In Section 2, both are defined as categorical.\n\n- W4. The application scenario of large attributed graph generation is unclear. Currently, generation of small graphs such as molecules are popular as they may potentially drive killer applications such as drug discovery."
                },
                "questions": {
                    "value": "See weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5919/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698975586511,
            "cdate": 1698975586511,
            "tmdate": 1699636629215,
            "mdate": 1699636629215,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HETgAYEJgq",
                "forum": "ledQ1BCrwc",
                "replyto": "A5oBAQnJCC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5919/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5919/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer xCEF"
                    },
                    "comment": {
                        "value": "Thank you so much for reviewing our paper and bringing valuable questions. We address the individual questions as follows.\n\n> 1. Motivation of the decoupled approach GraphMaker-Async is not well articulated. Besides, the choice of the word ``decoupled'' is misleading.\n\nWe provided a motivation for choosing GraphMaker-Async over GraphMaker-Sync from the perspective of edge dependency modeling in the above unified response.\n\nWe used the word ``decoupled'' as GraphMaker-Async consists of two subnetworks trained independently and once trained it first generates attributes and then edges conditioned on fixed attributes. We are open to other options if the reviewer has suggestions for better alternatives.\n\n> 2. What is the difference between node attributes and labels as both of them are categorical in section 2?\n\nThe confusion comes from the fact that one important application of our generative model is to generate and publish synthetic graphs without sharing the original data. ML models (such as Graph Neural Networks) can be trained over these synthetic graphs and are expected to achieve similar performance as those trained directly over the original graphs. To evaluate our model for this application, we adopted node classification and link prediction tasks as a proof of concept and considered the large-attributed graphs that are widely used for node classification tasks [1, 2]. The node labels defined by the node classification tasks are used as the conditional information in our generation process. It is true that distinguishing labels and attributes is often just an artifact, defined by an ML task, which is irrelevant to the data generation procedure. However, if a downstream ML task is given, using the labels as conditions may indeed help. In our case, we find that directly viewing the node label as a node attribute yields worse performance for more than 80% cases for the downstream node classification tasks as shown in section 4.4.  \n\n> 3. How are node attributes obtained for GraphMaker-E with an external approach conditioned on node labels?\n\nAs explained in the unified response, we leverage the empirical distribution $P(Y)\\prod_v\\prod_f P(X_{v, f} | Y_v)$ computed from the original data for the experiments in this paper. We agree it\u2019s better to mention it explicitly in 3.5 rather than 4.1.\n\n> 4. What is the application scenario of large attributed graph generation?\n\nAs elaborated in the first paragraph and unified response, firstly, large attributed graph generation can enhance the understanding of complex networks [3, 4]. Secondly, the generated graphs can be shared with the public in replacement of the original sensitive data while preserving data utility.\n\n[1] Kipf et al. Semi-Supervised Classification with Graph Convolutional Networks.\n\n[2] Shchur et al. Pitfalls of Graph Neural Network Evaluation.\n\n[3] Watts & Strogatz. Collective dynamics of \u2018small-world\u2019 networks.\n\n[4] Barab\u00e1si & Albert. Emergence of scaling in random networks."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700202175634,
                "cdate": 1700202175634,
                "tmdate": 1700202175634,
                "mdate": 1700202175634,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "faDzvUTqIJ",
                "forum": "ledQ1BCrwc",
                "replyto": "HETgAYEJgq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5919/Reviewer_xCEF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5919/Reviewer_xCEF"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "Thanks for the detailed response. I will weigh them carefully in the final review."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5919/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700314663783,
                "cdate": 1700314663783,
                "tmdate": 1700314663783,
                "mdate": 1700314663783,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]