[
    {
        "title": "GnnX-Bench: Unravelling the Utility of Perturbation-based GNN Explainers through In-depth Benchmarking"
    },
    {
        "review": {
            "id": "VecQTDftU0",
            "forum": "VJvbOSXRUq",
            "replyto": "VJvbOSXRUq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6942/Reviewer_aTj3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6942/Reviewer_aTj3"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a benchmarking study on perturbation-based explainability methods for GNNs and aims to evaluate a wide range of explainability techniques."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1\u3001This paper provides a detailed and comprehensive description of the existing explainers for GNNs and compares different explanation methods in a clear way. \n2\u3001This paper provides a large of experiments to evaluate algorithms for both factual and counterfactual reasoning explanation methods and considers the different perspectives that may affect the performance of the explanations including topology, model parameters, and model architectures.\n3\u3001The metrics for evaluating the explainers for GNNs are reasonable."
                },
                "weaknesses": {
                    "value": "1\u3001Whether adversarially adding the number of edges has an impact on the sufficiency of the factual explainers leading to different experimental results in Figure 2 or Table 4\n2\u3001Most experimental results do not seem to provide explanations about the experimental phenomena and comparisons of the advantages and disadvantages of different explanation methods. For example, why the stability of CF^2 has dropped significantly on the IMDB-B and AIDS datasets in Fig. 3.\n3\u3001For the experimental results of stability against topological noise, why are the GEM and SubgraphX not used.\n4\u3001There are differences between different factual explainers on different datasets. Is there a benchmark to select a proper explainers in practice."
                },
                "questions": {
                    "value": "Please see the weaknesses stated as above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6942/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6942/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6942/Reviewer_aTj3"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6942/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698453313105,
            "cdate": 1698453313105,
            "tmdate": 1700697378599,
            "mdate": 1700697378599,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gFlwZ0Tl2c",
                "forum": "VJvbOSXRUq",
                "replyto": "VecQTDftU0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6942/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6942/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer aTj3"
                    },
                    "comment": {
                        "value": "**Q1. Whether adversarially adding the number of edges has an impact on the sufficiency of the factual explainers leading to different experimental results in Figure 2 or Table 4.**\n\n*Response:* We have extended our stability experiments to more datasets for feature perturbation and adversarial attacks (Figures G and H, respectively). The behavior is similar to the topological noise attack explained in Section 4.2; the stability decays with the higher noise and inductive methods handle noise better than transductive.\n\nAs requested, we also provide a sufficiency score with explanations generated by the topological noise attack. The results are provided in Figure F. In summary, when the noise increases, the sufficiency drops for most cases, but not in all scenarios. This shows that despite the changes in the explanations caused by the noise, GNNs may still predict the same class under noisy conditions.\n\n\n **Q2. Most experimental results do not seem to provide explanations about the experimental phenomena and comparisons of the advantages and disadvantages of different explanation methods. For example, why the stability of CF^2 has dropped significantly on the IMDB-B and AIDS datasets in Fig. 3.**\n\n*Response:* We appreciate this feedback and now provide clear insights on trends observed across the experiments in the revised manuscript. CF^2 is a transductive method. This lies at the core of the trends observed. Specifically, transductive methods lack generalizable capability to unseen data. Furthermore, the stability is worse on denser datasets such as IMDB-B since due to the presence of more edges, the search space of explanation is larger. Transductive methods such as CF^2 and GNNExplainer witness higher deterioration in stability in such harder situations due to being transductive.\n\n**Q3. For the experimental results of stability against topological noise, why are the GEM and SubgraphX not used.**\n\n*Response:* We have updated Fig. 3 by adding GEM and SubgraphX. GEM has two-steps (distillation + generation) and one can add noise in any of these two steps. We have added noise before the distillation step, which makes it comparable to other methods. On the other hand, SubgraphX is time-consuming while providing subpar efficacy in terms of robustness compared to other explainers. For example, SubgraphX consumes $\\approx 26.5$ hours to run on 435 test graphs in the Mutagenicity dataset. The inclusion of GEM and SubgraphX in Fig. 3 does not affect our conclusions.\n\n**Q4. There are differences between different factual explainers on different datasets. Is there a benchmark to select a proper explainers in practice.**\n\n*Response:* This is an excellent question and is the ultimate objective of this study! The choice of the explainer depends on various factors and we make the following recommendations. We have now added a flowchart to help the user in selecting the most appropriate. This recommendation has now also been added as a flowchart (Fig. S in App. K). The same flowchart is presented in text below. We have added this discussion in the manuscript (App. K). We have also referred this discussion in the conclusions (Sec. 5).\n\n- For counter-factual reasoning, we recommend RCExplainer for graph classification and CF-GNNExplainer for node classification. \n- For factual reasoning, if the goal is to do node or graph classification, we need to first decide if we need an inductive reasoner or transductive. While an inductive reasoner is more suitable, we want to generalize to large volumes of unseen graphs, transductive is suitable for explaining single instances. In case of inductive, we recommend RCExplainer, while for transductive GNNExplainer stands out as the method of choice. These two algorithms had the highest sufficiency on average. In addition, RCExplainer displayed stability in the face of noise injection.  \n- For different task generalization beyond node and graph classification, one can consider using TAGExplainer.\n- In high-stakes applications, we recommend RCExplainer due to consistent results across different runs and robustness to noise.\n- If computation time is important, we recommend an inductive reasoner since they only involve a forward pass through the corresponding neural network. Transductive reasoners train the parameters on the input and hence is significantly slower in practice.\n\nWhile the above is a guideline, we emphasize that there is no one-size-fits-all benchmark for selecting the ideal explainer. The choice  depends on the characteristics of the application in hand and/or the dataset. The above flowchart takes these factors into account to streamline the decision process."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6942/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700257726678,
                "cdate": 1700257726678,
                "tmdate": 1700257726678,
                "mdate": 1700257726678,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yEoN0UcDca",
                "forum": "VJvbOSXRUq",
                "replyto": "2SsjHvkWIv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6942/Reviewer_aTj3"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6942/Reviewer_aTj3"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the detailed response"
                    },
                    "comment": {
                        "value": "Thanks for the detailed response and clarification of the authors. Part of my concerns have been addressed. Overall, I  will raise my score."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6942/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700697347962,
                "cdate": 1700697347962,
                "tmdate": 1700697347962,
                "mdate": 1700697347962,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "E5AjAGbDrr",
            "forum": "VJvbOSXRUq",
            "replyto": "VJvbOSXRUq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6942/Reviewer_ac1w"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6942/Reviewer_ac1w"
            ],
            "content": {
                "summary": {
                    "value": "This paper comprehensively studies the existing methods of explaining GNN predictors, including factual explainers and counterfactual explainers. The investigation is carried out in terms of stability, necessity/reproducibility, and feasibility for counterfactual explainers. And some conclusion of these investigations is obtained by extensive empirical evaluations."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "This paper investigates a critical problem of GNN predictors, that is the explainability pertaining to GNNs. Specifically, the counterfactual explanation is an important and meaningful explainer, which is worthy of studying. This paper fulfills the vacancy of the research on benchmarking it. The empirical evaluation is extensive and comprehensive. Therefore, the resulting conclusions from the experiments are solid and reliable."
                },
                "weaknesses": {
                    "value": "I believe there is some space for improvement in the paper's presentation. I suggest some important metrics, such as necessity and reproducibility can be expressed in mathematical equations. This can bring convenience for readers to understand the concepts."
                },
                "questions": {
                    "value": "The notations of A(G_s) in Equation 1 should be A(G').\nIn definition 2, the prediction of the perturbated graph is defined to be different from the counterpart of the original graph. I think this is valid for binary classification. For multi-classification problems, the counterfactual reasoning should be associated with a pre-assigned label.\nThe definitions of fidelity, necessity, and reproducibility seem to be vague. The fidelity in section 4 (under figure 2) is not clear, \"some works have used the term fidelity instead of sufficiency\" has no citations. The authors do not clearly give the definition of necessity and reproducibility and only give the intuition of these metrics (e.g. measures if ). This makes it difficult to figure out the metrics.\nThe measurement of feasibility which is defined as the number of connected graphs is somehow one-sided. Are there other measurements that can characterize the topological properties? And the relationship between defining the similarity with the topological properties of the test dataset and the feasibility measurement should be discussed and justified."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6942/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698851935793,
            "cdate": 1698851935793,
            "tmdate": 1699636809862,
            "mdate": 1699636809862,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xt3v3JM9p8",
                "forum": "VJvbOSXRUq",
                "replyto": "E5AjAGbDrr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6942/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6942/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ac1w: Part 1"
                    },
                    "comment": {
                        "value": "**Q1. I believe there is some space for improvement in the paper's presentation. I suggest some important metrics, such as necessity and reproducibility can be expressed in mathematical equations. This can bring convenience for readers to understand the concepts.**\n\nResponse: Thank you for this suggestion. We now define all metrics mathematically in Table 3 while discussing the metrics in Sec. 3 of the revised manuscript. The relevant metrics are reproduced verbatim below for easy access.\n\n$$\n    \\text{Sufficiency}(\\mathcal{S}) = \\frac{\\sum_{i=1}^{|\\mathbb{G}|} \\mathbb{1}(\\Phi({\\mathcal{G}_S^i}) = \\Phi(\\mathcal{G}^i))}{|\\mathbb{G}|}\n$$\n\n$$\n    \\text{Necessity}(\\mathcal{N}) = \\frac{\\sum_{i=1}^{|\\mathbb{G}|} \\mathbb{1}(\\Phi(\\mathcal{R}^i) \\neq \\Phi(\\mathcal{G}^i))}{|\\mathbb{G}|}\n$$\n\n$$\n    \\text{Stability}(\\mathcal{E}_X, \\mathcal{E}'_X) = \\frac{\\vert\\mathcal{E}_X\\cap\\mathcal{E}'_X\\vert}{\\vert\\mathcal{E}_X\\cup\\mathcal{E}'_X\\vert}\n$$\n\n$$\n    \\text{Reproducibility}^{+}(\\mathcal{R^+}) = \\frac{ACC(\\Phi_S)}{ACC(\\Phi)}\n$$\n\n$$\n    \\text{Reproducibility}^{-}(\\mathcal{R^-}) = \\frac{ACC(\\Phi_R)}{ACC(\\Phi)}\n$$\n\n- $\\mathbb{G} = \\{\\mathcal{G}^1, \\mathcal{G}^2, \\dots, \\mathcal{G}^n\\}$, the set of all graphs.\n- ${\\mathcal{G}^i_S}$ is the explanation subgraph of $\\mathcal{G}^i$ \n- $\\mathbb{G}_S = \\{\\mathcal{G}^1_S, \\mathcal{G}^2_S, \\dots, \\mathcal{G}^n_S\\}$ is the set of explanations.\n- $\\mathcal{R}^i = \\mathcal{G} - \\mathcal{G}^i_S$\n- $\\mathbb{R} = \\{\\mathcal{R}^1, \\mathcal{R}^2, \\dots, \\mathcal{R}^n\\}$ is the set of residual graphs.\n- $\\Phi$, $\\Phi_S$, and $\\Phi_R$  are the models trained on $\\mathbb{G}$, $\\mathbb{\\mathbb{G}}_S$, and $\\mathbb{\\mathbb{R}}$, respectively. All models are trained on the same labels.\n- $\\Phi(\\mathbb{G}^i)$ is the model's prediction on $\\mathbb{G}^i$.\n- $\\mathcal{E}_X$ and $\\mathcal{E}'_X$ are the set of edges in the explanations on the original graph and after noise injection.\n- $ACC(\\Phi)$ is the test accuracy of the model $\\Phi$.\n\n**Q2. The notations of A(G_s) in Equation 1 should be A(G').**\n\n*Response:* We have fixed it. Thanks for pointing this out.\n\n **Q3. In definition 2, the prediction of the perturbated graph is defined to be different from the counterpart of the original graph. I think this is valid for binary classification. For multi-classification problems, the counterfactual reasoning should be associated with a pre-assigned label.**\n\n*Response:*  Thank you for the suggestions. This has been incorporated in Def. 2. The relevant text is reproduced verbatim below.\n\n> In case of multi-class classification, if one wishes to switch to a target class label(s), then the optimization objective is modified as $\\mathcal{G}^*=\\arg\\min_{\\mathcal{G}'\\in\\mathbb{G},\\: \\Phi(\\mathcal{G}')=\\mathbb{C}} \\; dist(\\mathcal{G},\\mathcal{G}')$, where $\\mathbb{C}$ is the set of desired class labels and $\\mathbb{G}$ is the set of all graphs one may construct by perturbing $\\mathcal{G}$.\n\n**Q4. The definitions of fidelity, necessity, and reproducibility seem to be vague. The fidelity in section 4 (under figure 2) is not clear, \"some works have used the term fidelity instead of sufficiency\" has no citations**. \n\n*Response:* As noted in our response to Q1, we have now provided mathematical definitions of all the metrics in Table 3. Furthermore, we have removed the term Fidelity from our manuscript and consistently use only Sufficiency."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6942/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700257548144,
                "cdate": 1700257548144,
                "tmdate": 1700257548144,
                "mdate": 1700257548144,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KN0B5PO2l8",
            "forum": "VJvbOSXRUq",
            "replyto": "VJvbOSXRUq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6942/Reviewer_NT8w"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6942/Reviewer_NT8w"
            ],
            "content": {
                "summary": {
                    "value": "This work presents a benchmark for perturbation-based GNN explanation methods. Within the benchmark, this work provides a comprehensive comparison between both the factual and counter-factual explanation methods. This work conducts the comparison on various datasets, including 10 graph classification and 3 node classification ones. The experiments compare 7 GNN explanation methods in terms of the size of the perturbation, the sufficiency (percentage of the subgraphs that yield the same results as using full graph), and accuracy (the percentage of correct explanation). The results give a relative comparison among the seven methods. Furthermore, this work conducts a comparison of the methods regarding the stability with regard to noise injected into the underlying graph, different seeds of training explanation models, and variations in model architectures. Lastly, this work also provides an open-sourced codebase, making the benchmark accessible for public use."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- This work provides an extensive evaluation of perturbation-based GNN explanation methods in terms of both performance and stability. The comprehensive results give a quantitative comparison of existing explanation methods. \n- Besides performance, this work also considers the stabilities of GNN explanation methods. This provides a new aspect for evaluating GNN explanation algorithms. \n- This work provides an online repository of the proposed benchmark, making the evaluations accessible for a broader range of users."
                },
                "weaknesses": {
                    "value": "- The conclusions from the empirical comparison are not clear. It would be better to summarize the conclusions from the empirical comparison and provide conceptual insights, such as how would the results guide the future design of GNN explanation methods. \n- Discussion of the existing works needs more structure. Current discussion of the related works are based on the summary for each method. It would be better to provide more structures of the current works, such as what methods the existing ones share in common. \n- Details of the empirical studies need to be further elaborated. Please see Questions."
                },
                "questions": {
                    "value": "- It would be better to clearly define how the sufficiency score is computed. \n- Do the authors have any explanation for why the RCExplainer and the GNNExplainer have the highest sufficiency scores? It would be helpful to provide a more structured and conceptual comparison between the explanation methods. \n- What is the definition and scale of the noise shown in Figure 3?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "n/a"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6942/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6942/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6942/Reviewer_NT8w"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6942/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698891304291,
            "cdate": 1698891304291,
            "tmdate": 1700672542363,
            "mdate": 1700672542363,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3ayaqQ6Psm",
                "forum": "VJvbOSXRUq",
                "replyto": "KN0B5PO2l8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6942/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6942/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer NT8w: Part 1"
                    },
                    "comment": {
                        "value": "**Q1. The conclusions from the empirical comparison are not clear. It would be better to summarize the conclusions from the empirical comparison and provide conceptual insights, such as how would the results guide the future design of GNN explanation methods.**\n\n*Response:* This is an excellent suggestion. We appreciate the constructive feedback. To incorporate this suggestion, we have now made the following changes. \n\n* The conclusion section (Section 5) has been expanded to discuss research directions that may potentially yield solutions to the primary limitations identified in this study, namely - incorporating *generative modeling* in counterfactual reasoning to address feasibility concerns, and migrating towards *ante-hoc* reasoning to address instability and non-reproducibility. Current explainers are post-hoc in nature, wherein the explanations are generated post the completion of GNN training. In this pipeline, the explainers have no visibility to how the GNN reacts to perturbations on the input data, initialization seeds, etc. In the *ante-hoc* paradigm, the GNN and the explainer are jointly trained.\n*  For each experiment, we have added a paragraph titled \"Insights\" to clearly discuss the take-aways and provide explanations for the trends observed.\n\n**Q2. Discussion of the existing works needs more structure. Current discussion of the related works is based on the summary for each method. It would be better to provide more structures of the current works, such as what methods the existing ones share in common.**\n\n*Response:* We have incorporated this suggestion through the following mechanisms:\n* Tables 1 and 2 characterize different factual and counterfactual methods, respectively, along various dimensions such as scoring function, intended task (such as graph/node classification), modeling paradigm (transductive vs. inductive), etc. Through these tables, it is now easy to derive the common principles shared across algorithms.\n* We have also re-structured the related work discussion (Sec. 2.1) based on these tables to better elucidate the common design principles and enable easier abstraction of their conceptual designs.\n\n**Q3. It would be better to clearly define how the sufficiency score is computed.**\n\n*Response:* We have added the mathematical formulation of sufficiency as well as all other metrics used in our work (See Table 3 in the revised manuscript). The relevant portion is reproduced verbatim below.\n\nSufficiency encodes the ratio of graphs for which the prediction derived from the explanation matches the prediction obtained from the complete graph.\n\n$$\n    \\text{Sufficiency}(\\mathcal{S}) = \\frac{\\sum_{i=1}^{|\\mathbb{G}|} \\mathbb{1}(\\Phi({\\mathcal{G}_S^i}) = \\Phi(\\mathcal{G}^i))}{|\\mathbb{G}|}\n$$\n\n$$\n    \\text{Necessity}(\\mathcal{N}) = \\frac{\\sum_{i=1}^{|\\mathbb{G}|} \\mathbb{1}(\\Phi(\\mathcal{R}^i) \\neq \\Phi(\\mathcal{G}^i))}{|\\mathbb{G}|}\n$$\n\n$$\n    \\text{Stability}(\\mathcal{E}_X, \\mathcal{E}'_X) = \\frac{\\vert\\mathcal{E}_X\\cap\\mathcal{E}'_X\\vert}{\\vert\\mathcal{E}_X\\cup\\mathcal{E}'_X\\vert}\n$$\n\n$$\n    \\text{Reproducibility}^{+}(\\mathcal{R^+}) = \\frac{ACC(\\Phi_S)}{ACC(\\Phi)}\n$$\n\n$$\n    \\text{Reproducibility}^{-}(\\mathcal{R^-}) = \\frac{ACC(\\Phi_R)}{ACC(\\Phi)}\n$$\n\n- $\\mathbb{G} = \\{\\mathcal{G}^1, \\mathcal{G}^2, \\dots, \\mathcal{G}^n\\}$, the set of all graphs.\n- ${\\mathcal{G}^i_S}$ is the explanation subgraph of $\\mathcal{G}^i$ \n- $\\mathbb{G}_S = \\{\\mathcal{G}^1_S, \\mathcal{G}^2_S, \\dots, \\mathcal{G}^n_S\\}$ is the set of explanations.\n- $\\mathcal{R}^i = \\mathcal{G} - \\mathcal{G}^i_S$\n- $\\mathbb{R} = \\{\\mathcal{R}^1, \\mathcal{R}^2, \\dots, \\mathcal{R}^n\\}$ is the set of residual graphs.\n- $\\Phi$, $\\Phi_S$, and $\\Phi_R$ are the models trained on $\\mathbb{G}$, $\\mathbb{\\mathbb{G}}_S$, and $\\mathbb{\\mathbb{R}}$, respectively. All models are trained on the same labels.\n- $\\Phi(\\mathbb{G}^i)$ is the model's prediction on $\\mathbb{G}^i$.\n- $\\mathcal{E}_X$ and $\\mathcal{E}'_X$ are the set of edges in the explanations on the original graph and after noise injection.\n- $ACC(\\Phi)$ is the test accuracy of the model $\\Phi$."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6942/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700257236879,
                "cdate": 1700257236879,
                "tmdate": 1700257236879,
                "mdate": 1700257236879,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "g9kWECQjqf",
                "forum": "VJvbOSXRUq",
                "replyto": "eiwaAz4mFe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6942/Reviewer_NT8w"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6942/Reviewer_NT8w"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the authors' responses"
                    },
                    "comment": {
                        "value": "I have read the authors' responses. The authors have added more structures to the discussion of related works and experimental results. Thus, I would like to increase my score. After reading the experimental insights, I think that it would be better to shorten the insights and summarize them as a few sentences at the beginning of the experiments."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6942/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700672491413,
                "cdate": 1700672491413,
                "tmdate": 1700672491413,
                "mdate": 1700672491413,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9dJsGYaaIa",
            "forum": "VJvbOSXRUq",
            "replyto": "VJvbOSXRUq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6942/Reviewer_PPUE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6942/Reviewer_PPUE"
            ],
            "content": {
                "summary": {
                    "value": "The authors applied a benchmark evaluation to measure various GNN explainers' performances. A brief review of GNN explainer classification is introduced, then seven perturbation-based factual explainers and four perturbation-based counterfactual explainers are selected to conduct the benchmark test. Stability, necessity, reproducibility, feasibility, and comparative analysis are chosen to be evaluation criteria.  Size, fidelity, and accuracy are regarded as metrics. Finally, after the empirical evaluation, the authors provided some insights and directions expected to lead researchers enhance the overall quality and interpretability of GNNs."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1) A comprehensive introduction about how GNN explainers work and how GNN explainers are classified is provided.  Clear Figure 1 demonstrates research interest of the paper.\n2) Various perturbation-based GNN explainers are selected to evaluate their performances, increasing the soundness of conclusions. The selected explainers are published from 2003 to 2022, covering the development of GNN explainers for decades.Multiple runs were conducted to deal with randomness.\n3) Detailed appendix proves the rigor of experiments.  Comparative analysis is conducted to reveal some kay outcomes' features.  Many clear figures demonstrate the reasonability of conclusion."
                },
                "weaknesses": {
                    "value": "1) Lack of creativity and significance: The authors conducted an evaluation to measure many explainers' performances, but did not come up with a novel solution to overcome the discovered challenges.  Also, the conclusions are not insightful enough with further analysis. Based on this reason, it is hard to regard this paper as a research paper.\n2) Poor layout: The layout of words and tables is too dense, such as Table 1, 4, 5, and 8. Numbers inside table are too small and hard to read."
                },
                "questions": {
                    "value": "Authors may want to try to offer some new solutions to the discovered limitations of existing GNN explainers. Finding out these limitations is just a start of a research work. For instance, the feasibility concerns about counterfactual explainations appear due to the deviations in topological distribution. Authors can keep working in this direction and find out some methods to improve feasibility."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6942/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699457078762,
            "cdate": 1699457078762,
            "tmdate": 1699636809640,
            "mdate": 1699636809640,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mYoqstPeAa",
                "forum": "VJvbOSXRUq",
                "replyto": "9dJsGYaaIa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6942/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6942/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer PPUE"
                    },
                    "comment": {
                        "value": "**Q1. Lack of creativity and significance: The authors conducted an evaluation to measure many explainers' performances, but did not come up with a novel solution to overcome the discovered challenges. Also, the conclusions are not insightful enough with further analysis. Based on this reason, it is hard to regard this paper as a research paper.**\n\n*Response:* The Call for Papers for ICLR 2024 includes 'Datasets and Benchmarks' (refer to https://iclr.cc/Conferences/2024/CallForPapers), and our submission falls within this category. Benchmarking papers are not anticipated to present novel solutions; rather, the focus is on conducting a comprehensive empirical evaluation in a relevant area and offering fresh insights previously undiscovered. It is a reasonable expectation from a benchmarking paper to propose potential directions for addressing identified limitations, as we have done in Section 5. Based on the suggestions provided, we have further expanded our discussion on potential solutions in the revised manuscript.\n\n\n**Q2. Poor layout: The layout of words and tables is too dense, such as Table 1, 4, 5, and 8. Numbers inside table are too small and hard to read.**\n\n*Response:* We appreciate this constructive feedback. We have thoroughly revisited all sections of the paper and have ensured the fonts are large enough to be comfortably legible in the revised manuscript. We have also increased spacing around tables. We hope these changes have effectively addressed the presentation-related concerns."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6942/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700256852577,
                "cdate": 1700256852577,
                "tmdate": 1700256852577,
                "mdate": 1700256852577,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "e1LyRClhte",
                "forum": "VJvbOSXRUq",
                "replyto": "9dJsGYaaIa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6942/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6942/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to feedback from Reviewer PPUE"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nSince we are only a day away from the completion of the discussion phase, we are eagerly awaiting your feedback on the revised manuscript. We have addressed all of the presentation related concerns and present a significantly expanded discussion on potential solutions to the previously undiscovered shortcomings of the explainability methods with regards to stability, feasibility and reproducibility.\n\nFinally, we wish to clarify again that our submission has been made to the Dataset and Benchmark category of ICLR.\n\nPlease do let us know if there are any additional clarifications or experiments that we can offer. We would love to discuss more if any concern still remains. Otherwise, we would appreciate it if you could support the paper by increasing the score.\n\nregards,\n\nAuthors"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6942/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700542080141,
                "cdate": 1700542080141,
                "tmdate": 1700542091993,
                "mdate": 1700542091993,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]