[
    {
        "title": "On the Identifiability of Switching Dynamical Systems"
    },
    {
        "review": {
            "id": "L4eLBkFoqN",
            "forum": "GdTOzdAX5A",
            "replyto": "GdTOzdAX5A",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5912/Reviewer_QaMu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5912/Reviewer_QaMu"
            ],
            "content": {
                "summary": {
                    "value": "The authors present a paper on identifiability in MSMs and SDS, using Gaussian transitions and neural networks for parameterisation. The study's findings are empirically verified with synthetic experiments and suggest practical applications for causal discovery and time series segmentation in real and synthetic data."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The main review is concentrated to this section owing to the flow in which this review was conducted.\n\n\n### Introduction\n\n- Your definition of causal identifiability is wrong. You say: \"In causal inference (Peters et al., 2017), identifiability refers to whether the underlying causal structure can be correctly pinpointed from infinite observational data.\" - that is not at all what identifiability means in causal inference. It means whether or not an intervention e.g. $P(Y \\mid do(X=x))$ can be computed only from knowledge of the observational distribution $P(V)$ where $V$ is the set of all variables in the causal model, and the causal diagram $\\mathcal{G}$. What you are referring to has more to do with _causal discovery_ which is the process of learning the true DAG from the observational data.\n\n### Background\n\n- Is it important that $K < +\\infty$?\n- It may help readability if you use different symbols, rather than $\\theta$ for everything, for the different densities.\n\n### Theoretical considerations\n\n- This section may be better called 'Methods'. The current heading is a bit ambiguous - theoretical considerations of what?\n- I do not understand, what does $\\{1,\\ldots, K^T\\} \\rightarrow \\{1,\\ldots,K\\}^T$ mean?\n- What are these mild measure-theoretic considerations? What does 'mild' mean in this context?\n- You are interchangeably using | and \\mid in your densities, pick one.\n- Typo: 'indentifiability' under definition 3.2\n\n### Related work\n\n- Again, your definition of causal identifiability does not mean what you say it does.\n\n### Experiments\n\n- I am confused. In section 6.2 you are using the correct term 'causal discovery' and you are using the idea correctly as well, so why are you referring to the structure learning with 'identifiability' hitherto?\n\n### Conclusion\n\n- Same here; _causal discovery_ is being used rather than identifiability."
                },
                "weaknesses": {
                    "value": "See Strength section."
                },
                "questions": {
                    "value": "See Strength section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5912/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698269319582,
            "cdate": 1698269319582,
            "tmdate": 1699636628388,
            "mdate": 1699636628388,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "eG9cehLizm",
                "forum": "GdTOzdAX5A",
                "replyto": "L4eLBkFoqN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their time and constructive feedback on our work. We hope to engage in discussions during this period to further improve the quality of this manuscript.\n\n**Summary**\n\nWe first provide a summary of the issues outlined by the reviewer and the actions we will take accordingly.\n\n- The reviewer raises concerns in the terminology referring to identifiability in the context of causal discovery, as it can give the wrong impression that we are claiming structure identifiability.\n- **Action**: We update the document fixing the terminology, so that it becomes clear that although our results allow causal discovery in regime-dependent structures (thanks to having access to the transition derivatives), we are not claiming structure identifiability.\n\n\n**Response Details**\n\nBelow we provide clarifications for each of the issues outlined in the reviewer assessment.\n\n\n> Your definition of causal identifiability is wrong.\n\nConsidering our task regarding causality does not consider intervention distributions and we are working with observational data, we agree that the proper term would be causal discovery instead of causal inference. With this being said, the notion of identifiability holds true for causal discovery (whether the underlying causal graph can be determined from observational data).\n\nWe thank the reviewer for spotting this and we will update the terminology regarding causal inference to causal discovery.\n\n\n> Is it important that $K < \\infty$?\n\nIt is crucial to set $K < \\infty$ (and also $T < \\infty$), as we are framing our Markov Switching Model as a finite mixture model. This notion is generally true for State-Space Models with discrete variables. In this case, it helps us understand that although the number of mixture components grows exponentially ($K^T$), we can still use finite mixture model results as $T$ and $K$ are finite.\n\n> It may help readability if you use different symbols, rather than $\\theta$ for everything, for the different densities.\n\nWe use $\\theta$ to denote the parametrization of the distributions of our models. We used a single variable for simplification. We consider using different names for the decoders, discrete prior dynamics, and continuous prior dynamics (initial and transition distribution) could become cumbersome.\n\nIt also simplifies the formulation we use in the Estimation section, as we denote the parameters of the generative model with $\\theta$ and the approximate posterior with $\\phi$.\n\n\n> This section may be better called 'Methods'. The current heading is a bit ambiguous - theoretical considerations of what?\n\nExperiments aside, note that our main contributions are purely theoretical, i.e. we are not proposing any novel probabilistic modeling technique/method. The generative models we study come from a family of methods presented in recent years: KVAE (Fraccaro et al. 2017), SNLDS (Dong et al. 2020), RED-SDS (Ansari et al. 2021), etc. Therefore, we consider that a heading like \u201cMethods\u201d would give the reader the incorrect feeling that we are proposing a novel model.\n\nWe first present this notion in the \u201cBackground section\u201d, and then present our theoretical results in the next section. We named the section \u201cTheoretical Considerations\u201d to highlight that the core contribution of our work is theoretical, meaning that we are proving identifiability for well-established generative models which have been used in the past with no guarantees. The first paragraph of the \u201cTheoretical Considerations\u201d section explains what are such considerations (identifiable MSM and identifiable SDS).\n\nOther previous papers have also used this heading, such as RHINO (Gong et al 2023), or similar ones such as \u201cIdentifiability Theory\u201d by HMM-ICA (Halva et al. 2020) or iVAE (Khemakem et al 2020)."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700126993607,
                "cdate": 1700126993607,
                "tmdate": 1700126993607,
                "mdate": 1700126993607,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fD2djaFNoi",
                "forum": "GdTOzdAX5A",
                "replyto": "L4eLBkFoqN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer (2/2)"
                    },
                    "comment": {
                        "value": "> I do not understand, what does $1,\\dots,K^T \\rightarrow 1, \\dots, K^T$ mean?\n\nWe believe the reviewer is referring to the bijective *path indexing function* $\\varphi: ${$1,\\dots,K^T$}$ \\rightarrow ${$1, \\dots, K$}$^T$. This path indexing function is important because it allows us to translate the original notation used in Markov Switching Models to a notation which is suitable for a finite mixture model of $K^T$ components and vice versa. See below for further clarifications.\n\n- Consider a Markov Switching Model trajectory, i.e $p(z_{1:T}| s_{1:T})$. We can represent the state assignment for such trajectory using a tuple $(s_1=i_1, s_2=i_2, \\dots, s_T=i_T)$, where the space of the tuple is the cartesian product {$1, \\dots, K$}$^T$. \n- Using this notation for finite mixture models can be cumbersome. For example, the marginalization of $s_{1:T}$ requires T summations.\n- To simplify this, we use the *path indexing function*, which uniquely retrieves a set of states from a single index (in this case a number between $1$ and $K^T$). By presenting this bijection, we can change the original notation of MSMs to finite mixtures. Following the previous example, the marginalization now takes only a big sum.\nThe resulting notation with indices instead of tuples allows the proofs to be relatively easier to follow.\n\n> What are these mild measure-theoretic considerations? What does 'mild' mean in this context?\n\nThese conditions can be found in Appendix A, which is indicated in the main text. It basically means that the measure we use is well-defined.\n\n> Again, your definition of causal identifiability does not mean what you say it does.\n\nWe are a bit confused with this sentence, as we do not refer to \u201ccausal identifiability\u201d in this section. The only reference to causality we make is to summarize some contributions regarding latent causal models such as CITRIS and LEAP.\n\n> I am confused. In section 6.2 you are using the correct term 'causal discovery' and you are using the idea correctly as well, so why are you referring to the structure learning with 'identifiability' hitherto?\n\nWe believe the confusion comes from the following erroneous claim found in the introduction: \u201cThis also leads to the first identifiability proof for regime-dependent causal discovery\u2026\u201d We acknowledge this is not accurate to our results, as we are providing identification in terms of the MSM transitions, rather than structure identifiability.\n\nAlthough we mention structure identifiability to provide context of the main goal for causal discovery, we will make sure the erroneous claims are modified.\n\n> Same here; causal discovery is being used rather than identifiability.\n\nWe believe this is referred to the following sentences:\n\n\u201cWe empirically verify our theoretical results with synthetic experiments, and motivate our approach for regime-dependent causal discovery and high-dimensional time series segmentation with real data.\u201d\n\n\u201cWhile our work focuses on identifiability analysis, in practice accurate estimation is also key to the success of causal discovery/representation learning from real data.\u201d\n\nWe use the term causal discovery to denote the task of learning graphs from observational data, and we believe that the term is correctly used in this case."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700128411398,
                "cdate": 1700128411398,
                "tmdate": 1700128411398,
                "mdate": 1700128411398,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "COfknV8yW4",
                "forum": "GdTOzdAX5A",
                "replyto": "L4eLBkFoqN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reminder for Reviewer QaMu"
                    },
                    "comment": {
                        "value": "Dear Reviewer QaMu,\n\nOnce again, we appreciate your time in reviewing our work. As the discussion period is finishing soon, we would be grateful if you could confirm whether our reply and modifications to the document addressed your concerns."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700601411003,
                "cdate": 1700601411003,
                "tmdate": 1700601572022,
                "mdate": 1700601572022,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LNihLClh5D",
                "forum": "GdTOzdAX5A",
                "replyto": "COfknV8yW4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5912/Reviewer_QaMu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5912/Reviewer_QaMu"
                ],
                "content": {
                    "title": {
                        "value": "Acknowledgement"
                    },
                    "comment": {
                        "value": "Thanks to the authors for a thorough response. I confirm that I have read their review and have no further questions or comments."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700675774752,
                "cdate": 1700675774752,
                "tmdate": 1700675774752,
                "mdate": 1700675774752,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KjWJno0foY",
            "forum": "GdTOzdAX5A",
            "replyto": "GdTOzdAX5A",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5912/Reviewer_nPz5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5912/Reviewer_nPz5"
            ],
            "content": {
                "summary": {
                    "value": "This work focuses on the identifiability of Markov Switching Models and extended it to Switching Dynamical Systems. The authors presented identification conditions for first-order Markov models that uses non-linear Gaussian transitions. They proved the identifiability of Switching Dynamical Systems up to affine transformations. They also developed corresponding estimation algorithms. The proposed method was demonstrated by empirical studies on time series such as videos and climate data."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Conditions in which first-order MSMs with non-linear Gaussian transitions are identifiable up to permutations. \n\nAnalysis of identifiability conditions for non-parametric first-order MSMs.\n\nConditions for SDSs identifiability up to affine transformations of the latent variables and non-linear emission.\n\nDiscovery of time-dependent causal structures in time-series."
                },
                "weaknesses": {
                    "value": "The conditions of identifiability such as invertibility are strong and thus less nontrivial, and would limit the practicality.\n\nThe empirical studies lack demonstration of identifiability or the benefits of identifiability."
                },
                "questions": {
                    "value": "Could the authors discuss how useful the identifiability would be in practice, especially for those latent variables? I'm not questioning the contribution. I have seen papers talking about the identifiability subject to certain transformations, but few showcase it in their examples.\n\nThe index $a$ and $s$ seem exchangeable. What's the difference?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5912/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698679386691,
            "cdate": 1698679386691,
            "tmdate": 1699636628288,
            "mdate": 1699636628288,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "eCu9tFBJwV",
                "forum": "GdTOzdAX5A",
                "replyto": "KjWJno0foY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their time and constructive feedback on our work. We hope to engage in discussions during this period to find ways to improve our manuscript.\n\n**Weaknesses**\n\n\nFirst, we address the **weaknesses** outlined by the reviewer.\n\n> The conditions of identifiability such as invertibility are strong and thus less nontrivial, and would limit the practicality.\n\nWe agree that invertibility can be considered a strong assumption which can limit the practicality of our approach when extending it to realistic domains. However, the invertibility condition only applies to the emission of the Switching Dynamical System, and not the transitions of the Markov Switching Models where the requirement is smoothness (analytic functions).\n\nThe invertibility condition of the emission function in the Switching Dynamical System can be weakened to weakly injective functions (injective functions on at least an open set), which in turn gives us weakened identification results (**Theorem 3.2.ii**: The prior MSM is identifiable up to affine transformations).\n\nFor some extra context on the emission assumptions, other related works such as HMM-ICA (Halva et al. 2020), SNICA (Halva et al. 2021), LEAP (Yao et al. 2022),  and CITRIS (Lippe et al. 2022), also assume injectivity or even bijectivity (which is much stronger). In this case, the weakly-injectivity assumption which we include in our work is much weaker but rarely used in other related works.\n\n> The empirical studies lack demonstration of identifiability or the benefits of identifiability.\n\nWe consider the empirical studies to showcase some of the benefits of identifiability. Therefore, we believe some discussion here could be very helpful in terms of improving this part.\n- For the case with Markov Switching Model, the direct benefit of identifiability we aim to depict in our work is identifying regime-dependent causal structures. In causal discovery, there are few works which consider non-stationary time series, and even fewer which allow time-dependent causal structures. In this case, identifiability results for regime-dependent dynamics are helpful to understand data with e.g. seasonality trends. As we observe in the case we show (Section 6.2). We would like to note that regime-dependent causal discovery has not been proven identifiable, and our work establishes a first result on this matter by directly identifying functions.\n- For Switching Dynamical Systems, the benefits of identifiability are a bit more complex to demonstrate at this stage. For example, in case we had a latent causal structure underlying the continuous latent variables, the affine transformation would prevent us from correctly depicting such structure. For this reason, we showcased some results with 2D MSM rendered as videos, where the learned latent space is an affine transformation of the original one. For the case with salsa data, the problem relies on estimation of a complex and high-dimensional setting, which results in the method being very prone to state collapse. This motivates progressing our line of work further with consistent estimation methods for SDSs. We continue this discussion on the **questions** section.\n\nOf course, all of the cases with real data come at the cost of assuming correct model specification, i.e. whether the assumptions are in fact aligned with the *true underlying distribution*. In this case, identifiability theory is very important to understand how far we can go in terms of making interpretations from the learned structures (e.g. in the case of causal discovery)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700128843538,
                "cdate": 1700128843538,
                "tmdate": 1700128843538,
                "mdate": 1700128843538,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Bpjx3MDYgG",
                "forum": "GdTOzdAX5A",
                "replyto": "KjWJno0foY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer (2/2)"
                    },
                    "comment": {
                        "value": "**Questions**\n\nWe address the **questions** below:\n\n> Could the authors discuss how useful the identifiability would be in practice, especially for those latent variables?\n\nThis question is in line with the previous item. We would like to provide further motivation for the practicality of identifiability with the following previous result.\n\nFraccaro et al. (2017) [1] perform an experiment using a switching dynamical system (KVAE) with video data of a bouncing ball. In their experiments, they show a visualization of the 2D latent space, which results in a linear transformation of the original box in which the ball was contained. This empirical result suggests one should be able to prove that indeed there exists a one to one correspondence between the latent space distribution and observed distribution up to an affine transformation. Unfortunately such results cannot be found in the literature.\n\nIn our work, the distribution of the discrete states is independent of the observations, which means that the bouncing ball example is not embedded within our theoretical findings. However, we choose to depict an equivalent example using 2D MSMs rendered as image data to showcase that one can recover the true latents up to affine transformations purely from images (by using (Leaky)-ReLU CNNs) as decoders.\n\nWe can find further motivation for identifiable Switching Dynamical Systems with another example on climate data. In this case, imagine we cannot quantify the climate variables (and model them as MSMs), but instead, we have access to some high-dimensional representation of them (e.g. precipitation maps, etc). Given the seasonal nature of climate variables, approaches such as the one we present could be a good fit for identifying causal structures from high-dimensional inputs. For a visualization, see [Figure 1 of Runge et al. (2020)](https://www.nature.com/articles/s41467-019-10105-3) [2]. However, since we only achieve affine transformation identifiability, we would need to impose further restrictions to our model to reduce the affine transformation to e.g. component-wise scaling and permutation.\n\nWe believe our manuscript could benefit from including a similar discussion in the Appendix to motivate the importance of identifiable Switching Dynamical Systems.\n\n[1] Fraccaro, M., Kamronn, S., Paquet, U. and Winther, O., 2017. A disentangled recognition and nonlinear dynamics model for unsupervised learning. Advances in neural information processing systems, 30.\n\n[2] Runge, J., Bathiany, S., Bollt, E., Camps-Valls, G., Coumou, D., Deyle, E., Glymour, C., Kretschmer, M., Mahecha, M.D., Mu\u00f1oz-Mar\u00ed, J. and Van Nes, E.H., 2019. Inferring causation from time series in Earth system sciences. Nature communications, 10(1), p.2553.\n\n> The index a and  s seem exchangeable. What's the difference?\n\nThe indices $a$ we use in this case are used to show how to understand the Markov Switching Model family as a finite mixture model (finite mixture of $K^T$ trajectories). The idea is to drop the conditioning discrete state variables so that we can **write the MSM as a linear combination of functions in $\\mathbb{R}^{Tm}$.** We expand below for further clarification.\n- The notation using $s$ is the original used for indexing the state value at each time step. This notation becomes cumbersome when formulating the MSM as a finite mixture, as the state assignments in a trajectory are a tuple of length T, where the space of assignments becomes a cartesian product {$1, \u2026, K$}$^T$.\n- To see why the above notation is cumbersome, we can imagine trying to marginalize the state variables from $p(z_{1:T},s_{1:T})$, where the we would have T summations, and the state assignment would be $s_{1:T} = (i_1, \\dots, i_T)$.\n- To simplify this, we will just consider that our problem is indeed a mixture of $K^T$ trajectories. Then, we can use another indexing variable $i\\in ${$1, \\dots, K^T $}, which will be a number (and not a tuple). Now the trajectory indexing becomes much simpler as we  can use a single number. In this case, we introduce the indices $a^i_{1:T}$ for each $i$, that will retrieve the corresponding initial or transition functions for the family we defined.\n- The idea is that using $s$ and $a$ is interchangeable. Note that we indicate that they are equivalent notations. However, it facilitates work when framing MSMs as finite mixture models and thus proving identifiability, as we now have one big linear combination of functions."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700130149276,
                "cdate": 1700130149276,
                "tmdate": 1700130149276,
                "mdate": 1700130149276,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8PP5rMq6wC",
                "forum": "GdTOzdAX5A",
                "replyto": "KjWJno0foY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5912/Reviewer_nPz5"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5912/Reviewer_nPz5"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for addressing my concerns.\nSince the identifiability is a crucial point of this work, it is worthwhile to elaborate on those advantages of identifiability in comparison to other non-identifiable methods in the empirical examples.\nI have no further questions."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700591407323,
                "cdate": 1700591407323,
                "tmdate": 1700591472089,
                "mdate": 1700591472089,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "PNvInsUsfX",
            "forum": "GdTOzdAX5A",
            "replyto": "GdTOzdAX5A",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5912/Reviewer_JVt8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5912/Reviewer_JVt8"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes an identifiability results of switching dynamical systems. The results are a direct extension of Kivva et al. (2022). The main idea is to show that the distribution under the switch dynamic system can be represented through finite mixture distributes which are indeed identifiable."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The identifiability results of switching dynamical systems are proposed."
                },
                "weaknesses": {
                    "value": "- Does the number of states need to be specified as prior information? \n- Whether the number of states is identifiable and how to select it practically.\n- It would be better if there has a simple example to show the identifiability of the model in theory.\n- Moreover, the definition of the identifiability in this work should be stated clearly."
                },
                "questions": {
                    "value": "See the weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5912/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698766120280,
            "cdate": 1698766120280,
            "tmdate": 1699636628180,
            "mdate": 1699636628180,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UH5f5hmMJj",
                "forum": "GdTOzdAX5A",
                "replyto": "PNvInsUsfX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their time and feedback on our work, and we hope we can engage in further discussions.\n\nWe first clarify some concerns raised in the **summary** statement.\n\n> The results are a direct extension of Kivva et al. (2022).\n\nWe would like to clarify some **contributions** for the theory part, which we believe to be very important in terms of significance and novelty. \n- Although we use results from Kivva et al. (2022), they are only used for establishing the identifiability of the Switching Dynamical System given an identifiable Markov Switching Model prior.\n- Establishing results identifiability for non-linear Markov Switching Models is a non-trivial task even in the first-order case. To the best of our knowledge, our work is the first contribution to showcase results with non-linear Gaussian transitions (shown in the main text), and more importantly non-parametric transitions (Appendix B). Since results on finite mixture models cannot be directly extended to MSMs, we provide a novel technique to prove their identifiability (See Lemma B.1).\n- Finally, the identifiability of the transitions for such highly non-linear State-Space Models has not been addressed despite the variety of contributions in recent years. As these proofs are generally non-trivial, we consider our result to be very significant for the SSM community. Approaches like Halva et al. (2021) [1] include SDSs, but there are no identifiability statements on the transition functions.\n\nTherefore, we cannot qualify our work as a direct extension of Kivva et al. (2022), as proving identifiability for non-parametric non-linear MSMs is a non-trivial contribution with independent significance.\n\n[1] H\u00e4lv\u00e4, H., Le Corff, S., Leh\u00e9ricy, L., So, J., Zhu, Y., Gassiat, E. and Hyvarinen, A., 2021. Disentangling identifiable features from noisy data with structured nonlinear ICA. Advances in Neural Information Processing Systems, 34, pp.1624-1633.\n\n>  The main idea is to show that the distribution under the switch dynamic system can be represented through finite mixture distributes which are indeed identifiable.\n\nFrom this sentence it seems like the reviewer considers that if one writes a Markov Switching Model as a finite mixture, the model is identifiable. This is true **only when the mixture trajectories are linear independent**. Proving such a linear independence result is generally non-trivial, and one of our key contributions."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700130264112,
                "cdate": 1700130264112,
                "tmdate": 1700130264112,
                "mdate": 1700130264112,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sBrlh5jISK",
                "forum": "GdTOzdAX5A",
                "replyto": "PNvInsUsfX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer (2/2)"
                    },
                    "comment": {
                        "value": "Below we address the **weaknesses** outlined by the reviewer:\n\n> Does the number of states need to be specified as prior information?\n\nTL;DR: No.\n\nJust as in the non-temporal finite mixture case (e.g. Gaussian Mixture Model), the number of states **is identifiable from observations**, both for the MSM and SDS. This information can be found in **Definition 3.1**, where the notion of an identifiable MSM requires the number of states to be identifiable.\n\nNote that other recent ICA works which use discrete latent variables (HMM-ICA [2], IIA-ICA [3], or SNICA\u00a0[1]), rely on Gasiat et al. (2016) [4], which requires the number of states to be known a priori. Therefore, our result here is much more stronger.\n\n[2] H\u00e4lv\u00e4, H. and Hyvarinen, A., 2020, August. Hidden markov nonlinear ica: Unsupervised learning from nonstationary time series. In Conference on Uncertainty in Artificial Intelligence (pp. 939-948). PMLR.\n\n[3] Morioka, H., H\u00e4lv\u00e4, H. and Hyvarinen, A., 2021, March. Independent innovation analysis for nonlinear vector autoregressive process. In International Conference on Artificial Intelligence and Statistics (pp. 1549-1557). PMLR.\n\n[4] Gassiat, \u00c9., Cleynen, A. and Robin, S., 2016. Inference in finite state space non parametric hidden Markov models and applications. Statistics and Computing, 26, pp.61-71.\n\n> Whether the number of states is identifiable and how to select it practically.\n\nAs mentioned, the number of states is identifiable. Selecting the number of states in practice is a different notion than identifiability, which refers to the estimation method. \n\nAs an example, we can think about the equivalent non-temporal case where we need to find the number of mixture components in a clustering problem. One can then use the MLE objective with models initialized with different numbers of states. The identifiability conditions paired up with the general consistency of the MLE solution guarantee that the model with the correct number of states will have the highest data log-likelihood.\n\nNote that this only works when the number of states is identifiable.\n\n> It would be better if there has a simple example to show the identifiability of the model in theory.\n\nIn the first paragraph of section 3, we refer to our contribution as the temporal extension of a finite mixture model. In section 3.1, we adapt the notation of an MSM to finite mixture models, making the analogy where we now have a mixture of K^T trajectories. \n\n\u201cThis notation shows that the MSM extends finite mixture models to temporal settings as a finite mixture of $K^T$ trajectories composed by (conditional) distributions \u2026 \u201c\n\nWith this in mind, the identifiability of the MSM is close to the identifiability of a finite mixture model. Direct application of finite mixture model theory shows that linear independence of the $K^T$ mixings is a sufficient condition for identifiability. This explanation is depicted in the Proof sketch of **Theorem 3.1**, where we give the reader an overall idea of the proof technique, and how to prove linear independence using induction.\n\n\n> Moreover, the definition of the identifiability in this work should be stated clearly.\n\nWe thank the reviewer for the suggestion. However, we believe this notion is already stated in Definitions 3.1 and 3.3, where we state the definition of identifiable Markov Switching Models, and the identifiability of prior distributions up to affine transformations respectively.\n\nFor functions parameterized with neural networks, we refer to the paragraph after **Theorem 3.1**, second sentence, where we mention using analytic neural networks: \u201c... In the latter case, the identifiability result applies to the functional form only, since network weights do not uniquely index the functions that they parameterise \u2026\u201d. For further clarification, we will update the manuscript re-stating this latter notion of identifiability on neural network functions for the SDS as well."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700130708249,
                "cdate": 1700130708249,
                "tmdate": 1700130708249,
                "mdate": 1700130708249,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "JHwxfUIiK0",
            "forum": "GdTOzdAX5A",
            "replyto": "GdTOzdAX5A",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5912/Reviewer_SfP9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5912/Reviewer_SfP9"
            ],
            "content": {
                "summary": {
                    "value": "This paper provides identifiability theorems for general dynamical systems with nonlinear transitions and emission functions. This is done first by showing identifiability for Markov Switching Models and then for Switching Dynamical Systems. Variational inference algorithms are presented for learning and posterior inference."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The presentation is good and the paper reads well with nice explanations in many places.\n\nIt is in general important work to study and expand our understanding of identifiability in these models. Here the identifiability is shown for a general class of MSMs and SDSs which is a nice result. In particular, the identifiability does not assume independence of the latent components unlike like the works in the nonlinear ICA area.\n\nIt is also nice to see experiments, albeit somewhat limited (see below), on real data despite the theoretical focus of the paper."
                },
                "weaknesses": {
                    "value": "1) **The identifiability approach/results follow quite directly from previous works with some results already known previously** -- one could have assumed the results here to be already implied based on earlier works: the approach for proving MSM using mixtures model presentation is well known from the general work in [1] (which could be cited). While this specific class of models covered in this work is not explicitly mentioned, the results therein could be seen as already implying the identifiability of this type of models -- more explicit acknowledgement that this approach has been taken before would probably be sufficient (for the MSM results). The identifiabiltiy of SDSs with nonlinear activation function is just an application of the Kivva paper on this specific model class. Further identifiability of SDSs (in nonlinear ICA form) has actually already been established -- below point covers this more.\n\n2) **There are lacking citations and incorrect interpretations of previous works** -- if these are acknowledged appropriately the contributions of this paper would appear less significant. Most importantly, this paper claims that previous works have not considered identifiability in nonlinear dynamical systems with nonlinear emission function: specifically the authors state that \"In contrast, H\u00e4lv\u00e4 et al. (2021) assumes linear SDSs,\" -- this is not correct,  their identifiability results do not appear to make any such assumptions (based on my reading of their Theorems 1 and 2); their practical algorithm does seem to assume that but that has nothing to do with the identifiability. Identifiability of SDSs is thus achieved in their work. For identifiability of models with autoregressive transitions, see also [2], and the IIA-HMM model particularly -- I don't see this paper mentioned and discussed even though it has some similarity. In terms of estimation algorithm, the seminal work of [3] is not mentioned -- you need to at least explain why their work does not apply here or why the current approach is superior.\n\n3) **The identifiability results are weaker than acknowledged. or at least not sufficiently discussed** By directly relying on the result of Kivva to prove the identifiability of the nonlinear emission function / latent components, the results unfortunately inherit its weaknesses. 1) The identifiability requires one to know the family of the noise distribution which is a cumbersome assumption (but see Q2 below). 2) The results relies on piecewise linear emission function and is therefore less general than many other works that allow e.g. almost any injective $f(x)$ -- consider for instance what happens in your case if $f(x)$ is a Gaussian Process. 3) As far as I understand, that while there is no assumption of independence here (c.f. nonlinear ICA), the results are also clearly weaker i.e. for latent vector $\\mathbf{z}$ your results give essentially $f(\\mathbf{z}) = Af'(\\mathbf{z'}) + b$ -- contrast this to nonlinear ICA where one would identify the individual coordinates as per $z_i = h(z_i')$ for some invertible $h$ -- please correct if I have misunderstood. \n\n4) ** Experimental evaluation lacking in places**: The evaluation of the models on the salsa data seems very qualitative and much more rigorous evaluation would be preferred with some quantitative evaluation metrics.(Q3 below)\n\nmisc.:\n- \"p(z) is identifiable up to affine transformations\" -- This is imprecise language, explain whether you mean parameter identificaiton or identification of z or what.\n- Definition 2.1 define what $B$ is\n- grammar: \"The generative model consider in this work\" \n- Equation (4) and elswhere you use $p_a$ but earlier $p_{\\theta}$, please explain more clearly what the subscript $a$ means\n- Figure 2 is poor quality -- please provide a better quality figure\n- \"H\u00e4lv\u00e4 et al. (2021) introduces time-dependence between sources via linear SDSs\" , this appears to be incorrect as mentioned above (this mistake is in two places in the paper)\n\n\n\n[1] Allman et al.(2009) Identifiability of parameters in latent structure models with many observed variables\n\n[2] Morioka et al. (2021) Independent Innovation Analysis for Nonlinear Vector Autoregressive Process\n\n[3] Johnson et al. (2017) Composing graphical models with neural networks for structured representations and fast inference"
                },
                "questions": {
                    "value": "Q1: What is the justification for you estimation algorithm in light of the existence of the work [3] (see reference above) including benefits, disadvantages?\n\nQ2: Why do use the results of Khemakhem, Kivva that assumes that we know the noise terms distribution? Why do you not instead apply e.g. the results from Halva et al (2021), Theorem 1, that allows any arbitrary noise distribution?\n\nQ3: Why is it not possible to apply a more quantitative performance metric in the salsa experiment -?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5912/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5912/Reviewer_SfP9",
                        "ICLR.cc/2024/Conference/Submission5912/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5912/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699830403974,
            "cdate": 1699830403974,
            "tmdate": 1700678177849,
            "mdate": 1700678177849,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kCIulI9PEJ",
                "forum": "GdTOzdAX5A",
                "replyto": "JHwxfUIiK0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply summary"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their time and constructive feedback on our work, and we hope we can engage in further discussions to improve the quality of our manuscript.\n\nWe first provide a summary of our reply. For extra details, we refer to the detailed response.\n\n**Reply summary**\n- Our contribution on the MSM part is both **novel** and **significant**. \n  - Novelty + Significance: We obtain identifiability results of the MSM transitions up to permutations in **non-parametric** case. For clarity, we only presented a parametric example (non-linear Gaussian) in the main text as a special case.\n\n  - Novelty: our proof technique is new, which relies on **a brand new theoretical result (Lemma B.1)**. The direction from Allman et al. (2009) does not work for general non-parametric MSMs.\n- The existing work suggested by the reviewer (namely Halva et al. (2021)) is restrictive in terms of **assumptions** and **identifiability** results.\n  - Assumptions: Stationarity of the noiseless distribution $f(s_t)$ is already a very big restriction in our setup, where instead we could have a nonstationary latent MSM.\n  - Identifiability: Only demixing identifiability is achieved, i.e. identifiability of $f$ and $f(s_t)$. The identifiability of latent source transitions is not established. Therefore, Halva et al. (2021) do not prove the identifiability of SDSs.\n- The main reason for extending to SDSs using Kivva et al. (2022) relies on our assumptions of analytic priors and closedness under affine transformations."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700131012511,
                "cdate": 1700131012511,
                "tmdate": 1700131012511,
                "mdate": 1700131012511,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ijMefDErrV",
                "forum": "GdTOzdAX5A",
                "replyto": "JHwxfUIiK0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Detailed response to reviewer (1/3)"
                    },
                    "comment": {
                        "value": "**Response details**\n\nBelow we address the **weaknesses** outlined by the reviewer\n\n> The identifiability approach/results follow quite directly from previous works with some results already known previously\n\nWe are aware of Allman et al. (2009) results, which directly lead to HMM identifiability in Gassiat et al. (2016). In fact our initial attempts followed Allman et al. (2009), but in the end we found it not applicable to non-parametric MSMs due to the following reasons. \n- The Allman et al. (2009) technique is based on expressing the marginal distribution as a mixture of tensors, where each tensor is an outer product of 3 vectors, and each of these vectors is effectively $p(z_t | s_t)$. Therefore this technique can only be applied to HMMs where the emission probability is dependent on the discrete state only. On the other hand, MSMs introduce explicit dependencies on the data via the transition dynamics $p(z_t|z_{t-1},s_t)$.\n- The Allman et al. (2009) technique needs to have at least $T=3$. It won\u2019t work for $T=2$ and it\u2019s easy to give counterexamples here. In contrast, our technique for MSM works for $T=2$ under our assumptions.\n- The key restriction of Allman et al. (2009) technique (see its Section 4), as well as in many subsequent papers including Gassiat et al. (2016), comes from the use of Kruskal\u2019s \u201cThree-Way Arrays\u201d [1]. \n\nObserving the limitations of Allman et al. (2009), we decided to go back to the very first finite mixture model identifiability result (Yakowitz & Spragins, 1968) as the starting point. This leads to our key and novel theoretical result (Lemma B.1) which is crucial for our MSM identifiability proof in the non-parametric case.\n\n[1] Kruskal, J.B., 1977. Three-way arrays: rank and uniqueness of trilinear decompositions, with application to arithmetic complexity and statistics. Linear algebra and its applications, 18(2), pp.95-138.\n\n> There are lacking citations and incorrect interpretations of previous works.\n\nWe thank the reviewer for carefully comparing our work to existing literature. We will make sure previous work is properly acknowledged (including Morioka et al. (2021)) and modify the reference to other studies using general SDSs (which can be covered by Halva et al. 2021) by highlighting the assumptions on temporal dependence, rather than the assumptions on the transition model. \n\nNonetheless, we believe our contribution is significant even though other works have studied similar models.\n- The SDS assumptions of Halva et al. (2021) are a combination of the ones used for HMM-ICA (Halva et al. 2020), and Hyv\u00e4rinen et al. (2017) [2], thereby inheriting their limitations.\n  - Regarding HMM-ICA (Halva et al. 2020), the discrete states $s_t$ are assumed to follow a first-order stationary Markov chain with a full-rank transition matrix. The number of states are also required to be known. Instead, **our work makes no assumptions on knowing the number of states, or the structure of the dynamic model of $s_t$,** meaning it can be e.g., non-stationary and/or higher-order Markov.\n  - Regarding Hyv\u00e4rinen et al. 2017 [2], while it is true that they do not impose linearity the assumptions are placed on the temporal dependencies between sources. Our strategy works in a different spirit, where we directly establish restrictions on the transition mapping itself, which is more intuitive.\n- The identifiability results of Halva et al. (2021), although stronger in terms of achieving disentanglement of the sources, are weaker in terms of identifying the transitions in the latent space. \n  - Their main results (Thms 1 & 2) prove the identifiability of the non-linear mixing and source distribution, but make **no identifiability statements about the transition dynamics**. \n  - The Linear SDS assumed in Halva et al. (2021) is overcomplete ( observation dimensions < latent dimensions), which is problematic in terms of achieving transition identifiability.\n- We believe the following claim \u201cIdentifiability of SDSs is thus achieved in Halva et al. (2021)\u201d is not accurate. \n  - Identifiability results for HMMs include identifying the discrete transitions and source emission [3] (which would be transitions for SDSs). Halva et al. (2021) provides no result in this regard for SDS. \n  - Existing HMM identifiability results do not transfer to MSMs due to the explained limitation of Allman et al. (2009) technique. \n- Morioka et al. (2021) provides transition identifiability for vector autoregressive models (VAR), where only one transition function is used. On the contrary, Markov Switching Models propose using many transition functions conditioned on the discrete state variable. The extension IIA-HMM introduces an identifiable HMM from [3] thanks to source identification, but does not provide additional transition functions conditioned on the discrete variables."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700131453374,
                "cdate": 1700131453374,
                "tmdate": 1700131453374,
                "mdate": 1700131453374,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nBTiS0E0Fw",
                "forum": "GdTOzdAX5A",
                "replyto": "JHwxfUIiK0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Detailed response to reviewer (2/3)"
                    },
                    "comment": {
                        "value": "[2] Hyvarinen, A. and Morioka, H., 2017, April. Nonlinear ICA of temporally dependent stationary sources. In Artificial Intelligence and Statistics (pp. 460-469). PMLR.\n\n[3] Gassiat, \u00c9., Cleynen, A. and Robin, S., 2016. Inference in finite state space non parametric hidden Markov models and applications. Statistics and Computing, 26, pp.61-71.\n\n> The identifiability results are weaker than acknowledged. or at least not sufficiently discussed\n\nAlthough from Kivva et al. (2022) results we might have weaknesses in terms of the identification results (transitions and emission up to affine transformations), we argue that they have other advantages that can be interesting depending on the application.\n- The results from Kivva allow identifiability up to affine transformations of the prior distribution (which is identifiable), and hence we still achieve identifiability of the discrete state distribution up to permutations.\n- The results from Kivva also allow weaker assumptions than the injective mapping assumed in Halva et al. (2021), which uses a weakly-injective (and continuous) mapping (e.g. ReLU networks).\n- Following the previous point, note that weaker assumptions generally imply weaker identifiability statements. Therefore, our approach does not achieve decoder component-wise identifiability as we are not assuming independence as in ICA.\n\nWe follow this discussion point in Q2.\n\n> Experimental evaluation lacking in places\n\nWe agree that the evaluation of salsa data is focused on qualitative visualizations, although we provide reconstruction error metrics for reference. We continue this point in Q3.\n\n> misc:\n\nWe thank the reviewer for carefully revising our writing and we will make sure these changes are implemented accordingly. The only thing to note is that we already introduce the new indexing notation in the last sentence of page 3 as follows: \n\n\u201cCombined with the path indexing function, this establishes an injective mapping $\\phi \\circ \\varphi^{-1}$ to uniquely map a set of states $s_{1:T}$ to the $a_{1:T}$ indices, and we can view $p_{a_1^i}(z_1)$ and $p_{a_t^i}(z_t |z_{t-1})$ as equivalent notations of $p(z_1 | s_1)$ and $p(z_t |z_{t-1}, s_t)$ respectively for $s_{1:T} = \\varphi(i)$. This notation shows that the MSM extends finite mixture models to temporal settings as a finite mixture of $K^T$ trajectories composed by (conditional) distributions in $\\Pi_{\\mathcal{A}}$ and $\\mathcal{P}_{\\mathcal{A}}$\u201d\n\nWe will add a sentence clarifying that the subscript $\\theta$ is dropped for simplicity."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700131611221,
                "cdate": 1700131611221,
                "tmdate": 1700131611221,
                "mdate": 1700131611221,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zCchLy5RCf",
                "forum": "GdTOzdAX5A",
                "replyto": "JHwxfUIiK0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Detailed response to reviewer (3/3)"
                    },
                    "comment": {
                        "value": "**Questions**\n\nBelow we address the **questions** raised by the reviewer.\n\n> Q1: What is the justification for you estimation algorithm in light of the existence of the work [3] (see reference above) including benefits, disadvantages?\n\nWe appreciate the suggestion of an alternative estimation algorithm. The main justification for using approaches similar to Dong et al. (2020) [4] and Ansari et al. (2021) [5] is resorting to more recent techniques found in the literature. We note that SVAE (Johnson et al. (2017)) has been discussed in Dong et al. (2020) mentioning some of its disadvantages, which we provide below:\n- Although they combine exact Kalman Filtering and smoothing, they assume **linear** dynamics.\n- They assume a mean field posterior over continuous and discrete dynamics, which can limit the expressiveness of the inference network.\nAn additional reason to consider [4] and [5] is the fact that they directly address the problem of state collapse, which is a very important issue to consider when training SDSs (especially nonlinear SDSs).\n\n[4] Dong, Z., Seybold, B., Murphy, K. and Bui, H., 2020, November. Collapsed amortized variational inference for switching nonlinear dynamical systems. In International Conference on Machine Learning (pp. 2638-2647). PMLR.\n\n[5] Ansari, A.F., Benidis, K., Kurle, R., Turkmen, A.C., Soh, H., Smola, A.J., Wang, B. and Januschowski, T., 2021. Deep explicit duration switching models for time series. Advances in Neural Information Processing Systems, 34, pp.29949-29961.\n\n> Q2: Why do use the results of Khemakhem, Kivva that assumes that we know the noise terms distribution? Why do you not instead apply e.g. the results from Halva et al (2021), Theorem 1, that allows any arbitrary noise distribution?\n\nWe can argue using Kivva et al. (2022) from 3 different perspectives\n- Practicality: The reason for using Kivva et al. (2022) results rather than Halva et al. (2021) is the problem application (we are not doing ICA). Our important contribution is the work on identifiable MSMs, for which we provide identification results in the non-parametric case (see Appendix B) using a novel technique, given that Allman et al. (2009) results are not applicable to our setup.\n- Simplicity: Using Kivva et al. (2022) for SDSs is a natural extension of the previous model, where we use the fact that the MSM prior is analytic and closed under factored affine transformations.\n- Assumptions: Some of the assumptions that appear in Theorem 1 are not attractive to us (e.g. marginal distribution of $f(s_t)$ is stationary; $s_t$ denote sources). Note that our identifiable MSM allows nonstationary marginal continuous latent distributions (and therefore nonstationary $f(s_t))$, thanks to imposing no restrictions on the discrete state distribution.\n\nWe appreciate the reviewer\u2019s interest in the work of Halva et al. (2021). In future work, we will consider embedding our identifiable MSM within the SNICA setup to achieve alternative ICA results.\n\n\n> Q3: Why is it not possible to apply a more quantitative performance metric in the salsa experiment?\n\nWe understand the importance of providing quantitative performance metrics and will aim to provide forecasting results for the salsa dataset by the rebuttal deadline."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700131817176,
                "cdate": 1700131817176,
                "tmdate": 1700131817176,
                "mdate": 1700131817176,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "saHSazexso",
                "forum": "GdTOzdAX5A",
                "replyto": "JHwxfUIiK0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reminder for Reviewer SfP9"
                    },
                    "comment": {
                        "value": "Dear Reviewer SfP9,\n\nOnce again, we appreciate your time in reviewing our work. As the discussion period is finishing soon, we would be grateful if you could confirm whether our reply and modifications to the document addressed your concerns."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700661405751,
                "cdate": 1700661405751,
                "tmdate": 1700661405751,
                "mdate": 1700661405751,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xzx3WE35vi",
                "forum": "GdTOzdAX5A",
                "replyto": "JHwxfUIiK0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5912/Reviewer_SfP9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5912/Reviewer_SfP9"
                ],
                "content": {
                    "comment": {
                        "value": "**Thank you for your rebuttal! I have raised my score to \"slightly below acceptance\" which will be my final score and I think reflects this paper well as overall I think the paper has some nice results but not enough for this conference. Either stronger theoretical results are needed or the same results with more convincing experiments section.**\n\nDetails:\n- the rebuttal has convinced me that there is more novelty in identifying e.g. the transition parameters of the MSM/SDS and that that this wasn't done to this general level in prior work\n- nevertheless, there is a lot of overlap from several previous works. e.g. while it's true that the results don't follow fully from Kivva, a large part of the paper does. The authors also claim \"novel proof strategy\" but I disagree still, sure there are parts that are perhaps novel. But outside of Kivva, but parts of the proofs have similarities to Khemakhem; Allman; Gassiat; Morioka. \n- further: while there is some new identifiability for the SDS/MSM transitions, the identifiability of latent variables is much worse actually than in previous works in nonlinear ICA as I mentioned. I have previously been critical of Kivva for this same reason. Assuming known variance distribution is not a reasonable assumption for a work in identifiability theory. Other problematic assumption is that the of the piecewise linear nonlinearity. The authors claim *\"Kivva et al. (2022) argues piece-wise linear functions already have universal function approximation capabilities\"*. I have always find this argumentation to be faulty: universal approximation only holds at limit and we know from previous theory (Hyvarinen and Pajunen) that identifiability fails at this very limit -- thus the results do not cover general \"f(x)\" and in fact it's very hard to say where it fails and where it doesn't (e.g. what if f is a Gaussian Process?)\n- experimental work is limited and not convincing enough, as discussed, and it's hard to change one's opinion without seeing new results etc."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700679449116,
                "cdate": 1700679449116,
                "tmdate": 1700679665172,
                "mdate": 1700679665172,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]