[
    {
        "title": "DIFFNAT: IMPROVING DIFFUSION IMAGE QUALITY USING NATURAL IMAGE STATISTICS"
    },
    {
        "review": {
            "id": "nH19XzccvA",
            "forum": "mIQ2puu82H",
            "replyto": "mIQ2puu82H",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7106/Reviewer_NS8z"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7106/Reviewer_NS8z"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a \u201cnaturalness\u201d preserving loss function that can improve generative image quality on diverse tasks including image super-resolution,  unconditional image generation, and personalized few-shot fine-tuning. The proposed loss function is called the kurtosis concentration (KC) loss, which encourages the kurtosis values across different DWT (Discrete Wavelet Transform) of the images to be constant."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed method for improving image quality is simple but effective and can be applied in a plug-and-play manner. The theory of KC loss has a solid mathematical base and is persuasive.\n\n2. The quantitative experiments are sufficient to show that KC loss can effectively improve image generative quality."
                },
                "weaknesses": {
                    "value": "1. The visual results in Fig 6 do not show evident superiority of using KC loss. It is recommended to provide visual results with their corresponding KC statistic maps. \n\n2. The computational complexity of KC loss is not discussed. It is recommended to report the additional time consumption caused by KC loss."
                },
                "questions": {
                    "value": "Please see the Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7106/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7106/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7106/Reviewer_NS8z"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7106/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698240500377,
            "cdate": 1698240500377,
            "tmdate": 1699636839543,
            "mdate": 1699636839543,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "c8SWFry8zt",
                "forum": "mIQ2puu82H",
                "replyto": "nH19XzccvA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7106/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7106/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer NS8z"
                    },
                    "comment": {
                        "value": "**Q1. [The visual results in Fig 6 do not show evident superiority of using KC loss. It is recommended to provide more visual results]**\n\nResponse: Thanks for the suggestion!  More visual results have been provided in Fig. 18, 19, 20, 21, 22, 23, 24, 25 (Appendix).\n\n**Q2. [The computational complexity of KC loss is not discussed. It is recommended to report the additional time consumption caused by KC loss.]**\n\nResponse: The computation complexity of the proposed loss is presented in Sec. F (Computation complexity). The runtime analysis has been provided in Sec. G (Training time analysis) and Tab. 6 (Appendix)."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7106/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699976989277,
                "cdate": 1699976989277,
                "tmdate": 1699976989277,
                "mdate": 1699976989277,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ScPvmZq8Tf",
                "forum": "mIQ2puu82H",
                "replyto": "FOcpuiwjKG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7106/Reviewer_NS8z"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7106/Reviewer_NS8z"
                ],
                "content": {
                    "comment": {
                        "value": "The author's rebuttal addresses most of my concerns, and I'll keep my score."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7106/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700554837020,
                "cdate": 1700554837020,
                "tmdate": 1700554837020,
                "mdate": 1700554837020,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "pwCMZGDKiO",
            "forum": "mIQ2puu82H",
            "replyto": "mIQ2puu82H",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7106/Reviewer_XKja"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7106/Reviewer_XKja"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors utilize a generic naturalness, i.e. the kurtosis concentration (KC) loss, to improve diffusion model. The authors validate the proposed KC loss on three diffusion-based tasks, the experimental results show that introducing appropriate prior of natural image could lead to better generation model."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1) The authors validated the effectiveness of KC loss and show that appropriate prior of natural image is beneficial for diffusion model training.\n2) The proposed KC loss is easy to optimize.\n3) The authors validated the proposed loss on three widely studied tasks, the superiority experimental results validated the effectiveness of the proposed method."
                },
                "weaknesses": {
                    "value": "1) The authors argue that they provided theoretical insights into the advantage of KC loss, however, the theorems only analyzed the correctness of KC loss but did not analyze why the KC loss is beneficial for diffusion model training. I think the authors over claimed their contribution.\n2) In the literature of natural image prior modeling, a large variaty of models have been suggested for modeling natural image prior. Besides KC loss, are there any other priors which is beneficial for training diffusion models.\n3) The authors only analyzed the final generation quality with widely used image quality metrics, it will be the best if the authors could further present other properties of the proposed model, for example, can KC loss improve the convergence speed, will the additional KC loss leads to longer training time?"
                },
                "questions": {
                    "value": "Please refer to the weakness part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7106/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698652800946,
            "cdate": 1698652800946,
            "tmdate": 1699636839434,
            "mdate": 1699636839434,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1dAjcC0eXS",
                "forum": "mIQ2puu82H",
                "replyto": "pwCMZGDKiO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7106/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7106/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer XKja"
                    },
                    "comment": {
                        "value": "**Q1. [the theorems only analyzed the correctness of KC loss but did not analyze why the KC loss is beneficial for diffusion model training]**\n\nResponse: In the theoretical analysis, we motivate justifying how the KC loss improves denoising. Note that we are not proposing a new training methodology for diffusion models, rather the proposed loss is a plug-and-play module which can be integrated into any standard diffusion model pipeline. (as shown empirically in Sec. 4.1, 4.2, 4.3 of the main paper).\n\n**Q2. [ Besides KC loss, are there any other priors which are beneficial for training diffusion models?]**\n\nResponse: The most well-known prior for natural images is scale invariance, and (Zhang & Lyu) show that kurtosis concentration property can be motivated by the well-known prior for natural images, characterized by scale invariance. There might be some other natural image priors, but we haven\u2019t considered those in this paper (beyond the scope of this paper). Alternatively, we have also compared our method with LPIPS loss (i.e., a perceptual loss) , which we have added as a baseline as shown in Tab. 1, Tab. 2, Tab. 3 in the revised version.\n\n**Q3. [it will be the best if the authors could further present other properties of the proposed model, for example, can KC loss improve the convergence speed, will the additional KC loss leads to longer training time?]**\n\nResponse: Thanks for the suggestion! We have provided the complexity analysis of the proposed KC loss in Sec. F (Computation complexity). Additional experiments for timing analysis have been provided in Table. 6 (training time analysis). \n\nThe main idea of the diffusion model is to train a UNet, which learns to denoise from a random noise to a specific image distribution. More denoised steps typically ensure a better denoised version of the image, as seen in DDPM, LDM. In proposition 1, we show that minimizing projection kurtosis further denoise input signals. Therefore, KC loss helps in the denoising process and improves the convergence speed of the UNet. This has been discussed in the paragraph right after proposition 1 in the main paper. Fig. 3 shows using the same number of steps (400), a model trained with KC loss generates better quality images (measured in terms of SNR) than a standard guided diffusion model (both models were trained for the same number of epochs). This has been addressed in Sec. I (convergence analysis) in the Appendix of the updated version of the paper. The Loss convergence is shown in Fig. 14 in the Appendix of the updated version of the paper."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7106/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699976919892,
                "cdate": 1699976919892,
                "tmdate": 1699976919892,
                "mdate": 1699976919892,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "kM7qY3CGTF",
            "forum": "mIQ2puu82H",
            "replyto": "mIQ2puu82H",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7106/Reviewer_4XiE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7106/Reviewer_4XiE"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a novel kurtosis concentration loss to preserve image \"naturalness\" to enhance image quality within standard diffusion model pipelines by reducing the kurtosis gap between band-pass image versions. The evaluation of the KC loss across diverse tasks show consistent improvements in perceptual quality via metrics like FID, MUSIQ score, and user evaluations."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The idea is interesting and novel. The idea of designing a quality measure to align the distribution of natural images and generated images from the diffusion models is novel.\n2. The paper is clearly written. The reviewers can easily understand what the authors hope to convey."
                },
                "weaknesses": {
                    "value": "1. The experiments are not extensive. More comparisons on the conditional image-to-image translation should be provided.\n2. Despite improvement in quantitative results, the visual differences in using the loss or not are minor.\n3. This technical route, i.e. using IQA for improving generation quality, seems to be less effective than other alternative routes, e.g. [1].\n[1] Susung Hong, Gyuseong Lee, Wooseok Jang, Seungryong Kim, \"Improving Sample Quality of Diffusion Models Using Self-Attention Guidance,\" ICCV, 2023.\n4. The presented visual results are in small resolutions. Higher resolution results are suggested for putting into the paper."
                },
                "questions": {
                    "value": "1. Why are the FID values in the paper so high compared to those in other papers?\n2. The PSNR results shown in Table 3 are also very low."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7106/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698663382030,
            "cdate": 1698663382030,
            "tmdate": 1699636839308,
            "mdate": 1699636839308,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "aRUmhgI47k",
                "forum": "mIQ2puu82H",
                "replyto": "kM7qY3CGTF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7106/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7106/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 4XiE"
                    },
                    "comment": {
                        "value": "**Q1. [The experiments are not extensive. More comparisons on the conditional image-to-image translation should be provided.]**\n\nResponse: We have updated the main paper with additional experiments using more baselines in Tab. 1, Tab. 2, Tab. 3. We also include additional qualitative results in Fig. 18, 19, 20, 21, 22, 23, 24, 25 in the Appendix.\n\n\n**Q2. [Despite improvement in quantitative results, the visual differences in using the loss or not are minor.]**\n\nResponse: We have provided more qualitative results (zoomed version) in Fig. 18, 19, 20, 21, 22, 23, 24, 25 (Appendix).\n\n\n**Q3. [less effective than other alternative routes, e.g. [1]. [1] Susung Hong, Gyuseong Lee, Wooseok Jang, Seungryong Kim, \"Improving Sample Quality of Diffusion Models Using Self-Attention Guidance,\" ICCV, 2023.]**\n\nResponse: Our proposed loss function is used during training diffusion models. On the other hand, [1] is a training free approach and they propose to use self-attention guidance during inference. Therefore, these approaches are not comparable, but rather complementary to each other. Moreover, [1] uses an additional forward pass to generate the attention map, which increases the computation complexity 2x compared to guidance free method, whereas our method introduces very less overhead during training (See Table. 6, Appendix).\n\n**Q4. [The presented visual results are in small resolutions. Higher resolution results are suggested for putting into the paper.]**\n\nResponse: We have presented the results in Fig. 11, 12, 18, 19, 20, 21, 22, 23, 24, 25 (Appendix) in high resolution.\n\n**Q5. [Why are the FID values in the paper so high compared to those in other papers? The PSNR results shown in Table 3 are also very low.]**\n\nResponse: For a fair comparison, we have reproduced the baselines with the same training setting and images, and the results are reported. In a similar setting, using KC loss produces images with lesser FID and higher MUSIQ scores across tasks and datasets, which validate the efficacy of the proposed KC loss."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7106/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699976778578,
                "cdate": 1699976778578,
                "tmdate": 1699976778578,
                "mdate": 1699976778578,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vRRzx3dRWR",
            "forum": "mIQ2puu82H",
            "replyto": "mIQ2puu82H",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7106/Reviewer_en6K"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7106/Reviewer_en6K"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes to improve quality and reduce artifacts in diffusion-based generative models. More specifically, they propose a kurtosis concentration loss to increase SNR and therefore improve results' quality. Their method can be applied a wide range of generative pipelines."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. I think the mentioned problem of naturalness in generative process is important. And the idea to use natural image priors to improve quality is reasonable.\n\n2. The paper writing is clear to follow."
                },
                "weaknesses": {
                    "value": "1. My main concern is about effectiveness of this KC loss. In the experiment part, the authors gives FID and MUSIQ in Table 1, 2, which I think shows little improvements. And we all know that these metrics can not accurately measure image quality. \nMoreover, in Fig 6, Fig 8, Fig 9 and Fig 10, it is not obvious whether KC loss yields better results. I think the authors need to at lease hightlight the region or illustrate using zoom-out regions to show the difference.\n\n2. Although I also appreciate very much those early works about natural image priors, I think most of them are based on simplistic assumptions which may not be needed in today's large-data-driven methods.\nMore specically, I doubt that why kurtosis-based losses suit for the mentioned artifacts problem? Actually, losses need to be designed based on properties that you want to distinguish. I think at least statistics of a large amount of artifact images are needed. to prove kurtosis is a proper metric.\n\n3. In Fig 1, the authors show severe unnatural artifacts. However, I wonder is that really a common phenomenon? It is more like a bug in training process, and similar artifacts are not present in the other illustrations in the paper. Then what exactly are the types of artifacts that the authors want to solve?\n\n4. In Equ 5, the authors claim that diffusion models are typically trained using reconstruction loss in image domain. However, as far as I known, many diffusion models do not use such reconstruction loss, for example DDPM, DDIM. \nMoreover, the loss and optimization of diffusion model typically follow mathematical derivations. I wonder if we incorporate KC loss, do the training process still theoretically sound?"
                },
                "questions": {
                    "value": "Please address the problems in weaknessed part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7106/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7106/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7106/Reviewer_en6K"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7106/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698763895745,
            "cdate": 1698763895745,
            "tmdate": 1700409461364,
            "mdate": 1700409461364,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "yk9JypBBlO",
                "forum": "mIQ2puu82H",
                "replyto": "vRRzx3dRWR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7106/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7106/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer en6K"
                    },
                    "comment": {
                        "value": "**Q1. [My main concern is about the effectiveness of this KC loss ..authors need to at least highlight the region or illustrate using zoom-out regions to show the difference]**\n\nResponse: The effectiveness of KC loss has been shown quantitatively in Tables 1, 2, 3 (main paper). We have shown some qualitative examples in the paper, and based on the suggestion we have added more results highlighting the improved image quality. We have also verified the quality improvement using user study (Sec. human evaluation, page 7 main paper) by Amazon Mechanical Turks, and show that the generated images are indeed high quality. The comprehensive analysis is added in Sec J (Qualitative analysis, Appendix) ( Fig. 18, 19, 20, 21, 22, 23, 24, 25 in Appendix).\n\n**Q2. [Although I also appreciate very much those early works about natural image priors, I think most of them are based on simplistic assumptions which may not be needed in today's large-data-driven methods]** \n\nResponse: We use the naturalness prior to design a plug-and-play loss function to improve the image quality of the generated images. The loss can be added to any diffusion pipeline and further improve the image quality which is experimentally validated in the paper (Tab. 1, Tab. 2, Tab. 3 in the main paper). Hence, we contend that this loss does not serve as a substitute for large-scale data-driven methods; instead, it complements and enhances existing pipelines.\n\n**Q3. [I doubt that why kurtosis-based losses suit for the mentioned artifacts problem?.. at least statistics of a large amount of artifact images are needed. to prove kurtosis is a proper metric]**\n\nResponse: We would also like to clarify that the artifact issue is limited to some particular approaches (personalized few-shot finetuning, e.g., dreambooth, custom diffusion). Overall, our goal is to improve the image quality. More experimental results are added to visually show this in  Fig. 18, 19, 20, 21, 22, 23, 24, 25 (Appendix).\n\nWe also provide the average kurtosis analysis (Sec. H ) in the Appendix of the updated paper. It is observed that integrating KC loss reduces the kurtosis deviation, which resembles average natural image kurtosis statistics (Fig. 15, Fig. 16, Fig. 17 in the Appendix).\n\n**Q4. [In Fig 1, the authors show severe unnatural artifacts. However, I wonder is that really a common phenomenon?.. Then what exactly are the types of artifacts that the authors want to solve?]**\n\nResponse: Our primary goal is to improve the image quality of generated images produced by diffusion models for different tasks. We are not specifically targeting any unnatural artifact reduction during the generation process. One of the tasks is personalized few-shot finetuning (e.g., Dreambooth), featured in the teaser figure (Fig. 1). In Dreambooth, having unnatural artifacts is a known phenomenon (Ruiz et al.) since overfitting/underfitting might happen due to training a large model from a few examples, which might lead to poor-quality images, having higher FID scores. Therefore, the unnatural artifact issue is just an anecdotal instance and is not the primary motive of the paper. For example, this is not an issue in unconditional image generation, image super-resolution tasks. We primarily focus on improving the overall image quality in this paper."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7106/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699976532848,
                "cdate": 1699976532848,
                "tmdate": 1699976532848,
                "mdate": 1699976532848,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aP6ZvxRpnG",
                "forum": "mIQ2puu82H",
                "replyto": "WJ6XyvSHZ5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7106/Reviewer_en6K"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7106/Reviewer_en6K"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "Thanks for the response for previous comments. I read the response and the revised paper.\nThe response partly addressed my questions. But I think several questions are still not satisfying.\n\n1. `Artifact` / 'unnatural' is too general. Previously I want to know what exacly the kind of artifacts that this paper want to address. Color saturation, noise, blocking or others? And it would be better to explain a little more why KC loss can solve these.\n\n2. In Q3, I mean do those artifacts images really have larger KC values on statistics over a large dataset?\nIn Fig 17, the model with KC loss minimization will definitely has lower Kurtosis. But why `natural images have more concentrated kurtosis values'? I think the authors explain the effectiveness of the proposed method based on others' assumption, neglecting on what situation, for what kind of artifacts, on what kind of data (face or senary?) where the assumption works.\n\n3. In Q6, I mean the orignal loss and model of diffusion follows strict mathematical derivations. I just wonder if use KC loss, can we still find a suitable and strict derivations for that? However, I think the authors misunderstand and have not think in this direction. Indeed, neural networks can add loss at will and does not necessarily need to be strictly derived.\n\nI like the idea to use priors for networks. However, I think we need to know very clearly what exact problem we want to solve and why these priors are suitable and theorectically correct, rather than just borrow and use like a black box. Therefore, I think I still lean to reject."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7106/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700409298553,
                "cdate": 1700409298553,
                "tmdate": 1700409298553,
                "mdate": 1700409298553,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]