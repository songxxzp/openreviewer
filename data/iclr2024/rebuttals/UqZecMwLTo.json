[
    {
        "title": "A Unified Concept-Based System for Local, Global, and Misclassification Explanations"
    },
    {
        "review": {
            "id": "QpBpNnTgQs",
            "forum": "UqZecMwLTo",
            "replyto": "UqZecMwLTo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2455/Reviewer_ZcJk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2455/Reviewer_ZcJk"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a novel automated concept extraction and evaluation method that gives both local and global concepts to explain computer vision models. Their method takes inspiration from the field of Outlier detection, specifically using the softmax probability as an OOD detector, to fine-tune surrogate models that detect if concepts --image segments-- are important or not for a class. They evaluate their method against 4 attribution methods and show that their local explanation is competitive in terms of faithfulness and better in terms of completeness."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The framing of concept importance as the \"ood-ness\" of a concept w.r.t to the class of interest is interesting\n- The paper is overall clear\n- The evaluation w.r.t to feature attribution methods that also use surrogate models to give local importance scores is comprehensive"
                },
                "weaknesses": {
                    "value": "- The contextualization of the paper in terms of prior concept-based methods is missing important and relevant methods.[1-2-3]\n- Overall the evaluation is unconvincing. While the method is framed as an automated concept-based method, it does not compare itself to any other automated concept-based method [1-2], so it is hard to judge the proposed method\n- Minor weakness but I would advise dropping the notion of  \"ood\" images in the methodology as here no samples are really ood in the true sense of the term (except arguably the segment but certainly not the image from other classes) \n\n[1] Zhang et al. Invertible concept-based explanations for cnn models with non-negative concept activation vectors. In Proceedings\nof the AAAI Conference on Artificial Intelligence, volume 35, pages 11682\u201311690, 2021.\n\n[2] Fel et al. Craft: Concept recursive activation factorization for explainability. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023.\n\n[3] Fel et al. A Holistic Approach to Unifying Automatic Concept Extraction and Concept Importance Estimation. arXiv. 2023"
                },
                "questions": {
                    "value": "- The definition of concept in the literature is usually of a direction in the latent space of a model. How would you define the notion of concept in your method? \n- If I understand correctly, you fine-tune your surrogate model with images and their true label, is there a reason you do not use the output of the base model as a label instead?\n- In the evaluation, talking about GradCAM and LRP you say \"two attribution methods modified for the concept-based explanations\" what does that mean?\n- What is the motivation behind evaluating the generality of the concepts extracted by the proposed method? I would have argued that this is not necessarily something we want from an explainability method (which explains a specific model) to aim to be general so as to be able to explain different models at the same time."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2455/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2455/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2455/Reviewer_ZcJk"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2455/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698513402948,
            "cdate": 1698513402948,
            "tmdate": 1699636181658,
            "mdate": 1699636181658,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "iyvkvKuJ1a",
            "forum": "UqZecMwLTo",
            "replyto": "UqZecMwLTo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2455/Reviewer_2Hkv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2455/Reviewer_2Hkv"
            ],
            "content": {
                "summary": {
                    "value": "This paper centers on the subject of concept-based explanations in machine learning models. The authors introduce a unified framework designed to offer both local and global concept-based explanations, in addition to elucidating misclassifications. While the methodology proposed is straightforward, it is capable of generating cogent results."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "Concept-based explanation in deep learning models constitutes a critical issue in the field of interpretable and explainable artificial intelligence.\n\nThe framework presented in the paper has the capability to furnish both local and global explanations, although it should be noted that pre-existing frameworks also possess this feature."
                },
                "weaknesses": {
                    "value": "The adoption of a model tailored for binary classification tasks in UCBS appears to be a point of concern. This configuration prevents the concept-based system from contrasting the target class against a specific non-target class, leading to a loss of information. This approach diverges from the operation of deep learning (DL) classification models, which are typically trained to contrast multiple classes concurrently using a softmax function.\n\nA lot of details are missing. Is the binary DNN classifier a separately trained network? Or is it using the encoder of the original network (the neural network it is explaining) and adding an additional binary classification head?\n\nThe authors assert that UCBS obviates the necessity for user-defined concepts and the application of external scoring methods (i.e., it eliminates \u201cthe need for providing user-defined concepts and applying external scoring methods\u201d). However, the binary DNN classifier employed in their approach could arguably be considered an external tool. Furthermore, the paper lacks clarity on the distinct advantages of UCBS in comparison to other established methods like TCAV.\n\nThis leads to a closely related significant concern: the absence of pertinent baseline methods. There exists a substantial body of work on concept-based explanations for deep neural networks (DNNs), yet none of these are included as baselines in the paper. Consequently, it becomes unfeasible to assess UCBS's merits relative to the state-of-the-art. It's worth noting that the baselines employed in the paper, such as SHAP and LIME, are general methods and not specific to concept-based approaches.\n\nAdditionally, the authors characterize UCBS as an unsupervised learning method, a claim that appears misleading. UCBS relies on a segmentation neural network that is trained in a supervised manner. The labels used for training these segmentation networks essentially become the inherited concepts for UCBS. Therefore, this claim about the unsupervised nature of UCBS does not seem to be accurate."
                },
                "questions": {
                    "value": "See comments above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2455/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698680231696,
            "cdate": 1698680231696,
            "tmdate": 1699636181590,
            "mdate": 1699636181590,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "cdao8ZVEHj",
            "forum": "UqZecMwLTo",
            "replyto": "UqZecMwLTo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2455/Reviewer_itZT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2455/Reviewer_itZT"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed UCBS, a new concept-based interpretation system to analyze the dataset of image classifiers locally and globally. The main idea is to train surrogate models classifying original/super-pixel images of the given class and randomly selected images, then leverage this model to rank and figure out the concepts. The paper showed that UCBS outperforms LIME, SHAP, LRP, and GradCAM in various metrics such as Insertion, Deletion, etc. I agree with the nature of the importance of this topic, but the method is too simple, and the motivation of the main idea is not described well."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The idea is straightforward to follow and reproduce.\n- The cost of the proposed method is lower than recently proposed saliency map-based explanation methods.\n- UCBS outperformed the other baselines, such as LIME, SHAP, LRP, and GradCAM."
                },
                "weaknesses": {
                    "value": "- Concerns on implementation\n  - It is mentioned that the output of the convolution, maxpool, and avgpool with zero pixel area is zero. However, the color of the padded area in the figure is black, which means that the value of the padded area will not be zero after input normalization. This brings out the concerns that the implementation differs from the intentions described on page 3. \n- Underestimated performance of baselines\n  - The deletion score of LIME and GradCAM of the paper (https://arxiv.org/pdf/1806.07421.pdf) is 0.12, which is much lower than the numbers denoted in this paper. \n- Presentations\n  - The datasets $\\mathcal{D^c}$, $\\mathcal{D^c_{S}}$, and $\\mathcal{D^c_{out}}$ are defined as sets of images in the notation section, while they seem sets of $(x, y)$ tuples in Eq (2).\n  - I guess from Figure 1a that $y = 0$ for $\\mathcal{D^c_{out}}$ and $y = 1$ for otherwise, but it is not denoted in the paper.\n  - Notation $c$ is sometimes omitted without mention.\n  - I guess the $Net_S$ should be a set of functions with the same numbers as class, $Net_S= ${$f^c_\\theta$}.\n  - The images in Figure 1 are too small.\n- Absence of ablation study\n  - I believe it is essential for this paper to show the ablation study, especially for concept learning. Specifically, we can replace the logit of surrogate model $f_\\theta^{'c}$ as $IS(s_{i,j}) = f_\\theta^{'c}(s_{i,j})$ with a pre-trained image classifier."
                },
                "questions": {
                    "value": "- Is there any analysis that training using superpixel or segment helps the model to learn important regions more than background regions? \n- Why there is $c$ in notation $f_\\theta^{',c}$ while there is no $c$ in $f_\\theta$?\n- How about leveraging the image captioning models to see the concepts in the text?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2455/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2455/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2455/Reviewer_itZT"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2455/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698728503686,
            "cdate": 1698728503686,
            "tmdate": 1699636181462,
            "mdate": 1699636181462,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "yR3F8fh3M1",
            "forum": "UqZecMwLTo",
            "replyto": "UqZecMwLTo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2455/Reviewer_u8Pp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2455/Reviewer_u8Pp"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a novel framework called Unified Concept-Based System (UCBS) that provides concept-based explanations of Deep Neural Networks (DNNs). \nContrary to traditional eXplainable AI (XAI) methods that work on the level of single input features (pixels for image data), UCBS operates on the concept level providing more human-understandable explanations. Concepts are hereby defined as input feature groups (super-pixels) extracted from the dataset. \n\nAn essential feature of the UCBS framework is its ability to generate both local (instance-wise) and global (class-wise) explanations.\nBy comparing local and global explanations, UCBS enables a deeper understanding of misclassified predictions.\nTo compute local importance scores of concepts, surrogate models are employed. These surrogate models are fine-tuned versions of the original (explained) DNNs.\n\nThe authors illustrate the effectiveness of the UCBS approach through both qualitative and quantitative assessments, comparing it to established (local) XAI methods. Qualitatively, they provide examples of correct and incorrect predictions, showcasing how UCBS enhances interpretability. Quantitatively, the authors evaluate the model in terms of faithfulness, completeness, and generality.\""
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The UCBS framework's capability to produce both local (instance-wise) and global (class-wise) explanations is a vital aspect.\nIndeed, it seems to be very useful to combine both local and global explanations to gain an understanding of how individual predictions deviate from the typical case.\n\nThe methodology section of the UCBS approach is clearly described and straight-forward to understand.\n\nThe authors thoughtfully acknowledge limitations of UCBS, notably the dependency on super-pixels.\n\nIn the evaluation section, the qualitative examples provided are clear and effectively illustrate the practical utility of their approach."
                },
                "weaknesses": {
                    "value": "The local component of UCBS appears to closely resemble traditional local XAI methods, such as SHAP and LIME, by focusing on super-pixel relevance scores. \nHowever, it may be more insightful to explore the presence of global concepts within the local (prediction) context and their respective importance, akin to the methods introduced in CRP [1] and CRAFT [2].\nOnly the global UCBS component seems to be concept-based (by operating on the latent representations of the DNN).\n\nIn terms of the limitations of UCBS, a more comprehensive discussion regarding the number and relevance of hyper-parameters, particularly in the context of fine-tuning surrogate models, would provide a valuable addition. An ablation study investigating the influence of these hyper-parameters on the quantitative evaluation metrics would be of interest.\n\nConcerning the quantitative evaluation, it's worth noting that the authors exclusively compare UCBS against local XAI methods. It would be beneficial to see a comparison against other concept-based XAI methods to provide a more comprehensive perspective. Additionally, the faithfulness evaluation curves are presented for only two methods and two samples in the appendix. Including the final curves used to calculate faithfulness metrics would enhance the overall value of the analysis.\"\n\n[1] Achtibat, Reduan, et al. \"From attribution maps to human-understandable explanations through Concept Relevance Propagation.\" Nature Machine Intelligence 5.9 (2023): 1006-1019.\n\n[2] Fel, Thomas, et al. \"Craft: Concept recursive activation factorization for explainability.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023."
                },
                "questions": {
                    "value": "Can you motivate the choice of the generality metric? Would it be possible to compare UCBS here to some other concept-based XAI method?\n\nIt would be also interesting to compare your (local) component against other local XAI approaches (LRP, SHAP, etc.) in terms of computational complexity, as it seems to be only based on few DNN forward passes (one for each super-pixel)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2455/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2455/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2455/Reviewer_u8Pp"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2455/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698763820881,
            "cdate": 1698763820881,
            "tmdate": 1699636181384,
            "mdate": 1699636181384,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "Xnu3bVVbeW",
            "forum": "UqZecMwLTo",
            "replyto": "UqZecMwLTo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2455/Reviewer_DJR7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2455/Reviewer_DJR7"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a unified framework for generating both local and global concept based explanations. The proposed framework considers a surrogate model trained with superpixels of an image for generating concepts, which are used then used to extract local and global explanations."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The proposed approach is innovative and can be used to generate and score the relevance of concepts\n- The illustrations of local explanations are well presented, nice framework and illustration figures\n- The paper is well written and easy to follow"
                },
                "weaknesses": {
                    "value": "- The proposed approach is certainly not the first to explore the extraction of local and global explanations, please refer to [1, 2]. \n- What is the motivation for having the out-of-distribution dataset to train the surrogate model?\n- The proposed approach only captures the concepts that can be described as a part of an image. Is it possible to capture concepts like lighting that are expressed in an entire image?\n- I'm unsure of how to interpret global explanations. Can you please provide more discussion for the same? \n- It is a bit unclear how the scores in Table 1 are computed, given the UCBS is fine-tuned on superpixel images; the scores like insertion, deletion, and faithfulness are expected to be high for UCBS, given they are on the manifold, while in case of LIME, SHAPE, GradCAM, and LRP the concepts are off-manifold resulting in lower score. Could you please justify this?\n  \n\n\n[1] Kori, A., Glocker, B. and Toni, F., 2022. GLANCE: Global to Local Architecture-Neutral Concept-based Explanations.\u00a0_arXiv preprint arXiv:2207.01917_.\n\n[2] Setzu, M., Guidotti, R., Monreale, A., Turini, F., Pedreschi, D. and Giannotti, F., 2021. Glocalx-from local to global explanations of black box ai models.\u00a0_Artificial Intelligence_,\u00a0_294_, p.103457."
                },
                "questions": {
                    "value": "Please refer to weakness section"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2455/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2455/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2455/Reviewer_DJR7"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2455/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698771312110,
            "cdate": 1698771312110,
            "tmdate": 1699636181297,
            "mdate": 1699636181297,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]