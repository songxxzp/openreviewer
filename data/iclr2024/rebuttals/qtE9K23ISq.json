[
    {
        "title": "Towards domain-invariant Self-Supervised Learning with Batch Styles Standardization"
    },
    {
        "review": {
            "id": "sdrTfQtWEu",
            "forum": "qtE9K23ISq",
            "replyto": "qtE9K23ISq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission304/Reviewer_qeEH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission304/Reviewer_qeEH"
            ],
            "content": {
                "summary": {
                    "value": "Existing UDG ( Unsupervised Domain Generalization) methods usually require samples to have domain labels for better learning of domain invariant features. The collection of domain labels is also costly in practical scenarios, which limits existing UDG. This paper proposes a BSS ( Batch Styles Standardization) approach in combination with existing SSL ( Self Supervised Learning ) methods, eliminating the need for domain labels. The authors combine the proposed BSS method with several SSL methods, experiment on UDG datasets, and obtain significant improvement in results."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This paper studies a novel problem, i.e. Unsupervised Domain Generalization without domain label. The basic idea is sound and very worthwhile.\n2. Compared with the existing UDG methods, the experimental accuracy of the author's method has a significant advantage.\n3. The writing is good, and the structure is easy to follow.\n4. The ablation experiment was adequate.\n5. In the part of comparative experiment, the author combined BSS with various types of SSL methods to demonstrate the universality of this method."
                },
                "weaknesses": {
                    "value": "1. Inadequate ablation experiments.\n\nIn Section 5.2, the authors do not show the ablation effect of the original SimCLR. Table 4 demonstrates the effectiveness of FA and BSS compared to baseline SimCLR. However, it is not reflected in Section 5.2. So it does not show that FA and BSS are effective compared to \noriginal SimCLR.\n\n2. Perhaps there is a limitation to BSS.\n\nAssuming that domain labels are not available, there is no guarantee that a number of randomly selected images belong to different domains. As the author said, \"Finally, after applying the inverse Fourier transform to the different modified Fourier transforms, the style of the randomly chosen image is transferred to all images, effectively standardizing/harmonizing the style.\"\nIn the worst case, it is possible that a number of randomly selected images all belong to the same domain (same style), and then their magnitude spectra may be similar. If the magnitude spectra of these images are still used to augment all of the images, it may indeed create harder negative samples (because of the similar magnitude spectra). However, it would also create the problem of more similarity between pairs of positive samples, potentially forcing the network to capture more similar style information than domain invariant information in the positive sample pairs."
                },
                "questions": {
                    "value": "1. What does \"spurious correlations\" mean? Is it the possibility that in SSL, when repelling negative samples, the main basis for error may be the difference in style?\n2. In section 4.2, \"We did not use ImageNet transfer learning, except on DomainNet to allow fair comparisons with prior UDG works.\" Does it mean that this paper uses an ImageNet pre-trained model when conducting experiments on the DomainNet dataset?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission304/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697543760924,
            "cdate": 1697543760924,
            "tmdate": 1699635957092,
            "mdate": 1699635957092,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "OCbbz9l5Oh",
                "forum": "qtE9K23ISq",
                "replyto": "sdrTfQtWEu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission304/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission304/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your time and insightful feedback. You will find below a response to your concerns/comments/questions.\n\n> **In Section 5.2, the authors do not show the ablation effect of the original SimCLR.**\n\nWe have conducted the same ablation experiments as detailed in Section 5.2 specifically for a SimCLR with standard image data augmentation. The results of these additional experiments have been included to the existing plots on Figure 2. In examining the experiment on average domain purity varying with the number of nearest neighbors (Figure 2a), standard SimCLR exhibits only slightly higher average domain purity than SimCLR with FA, but significantly higher than SimCLR with Batch Style Standardization (BSS) (higher domain purity is worse). This observation suggests that FA does not significantly enhance domain-invariance compared to BSS. Similarly, in Figure 2b, it is noticeable that standard SimCLR results in negatives dissimilar to the anchors. SimCLR with FA produces negatives more similar to the anchors but not to the same extent as SimCLR with BSS. Finally, in terms of performance concerning batch size, standard SimCLR yields considerably lower performances compared to SimCLR with FA or with BSS.\n\n> **Perhaps there is a limitation to BSS. Assuming that domain labels are not available, there is no guarantee that a number of randomly selected images belong to different domains. [...] it may indeed create harder negative samples. However, it would also create the problem of more similarity between pairs of positive samples, potentially forcing the network to capture more similar style information than domain invariant information in the positive sample pairs.**\n\nIndeed, in the worst-case scenario, we could sample a batch of $N$ examples from a single domain (same style). Applying BSS successively $V$ times on this batch would result in\n$V$ batches of examples, each with its own style (as depicted in Fig 1c). As you correctly mentioned, because all examples initially came from the same domain (same style), we should end up with a single style for all examples, creating harder negatives but simpler positives. In contrastive learning, the loss tries at the same time to bring the positive pairs closer and to drive away the negative ones: since in this pathological case, all examples have the same style, the style cannot be used to do both at the same time. It should also be noted that on top of the style standardization, geometric augmentation and batch-wise color augmentations are applied (see section 3.2.2, ablation in section 5.1, table 4). This mitigates the problem since the $V$ positives have undergone different color augmentations.\n\n> **What does \"spurious correlations\" mean?**\n\nIn general, correlations or features are said to be spurious when they predict the target label without possessing a causal relationship with it. In the context of SSL, spurious features would be typically associated with non-causal attributes such as style (color, texture, etc.), while the target variable would be the ones related to the SSL task objectives. As an example, in SimCLR, when diverse styles coexist among the positive and negative examples, \u201cstyle features\u201d may be used to solve the contrastive task.\n\n> **In section 4.2, \"We did not use ImageNet transfer learning, except on DomainNet to allow fair comparisons with prior UDG works.\" Does it mean that this paper uses an ImageNet pre-trained model when conducting experiments on the DomainNet dataset?**\n\n Using Transfer Learning / pretrained models in DG/UDG is a common practice in the community but we think it is misguided. Often the pre-training dataset, like ImageNet for example, can include one or more of the target domains  (e.g: photo for PACS). We have tried to limit as much as possible the usage of transfer learning in our experiments and only used it for the DomainNet dataset."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission304/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700130090377,
                "cdate": 1700130090377,
                "tmdate": 1700148741395,
                "mdate": 1700148741395,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jPMGoaV6Qb",
                "forum": "qtE9K23ISq",
                "replyto": "OCbbz9l5Oh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission304/Reviewer_qeEH"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission304/Reviewer_qeEH"
                ],
                "content": {
                    "title": {
                        "value": "The standard SimCLR is not included in Figure2."
                    },
                    "comment": {
                        "value": "If the author-uploaded PDF is accurate, the three subfigures in Figure 2 indeed only contain SimCLR w/ FA and SimCLR w/ BSS (without a third standard SimCLR or SimCLR w/o any). Intuitively, SimCLR w/o any should perform worse than both SimCLR w/o FA and SimCLR w/o BSS because it does not use any cross-domain data augmentation. However, for rigor, it's still necessary for the authors to present the baseline SimCLR results to demonstrate the effectiveness of methods like BSS or FA for UDG."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission304/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700233246754,
                "cdate": 1700233246754,
                "tmdate": 1700233246754,
                "mdate": 1700233246754,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jDDRohTLvz",
                "forum": "qtE9K23ISq",
                "replyto": "OCbbz9l5Oh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission304/Reviewer_qeEH"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission304/Reviewer_qeEH"
                ],
                "content": {
                    "title": {
                        "value": "The worst-case scenario of BSS"
                    },
                    "comment": {
                        "value": "Thanks to the authors for the answers to the question. In fact, the probability of the worst-case scenario occurring is very small. And even if it occurs it's hard to say what effect it would have in training, which is a difficult abstract question to answer, so I apologize for being too harsh in suggesting a BSS limitation.\n\nIn addition, I think BSS can be optimized to change the strategy of choosing images for augmenting. An immature idea is to design a function f(-, -) that compares the similarity of the amplitude spectra between samples, and by comparing the amplitude spectra of all the samples in a mini-batch, the top-k samples that have the lowest similarity with the other samples will be selected as the \"chosen image\"."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission304/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700235892126,
                "cdate": 1700235892126,
                "tmdate": 1700235892126,
                "mdate": 1700235892126,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WVdd9O8ceL",
                "forum": "qtE9K23ISq",
                "replyto": "sdrTfQtWEu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission304/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission304/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Re: The standard SimCLR is not included in Figure2."
                    },
                    "comment": {
                        "value": "> **If the author-uploaded PDF is accurate, the three subfigures in Figure 2 indeed only contain SimCLR w/ FA and SimCLR w/ BSS (without a third standard SimCLR or SimCLR w/o any). Intuitively, SimCLR w/o any should perform worse than both SimCLR w/o FA and SimCLR w/o BSS because it does not use any cross-domain data augmentation. However, for rigor, it's still necessary for the authors to present the baseline SimCLR results to demonstrate the effectiveness of methods like BSS or FA for UDG.**\n\nWe do not understand why you cannot see the new experiments concerning standard SimCLR on Figure 2. Normally, we had updated Figure 2 on our revised version submitted on **November 16, 2023, at 11:11 UTC**, including the requested experiments related to the standard SimCLR (blue color on each of the subfigures). However, the figure\u2019s caption was not updated. Just in case, we have reuploaded the new version of the paper (with a more detailed caption). Kindly inform us if you still cannot see these new experiments.\n\n\nAs you correctly intuited, the SimCLR performs worse than the SimCLR with FA and SimCLR with BSS since it does not use cross-domain augmentation (FA) or normalization (BSS)\u00a0 that help a lot to achieve out-of-domain generalization."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission304/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700248129062,
                "cdate": 1700248129062,
                "tmdate": 1700248545266,
                "mdate": 1700248545266,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "euwr2BPv8w",
                "forum": "qtE9K23ISq",
                "replyto": "sdrTfQtWEu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission304/Reviewer_qeEH"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission304/Reviewer_qeEH"
                ],
                "content": {
                    "title": {
                        "value": "About the latest uploaded version"
                    },
                    "comment": {
                        "value": "**I apologize for the misunderstanding in my previous responses.** I mistakenly believed that the ICLR review process restricts the uploading of new paper versions, which led me to not download the PDF again.\n\nAfter re-reading the new version of the paper, the authors show the results of Standard SimCLR. As stated in the Rebuttal, **the performance of SimCLR is worse than SimCLR w/ FA and SimCLR w/ BSS**. Overall, the authors addressed previous Weaknesses in the newly uploaded version."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission304/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700460980144,
                "cdate": 1700460980144,
                "tmdate": 1700461025056,
                "mdate": 1700461025056,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ccx2PtNpMP",
            "forum": "qtE9K23ISq",
            "replyto": "qtE9K23ISq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission304/Reviewer_PTUx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission304/Reviewer_PTUx"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the problem of Unsupervised Domain Generalization (UDG) and proposes Batch Styles Standardization (BSS) for contrastive-based pretraining. It is a Fourier-based method that aims to standardize the style of images in a batch. The method can be plugged into many existing methods easily and shows good performance improvement across multiple benchmarks"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is well-written and easy to follow.\n\n- The motivation is clear and the method is simple and neat.\n\n- The reported performance improvement is significant over the previous methods."
                },
                "weaknesses": {
                    "value": "My major concern is that some important baselines are missing:\n- What is the performance of the ERM (empirical risk minimization) on those benchmarks? People have observed ERM being a very strong baseline when it comes to domain generalization settings [1, 2].\n- As a small fraction of labeled data is always used, why not try some good semi-supervised learning methods such as FixMatch [3] or AdaMatch [4] (which also deals with domain shift)? And there is also contrastive-based semi-supervised learning such as CoMatch [5]. Since the goal is to improve the performance on unseen target domains, what is the advantage of using a framework of unsupervised pretraining + finetuning?\n- A related remark would be: what is the SOTA methodology when it comes to domain shift? In practice, one may easily resort to some VLMs (e.g. CLIP and its variants) pre-trained on large-scale image-text pair data when facing domain shift problems. As CLIP models have shown very good performance on samples under distribution shift, especially in image classification, I wonder to what extent can the problem be solved by them already. I think it makes more sense to develop techniques on top of these strong baselines, as it is very likely the method or the performance improvement on small-scale datasets or non-SOTA models does not transfer/scale well. It would be much more interesting to see if the proposed BSS still holds the same performance gap on top of CLIP. That being said, this remark is not a criticism of the authors who follow the common practice. But it would be still great if the authors could share their thoughts on this point.\n\nMinor:\n- To be more self-contained, it would be great if the authors could also introduce the contrastive-based UDG methods before Section 3.2.2.\n\n[1] In Search of Lost Domain Generalization, Ishaan Gulrajani et al., ICLR 2021\n[2] OoD-Bench: Quantifying and Understanding Two Dimensions of Out-of-Distribution Generalization, Nanyang Ye et al., CVPR2022\n[3] FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence, Kihyuk Sohn et al., NeurIPS 2020\n[4] AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation, David Berthelot et al., ICLR 2022\n[5] CoMatch: Semi-supervised Learning with Contrastive Graph Regularization, Junnan Li et al., ICCV 201"
                },
                "questions": {
                    "value": "- What are the source domains for PACS pretraining?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission304/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission304/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission304/Reviewer_PTUx"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission304/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698197080866,
            "cdate": 1698197080866,
            "tmdate": 1700665614838,
            "mdate": 1700665614838,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4FxJHIR5HI",
                "forum": "qtE9K23ISq",
                "replyto": "ccx2PtNpMP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission304/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission304/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your time and relevant feedback. You will find below a response to your concerns.\n\n> **What is the performance of the ERM (empirical risk minimization) on those benchmarks?**\n\nPerformances of the ERM baseline have been included in Tables 1 and 2. In our setting, ERM has a low performance since it is the only method that does not  benefit from the SSL pretraining step while the amount of labeled data used for finetuning is too small to make the model generalize well.\n\n\n> **As a small fraction of labeled data is always used, why not try some good semi-supervised learning methods such as FixMatch [3] or AdaMatch [4] (which also deals with domain shift)?\n[...] what is the advantage of using a framework of unsupervised pretraining + fine tuning?**\n\nThis is a fair question: Indeed, in practical scenarios aimed at producing a model with robust generalization to unseen domains, a dilemma can arise regarding two primary learning strategies:\n1. Unsupervised Pretraining handling domain shift (UDG) + Finetuning\n2. Semi-Supervised Learning, such as FixMatch, combined with Domain Generalization techniques to handle domain shift. (Note: AdaMatch works in a Unsupervised Domain Adaptation setting not Domain Generalization)\nIn practice, these strategies are not mutually exclusive: Combining both approaches would allow one to harness the strengths of each, potentially achieving optimal performance on unseen domains. Consequently, the suggested approach would be to (1) perform unsupervised pretraining addressing domain-shift (UDG) and subsequently (2) fine-tune the model using Semi-Supervised Learning in conjunction with Domain Generalization techniques.\n\nHowever, within the context of UDG, where the primary focus is evaluating the method's capacity to learn domain-invariant features, the typical workflow involves: (1) unsupervised training on source domains, (2) finetuning on source domains via linear probing, and (3) evaluation on unseen target domains. That is why the community follows this workflow.\n\n> **As CLIP models have shown very good performance on samples under distribution shift, especially in image classification, I wonder to what extent the problem can be solved by them already. [...]. It would be much more interesting to see if the proposed BSS still holds the same performance gap on top of CLIP [...] it would still be great if the authors could share their thoughts on this point.**\n\nIt's indeed a very insightful remark. Vision-language models like CLIP have demonstrated impressive zero-shot capabilities in in-distribution evaluation scenarios and even in open-world evaluation scenarios. We acknowledge that VLMs have made strides in solving domain-shift problems and may serve as a strong foundation for developing new techniques for out-of-distribution (OOD) generalization.\n\nHowever, there are certain considerations and potential challenges when relying solely on VLMs for domain-shift problems:\n\n1. VLMs often necessitate a substantial amount of labeled data for pretraining, and pretrained image and text encoders might not be well-suited for specific task data. For instance, in the histopathology field, existing pretrained VLM like CLIP does not generalize well while histopathology available paired data (images, diagnoses) are too scarce to train a new VLM from scratch [1].\n2. While fine-tuning these models can yield significant performance gains on a given data distribution, it has been observed to potentially diminish out-of-distribution generalization ability [2, 3]. Hence, careful fine-tuning is essential to preserve their generalization capability in OOD evaluation scenarios.\n3. On top of that, fair evaluation of their OOD capabilities are hard because VLMs are often trained on very large datasets that include many unknown domains. This makes it difficult to be sure that the target domains have not been seen during training.\n\nAs suggested, it would be interesting to investigate whether BSS can enhance domain-invariance and improve performances on top of VLMs, thereby addressing the challenge of loss of OOD generalization during fine-tuning.\n\nReferences:\n* [1] Lu et al. \"Towards a visual-language foundation model for computational pathology.\", arXiv preprint 2023.\n* [2] Wortsman et al. \"Robust fine-tuning of zero-shot models.\", CVPR 2022\n* [3] Goyal, Sachin, et al. \"Finetune like you pretrain: Improved finetuning of zero-shot vision models.\u201d, CVPR 2023.\n\n>  **To be more self-contained, it would be great if the authors could also introduce the contrastive-based UDG methods before Section 3.2.2.**\n\nContrastive-based UDG methods have been introduced before Section 3.2.2 (related works about UDG).\n\n> **What are the source domains for PACS pretraining?**\n\nFor the experiments on PACS, we followed the common practice in the UDG community employing a leave-one-out domain evaluation. In Table 1, we only specifies the target domain for evaluation which implies that all other domains serve as pretraining."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission304/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700130044092,
                "cdate": 1700130044092,
                "tmdate": 1700148700846,
                "mdate": 1700148700846,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "522QhZAvTf",
                "forum": "qtE9K23ISq",
                "replyto": "4FxJHIR5HI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission304/Reviewer_PTUx"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission304/Reviewer_PTUx"
                ],
                "content": {
                    "title": {
                        "value": "Post-rebuttal decision"
                    },
                    "comment": {
                        "value": "I thank the authors for their detailed response and additional experimental results. They address my concerns. Thus, I increased my score."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission304/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700665584434,
                "cdate": 1700665584434,
                "tmdate": 1700665584434,
                "mdate": 1700665584434,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qkf7sxgnmM",
            "forum": "qtE9K23ISq",
            "replyto": "qtE9K23ISq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission304/Reviewer_gWCx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission304/Reviewer_gWCx"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the unsupervised domain generalization problem where there is a labeled training set, an unlabeled training set, and a test set. The main claim is that the style information should be standardized in training, which motivates the authors to propose BSS (Batch Style Standardization) to combine with self-supervised learning methods. Experiments on several benchmark datasets show the effectiveness of the BSS method.\n\n-----Post rebuttal\n\nI increased my score from 3 to 5 since they addressed my concerns. However, I did not give a 6 since I still think the novelty is limited."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The proposed method is simple and useful in image datasets.\n2. The combination of BSS with SSL is interesting.\n3. The results show that the BSS approach is effective compared to other counterparts."
                },
                "weaknesses": {
                    "value": "1. The major weakness is novelty. Given that Fourier-based methods have been extensively studied in existing DG literatures, the direct adoption of Fourier features is not entirely novel. Plus, the idea of transforming the styles in batch is deeply related to Mixstyle [Zhou et al., ICLR21] but authors did not compare or discuss the difference.\n2. The motivation of combining BSS with self-supervised learning is not clear. I can only see this: we can always combine them, that's all. I do not see the insights of such combination.\n3. Section 3.2, i.e., the BSS part, is hard to understand. Authors should do their best to better present this part.\n4. Comparision approaches are not enough: authors should compare with existing Fourier methods to validate their effectiveness.\n5. There lacks theoretical support of why such BSS approach can succeed in learning domain-invariant representations."
                },
                "questions": {
                    "value": "See weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission304/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission304/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission304/Reviewer_gWCx"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission304/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698403023798,
            "cdate": 1698403023798,
            "tmdate": 1700718320601,
            "mdate": 1700718320601,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "O410pb5yRa",
                "forum": "qtE9K23ISq",
                "replyto": "qkf7sxgnmM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission304/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission304/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your time and constructive feedback. You will find below a response to your concerns.\n\n> **The idea of transforming the styles in a batch is deeply related to Mixstyle but authors did not compare or discuss the difference.**\n\nWhile MixStyle also transform the styles in the batch to improve out-of-domain generalization, significant differences exist between the proposed BSS and MixStyle:\n1. The objectives of MixStyle and BSS diverge: MixStyle seeks to alter the style of examples, introducing a broad style variability at the features-level, whereas BSS strives to eliminate the style variability by enforcing a single style at the image-level (style augmentation vs style standardization).\n2. To alter the style of examples at the features-level, MixStyle mixes the features maps` statistics (mean, std)  with those of random examples. In contrast, BSS normalizes the style of all examples in a batch by replacing all amplitudes with those of a randomly chosen image, resulting in a batch with a single style. In practice, MixStyle could be extended to normalize the style of examples by swapping all the statistics of a batch with those of a randomly chosen image and used within BSS to replace the proposed Fourier-based normalization.\n3. MixStyle relies on the assumption that style information of examples can be captured by the examples\u2019 statistics (mean, std) of bottom layers features in CNN [1]. This assumption is not directly transferable to all architecture like Vision Transformers for example. This makes MixStyle specific to the CNN architecture, whereas BSS operating at the image-level is architecture agnostic.\n\nReferences:\n* [1] Huang et al.. \"Arbitrary style transfer in real-time with adaptive instance normalization.\", ICCV 2017\n\n> **The motivation of combining BSS with self-supervised learning is not clear. [...]. I do not see the insights of such combination.**\n\nThe primary motivation behind normalizing styles examples is to reinforce domain-invariance. Style normalization in a batch has the desired effect only if comparisons between examples of the batch occur during training. This is the case in the considered SSL methods but not in a standard supervised setting with a cross-entropy loss.\n\nThe intuition behind why combining BSS to SSL methods helps to achieve domain- invariance is the following: both contrastive and non-contrastive SSL methods aim to distribute batch examples over an embedding space. This distribution over the embedding space can be driven explicitly by contrastive loss like in SimCLR or implicitly by methods preventing representation collapse like Sinkhorn-Knopp (SWaV, MSN), centering (DINO), or variance regularization (VicReg). However, when diverse styles coexist within a batch, there is no inherent mechanism preventing the distribution from being influenced by these different styles. In such case, these spurious correlations may harm the performance of the fine-tuned SSL model in an out-of-distribution evaluation scenario (UDG). Therefore, our hypothesis posits that normalizing the styles of examples in a batch should help reduce the emergence of spurious correlations in SSL features thereby enhancing domain-invariance. \n\nEmpirical evidence supports this intuition, as substantial performance gaps between our method utilizing Fourier-based augmentations (FA) and BSS (styles normalization) have been observed (please refer to Table 1, 2, 3). Additionally,  the experiments provided in section 5.2 clarify the underlying mechanisms that contributed to BSS's effectiveness in improving domain-invariance in SSL representations.\n\n> **The BSS part, is hard to understand**\n\nWe have tried to be as clear as possible by providing a description of the exact process of how BSS is performed (Section 3.2.2 - 2nd paragraph), a Figure illustrating how BSS is performed (Figure 1) and pseudo-code along with a Pytorch implementation of BSS. We will try to improve the explanation but it would help if you could explain which specific aspect you find unclear.\n\n> **Authors should compare with existing Fourier methods to validate their effectiveness.**\n\nAll results from Table 1, 2 and 3 compare to existing UDG methods based on FA (DiMAE, CycleMAE (new)). Comparison to a standard FA strategy is also available for all experiments. If you can think of more pertinent comparisons, could you please point them out?\n\n> **Lacks theoretical support**\n\nIn the UDG community, it is common practice to present motivations, intuitions, and empirical validations through performances or experiments (DARLING, BRaD, DiMAE, CycleMAE). Producing meaningful theoretical support for DG deep learning methods is hard:  strong assumptions regarding the data, such as a modelization of semantic/style separation, would be required and in practice, such assumptions never hold on real datasets. Moreover, our non-reliance on domain labels makes it even harder."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission304/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700129399467,
                "cdate": 1700129399467,
                "tmdate": 1700148633319,
                "mdate": 1700148633319,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "he0UCacjB1",
                "forum": "qtE9K23ISq",
                "replyto": "O410pb5yRa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission304/Reviewer_gWCx"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission304/Reviewer_gWCx"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response. I carefully read the comments from other reviewers. Most of my concerns are addressed now. I increase my rating to 5. No further response needed."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission304/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700718190963,
                "cdate": 1700718190963,
                "tmdate": 1700718190963,
                "mdate": 1700718190963,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "nvR4llSAvR",
            "forum": "qtE9K23ISq",
            "replyto": "qtE9K23ISq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission304/Reviewer_eMsd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission304/Reviewer_eMsd"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a batch-standardization method for domain-invariant self-supervised learning. The idea is borrowed mainly from Fourier domain adaptation. However, the new advantage is that it eliminates the requirements of domain labels. This paper validates the effectiveness on various benchmarks, such as PACS, DomainNet."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The biggest advantage of the proposed method is that it does not need domain labels to learn domain invariant features. It indeed reduces the requirements for domain labels. The experimental results show the effectiveness of the proposed BSS on various benchmarks."
                },
                "weaknesses": {
                    "value": "[1] Originality: This paper proposes a batch-style standardization method to mix the domain styles in the batch. However, the idea is largely borrowed from Fourier Domain Adaptation [A], FACT[B] and Domain-invariant masked autoencoder [C]. The extension to samples in a mini-batch is also direct and does not need significant designs. Considering the author only claims one novelty, I do not think this paper is above the bar of ICLR.\n\n[A] FDA: Fourier Domain Adaptation for Semantic Segmentation\n[B] A Fourier-based Framework for Domain Generalization\n[C] Domain Invariant Masked Autoencoders for Self-supervised Learning from Multi-domains\n\n\n[2] The experimental results. I have also noticed that CycleMAE, which was published in the last ICLR, also lists the comparison of different pretrained models in Table 5. It shows comparable results with unsupervised learning pretrained models. In addition, the author should compare with CycleMAE [D].\n[D] CYCLE-CONSISTENT MASKED AUTOENCODER FOR UNSUPERVISED DOMAIN GENERALIZATION"
                },
                "questions": {
                    "value": "Novelty and experiments are my most important concerns. Please carefully address my concerns listed in the weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission304/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission304/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission304/Reviewer_eMsd"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission304/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698547487179,
            "cdate": 1698547487179,
            "tmdate": 1700703753919,
            "mdate": 1700703753919,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2eEOrxsv8V",
                "forum": "qtE9K23ISq",
                "replyto": "nvR4llSAvR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission304/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission304/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your time and constructive feedback. Your first point about novelty is treated in the global response. You will find below a response to your other remarks.\n\n> **The author should compare with CycleMAE**\n\nThank you for pointing out this recent work that we missed during our initial submission. We have updated the related works accordingly and included performances of the method in Table 1 and 2.\n\nIn examining the performances on PACS (Table 1), CycleMAE demonstrates slightly superior average performances at label fractions of 10% and 100%, compared to SimCLR with BSS. However, it should be noted that CycleMAE and our approaches differ in experimental settings:\n- CycleMAE employs ImageNet pretraining, while we do not.\n- Full finetuning is conducted on the 10% labeled data setting in CycleMAE, whereas we utilize linear probing as per BRaD experimental setting.\n- CycleMAE uses a ViT-small architecture, whereas most compared methods, including ours, utilize a ResNet18 architecture.\n\nConcerning the performances on the DomainNet subset (Table 2), our initial observations and comparisons remain consistent."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission304/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700127744975,
                "cdate": 1700127744975,
                "tmdate": 1700148574936,
                "mdate": 1700148574936,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8ib07UjvjZ",
                "forum": "qtE9K23ISq",
                "replyto": "2eEOrxsv8V",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission304/Reviewer_eMsd"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission304/Reviewer_eMsd"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your reply"
                    },
                    "comment": {
                        "value": "Thanks for the reviewer's reply. \n\nI noticed that cycleMAE uses the ImageNet pretrain. However, I do not think it will lead to any problems because some pretraining methods directly related to the task also use ImageNet pretraining. \n\nAlso, I recommend the author to try on ViT backbone since ViT has shown better scalability and modality-friendliness in recent years.\n\n\nTo conclude, I understand the author's response, and I think it is reasonable for the current paper, thus, I can slightly raise my score.\n\nHowever, I request the author to add results with ViT backbone and results using ImageNet pretraining."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission304/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700703714228,
                "cdate": 1700703714228,
                "tmdate": 1700703714228,
                "mdate": 1700703714228,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "tZdtRlTon0",
            "forum": "qtE9K23ISq",
            "replyto": "qtE9K23ISq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission304/Reviewer_qVbh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission304/Reviewer_qVbh"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes Batch Styles Standardization (BSS) to reduce spurious correlations in conventional self-supervised learning (SSL) representations, thereby making the resulting models generalize better on the test data drawn from an unseen domain. Specifically, the authors leverage the existing Fourier-based augmentation technique to transfer the style of a randomly chosen image to all other images within a batch. They also elaborate how BSS can be integrated with popular contrastive and non-contrastive SSL methods such as SimCLR, SWaV, and MSN. Experiments were conducted on 3 benchmark datasets for domain generalization to evaluate how BSS improves the performance of these SSL methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper is well written.\n2. The authors perform a comprehensive literature review on SSL and unsupervised domain generalization.\n3. The paper offers a clear explanation of how Fourier-based augmentation and BSS operate on images, making the methodology more reader-friendly for a broader audience."
                },
                "weaknesses": {
                    "value": "For now I do not see any obvious weaknesses or technical flaws in the paper. However, it would be beneficial if the authors could provide further clarity on the novelty aspect. At the moment, it appears to be an application of Fourier-based augmentation to self-supervised learning.\n\nMinor suggestions:\nSimCLR and SWaV should be categorized as contrastive-based SSL methods in the second paragraph of Contributions."
                },
                "questions": {
                    "value": "Can authors conduct some investigation on why BSS is sometimes outperformed (though by a small margin) by regular Fourier-based augmentation on the DomainNet dataset?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission304/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission304/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission304/Reviewer_qVbh"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission304/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698802873445,
            "cdate": 1698802873445,
            "tmdate": 1699635956704,
            "mdate": 1699635956704,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PHyIoAyWql",
                "forum": "qtE9K23ISq",
                "replyto": "tZdtRlTon0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission304/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission304/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your time and constructive feedback. Your main concern about novelty is treated in the global response, your others remarks are covered below.\n\n> **SimCLR and SWaV should be categorized as contrastive-based SSL methods in the second paragraph of Contributions.**\n\nThe categorization of SimCLR and SWaV as contrastive-based SSL methods have been clarified in an updated version of the paper in the second paragraph of Contributions.\n\n> **Investigation on why BSS is sometimes outperformed (though by a small margin) by regular Fourier-based augmentation on the DomainNet dataset?**\n\nWe do not have a clear understanding of why BSS does not work as well for these few cases or a specific methodology to investigate them. However, it should be noted that, on average, BSS outperforms Fourier-based augmentation (FA) with a clear margin."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission304/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700127641643,
                "cdate": 1700127641643,
                "tmdate": 1700148553192,
                "mdate": 1700148553192,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]