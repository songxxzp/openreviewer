[
    {
        "title": "Reverse Chain: A Generic Rule for LLMs to Master Multi-API Planning"
    },
    {
        "review": {
            "id": "JjMS307C4J",
            "forum": "vDSkfIUnEO",
            "replyto": "vDSkfIUnEO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3153/Reviewer_yWYw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3153/Reviewer_yWYw"
            ],
            "content": {
                "summary": {
                    "value": "The proposed Reverse Chain can empower large language models (LLMs) with the ability to use external APIs with only prompts. The approach allows LLMs to implement multiple function calling, which is a challenging task due to the complicated relations between different APIs. The authors also conduct experiments that show impressive results, indicating the potential of Reverse Chain in enhancing the performance of LLMs."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This approach is different from existing approaches that use tool demonstration data to fine-tune LLMs, which can be costly and hard to generalize to new registered APIs. Reverse Chain employs a generic rule to decompose a complicated multi-function calling problem into two types of simple tasks for LLMs, that is API selection and argument completion. This original approach is a significant contribution to the field.\n\n2. The paper presents extensive experiments to evaluate the effectiveness of Reverse Chain. The experiments show that Reverse Chain could efficiently improve the tool-use capabilities of the existing LLMs, e.g., ChatGPT. Moreover, the combination of a generic rule with LLMs enabled Reverse Chain to attain better performance compared to CoT and ReAct."
                },
                "weaknesses": {
                    "value": "1. The method can make the multi-api planning processing more autonomous, but it takes some time to implement the method. Therefore, the complicated process of using the method may be a weakness.\n\n2. The method might take more throughput from the LLM (e.g., the process of selecting API, repeating complete argument). This can cause more computation or more cost on ChatGPT API fees.\n\n3. the paper could benefit from a more detailed comparison with existing approaches. While the paper compares Reverse Chain with CoT and ReAct on ChatGPT, it does not provide a comprehensive experimental comparison on other LLM (e.g., different scales of llama models). Offering a more exhaustive comparison with alternate LLMs would furnish readers with a clearer perspective on the scalability of the Reverse Chain and the efficacy of its selection criteria across different LLMs."
                },
                "questions": {
                    "value": "Please see the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N.A."
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3153/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698540618493,
            "cdate": 1698540618493,
            "tmdate": 1699636262999,
            "mdate": 1699636262999,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "anZIlpJBfv",
            "forum": "vDSkfIUnEO",
            "replyto": "vDSkfIUnEO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3153/Reviewer_62YQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3153/Reviewer_62YQ"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents the ReverseChain, which first selects a final API to handle a given task via LLMs, then ask LLMs to fill the required arguments from user query and avaliable API sets. This process continues until a given task is completed. Extensive numerical experiments indicate an impressive capability of Reverse Chain on implementing multiple function calling."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Novel idea to use a ReverseChain for API calling, by iteratively select API and fill arguments. \n\n2. Clear paper writting. The reviewer can easily follow the methods and experiments.  \n\n3. Strong performance compared to baselines (94.9 vs 88.6)\n\n4. Good ablation and error analysis to show more insights about the methods."
                },
                "weaknesses": {
                    "value": "1. The reviewers are mostly concerning about the datasets for evaluation. The auhors only hand-craft about 500 examples from an existing dataset API-bank, and most of them (about 350) are two-level nested API calling, I am concerning the possiable bias in the dataset. For example, if the APIs have similar functinality, this will be hard the the ReverseChain to select a correct final API. But the authors did not provide more evidence about why this dataset is good for evaluation.  \n\n2. The related work is not sufficient. As a very hot topic, there are many studies about LLM-based API calling. The authors only use two short paragraphs in Sention 4. Besides, the reviewer found that the ablation methods in Section 3.2.2 are very similar to the one-step agent and sequential agent proposed in TPTU [1], the authors could discuss their differences if possiable. [1] TPTU: Task Planning and Tool Usage of Large Language Model-based AI Agents.\n\n\n3. small writing issues. e.g., \"they may contain thoughts,action\" ==> thoughts, actions; \"T represents the temperature of GPT-3.5.\"  ==> remove it."
                },
                "questions": {
                    "value": "1. Could the authors provide more evidence about why the hand-crafted dataset is good for evaluation?  \n\n2. Could the authors add more related works and disscuss the differences between the ablation methods in Section 3.2.2 and the one-step agent and sequential agent proposed in TPTU?  \n\n3. If the APIs have similar functinality, this will be hard the the ReverseChain to select a correct final API. Can ReverseChain works well in this setting?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3153/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698592527011,
            "cdate": 1698592527011,
            "tmdate": 1699636262899,
            "mdate": 1699636262899,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Shzsstw17L",
                "forum": "vDSkfIUnEO",
                "replyto": "anZIlpJBfv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3153/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3153/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Difference from TPTU"
                    },
                    "comment": {
                        "value": "Thank you for your suggestions.\nQ: The related work is not sufficient.  \nA: We will add more related work and comparison with our work in the next version of the paper.\n\nQ: The reviewer found that the ablation methods in Section 3.2.2 are very similar to the one-step agent and sequential agent proposed in TPTU [1], the authors could discuss their differences if possible.\n\nA: There is a big difference between our work Reverse Chain and one-step agent in TPTU.\nTPTU is executed in forward order when generating a plan, while Reverse Chain is executed in reverse order when generating a plan. Starting from the last API, it infers the APIs required in the previous step in reverse.\n\nTake the example in the TPTU paper as an example:\nQuestion: How much budget is required to provide a 100$ incentive for each colleague who has worked for five years?\n\nIn TPTU, the planning is:\n1. SQL generator: \u201cFiguring out how many colleague who has worked for five years from the database; taking it as X.\u201d\n2. Python generator: \u201cCalculating the value of 100*X with a calculator\u201d\n\nHowever, in Reverse Chain, First, it is recognized that the final intent is calculation, so calculator is chosen. The calculator parameter is missing X, and then the SQL generator is chosen to generate the number of colleagues who has worked for five years from the database, which is X."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3153/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700566598028,
                "cdate": 1700566598028,
                "tmdate": 1700566598028,
                "mdate": 1700566598028,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ub7XRzaZtU",
                "forum": "vDSkfIUnEO",
                "replyto": "Shzsstw17L",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3153/Reviewer_62YQ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3153/Reviewer_62YQ"
                ],
                "content": {
                    "title": {
                        "value": "Possiable bias in the datasets for evaluation?"
                    },
                    "comment": {
                        "value": "Thanks for the clarification. It helps for understanding the difference between Reverse Chain and TPTU.\n\nI am also concerning about the datasets for evaluation. Could the authors give some explaination? I would be happy to increase the score if this main concern is addressed."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3153/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700619867036,
                "cdate": 1700619867036,
                "tmdate": 1700619867036,
                "mdate": 1700619867036,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Js33r3JxxH",
            "forum": "vDSkfIUnEO",
            "replyto": "vDSkfIUnEO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3153/Reviewer_xS6A"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3153/Reviewer_xS6A"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors present an in-context learning approach to enable LLMs use API calls to complete user requests. The authors present a general approach called \"Reverse Chain\", which can also extend to serving user requests which involve multiple levels of API calls to fulfill top-level API request. The authors compare with different zero-shot and few-shot approaches and show interesting performance of their approach."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- I think the paper is well-motivated. Having the LLMs be able to output API calls is useful for lots of applications to enable the model access a lot of different information that it doesn't have knowledge of directly, or is too big to fit in context. \n\n- The biggest strength of this approach is its simplicity. The approach is intuitive and the ablations considered by the authors help understand the approach better."
                },
                "weaknesses": {
                    "value": "- I am mainly concerned about the novelty of this approach. The authors do mention the relevant recent papers in their related work section, however, I feel that the authors haven't done an adequate job of comparing their work with existing work. (more on this in questions section)\n\n- I think the experiments can be expanded a bit more. The current dataset seems limited and small."
                },
                "questions": {
                    "value": "- How does this paper compare more directly with the depth-first approach presented in ToolLLM paper [1]? I understand that ToolLLM paper didn't directly look at composition multi-tool problem, but shouldn't it be straightforward to extend their DFS approach to do this? And won't that be similar to what you're proposing?\n\n- How does this method scale with # of APIs? For instance, the ToolLLM[1] paper had >16,000 APIs in their dataset. This would require some shortlisting using a retriever. \n\n- I think the authors should also include # of API calls in their experimental results so that readers can understand the trade-off between cost/latency and the quality of the final outputs. My guess is that for applications that need very few APIs and where the API names are very distinct, simple zero-shot methods would suffice. \n\n- It'll be useful to break down the analysis based on the length of API call or num. of arguments in the API call and the performance of Reverse Chain and the corresponding baselines. \n\n- Summarizing the above two steps into a discussion section to directly point out under what circumstances Reverse Chain would be useful would be greatly beneficial for researchers and practitioners alike.\n\n\nReferences\n\n[1] Qin, Y., Liang, S., Ye, Y., Zhu, K., Yan, L., Lu, Y., ... & Sun, M. (2023). Toolllm: Facilitating large language models to master 16000+ real-world apis. arXiv preprint arXiv:2307.16789."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3153/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3153/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3153/Reviewer_xS6A"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3153/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699047317099,
            "cdate": 1699047317099,
            "tmdate": 1699636262836,
            "mdate": 1699636262836,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "VN6yoyLupi",
            "forum": "vDSkfIUnEO",
            "replyto": "vDSkfIUnEO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3153/Reviewer_2PHd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3153/Reviewer_2PHd"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents an approach called Reverse Chain for compositional API calling. The approach uses prompts to start off with the Goal API to be determined followed by filling in the arguments of the APIs iteratively either by extracting from the user text or calling another API. The approach is fairly straight forward and the experimental results shows that it works very well. The paper is also well written and understandable. Backward chaining in reasoning techniques has been effectively explored for LLMs in this work. The ablation study and the error analysis evidences further on the reverse chain approach. \n\nPrimary concerns of this work are as follows: \n1. Generalizability of the approach: This approach is specific to single goal \u2014> compositional API calling work. When there are aspects of multiple goals in a specific user query it is unclear how this approach can be adapted. Furthermore, this does set an iterative pipeline of two tasks API selection and Argument Completion in a way that it gets hard for it to be more generalizable in the context of plug-ins and other API tasks. This does beg the question \u201cWould APIs be only used in such scenarios?\u201d \n2. Dataset for evaluation: This brings a larger concern \u2014 looking at the prompt and the few shot examples, it\u2019s very clear that the dataset is constructed exactly for the reverse chain to work. The results for level 1 and level 2 clearly shows significant performance where the API/Tool calling abilities of large language models is yet to be improved. This is also true for few shot cot which is doing much better than ReAct.\n    1. Furthermore, given 126 APIs in the dataset \u2014 does each instance during test have all the 126 APIs? How many domains does these APIs belong to? \n    2. 492 samples \u2014 What\u2019s the distribution of the 126 APIs in the 492 samples. \n    3. More details of the dataset is necessary to interpret the results better."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Paper has a very simple but effective approach to solve compositional API calling.\n2. Results show the evidence and the paper is presented well"
                },
                "weaknesses": {
                    "value": "1. Questions about Generalizability of the approach\n2. Dataset details are not self contained in the paper which is necessary to interpret the results"
                },
                "questions": {
                    "value": "In the Summary"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3153/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3153/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3153/Reviewer_2PHd"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3153/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699245476578,
            "cdate": 1699245476578,
            "tmdate": 1699636262755,
            "mdate": 1699636262755,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "JezhslaXKH",
            "forum": "vDSkfIUnEO",
            "replyto": "vDSkfIUnEO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3153/Reviewer_75Tz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3153/Reviewer_75Tz"
            ],
            "content": {
                "summary": {
                    "value": "This article proposes a Reverse Chain to empower LLMs with capabilities to use external APIs with only prompts. In this reverse chain, the LLMs are asked to fill in the required arguments based on the query/context before checking with the user. A good attempt on in-contextual learning methods comparison but lacked research contribution."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Reverse Chain concept for multi api planning\nGood contribution on tool comparison & in-context method comparison"
                },
                "weaknesses": {
                    "value": "Some of the weakness of this article are as follows: \n1. The concept of reverse chain can be applied to simple tasks for ex. API selection and argument completion. \n2. How reverse chain proved to be effective in multi-API planning is not delineated in detail\n3. This article focuses on comparing multiple tools or methods in API calling & planning & reduces research contribution.\n4. Experimental results too discusses on comparing different methods of in-context learning against Reverse Chain but needed empirical evaluation of the proposed method to be accepted in reputed ICLR."
                },
                "questions": {
                    "value": "The complexity on the API nesting needs to be at a higher in order to prove Reverse Chain out passes the other in-context learning approaches? Why the nesting of APIs are set at 2, 3 and 4 levels? Is there any experiments conducted with larger nesting capabilities? \nFinal date set has about 126 APIs and 492 samples; what about the number of queries that was tested against the metrics?\nThe authors have made a statement \"This framework enables the LLM to generate responses by following a logical sequence of thinking, taking action, and observing the results.\" How this can be achieved needs to be explored in detail with Reverse Chain?\nIn section 3.3 -> It summarizes the numbers based on wrong final tool/ wrong argument api and value but does not state any where against how many number of times or queries used against?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3153/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699583065075,
            "cdate": 1699583065075,
            "tmdate": 1699636262691,
            "mdate": 1699636262691,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]