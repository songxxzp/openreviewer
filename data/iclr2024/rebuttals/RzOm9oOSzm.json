[
    {
        "title": "Unveiling Linear Mode Connectivity of Re-basin from Neuron Distribution Perspective"
    },
    {
        "review": {
            "id": "bAaVBpdSWp",
            "forum": "RzOm9oOSzm",
            "replyto": "RzOm9oOSzm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7417/Reviewer_ehnr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7417/Reviewer_ehnr"
            ],
            "content": {
                "summary": {
                    "value": "This paper connects the theory of random matching problem and the weight matching method of Git Re-basin (Ainsworth et al). They give an upper bound over the loss barrier between two models and the bound is related to the distribution of model parameters (which could be formulated as discrete entropy). Also, they find pruning could potentially decrease the loss barrier between two models after re-basining."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- First of all, the authors identified an important problem that is why the permutation methods (including weight matching proposed in Ainsworth et al., 2022 and Entezari et al., 2021) could achieve LMC between two independently trained models and why they fail in some cases (e.g. early training). \n- A good point of this paper is to build the connection between random matching problem and loss barrier between two models. \n- Also, the phenomenon that pruning could potentially decrease the loss barrier after re-basining is interesting."
                },
                "weaknesses": {
                    "value": "Theoretical side:\nThe theorem 3.1 tells a simple conclusion that is the loss barrier between models are bounded by the distance between their model parameters, which is intuitive and aligns with most literatures (I am not questioning on theorem 3.1). The theorem 3.2 gives an upper bound over the distance between two random model parameters. After that, theorem 3.3 just combines above two theorems. Therefore, I thought the core part of this paper is simply the theorem 3.2 (sometimes the author refers it as Lemma 3.2, which might be a typo...). \n- However, in a real case, the model parameters might not be \"random\" and the bound given by theorem 3.2 might be useless in practice. In that case, the relation between the loss barrier and the entropy could be overestimated.\n- Also, the theorem 3.2 actually directly comes from the random Euclidean matching problems (as mentioned by the authors in Sec 3.)\nAbove all, the theoretical contribution of this paper is marginal.\n\nExperimental side:\n1. Sec 4.2, the experiments are quite \"toy\" (Polynomial Task, single output MLP and only first layer are tested). For both Sec 4.1 & 4.3, the experiments are conducted over standard image classification task and models, however, for Sec 4.2, the experiments are quite trivial. Harder datasets and models are needed for Sec 4.2.\n2. Still 4.2, only the change of distribution of model parameters before training and after training cannot show a strong correlation between the loss barrier and entropy. More carefully designed experiments are needed.\n3. Pruning experiments are interesting but the explanation of why Only Pruning and Lottery Ticket Hypothesis fail is not that clear. Actually, the failure cannot be predicted by their theoretical analysis.\n4. From Figure 5, the loss does not always first decrease and then increase. For MLP and CIFAR-10, the loss first increases with pruning ratio actually. The phenomenon contradicts with the results of other dataset and models. Also, the loss curves of train dataset and test set are not always consistent.\n5. The entropy before and after pruning should be presented for comparison.\n\nOverall, the experimental contribution is not sound to me."
                },
                "questions": {
                    "value": "1. For Sec 4.1, I wonder if all the models are all randomly initialized, how could loss barrier exist? Because in my mind, one randomly initialized model could be a \"random guess\" classifier, and therefore, if two \"random guess\" classifier are interpolated, the interpolated model should still random guess, then there couldn't exist any loss barrier."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7417/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7417/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7417/Reviewer_ehnr"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7417/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698322610323,
            "cdate": 1698322610323,
            "tmdate": 1699636889655,
            "mdate": 1699636889655,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "VMVr070ros",
            "forum": "RzOm9oOSzm",
            "replyto": "RzOm9oOSzm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7417/Reviewer_Lp2L"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7417/Reviewer_Lp2L"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates the theory of re-basins, explores when and why re-basins improve linear mode connectivity, and examines the problem from a neuron distribution perspective. The authors conducted analytical experiments on neuron distributions with different initializations, comparisons before and after fine-tuning, pruning, and more. Notably, the pruning-then-fine-tuning experiments yield interesting findings. Finally, the authors demonstrate how to apply their theory to other methods, such as OTFusion and FedMA."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This paper examines linear mode connectivity (LMC) after re-basin through changes in neuron distribution. \n- The authors provide both theoretical analysis as well as practical experiments. \n- The finding that pruning and then fine-tuning at a higher rate improves re-basin is an interesting discovery. \n- The writing is clear."
                },
                "weaknesses": {
                    "value": "The analysis using entropy is rather trivial in hindsight; for instance, different initializations result in a higher entropy of the neuron distribution (Fig. 2), and training changes the neuron distribution from uniform to bi-modal (Fig. 3). Overall, the theoretical/analytical contribution may be somewhat thin."
                },
                "questions": {
                    "value": "N/A"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7417/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698509209576,
            "cdate": 1698509209576,
            "tmdate": 1699636889549,
            "mdate": 1699636889549,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "vEL1OwFAVB",
            "forum": "RzOm9oOSzm",
            "replyto": "RzOm9oOSzm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7417/Reviewer_3GTP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7417/Reviewer_3GTP"
            ],
            "content": {
                "summary": {
                    "value": "The authors aim at their research to explain the linear mode connectivity, i.e., the ability of neural networks to be connected by a low loss line, through the properties of the weights values distribution. In particular they are using discrete Shannon entropy of the weights distribution as a characteristic that should be low in order to allow for low barrier between models. They provide a theoretical result for the upper bound on the difference of network outputs that depends on the entropy of the weights distribution. Further they evaluate empirically the values of the barrier and entropy for the newly initialized models, after training and after pruning. It is proposed to use pruning as a method for enhancement of the linear connectivity via empirical results with some state-of-the-art vision models and fusion methods."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Paper aims at having a theoretically justified result about effect of entropy on the barrier between two models. Additionally, this result is used to propose an applicational enhancement for permutation based matching between networks in order to fuse them (as a fusion ensemble or federated learning)."
                },
                "weaknesses": {
                    "value": "Paper is hard to follow and there are many questions that arise upon reading it.\n\nThe first question that is aimed to answer is about hardness of LMC at initialization as in Ainsworth et al. The answer that paper gives is that it depends on the entropy of the initialization, but there is no correspondence to the initial question in a sense of considering same experiments as in Ainsworth et al. and changing initialization to less entropy one. Moreover, already at Ainsworth et al. it is mentioned that in a concurrent work it was shown that mapping found after training improves LMC at initialization. How can entropy explain this? In Entezari et al. it was proven that for wide networks LMC is possible at initialization. How does this result connects to the entropy?\n\nThe authors use definition of the barrier introduced in Entezari et al. Nevertheless, it is not quite clear to me how \\alpha is selected there (and later in the paper Entezari et al. just use 1/2, thus returning to the classical definition of Frankle et al.). I wonder how the authors use this definition. Moreover, in the theorem 3.1 instead of bounding barrier, some other value is bounded - supremum over difference between network output for interpolated weights and interpolation of network outputs. This already does not correspond to any of the definitions. I can assume that they still can be linked, but this linking is not given in the paper.\n\nProof of theorem 3.1 does not require permutations per se - it is introduced in the very end to shrink the barrier. So overall, it should mean that entropy of neuron distribution can bound the difference between output of interpolated model and interpolation of the models? Moreover, result in lemma 3.2 requires 0 mean of the distribution of the neuron weights - I think it does not have to be the case in a trained network. Finally, the proof of theorem 3.3 is absent. While it is connecting theorem 3.1 and lemma 3.2 it requires some polynomial properties of the network, which are not explained.\n\nThe experiment in section 4.2 uses a network with sigmoid activation. Such activation is known to bin into two corner cases with training (see discussion about experiments in the work on information bottleneck of N.Tishby). Therefore the demonstrated peaks in the values of the weights does not necessarily mean the desired result.\n\nThe argument for why pruning by itself does not result in decrease of the barrier value is not convincing for me. The value of the barrier is normalized by the losses of the two initial models, therefore it should not mean that the barrier will be high if models do not perform well. And fine-tuning after matching is known to always improve LMC, so once again this experiment does not show the desired result.\n\nMinor:\n\n- currently, pruning does not smoothly integrate in the paper: in the introduction it is formulated as \"we observe that pruning can improve LMC, but what is the mechanism\", while in the paper itself pruning is directly proposed as a method to decrease entropy.\n\n- the Figure 1 is very sloppy - why the shadow areas are exactly where solutions would be? How is it justified?\n\n- the formulation \"making neuron distribution gather around minima\" is unclear to me\n\n- in the introduction it is controversially claimed that the proposed method makes re-basin easier, while it is not the case\n\n- neuron entropy and neural entropy are used in parallel in the paper, while neuron entropy is the term introduced\n\n- lemma 3.2 is called theorem 3.2 in the text\n\n- using assumptions from another paper (Mei et al.) without explaining them (at least in appendix) makes the paper not self-contained"
                },
                "questions": {
                    "value": "Please see questions in the section \"Weaknesses\"."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7417/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698766535640,
            "cdate": 1698766535640,
            "tmdate": 1699636889436,
            "mdate": 1699636889436,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "J2fwpIKktN",
                "forum": "RzOm9oOSzm",
                "replyto": "vEL1OwFAVB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7417/Reviewer_3GTP"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7417/Reviewer_3GTP"
                ],
                "content": {
                    "comment": {
                        "value": "Unfortunately I do not find answers to my questions in the general responses, so I stay with my score."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7417/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700741500324,
                "cdate": 1700741500324,
                "tmdate": 1700741500324,
                "mdate": 1700741500324,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "2V8bx7vCTT",
            "forum": "RzOm9oOSzm",
            "replyto": "RzOm9oOSzm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7417/Reviewer_y1Dw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7417/Reviewer_y1Dw"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a conjecture that behavior of loss barrier in Linear Mode Connectivity (LMC) of Deep Neural Networks can be explained through entropy (non-uniformity) of distribution imposed on the neurons of the network. The authors show that for multi layered perceptron the loss barrier between two networks are upper bounded by O(polynomial(number of neurons in hidden layers) x exponential(entropy of neuron distributions)). The paper goes on the explain that pruning results in reduction in entropy and hence loss barrier of LMC for pruned networks are better, resulting in higher accuracy of fused model. The experiments in the paper are two fold (a) to show empirically that entropy and LMC are connected (b) apply pruning to various existing methods for better fusion of deep networks."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The ideas presented in the paper are interesting and could have potential applications in understanding of LMC, as well as in improving accuracy of model fusion methods. \n\na) The connection between loss barrier of LMC and entropy is novel and should be explored further. \n\nb) The application of pruning in model fusion seems to be a positive direction in improving the accuracy of fused model."
                },
                "weaknesses": {
                    "value": "In the current state the results in the paper does not seem to back the contributions mentioned in the introduction and abstract. There are various weak points:\n1) The paper proposes a conjecture on how entropy could explain some of the behavior in loss barrier and LMC. However various parts of abstract and introduction tries to hint that the proposal contains a \"theory to demystify the mechanism behind LMC of re-basin\". The contributions needs to be reworded.\n2) The paper deals only with MLP with bias=0. The presence of bias term and cases like Deep networks with transformer units seem to be non-trivial to extend to as opposed to as claimed in the paper.\n3) The theorem provides an upper bound on loss barrier and entropy of imposed distributions on neurons. However two things seem to be missing. The first is usefulness of the bound. The polynomial function in bound is over width of NNs across all the depth. This number could be potentially very large rendering the bound trivial. It has to be shown that the entropy term is significant over the other terms in the bound to be able to attribute the behavior of LMC to entropy. Secondly, there is hardly any section devoted to the nature of such distributions that would be present in deep networks after they are trained. Both of these seem to be crucial to the claims made.\n4) There seems to be a confusion about if the results in paper are about better LMC (higher accuracy along linear path) vs smaller loss barrier in the presented material. I think the theorems need to be re-interpreted for converged NNs.\n5) The experiment results do not contain any standard deviations for most parts. This makes it hard to understand if the benefits from proposed pruning are significant in nature. The results in table 2 and those of FedMA are very close that it can be considered statistically significant. \n6) Results on FedMA are not included in the main paper. Please replace some section of Table 2 to accommodate the same.\n7) Based on the main theorem proposed, section 4.2 argues that pruning results in lower entropy and hence better loss barrier. However the later part of the section claims that \"LMC first increases and then drops Figure 5\". This seems to be not explained by the theory proposed and is a major point of confusion in presented material. What is meaning of LMC increasing or decreasing? Is this referring to loss barrier or accuracy along linear mode?"
                },
                "questions": {
                    "value": "Q1) Could you provide the comparison between the relative order of magnitudes of various constants in the presented Theorem 3.1? It seems crucial to understand the same to understand the impact of entropy in that equation.\n\nQ2) Consider two untrained VGG network on MNIST dataset vs two trained VGG network. As seen in Figure 4, the trained networks have non-trivial loss barrier. But the non-trained networks would have closer to zero loss barrier because they already are at a high point in the loss landscape. There can be different ways in which this can be made to happen. However the entropy of trained networks are lower, but it does not explain the different in loss barrier? This seems contradictory to the result in the paper.\n\nQ3) I don't seem to get grasp on how bias could be added to weight matrix through small adjustment as mentioned just before section 2.2. Please elaborate the same in the light of if equation 3 still holds. \n\nQ4) In experiment 4.1, why are the curves later fit to the observation vs plotting the entropy exp(.) function.\n\nQ5) Are bias terms = 0 in all the networks considered in experiments? If not how is OTFusion extended for the same.\n\nQ6) Could you please why LTH does not lead to good fused networks? Different matching algorithms should be able to combine two models generated by LTH.\n\nQ7) What does '/' mean in Table 2? Please also include base model accuracy for fusion. Why are models fine tuned till epoch 30? \n\nTypos:\n\na) Please fix VGG11 vs VGG16 in Table 2 and section 5. They seem to be interchangeably used."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7417/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7417/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7417/Reviewer_y1Dw"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7417/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698824534156,
            "cdate": 1698824534156,
            "tmdate": 1699636889318,
            "mdate": 1699636889318,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]