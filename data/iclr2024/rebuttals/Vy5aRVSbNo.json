[
    {
        "title": "Looping LOCI: Developing Object Permanence from Videos"
    },
    {
        "review": {
            "id": "36a205XNE1",
            "forum": "Vy5aRVSbNo",
            "replyto": "Vy5aRVSbNo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5681/Reviewer_so16"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5681/Reviewer_so16"
            ],
            "content": {
                "summary": {
                    "value": "The paper focuses on the problem of compositional scene representation learning from videos. Specifically, the authors propose an extension of the Loci (Traub et al., ICLR 2023) by an additional module where it can decide whether to leverage the sensory input to determine the object state or purely rely on previous object states. In this way, the proposed method is able to handle object occlusions and sensory interruptions (masking random frames to be black). The experiments show that the model obtains better object tracking performance on the ADEPT dataset compared with baselines, and better performance of sensory interruptions on the CLEVERER dataset."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper proposes an interesting extension of Loci to handle object occlusion and sensory interruptions.\n- The proposed method exhibits strong object tracking performance on the ADEPT dataset compared with previous methods like Loci and SAVi."
                },
                "weaknesses": {
                    "value": "- My major concern about the paper lies in the limited contribution and generalizability of the proposed method. The design of the model is a bit complex and ad-hoc. The core contribution is the introduction of an inner loop that enables the model to imagine object dynamics without sensory inputs. To be more specific,  the proposed model is encouraged to ignore the sensory input when the object is being occluded. This does not make sense when the camera is moving, as the camera motion (which needs to be inferred from video) should also be considered for inferring the view-centered object motion. Failing to account for that makes the model rather limited. I am interested in authors\u2019 opinions about how to extend the current model to support this. It is interesting to see the current model\u2019s performance on the LA-CATER Moving dataset proposed in [1] which contains camera movements. \n\n- On the other hand, the evaluation of the paper is rather limited. The main experiments regarding object tracking only consider ADEPT, a synthetic object with a simple background and at most 3 moving objects. It is unknown how the method will perform on more complex and realistic datasets. I understand this is a common concern for a lot of compositional scene representation learning works. But given the limited technical contribution of the paper and the complexity of the proposed method, I believe a more comprehensive evaluation will make the paper stronger. For example, why authors do not evaluate on the CLEVRER and Aquarium as in the original Loci paper? \n\n[1] Object Permanence Emerges in a Random Walk along Memory. Pavel Tokmakov, et al. ICML 2022"
                },
                "questions": {
                    "value": "Apart from the questions I mention in the weakness section, I have a few more questions:\n\n- In Figure 4, t=42, why the green object ceases to exist in the imagination of loci-looped?\n- Can this inner loop mechanism be leveraged in other compositional scene representation learning methods? Demonstrating the effectiveness of this mechanism on other models will also make the paper stronger.\n- Can authors provide more qualitative results (e.g. videos) about the tracking performance of the proposed method?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5681/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5681/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5681/Reviewer_so16"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5681/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698738539332,
            "cdate": 1698738539332,
            "tmdate": 1699636593210,
            "mdate": 1699636593210,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KhsIghQrwZ",
                "forum": "Vy5aRVSbNo",
                "replyto": "36a205XNE1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5681/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5681/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to Reviewer so16"
                    },
                    "comment": {
                        "value": "Thank you for acknowledging that Loci-Looped exhibits strong object tracking performance. Please see the general response as response to most of your comments. \n\nIndeed, in Figure 4 the model narrows down the hidden object as it approaches the edge of the occluder. This interesting behavior is fully emergent as the model never encountered vanishing objects in the training dataset. The model does not completely let the object vanish, which becomes apparent by the surprise signal.\n\nIn general, this inner loop should be applicable to other compositional scene representation learning methods if they use a latent prediction module. For example this is the case in SAVi, where a percept gate could be incorporated after the Correction module. In contrast, this would not work for Steve as this model does not predict the next object states. However, we hypothesize that the success of the inner loop in Loci-Looped also depends on its inductive bias to maintain stable object representations which is enforced by the GateLORD architecture as well as by the regularization terms."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5681/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700531106571,
                "cdate": 1700531106571,
                "tmdate": 1700531106571,
                "mdate": 1700531106571,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RGZaPoC0dd",
                "forum": "Vy5aRVSbNo",
                "replyto": "KhsIghQrwZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5681/Reviewer_so16"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5681/Reviewer_so16"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks authors for the response. I believe the experiments of the paper still fail to demonstrate the generalizability of the method.  I will keep my rating."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5681/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700730562062,
                "cdate": 1700730562062,
                "tmdate": 1700730562062,
                "mdate": 1700730562062,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "GZ94r0G8Xv",
            "forum": "Vy5aRVSbNo",
            "replyto": "Vy5aRVSbNo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5681/Reviewer_A5xP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5681/Reviewer_A5xP"
            ],
            "content": {
                "summary": {
                    "value": "In this manuscript the authors describe an extension of their Loci method for tracking objects in video. They add an internal connection that propagates latent predictions directly to a model that previously had only a loop through pixel space. This addition improves tracking for fully occluded images substantially for simplified rendered scenes."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Overall this approach is interesting as an interpretable model of object tracking and the authors present some observations showing that their method tracks fully occluded objects now. The model still learns in an unsupervised way from video data, is evaluated on a few different tasks and does pass basic object constancy tests as used for children."
                },
                "weaknesses": {
                    "value": "The tests are all performed in extremely reduced situations where simple objects move along fully predictable straight trajectories, which raises concerns about the scaling and generality of the approach. Additionally the work is clearly incremental as it extends a highly similar method from last year. Thus, I am not convinced this manuscript warrants another publication yet.\n\nFor the evaluations, I believe a more natural dataset with higher variability of the trajectories and object motion and/or in the properties of objects would be desirable. And even for the simple situations covered by the manuscript, more comparison models are necessary. At very least the PLATO and ADEPT models mentioned in the manuscript should really be tested on the same data for comparisons. And going further I am also not convinced that other models without explicit object representations categorically cannot represent the objects through occlusions. While I share the intuition that they should be worse, I think this should be shown properly by evaluating  such more general models on the same test data.\n\nAnd on the model side, it is an observation that this added loop improves the Loci model, but this seems to me like an incremental improvement about this specific model. To be convincing as an insight about models I would require an application to multiple models that shows that this is indeed a general productive direction for object slot models. As it stands now, I don\u2019t see any clear insight to gain from this manuscript beyond the authors presenting a revised version of their model."
                },
                "questions": {
                    "value": "I don\u2019t have questions for the authors."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5681/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698790436124,
            "cdate": 1698790436124,
            "tmdate": 1699636593121,
            "mdate": 1699636593121,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gjGh8gX4gx",
                "forum": "Vy5aRVSbNo",
                "replyto": "GZ94r0G8Xv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5681/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5681/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to Reviewer A5xP"
                    },
                    "comment": {
                        "value": "Thank you very much for acknowledging that the addition of the inner loop substantially improves tracking for occluded objects.\n\nThank you for the comment. Indeed, the tested occlusion scenarios are rather simple. The more surprising it is that these tests can not be solved by current state-of-the-art models like Loci-v1 or SAVi. Although our introduction of the internal information fusion process is incremental, our work clearly shows that this addition has a major effect on the model's ability to deal with occlusion scenarios. To the best of our knowledge this is the first time such a process is introduced for compositional scene representation models.\n\nIn general, the inner loop can be incorporated in all models that make use of a latent prediction model. For compositional scene representation models, this is however not very common as many models do not ensure slot consistency over time using recurrent next-step predictions. Incorporating the precept module into other compositional scene representation models is an interesting avenue for future experiments. The slot-wise information fusion process may also be an interesting candidate for other object-centric transition models in different model domains, for example in the DREAMer (Hafner et. al, 2019) architecture."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5681/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700530947397,
                "cdate": 1700530947397,
                "tmdate": 1700530947397,
                "mdate": 1700530947397,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "arg4YMgxPA",
                "forum": "Vy5aRVSbNo",
                "replyto": "gjGh8gX4gx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5681/Reviewer_A5xP"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5681/Reviewer_A5xP"
                ],
                "content": {
                    "title": {
                        "value": "Read response, keep my rating"
                    },
                    "comment": {
                        "value": "I appreciate the authors' response and agree with them that the loop they introduce here could still be an interesting addition for more complex situations or other models. However, I maintain that this would be necessary to complete this project and make it convincing enough. Thus, I did not change my ratings."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5681/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700697646841,
                "cdate": 1700697646841,
                "tmdate": 1700697646841,
                "mdate": 1700697646841,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9T5erkGPkN",
            "forum": "Vy5aRVSbNo",
            "replyto": "Vy5aRVSbNo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5681/Reviewer_3utS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5681/Reviewer_3utS"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a follow-up architecture with a different set of regularizers based on prior slot attention next-frame prediction work. The authors claim that the system is able to \"form concepts of object permanence and inertia from scratch in a fully self-supervised\nmanner.\" The authors evaluate the system on two datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- **S1** The study could offer understanding on the advantages and limitations of current machine learning systems for modeling object permanence.\n- **S2** The approach description is written clearly. the authors provide detailed descriptions of their proposed approach."
                },
                "weaknesses": {
                    "value": "**W1 - A critical aspect of the result - visualization of slot attention decomposition is missing**. \n\nThe result section does not contain any illustrations of slot decomposition and roll-out results across time. Please see **Figure 6** in [1] and **Figure 5** in [2]. It is critical to visualize slot decompositions, especially given how strongly authors are attempting to make the \"object permanence\" claim.\n\n \n**W2 - More ablation experiments are needed to justify the robustness of the system**. \n\n- For instance, for **Figure 2**, what would happen if the authors change the camera poses, such as following a spherical trajectory, while rolling out the model? The authors could visualize slot decompositions while varying camera poses. \n- How important is each of the regularizers proposed in **Table 1**? Many changes are made going from Loci-v1 to Loci-looped.\n\n\n**W3 - More comparisons with baselines are needed** The authors did not compare against many powerful frameworks, such as [1] and [2]. It would be very valuable to know where the proposed approach stands.\n\n\n**W4 - More discussions and analysis are needed to justify strong claims** such as \"forming the concept of object permanence and inertia from scratch.\" \n- How is inertia property tested in the ADEPT's vanish scenario? \n- Can the proposed system estimate the unknown inertial parameters of rigid bodies in the physical system given videos?\n\n**W5 - What are the limitations of this work? There does not seem to be any discussion.** For example, how would the system perform if non-rigid materials were present in the scene? Suppose a cup of water is being poured into a basket that is occluded by a board, a similar setup to your current experiments. Could the system still infer that the water is permanent across time?\n\n\n[1] Elsayed et al., SAVi++: Towards End-to-End Object-Centric Learning from Real-World Videos, NeurIPS 2022.\n\n[2] Wu et al., SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric Models, ICLR 2023."
                },
                "questions": {
                    "value": "Please see the weaknesses section above. Thanks."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5681/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698800644969,
            "cdate": 1698800644969,
            "tmdate": 1699636593023,
            "mdate": 1699636593023,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rDCZHgUsS0",
                "forum": "Vy5aRVSbNo",
                "replyto": "9T5erkGPkN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5681/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5681/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to Reviewer 3utS"
                    },
                    "comment": {
                        "value": "Thank you very much for the thoughtful comments. \n\nThank you for the helpful comment, pointing out that the slot decomposition is missing in the illustrations. We now provide illustrations of the slot decomposition in the appendix. We hope this makes clear, that the objects persist in the slot representation when occluded. Moreover, we now provide videos in the supplementary material.\n\nConcerning the importance of the different regularization terms: The Gestalt Change, the Position Change and Object Permanence Regularization are ablated in Traub et al. (2023), suggesting that the Gestalt Change and the Position Change regularization is important for learning. We are currently running ablation studies on the Input-Frame Reconstruction Loss and the Gate Opening Regularization and will add them to the Appendix.\n\nWe now clarify in the methods section that we define intertia as the continuation of motion unless acted on by an external force. We test this property by letting the model predict how the occluded objects continue to move when hidden or when a blackout occurs. \n\nIndeed non-rigid materials present a challenge to the current model (and very likely to most others). We are happy to include this aspect as a limitation in the discussion section among other limitations."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5681/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700530754109,
                "cdate": 1700530754109,
                "tmdate": 1700530754109,
                "mdate": 1700530754109,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "WlJIHqFd38",
            "forum": "Vy5aRVSbNo",
            "replyto": "Vy5aRVSbNo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5681/Reviewer_4W7W"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5681/Reviewer_4W7W"
            ],
            "content": {
                "summary": {
                    "value": "The paper provides an improved version of the recently proposed Loci (location and identity tracking) model, by introducing an internal loop of prediction and updating. The major advantage of the proposed Loci-looped model is that the network is able to track objects even when they are occluded or during blackout. The paper claims that it shows surprise signal when an object violates object permanency, reflecting the learning of the rule of object permanency and inertia"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The infants' learning of objects' property is holistic: they not only learn to segment objects, but indeed learn certain properties of objects (such as object permanency) without supervision. It is nice to have a model that simultaneously learn both without supervision. As pointed out by the authors, although many models show good performance on some datasets, they use supervision or conditioning signals that are not available to human brain, thus do not provide insight for how these abilities can be jointly learned without supervision as infants.\n\nThe idea of separately generating object mask and visibility mask appears to be novel, which is required for demonstrating object permanency."
                },
                "weaknesses": {
                    "value": "I believe that the ability of correctly segmenting objects in the newly proposed framework largely comes from the information bottleneck. Although it works well with the chosen datasets which have almost pure colors in each object, I doubt it will work well in environments with more complex texture as in nature or in datasets such as MOVI-c and beyond (https://github.com/google-research/kubric/tree/main/challenges/movi). Although I guess segmentation is not treated as a major contribution, I worry about how much the proposed principle can be scaled up and generalize. \n\nIf we are restricted to a simple environment, one can imagine that another model that simply clusters pixels based on colors and estimate the center of mass of the clustered pixels could likely segment and localize objects correctly in the CRATER dataset, without using a neural network. Then an RNN that learns to predict the center of mass based on the previous trajectory extracted with the above approach and weights its loss function based on the number of pixels in the correct color corresponding to that object can also shut down gradient when an object is occluded, and then receive teaching signal once the object reappears. This way, the RNN may also be able to learn to predict a linear moving trajectory. Now perhaps what I describe here essentially is similar to the idea of perceptual gate and perhaps the advantage of the current model is that the gate is learned rather than being hard coded as being decided by pixel counts, what I am trying to say is that the environment may not pose enough challenge for the task that the model aims to solve (all of segmentation, localization and tracking). If an environment allows defining the gate by a pre-defined rule, then learning it seems trivial. I am not against using such dataset for proof of principle. But I think this limitation should not be ignored.\n\n\nI hope that the writing can be slightly clearer. For example, the meaning of Gestalt has expanded to capture the principle to organize parts into an object due to Gestalt school of psychology. If you follow the simple description of gestalt code as \"mainly representing shape and surface pattern\" in loci-v1 paper, it is a good idea to define it here as well.\n\nThere are other unclear parts. Please see my questions.\n\nThe slot error is claimed to serve as a surprise signal. But some details of its pattern appears strange to me. In Figure 3, after frame 30, the slot error is of similar magnitude for both the reappearing and vanishing object. If as the paper tries to claim that the model learns to imagine objects behind the plate during occlusion, then I would expect that it should predict the appearance and location of the object more or less correctly when the object should reappear. In other words, the slot error should be smaller in the reappearing case than in the vanishing case (which violates object permanency and should not be predictable at all). An indifference here seems to indicate either the prediction of occluded object is quite wrong upon reappearing or that the model somehow learns to predict vanishing object somewhat correctly?"
                },
                "questions": {
                    "value": "In equation 2: there seems to be no restriction being mentioned that the visibility mask should be smaller than the object mask (or even within it), I assume it is possible for the numerator to become larger than denominator and for the occlusion state to be negative. How do you stop this? \n\nThere is a sentence between Figure 2 and 3.3: \"By adding Gaussian noise with a fixed standard deviation ..., learning is biased to move further into plateaus away from ridges where possible.\" I am sorry that I did not quite get what plateaus and ridges refer to here. Something about loss landscape as a function of all network weights? \n\nBelow that, it was stated that L0 regularization is imposed on gate opening, but L0 loss has no gradient. If I understand correctly, equation 10 indicates that you instead use 1 as gradient. To me it seems that you are actually imposing L1 loss for positive values instead of L0 loss.\n\nIn Result of 4.2 next to Figure 3, I did not really understand \"significant correlation between the slot error of vanished objects and the visibility of reappearing objects\". If these two quantities are of two different objects, why should we expect them to be correlated? I also don't understand by \"likewise, we find the same pattern for the size of visibility mask\" what correlation you refer to.\n\nIn the experiment of 4.2, does the occluding plate also get assigned a slot, or is it treated as part of the background by the network? How does the prediction for the plate looks like when it falls?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5681/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5681/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5681/Reviewer_4W7W"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5681/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699707591143,
            "cdate": 1699707591143,
            "tmdate": 1699708828538,
            "mdate": 1699708828538,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "WbU4vHAK8s",
                "forum": "Vy5aRVSbNo",
                "replyto": "WlJIHqFd38",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5681/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5681/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to Reviewer 4W7W"
                    },
                    "comment": {
                        "value": "We deeply value the reviewer's recognition of our model's ability to emulate infants' holistic learning without supervision -- a pivotal aspect in understanding how these innate abilities can be jointly learned.\n\nWe appreciate the suggestion for a rule-based baseline. We have added a Loci-Visibility baseline, whose percept gate is controlled solely based on the perceived occlusion state i.e. Loci switches to the inner-loop when objects become occluded. We find that it performs superior to Loci-Unlooped highlighting the importance of the inner loop. However, it performs inferior to Loci-Looped, demonstrating the importance of learning an adaptive gate control function that flexbily balances the inner and the outer looop, rather than approximating a simple rule.\n\nWe also recognize the necessity of testing the model on more complex occlusion scenarios, such as non-linear object movements or containment situations. This limitation has been now duly addressed in our discussion, emphasizing the need for datasets that pose greater challenges in terms of segmentation, localization, and tracking to further evaluate and enhance the model's abilities.\n\nThank you for pointing out that Figure 3 was a bit confusing in that respect. Due to averaging effects the greater surprise in the vanishing trials was not explicitly illustrated in the plot. We have added an additional box plot (Figure 3a) showing that the maximum slot errror is significantly larger when hidden objects fail to reappear after occlusion and after the occluder rotates to the ground, compared to trials in which objects do reappear. We also now add a video to the supplementary material, which shows that our system expects the reappearance and then \"parks\" the object behing the occluder until the occluder falls over. Please note that this latter behavior is fully emergent, as our system was not trained on vanishing trials. \n\n\nAnswering the questions:\nThe requirement that the object mask must be contained within the object mask itself stems from equation 1. This constraint emerges from our approach to computing the object mask, where we consider only slot-object k within the scene, disregarding other slots. Consequently, slot k only competes with the background for visibility yielding the object mask. Conversely, when deriving the visibility mask, slot k competes not just with the background but also with all other slots present. If the other slots do not intersect with slot-object k, the object mask aligns with the visibility mask. However, if there's an overlap between the remaining slots and slot-object k, the visibility mask becomes a subset of the object mask. This implies that the visibility mask can never exceed the object mask (paragrpah 3.2.1.).\n\nIndeed, the sentence \"By adding Gaussian noise with a fixed standard deviation ..., learning is biased to move further into plateaus away from ridges where possible\",  refers to the landscape of the rectified tanh activation function. We rephrased this sentence to \"... the gates tend to either close or open, rather than remaining partially open\", to improve comprehension.\n\nThe distinction between L0 and L1 regularization lies in the computation of the backpropagated error. In the scenario of the L1 Loss, the backpropagated error equates to the value of alpha (gate opening; alpha * 1). However, in our case, the backpropagated error is either 1 (when alpha > 0) or 0 (when alpha = 0, expressed as heavyside(alpha) * 1).\n\nThank you for pointing that the correlation needs more explanation. The concept here revolves around the similar trajectories of objects reappearing and vanishing. The visibility spike of reappearing objects (observed after frame 30 in Figure 3) signifies an expected moment when both vanishing and reappearing objects should become visible again. Therefore, the visibility of reappearing objects serves as an indicator for the visibility of vanishing objects. Our observation reveals that both the slot error and the visibility mask for vanished objects rise within this specific time interval. This suggests that the model anticipates the vanishing objects to become visible again during this interval, effectively predicting their reappearance. We've revised the paragraph to convey this argument more clearly and moved it to the appendix.\n \nIndeed, the occluding plate is also assigned a slot. It is represented as one object in the model. We have added illustrations to the appendix showing the model's prediction for the falling plate. Moreover, we have added video material to the supplementary material."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5681/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700530611858,
                "cdate": 1700530611858,
                "tmdate": 1700530611858,
                "mdate": 1700530611858,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]