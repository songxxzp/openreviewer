[
    {
        "title": "A Bias-Variance-Covariance Decomposition of Kernel Scores for Generative Models"
    },
    {
        "review": {
            "id": "Dc1HtnnTkG",
            "forum": "EvwnYpesoD",
            "replyto": "EvwnYpesoD",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3423/Reviewer_ox7H"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3423/Reviewer_ox7H"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on the evaluation of generative models\u2019 performance. Generalization and uncertainty are two primary consideration and the bias-variance-covariance decomposition are introduced for kernel scores and entropy. The performance is examined on vision, voice and text datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper is clearly written and the studied topic is crucial in large language models.\nThe author develops the distributional correlation as a tool to insight into the generative model\u2019s fitting.\nThe author performed extensive experiments to validate the effectiveness of the developed tool."
                },
                "weaknesses": {
                    "value": "See the question part below."
                },
                "questions": {
                    "value": "Can you explain the reason why this method works best on question answering datasets?\nI\u2019m wondering how to generalize the theory to others except the kernel scores."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3423/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698135453648,
            "cdate": 1698135453648,
            "tmdate": 1699636293883,
            "mdate": 1699636293883,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jPQ8aEZq0h",
                "forum": "EvwnYpesoD",
                "replyto": "Dc1HtnnTkG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Overview"
                    },
                    "comment": {
                        "value": "Dear reviewer ox7H,\n\nThank you very much for taking the time to engage with our paper. Below, we have tried to address all of your feedback and questions. \nSpecifically, we give reasoning for our strong performance in natural language generation and explain why a covariance term cannot be derived for other losses.\nPlease take a look and let us know in case you would like additional clarification on any of these points."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3423/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700225550033,
                "cdate": 1700225550033,
                "tmdate": 1700225550033,
                "mdate": 1700225550033,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sUaMUi9vcF",
                "forum": "EvwnYpesoD",
                "replyto": "Dc1HtnnTkG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reasoning for the Natural Language Performance"
                    },
                    "comment": {
                        "value": "Kernel scores are loss functions giving good values when the prediction is close to the ground truth and bad values when not. In Figure 4 and 6, the Pearson correlation between the kernel entropy (our uncertainty measure) and the loss (kernel score) shows that kernel entropy is very effective in predicting the loss. \nThe nlg results in Figure 7 confirm that this holds for the loss used to evaluate question answering datasets.\nPart of the explanation for our good results is that the embedder transforms the generated answers into a semantically meaningful vector space, in which the kernel then compares the similarities. Vector embeddings combined with the cosine similarity have a long history in the NLP domain, which underlines their effectiveness (Camacho-Collados et al, 2018).\n\n**References:**\n\nJose Camacho-Collados and Mohammad Taher Pilehvar. From word to sense embeddings: A survey on vector representations of meaning. Journal of Artificial Intelligence Research, 63:743\u2013788, 2018."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3423/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700225641854,
                "cdate": 1700225641854,
                "tmdate": 1700225641854,
                "mdate": 1700225641854,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XMbl6qLHTd",
                "forum": "EvwnYpesoD",
                "replyto": "Dc1HtnnTkG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Generalizing Theory to other Losses"
                    },
                    "comment": {
                        "value": "We were able to derive the bias-variance-covariance decomposition by using a quadratic form in the definition of kernel scores. This quadratic form is in general not present for other losses, which prohibits deriving a covariance term."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3423/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700225691553,
                "cdate": 1700225691553,
                "tmdate": 1700225691553,
                "mdate": 1700225691553,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "CtylaPSQgS",
            "forum": "EvwnYpesoD",
            "replyto": "EvwnYpesoD",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3423/Reviewer_27VK"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3423/Reviewer_27VK"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a method to analyze the performance of a generative model in terms of bias (compared to the true distribution) vs. variance (with respect to replications of the model on independent training data), using kernel methods to estimate distributional distances.  It develops theory which defines RKHS-based variance scores and develops simple U-statistic-like estimators.  They demonstrate their approach in image generation (Infinite MNIST), Audio Generation (LJSpeech), and Natural Language Generation examples.  In image generation example, the method shows that the variance stays high and is reduced throughout training, while bias quickly converges."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper contributes a useful theoretical tool.  it is clearly written.  The image generation and audio generation examples demonstrate that the method can provide useful insights into the properties (e.g. distributional diversity, stability) of the generative models.  For example, the paper demonstrates some suggestive evidence for how mode collapse affects only the bias but not the variance.  We see that using predictive kernel entropy of LLM answers to predict answer quality can be a useful tool, and compares favorably to lexical similarity and semantic entropy."
                },
                "weaknesses": {
                    "value": "Practitioners may find it challenging to apply this method to their case.  It is not clear what considerations should guide selection of a kernel.\nSome details about the experiments are missing, which make it harder to interpret the results (see Questions)."
                },
                "questions": {
                    "value": "1. In figure 4, what are the points being plotted?  The 20 different models?\n2. Why is only a single model used to compute kernel entropy? Are there any the advantages of using multiple models to compute the entropy?\n3. How is the bias calculated in the mode-collapse experiment of section 5.1?  Is the original distribution used to compute the bias, or the modified distribution with reduced frequency of class 0 used?\n4. Why use RBF kernel for images, but Laplace kernel for audio?\n5. Why do we see an entropy increase as training progresses for audio, but not for images?  Could it be an artifact of the choice to use a different kernel for images vs audio?\n6. In the language model experiment, does the superiority of using kernel entropy for predicting correct answers depend on the choice of kernel?  How are the AUC scores for Laplace kernel?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3423/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698174582109,
            "cdate": 1698174582109,
            "tmdate": 1699636293791,
            "mdate": 1699636293791,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rYjYPi2bZl",
                "forum": "EvwnYpesoD",
                "replyto": "CtylaPSQgS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Overview"
                    },
                    "comment": {
                        "value": "Dear reviewer 27VK,\n\nWe appreciate your thorough review of our paper. In response to your feedback and questions, we have made efforts to address them comprehensively below. Specifically, we update Appendix C.2 with evaluations of the RBF kernel for the audio experiments and the Laplacian and polynomial kernel for the language experiments. We discuss the results in the following and also explain why kernel entropy stays constant in the image experiments but increases in the audio experiments.\nLast, we give answers to the other miscellaneous questions.\nIf you require further clarification on any specific points, please feel free to let us know."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3423/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700224537699,
                "cdate": 1700224537699,
                "tmdate": 1700224627298,
                "mdate": 1700224627298,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PRWwjHHsLo",
                "forum": "EvwnYpesoD",
                "replyto": "CtylaPSQgS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "content": {
                    "title": {
                        "value": "RBF Kernel for Audio Experiments"
                    },
                    "comment": {
                        "value": "The RBF kernel is a common kernel for low-to-medium dimensional data, such as low resolution images like MNIST (Sch\u00f6lkopf, 1997).\nHowever, the RBF kernel does not scale well to higher dimensions (Binkowski et al, 2018).\nThis is problematic since audio instances are represented by vectors of length 100,000 or more in our experiments (c.f. Figure 10 Appendix C.2.2).\nConsequently, we use the Laplacian kernel in the main paper but also add an evaluation with the RBF kernel in Figure 11 in Appendix C.2.2.\nAs expected, the results are more erratic compared to the Laplacian kernel but show a similar trend.\nSpecifically, the kernel score and kernel entropy increase and decrease at the same training iterations, however the absolute Pearson correlation between them is only between 0.8 and 0.9.\n\n**References:**\n\nBernhard Sch\u00f6lkopf. Support vector learning. PhD thesis, Oldenbourg M\u00fcnchen, Germany, 1997.\n\nMiko\u0142aj Bi\u0301nkowski, Danica J Sutherland, Michael Arbel, and Arthur Gretton. Demystifying MMD GANs. In International Conference on Learning Representations, 2018."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3423/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700224700949,
                "cdate": 1700224700949,
                "tmdate": 1700224700949,
                "mdate": 1700224700949,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2FjQ1Ph25F",
                "forum": "EvwnYpesoD",
                "replyto": "CtylaPSQgS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Natural Language Results for Different Kernels"
                    },
                    "comment": {
                        "value": "We compare the AUROC of the kernel entropy for various choices of kernels in Figure 14 in Appendix C.2.3.\nThe differences between RBF and polynomial kernel as well as cosine similarity are marginal, while the Laplacian kernel performs worse.\nThis is in line with common practice in NLP, where cosine similarity is the most often used kernel to compare text embeddings (Camacho-Collados & Pilehvar, 2018).\n\n**References:**\n\nJose Camacho-Collados and Mohammad Taher Pilehvar. From word to sense embeddings: A survey on vector representations of meaning. Journal of Artificial Intelligence Research, 63:743\u2013788, 2018."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3423/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700224850837,
                "cdate": 1700224850837,
                "tmdate": 1700224850837,
                "mdate": 1700224850837,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iJqJN9X4kW",
                "forum": "EvwnYpesoD",
                "replyto": "CtylaPSQgS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Kernel Entropy Stays Constant in Images but Increases in Audio"
                    },
                    "comment": {
                        "value": "The discrepancy of the kernel entropy behavior between the image and audio experiments can be explained via the architecture and task setup. For image generation, the initial diffusion model already generates volatile and noisy samples. This leads to a roughly constant kernel entropy throughout training. In contrast, the audio model initially generates very short audio instances (c.f. Figure 10 Appendix C.2.2).\nThis means that most of the entries in the audio vector are zeros, which results in a small kernel entropy. Consequently, the kernel entropy increases as soon as the model learns to produce longer audio instances."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3423/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700224996243,
                "cdate": 1700224996243,
                "tmdate": 1700224996243,
                "mdate": 1700224996243,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "V4ZXa0xNUd",
                "forum": "EvwnYpesoD",
                "replyto": "CtylaPSQgS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Miscellaneous Questions"
                    },
                    "comment": {
                        "value": "* Q: \u201cPractitioners may find it challenging to apply this method to their case.\u201d\n\nA: We added a description of our procedure to compute the kernel entropy in Algorithm 1 Appendix C.1. Note that our final approach is simpler to implement than semantic entropy introduced by Kuhn et al (2023).\n\n\n* Q: \u201cIn figure 4, what are the points being plotted? The 20 different models?\u201d\n\nA: Each point in Figure 4 corresponds to a digit.\n\n\n* Q: \u201cWhy is only a single model used to compute kernel entropy? Are there any advantages of using multiple models to compute the entropy?\u201d\n\nA: We compute the kernel entropy based on single models to stay as truthful as possible to practical constraints: Generative models are usually computationally very expensive and closed-source access is almost always provided only to single models. It is likely that the average kernel entropy of multiple models gives even better results because this improves the estimation.\n\n\n* Q: \u201cHow is the bias calculated in the mode-collapse experiment of section 5.1? Is the original distribution used to compute the bias, or the modified distribution with reduced frequency of class 0 used?\u201d\n\nA: The MMD, bias, and variance values in Figure 5 are only computed with respect to digit \u20180\u2019 (which has reduced frequency in the training data). \nThe other digits in the mode-collapse experiment have similar lines as in Figure 3 (no reduced frequency in the training data).\n\n\n**References:**\n\nLorenz Kuhn, Yarin Gal, and Sebastian Farquhar. Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation. In The Eleventh International Conference on Learning Representations, 2023."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3423/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700225372598,
                "cdate": 1700225372598,
                "tmdate": 1700225372598,
                "mdate": 1700225372598,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6eTFHdQuhw",
                "forum": "EvwnYpesoD",
                "replyto": "rYjYPi2bZl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3423/Reviewer_27VK"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3423/Reviewer_27VK"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your replies"
                    },
                    "comment": {
                        "value": "Thanks for addressing my questions.  I still need more time to digest the new additions, but I will consider raising my score during the reviewer-reviewer discussion period."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3423/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700580272331,
                "cdate": 1700580272331,
                "tmdate": 1700580272331,
                "mdate": 1700580272331,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "jcWceYMOBp",
            "forum": "EvwnYpesoD",
            "replyto": "EvwnYpesoD",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3423/Reviewer_vzDu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3423/Reviewer_vzDu"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors propose the bias-variance-covariance decomposition for kernel scores, which is an unbiased and consistent estimator for uncertainty measurement in deep generative models such as large language models. Their approach only requires samples from the predictive distribution rather than the distributions themselves, which means that we can evaluate all terms in the composition for any deep generative model. \nEmpirically they evaluate their approach on models with image and video data and large language models, and they showed that their kernel  entropy outperforms other baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper is well-motivated; It is worth studying the generalization and uncertainty characterization in large language models. The paper is clearly written and well structured. To my knowledge, the math derivation in the methodology is sound. I found it useful that their estimator only would require samples from the predictive distributions rather than those distributions themselves, which has a large range of applications. Also, they provide comprehensive evaluations of both image data and text data."
                },
                "weaknesses": {
                    "value": "The authors claim that one of the advantages of their uncertainty estimator is that it includes a covariance term. I would hope to see a more detailed discussion on this. For example, how that covariance term characterizes uncertainty that cannot be done by prior work."
                },
                "questions": {
                    "value": "1. How do different sample sizes affect the empirical results? In Figure.2 there is a fixed sample size. I wonder how to tune that in general.\n2. Is there any difference in terms of the outperformance of your estimator when you work on image data and text data?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3423/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3423/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3423/Reviewer_vzDu"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3423/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698715871388,
            "cdate": 1698715871388,
            "tmdate": 1699636293728,
            "mdate": 1699636293728,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3XHs7RdIAY",
                "forum": "EvwnYpesoD",
                "replyto": "jcWceYMOBp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Overview"
                    },
                    "comment": {
                        "value": "Dear reviewer vzDu,\n\nWe appreciate your thorough review of our paper. We have carefully addressed all the feedback and queries you provided below. Specifically, we discuss the effect of different sample sizes and the benefits of an explicit covariance term in the bias-variance decomposition.\nFeel free to reach out if you need further clarification on any of these matters."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3423/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700223978675,
                "cdate": 1700223978675,
                "tmdate": 1700223978675,
                "mdate": 1700223978675,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hLVn78I0KH",
                "forum": "EvwnYpesoD",
                "replyto": "jcWceYMOBp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Effect of Sample Sizes"
                    },
                    "comment": {
                        "value": "In general, our theoretical results and Figure 2 indicate that more samples are always better. However, at some point the improvements are too marginal to justify the computational costs. To highlight this point, we plot the AUROC of the kernel entropy in case of Opt-13b and CoQA for different sample sizes (=number of text generations) in Figure 15 in Appendix C.2.3. As can be seen, more samples are always better, but the improvement flattens for larger sizes. In the main paper in Figure 7, we use 20 generations for CoQA and 10 generations for TriviaQA, which follows Kuhn et al (2023).\n\n**References:**\n\nLorenz Kuhn, Yarin Gal, and Sebastian Farquhar. Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation. In The Eleventh International Conference on Learning Representations, 2023."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3423/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700224069865,
                "cdate": 1700224069865,
                "tmdate": 1700224069865,
                "mdate": 1700224069865,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "P8IQAU20cR",
                "forum": "EvwnYpesoD",
                "replyto": "jcWceYMOBp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Benefits of the Covariance Term"
                    },
                    "comment": {
                        "value": "In previous work, the bias-variance decomposition is often used to motivate ensemble approaches. Specifically, it is assumed that the individual ensemble members are independent, which then reduces the variance term and also the generalization error. However, it is not clear how negative the effect on the generalization error is when this assumption is violated.\nOur variance-covariance decomposition allows us to quantify the negative impact of correlated ensemble members via the covariance term. In Figure 3 we use the normalized covariances (=correlations) for better interpretability. As we can see, the correlations between epochs 20 to 40 are very high, which means that creating an ensemble based on iterative gradient steps, like stochastic weight averaging Gaussian (Maddox et al, 2019), strongly violates the independence assumption. Specifically, we can now quantify how much this correlation/covariance impacts the generalization error. This underlines the practical relevance of our theory.\n\n**References:**\n\nMaddox, W. J., Izmailov, P., Garipov, T., Vetrov, D. P., & Wilson, A. G. (2019). A simple baseline for bayesian uncertainty in deep learning. Advances in neural information processing systems, 32."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3423/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700224189957,
                "cdate": 1700224189957,
                "tmdate": 1700224189957,
                "mdate": 1700224189957,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "TBoPAvo7UK",
            "forum": "EvwnYpesoD",
            "replyto": "EvwnYpesoD",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3423/Reviewer_XNge"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3423/Reviewer_XNge"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a bias-variance-covariance decomposition for kernel scores, applying this decomposition to generative models. In particular they aim at assessing uncertainty of predictions by looking at the derived variance term (and the related predictive kernel entropy) as measures of uncertainty."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The work is well-motivated, since evaluating predictive uncertainty for generative models is a relevant problem. \n- The writing of the paper is clear and easy to follow. \n- The results in Section 5.3 indicate that the proposed approach favourably compares to recent relevant work on assessing predictive uncertainty of LLMs in QA tasks."
                },
                "weaknesses": {
                    "value": "Since the paper falls far from my area of expertise, and I am not sufficiently familiar with the mentioned related work, I'll refrain from commenting on the validity of the theoretical/methodological contribution.  However, specifically to the empirical results in the paper:\n- A large part of the empirical results (aside from Section 5.3) do not seem to contain important and conclusive insights. The main take-away seem to be distributional variance showing correlation with MMD, while many other observations such as on the stability of training do not seem to be as valuable.\n- \"This includes the discovery that mode collapse of underrepresented minority groups is expressed purely in the bias.\" made as a claim in the Introduction should be probably revisited. As far as I understand, the authors conclude this from their results on a single model and a single experiment, which is not enough to make a general statement. \n- While the paper is largely motivated by the need for evaluating predictive uncertainty for generative models, the only assessment of the approach for this purpose is made for LLMs on QA task (Section 5.3). The authors claim that their proposed uncertainty measure is applicable to a large range of generative models, and that this is an advantage over previously proposed methods, so it would be important to test its effectiveness in assessing predictive uncertainty for other generative tasks (e.g. image generation)."
                },
                "questions": {
                    "value": "To fully understand the setup and results in Section 5.3 I had to open the work from which the setup is replicated [1]. I think the section would benefit from a more thorough introduction of the experiment, in order to be self-contained. \n\n[1] Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar. Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation. In The Eleventh International Conference on Learning Representations, 2023."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3423/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3423/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3423/Reviewer_XNge"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3423/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698951756908,
            "cdate": 1698951756908,
            "tmdate": 1699636293637,
            "mdate": 1699636293637,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "X5e1vCa7kI",
                "forum": "EvwnYpesoD",
                "replyto": "TBoPAvo7UK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Overview"
                    },
                    "comment": {
                        "value": "Dear reviewer XNge,\n\nThank you for your time and attention. We appreciate your thorough review of our paper. We have carefully considered all your feedback and questions in the following responses. Specifically, we communicate how we adjust our claims about mode collapse and how image, audio, and language experiments are connected with uncertainty estimation. If you need further clarification on any of these points, please feel free to let us know."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3423/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700223698867,
                "cdate": 1700223698867,
                "tmdate": 1700223698867,
                "mdate": 1700223698867,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "asLow8Xq8I",
                "forum": "EvwnYpesoD",
                "replyto": "TBoPAvo7UK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Adjusting Claims about Mode Collapse"
                    },
                    "comment": {
                        "value": "We agree with the reviewer that the provided evidence is not sufficient to back our strong claims about mode collapse. We now soften our claims/formulations and clarify that our bias-variance-covariance decomposition can be used as a tool to diagnose mode collapse or overfitting and elucidate its nature in terms of bias and variance. We now also provide additional experiments to showcase the practical utility and repeat the same mode-collapse experiment of Figure 5 with other digits reduced (digit \u20182\u2019 and \u20183\u2019, c.f. Figure 9 Appendix C.2.1). Based on our bias-variance decomposition, we discovered that mode collapse does not appear in these cases. However, the lack of training data is still expressed in an increased bias term. Consequently, we are still convinced that our decomposition is a useful tool to gain insights into the fitting behavior of generative models."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3423/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700223748757,
                "cdate": 1700223748757,
                "tmdate": 1700223748757,
                "mdate": 1700223748757,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "twFtv2KixG",
                "forum": "EvwnYpesoD",
                "replyto": "TBoPAvo7UK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3423/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Uncertainty Estimation in Image, Audio, and Natural Language Experiments"
                    },
                    "comment": {
                        "value": "We now clarify how the experiments for image and audio are connected to the natural language generation (nlg) ones in terms of uncertainty estimation. In general, a meaningful measure of uncertainty is able to predict the loss for a given prediction.\nThe literature formulates nlg uncertainty estimation as a binary classification problem with a binary loss (Kadavath et al, 2022; Kuhn et al, 2023), i.e. a generation is either correct or wrong. Consequently, it makes sense to use the AUROC as a summary measure of how well an uncertainty measure predicts the correctness (i.e. is correlated to the loss). For image and audio generation we use a kernel-based loss function (kernel score), which has a continuous range of how good a prediction is. Consequently, we cannot use the AUROC anymore. Instead, we use the Pearson correlation (range between -1 and 1) to assess how well an uncertainty measure can predict the loss. Absolute values close to 1 indicate a very good uncertainty estimate.\nIn Figure 4 and 6, we can see that kernel entropy is very predictive of the loss (absolut Pearson correlation >0.9), making it an excellent measure of uncertainty in these cases. The nlg experiments in Figure 7 confirm that kernel entropy also gives state-of-the-art results for the binary loss function proposed by Kuhn et al (2023).\n\n**References:**\n\nSaurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, et al. Language models (mostly) know what they know. arXiv preprint arXiv:2207.05221, 2022.\n\nLorenz Kuhn, Yarin Gal, and Sebastian Farquhar. Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation. In The Eleventh International Conference on Learning Representations, 2023."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3423/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700223825720,
                "cdate": 1700223825720,
                "tmdate": 1700223825720,
                "mdate": 1700223825720,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]