[
    {
        "title": "Discovering Failure Modes of Text-guided Diffusion Models via Adversarial Search"
    },
    {
        "review": {
            "id": "hqizcwAyhY",
            "forum": "TOWdQQgMJY",
            "replyto": "TOWdQQgMJY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1931/Reviewer_jsKc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1931/Reviewer_jsKc"
            ],
            "content": {
                "summary": {
                    "value": "In this study, the authors investigate the limitations of Text-guided diffusion models (TDMs) and propose a novel approach called SAGE to systematically explore and understand these failures. TDMs are commonly used for image generation but can exhibit unexpected issues. The study identifies four key failure modes that have not been extensively studied before: \n1) TDMs can generate images that fail to accurately represent the semantics of the input text prompts. The authors discuss the causes and potential solutions for this issue.\n2) Some regions in the latent space of TDMs lead to distorted images, regardless of the text prompt. This suggests that certain parts of the latent space are not well-structured. \n3) Latent samples can produce natural-looking images that are unrelated to the given text prompt, indicating a potential misalignment between the latent and prompt spaces.\n4) The addition of a single adversarial token embedding to input prompts can lead to the generation of various specified target objects with minimal impact on CLIP scores, highlighting the fragility of language representations.\n\nOverall, the SAGE method efficiently explores both the discrete language space and the complex latent space, shedding light on these TDM failure modes and offering insights into potential solutions."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This work is interesting and systemically studying the failure mode of text to image generation model is an important and sometimes overlooked area of research.\n2. Comprehensive human study provides important validation on the results."
                },
                "weaknesses": {
                    "value": "1. It's well known that text image generative model can not handle multiple objects especially when keywords are relational and containing novel actions, for instance, \u201cA photo of a cat fighting a fish\u201d. If it's a novel scenario that was not seen in the training set, text to image models often produce only one of the subjects or some blended versions.\n\n2. Most of the proposed failures seem contrived, which are not really issues concerning day to day usage of text-to-image models, especially the ones in latent space, where explicitly optimization/distortion need to be performed on the latent vector, such that it will produce distort the image. If sampled naturally, this event is very unlikely to happen.\n\n3. The arguments are very hand-waving. Not enough evidence/details are provided to support the claims. \n    1) \"Furthermore, we demonstrate that these failure examples are not isolated spots in the latent space; rather, they exist as connected regions, wherein any sample will generate similar distorted images (see Supp. B.3). It shows that these distorted images can be generated with meaningful probability under Gaussian sampling, and the probability can be computed by the probability density function.\"\n    No calculation has been shown/referred to neither in the main body nor the appendix on the probability. In addition, the paper demonstrated only QQ-plot and statistic of three prompts. It's unclear whether it's a generalized phenomenon. \n     2)  \"Tab. 2 compares the normalized size of these failure regions and the probability of ...\" No details are provided on how the failure regions were calculated/estimated. How exactly the algorithms in PoseExaminer is adopted remains questionable.\n\n\n\nOne side note but not the main concerns I have on this paper: the presentation lacks structure and appears to be very messy. The authors seem to be ambitious in delivering many things all at once but failed to fufill any of the promises."
                },
                "questions": {
                    "value": "1. Do models hidden behind APIs also suffer the same failure modes? \n2. Instead of using the proposed optimization method to \"failure mode\", which is not of much significant value, why not use it to show the capability of steering/manipulation of the generated images?\n3. What happens if prompt engineering was applied, would it impact the way it fails?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1931/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1931/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1931/Reviewer_jsKc"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1931/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697674596495,
            "cdate": 1697674596495,
            "tmdate": 1700688644742,
            "mdate": 1700688644742,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "w5bTvn0T7F",
                "forum": "TOWdQQgMJY",
                "replyto": "hqizcwAyhY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author's Response to Weaknesses Raised by Reviewer jsKc (1/2)"
                    },
                    "comment": {
                        "value": "Based on the reviews, we notice that the main contribution of our paper was not fully appreciated, since the review mostly focuses on the failure patterns we reported.\n\nWe want to emphasize that the main contribution is **SAGE, the first automated method to systematically and effectively find failure modes in any TDM.** SAGE comprises three non-trivial types of attacks in the latent space, token space, and human-understandable language space. Achieving these three attacks is challenging, due to the discrete nature of human language space and its intricate patterns, as well as the gradient vanishing problem in the latent space, making the optimization non-differentiable directly. **As appreciated by all other three reviewers, this problem we introduced is novel, meaningful, and important in the research of TDMs. And the proposed method, i.e SAGE,  is effective (6z3X), intelligent (6EFD), and practical (6EFD).** The systematic analysis of the failure modes is considered as our second contribution.\n\n&emsp;\n\n> W1: \"Multi-object relation is a well-known problem, especially in novel scenarios\"\n\nFirstly, **we propose the first algorithm that systematically finds these prompts. Knowing these problems exist is different from finding these prompts automatically. And the latter is even more important** as it enables us to understand the performance of current methods in existing challenging scenarios. If they still fail, our method will further help us to know when, why, and how such failures occur. It helps us find solutions to circumvent these failures in real world applications, and develop better models in the future. For example, Imagen shows that using LLM can significantly improve this mult-object problem, and they show many better examples, but our experiments in Tab 3 show that multi-object is still a problem for LLM-based models. Then, with a comprehensive analysis as we did in the Appendices B.2, we can further understand more about these failures and how we may improve them. **Therefore, we believe that automatically and systemically detecting these errors, no matter for a newly developed method or a widely used product, is very important and helpful.**\n\n**Secondly, multi-object relation is just one of the ten typical failures of incomprehensible language prompts we reported in Fig 4.** As we discussed in Sec 5.1 and Sec B2 (a) , the failure of \u201ccat fighting a fish\u201d **is not due to multiple objects, but due to the actions itself.** We also give an example \u201ca bird running back\u201d, which only has one object, but still fails due to the action. In fact, **at least 7 types of failures in Fig 4 (a,b,c,e,h,i,j) contain prompts that only involve one single object** (Please see Sec B2).\n\nFinally, we want to argue that **the ability to generate such unseen/novel scenarios is in fact one of the most important features of TDMs.** Many showcases on the official websites of Imagen and Parti involve uncommon prompts and multiple objects (e.g., \u201cA brain riding a rocket ship heading towards the moon\u201d, etc ). We think **any scenarios that can be easily imagined by humans should be able to be generated by a TDM.** In addition, many prompts we reported can be found in real world. For example, \u201ca cat fighting a fish\u201d can be envisioned as your cat trying to catch a goldfish in your fish tank.\n\n&emsp;\n\n> W2: Failures in latent space seems contrived and are not really issues in day to day usage.\n\nFirstly, as we discuss in Sec 5.3and Tab 2, **the failure in latent space can be sampled in day-to-day usage, and is related to model stability** (i.e., the probability of unrelated images being generated under random sampling). The method we presented provides an efficient way to reveal these problems in advance. And it enables us to evaluate which object categories are not sufficiently well represented. For example in Table 2, for the 5 categories found by SAGE, **9.2% of the randomly generated images are irrelevant to the inputs**, which is clearly important information.\n\nIn addition, the existence of these latent variables indicates that the latent space is not well-structured, which is important and provides insights for further improvement of diffusion models. As shown in other papers [b,c], understanding the latent space is critical for downstream tasks.  Our method provides new insights into the latent space, and opens a new solution to study it.\n\nFinally, we want to mention again that the types of failures discovered in latent space are just a small part of our second contribution. The main contribution is SAGE, the first automated method to systematically find failure modes of any TDMs. The second contribution is the failure modes we discovered, which includes all ten types of failures in prompt space and most of them are unexplored previously. Failure in latent space is just one small part of our second contribution.\n\n[b] Blattmann et al. \"Align your latents: ...\" CVPR 2023.\n\n[c] Xia et al. \"Gan inversion: A survey.\" TPAMI 2022"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1931/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700500584669,
                "cdate": 1700500584669,
                "tmdate": 1700500584669,
                "mdate": 1700500584669,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PyR4tkKdyh",
                "forum": "TOWdQQgMJY",
                "replyto": "hqizcwAyhY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author's Response to Weaknesses Raised by Reviewer jsKc (2/2)"
                    },
                    "comment": {
                        "value": "> W3: The arguments are very hand-waving.\n>> W3.1: \"No calculation has been shown/referred to neither in the main body nor the appendix on the probability. In addition, the paper demonstrated only QQ-plot and statistic of three prompts. It's unclear whether it's a generalized phenomenon.\"\n\nRegarding the **calculation of the probability**, what we want to emphasize is that since the failure samples exist as a connected region (e.g. $[a,b]$), then **the sample rate is not zero and is theoretically computable through the probability density function:**\n$$\\text{Pr}[a\\leq X \\leq b] = \\int_a^bf_X(x)dx$$\nIt implies that these failure cases are meaningful. However, computing the exact probability is impossible since it is an extremely high-dimension problem and the exact range of each dimension is hard to determine. We will revise this sentence into :\"*These failure examples can be generated with non-zero probability under Gaussian sampling according to the probability density function.*\u201d \n\n&emsp;\n\nRegarding whether it is a **generalized phenomenon. It is indeed a generalized phenomenon.** For **ALL** results, we compute their statistics to evaluate if they are outliers from $\\mathcal{N}(0,I)$, and report the overall **Non-Gaussian Rate** in Table 1.  **75% percent are not outliers, showing that it is actually a generalized phenomenon.**\n\n&emsp;\n\n>>W3.2: \"No details are provided on how the failure regions were calculated/estimated\"\n\nPoseExaminer provides an intuitive way to compute the final boundary in a high-dimension system under certain constraints, in which they gradually expand the upper and lower boundary of each dimension. We follow their method, and starting from the latent variable we find, we gradually expand the boundary until it becomes an outlier or no longer causes the model to fail. We add a detailed explanation in Appendices B.3 of the revision.\n\n&emsp;\n\n> W4: \"One side note but not the main concerns I have on this paper: the presentation lacks structure and appears to be very messy. The authors seem to be ambitious in delivering many things all at once but failed to fufill any of the promises.\"\n\nYes, we indeed try to thoroughly discuss all failures we find, delving into the underlying causes and potential solutions. Our manuscript underwent multiple revisions prior to submission. And we believe reviewers 5bJZ, 6z3X, and 6EFD agree that our paper is well-structured and easy to follow (as indicated in their comments and the Presentation score).  We would greatly appreciate any additional detailed suggestions to further refine this paper. Thank you very much!"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1931/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700501706182,
                "cdate": 1700501706182,
                "tmdate": 1700501789514,
                "mdate": 1700501789514,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "m75V7jkLIG",
                "forum": "TOWdQQgMJY",
                "replyto": "hqizcwAyhY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author's Response to Questions Raised by Reviewer jsKc"
                    },
                    "comment": {
                        "value": "We answer the questions raised by Reviewer jsKc below.\n\n&emsp;\n\n>Q1: \"Do models hidden behind APIs also suffer the same failure modes?\"\n\nYes. We have experimented with StableDiffusion-XL online, DALL-E, Firefly from Adobe, and Midjourney. They also suffer from many similar failures. For example, StableDiffusion-XL struggles with scenarios like \"cat tracking bear,\" while Midjourney faces difficulties with the concept of a \"beaded item.\"\n\n\nIn addition, we want to emphasize that our method is not intended to \u201cattack\u201d an already deployed system. **Instead, its purpose is to help researchers and developers to understand the important failure modes of the method they are working on,** helping develop better image diffusion models. Just like the role of a standard benchmark for discriminative tasks like classification or detection, understanding the failure modes of a machine learning system is generally important.\n\n&emsp;\n\n>Q2: \"Instead of using the proposed optimization method to failure mode, which is not of much significant value, why not use it to show the capability of steering/manipulation of the generated images?\"\n\nThis is a very good point. We think our method can be directly used to manipulate/generate more accurate and realistic images, by optimizing the diffusion in an opposite direction instead of making them fail. \n\nHowever, **as acknowledged by the other three reviewers, we still believe that understanding the failure modes of TDMs is a meaningful and important problem in the research of TDMs.** It provides insights into how to further improve current TDMs, and provides a benchmark to evaluate any future TDM, which could be a long-term and important benefit for the development of TDMs. However, we do agree that using our method to improve the generated image is an interesting idea, and we will explore it in the future. Thank you!\n\n>Q3: \"What happens if prompt engineering was applied, would it impact the way it fails?\"\n\nThis is a good question. It mainly depends on the type of failure modes. For example, prompt engineering can help alleviate the failure caused by certain actions, by giving a more detailed description of the action. For example: \u2018A photo of a cat fighting fish\u2019 generated wrong images in SD2.1, but \u2018A photo of a cat and a fish, the cat is trying to catch the fish\u2019 gives better results. However, finding these prompts can be very hard. \n\nIn addition, prompt engineering can not address many failures caused by the failure of the diffusion module itself, such as certain deformation of the object required by the prompt (see Appendices B.2). For these questions, a better and more robust diffusion model is needed."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1931/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700502281613,
                "cdate": 1700502281613,
                "tmdate": 1700502281613,
                "mdate": 1700502281613,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vRUQv79ltT",
                "forum": "TOWdQQgMJY",
                "replyto": "hqizcwAyhY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer jsKc,\n\nThanks again for your valuable feedback and suggestions. We are curious whether the feedback we provided has effectively addressed your concerns. Feel free to add new comments if you have any further questions. We are more than happy to continue discussions and will do our best to provide thorough responses.\n\nBest regards,\n\nPaper 1931 Authors"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1931/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659792049,
                "cdate": 1700659792049,
                "tmdate": 1700659792049,
                "mdate": 1700659792049,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CWZq1ick7b",
                "forum": "TOWdQQgMJY",
                "replyto": "m75V7jkLIG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1931/Reviewer_jsKc"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1931/Reviewer_jsKc"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the responses"
                    },
                    "comment": {
                        "value": "I have read the responses carefully and understand the motivation a bit more. Although I still can not fully appreciate the said contributions, I am willing to raise the rating to weak accept."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1931/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688561311,
                "cdate": 1700688561311,
                "tmdate": 1700688561311,
                "mdate": 1700688561311,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LZ2Pr8gPrI",
            "forum": "TOWdQQgMJY",
            "replyto": "TOWdQQgMJY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1931/Reviewer_6EFD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1931/Reviewer_6EFD"
            ],
            "content": {
                "summary": {
                    "value": "Text-guided diffusion models (TDMs) are prone to unexpected failures, such as generating incorrect images from natural-looking text prompts or producing inconsistent images from the same text with different latent variable samples. To address this, the study introduces SAGE, an adversarial search method that explores TDMs' prompt and latent spaces to identify failures, using image classifiers for guidance and human verification for accuracy. The investigation reveals four main failure modes, highlighting issues with semantic capture, latent space structure, prompt-latent misalignment, and the fragility of language representations, suggesting avenues for future improvement."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- Proposed a smart adversarial search algorithm to identify failures in TDMs, finding \u201creasonable\u201d tokens, texts, and latent codes to input into the TDMs, leading to failure generations.\n\n- Here, \u201creasonable\u201d latent code implies that we draw the code close to N(0,I), and the text should be human-readable. This proposed adversarial attack is not only fair to the TDMs but also practical for users.\n\n- The algorithm demonstrates an intelligent method (using residual connections) to avoid backpropagating through the entire extensive diffusion model, thereby enhancing computational efficiency.\n\n- The text is well-composed, accompanied by a self-explanatory figure delineating the overall pipeline.\n\n- The system is fully automated and reinforced by human evaluation."
                },
                "weaknesses": {
                    "value": "- Given that the pipeline heavily relies on the robust classifier, I'm curious if this means the SAGE system will primarily detect the blatantly poor cases, while struggling to identify the more subtle, not-so-good ones.\n\n- While SAGE employs an ensemble of classifiers, it still seems akin to a handful of neural classifiers trained on the same dataset. True, one might outperform another, but I'm inclined to think that these classifiers would exhibit similar decision boundaries."
                },
                "questions": {
                    "value": "1. Q1: \n- I'm somewhat puzzled by the SSR(A) in Table 1. It seems slightly biased in favor of the SAGE method, considering it's directly optimized based on this metric.\n\n2. Humans and automatic systems have different perceptions. \n\n- Q2.1: Would you attribute the reason SSR(H) isn't a full 100% to SAGE generating some false positives, or is it more about the perceptual differences among the observers?\n\n- Q2.2: As I mentioned earlier, my concern is that SAGE may only identify blatantly incorrect instances. From what you've observed, were there moments where you thought, \"That's clearly a failure, but SAGE didn't recognize it in the samples\"? If such instances occurred, could you provide some insights into why that might be?\n\nOverall this is an excellent work, I can\u2019t wait to try your demo."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "10: strong accept, should be highlighted at the conference"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1931/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698638000514,
            "cdate": 1698638000514,
            "tmdate": 1699636124019,
            "mdate": 1699636124019,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KmWXfGDsn5",
                "forum": "TOWdQQgMJY",
                "replyto": "LZ2Pr8gPrI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author's Response to Concerns Raised by Reviewer 6EFD"
                    },
                    "comment": {
                        "value": "Thank you so much! We are thrilled to hear that you enjoyed my work. It is truly encouraging.\n\n&emsp;\n\n>W1: \"If SAGE primarily detects the blatantly poor cases\"\n\nYes, it is correct. All the failures we detect are obvious failures, where the key object is not observed in the generated image. That\u2019s why in Table 1, human evaluation often reports more failures than automated evaluation. There are several failure cases that cannot be detected by automated evaluation, such as generating incorrect objects (e.g. a cat with two heads), incorrect actions, incorrect numbers, and incorrect features (e.g. \u2018 white cat\u2019 generating a yellow cat). These failures pose challenges for current algorithms, requiring better and more robust discriminative models\u2014many of which do not exist. In fact, the evaluation of generative models is still an open question, with current metrics like FID score and CLIP score proving limited and less accurate. It is worth noting that SAGE is general and the evaluator can be changed easily. We expect that future research will find even better discriminative models.\n\nIn addition, we believe this actually shows the effectiveness of our model. Despite focusing on these obvious failure cases, we still achieve a high search success rate.\n\n&emsp;\n\n>W2: \"These classifiers would exhibit similar decision boundaries.\"\n\nThat is another reason to add an edge-based classifier. While it has a relatively lower classification accuracy compared to a standard ViT, **it has a rather different decision boundary.** Standard ViTs often exhibit bias toward object textures over shapes [a], while the edge-based classifier focuses solely on object shapes. It greatly reduces the false positive rate and helps us find failures genuinely generated by the diffusion model. However, we agree that integrating more discriminative models with different decision boundaries would further improve our algorithm, and even enable us to find more subtle cases.\n\n[a] Geirhos et al. \"ImageNet-trained CNNs are biased towards texture...\" ICLR. 2018.\n\n&emsp;\n\n>Q1: \"SSR(A) seems slightly biased in favor of SAGE\"\n\nIn fact, both the baseline and SAGE use this metric as the optimization goal, so we think it is a fair comparison. We use it because it is the only robust metric we currently have that gives less false positives. As demonstrated in Figure 3 and the reported number on it, the ensemble of robust classifiers still gives a false positive rate of 67.5%, while our classifier achieves a significantly lower false positive rate of only 22.5%.\n\n&emsp;\n\n>Q2: \"Humans and automatic systems have different perceptions.\"\n>>Q2.1: \"The reason SSR(H) isn't a full 100%\"\n\nIn short, the diffusion model generates many ambiguous images with strong disturbance that fool the discriminative model, resulting in a 100% SSR(A). However, during the human evaluation, we categorize all ambiguous images as correct cases, which cause SSR(H) not a full 100%.\n\nSpecifically, despite our efforts to build a robust classifier system, the most robust discriminators remain vulnerable. When optimizing the latent variables, the diffusion model can generate challenging cases with strong disturbance for the discriminators. However, many of these challenging cases are ambiguous even for humans. In general, we set a very lenient threshold for human evaluators: Since the input prompt is \u2018A photo of a [class]\u2019, we consider any image with key features of the target objects as a correct case. For example, in Figure 3, we consider the left image as a cat while the right one is not. \n\n>>Q2.2: The reason why SAGE didn't recognize a failure observed by human:\n\nYes, we have indeed observed many of these cases. We summarize several of them here: \n\n1. A prompt typically contains several features beyond the object itself, such as colors, relations, actions, etc. However, we do not have a good discriminative model to detect all these features. Understanding all information from an image involves many open problems in computer vision. An example of this is in Figure 4 (b), what we want is a real cat near a sketch of a flower. However, the generative model often gives sketches of both cat and flower, and the discriminative mode can not tell the difference. The answer in W1 gives more examples. \n\n2. Current discriminative models usually detect whether there is any feature of the target object in the image. Therefore, some dominant features alone can be identified as the target object with a very high confidence score. This is completely different from human vision. As exemplified in Figure 4 (h), many generated images contain a human's hand/foot with cat skin, yet these images are still classified as a cat. Similar problems can also be found in Figure 5 (b) and (c), where a dalmatian and a warplane are detected.\n\n3. Current discriminative models do not assess the reasonableness of the object. A cat with two heads or a person with four legs will still be recognized by the discriminative model."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1931/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700504863894,
                "cdate": 1700504863894,
                "tmdate": 1700504863894,
                "mdate": 1700504863894,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xIkiuDhRXZ",
                "forum": "TOWdQQgMJY",
                "replyto": "LZ2Pr8gPrI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer 6EFD,\n\nThank you once again for your positive feedback and valuable suggestions! If you require any additional information or clarification from us, please don't hesitate to reach out.\n\nBest regards,\n\nPaper 1931 Authors"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1931/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659715195,
                "cdate": 1700659715195,
                "tmdate": 1700659715195,
                "mdate": 1700659715195,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "E70s6ltZq6",
            "forum": "TOWdQQgMJY",
            "replyto": "TOWdQQgMJY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1931/Reviewer_6z3X"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1931/Reviewer_6z3X"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents an automatic way of detecting failure text prompts in text-guided diffusion models (TDMs). A robust image classifier based surrogate loss is proposed to detect accurate failure cases due to diffusion models. In addition, to deal with vanishing gradient issue, the authors apply approximate gradients to back-propagate, via residual connection. Adversarial based approach helps to identify the natural text prompts (non-outlier) that cause the failure cases. The experimentation results show the model is efficient in finding the failure cases (SSR), and evaluated via human annotation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "I think the task the paper is presenting is novel and is important in the research of TDMs. The authors managed to present thorough experimentation and analysis on evaluating the proposed model performance. The presented samples do show the effectiveness of model in identifying the true failure cases from natural text prompts."
                },
                "weaknesses": {
                    "value": "1. Overall, while the paper is one of the first to target such a problem in finding actual failure in TDMs, the problem itself is rather similar to some of the previously well studied tasks, with adversarial-based approaches. The discriminator here is to identify and remove the irrelevant feature in the latent space, so that it becomes task oriented. Such an approach has been used in tasks such as fair classification. \n2. Though various evaluation being conducted, it is hard to measure the effectiveness of each proposed component in the model. To better connect the intuition of each contribution of the work and the actual analysis/effectiveness, it would be great to have some ablation study."
                },
                "questions": {
                    "value": "1. As many findings are presented in the paper, what would be some potential solution to handle these failure cases?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1931/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698805039951,
            "cdate": 1698805039951,
            "tmdate": 1699636123952,
            "mdate": 1699636123952,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oThBOSQ5te",
                "forum": "TOWdQQgMJY",
                "replyto": "E70s6ltZq6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author's Response to Concerns"
                    },
                    "comment": {
                        "value": "We thank Reviewer 6z3X for the review, and we address the concerns below.\n\n&emsp;\n\n> W1: \"While the paper is one of the first to target such a problem in finding actual failure in TDMs, the problem itself is rather similar to some of the previously well studied tasks.\"\n\nWhile the high-level concept is similar to other tasks, like adversarial machine learning in image classification, we believe it does not diminish the novelty or contribution of our paper. As the reviewer already appreciated, we define and study a novel, important, and meaningful task in the context of text-guided diffusion models (TDMs), namely discovering the failure modes in TDMs automatically and systematically. We provide an effective and comprehensive solution to solve this task, and reveal several previously unexplored but important failure modes that exist across all widely used TDMs.  Moreover, finding these failure modes in TDMs automatically is very challenging, leading previous researchers to rely on manual sampling: \n\n1. The human language space is discrete, making it hard to optimize. It also follows intricate patterns, which requires complex constraints to ensure that the generated prompt remains natural and comprehensible for humans. To solve this problem, we use LLM as the language prior, and propose a gradient-guided optimization to efficiently search over the discrete language space.\n\n2. Unlike GANs or classification models, diffusion models are significantly more complex, often involving hundreds of sampling steps during inference.  This complexity makes it impossible to directly back-propagate the gradient from the output to the latent space. To solve this problem, we add residual connection in the diffusion step and use the approximate gradients for efficient optimization.\n\n3. We do not have a reliable metric for image generation or a robust discriminator to detect failures. Currently, classifiers are sensitive to noise and biased towards texture. A simple ensemble of classifiers gives us a high rate of false positives (i.e., most failures are due to the classifier errors instead of the TDMs). To solve this problem, we train an edge-based classifier that has different decision boundaries. \n\nIn the experiment section, we demonstrate the effectiveness of all these methodological components through various ablation studies (Please also see the answer for W2)\n\n\nIn conclusion, as you already appreciated, the task we introduce is novel and important, and is very challenging. Our proposed method is also novel, non-trivial, and effective, despite sharing a very high-level concept with other adversarial-based approaches.\n\n&emsp;\n\n> W2: \"It would be great to have some ablation study.\"\n\nYes, we agree that the ablation study is important. **We provide several ablation studies in the original paper**. However, due to space constraints, **most of the ablations are included in the appendices**. We list all ablations in the paper and the appendices as follows:\n\n1. The baseline in Table 1, under the section \u201cHuman-understandable text prompt space\u201d, uses greedy search with LLaMA instead of the proposed gradient-guided search with LLaMA. The observed improvement shows *the effectiveness of gradient-guided optimization.* \n2. The baseline in Table 1, under the section \u201cLatent space\u201d, uses a modified projected gradient descent instead of the proposed searching policy in latent space. We apply several engineering optimizations to fit the entire system with a standard PGD in an A100. The improvement shows *the effectiveness of using approximate gradients with residual connection.*\n3. Figure 3 and the reported search success rate on the figure compare the results with and without edge ViT, showing *the importance of the edge-based classifier.*\n4. Table 5 and Figure 10 compare the generated image with and without residual connection, showing that the residual connection does not affect the generated image. Table 6 compares the search success rate when adding residual connections to different denoising steps. These two ablation experiments *demonstrate that residual connection enables efficient searching of failure cases in the latent space without affecting the image generation.*\n5. Table 7 compares *the different choices of large language models*. \n6. Table 8 compares *the use of prompt template* (i.e., \u201cA photo of a\u201d )\n\nWe have tried our best to provide elaborate ablation studies. We would greatly appreciate more specific suggestions regarding additional ablations that could enhance our analysis."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1931/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700498465922,
                "cdate": 1700498465922,
                "tmdate": 1700498465922,
                "mdate": 1700498465922,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GLkXYaYImi",
                "forum": "TOWdQQgMJY",
                "replyto": "E70s6ltZq6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author's Response to Questions"
                    },
                    "comment": {
                        "value": "We address the question raised by Reviewer 6z3X below.\n\n&emsp;\n\n> Q: \"What would be some potential solution to handle these failure cases?\"\n\nWe discuss in detail the **underlying causes and several potential solutions of each failure mode in Appendices B.2.** For example, in the first failure reported in Figure 4 (i.e., failure due to specific actions), we have identified three potential causes: (1) the incorrect pairing of specific verbs with nouns (e.g., \u201ca cat fighting fish\u201d consistently interpreted as a type of fish in SDV2.1, but not in SDV1.5), (2) the bias of certain objects with actions (e.g., \u201ca bird running back\u201d usually results in an image of a man running, but with feathers on his arms), and (3) the deformation of objects related to the actions (e.g., \u201ca cat chasing dogs\u201d usually gives an image of an unidentifiable object chasing a dog ). \n\nConsidering the underlying causes, we think that problem 1 can be alleviated by better prompt engineering. Additionally, using LLM instead of CLIP, or adopting a better training strategy for CLIP to disentangle object-level information with attributes, may alleviate both problem 1 and 2. \n\nHowever, we want to emphasize that finding a good solution is difficult. As shown in Table 3, although LLM helps alleviate some problems, it doesn't completely solve them; rather, it merely reduces the failure rate.\n\nPlease take a look at Appendices B2 for more discussions."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1931/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700498753096,
                "cdate": 1700498753096,
                "tmdate": 1700498753096,
                "mdate": 1700498753096,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "y9DYv6DR26",
                "forum": "TOWdQQgMJY",
                "replyto": "E70s6ltZq6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer 6z3X,\n\nThanks again for your valuable feedback and suggestions. We are curious whether the feedback we provided has effectively addressed your concerns. Feel free to add new comments if you have any further questions. We are more than happy to continue discussions and will do our best to provide thorough responses.\n\nBest regards,\n\nPaper 1931 Authors"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1931/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659497285,
                "cdate": 1700659497285,
                "tmdate": 1700659497285,
                "mdate": 1700659497285,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ywG14no6iN",
            "forum": "TOWdQQgMJY",
            "replyto": "TOWdQQgMJY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1931/Reviewer_5bJZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1931/Reviewer_5bJZ"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed a method called SAGE to search natural and human-understandable texts that text-guided diffusion models (TDMs) cannot generate images correctly for the first time. This method explores the discrete prompt space and the high-dimensional latent space to discover undesirable behaviors automatically. This method utilizes algorithms of adversarial attack and image classifiers as surrogate loss functions. To generate natural prompts, the authors use large language models (LLMs) like LLaMA to search for suitable prompts. The authors conduct experiments on several metrics to demonstrate the effectiveness. The authors also conclude 4 different failure types of TDMs by analyzing the results of failure examples."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.\tThe topic is meaningful for researchers to understand the failures of diffusion models. Natural prompts are closer to real-world scenarios and are more beneficial for improving the robustness of TDMs.\n\n2.\tThis work further analyzes the deeper causes and possible solutions through the structure of TDMs and the corresponding language features. These discussions appear to be both comprehensive and effective.\n\n3.\tThe paper is well-structured and easy to follow. The procedure is demonstrated well in Figure 2 and its description. The author provided detailed descriptions of the method and experiments."
                },
                "weaknesses": {
                    "value": "1.\tThe authors do not demonstrate their method in pseudo-code. The code is not included in the supplement material either. Would the authors demonstrate their method in pseudo-code?\n\n2.\tTime cost is not shown in the paper.\nIt seems time-consuming to run a LLaMA and an ensemble of classifiers simultaneously in the attack. How much GPU memory and how long does it take to find an example?\n\n3.\tThe detail of human evaluation is missing. \nThe paper doesn't demonstrate differences in the ratings of different human evaluators. How does the author handle rating differences and assess the accuracy of human evaluators?\n\n4.\tThe metric needs to be clarified.\nCould the authors further explain why the Non-Gaussian Rate (NGR) is reported? What is the purpose of this metric in the experiments?"
                },
                "questions": {
                    "value": "1.\tHow much GPU memory and how long does it take to find an example?\n\n2.\tCould the authors further explain why the Non-Gaussian Rate (NGR) is reported? What is the purpose of this metric in the experiments?\n\n3.\tHow does the author handle rating differences and assess the accuracy of human evaluators? Could the authors further explain the human evaluation process?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1931/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698828627523,
            "cdate": 1698828627523,
            "tmdate": 1699636123876,
            "mdate": 1699636123876,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "a3ZPp2MYwB",
                "forum": "TOWdQQgMJY",
                "replyto": "ywG14no6iN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author's Response to Concerns Raised by Reviewer 5bJZ"
                    },
                    "comment": {
                        "value": "We thank Reviewer 5bJZ for the review, and we address the concerns below.\n\n&emsp;\n\n>W1: Pseudo-code\n\nThank you for the valuable suggestion. We will provide the pseudo-code in Appendices A.2 of the revision. We plan to submit the revision on Monday, Nov 20. Additionally, the code will be released upon the publication of this paper.\n\n&emsp;\n\n>W2 (Q1): Time and memory cost \n\nFor finding natural prompts, it takes an average of 51.26 minutes on one A100 GPU. LLaMA itself requires about 24GB of memory, the SD V2.1 we test requires around 10GB. The ensemble of classifiers takes about 12 GB, and the entire system requires approximately 46 GB of memory.\n\n&emsp;\n\n> W3 (Q3): \"The detail of human evaluation is missing\"\n\nWe mentioned the human evaluation details in Appendices B.1. In summary, 3 human evaluators are assigned to each image, and the final score for each image is the average of their ratings. During the rebuttal period, we computed the variance of the score obtained for each image. We report the results in the following table. Notably, the ratings exhibit good consistency for the majority of the images. We will also include this table in the revision.\n\n| Variance        | <=0.222 | 0.222-1 | >=1  |\n|-----------------|--------------|--------------|-----------|\n| Proportion     | 76.2%   | 23.4%   | 0.4% |\n\n&emsp;\n\n> W4 (Q2): \"why the Non-Gaussian Rate (NGR) is reported?\"\n\nWe report the Non-Gaussian Rate as it measures the validity of failure cases in latent space. Typically diffusion models assume the latent variable follows an $\\mathcal{N}(0,I)$ distribution. Therefore, we want the failure samples to follow this distribution, i.e. to have a high likelihood under the  $\\mathcal{N}(0,I)$ distribution, which indicates that these samples are not outliers."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1931/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700503541957,
                "cdate": 1700503541957,
                "tmdate": 1700503541957,
                "mdate": 1700503541957,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "W3qnuCo5vy",
                "forum": "TOWdQQgMJY",
                "replyto": "ywG14no6iN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1931/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer 5bJZ,\n\nThanks again for your valuable feedback and suggestions. We are curious whether the feedback we provided has effectively addressed your concerns. Feel free to add new comments if you have any further questions. We are more than happy to continue discussions and will do our best to provide thorough responses.\n\nBest regards,\n\nPaper 1931 Authors"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1931/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659388344,
                "cdate": 1700659388344,
                "tmdate": 1700659388344,
                "mdate": 1700659388344,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xv2AFly42J",
                "forum": "TOWdQQgMJY",
                "replyto": "a3ZPp2MYwB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1931/Reviewer_5bJZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1931/Reviewer_5bJZ"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response. My questions have been addressed."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1931/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700741144686,
                "cdate": 1700741144686,
                "tmdate": 1700741144686,
                "mdate": 1700741144686,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]