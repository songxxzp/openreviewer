[
    {
        "title": "Defining Expertise: Applications to Treatment Effect Estimation"
    },
    {
        "review": {
            "id": "KTvvbnQggZ",
            "forum": "1YPfmglNRU",
            "replyto": "1YPfmglNRU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6457/Reviewer_uYNJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6457/Reviewer_uYNJ"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the role of expertise in treatment effect estimation. They formalize predictive (actions dependent on treatment effect) and prognostic expertise (actions dependent on potential outcomes) and argue that knowledge of the type of expertise provides a useful inductive bias for selection of a treatment effect estimation method. They further show that the type of expertise present in a dataset can be estimated observationally with a plug-in method, suggesting a meta-algorithm whereby the type of expertise is estimated and the more appropriate method chosen. Experiments are conducted with sweeps over the amount of each type of expertise in the data. The results have implications particularly for the appropriateness of methods that learn balancing representations, as these are shown to worse than other methods in cases with predictive expertise (as the balancing removes information about the treatment effect from the representation) and better than other methods in cases with prognostic expertise (as the shifts present are unrelated to the treatment effect)."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* This work offers a novel perspective and analytic framework for reasoning about expertise in treatment effect estimation problems. I found it particularly insightful in the context of reasoning about the causes of covariate shift and overlap violations across treatment strata and the implications for estimation. \n* The paper is well-written and clear, with high-quality visualizations.\n* The experiments are well-designed and convincing in supporting the theoretical claims with empirical evidence."
                },
                "weaknesses": {
                    "value": "The paper takes a somewhat narrow lens with respect to the breadth of relevant prior work considered. It largely focuses on a particular lineage of treatment effect estimation methods that use neural networks for representation learning, balancing, and fitting potential outcome models. The work would be stronger if it could be contextualized better in the full landscape of work on causal inference for treatment effect estimation across fields, including statistics, epidemiology, and econometrics. \n\nIt would be particularly prudent to try to understand how this work fits into the broader landscape of approaches that aim to learn doubly-robust estimators that only require one of either the treatment or outcome models correctly and do not require any notion of balancing beyond overlap. For example, see the Augmented Inverse Propensity Weighted Estimator (e.g., Glynn and Quinn 2010) and Targeted Maximum Likelihood Estimation (Schuler and Rose 2017)\n\nReferences\n* Glynn, Adam N., and Kevin M. Quinn. \"An introduction to the augmented inverse propensity weighted estimator.\" Political analysis 18.1 (2010): 36-56.\n* Schuler, Megan S., and Sherri Rose. \"Targeted maximum likelihood estimation for causal inference in observational studies.\" American journal of epidemiology 185.1 (2017): 65-73."
                },
                "questions": {
                    "value": "* As a suggestion, it would interesting to understand the relationship between the issues identified with balancing representations for treatment effect estimation in the presence of predictive expertise with the consistency issues identified with balanced representations for domain adaptation (see Johansson 2019 https://proceedings.mlr.press/v89/johansson19a.html).\n* Please elaborate on the relationship the expertise measures and mutual information and the motivation for defining new measures given the relationship between them.\n* I don\u2019t follow the argument in section 3.1 regarding the relationship between the two types of expertise. It seems odd to say that predictive expertise implies prognostic expertise, because a policy with predictive expertise (dependent only on the treatment effect) would be insensitive to a constant shift in the potential outcomes while a policy with prognostic expertise would be sensitive to it."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6457/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6457/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6457/Reviewer_uYNJ"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6457/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698690185631,
            "cdate": 1698690185631,
            "tmdate": 1699636722183,
            "mdate": 1699636722183,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "89C7EdxzD3",
                "forum": "1YPfmglNRU",
                "replyto": "KTvvbnQggZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6457/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6457/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer uYNJ (Part 1/2)"
                    },
                    "comment": {
                        "value": "Dear Reviewer uYNJ, thank you for your thoughtful comments and suggestions! Below, we aim to address all the individual points raised in your review and hope that this alleviates any remaining concerns \u2014 please also see the revised paper for changes (highlighted in blue).\n\n---\n\n**(W1) Specific focus on balancing representations**\n\nWe chose to focus on this specific strand of literature because it has emerged as *the predominant way* of tackling confounding biases in the heterogeneous treatment effect estimation problem in machine learning over the last years \u2014 balancing representations have appeared in a majority of the publications on heterogeneous treatment effect estimation in machine learning conferences (e.g. Johansson et al., ICML 2016; Shalit et al., ICML 2017; Yao et al., NeurIPS 2018; Hassanpour & Greiner, ICLR 2020; Du et al., 2021; Assaad et al., AISTATS 2021; Huan et al., 20222), and also been extended to other settings, such as survival data (e.g. Chapfuwa et al., CHIL 2021; Curth et al., NeurIPS 2021) and time-series data (e.g. Bica et al., ICLR 2020; Melnychuk et al., ICML 2022; Seedat et al., ICML 2022). Given the widespread use of this technique in the machine learning literature, we believe a focus on balancing representations to be warranted for the audience targeted by this venue.\n\n---\n\n**(W2) Relationship to doubly robust estimators**\n\nOur work is largely orthogonal to the work on doubly robust estimators from the (bio)statistics and econometrics literature. In particular, the majority of approaches considered in this literature, and in particular also those cited in the review, target the *average treatment effect*, while we study conditional average treatment effects (CATE, i.e. personalized effects, instead of population-average effects). We focus on estimators based on neural networks because these have been the focus of study in the machine learning literature on CATE estimation since the seminal papers by Shalit, Johansson, and Sontag on the topic in 2016/2017.\n\nNonetheless, some doubly robust approaches have recently been adapted to the CATE estimation setting, for instance giving rise to DR-learner in Kennedy EH, \u201cTowards optimal doubly robust estimation of heterogeneous causal effects,\u201d *arXiv preprint arXiv:2004.14497*, 2020. The approaches considered in our paper could be used therein as plug-ins for the outcomes, where improved outcome estimation by making use of expertise would likely improve estimation of CATEs by the DR-learner downstream \u2014 for instance, Curth & van der Schaar (2021a,b) showed experimentally that using neural networks with better architectures to estimate the outcome portion of the DR-learner improves the performance of the DR-learner as a whole."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6457/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700140249076,
                "cdate": 1700140249076,
                "tmdate": 1700140249076,
                "mdate": 1700140249076,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "X0RHI9RNan",
                "forum": "1YPfmglNRU",
                "replyto": "KTvvbnQggZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6457/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6457/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer uYNJ (Part 2/2)"
                    },
                    "comment": {
                        "value": "---\n\n**(Q1) Consistency issues with balanced representations for domain adaptation**\n\nThank you for highlighting this interesting connection. The issues arising with balancing representations for treatment effect estimation in the presence of predictive expertise are indeed due to *information loss* in the representation as analyzed theoretically in Johansson et al. (2019).\n\n**Changes:** We have now added a footnote in Section 4.1 to highlight that their results could be adapted from their domain adaptation context to our treatment effect estimation context to provide generalization bounds for this setting.\n\n---\n\n**(Q2) Relationship between expertise and mutual information**\n\nOur definitions of expertise are exactly equal to the mutual information between actions and outcomes. For predictive expertise, $E^{\\pi}\\_{\\textit{pred}}=I(A^{\\pi};Y\\_1-Y\\_0)/\\mathbb{H}[A^{\\pi}]$, and for prognostic expertise, $E^{\\pi}\\_{\\textit{prog}}=I(A^{\\pi};Y\\_0,Y\\_1)/\\mathbb{H}[A^{\\pi}]$. We chose to express expertise in terms of conditional entropies rather than in terms of mutual information because we believe that the former type of expression makes it easier to understand why these definitions are intuitive and why they capture mathematically what we might describe as \u201cexpertise\u201d in language.\n\n**Changes:** We now highlight that our definitions can equivalently be expressed in terms of mutual information in a brand-new appendix (Appendix A).\n\n---\n\n**(Q3) Why does predictive expertise imply prognostic expertise?**\n\nPredictive expertise implies prognostic expertise because $Y_1-Y_0$ is a deterministic function of $(Y_0,Y_1)$. If a policy depends on the treatment effect $Y_1-Y_0$ and hence has predictive expertise, we can also say that the same policy depends on the pair $(Y_0,Y_1)$ and hence has prognostic expertise. We can not say the converse \u2014 for instance, a policy that only depends on $Y_0$ would have high prognostic expertise, but since it does not depend on $Y_1-Y_0$ directly, it would generally have low predictive expertise.\n\nFormally, the fact that $Y_1-Y_0$ is a deterministic function of $(Y_0,Y_1)$ means that it is generally less informative than $(Y_0,Y_1)$ and at most as informative as $(Y_0,Y_1)$ \u2014 knowing the two potential outcomes $Y_0,Y_1$, we can easily compute the treatment effect $Y_1-Y_0$, but not the other way around. We have $\\mathbb{H}[Y_1-Y_0|Y_0,Y_1]=0$ therefore  $H[A^{\\pi}|Y_1-Y_0]\\geq H[A^{\\pi}|Y_0,Y_1]$ and therefore $E^{\\pi}\\_{\\textit{pred}}\\leq E^{\\pi}\\_{\\textit{prog}}$. Since predictive expertise is a lower bound for prognostic expertise, having predictive expertise would also imply having prognostic expertise.\n\nThe example of a constant shift in the potential outcomes is not particularly helpful in understanding this relationship. In the case of a policy that depends only on the treatment effect, the treatment assignments would not be affected by such a constant shift. As long as the treatment assignments remain the same, neither predictive expertise nor prognostic expertise would be sensitive to the constant shift \u2014 that is the policy would still have the same predictive expertise and prognostic expertise under any constant shift. This is a desirable property of expertise: Expertise should capture how differences in outcomes from one subject to another impact treatment assignments for those subjects *independent* of the unit/scaling and the zero-point/mean of outcomes.\n\n**Changes:** We have now stated the fact that predictive expertise is a lower bound for prognostic expertise (hence having predictive expertise implies having prognostic expertise) as Proposition 3 with an accompanying proof (see new Appendix B)."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6457/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700140273628,
                "cdate": 1700140273628,
                "tmdate": 1700140345227,
                "mdate": 1700140345227,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YDawqQUbZW",
                "forum": "1YPfmglNRU",
                "replyto": "X0RHI9RNan",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6457/Reviewer_uYNJ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6457/Reviewer_uYNJ"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response and the revisions. I will keep my overall score the same (8).\n\nAnd thank you for the explanation regarding why predictive expertise implies prognostic expertise. The bound framing is helpful."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6457/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700512731344,
                "cdate": 1700512731344,
                "tmdate": 1700512731344,
                "mdate": 1700512731344,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Q1CvJ0enp4",
            "forum": "1YPfmglNRU",
            "replyto": "1YPfmglNRU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6457/Reviewer_obyv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6457/Reviewer_obyv"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces the idea that selection bias due to expertise might be informative in designing and selecting methods for the conditional treatment effect (CATE) estimation.\n\nThey differentiate between two types of expertises, which are formally defined using the concept of entropy for actions induced by a certain policy. On the one hand, they define *prognostic expertise* where actions are based on all potential outcomes. It is given as one minus the relation of the entropy conditional on the potential outcomes and the total entropy. On the other hand, *predictive expertise* refers to the case where actions are based on the treatment effects, and is defined analogously as one minus the relation of the entropy conditional on the treatment effect and the total entropy. Note that these definition bound the expertise between zero and one with zero being no expertise and one being perfect expertise.\n\nThey draw connections from expertise to the validity of the overlap assumptions. In particular, the higher the expertise of a policy, the lower is the overlap.\n\nThey perform multiple experiments using semi-synthetic data and give intuitive explanations for the different performance of state-of-the-art CATE estimation methods.\n\nBased on the theoretical definition of expertise, they propose an estimator for the predictive and prognostic expertise and a pipeline, called \"expertise-informed\" to that automatically chooses a suitable CATE estimator based on the dominant expertise type."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper seems to be novel in introducing the idea that a specific type of selection bias, namely allocation done by experts, is informative.\n\n2. The paper is very well-written. It provides a great intuition why the idea of formally introducing expertise is fundamental and how it is related to other quantities of interest such as optimality or overlap assumption.\n\n3. The proofs are very detailed and easy to follow."
                },
                "weaknesses": {
                    "value": "*Definition of Expertise*\n\n1. The relationship between in-context action variability and the overlap assumption is just intuitively explained. A formal proof for this relationship is missing.\n\n2. In Figure 1 the axis tick values are missing. (The ticks are also confusing as for $C^{\\pi}=0$, the expertise is somewhere between ticks.)\n\n*Application*\n\n3. The authors explain in great detail why some CATE estimator perform intuitively better under some type of expertise than others. A formal proof for this intuition is however missing.\n\n*Estimating Expertise*\n\n4. It is unclear in the proposed pipeline whether the expertise is estimated on same samples used for training or on some hold-out set and what the consequences of this choice have on the outcomes."
                },
                "questions": {
                    "value": "*Definition of Expertise*\n\n1. The entropy is defined with log to base 2. Do you decide on this because the actions are binary, i.e. $A\\in$ { 0,1}?\n\n2. Could you formally prove that $C^{\\pi} =0$ implies the violation of the overlap assumption?\n\n3. The comment (i) after Proposition 2 is unclear to me. Could you provide an example for that?\n\n*Application*\n\n4. Is it possible to give more formal arguments how the discussed CATE estimators (TARNet, IPW, CFRNet, DragonNet) are related to the entropy definition of expertise?\n\n5. Are the results sensitive to the choice of network based CATE estimators in the analysis?\n\n*Estimating Expertise*\n\n6. Could you please provide a more detailed description of your pipeline process, in particular whether the same samples are used for estimating expertise and treatment effect? Do you anticipate pre-testing problems in this case?\n\n7. How sensitive are the outcomes of the pipeline to the threshold 1\\2?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6457/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6457/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6457/Reviewer_obyv"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6457/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698834562405,
            "cdate": 1698834562405,
            "tmdate": 1699636722030,
            "mdate": 1699636722030,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "iCGFi6j1xK",
                "forum": "1YPfmglNRU",
                "replyto": "Q1CvJ0enp4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6457/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6457/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer obyv (Part 1/2)"
                    },
                    "comment": {
                        "value": "Dear Reviewer obyv, thank you for your thoughtful comments and suggestions! Below, we aim to address all the individual points raised in your review and hope that this alleviates any remaining concerns \u2014 please also see the revised paper for changes (highlighted in blue).\n\n---\n\n**(Q1)** *The entropy is defined with log to base 2. Do you decide on this because the actions are binary, i.e. $A^{\\pi}\\in\\{0,1\\}$?*\n\nYes, indeed the entropy is defined with $\\log_2$ because the actions are binary. This is a fairly arbitrary decision. When $\\log_2$ is used, the variability of a uniformly random policy happens to be one.\n\n---\n\n**(Q2)** *Could you formally prove that $C^{\\pi}=0$ implies the violation of the overlap assumption?*\n\n**(W1)** *The relationship between in-context action variability and the overlap assumption is just intuitively explained. A formal proof for this relationship is missing.*\n\nYes, it is possible to formally prove this relationship. Thank you for the suggestion. \n\n**Changes:** We have now stated the fact that having zero in-context action variability implies that the overlap assumption is violated as Proposition 4 with an accompanying proof (see new Appendix B).\n\n---\n\n**(Q3)** *The comment (i) after Proposition 2 is unclear to me. Could you provide an example for that?*\n\nAn example can be found in the paragraph titled \u201cHow does expertise differ from optimality?\u201d in Section 3.1. There, we considered $\\mathbb{E}[Y^{\\pi}]$ to be our success measure. While $\\pi_{\\textit{risk}}$ was suboptimal with respect to this success measure, it happened to be a perfect predictive expert. This is because $\\pi_{\\textit{risk}}$ was aiming to achieve a different objective: making risk-averse decisions.\n\n---\n\n**(W2)** *In Figure 1 the axis tick values are missing. (The ticks are also confusing as for $C^{\\pi}=0$, the expertise is somewhere between ticks.)*\n\n**Changes:** We have now added tick labels to Figure 1. However, the point of Figure 1 is more conceptual than quantitative, the important information is the relative positions of the three regions (smaller/larger expertise, smaller/larger in-context action variability).\n\n---\n\n**(Q4)** *Is it possible to give more formal arguments how the discussed CATE estimators (TARNet, IPW, CFRNet, DragonNet) are related to the entropy definition of expertise?*\n\n**(W3)** *The authors explain in great detail why some CATE estimator perform intuitively better under some type of expertise than others. A formal proof for this intuition is however missing.*\n\nWe believe that a theoretical analysis of existing CATE estimators is out of the scope of this initial paper on defining expertise, which not only provides and motivates a formal definition of expertise for the first time, but also theoretically analyzes its relationship to the CATE estimation problem (Propositions 1, 2, and now 3, 4), empirically explores its relationship to the existing CATE estimators, and even highlights model selection as one of its practical use cases.\n\n---\n\n**(Q5)** *Are the results sensitive to the choice of network based CATE estimators in the analysis?*\n\nWe have used the same network architecture for all CATE estimators. This means that any similarities and differences that are observed between the estimators should be the result of how the estimators are trained rather than the capacity/complexity of the network architecture they use."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6457/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700139975662,
                "cdate": 1700139975662,
                "tmdate": 1700139975662,
                "mdate": 1700139975662,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cIszkTGZ6v",
                "forum": "1YPfmglNRU",
                "replyto": "Q1CvJ0enp4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6457/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6457/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reponse to Reviewer obyv (Part 2/2)"
                    },
                    "comment": {
                        "value": "---\n\n**(Q6)** *Could you please provide a more detailed description of your pipeline process, in particular whether the same samples are used for estimating expertise and treatment effect? Do you anticipate pre-testing problems in this case?*\n\n**(W4)** *It is unclear in the proposed pipeline whether the expertise is estimated on same samples used for training or on some hold-out set and what the consequences of this choice have on the outcomes.*\n\nWhen practically implementing *Expertise-informed*, given a training dataset, we always train two models: *Action-predictive* and *Balancing* using the same training dataset. We then use the trained *Action-predictive* model to estimate predictive and prognostic expertise, and use those estimates to select which model to use during test time on a held-out testing dataset. This means that *Expertise-informed* never sees the testing dataset until training, selecting, and committing to a particular model for testing. Here, the fact that the same training dataset is used both for model training and model selection should have minimal impact on results because model selection relies on estimating expertise for the entire training dataset while model performance is measured with respect to the accuracy of estimating treatment effects for individual data points. It would have been a different story if model selection also relied on performance in estimating treatment effects (the same task we want our models to achieve).\n\n---\n\n**(Q7)** *How sensitive are the outcomes of the pipeline to the threshold 1\\2?*\n\nVarying the threshold used in *Expertise-informed* would shift its performance between that of *Balancing* and *Action-predictive*. As the threshold approaches 0, we expect the performance of *Expertise-informed* to converge to that of *Balancing* (as all datasets would be classified as prognostic), and as the threshold approaches 1, we expect its performance to converge to that of *Action-predictive* (as all datasets would be classified as predictive). An important point to consider is that the performance of *Expertise-informed* would never drop below the minimum performance between *Balancing* and *Action-predictive* as it always selects one of these methods or the other."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6457/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700140036726,
                "cdate": 1700140036726,
                "tmdate": 1700140058498,
                "mdate": 1700140058498,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Hte5yUCO9D",
                "forum": "1YPfmglNRU",
                "replyto": "cIszkTGZ6v",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6457/Reviewer_obyv"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6457/Reviewer_obyv"
                ],
                "content": {
                    "title": {
                        "value": "Re: Reponse to Reviewer obyv"
                    },
                    "comment": {
                        "value": "Dear authors, thank you for your detailed answers and adding the additional proofs (in particular Proposition 4) in the appendix. They are very insightful and addressed my questions. I'll keep my rating (8: accept, good paper)."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6457/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700558762506,
                "cdate": 1700558762506,
                "tmdate": 1700558762506,
                "mdate": 1700558762506,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BtlwK9OVPi",
            "forum": "1YPfmglNRU",
            "replyto": "1YPfmglNRU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6457/Reviewer_ScD8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6457/Reviewer_ScD8"
            ],
            "content": {
                "summary": {
                    "value": "THis paper extends methods for estimating causal treatment from observational data in the presence of expert actions, e.g. the treatment decisions of a clinician.  There is value in the information available from the expert's actions;  What can we learn about the effectiveness of treatment from their actions as domain experts? As mentioned in the  paper \"These methods become susceptible to confounding... and treatments (are assigned) based on factors that infuend the outcomes...\" This is related to \"confounding by indication\" [ Salas, M., Hotman, A., Stricker, B.H.: Confounding by indication: an example of variation in the use of epidemiologic terminology. American journal of epidemiology 149(11), 981\u2013983 (1999)]. Confounding occurs because the expert's action conditions both the treatment applied and the outcome\n\nThe paper makes a distinction between \"predictive\" expertise (knowledge of likely outcome,  specifically of Y_1 - Y_0, as occurs in healthcare) and \"prognostic\" expertise. (knowledge of potential outcomes, Y_1, Y_0 as occurs in education) Prognostic expertise implies predictive, since Y_1 - Y_0 can be determined by knowlege of Y_1 and Y_0. \n\nFor this to work one must take into account \"overlap\" - the variability due to the decision-maker's imperfect knowledge; equivalently the possibility of perfect expertise.  The paper makes the point that one needs the additional distinction between \"predictive\" and \"prognostic.\""
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper shows that it is possible to take expertise into account and exploit the value of a decision-maker's inductive bias. It concludes that the type of expertise affects the performance of methods for estimating treatment effect (because such methods rely on the difference Y_1 - Y_0,?) , and that the difference in type of expertise may be evident as a way to distinguish datasets."
                },
                "weaknesses": {
                    "value": "The prognostic - predictive distinction on which the paper depends is so subtle that it is hard to see how it is of any consequence.  This may be just a lack of clarity and familiarity with the current economic literature on causality, but it seems to rely on a strong claim that characteristically clinical treatment decisions would be ignorant of outcomes, but only of the _difference_ in outcomes, a claim whose reasons are obscure.  Both types of expertise are defined in terms of expectations of actions conditioned on outcomes as in Equations (2) and (3) -- definitions that leave this question of the distinction open. \n\nSuch formulation of expertise  as '.. to what extent the actions of a decision-maker are informed by what a subject\u2019s potential outcomes\" seem to contradict the basic notion that experts \"assign treatments based on factors that influence the outcomes.\" What influences what?  In simple terms, the decision-maker's action depends on their state of information -- the features known to them at the time they make their decision. One presumes that thinking of actions influenced by subsequent outcomes is a convention in the economics literature on causality.  This may be necessary for the methods of analysis but it is far from intuitive. \n\nIn summary, the significance of the paper relies on a questionable distinction."
                },
                "questions": {
                    "value": "In this conference venue why not draw upon the ML literature on causality (e.g. Pearl's work) and its use of structural equation models? I presume this touches on a long standing discussion that encompasses much more than just the claims of the paper, but such a comparison would open the field to a larger audience, and possibly, by recourse to additional domain knowledge elucidate why it is so that \"Cases where more information can be gained through expertise (i.e. cases with high expertise) happen to align with cases where treatment effect estimation is particularly hard.\" (But other methods may be able to identify the causal effect.)"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6457/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699229858096,
            "cdate": 1699229858096,
            "tmdate": 1699636721908,
            "mdate": 1699636721908,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5gaBNmXakS",
                "forum": "1YPfmglNRU",
                "replyto": "BtlwK9OVPi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6457/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6457/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ScD8"
                    },
                    "comment": {
                        "value": "Dear Reviewer ScD8, thank you for your thoughtful comments and suggestions! Below, we aim to address all the individual points raised in your review and hope that this alleviates any remaining concerns \u2014 please also see the revised paper for changes (highlighted in blue).\n\n---\n\n**(W1) Prognostic-predictive distinction**\n\nWe would like to emphasize that the distinction between prognostic and predictive variables is made within the medical and biostatistics literature (e.g. Ballman, 2015; Sechidis et al., 2018) outside of our work. We simply extend the same distinction to policies \u2014 that is to say, we differentiate between policies that depend on prognostic variables and policies that depend on predictive variables).\n\nPolicies that have predominantly predictive expertise \u2014 meaning policies that largely depend on the difference between the two potential outcomes (but not on the potential outcomes individually) \u2014 can arise naturally when the goal of a decision-maker is to maximize outcomes. For instance, consider the policy that always selects the action that would lead to the best estimated outcome: $\\pi(x)=1$ if $\\mathbb{E}[Y_1|X=x]>\\mathbb{E}[Y_0|X=x]$ and $\\pi(x)=0$ otherwise \u2014 it has maximal predictive expertise. Since achieving better outcomes for patients is often the primary goal of clinicians when treatment decisions (e.g. Graham et al., 2007; Caye et al., 2019), such policies can be more prevalent (compared with policies with predominantly prognostic expertise but no predictive expertise) in the healthcare domain.\n\n---\n\n**(W2) Relationship between features, actions, and outcomes**\n\nIn our framework, features cause actions, and actions (together with features) cause outcomes. Features $X$ have a distribution $\\alpha$ independent of any policy, actions $A^{\\pi}$ are determined on the basis on features only such that $A^{\\pi}\\sim\\pi(X)$, and outcomes are a joint consequence of both: $Y=\\rho_{A^{\\pi}}(X)$.\n\nWhen we say \u201cto what extent the actions of a decision-maker are informed by what a subject\u2019s potential outcomes **could be**,\u201d our intention is not to imply that a decision-maker\u2019s actions are caused/influenced by potential outcomes, which would be unknown at the time of decision-making. Of course, we agree that in any practical setting, a decision-maker\u2019s actions can only depend on the information that is available to them \u2014 in our formulation, this would be features $X$. Some of these features would cause/influence/determine the potential outcomes $Y_0,Y_1$ (let those features be $X_{\\textit{critical}}$) and some would not. According to our definition, an expert would mainly consider features $X_{\\textit{critical}}$ over $X\\setminus X_{\\textit{critical}}$, estimate what $Y_0,Y_1$ **could be** based on these features, and make a decision accordingly. With expertise, we aim to capture to what extent a decision-maker follows this process \u2014 meaning to what extent their actions are informed by estimated outcomes $\\hat{Y}\\_0,\\hat{Y}\\_1$ based on $X\\_{\\textit{critical}}$.\n\n**Changes:** Thank you for bringing the possibly confusing phrasing of our intuitive definition of expertise to our attention. We have now rephrased the sentence to make it clear that actions never directly depend on potential outcomes.\n\n---\n\n**(Q1) Why not use the graphical framework of Pearl?**\n\nWe refrained from using the graphical framework of Pearl because it is specifically not well-equipped to distinguish between prognostic and predictive variables. This is because DAGs are notoriously bad at representing effect modification (i.e. predictive variables) natively. There have been proposals to extend the graphical framework to better depict effect modifiers (Weinberg CR, \u201cCan DAGs clarify effect modification?\u201d *Epidemiology 18*, 2007), but to the best of our knowledge, no solution has been well established in the literature to this data.\n\n**Changes:** Thank you for bringing Pearl\u2019s framework to our attention as an alternative formulation. We have now included this discussion in a brand-new appendix (Appendix A)."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6457/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700139706828,
                "cdate": 1700139706828,
                "tmdate": 1700140082481,
                "mdate": 1700140082481,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qkO3uhkiBK",
            "forum": "1YPfmglNRU",
            "replyto": "1YPfmglNRU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6457/Reviewer_7Wu5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6457/Reviewer_7Wu5"
            ],
            "content": {
                "summary": {
                    "value": "The paper discusses the notion that expert decision-makers can implicitly use their domain knowledge when choosing actions, like prescribing treatments. These actions, in turn, can reveal insights about the domain. For example, frequently prescribed treatments might be more effective. However, current machine learning methods may fail to capitalize on the concept of \"expertise\" as a guiding factor. Specifically, in the context of estimating treatment effects, the prevailing assumption is simply that treatments overlap without considering expert behavior. The paper proposes that recognizing two types of expertise: (1) predictive and (2) prognostic, possessed by decision-makers may enhance the methodology and selection of models for estimating treatment effects. The authors show that understanding the predominant expertise in a domain may significantly impact the performance of these models and that it is possible to identify the type of expertise in a dataset to inform model choice."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper presents the following advantages: \n\nFirstly, it effectively communicates its proposed concepts through relatable examples, such as those from the medical and teaching fields, introducing and distinguishing between predictive and prognostic expertise. \n\nSecondly, it addresses an intriguing problem that may often be overlooked in causal inference: the incorporation of domain knowledge. By shedding light on this issue, the paper emphasizes the importance of considering expert behavior in the analysis, which could lead to more accurate and informed causal inferences."
                },
                "weaknesses": {
                    "value": "Please see more details in the Questions section."
                },
                "questions": {
                    "value": "1. The paper proposed two novel concepts to define the expert knowledge: (1) Prognostic expertise: $\\mathbb{E}^{\\pi}_{prog} = 1 - \\mathbb{H}[A^{\\pi}|Y_0, Y_1] / \\mathbb{H}[A^_{\\pi}]$. (2) Predictive expertise: $\\mathbb{E}^{\\pi}_{pred} = 1 - \\mathbb{H}[A^{\\pi}|Y_1 - Y_0] / \\mathbb{H}[A^_{\\pi}]$. The rationale for selecting entropy over other statistical measures, such as the variance of actions, is not immediately clear. Can you elucidate the benefits of employing entropy in this context? What are the specific advantages of entropy in capturing the nuances of expert decision-making, and under what conditions does it outperform simpler measures like variance?\n\n2. The consideration of domain expert knowledge in personalized decision-making problems is crucial but challenging, especially given that such expertise may not always be accurate or easily discernible in real data sets. How might one effectively balance the integration of domain knowledge with data-driven insights to mitigate the risk of relying on potentially inaccurate expertise? Is there a methodology within your framework that utilizes data-driven approaches to validate and calibrate the contributions of domain expertise, particularly through the lens of prognostic and predictive expertise measures?\n\n3. In the context of clinical trials, where treatment assignments are typically randomized and propensity scores are uniformly distributed. Then, the application of expert knowledge is less straightforward. Considering such scenarios, how do the proposed prognostic and predictive expertise metrics maintain their utility? Can these metrics still provide meaningful information for personalized treatment recommendations when the baseline assumption of expert influence on treatment assignment is removed? How might these metrics be adapted or interpreted in a randomized trial environment to enhance personalized medicine approaches?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6457/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6457/Reviewer_7Wu5",
                        "ICLR.cc/2024/Conference/Submission6457/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6457/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699334024481,
            "cdate": 1699334024481,
            "tmdate": 1700802436156,
            "mdate": 1700802436156,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tj3g5Ef4WO",
                "forum": "1YPfmglNRU",
                "replyto": "qkO3uhkiBK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6457/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6457/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 7Wu5"
                    },
                    "comment": {
                        "value": "Dear Reviewer 7Wu5, thank you for your thoughtful comments and suggestions! Below, we aim to address all the individual points raised in your review and hope that this alleviates any remaining concerns \u2014 please also see the revised paper for changes (highlighted in blue).\n\n---\n\n**(Q1) Why entropy over statistical measures?**\n\nAlthough variance, similar to entropy, could also be indicative of how \u201crandom\u201d a random variable is, the two quantities measure fundamentally different things: Variance quantifies the amount of spread around a mean while entropy quantifies uncertainty. When defining expertise, our aim is to capture the uncertainty of outcomes when the actions of a decision-maker are known vs. not known to an outside observer (the bigger the difference between the two cases, we say the larger the expertise is). Hence, a more direct measure of uncertainty is naturally more suitable to our aim and use case.\n\nOn a more technical level, attempting to define expertise through variance has two immediate shortcomings:\n\n1. First, variance is not well defined for categorical variables, such as binary actions in our work, unless we assign numerical values to each category. Even if we were to assign such numeric values (for instance, $A^{\\pi}=0$ for the negative treatment and $A^{\\pi}=1$ for the positive treatment), the resulting variance would be sensitive to our assignments (for instance, the variance of $A^{\\pi}$ would have increased if we were to represent the negative treatment as $A^{\\pi}=-1$ instead of $A^{\\pi}=0$, which should not be a meaningful change as far as expertise is concerned).\n\n2. Variance depends on the scale of variables whereas entropy does not. For instance, the variance of $2Y$ would be double the variance of $Y$, while their entropies would be the same: $\\mathbb{H}[Y]=\\mathbb{H}[2Y]$. Such sensitivity to scale is undesirable when defining expertise \u2014 the fact that outcomes are recorded twice as large in a dataset (maybe due to a change of units) should have no effect on expertise.\n\n**Changes:** Thank you for bringing statistical measures to our attention as an alternative to entropy. We have now included this discussion in a brand-new appendix (Appendix A).\n\n---\n\n**(Q2) Data-driven approaches to discerning domain expertise**\n\nOur experiments reveal that different methods are more or less suitable to settings with different types of domain expertise. We strongly agree that this makes it extremely important to accurately discern the type of expertise present in a domain or dataset when selecting between different methods. While machine learning traditionally relies on domain knowledge in making such decisions, our framework enables a more data-driven and quantitative approach: We propose the pipeline \u201cexpertise-informed\u201d in Section 4.2 precisely to demonstrate one such approach.\n\nNotice that *Expertise-informed* first identifies the prominent type of expertise present in a dataset by estimating the measures of prognostic and predictive expertise (and considering their ratio). Then, it takes advantage of this identification by selecting the most appropriate algorithm for estimating treatment effects: *Action-predictive* for datasets with predominantly predictive expertise vs. *Balancing* for datasets with predominantly prognostic expertise.\n\n---\n\n**(Q3) Randomized controlled trials**\n\nYou are correct that, in a randomized controlled trial, when the propensity scores are uniform across treatments, there would be no expertise \u2014 and appropriately, both the predictive and the prognostic expertise would be equal to zero for datasets collected through a randomized controlled trial (this can be inferred from Proposition 1, as we mention in the paragraph above Proposition 1, a uniform policy would have $C=1$ hence $E_{\\textit{pred}}=0$ and $E_{\\textit{prog}}=0$). Consequently, expertise as an inductive bias would of course be less helpful in estimating treatment effects using such datasets, however in that case, the datasets would already be ideal for treatment effect estimation with no confounding bias (the best case scenario in Figure 1). This is why we mainly focused on the high expertise, low overlap setting (the amber region in Figure 1).\n\nWhile taking advantage of expertise would not be possible for datasets collected through a randomized controlled trial, estimating expertise (as in Section 4.2) can still act as a data-driven way to determine whether the data we have is effectively randomized or not: The closer both $E_{\\textit{pred}}$ and $E_{\\textit{prog}}$ are to $0$, the closer the data would be to trial data, in which case we might prefer conventional supervised learning methods over algorithms specialized for treatment effect estimation.\n\n**Changes:** We have now included this discussion in a brand-new appendix (Appendix A)."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6457/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700139479753,
                "cdate": 1700139479753,
                "tmdate": 1700139479753,
                "mdate": 1700139479753,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]