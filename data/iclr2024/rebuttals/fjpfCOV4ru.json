[
    {
        "title": "Ito Diffusion Approximation of Universal Ito Chains for Sampling, Optimization and Boosting"
    },
    {
        "review": {
            "id": "T8BuBBZAWM",
            "forum": "fjpfCOV4ru",
            "replyto": "fjpfCOV4ru",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8195/Reviewer_4gNA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8195/Reviewer_4gNA"
            ],
            "content": {
                "summary": {
                    "value": "This work considers a rather general and broad class of Markov chains,\nIto chains that look like Euler-Maryama discretization of some Stochastic\nDifferential Equation. However, I am not fully convinced of the importance of this work."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "This paper studies a rather general and broad class of Markov chains and studies the convergence rates."
                },
                "weaknesses": {
                    "value": "1. The theoretical results do not provide any new insight to the community.\n2. The analysis is based on standard techniques.\n3. The paper lacks a empirical study to verify the theoretical findings."
                },
                "questions": {
                    "value": "None"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8195/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8195/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8195/Reviewer_4gNA"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8195/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698568529317,
            "cdate": 1698568529317,
            "tmdate": 1699637016525,
            "mdate": 1699637016525,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "G6pbpk6d5w",
                "forum": "fjpfCOV4ru",
                "replyto": "T8BuBBZAWM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8195/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8195/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for review. Let us address the concerns that you raised:\n\n>The theoretical results do not provide any new insight to the community.\n\nPrior to our knowledge, our work is the first one to establish the following insights:\n1. **Convergence in Wasserstein-2 of SGD diffusion** under the weak assumption that $\\mathcal{W}_2$-CLT holds, which in particular, satisfied if the noise satisfies $\\mathbb{E}\\|\\epsilon_k\\|^4 \\le \\mathrm{const}$, which in prior works appeared only in (Li et al., 2019) [38] (last row in Table 2), however in that work convergence was proved in the weak sense and assumed dissipativity of the drift, which is a restriction, that does not allow to apply to such to problems as a stochastic approximation or saddle-point optimization.\n2. **We are the first** to establish **non-asymptotic convergence for the Stochastic Gradient Langevin Boosting** algorithm, developed in [53]. All prior results around SGLD do not apply to that case, as they all assume the normality of the noise, which is not satisfied in that case. In the original work, authors were able to obtain only asymptotic first-order weak convergence results based on the almost a century-old work of Kushner J., \"On the Weak Convergence of Interpolated Markov Chains to a Diffusion.\"\n\n>The analysis is based on standard techniques.\n1. **All prior works on the convergence of Markov Chains to Diffusions assume at least distant dissipativity** of the drift (that drift points to the origin outside of a ball), which simplifies their analysis, and **most of the works assume normality of the noise** or close to normal distribution, **or establish convergence in a weaker than Wasserstein-2 sense**. **Techniques developed in our work**, namely **window coupling (see Eq. 4) and coupling via noise (see Eq. 3)**, **are novel and non-standard**. They both aim to **circumvent the lack of such assumptions on which the prior works were based. **\n2. Regarding standard results like the Girsanov theorem, it does not apply to our non-Markov process, which appears in our analysis due to our novel coupling approaches that procured a non-Markov process for which the Novikov condition fails. Thus, in Theorem 1, we showed how such a non-markovian process can be reduced to the standard via a non-standard chain of arguments developed in Section B.3., based on Lemma 10.  **Again, this is not only a non-standard technique but provides novel fundamental insights about the Girsanov theorem.**\n3. As for the SGD diffusion case, our Lemma 4 and techniques used to prove it are crucial for establishing Wasserstein-2 convergence of the SGD diffusion, which is another novel development of our work, which is game-changing results for showing SGD diffusion bounds for Wasserstein-2, without which the final bound of Theorem 2, would've been trivial and no convergence established. Which is, **again, new insight and new technique.**\n\n>The paper lacks a empirical study to verify the theoretical findings.\n\nOur work is purely theoretical and establishes explicit convergence bounds for many algorithms known for practicians to exhibit diffusion-like behavior, like SGLB, SGD, and any stochastic optimization. We merely unified them under one analysis done at the weakest possible assumptions. Such unification produced novel, previously unknown/sharper bounds of their convergence in Wasserstein-2 for algorithms like SGD and SGLB. \n\nWe are confused about what type of empirical study the Reviewer wants to see, as the Wasserstein-2 distance is non-constructive by its definition (see Section A), while it is of undoubtful importance for the field."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700317679591,
                "cdate": 1700317679591,
                "tmdate": 1700318399781,
                "mdate": 1700318399781,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "U71fEFMw6l",
            "forum": "fjpfCOV4ru",
            "replyto": "fjpfCOV4ru",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8195/Reviewer_RRnG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8195/Reviewer_RRnG"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies a broad class of Markov chains called Ito chains, which allows for almost arbitrary isotropic and state-dependent noise instead of normal and state-independent one. The paper analyzes the coupling between Ito chains and its anagolous SDEs, and provides an upper bound for $\\mathcal{W}_2$ distance between laws of the two. Their results cover many of the known estimates. In particular, some techniques such as Window Coupling and an augmented version of Girsanov's Theorem are of independent interest."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Originality: The originality is high. The authors study a quite general class of Markov chains and analyze the upper bound between SDE, which is also a popular research area.\nClarity: the clarity is good. The paper sequentially introduces several auxiliary SDEs/Markov chains to eventually bridge the gap between the processes of interest: $X_k$ and $Z_t$. The motivation of each proposed auxiliary processes are clearly stated and is easy to follow for readers.\nSignificance: The theoretical contribution is quite good for this area. The authors consider non-Gaussian and state-dependent chains which is not so deeply investigated in literature. The window coupling and \"modified\" Girsanov theorem may be of independent interest."
                },
                "weaknesses": {
                    "value": "There are some mistakes and typos in proofs:\n - In Appendix, the equations in the middle of page.18 (the one after (10)), a noise matrix $\\sigma(Y_{\\bar{\\eta}k}^S)$ before $\\zeta_k^S(X_{Sk})$ is missing. The same issue appears in most of the later equations in this proof.\n - In the same equation, the last two terms have a wrong scaling w.r.t. $S$. Specifically, they should be $4\\mathbb{E}\\left[\\left\\|\\frac{1}{\\sqrt{S}}\\sum_{i=1}^{S-1} \\sigma(X_{Sk}) (\\epsilon_{Sk+i} - \\frac{1}{\\sqrt{S}}\\zeta_k^S(X_{Sk})) \\right\\|^2\\right]$ and $4\\mathbb{E}\\left[\\left\\| \n\\sum_{i=0}^{S-1}(\\sigma(X_{Sk}) - \\sigma(Y_{\\bar{\\eta}k}^X)) \\zeta_k^S(X_{Sk}) \\right\\|^2\\right]$. Consequently, some following terms should be multiplied by $S^2$ or so. (It seems not to affect the final upper bound, though. It is better to still check the whole roadmap of proofs.)\n - I wonder how the last term in the top equation on page.19 is derived ($4M_0\\|X_{Sk}-Y_{\\bar{\\eta}k}^X\\|^2$). It seems merely using Assumption 1 (4) is not enough. Or maybe there should be some additional assumptions?"
                },
                "questions": {
                    "value": "The window coupling seems to be among the crucial parts in this paper. Could authors explain if this is first proposed by this paper, or already appears in literature? It is best to provide some references.\n\nThe paper gives better bounds for SGD with Gaussian/non-Gaussian cases [1]. Could authors compare the theoretical techniques used in two papers and explain where do such improvements probably come from?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8195/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8195/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8195/Reviewer_RRnG"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8195/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698569040540,
            "cdate": 1698569040540,
            "tmdate": 1699637016358,
            "mdate": 1699637016358,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "naenaf9WvU",
                "forum": "fjpfCOV4ru",
                "replyto": "U71fEFMw6l",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8195/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8195/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are grateful to the Review for the positive review and fair concerns. Let us answer the weaknesses first.\n> In Appendix, the equations in the middle of page.18 (the one after (10)), a noise matrix .. is missing. ...\n\n\n>In the same equation, the last two terms have a wrong scaling w.r.t. $S$...\n\nThank you for noticing that typos! As you mentioned, it does not affect the final bound as we are reducing noise to a form passed into the $\\mathcal{W}_2$-CLT assumption. **We fixed both typos in the updated revision** by keeping $\\zeta^{S}_k$ outside of summation, which also improved clarity.\n\n>I wonder how the last term in the top equation on page.19 is derived. It seems merely using Assumption 1 (4) is not enough. Or maybe there should be some additional assumptions?\n\nAssumption 1 (4) and (5) are enough! Seems like during pre-submission revisioning we lost a chain of arguments, where we show how it follows. **We updated the revision** with the missing argument. The argument is following: \nFirst we note the following algebraic identities:\n\n $\\mathbb{E}\\langle \\sigma(x) (\\epsilon_{k}(x) - \\epsilon_{k}(x')), \\sigma(x) (\\epsilon_{k}(x) + \\epsilon_{k}(x'))\\rangle = \\mathbb{E}\\langle \\sigma(x') (\\epsilon_{k}(x) - \\epsilon_{k}(x')), \\sigma(x') (\\epsilon_{k}(x) + \\epsilon_{k}(x'))\\rangle = 0$\n\n$\\mathbb{E} \\big\\| (\\sigma(x) + \\sigma(x'))(\\epsilon_{k}(x) - \\epsilon_{k}(x'))\\|^2 \\ge \\mathbb{E} \\big\\| (\\sigma(x) - \\sigma(x'))(\\epsilon_{k}(x) - \\epsilon_{k}(x'))\\|^2$\n\nThey hold due to assumptions of $\\mathbb{E}\\epsilon_k = 0$, $\\mathbb{E} \\epsilon_k \\epsilon_k^T = I_{d}$ and $\\sigma = \\sigma^T \\ge 0$. Then it follows:\n$$M_{0}^2 \\|x-x'\\|^2 \\ge \\mathbb{E}\\|\\sigma(x) \\epsilon_{k}(x) - \\sigma(x') \\epsilon_{k}(x')\\|^2 $$\n  $$  =   \\frac{1}{4} \\mathbb{E}\\Big\\| \\big(\\sigma(x) + \\sigma(x'))(\\epsilon_{k}(x) - \\epsilon_{k}(x')) + \\big(\\sigma(x) - \\sigma(x'))(\\epsilon_{k}(x) + \\epsilon_{k}(x'))\\Big\\|^2$$\n   $$ =   \\frac{1}{4} \\mathbb{E}\\Big\\| \\big(\\sigma(x) + \\sigma(x'))(\\epsilon_{k}(x) - \\epsilon_{k}(x'))\\Big\\|^2 + \\frac{1}{4}\\mathbb{E}\\|\\big(\\sigma(x) - \\sigma(x'))(\\epsilon_{k}(x) + \\epsilon_{k}(x'))\\Big\\|^2 $$\n    $$ + \\frac{1}{2}\\mathbb{E}\\Big\\langle \\big(\\sigma^2(x)\n    - \\sigma^2(x')\\big) (\\epsilon_{k}(x) - \\epsilon_{k}(x')), \\epsilon_{k}(x) - \\epsilon_{k}(x')\\Big\\rangle $$\n   $$ =  \\frac{1}{4} \\mathbb{E}\\Big\\| \\big(\\sigma(x) + \\sigma(x')\\big)(\\epsilon_{k}(x) - \\epsilon_{k}(x'))\\Big\\|^2 + \\frac{1}{4}\\mathbb{E}\\|\\big(\\sigma(x) - \\sigma(x'))(\\epsilon_{k}(x) + \\epsilon_{k}(x'))\\Big\\|^2 $$\n    $$ + \\frac{1}{2}\\mathbb{E}\\Big\\langle \\sigma(x) (\\epsilon_{k}(x) - \\epsilon_{k}(x')), \\sigma(x)(\\epsilon_{k}(x) - \\epsilon_{k}(x')\\Big\\rangle $$\n    $$ - \\frac{1}{2}\\mathbb{E}\\Big\\langle \\sigma(x') (\\epsilon_{k}(x) - \\epsilon_{k}(x')), \\sigma(x)(\\epsilon_{k}(x) - \\epsilon_{k}(x')\\Big\\rangle$$\n   $$ =  \\frac{1}{4} \\mathbb{E}\\Big\\| \\big(\\sigma(x) + \\sigma(x')\\big)(\\epsilon_{k}(x) - \\epsilon_{k}(x'))\\Big\\|^2 + \\frac{1}{4}\\mathbb{E}\\|\\big(\\sigma(x) - \\sigma(x'))(\\epsilon_{k}(x) + \\epsilon_{k}(x'))\\Big\\|^2 $$\n  $$  \\ge  \\frac{1}{4} \\mathbb{E}\\Big\\| \\big(\\sigma(x) - \\sigma(x')\\big)(\\epsilon_{k}(x) - \\epsilon_{k}(x'))\\Big\\|^2 + \\frac{1}{4}\\mathbb{E}\\|\\big(\\sigma(x) - \\sigma(x'))(\\epsilon_{k}(x) + \\epsilon_{k}(x'))\\Big\\|^2 $$\n  $$  \\ge  \\frac{1}{2} \\mathbb{E} \\big\\|(\\sigma(x) - \\sigma(x'))\\epsilon_{k}(x)\\big\\|^2 + \\frac{1}{2} \\mathbb{E} \\big\\|(\\sigma(x) - \\sigma(x'))\\epsilon_{k}(x')\\big\\|^2 $$\n    $$\\ge \\|\\sigma(x) - \\sigma(x')\\|_{F}^2$$\n\nAnd on questions:\n> The paper gives better bounds for SGD with Gaussian/non-Gaussian cases [1]. Could authors compare the theoretical techniques used in two papers and explain where do such improvements probably come from?\n\nIf we understood correctly, by [1], you mean Alfonsi A. et al., \"Optimal transport bounds between the time-marginals of a multidimensional diffusion and its Euler scheme.\". \nTo answer this, we can refer to Remark 3.2 in [1], where the authors point out that the bound can be improved if uniform ellipticity is assumed (which we explicitly stated in Table 2 and our Assumption 1). We also note that the work [1] considered a general SDE case and might not cover the SGD case. As for the SGD case, we compare it against [15] and note that the work [15] considers the Wasserstein-1 distance. We believe that improvement in our bound comes mainly from using entropic bounds instead of the Lyapunov-type of analysis, which became possible due to Lemma 4.\n\n>The window coupling seems to be among the crucial parts in this paper. Could authors explain if this is first proposed by this paper, or already appears in literature? It is best to provide some references.\n\nBest to our knowledge, we have not seen it in any prior works, however, some intuitive kind of arguments similar to that are common in prior literature (e.g., Latz J., \"Analysis of stochastic gradient descent in continuous time\"). As for the term $L(X_{Sk} - Y_k)$, since all prior works assumed dissipativity/convexity, it was not needed for them."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700329814114,
                "cdate": 1700329814114,
                "tmdate": 1700329909836,
                "mdate": 1700329909836,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KKIhDAoE0J",
            "forum": "fjpfCOV4ru",
            "replyto": "fjpfCOV4ru",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8195/Reviewer_i2Nt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8195/Reviewer_i2Nt"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers a general class of Markov chains called Ito chains that cover a wide range of applications including sampling, optimization, and boosting. The paper provides bounds for the approximation error in W_2 distance between such Ito chains and the corresponding stochastic differential equation (which can then be used to study the Markov chain). In several applications, the bounds improve upon previous results or are completely new."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The results in this paper provide novel and general bounds on the approximation error for Ito chains using the corresponding stochastic differential equation. The results cover a broad range of applications in sampling, optimization, and boosting (for example, SGLD, SGD, and Stochastic Gradient Boosting) and are novel in several such applications (for example, the results cover almost arbitrary isotropic and state-dependent noise). The proof involves several new ideas and the presentation is quite clear."
                },
                "weaknesses": {
                    "value": "It would be nice if the author(s) could comment on whether Assumption 1 in Section 2 is typically satisfied/easy to verify in applications."
                },
                "questions": {
                    "value": "It would be nice if the author(s) could comment on whether Assumption 1 in Section 2 is typically satisfied/easy to verify in applications."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8195/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8195/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8195/Reviewer_i2Nt"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8195/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698815134238,
            "cdate": 1698815134238,
            "tmdate": 1699637016225,
            "mdate": 1699637016225,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ySo3TnpKqs",
                "forum": "fjpfCOV4ru",
                "replyto": "KKIhDAoE0J",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8195/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8195/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are grateful for your positive review and high score! \n\nLet us answer your question/weakness.\n\n>It would be nice if the author(s) could comment on whether Assumption 1 in Section 2 is typically satisfied/easy to verify in applications.\n\nWhen formulating assumptions, we attempted to cover as much generality as possible to cover/generalize the majority of prior works.\n\nAs for checking them, it is helpful to simplify some of them first (with maybe loss of generality), for example:\n1. $\\mathcal{W}_{2}$-CLT will be satisfied if $\\mathbb{E} \\epsilon_k^4 \\le \\mathrm{const}$\n2. For uniform ellipticity, if we are working with SGD with dissipative/convex loss (e.g., regularized by $L_{2}$ norm), then it is possible to show that iterations remain in a ball, which, even if the covariance is not bounded by default, can be considered as bounded without loss of generality, which is a standard trick in SGD literature.\n3. Assumption like $\\mathbb{E} \\| \\sigma(x) \\epsilon_k(x) - \\sigma(x') \\epsilon_k(x')\\|^2 \\le M_{0}^2 \\|x-x'\\|^2$ will be satisfied if both $\\sigma(x), \\epsilon_k(x)$ are Lipshitz-continuous, which in the case of SGD/SGLD is satisfied automatically if the loss (which gradient we are taking as drift $b(x)$ are Lipshitz smooth)\n4. Assumptions on bias/covariance shifts in such cases as smoothed SGDL or SGD will be satisfied automatically if the loss function (which gradient we are taking as drift $b(x)$) is Lipshitz-smooth, which is quite a standard assumption.\n5. Generally, checking the assumptions will require proving they are held on a case-by-case basis. However, in most cases, there is something like Lipshitz-smoothness of the loss / Lipshitz continuity of the drift, which makes them hold by default."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700330842377,
                "cdate": 1700330842377,
                "tmdate": 1700331084171,
                "mdate": 1700331084171,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3sS4dQ04Ac",
                "forum": "fjpfCOV4ru",
                "replyto": "ySo3TnpKqs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8195/Reviewer_i2Nt"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8195/Reviewer_i2Nt"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the detailed response and clarification!"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700686150309,
                "cdate": 1700686150309,
                "tmdate": 1700686150309,
                "mdate": 1700686150309,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]