[
    {
        "title": "Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space"
    },
    {
        "review": {
            "id": "FgHlqLDK1D",
            "forum": "4Ay23yeuz0",
            "replyto": "4Ay23yeuz0",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6938/Reviewer_dVGm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6938/Reviewer_dVGm"
            ],
            "content": {
                "summary": {
                    "value": "This paper present a new latent diffusion model/code for tabular data generation.\nTransposing to tabular data the recent ideas of (Rombach et al. CVPR 2022 and Karras et al. NeuIPS 2022), their model architecture is two-folds:\n- a transformer-based \\beta-VAE to embedd tabular data into a latent space\n- a score-based generator based on (Song et al. ICLR 2021)'s architecture\n\nAs a slight algorithmic contributions, the authors propose to use an \"adaptive VAE loss weighing\".\n\nIn the experiment section, the method is benchmarked against 6 state of the art tabular data generation models on 6 datasets. A few ablation tests are provided (one to justify the adaptive weighing).\nThis paper is only focused on unconditional generation, some experiments on missing-values imputation are also provided.\n\nIt is worth noting that both the code and a rich appendix are provided as supplementary material.\nThe code is clear and well commented.\nThe appendix provides a clear background on recent score-based generation best-practices and several supplementary experiments. Several implementation and methodology details allows the readers to retrieve what they needs to reproduce and understand this work."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "I suggest acceptance:\n\n- I really liked reading this paper. It is well written with several clear illustrations. \n- The contribution is mostly incremental but solid and well driven.\n- The provided code is clear and will be useful for the community (if it is published)\n- The supplementary material provides a detailed and clear background summary.\n- The experiment section could be improved but seems solid: the method seems efficient and fast when compared against other SOTA methods.\n- The model is tested with a single hyper-parameter configuration on all datasets"
                },
                "weaknesses": {
                    "value": "- The scientific contribution is mostly incremental and expected\n- The authors claim that no \"unified and comprehensive evaluation\" exists for tabular data synthesis. To my opinion, one weakness of this paper is indeed that it feeds this lack of a unified benchmark by proposing another new benchmark with new metrics that are not used in other papers. Sticking a bit more to previous paper's metrics and datasets could improve that point.\n- given the size of the appendix, one is surprised to see that no simple baselines like Bayesian Networks or SMOTE are provided in the experiments. SMOTE is known to be a competitive baseline for \"target-conditional\" data generation.\n- No privacy preservation metrics (like DCR) are provided. No detection test metric (like C2ST) is provided\n- The absence of hyper-parameters tuning in the benchmark is both laudable and questionable as it may hinder some of the other models (a fair option could be to report the total training time with a fixed budget)."
                },
                "questions": {
                    "value": "- Could you use the \"sdmetrics\" library to provide some privacy (like DCR) and detection (like C2ST) metrics in your benchmark ?\n- A few more datasets common with previous papers like (Kotelnikov et al. 2022, see Table 2) could improve the benchmark.\n- Could you add SMOTE (with unconditional sampling) as a baseline in your results ?\n- Are the confidence intervals on result tables computed through cross validation or only through multiple-sampling ?\n\n- Will you publish your code ?\n- Did you try your code on 2d synthetic sklearn examples ?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6938/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698680252028,
            "cdate": 1698680252028,
            "tmdate": 1699636809389,
            "mdate": 1699636809389,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KqAogzHyRl",
                "forum": "4Ay23yeuz0",
                "replyto": "FgHlqLDK1D",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dVGm (1/2)"
                    },
                    "comment": {
                        "value": "We appreciate the insightful feedback from the reviewer, which improves our evaluation setup.\n\n> Q1 & W4 Provide privacy metrics (e.g., DCR) and detection metrics (e.g., C2ST) in the benchmark.\n\nBased on the suggestion, we have included the DCR score as a metric for assessing privacy protection, as well as C2ST as a metric for detection. Below are the implementation details of these two metrics and our preliminary results.\n\n**For the DCR score**, it appears that the \u201csdmetrics\u201d library does not provide a corresponding implementation. Therefore, we developed this metric from scratch. Specifically, we followed the 'synthetic vs. holdout' setting as described in 'https://www.clearbox.ai/blog/2022-06-07-synthetic-data-for-privacy-preservation-part-2.' We initially divided the dataset into two equal parts: the first part served as the training set for training our generative model, while the second part was designated as the holdout set, which was not used for training. After the completion of model training, we sampled a synthetic set of the same size as the training set (and the holdout set). \n\nWe then calculated the DCR scores for each sample in the synthetic set with respect to both the training set and the holdout set. We can create histograms to visualize the distribution of DCR scores for the synthetic set in comparison to both the training and holdout sets. Intuitively, if there is a privacy issue (e.g., if the synthetic set is directly copied from the training set), then the DCR scores for the training set should be closer to 0 than those for the testing set. Conversely, if there is no privacy issue, the distribution of DCR scores for the training and holdout sets should largely overlap.  We plot these figures and have updated them in Figure 10, Appendix F.5 in the revised paper.\n\nAdditionally, we can calculate the probability that a synthetic sample is closer to the training set (rather than the holdout set). If this probability is close to 50% (i.e., 0.5), it indicates that the distribution of distances between synthetic and training instances is very similar (or at least not systematically smaller) than the distribution of distances between synthetic and holdout instances. This finding is a positive indicator in terms of privacy risk. The table below displays the results obtained by different models, **including SMOTE**, on this metric, on Default and Shoppers datasets:\n\n\n| Method        | Default            | Shoppers    |\n| --------      | -------            | -------     | \n| SMOTE         |  91.41%\u00b13.42       | 96.40%\u00b14.70 |\n| STaSy         |  50.23%\u00b10.09       | 51.53%\u00b10.16 |\n| Codi          |  51.82%\u00b10.26       | 51.06%\u00b10.18 |\n| TabDDPM       |  52.15%\u00b10.20       | 63.23%\u00b10.25 |\n| TabSyn (ours) |  51.20%\u00b10.18       | 52.90%\u00b10.22 |\n\n\n**For the C2ST score**, we employed the detection metric provided by sdmetrics: https://docs.sdv.dev/sdmetrics/metrics/metrics-in-beta/detection-single-table. This metric assesses how challenging it is to distinguish real data from synthetic data. We utilized the built-in logistic regression and SVC detectors for evaluation. In the table below, we present the results obtained using logistic regression as the detection method.\n\n| Method | Adult | Default | Shoppers | Magic  | Beijing | News |\n| --- | --- | --- | --- | --- | --- | --- |\n|SMOTE | 0.9710 | 0.9274 | 0.9086 | 0.9961 | 0.9888 |  0.9344|\n| CTGAN | 0.5949 | 0.4875 | 0.7488 | 0.6728 | 0.7531 | 0.6947 |\n| TVAE | 0.6315 | 0.6547 | 0.2962 | 0.7706 | 0.8659 | 0.4076 |\n| GOGGLE | 0.1114 | 0.5163 | 0.1418 | 0.9526 | 0.4779 | 0.0745 |\n| GReaT | 0.5376 | 0.4710 | 0.4285 | 0.4326 | 0.6893 | - |\n| STaSy | 0.4054 | 0.6814 | 0.5482 | 0.6939 | 0.7922 | 0.5287 |\n| CoDi | 0.2077 | 0.4595 | 0.2784 | 0.7206 | 0.7177 | 0.0201 |\n| TabDDPM | 0.9755 | 0.9712 | 0.8349 | **0.9998**| 0.9513 | 0.0002 |\n| TabSyn | **0.9986** | **0.9870** | **0.9740** | 0.9732 |**0.9603** | **0.9749** |\n\nAs indicated in the table, the Detection score exhibits superior discriminative power compared to other metrics such as single-column density estimation, pair-wise column shape estimation, and MLE. The detection score shows significant variations across different models for synthetic data generation. The proposed TabSyn consistently achieves notably high scores across all datasets. SMOTE directly interpolates within the training set, so it is not surprising that it achieves high scores in the detection metric.\n\nWe've updated these results in the revised paper in Appendix F.5 and AppendiX F.6. In the latest version of the code, we have added these two metrics to evaluate the performance of synthetic data on privacy protection and detection tasks. Please refer to the updated README.md file for details. Thanks again for the suggestions."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6938/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700183435282,
                "cdate": 1700183435282,
                "tmdate": 1700183672628,
                "mdate": 1700183672628,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ebBxoKDJOQ",
                "forum": "4Ay23yeuz0",
                "replyto": "FgHlqLDK1D",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dVGm (2/2)"
                    },
                    "comment": {
                        "value": "> Q2 & W2: Incorporate more datasets.\n\nWe selected datasets for our research based on two key criteria: data type diversity and accessibility. Since our study focuses on synthesizing tabular data containing both numerical and categorical features, we needed datasets with mixed data types. Also we preferred openly available datasets that could be easily downloaded for reproducibility.  After reviewing options, we chose six representative tabular datasets with mixed data types from UCI Machine Learning Repository to use in our experiments. The datasets contain a combination of numerical and categorical features relevant to our research goals. To facilitate future work, we provide code in our open-source codebase to download these datasets.\n\nWe recognize that many datasets in Table 2 of TabDDPM (Kotelnikov et al. 2022) only include numerical features, which do not match the mixed data types needed for this research. To expand the availability of suitable datasets, we plan to acquire and integrate additional datasets from Table 2 that do contain both numerical and categorical features. We welcome contributions from the research community to further expand the selection of datasets compatible with our codebase and support new lines of research.\n\n\n> Q3 & W3: Add SMOTE as a baseline in the results.\n\nThank you for the reviewer's suggestion; indeed, SMOTE can also be utilized for synthesizing new data in tabular data scenarios. Our initial idea was to investigate the synthesis of new data using deep generative models from random noise. While SMOTE can also generate new data, being an interpolation-based method, it may lack a certain level of randomness. Furthermore, SMOTE may encounter certain challenges when it comes to interpolating categorical features. Therefore, we did not consider it as a baseline in our study. \n\nSince the reviewer suggested it, we conducted experiments using SMOTE on the six datasets studied in this paper. We transformed categorical features into one-hot encoding for interpolation purposes. The table below shows the performance of SMOTE on various tasks across different datasets (Furthermore, in the previous response, we also provided its performance in terms of privacy protection and detection):\n\n| Metric | Adult | Default | Shoppers | Magic  | Beijing | News |\n| --- | --- | --- | --- | --- | --- | --- |\n| Single Column | 1.6\\% | 1.48\\% | 2.68\\% | 0.91\\% | 1.85\\% | 5.31\\% |\n| Pair Correlation | 3.28\\% | 8.41\\% | 3.56\\% | 3.16\\% | 2.39\\% | 5.38\\% |\n| MLE | 0.899 | 0.741 | 0.911 | 0.934 | 0.593 | 0.897 |\n\nWe note that by interpolating on individual dimensions, SMOTE exhibits excellent performance in the single-column density estimation metric. However, in the column pair correlation estimation metric, SMOTE's performance becomes suboptimal. This could be attributed to the possibility of non-linear correlations between different columns, making it challenging to reconstruct them through interpolation. On the Machine Learning Efficiency task as well, the data generated by SMOTE has achieved commendable performance. However, as discussed in Q1 & W4, the DCR score of the data generated by SMOTE is notably low, indicating a significant probability of direct copying from the training set. \n\nTherefore, we believe that SMOTE can serve as a data augmentation method but may not be suitable as a standalone generative model. In the latest version of the code, we have added support for SMOTE as a new baseline. Please check the updated code if you are interested. We will also include the results above in the corresponding tables in the revised table.\n\n> Q4: Confidence Intervals.\n\nThe confidence score is computed through cross-validation. To be detailed, we randomly split the dataset 20 times, and within each split we train the model and sample the synthetic dataset.\n\n\n> Q5: Publishment of the codes.\n\nSure, we will publish the entire codebase.\n\n\n> Q6: Try the codes on 2d synthetic sklearn examples.\n\nOur method can also be applied to 2d synthetic data from sklearn. In the updated codes, we have added a 2d synthetic dataset 'blob' of three classes created using sklearn.makeblobs. It is reformulated as a tabular dataset of 3 columns, where the first two columns are the 2d numerical features, and the last column is the categorical feature, denoting the label of each example. We also created a notebook blob.ipynb for facilitating running experiments on the synthetic dataset."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6938/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700183487864,
                "cdate": 1700183487864,
                "tmdate": 1700197551364,
                "mdate": 1700197551364,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uPgbhesrjb",
                "forum": "4Ay23yeuz0",
                "replyto": "KqAogzHyRl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6938/Reviewer_dVGm"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6938/Reviewer_dVGm"
                ],
                "content": {
                    "title": {
                        "value": "Q1 & W4 Provide privacy metrics (e.g., DCR) and detection metrics (e.g., C2ST) in the benchmark."
                    },
                    "comment": {
                        "value": "You are right, dcr and dcr_rate are not provided in sdmetrics. It should be as it is simple to implement.\nI appreciate, this quick improvement. It shows that TabSyn is both safe and realistic."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6938/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700238135771,
                "cdate": 1700238135771,
                "tmdate": 1700238135771,
                "mdate": 1700238135771,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6R7WyBtr6y",
                "forum": "4Ay23yeuz0",
                "replyto": "ebBxoKDJOQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6938/Reviewer_dVGm"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6938/Reviewer_dVGm"
                ],
                "content": {
                    "title": {
                        "value": "Q3 & W3: Add SMOTE as a baseline in the results."
                    },
                    "comment": {
                        "value": "Great. SMOTE is indeed good for MLE but poor at preserving privacy, but it is simple and cheap to train: it hence makes a sound baseline for tabular generative models."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6938/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700238457144,
                "cdate": 1700238457144,
                "tmdate": 1700238457144,
                "mdate": 1700238457144,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Gl3Ts1thfD",
            "forum": "4Ay23yeuz0",
            "replyto": "4Ay23yeuz0",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6938/Reviewer_aVor"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6938/Reviewer_aVor"
            ],
            "content": {
                "summary": {
                    "value": "Authors propose a generative model for mixed type tabular data. The proposed model first tokenizes the mixed type columns, feeds it to a one transformer layer, which then forms as the encoder in the VAE model. Finally the latent space is fixed by diffusion."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Very reasonable model for the mixed type tabular data. Definitely something that I would use in my day to day work. Results are also convincing."
                },
                "weaknesses": {
                    "value": "- Model itself seems to be pretty much the same as Vahdat 2021, except that in that paper authors used only images, whereas now tokenization is needed to use the same model. I would like authors to comment on this, and it would really help the paper to be very clear in the Introduction that where the technical novelty lies."
                },
                "questions": {
                    "value": "- what would be the accuracy in the downstream task if latent code would be used directly (and no synthetic data). I understand that this is not possible for all models. But for the models that it is possible it would be interesting to see how much benefit there is (i.e. can you win real)\n- Are all classification tasks in downstream binary tasks? If no, then AUC is not a correct metric."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6938/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6938/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6938/Reviewer_aVor"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6938/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698695310340,
            "cdate": 1698695310340,
            "tmdate": 1700687035163,
            "mdate": 1700687035163,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "BTGs45GzdN",
                "forum": "4Ay23yeuz0",
                "replyto": "Gl3Ts1thfD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer aVor (1/2)"
                    },
                    "comment": {
                        "value": "Thank you for your insightful comments and suggestions to help us improve the clarity and soundness of our research. Every question raised by you has been thoughtfully examined.\n\n> W1: The difference between Latent Score-based Generative\nModel (LSGM) and our proposed TabSyn, and the technical novelty\n\n\nWe acknowledge your observation regarding the similarity between Tabsyn and LSGM (Vahdat 2021). However, it is important to highlight key distinctions. \n \n1. A key difference between tabular data and image data lies in the variety of data types present in tabular data, encompassing both numerical and categorical features. In contrast, image data primarily comprises continuous pixel values that denote color and intensity. Tabsyn is specifically designed for mixed-type tabular data, a domain with unique challenges not addressed by LSGM. The feature tokenization process in Tabsyn represents a notable advancement tailored for such data, ensuring effective handling of diverse data types (numeric, categorical, etc.). \n2. Additionally, a fundamental aspect of tabular data is its complex relationships between columns, which differs from the localized spatial correlation observed in images, where pixel values largely correlate with adjacent pixels. Tabsyn uses a lightweight transformer model as the encoder and decoder in the VAE to capture intricate columns relationships. The self-attention mechanism in the Transformer enables each column to dynamically interact and integrate information from all other columns. This is accomplished by learning the importance weights of every other columns when processing a particular column.\n3. Training a VAE on tabular data presents a distinct challenge compared to training on image data. With image data, small errors in pixel values often do not significantly impact object recognition. However, with tabular data, precision in the values of each column is relatively more important for preserving the semantics of the data. As a result, a higher weight on the reconstruction loss is beneficial when training a VAE on tabular data in order to minimize distortion of the input. However, an excessively high reconstruction loss weight can lead to a poor approximation of the posterior distribution, $q(z)$. To address this issue, we introduce an adaptive schedule for the weight parameter, $\\beta$, which allows more effective training of the VAE model on tabular data. The rationale and efficacy of this adaptive weight schedule are demonstrated through the results presented in Figure 3 and Table 4 in the paper.\n4. Although the diffusion process is conceptually similar to LSGM, we make further improvements to the sampling speed. Specifically, we introduce a noise level proportional to the time step. Through theoretical analysis and empirical experiments, we demonstrate this improvement significantly reduces the number of steps needed to generate synthetic data compared to LSGM.\n\nOverall, Tabsyn's technical innovations lie in its specialized approach to handling the mixed-type and complexity of tabular data, from (1) its feature tokenization process and (2) its sophisticated use of a transformer model to capture column relationships to (3) its adaptive training schedule for VAE and (4) enhanced diffusion process for efficient data generation. These technical advancements are critical in enhancing the model's performance and are not present in LSGM."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6938/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700183763843,
                "cdate": 1700183763843,
                "tmdate": 1700183763843,
                "mdate": 1700183763843,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "limn3BgL75",
                "forum": "4Ay23yeuz0",
                "replyto": "Gl3Ts1thfD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer aVor (2/2)"
                    },
                    "comment": {
                        "value": "> Q1: The accuracy in the downstream tasks when the latent codes are directly used.\n\nOur paper focuses on synthesizing mixed-type tabular data using deep generative models. The primary goal is to generate synthetic data that faithfully reproduces the distribution of the original dataset. The variational autoencoder (VAE) in TabSyn learns latent representations of each row of tabular data, but is not optimized for any specific downstream task.\n\nMost importantly, since we currently focus on unconditional training, label information (such as class labels in classification tasks and target values in regression tasks) is trained and generated alongside other columns' features. Therefore, the latent encoding obtained by the VAE model already contains label information. In this case, if we directly use latent encoding to predict downstream tasks, there is actually a risk of label leakage. We conducted experiments in this regard and found that accuracy, AUC score, and other metrics were all close to 100%.\n\n\n> Q2: Are all classification tasks in downstream binary tasks? (AUC)\n\nYes, the four classification datasets - Adult, Default, Shoppers and Magic - are all for binary classification. As a result, we use the AUC score as the metric in Machine Learning Efficiency tasks. \n\nOur proposed method can also directly train on multi-class classification datasets without requiring modifications during training since it is an unconditional generation approach. It simply requires additional metrics to evaluate the downstream multi-class classification task. As suggested by Reviewer dVGm, we created a synthetic multi-class classification dataset. We also provided a blob.ipynb notebook to facilitate creating such a dataset. Please check the updated codes if you are interested (https://anonymous.4open.science/r/TabSyn-ICLR-Submission-6938/blob.ipynb)."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6938/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700183807682,
                "cdate": 1700183807682,
                "tmdate": 1700183861581,
                "mdate": 1700183861581,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QioHyEcujU",
                "forum": "4Ay23yeuz0",
                "replyto": "Gl3Ts1thfD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A reminder"
                    },
                    "comment": {
                        "value": "Dear reviewer, we have submitted my reply a few days ago. Now the deadline for reviewer-author discussion is approaching, but we observe that you have not replied to my comment. We would be happy if you let me know if you still have some questions or replies. If so, we will reply promptly. Looking forward to your reply."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6938/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700583217458,
                "cdate": 1700583217458,
                "tmdate": 1700583217458,
                "mdate": 1700583217458,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xvmMMu2j4z",
                "forum": "4Ay23yeuz0",
                "replyto": "QioHyEcujU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6938/Reviewer_aVor"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6938/Reviewer_aVor"
                ],
                "content": {
                    "title": {
                        "value": "Reviewer answer"
                    },
                    "comment": {
                        "value": "I apreciate authors answer and clarification of the technical novelty. I am willing to raise the score."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6938/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687007016,
                "cdate": 1700687007016,
                "tmdate": 1700687007016,
                "mdate": 1700687007016,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "QHmeOXRpN8",
            "forum": "4Ay23yeuz0",
            "replyto": "4Ay23yeuz0",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6938/Reviewer_Fs1y"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6938/Reviewer_Fs1y"
            ],
            "content": {
                "summary": {
                    "value": "Extending diffusion models to handle tabular data presents challenges due to the complex distributions and diverse data types inherent to such data. To address this, the authors introduce the use of a Variational Autoencoder (VAE) to learn a regularized latent embedding representation of the data, which is subsequently processed by a diffusion network for synthesis. Notably, the study employs a comprehensive set of multi-dimensional evaluation metrics for the generated data, filling a gap often observed in previous research. The proposed method excels across these metrics, underscoring its efficacy in generating synthetic data that closely mirrors the original data distribution."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- The method effectively manages mixed-type data by transforming them into a single cohesive space to ensure capturing or inter-column relationships.\n\n- Compared to existing diffusion-based methods, this method requires fewer reverse steps and offers faster data synthesis.\n\n- The authors have provided a unified comparison environment for their proposed tabular data synthesis, as well as all the compared baseline methods, and made their code base publicly available.\n\n- The study employs a diverse set of multi-dimensional evaluation metrics for a holistic assessment of the generated data, addressing a common shortcoming in previous research.\n\n- The method has been rigorously tested on six datasets using five metrics, and it consistently outperforming other existing methods, indicating its prowess in generating synthetic data that closely reflects the original data distribution."
                },
                "weaknesses": {
                    "value": "- The method's efficacy is contingent upon a well-trained VAE. It would be beneficial to compare the outcomes between optimally and sub-optimally trained VAEs, providing insights into worst-case vs. best-case scenarios.\n\n- Given the generative capability of VAEs, it would be insightful to see results from data generated solely by the VAE used in this study. The distinction between the paper's transformer-based VAE and TVAE warrants further exploration to determine the independent efficacy of the former.\n\n- While adjusting default hyperparameters for a fair comparison is commendable, understanding performance under default settings across consistent training epochs would give a fuller picture. This would ascertain whether hyperparameter enlargement (as done for CTGAN and CoDi) equally benefits the models or favors the presented method disproportionately.\n\n- The discrepancy observed where TabDDPM struggles with the News dataset (poor performance in Table 1), yet exhibits a low error rate in Table 2 seems unintuitive. Additionally, given TabDDPM's consistent second-place ranking, except for the News dataset, its fourth-place average rank seems unfair. An alternative could be per-dataset ranking or reporting modal / averaged ranks. \n\n- Given that the News dataset is primarily of numeric nature, it seems counterintuitive that TabDDPM, a diffusion based model would underperform on this dataset. It would be beneficial to understand the authors' rationale behind the model's inability to generate meaningful content for this dataset.\n\n- The deployment of MLE as a metric for privacy is unconventional. Traditionally, MLE assesses the synthetic data's task-performance equivalence to real data, not privacy leakage. It would be enriching if the authors could shed light on this choice.\n\n\nOverall, this paper stands out for its meticulous code, articulate presentation, and thorough analysis. I commend the authors for their contribution."
                },
                "questions": {
                    "value": "Thank you for sharing your code with the community; it's a valuable resource. While exploring it, I encountered a few queries and points of feedback:\n\n1. **Device Attribute Error**: When executing the command `python main.py \u2014dataname adult \u2014method vae \u2014mode train`, I came across the \u201cAttributeError: \u2019Namespace\u2019 object has no attribute \u2018device\u2019\u201d. I was able to address this by introducing an else statement post line 7 in `main.py` to default to 'cpu'. Consider incorporating this for broader compatibility.\n   ```python\n   if \u2026:\n       args.device = \u2026\n   else:\n       args.device = 'cpu'\n   ```\n\n2. **Sample Size Limitation**: I attempted the VAE training phase with 40 samples and encountered an `IndexError: index out of range in self`. This wasn't an issue with the full sample size of 32561. Is the model designed to accommodate only larger samples, or is there a potential to adapt it to smaller sample sizes?\n\n3. **Epoch Setting for VAE Model**: The default epoch for the VAE model in the code is set to 4000. Based on my prior experiences with the TVAE model using CTGAN's code, training for around 300 epochs usually suffices. Is the transformer architecture inherently more demanding in terms of training duration? Additionally, what criteria do you rely on to determine the termination of training? Introducing an early stopping mechanism might be beneficial, especially considering the subsequent training phase for the diffusion model. It's also noteworthy that a Train/Val accuracy of 100% seems achievable by the 1000th epoch."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6938/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698753072389,
            "cdate": 1698753072389,
            "tmdate": 1699636809167,
            "mdate": 1699636809167,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SKCkMLKqIb",
                "forum": "4Ay23yeuz0",
                "replyto": "QHmeOXRpN8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Fs1y (1/3)"
                    },
                    "comment": {
                        "value": "We appreciate the thoughtful feedback and suggestions from the reviewer on our paper. In the responses below, we have carefully addressed each of the reviewer's questions.\n\n> Q1: Device Attribute Error.\n\nThanks for identifying this issue. We have addressed it in the latest codebase version.\n\n> Q2: Sample Size Limitation.\n\nWe tried using a smaller batch size of 40, as suggested but did not see the error you described. Could you please provide more details on where exactly the error occurred, the exact command, and the experimental environment you used that triggered the issue? If you're using an older version of the code, please try downloading the latest version from the anonymous GitHub repository, which contains some new fixes.\n\n> Q3: Epoch setting for VAE Model.\n\n**Why TabSyn requires a larger number of training epochs?**\n\nOn one hand, optimizing a Transformer can indeed be more challenging than an MLP, necessitating a greater number of epochs to ensure VAE convergence. On the other hand, our VAE requires the scheduling of the trade-off hyperparameter beta during training, which involves a certain number of steps. Depending on the training stage, we gradually adjust the importance weighting between Reconstruction loss and KL loss (see Figure 3 in the submitted paper).\n\n**Criteria used to determine the termination of training.**\n\nIn all of the experiments, we trained the VAE for a fixed 4000 epochs. This decision was based on our observation that after training for 4000 epochs, the VAE's validation reconstruction loss had already approached convergence to a low value. This indicates that the learned VAE is capable of effectively reconstructing the input data. We did not employ any additional techniques to prematurely terminate the training of the VAE.\n\n**Introducing early stopping might be beneficial.**\nWe have implemented early stopping in the updated codebase to terminate VAE training prematurely based on the suggestion to use this technique.\n\n**Train/Val accuracy of 100% seems achievable by the 1000th epoch.**\n\nThe output training/validation accuracy solely reflects the reconstruction correctness of categorical features, and therefore, it cannot represent the overall reconstruction results since numerical features also require reconstruction. Moreover, consider a binary categorical variable where the ground truth is class 0. Predicted class distributions of [0.55, 0.45] and [0.99, 0.01] would both be considered correct predictions, but it's evident that we prefer predictions with higher confidence. Hence, Cross-Entropy loss is a more effective measure than accuracy in reflecting the quality of reconstruction, as it takes into account the confidence in predictions.\n\n> W1: Performance of sub-optimally trained VAEs.\n\nWe investigated the quality of synthetic data generated by TabSyn using the embeddings of the VAE obtained at different epochs as the latent space. In the updated paper's Appendix F.4, Figure 9, we plot the results of single-column density estimation and pair-wise column correlation estimation on the Adult and Default datasets, with intervals set at 400 epochs. We can observe that \n1. Increasing the training epochs of the VAE improves the quality of TabSyn's generated data.\n2. even when the VAE is sub-optimal (e.g., training epochs around 2000), TabSyn's performance is close to the optimal ones. \n3. even with a relatively low number of VAE training epochs (e.g., 800-1200), TabSyn's performance approaches or even surpasses the most competitive baseline, TabDDPM.\n \nBased on these observations, we recommend thoroughly training the VAE to achieve superior data generation quality when resources are abundant. However, when resources are limited, reducing the VAE training duration still yields decent performance.\n\nBesides, in Figure 6 of the initial paper submission, we investigated the sensitivity of hyperparameters in the VAE on TabSyn's performance. This can be considered as an evaluation of TabSyn's performance under the assumption of a suboptimal VAE."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6938/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700183021032,
                "cdate": 1700183021032,
                "tmdate": 1700183249313,
                "mdate": 1700183249313,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Arh5OP6Qms",
                "forum": "4Ay23yeuz0",
                "replyto": "QHmeOXRpN8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Fs1y (2/3)"
                    },
                    "comment": {
                        "value": "> W2: Synthetic data generated directly from TabSyn's VAE\n\nWe studied the data synthesis capability of TabSyn's VAE under different $\\beta$ settings just as done in Table 4. The results on Adult dataset concerning density estimation errors are presented in the following table.\n\n|  $\\beta$           |  Single            | Pair         |\n| --------           | -------            | -------      | \n| VAE: $\\beta=1.0$(Vanilla VAE) | 12.67\\% $\\pm$ 1.44 | 23.37\\% $\\pm$ 2.15 |\n| VAE: $\\beta=0.1$              | 24.01\\% $\\pm$ 1.6 | 37.61\\% $\\pm$ 1.99 |\n| VAE: $\\beta=0.01$             | 31.99\\% $\\pm$ 1.5 | 45.22\\% $\\pm$ 3.31 |\n| VAE: Scheduled $\\beta$  | 36.25\\% $\\pm$ 2.26 | 50.18\\% $\\pm$ 3.19 |\n| TabSyn  | **0.58\\%** $\\pm$ 0.06 | **1.54\\%** $\\pm$ 0.27 |\n\nAs demonstrated in the table, directly using TabSyn's VAE model to obtain synthetic data leads to poor data quality, regardless of the $\\beta$.  Indeed, a small $\\beta$ can lead to effective reconstruction of the original table, but at the cost of $q(z)$ deviating significantly from the standard normal distribution $\\mathcal{N}(0, I)$. On the other hand, a larger beta can make $q(z)$ approach $N(0, I)$, but it may result in poorer reconstruction quality. Furthermore, we found that, for the VAE, maintaining $q(z)$ close to $\\mathcal{N}(0, I)$ is advantageous for generating higher-quality synthetic data.\n\n> W3: Performance under different parameter scales\n\nWe agree with the reviewer that comparing the performance of different methods of different scales of parameters will provide a broder comparison of each method. To this end, we adjust the hidden dimension of TabSyn's denoising MLP (the architecture of which is in Appendix D.2, Figure 8) within [128, 256, 512, 1024] (1024 is the default value). We adjust those for baseline methods CTGAN, CoDi and TabDDPM correspondingly. The following table presents the performance comparison concerning single column and pair correlation on Adult (singl-column error / pair correlation error):\n\n|   Hidden dim  | 128  | 256   | 512  | 1024   |\n| --------   | ------- | ------- |  ------- | ------- | \n|  CTGAN  | 23.14 / 28.92 | 20.64 / 25.26 |  17.92 / 22.89 | 16.84 / 20.23 |\n|  CoDi   | 29.16 / 29.65 | 26.42 / 27.58 | 22.91 / 24.06 | 21.38 / 22.49 |\n|  TabDDPM   | 8.69 / 12.39 | 5.36 / 8.75 | 2.32 / 4.19 | 1.75 / 3.01 |\n|  TabSyn | **4.02** / **8.51** | **1.92** / **4.22** | **0.65** / **2.06** | **0.58** / **1.54** |\n\nA clear observation is that when reducing the model's parameter count, all models exhibit a similar degree of performance decline. This is easily understood because when the model's capacity is not large enough, it becomes challenging to accurately learn the distribution of complex data. Our TabSyn maintains a significant advantage even when the parameter count is reduced."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6938/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700183240132,
                "cdate": 1700183240132,
                "tmdate": 1700183279818,
                "mdate": 1700183279818,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RAZjx7k040",
                "forum": "4Ay23yeuz0",
                "replyto": "QHmeOXRpN8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Fs1y (3/3)"
                    },
                    "comment": {
                        "value": "> W4 & W5: The strange behavior of TabDDPM on News dataset.\n\nThe reviewer observes an interesting phenomenon with TabDDPM. When we tried to reproduce TabDDPM's results, we noticed it performs very well on most datasets but does poorly on the News dataset. This is not due to training issues, since the training curve looks normal. Instead, the generated content converges to repetitive values rather than a diverse distribution. This explains the failure to generate meaningful News content. To illustrate, we show the samples from the News training set and the corresponding TabDDPM syntheses. The training data exhibits variety, while the model's output is stuck in a narrow mode.\n\nTraining Set (News dataset)\n|   timedelta | n_tokens_title | n_tokens_content | n_unique_tokens |n_non_stop_words  | ... |\n| --------   | ------- | ------- |  ------- | ------- | ------- | \n|  423.0 | 7.0 | 259.0 |0.6762295 |1.0 |\n|  147.0 | 10.0 | 577.0 | 0.5044092 | 1.0|\n|  665.0 | 8.0 | 252.0 | 0.6468254 | 1.0 |\n|  593.0 | 10.0 | 167.0 | 0.7468354 | 1.0 |\n|  ... | ... | ... | ... | ... |\n\n\nTabDDPM Synthesized Data (News dataset)\n|   timedelta | n_tokens_title | n_tokens_content | n_unique_tokens |n_non_stop_words  | ... |\n| --------   | ------- | ------- |  ------- | ------- | ------- | \n|  731.0 | 23.0 | 0.0 | 701.0 | 1042.0 |\n|  731.0 | 23.0 | 0.0 | 701.0 | 1042.0 |\n|  731.0 | 23.0 | 0.0 | 701.0 | 1042.0 |\n|  731.0 | 23.0 | 0.0 | 701.0 | 1042.0 |\n|  ... | ... | ... | ... | ... |\n\n\nTo investigate further, we attempted to remove the two columns of categorical features from News, leaving only numerical features. With this simplified dataset, TabDDPM now synthesizes high-quality diverse examples. It achieved low error rates of 0.81% on Single Column Density Estimation and 1.09% on Column Pair Correlation Estimation. This suggests the categorical columns in News caused issues for TabDDPM in properly learning the true data distribution.\n\nWe further investigate the changes in training loss under both scenarios and found that in the absence of categorical columns, the Gaussian noise loss (corresponding to numerical features) can converge to a relatively low value, around 0.25. However, when both categorical columns are present, the Gaussian noise loss can only decrease to around 0.6. This suggests that the multinomial losses from the categorical columns may be hindering the training of the numerical columns. It indicates that the current training method adopted by TabDDPM may have some limitations, although this could be considered a corner case.\n\n> W6: Deploy MLE as a privacy protection metric.\n\nThe initial version of the paper used Machine Learning Efficiency (MLE) as a Privacy Protection application because we thought training models on synthetic data instead of original data protected privacy. After listening to this suggestion, we realized that categorizing MLE as a privacy protection task was inappropriate. Therefore, in the updated paper, we have revised this statement. \n\nAdditionally, we adopted the suggestion from reviewer dVGm, using the Distance to Closest Records (DCRs) scores to evaluate privacy protection. The corresponding results have been updated in Appendix F.5, Figure 10, and Table 12. The corresponding code updates have also been incorporated into our codebase."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6938/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700183326098,
                "cdate": 1700183326098,
                "tmdate": 1700197241374,
                "mdate": 1700197241374,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jJhdFGeWWP",
                "forum": "4Ay23yeuz0",
                "replyto": "RAZjx7k040",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6938/Reviewer_Fs1y"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6938/Reviewer_Fs1y"
                ],
                "content": {
                    "title": {
                        "value": "Q2: Sample Size Limitation"
                    },
                    "comment": {
                        "value": "Thank you for your diligent response to my inquiries. Upon re-executing the code with a reduced sample size, I experienced no errors, which leaves me puzzled as to the original cause of the issue. However, everything is functioning correctly at present. My score remains unchanged, and I extend my best wishes to the authors. Thank you for your contribution."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6938/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700383103880,
                "cdate": 1700383103880,
                "tmdate": 1700383103880,
                "mdate": 1700383103880,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "cBCAr9WBf2",
            "forum": "4Ay23yeuz0",
            "replyto": "4Ay23yeuz0",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6938/Reviewer_q7Xg"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6938/Reviewer_q7Xg"
            ],
            "content": {
                "summary": {
                    "value": "This work introduces a latent diffusion model for generating tabular data, and presents a benchmark consisting of six datasets and five quality metrics to evaluate the performance. The comparison in this unified testing environment demonstrates the superiority of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "\u2022\tThis paper presents a benchmark that is beneficial to the community.\n\n\u2022\tThe better performance over previous work across five quality metrics showcases its effectiveness in generating high-quality tabular data."
                },
                "weaknesses": {
                    "value": "1.\tThe motivation behind using latent diffusion for tabular data generation is not thoroughly discussed in the paper, and the model design does not effectively exploit the characteristics of tabular data.\n\n2.\tThe VAE decoder design is tailored specifically for either numerical or categorical features, which limits its applicability in a wider range of tabular data scenarios, such as datasets containing a mixture of both numerical and categorical features."
                },
                "questions": {
                    "value": "1.\tAre the results shown in Figure 3 derived from the training set or the validation set?\n\n2.\tDoes replacing the MLP in the diffusion model with a more powerful architecture, such as a Transformer, have any impact on the performance?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6938/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6938/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6938/Reviewer_q7Xg"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6938/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698930007200,
            "cdate": 1698930007200,
            "tmdate": 1700837507268,
            "mdate": 1700837507268,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FMxTtMM5rP",
                "forum": "4Ay23yeuz0",
                "replyto": "cBCAr9WBf2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer q7Xg  (1/2)"
                    },
                    "comment": {
                        "value": "We appreciate the valuable feedback and have carefully considered the points raised. Below, we address your concerns, hoping our revisions clarify all the questions and strengthen the quality of our work. \n\n> W1: The motivation behind using latent diffusion for tabular data generation.\n\nWe have illustrated the motivation behind using latent diffusion for tabular data in the first paragraph of the Introduction section. To provide a clearer and more concise explanation, we can rephrase it as follows: \n\nOne significant distinction between tabular data and image data is the presence of mixed data types in tabular data, including both numerical and categorical features, whereas image data primarily consists of continuous pixel values representing color and intensity.  Standard diffusion processes rely on a continuous input space with Gaussian noise perturbation, making them unsuitable for handling categorical features. Prior work employed different distribution functions for different data types (e.g., Gaussian noise for numerical variables and categorical noise for categorical variables). This approach poses difficulties in the model's ability to effectively capture the co-occurrence patterns among different types of data. To address this limitation and preserve inter-column correlations for tabular data, our approach involves developing a diffusion model in a joint space that accommodates both numerical and categorical features. This choice to use latent diffusion for tabular data generation is driven by the need to bridge this gap. \n\nIn the following answer, we illustrate how we achieve this by transforming mixed-type tabular data into a unified space using a well-designed VAE for tabular data.\n\n> W1-2: Model design for tabular data characteristics and handling mixed-type data.\n\nTabular data have three main characteristics: (1) the mixed type heterogeneous data, including numerical variables and categorical variables, (2) the correlation among columns, and (3) the complex and varied distribution and statistical properties for each column.\n\n- To handle mixed-type data, we have developed specialized feature tokenizers that transform each column into a space with the same *d* dimensions. For numerical columns, we utilize learnable linear transformations, while for categorical columns, we employ learnable embedding lookup tables. Then, these processed features were further fused through a Transformer encoder.\n- To capture correlation among columns, we employ a VAE-based on the Transformer architecture. The self-attention mechanism in Transformer allows each column to dynamically interact and fuse with all others. This is achieved by learning the importance weights of every other column when processing a particular column. \n- To learn the complex tabular data distributions, we combine the VAE and the diffusion process. By training a VAE on tabular data, each column's statistics are compressed into latent variables that capture the essential statistical properties of that column. The VAE is trained using a reconstruction loss function with a KL divergence term. This regularization encourages the latent space to approximate a standard normal distribution, which supports capturing the varied distributions of different columns. After training the VAE, a diffusion process is applied to the latent representations. By needing to denoise the added noises during the diffusion process, the model learns the underlying structure of the data distribution. Together, VAEs and diffusions allow for capturing complex and varied column distributions."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6938/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700182826188,
                "cdate": 1700182826188,
                "tmdate": 1700182826188,
                "mdate": 1700182826188,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "K7YOiHbn9M",
                "forum": "4Ay23yeuz0",
                "replyto": "cBCAr9WBf2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer q7Xg (2/2)"
                    },
                    "comment": {
                        "value": "> Q1: Are the results shown in Figure 3 derived from the training set or the validation set?\n\nThe results shown in Figure 3 are from the validation loss, and we will change the label of the y-axis from \"loss\" to \"validation loss\" to make it clearly stated.\n\n> Q2: Impacts of replacing the MLP in the diffusion model with a more powerful architecture.\n\nWe experimentally evaluated multiple neural network architectures, including MLPs, MLPs with residual connections, and Transformers for the denoising function (since these structures have been proven effective at modeling tabular data [1]).  Across all architectures tested, we observed negligible differences in denoising performance. Given the faster training and sampling speed of MLPs (detailed in Table 8, Appendix F.1), and for fair comparison to prior work using MLP-based denoising functions, we selected the MLP architecture.\n\n\nThe error rates of column-wise density estimation (denoted as Single) and pair-wise column correlation estimation (denoted as Pair) on the Adult dataset for each architecture are presented as follows:\n\n|  Architecture           |  Single            | Pair         |\n| --------                | -------            | -------      | \n| TabSyn (MLP, current design)   |   0.58             |    1.54      |\n| TabSyn (Residual)         |   0.55             |    1.52      |\n| TabSyn (Transformer)    |   0.53             |    1.52      |\n\n\nReferences:\n\n[1] Gorishniy, Yury, et al. \"Revisiting deep learning models for tabular data.\" Advances in Neural Information Processing Systems 34 (2021): 18932-18943."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6938/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700182904361,
                "cdate": 1700182904361,
                "tmdate": 1700182904361,
                "mdate": 1700182904361,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CScPVIKmRP",
                "forum": "4Ay23yeuz0",
                "replyto": "cBCAr9WBf2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6938/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A reminder"
                    },
                    "comment": {
                        "value": "Dear reviewer, we have submitted my reply a few days ago. Now the deadline for reviewer-author discussion is approaching, but we observe that you have not replied to my comment. We would be happy if you let me know if you still have some questions or replies. If so, we will reply promptly. Looking forward to your reply."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6938/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700583179506,
                "cdate": 1700583179506,
                "tmdate": 1700583179506,
                "mdate": 1700583179506,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]