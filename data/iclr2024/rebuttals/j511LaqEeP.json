[
    {
        "title": "Non-Exchangeable Conformal Risk Control"
    },
    {
        "review": {
            "id": "MBPPVQCtvx",
            "forum": "j511LaqEeP",
            "replyto": "j511LaqEeP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5857/Reviewer_r1o1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5857/Reviewer_r1o1"
            ],
            "content": {
                "summary": {
                    "value": "The paper shows how to perform conformal risk in a non-exchangeable setting --- i.e. for any given loss l, providing a threshold such that the true loss is less than some pre-specified alpha. Unlike the typical conformal prediction setting that assumes that data satisfies the exchangeable assumption (i. e. any permutation of the data is equally likely), it tries to relax such assumption. Also, unlike the typical conformal prediction that provides a prediction set that's supposed to contain the true label, it studies a more general form usually referred to as conformal risk control.\n\nThe paper achieves the above goal by combining Barber et al. (Conformal Prediction Beyond Exchangeability) and Angelpoulos et al. (Conformal Risk Control). \n\nFinally, the paper tests the idea on three datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "-The idea proposed here seems to actually work in practice as shown by their experiments."
                },
                "weaknesses": {
                    "value": "-The main contribution of the paper seems to be just a combination of two techniques, conformal prediction beyond exchangeability and conformal risk control. Once one understand the idea behind conformal prediction (i.e. finding an (1-alpha) quantile of the conformal score in the calibration data set), the idea of conformal risk control follows pretty naturally (finding some alpha-cut off for some monotonic loss in the calibration data set). And hence, techniques known for conformal prediction can be easily translated to conformal risk control \u2014 i.e. handling distribution shift. In this specific case, the paper is leveraging the technique of conformal prediction beyond exchangeability. Also, there isn\u2019t inherent difficulty in applying the beyond the exchangeability idea to this conformal risk control setting to my knowledge. If there is additional difficulty in applying the beyond the exchangeability idea to the conformal risk control setting compared to applying the idea to the typical conformal prediction setting, it would be great if the authors can emphasize that and how this difficulty was overcome.  \n-There\u2019s no clear guideline as to how to go about setting these weights and one has to resort to heuristics. But I think this point is not necessarily specific to the approach in this paper but with the original conformal prediction beyond exchangeability of Barber et al."
                },
                "questions": {
                    "value": "-In Equation (3) where Z_i is defined, shouldn\u2019t Z_i be what you get by swapping the test point (X_{n+1}, y_{n+1}) with (X_i, y_i) as opposed to the nth calibration data point (X_n, y_n)? This is how things are defined in Barber et al. as well."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5857/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5857/Reviewer_r1o1",
                        "ICLR.cc/2024/Conference/Submission5857/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5857/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698699252985,
            "cdate": 1698699252985,
            "tmdate": 1700674611727,
            "mdate": 1700674611727,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VtPpirPGQ4",
                "forum": "j511LaqEeP",
                "replyto": "MBPPVQCtvx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5857/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review. We address below your concerns about our paper.\n\n> The main contribution of the paper seems to be just a combination of two techniques, conformal prediction beyond exchangeability and conformal risk control (...) techniques known for conformal prediction can be easily translated to conformal risk control \u2014 i.e. handling distribution shift. (...) there isn\u2019t inherent difficulty in applying the beyond the exchangeability idea to this conformal risk control setting to my knowledge. If there is additional difficulty (...) it would be great if the authors can emphasize that and how this difficulty was overcome.\n\nWe respectfully disagree with the claim that our paper is \u201cjust\u201d a combination of two techniques and that \u201cthere isn\u2019t inherent difficulty in applying the beyond the exchangeability idea to this conformal risk control setting\u201d. For example, one nontrivial aspect in our proof was to generalize / replace the step in Barber et al.'s proof (their Eqs. 24-26) which involves defining the set of \u201cstrange\u201d points and showing that noncoverage implies strangeness of point K. In conformal risk control, \u201cnoncoverage of a test point\u201d does not make sense, since we are upper bounding the risk and not modeling coverage. To overcome this difficulty and prove our theorem in the context of risk control, we handled this by (1) defining random variables $F(Z)$ which contain the losses as a function of $\\lambda^*(Z)$, and (2) deriving a bound that includes a TV distance using $F(Z)$, and (3) invoking the non-monotonicity of the loss to obtain the final result. These elements are specific to our paper and absent in Barber et al. (2023) and Angelopoulos et al. (2023)\u2019s proofs. In short, the proof style is similar but some of the key steps are substantially different and nontrivial. We invite the reviewer to compare the proofs and check the differences in case any doubt remains. \n\nAs pointed out by Reviewer wGbj, non-exchangeability happens frequently in practice, and thus it is important to explore robust weighting schemes and their implications. As explained, our method and proofs use techniques from Barber et al. (2023) and Angelopoulos et al. (2023), but their combination is not straightforward and has not been done before. We address the problem of risk control under non-exchangeable settings, which is highly relevant, yet the existing literature doesn't offer comprehensive solutions (please see Reviewer 2JpW\u2019s comment on this topic). In addition to the theoretical results, our experiments show that the proposed method is useful in practice in both synthetic and real-world settings. \n\nWe hope this clarifies our goals and the significance of our contributions and alleviates your concerns. \n\n> There\u2019s no clear guideline as to how to go about setting these weights and one has to resort to heuristics. But I think this point is not necessarily specific to the approach in this paper but with the original conformal prediction beyond exchangeability of Barber et al.\n\nAs pointed out in the answer to Reviewer wGbj, although our theoretical bound on $\\mathbb{E}[L(\\hat{\\lambda}; (X_{n+1}, Y_{n+1}))]$ holds for any choice of weights, its usefulness relies on the coverage gap in Eq. 7 being small, i.e., on our ability  to choose small weights $w_i$ for data points $Z^i$ with large total variation distance $d_{\\mathrm{TV}}(Z, Z^i)$. In Barber et al. 2023 (Lemma 1) it is shown that $d_\\mathrm{TV}(Z, Z^i) \\le 2d_\\mathrm{TV}(Z_i, Z_{n+1})$, and while the true value of this term is unknown, in some cases it can be properly modeled or approximated. For instance, in the presence of distribution drift in time series, we expect  $d_{\\mathrm{TV}}(Z_i, Z_{n+1})$ to decrease with $i$, therefore we should  choose weights that increase with $i$. Our experiments (e.g., $\\S4.1$, Setting 3) empirically validate this assumption for the case of distribution drift. The same principle can be applied in other domains (e.g., for spatial data, one may place higher weights to points close in space to the test point). \n\nWe agree  that the paper benefits from more discussion on this topic, and for that reason we updated it accordingly (please see $\\S3$ after Eq. 8). In particular, we included a new subsection ($\\S3.2$) that suggests a practical strategy for choosing the weights based on knowledge or assumptions about how the TV distance $d_{\\mathrm{TV}}(Z, Z^i)$ varies over time, via a regularized minimization of the coverage gap using the maximum entropy principle. We also show in this subsection that this principle provides further justification for the use of weights with an exponential decay in time series under a distribution shift, which we use in our experiments of $\\S4.1$ and $\\S4.2$. We hope this addresses your main concerns.\n\n_(continues in a follow-up comment)_"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700262586864,
                "cdate": 1700262586864,
                "tmdate": 1700262586864,
                "mdate": 1700262586864,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xmLrsOGAsY",
                "forum": "j511LaqEeP",
                "replyto": "MBPPVQCtvx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5857/Reviewer_r1o1"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5857/Reviewer_r1o1"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response!"
                    },
                    "comment": {
                        "value": "(1) Novelty beyond Barber et al. and Angelopoulos et. al.\n\nMaybe this has to do with me not having read Barber et al. and Angelopoulos et al. very closely, and I\u2019m missing some nuances in technical details. I understand the proof that is described in the response is not in Barber et al. and additional arguments will be needed to handle conformal risk control aspect of the paper. However, my understanding was that what is in the described proof sketch in the response is essentially the main insights in Angelopoulos et al. \n\nLet me try to clarify with more specific details, and please correct me if I\u2019m wrong. \n\nAs said in the response, talking about non-coverage of a test point doesn\u2019t make sense the conformal risk control, and the set of \u201cstrange points\u201d has to be thought through more carefully. And the original conformal risk control paper shows how one can define a set of strange points not just via non-coverage but via thresholding a monotonic loss, thereby going from vanilla conformal prediction to conformal risk control. The insight here I guess is realizing that given a monotonic non-conformal score, the prediction set is monotonic in the threshold. \n\nTherefore, one can just go to the proof that\u2019s outlined on page 32 of Barber et al. (right before section 7) and instead of miscoverage (a point in the prediction set or not), one can write down the monotonic loss and the rest of the proof follows; my impression is that this swapping of miscoverage with a monotonic loss has been already done in Angelopoulos et al. \n\nIn fact, the proof of Theorem 1 of this paper looks like the proof of Theorem 2 in Barber et al. (specifically the proof on page 32 right before section 7) except for the swapping of the miscoverage with the monotonic loss. And one can see this connection of miscoverage and monotonic loss in Section 2 of Angelopoulos et al. \n\nLet me know if I'm missing more subtle nuances.\n\n\n\n(2) Choice of Weights\n\nThank you for adding more discussion on this topic of how to go about choosing these weights."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700276513236,
                "cdate": 1700276513236,
                "tmdate": 1700328174390,
                "mdate": 1700328174390,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JjKymMU7rV",
                "forum": "j511LaqEeP",
                "replyto": "v7kvjfhNPn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5857/Reviewer_r1o1"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5857/Reviewer_r1o1"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the detailed comparison"
                    },
                    "comment": {
                        "value": "First of all, I really wish I took out the word \"just\" when describing the combination of ideas as i see that it might have come across as dismissive of the work. So my apologies. But I do think that when evaluating a paper, it isn\u2019t too inappropriate to consider the novelty of the paper on top of technical correctness.\n\nIn the above response, I have some questions regarding the response:\n1. \u201cunlike the residuals in Barber et al., which do not have a similar dependency\". Doesn't Barber et al., choose lambda to be essentially the alpha quantile of the residuals or equivalently conformal scores of the calibration dataset too?\n\nMore specifically, I thought that since we are talking about split conformal prediction where the predictor $\\mu$ is fixed, there's no difference in analysis in terms of studying the distribution over the original points $(x,y)$ and and studying the distribution over the residuals $(x, |\\mu(x) - y|)$ or any other conformal score $(x, s_\\mu(x,y))$, no? More specifically, given a calibration dataset $((x_1, y_i), ..., (x_n, y_n))$, there's an immediate deterministic mapping to $((x_1, s_\\mu(x_1,y_1)), ... , (x_n, s_\\mu(x_n, y_n)))$ if you fix the conformal score function $s$ and the predictor $\\mu$ beforehand.\n\nTherefore, even the TV distance between the distribution over (x,y)\u2019s should be the same for the distribution over (x,s)\u2019s, right? \n\nSo I don\u2019t understand this comment about two loss functions? To me, there\u2019s only one loss function in Barber et al. too in the split conformal case.: in fact, to me the insight of Angelopoulos et al is  you get conformal prediction if you use the loss function as $E_{(x,y)}[1[s(x,y) \\le \\lambda]]$ which is monotonic in lambda.\n\n\n2. \u201cThey show their bound to show that miscoverage implies \u2026(their eq 23) \u2026 We use our bound to show that ... . This is qualitatively different\". \nFirst, just for me to understand what is stated in the response: it\u2019s saying that if the expected risk of the (n+1)th point was less than alpha, then it must have been the case that the chosen $\\hat{\\lambda}$ must have been big enough compared to the true cut-off $\\lambda^*$ to guarantee that the expected risk of \n\nCan you state the qualitative difference here to Barber et al. a little more? The bound that this paper talks about in terms of comparing $\\hat{\\lambda}$ and $\\lambda^*$ is rather similar to the inequality 22 in Barber et al.? The left-hand side of the inequality is like $\\hat{\\lambda}$ and the right hand side inequality is like $\\lambda*$. \n\n\nAnyway, I have changed my score in light of thinking through this a little more."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700541401046,
                "cdate": 1700541401046,
                "tmdate": 1700541401046,
                "mdate": 1700541401046,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IJnc39EyOn",
                "forum": "j511LaqEeP",
                "replyto": "vxNvMGtxc4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5857/Reviewer_r1o1"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5857/Reviewer_r1o1"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the clarification"
                    },
                    "comment": {
                        "value": "Thanks for the clarification. I think I finally understand the the paper's subtle difference to Barber et al. and Angelopoulos et. al.: the TV-distance discussion above (in terms of its presence/absence of the lambdas) helped me. \n\nI have raised the score accordingly."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700674582802,
                "cdate": 1700674582802,
                "tmdate": 1700674582802,
                "mdate": 1700674582802,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "U2ZaCXPhJo",
            "forum": "j511LaqEeP",
            "replyto": "j511LaqEeP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5857/Reviewer_aj7z"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5857/Reviewer_aj7z"
            ],
            "content": {
                "summary": {
                    "value": "This paper extends conformal risk control (CRC) under the exchangeable setup to the non-exchangeable setup, i.e., converting \u201cAngelopoulos et al. (2023a)\u201d to the \u201cBarber et al. (2023)\u201d-style. In particular, the coverage guarantee under non-exchangeability is stated and proven in Theorem 1 and the proof follows techniques by Barber et al. (2023) and Angelopoulos et al. (2023a). The efficacy of the proposed algorithm is empirically demonstrated by using synthetic and real data with multiple shifts."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Originality: This paper combines the results by Barber et al. (2023) and Angelopoulos et al. (2023a), leading to a new result. \n\nQuality: the claim is well-justified via Theorem 1 and its proof. \n\nClairity: the paper is mostly well-written. \n\nSignificance: considering that the conformal prediction can be extended to the non-exchangeable setup by Barber et al. (2023), so it is not surprising that conformal risk control can be extended in a similar way. But, it is still a new result."
                },
                "weaknesses": {
                    "value": "The following includes my concerns. \n\n1. Under the non-exchangeable setup, the CRC should be broken, and this is why we need non-exchangeable extension of CRC. But, I cannot see the trend in Setting 3 in Figure 1 and Figure 3, which is unsatisfactory. In particular, I\u2019m not convinced why open-domain QA experiments (related to Figure 3) fit the non-exchangeable setup \u2013 the concrete scenario on why we need to consider the non-exchangeable setup here is required. Moreover, the way to generate w_i is not correct \u2013 by Barber et al. (2023), w_is prespecified but not data-dependent (see Section 4.5. by Barber et al. (2023) for a careful discussion on the data-dependent weights). This may demonstrate that open-domain QA is not a proper target of this method. \n\n2. It would be more readable if the controlled loss is summarized in scalar statistics. For example, in Setting 3 in Figure 1, I cannot see why the proposed approach is good."
                },
                "questions": {
                    "value": "1. Can you draw plots such that CRC is clearly broken under the non-exchangeable setup?\n2. Can you provide the concrete scenario on why we need to consider the non-exchangeable setup in open-domain QA experiments? You also can replace the experiments. \n3. Can you justify why weights are generated in a data-dependent way in open-domain QA experiments?\n4. Can you summarize / provide scalar statistics on the controlled loss such that we can see whether the proposed approach controls the risk but the baseline fails to control it?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5857/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698762037666,
            "cdate": 1698762037666,
            "tmdate": 1699636620160,
            "mdate": 1699636620160,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "RHkISpGs8H",
                "forum": "j511LaqEeP",
                "replyto": "U2ZaCXPhJo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5857/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your thoughtful review and suggestions. We address the main points below.\n\n> Under the non-exchangeable setup, the CRC should be broken (...); (...) in Setting 3 in Figure 1, I cannot see why the proposed approach is good.; Can you summarize / provide scalar statistics on the controlled loss such that we can see whether the proposed approach controls the risk but the baseline fails to control it?\n\nPlease note that Figure 1 shows that the CRC baseline fails at providing the desired risk level in the presence of distribution drift (setting 3), whereas the proposed approach does not: the orange curve (CRC) is mostly above the black dotted line, while the green one (our method) tends to be below. We rescaled the axes in  this figure for clarity. We also followed your suggestion and  added scalar statistics  (mean/median) to the paper, which further strengthen this point  (see Table 2, reproduced  below). We also included some of these values in the main text (last paragraph of $\\S4.1$) for further clarity. We hope to have clarified  your concern.\n\n| Setting   | 1 (i.i.d data) | 2 (changepoints) | 3 (distribution drift) |\n|-----------|----------------|------------------|------------------------|\n| CRC       | 0.191/0.183    | 0.246/0.228      | 0.225/0.218            |\n| Non-X CRC | 0.181/0.175    | 0.196/0.183      | 0.182/0.175            |\n\n> In particular, I\u2019m not convinced why open-domain QA experiments (related to Figure 3) fit the non-exchangeable setup (...) the way to generate w_i is not correct \u2013 by Barber et al. (2023), w_is prespecified but not data-dependent (...); Can you justify why weights are generated in a data-dependent way in open-domain QA experiments?\n\nFor an intuitive scenario where non-exchangeability provides a good framework for the QA experiment, imagine a situation where the questions are posed by multiple users, with the same user having a tendency to ask semantically similar questions. Our results in this experiment suggest that choosing weights based on question similarity leads to smaller prediction sets while attaining the same risk level (see Figure 3 (left)). We believe this is an interesting result potentially useful in future research. \n\nYou are right that Theorem 1 requires the independence $K \\perp Z$ as in Barber et al. (2023). For the other experiments ($\\S4.1$ and $\\S4.2$), we always assume data-independent weights. Our goal with the QA experiment is to assess whether the framework still works in practice when this assumption is relaxed (in cases where prior information about the domain of the questions or the user who asked them is available, one could choose a priori higher weights for closer domains/users without violating this assumption). Furthermore, note that it is possible to generalize our bound to allow data-dependent weights by conditioning the TV distance on the weights as described by Barber et al. (2023), $\\S4.5$ (paragraph \u201cFixed versus data-dependent weights''). \n\nTo sum up, we believe that the results of $\\S4.3$ are still interesting and useful. We agree, however, that the paper would benefit from a clearer discussion about this point along with a justification for that experiment. Therefore, we  added this information in $\\S3$ (last paragraph before $\\S3.1$) and $\\S4.3$ and updated the abstract/introduction accordingly. We hope this alleviates your concern."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700262248889,
                "cdate": 1700262248889,
                "tmdate": 1700262248889,
                "mdate": 1700262248889,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LoKNMSrMiU",
                "forum": "j511LaqEeP",
                "replyto": "RHkISpGs8H",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5857/Reviewer_aj7z"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5857/Reviewer_aj7z"
                ],
                "content": {
                    "title": {
                        "value": "Thanks"
                    },
                    "comment": {
                        "value": "Thanks for detailed response! The response enhanced my understanding, but I still have concerns. \n\n1. To my understanding, the authors' may be confused the empirical realization of the marginal coverage guarantee (5). As it is not conditioned on the calibration set (i.e., the PAC-style guarantee), the empirical coverage should be *around* alpha (not below alpha) -- if it is not convinced, see Figure 2 of Tibshirani et al. (2019). Thus, Table 2 does not demonstrate non-X CRC is clearly better than CRC (as the empirical risks are around alpha) under shifts. \n\n2. It is okay to show practical values of the proposed method in open-domain QA experiments, but anyway it is heuristic and not supported by the main theorem, which even undermine the value of the main theorem. I'd replace this into another experiment that justifies the main theorem, and put open-domain QA experiments into the other section to independently highlight the claimed practical value. \n\nMainly the empirical results do not support the paper's claim, so, I'll maintain my score."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700699254141,
                "cdate": 1700699254141,
                "tmdate": 1700699254141,
                "mdate": 1700699254141,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "FU8VV5F9ID",
            "forum": "j511LaqEeP",
            "replyto": "j511LaqEeP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5857/Reviewer_wGbj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5857/Reviewer_wGbj"
            ],
            "content": {
                "summary": {
                    "value": "This paper expands on the non-exchangeable setting for conformal risk control by Angelopoulos et. al. (2023). Conformal risk control is a generalization of conformal prediction that expands control of coverage losses to control of any monotonic, upper-bounded, exchangeable function $L \\colon \\Lambda \\rightarrow [0, B]$, where $\\Lambda$ is the space of single-dimensional inputs to ${L}$. Most often ${L}$ is some deterministic function $\\mathcal{L}$ of a parametrized, conformal set $\\mathcal{C}(X; \\lambda)$ and the label $Y$ that obeys $\\lambda_1 \\leq \\lambda_2 \\implies \\mathcal{C}(X; \\lambda_1) \\subseteq \\mathcal{C}(X; \\lambda_2) \\implies \\mathcal{L}(\\mathcal{C}(X; \\lambda_1), Y) \\geq \\mathcal{L}(\\mathcal{C}(X; \\lambda_2), Y) $.\n\nAs the paper by Angelopoulos et. al. (2023) showed, conformal risk control is considerably more flexible than standard conformal prediction, while still retaining nearly identical guarantees. The work by Angelopoulos et. al. (2023) briefly touched on straightforward extensions to conformal risk control, including proving a bound on the degradation in guaranteed risk as a function of $\\sum TV(Z_i, Z_{n+1})$, where $Z_i = (X_i, Y_i)$, similar to the work of Barber et. al. (2022). This paper further includes the use of data _weight_ functions (as in Barber et. al. (2022)), and shows that this can have good empirical impact on several experimental domains.\n\n[1] Conformal Risk Control. Anastasios N. Angelopoulos, Stephen Bates, Adam Fisch, Lihua Lei, Tal Schuster. 2023.\n\n[2] Conformal prediction beyond exchangeability. Rina Foygel Barber, Emmanuel J. Candes, Aaditya Ramdas, Ryan J. Tibshirani. 2022."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper is clear, and does a good job at deriving bounds for how weighted conformal risk control performs under non-exchangeability. Non-exchangeability will happen often in practice, so it is impactful to explore more robust weighting schemes and their implications. The empirical results are encouraging. It's a bit unclear as to how _useful_ the guarantees are, in the sense that they can be too loose if $\\sum w_i TV(Z, Z^i)$ is very large, or more likely yet, simply unknown. When some practical knowledge about the domain is available, however, designing an appropriate weighting scheme can be effective (which is demonstrated for some of the experiments here)."
                },
                "weaknesses": {
                    "value": "While, again, the paper is nicely written, it is a somewhat incremental step from previous work in Barber et. al. and Angelopoulos et. al. It's also a bit of an over-claim to say that risk is _controlled_ in a non-exchangeable setting, rather what the paper does is develop a conservative upper bound for the risk under non-exchangeability that depends on quantiles that we cannot realistically know, i.e., $TV(Z_i, Z_{n+1})$."
                },
                "questions": {
                    "value": "- I'm unclear if Theorem 1 holds for data-dependent weights? A similar requirement of independence is in Barber's results, and it would seem that it should be required here too. Particularly in the iterated expectation step here, I think this assumes $K \\perp Z$. This is a major claim in the paper (e.g., \"[...] allows weighting the data based on its statistical similarity with the test examples\" in the abstract), and in the QA experiment, the weights are a function of the data points, $w_i = \\textrm{sim}(X_i, X_{n+1})$. \n- Otherwise, it's also unclear what the best strategy should be for selecting weighting functions (this seems rather adhoc in the experiments).\n- Note that we can get the same bound in Lemma 1 directly from the analysis of Angelopoulos et. al. by defining $\\tilde{g}(Z) = g(Z) - A$, which then has range $[0, B - A]$ for $g(Z) \\in [A, B]$, and then it follows that\n$| \\mathbb{E}[g(Z)] - \\mathbb{E}[g(Z')] | =  | \\mathbb{E}[g(Z) - A] - \\mathbb{E}[g(Z') - A] | = | \\mathbb{E}[\\tilde{g}(Z)] - \\mathbb{E}[\\tilde{g}(Z') ] |$,\nand then we proceed directly with the proof in Angelopoulos et. al. to get\n $| \\mathbb{E}[\\tilde{g}(Z)] - \\mathbb{E}[\\tilde{g}(Z') ] | \\leq (B-A) TV(Z, Z').$"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5857/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698814446882,
            "cdate": 1698814446882,
            "tmdate": 1699636620043,
            "mdate": 1699636620043,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Jzxm8j66jX",
                "forum": "j511LaqEeP",
                "replyto": "FU8VV5F9ID",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5857/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review and suggestions. We are glad that you found the paper nicely written. We address the main points below.\n\n> It's also a bit of an over-claim to say that risk is controlled in a non-exchangeable setting, rather what the paper does is develop a conservative upper bound for the risk under non-exchangeability that depends on quantiles that we cannot realistically know, i.e., TV(Z_i, Z_{n+1}).\u201d\n\nYou are right that our upper bound contains a coverage gap that is not easy to control, and we updated the manuscrit to make this more clear (see $\\S3$). Nevertheless, we believe the upper bound derived in our paper can still be practically useful and it can  motivate heuristics for reducing this coverage gap via a suitable choice of the weights. We added a discussion in a new subsection ($\\S3.2$), where we also provide a maxent heuristic that, among other things, justifies exponentially decaying weights in distribution shift scenarios. We hope this clarifies your concerns.\n\n> \u201cI'm unclear if Theorem 1 holds for data-dependent weights? A similar requirement of independence is in Barber's results, and it would seem that it should be required here too. Particularly in the iterated expectation step here, I think this assumes K \\perp Z. This is a major claim in the paper (e.g., \"[...] allows weighting the data based on its statistical similarity with the test examples\" in the abstract), and in the QA experiment, the weights are a function of the data points, w_i=sim(X_i, X_{n+1}).\u201d\n\nIndeed, our Theorem 1 requires the independence $K \\perp Z$ as in Barber et al. (2023). Our goal with the QA experiment is to assess whether the framework still works in practice when we relax this assumption (we set higher weights for questions in a \u201cneighborhood\u201d of $X_{n+1}$). For the other experiments ($\\S4.1$ and $4.2$), we always assume data-independent weights. Note that it is possible to generalize our bound to allow data-dependent weights by conditioning the TV distance on the weights as done by Barber et al. (2023),  $\\S4.5$ (paragraph \u201cFixed versus data-dependent weights''). While we believe that the results of $\\S4.3$ are still interesting and useful in practice, we agree that the paper would benefit from more discussion about this point. We added a note in $\\S3$ (last paragraph before $\\S3.1$) and in $\\S4.3$ to clarify this and we also updated the abstract/introduction accordingly. \n\n> \u201cOtherwise, it's also unclear what the best strategy should be for selecting weighting functions (this seems rather adhoc in the experiments).\u201d\n\nAlthough our theoretical bound on $\\mathbb{E}[L(\\hat{\\lambda}; (X_{n+1}, Y_{n+1}))]$ holds for any choice of weights, its usefulness relies on the coverage gap in Eq. 7 being small, i.e., on our ability  to choose small weights $w_i$ for data points $Z^i$ with large total variation distance $d_{\\mathrm{TV}}(Z, Z^i)$. In Barber et al. (2023), Lemma 1, it is shown that $d_\\mathrm{TV}(Z, Z^i) \\le 2d_\\mathrm{TV}(Z_i, Z_{n+1})$, and while the true value of this term is unknown, in some cases it can be properly modeled or approximated. For instance, in the presence of distribution drift in time series, we expect  $d_{\\mathrm{TV}}(Z_i, Z_{n+1})$ to decrease with $i$, therefore we should  choose weights that increase with $i$. Our experiments (e.g., $\\S4.1$, Setting 3) empirically validate this assumption for the case of distribution drift. The same principle can be applied in other domains (e.g., for spatial data, one may place higher weights to points close in space to the test point). \n\nWe agree  that the paper benefits from more discussion on this topic, and for that reason we updated it accordingly (please see $\\S3$ after Eq. 8). In particular, we included a new subsection ($\\S3.2$) that suggests a practical strategy for choosing the weights based on knowledge or assumptions about how the TV distance $d_{\\mathrm{TV}}(Z, Z^i)$ varies over time, via a regularized minimization of the coverage gap using the maximum entropy principle. We also show in this subsection that this principle provides further justification for the use of weights with an exponential decay in time series under a distribution shift, which we use in our experiments of $\\S4.1$ and $\\S4.2$. We hope this addresses your main concerns."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700261980087,
                "cdate": 1700261980087,
                "tmdate": 1700261980087,
                "mdate": 1700261980087,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qjMb7EY6SM",
                "forum": "j511LaqEeP",
                "replyto": "FU8VV5F9ID",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5857/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your time reviewing our paper. We hope you had the chance to look at our answers and updated version of the paper. Since the author response period is almost ending, we kindly request your feedback on wether we addressed your concerns. Please do let us know if further clarification is needed."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700571360957,
                "cdate": 1700571360957,
                "tmdate": 1700571434676,
                "mdate": 1700571434676,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5ydpMHKtvJ",
                "forum": "j511LaqEeP",
                "replyto": "Jzxm8j66jX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5857/Reviewer_wGbj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5857/Reviewer_wGbj"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for replying to my review comments and questions. In particular:\n\n- Thanks for adding the section on how to choose weights. This is helpful. Again, I'm still a little unconvinced of the utility here, as it gives us intuition about how standard CRC will fail if exchangeability does not hold, but not a concrete correction. That intuition is already quite straightforward to see from the original extensions in CRC. Still, I do appreciate the more comprehensive derivation that was done to also include weighting as in Barber (vs. the simpler bound in CRC).\n- I'm still not sure that it's clear enough that weights need to be independent from the data points for this bound to hold (switching to \"relevance\" is still ambiguous). I also think that this should be stated directly as an assumption in Thm. 3.1.\n-  Finally, though a nitpick, as per my original comments, I don't really see that fact that losses can be bounded in [A, B] vs [0, B] as a \"significant\" difference over CRC, as written in the related work."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700677448648,
                "cdate": 1700677448648,
                "tmdate": 1700677448648,
                "mdate": 1700677448648,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qKuiMh1dno",
            "forum": "j511LaqEeP",
            "replyto": "j511LaqEeP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5857/Reviewer_2JpW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5857/Reviewer_2JpW"
            ],
            "content": {
                "summary": {
                    "value": "The paper describes how to perform conformal risk control for non-exchangeable data in the split conformal setting. It is shown that the proposed method has adaptive coverage guarantees, and performs well on a mixture of real-world and synthetic settings."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper connects two modern techniques in conformal prediction, and is thus very relevant for the community. It is well-written and easy to follow as an expert. The writing is simple, and I expect the paper will also be easy-to-follow for readers unfamiliar with conformal prediction."
                },
                "weaknesses": {
                    "value": "The method combines previous work in a relatively straightforward way. The proof of Theorem 1 does not introduce new techniques. The experiments follow settings proposed in previous works. The paper is solving a completely new problem, and naturally, there are no baselines for it. \n\nThus, while the proposed method is novel and useful, the paper would be strengthened with a more in-depth theoretical/experimental study. Some suggestions are,\n- Writing down full-conformal and cross-conformal versions of the proposed method\n- Considering new experimental settings, such as established ML distribution shift datasets\n- Discussion on how one can set the weights in practice\n- An interpretation of Theorem 1 for a non-expert in conformal\n- A discussion around the implication of Theorem 1 for specific types of distribution shift\n\nFor instance, for the synthetic experiment in Sec 4.1, some questions that can be considered are, \n- What is the exact coverage guarantee of Theorem 1? Could you put it on the plot and compare it to the obtained coverage? \n- Are there some \"optimal\" weights that give close-to optimal coverage? \nSimilar questions can be considered for the other experiments, although the true TV is not known, so the authors would have to think of other ways of analyzing the experiment. \n\n## Small errors/questions: \n- Just below eq. (5), C_\\lambda' should be C_{\\lambda'}\n- Sec 2.3: \"loss is nonincreasing\": nonincreasing in which parameter and in what sense?"
                },
                "questions": {
                    "value": "Please look at questions in the \"Weaknesses\" section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5857/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699238176073,
            "cdate": 1699238176073,
            "tmdate": 1699636619946,
            "mdate": 1699636619946,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TkCPMyJS9U",
                "forum": "j511LaqEeP",
                "replyto": "qKuiMh1dno",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5857/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your positive reviews! We already incorporated some of your suggestions in the updated manuscript. In particular, we added some discussion following our main result in $\\S3$, after Eq. 8, giving some intuition on which circumstances our results are useful; we also included a new subsection ($\\S3.2$) that suggests a strategy for regularized minimization of the coverage gap inspired by the maximum entropy principle, providing further justification for the use of weights with an exponential decay in time series under a distribution shift, which we use in the experiments of $\\S4.1$ and $\\S4.2$.\n\n> Just below eq. (5), C_\\lambda' should be C_{\\lambda'}\n\nThanks for pointing this out, we fixed the typo.\n\n> Sec 2.3: \"loss is nonincreasing\": nonincreasing in which parameter and in what sense?\n\nThe loss should be nonincreasing with respect to $\\lambda$. In practice, if we construct predictions sets of the form $\\mathcal{C}\\_{\\lambda}(\\cdot)$, with larger $\\lambda$ yielding larger prediction sets, then the loss function must shrink as $\\mathcal{C}\\_{\\lambda}(\\cdot)$ grows. We clarified this in the manuscript ($\\S2.3$)."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700261659172,
                "cdate": 1700261659172,
                "tmdate": 1700261659172,
                "mdate": 1700261659172,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]