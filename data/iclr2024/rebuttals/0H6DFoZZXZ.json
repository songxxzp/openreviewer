[
    {
        "title": "Language Control Diffusion: Efficiently Scaling through Space, Time, and Tasks"
    },
    {
        "review": {
            "id": "UUmTO7PzHM",
            "forum": "0H6DFoZZXZ",
            "replyto": "0H6DFoZZXZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3982/Reviewer_74cS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3982/Reviewer_74cS"
            ],
            "content": {
                "summary": {
                    "value": "This paper aimed to introduce the hierarchical diffusion policy into robotics control based on language instructions, while this framework faces three challenges: direct long-horizon planning, non-task-specific representation, and computational inefficiency. By proposing a diffusion-based model named Language to Control Diffusion (LCD), this paper addressed these issues."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper is well-structured and technically sound. The core idea is to pretrain a state encoder and then utilize the latent diffusion model to instantiate high-level policy, generating high-level goals by following the language instruction. The generated goals are then fed into the low-level policy network to obtain the final action.  The empirical results show performance improvements over the previous approaches. The authors also provided many empirical insights of the utilization of diffusion model for visual decision making tasks, which is valuable."
                },
                "weaknesses": {
                    "value": "1. It appears that some crucial descriptions of the model are missing. For instance, there is little mention in the paper about how the state encoder is trained. After going through HULC[Mees et al., 2022a], I just noticed that the encoder is possibly the one in HULC model. Therefore, the author considers both the encoder and LLP to be pretrained. I suggest the author add the corresponding description because it is currently hard to find out this from the logical flow of the paper. It is still important to clarify the training objective and the structure of the state encoder and low-level policy.\n\n2. The novelty of the paper is limited, as it is a combination of diffusion model and HULC.\n\n3. The assumption of the dataset being optimal is very strong in real-world settings, which limits the applicability of the proposed method. \n\n4. The textual encoder -  T5-XXXL model in this paper - is quite large, which increases the inference time. Is it possible to use the textual encoder in CLIP?"
                },
                "questions": {
                    "value": "1. It seems low-level policy and the state encoder are coupled in HULC, is it possible to pretrain both modules separately via different objectives?\n\n2. What is the total number of parameters in LCD?\n\n3. Learning state mapping functions and latent planning models separately seems quite reasonable in RL tasks, is there a way to combine a pre-trained encoder on a more extensive visual dataset, similar to models like VQ-VAE used in Stable Diffusion, for state feature extraction, rather than pre-training the encoder solely on robot tasks?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3982/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3982/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3982/Reviewer_74cS"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3982/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698675114196,
            "cdate": 1698675114196,
            "tmdate": 1700501017886,
            "mdate": 1700501017886,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VH1sHE2vbb",
                "forum": "0H6DFoZZXZ",
                "replyto": "UUmTO7PzHM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3982/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3982/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "> We appreciate the thorough review and the valuable suggestions you've provided regarding the clarity of the state encoder, dataset optimality, and the usage of T5-XXL, each of which has helped us to reflect on and improve the manuscript. We would like to address each of these points specifically.\n\n**Weaknesses:**\n\n1.  It appears that some crucial descriptions of the model are missing. For instance, there is little mention in the paper about how the state encoder is trained. After going through HULC[Mees et al., 2022a], I just noticed that the encoder is possibly the one in HULC model. Therefore, the author considers both the encoder and LLP to be pretrained. I suggest the author add the corresponding description because it is currently hard to find out this from the logical flow of the paper. It is still important to clarify the training objective and the structure of the state encoder and low-level policy.\n\n>  We have added a [new section in Appendix C](https://i.imgur.com/wvYxnf9.png) in the paper to help clarify the choice of state encoder.\n    \n> We confirm that the state encoder is not explicitly trained, but rather is just the output of a hidden layer within the low-level policy. We attempted to illustrate this in [Figure 1](https://i.imgur.com/4OPlRqG.png), although recognize this may have been unclear. \n    \n>We have tried our best to clarify our definition and choice of state encoder, and now reference Appendix C in the [introduction](https://i.imgur.com/Ogo0poi.png), the end of the [background](https://i.imgur.com/Ogo0poi.png), and in [Section 3.2](https://i.imgur.com/6TjIN27.png).\n    \n    \n2.  The novelty of the paper is limited, as it is a combination of diffusion model and HULC.\n\n > We respectfully disagree with the reviewer's assessment. It is nontrivial to combine diffusion models as a high level policy (HLP) in hierarchical RL with a low level policy (LLP). \n\n> Naively combining the two immediately leads to several problems - choosing a principled representation for the diffusion model to output becomes an issue, and simply training end-to-end would lead to a nonstationary objective for the diffusion model (as the data distribution is changing) [1]. We have this ablation in [Table 1](https://i.imgur.com/PqpVOGx.png) as Diffuser-1D and Diffuser-2D, which significantly underperform all other models. On the other hand, trying to avoid these issues by training the diffusion model directly to output videos is computationally expensive [2] and also models task-irrelevant details, which may lead to failure in generalization [3] (Please see their [Appendix A.1](https://i.imgur.com/1lDr7uh.png). It is not obvious how to simultaneously solve the nonstationarity, efficiency, and representation problem.    \n    \n> We propose a novel solution to the representation and efficiency problem by proposing the usage of a frozen pretrained LLP representation. This is not an obvious solution. Furthermore, we give a principled motivation for this choice with our suboptimality theory in Proposition 3.1. Finally, we solve the nonstationarity problem by proposing a latent two-stage training approach, by freezing the LLP during the HLP diffusion training.\n    \n> To the best of our knowledge, no other paper has proposed or instantiated a successful latent diffusion planner, let alone with language conditioning. In our work, we are able to demonstrate both the theoretical and empirical effectiveness of such an approach.  Empirically our model significantly outperforms all other methods, and does so 3.3x to 15x faster than other diffusion-based approaches.\n    \n>  [1] Sohl-Dickstein et al. Deep Unsupervised Learning using Nonequilibrium Thermodynamics. ICML, 2015.\n> [2] Rombach et al. High resolution image synthesis with latent diffusion models. In  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 10684\u201310695, 2022.\n> [3] Du et al. Video Language Planning. arxiv, 2023. \n    \n3.  The assumption of the dataset being optimal is very strong in real-world settings, which limits the applicability of the proposed method.\n   \n> Empirically we have found that our method works well even when this optimality assumption is violated, as the data in the CALVIN benchmark is in fact suboptimal [4]. We do acknowledge that there is a gap between the theory and practice and have now explicitly detailed this gap in the paper [here](https://i.imgur.com/bQPcAXt.png)  in Appendix G.\n\n> [4] Mees et al. Calvin: A benchmark for language-conditioned policy learning for long-horizon robot manipulation tasks. IEEE Robotics and Automation Letters, 2022b.\n    \n4.  The textual encoder - T5-XXXL model in this paper - is quite large, which increases the inference time. Is it possible to use the textual encoder in CLIP?\n\n> Thank you for the suggested ablation. We are currently running these experiments now, and will update you when they have finished running."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700060373547,
                "cdate": 1700060373547,
                "tmdate": 1700060373547,
                "mdate": 1700060373547,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ppNorkfVaE",
                "forum": "0H6DFoZZXZ",
                "replyto": "q7BM5xYP7b",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3982/Reviewer_74cS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3982/Reviewer_74cS"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "I want to thank the authors for their explanation and additional experimental results, it does solve some questions for me. I remain somewhat uncertain about whether to accept this paper. The empirical results of this paper, I believe, are quite insightful. However, the novelty of the methodology may be somewhat limited, despite the authors arguing that their method is non-trivial. Therefore, I am unsure about accepting this paper. Nevertheless, considering the inspiration I have drawn from this paper and the authors' earnest responses, I will, for now, raise my score to 6. This does not, however, indicate my final support for the acceptance of this paper. Should any reviewer strongly oppose its acceptance, I will take their opinion into consideration. Conversely, if the majority deems the paper sufficient over the ICLR's bar, I will agree with them."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700501000222,
                "cdate": 1700501000222,
                "tmdate": 1700501000222,
                "mdate": 1700501000222,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "C7yxLXp9wz",
            "forum": "0H6DFoZZXZ",
            "replyto": "0H6DFoZZXZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3982/Reviewer_FYfw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3982/Reviewer_FYfw"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies text-to-control problems and proposes Language to Control Diffusion models as a hierarchical planner conditioned on language (LCD). This hierarchical approach scales the diffusion model along the spatial, time, and task dimensions."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is clearly written and easy to follow.\n2. The proposed hierarchical approach makes intuitive sense to scale the control diffusion models.\n3. The authors provide both theoretical guarantees and experimental results."
                },
                "weaknesses": {
                    "value": "1. The authors stated that the proposed algorithm avoids \"the usage of a predefined low level skill oracle\". Isn't the low-level controller also adopted by LCD in this work? Do the authors refer to the imitation learning setting where we only access to the trajectories instead of the controller?\n2. Can the authors comment more on the difference between the proposed method and previous text-to-video works, such as [1, 2]? Again, the authors mentioned that \"they again avoid the issue of directly generating low level actions by using a low-level controller or an inverse dynamics model which we are able to directly solve for\", but I didn't see the the downside of leveraging low-level controllers.\n3. Besides, I would like to know if these text-to-video methods are directly comparable to LCD in experiments.\n4. It is not very clear to me what dom(P(s'|s, a)) measures and the intuitive sense behind it. For terms that are not commonly used in RL theory, it would be better to state its definition and intuition of the proof/bound. It is also not clear what the circle means in the definition of the low-level policy.\n5. The theorem comes before the practical instantiation of the algorithm. The gaps between theory and practice should be explicitly analyzed.\n\n[1] Learning Universal Policies via Text-Guided Video Generation.\\\n[2] VIDEO LANGUAGE PLANNING."
                },
                "questions": {
                    "value": "Please see the weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3982/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698729664848,
            "cdate": 1698729664848,
            "tmdate": 1699636359792,
            "mdate": 1699636359792,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "89iObGakQs",
                "forum": "0H6DFoZZXZ",
                "replyto": "C7yxLXp9wz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3982/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3982/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "> We appreciate the reviewer's insightful questions and valuable critique. To summarize, we have addressed concerns about the role of low-level controllers, differences between our method and other text-to-video works, the comparability of these methods in experiments, the clarification of certain terms and symbols, and the gaps between theoretical and practical applications in our approach. We trust that our responses below will provide a more comprehensive understanding of our research and its implications. \n\n**Weaknesses:**\n\n1.  The authors stated that the proposed algorithm avoids \"the usage of a predefined low level skill oracle\". Isn't the low-level controller also adopted by LCD in this work? Do the authors refer to the imitation learning setting where we only access to the trajectories instead of the controller?\n\n> Here, we refer to two disparate assumptions that we avoid:\n\t> 1. We do not have a perfect low-level controller or inverse dynamics model. This is exactly as you say above. Instead, we must learn a low-level policy (LLP) in our setting.\n\t> 2. We do not define a fixed set of predefined skills between the high-level policy and the low-level controller, also known as the \"communication interface\".  For example, in Saycan [1] the high level policy chooses between a set of skills like {find apple, place coke, go to table}. In our setting, we do not assume that such a set has been defined.\n\n> [1] Ahn et al. Do as i can, not as i say: Grounding language in robotic affordances, 2022. https://arxiv.org/abs/2204.01691\n3.  Can the authors comment more on the difference between the proposed method and previous text-to-video works, such as [1, 2]? Again, the authors mentioned that \"they again avoid the issue of directly generating low level actions by using a low-level controller or an inverse dynamics model which we are able to directly solve for\", but I didn't see the the downside of leveraging low-level controllers.\n\n\t\n[1] Learning Universal Policies via Text-Guided Video Generation.  \n[2] VIDEO LANGUAGE PLANNING.\n\n> Thank you for raising this important point. Here are two reasons why avoiding low-level controllers may be advantageous:\n\n> 1. **Non-Transferability Across Domains**: Many domains do not have a readily available predefined low-level controller, and constructing such a controller requires extensive work that is domain-specific [3]. Once built, these controllers are often not transferable to other contexts, limiting their applications to the scenarios for which they were originally designed. Predefined controllers may restrict the ability of a model to generalize to new contexts or tasks. They are often tailored to specific skill sets and may not support unanticipated actions or sequences that were not considered during their development. This limitation becomes evident when we encounter a requirement for a novel skill or action that the existing low-level controller does not support.\n\n> 2. **Complexity in Construction**: A low-level controller can be intricate to construct [4], particularly in environments that involve many degrees of freedom or require nuanced motor control. The development process can be labor-intensive and may require expert knowledge in robotics, motor control, or specific domain physics.\n\n>[3] Hatze et al. The fundamental problem of myoskeletal inverse dynamics and its implications\n\n>[4] Hitzler et al. \"Learning and Adaptation of Inverse Dynamics Models: A Comparison,\" IEEE-RAS 19th International Conference on Humanoid Robots (Humanoids), Toronto, ON, Canada, 2019, pp. 491-498, doi: 10.1109/Humanoids43949.2019.9035048.\n\n> We defer our answer on the difference between our method and previous text-to-video works below."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700060203452,
                "cdate": 1700060203452,
                "tmdate": 1700060203452,
                "mdate": 1700060203452,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "niHJXiAv7j",
                "forum": "0H6DFoZZXZ",
                "replyto": "C7yxLXp9wz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3982/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3982/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "4.  Besides, I would like to know if these text-to-video methods are directly comparable to LCD in experiments.\n\n> We give two main points of comparison between text-to-video methods and LCD here:\n\n> 1. **Robustness of Communication Interface**: Text-to-video methods rely heavily on a high-quality decoder or skill oracle capable of generalizing well across various contexts  (see [Appendix A.1](https://i.imgur.com/1lDr7uh.png) of Video Language Planning). The quality of these components is critical for their success, and performance can degrade if these elements do not generalize well. Our approach incorporates this inductive bias and performs diffusion directly in the latent goal space of the decoder rather than in the image space, which often hallucinates (see [Figure XII of Video Language Planning](https://i.imgur.com/VvI9Wvx.png),  [related work in Tune-A-Video](https://i.imgur.com/S0mWtGe.png) [5]) and is significantly more computationally expensive.  Thus, our method potentially offers more consistent results in a wider range of scenarios.\n\n> 2. **Efficiency and Accessibility**: Our LCD method was designed with efficiency in mind. Text-to-video methods may indeed give better performance in some scenarios where large-scale compute is accessible. However, this is often not an option for individual researchers or small-scale labs. LCD provides an agile and less resource-demanding alternative, enabling rapid iteration and experimentation with diffusion planners.\n\n> In conclusion, when comparing with text-to-video methods, LCD offers a valuable and pragmatic solution for research settings where computational resources or the ability to develop complex decoders and communication interfaces are limited. We believe that the LCD's advantages, particularly in terms of efficiency and robustness, make it a worthwhile alternative for many practical applications.\n\n> [5] Wu, Jay Zhangjie, et al. \"Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation.\" _Proceedings of the IEEE/CVF International Conference on Computer Vision_. 2023.\n\n5.  It is not very clear to me what dom(P(s'|s, a)) measures and the intuitive sense behind it. For terms that are not commonly used in RL theory, it would be better to state its definition and intuition of the proof/bound. It is also not clear what the circle means in the definition of the low-level policy.\n\n> $\\text{dom}(P(s'|s, a))$ is the size of the set of possible next states, or more formally the cardinality of the domain of the transition dynamics function. In the definition $\\pi_{lo}(s) := \\phi \\circ E(s)$  ,  the $\\circ$ symbol refers to function composition. We have added these definitions for clarity [in Section 3.1](https://i.imgur.com/xcu1Pik.png).\n\n7.  The theorem comes before the practical instantiation of the algorithm. The gaps between theory and practice should be explicitly analyzed.\n\n> We appreciate the reviewer's thoughtful recommendation. Following this guidance, we have elaborated on this aspect and included a new section in [Appendix G](https://i.imgur.com/bQPcAXt.png) of our paper. We trust this addition clarifies the point and strengthens our argument.\n\n> We believe that our comprehensive rebuttal and modifications emphasize the strength and scalability of our research, with the capacity to influence future advancements in the field. We hope that our responses have sufficiently met your queries and concerns. This paper's potential to enhance scalability and advancement toward longer horizons could greatly contribute to this research area. Thank you very much for your thoughtful evaluation of our research, and we eagerly look forward to your continued feedback."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700060221948,
                "cdate": 1700060221948,
                "tmdate": 1700060293750,
                "mdate": 1700060293750,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0YbY9p4M4w",
                "forum": "0H6DFoZZXZ",
                "replyto": "niHJXiAv7j",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3982/Reviewer_FYfw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3982/Reviewer_FYfw"
                ],
                "content": {
                    "comment": {
                        "value": "This addresses most of my concerns. Thank the authors for the clarification."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700632341937,
                "cdate": 1700632341937,
                "tmdate": 1700632341937,
                "mdate": 1700632341937,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7yiZml58ZC",
            "forum": "0H6DFoZZXZ",
            "replyto": "0H6DFoZZXZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3982/Reviewer_z6e9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3982/Reviewer_z6e9"
            ],
            "content": {
                "summary": {
                    "value": "In this work, the authors propose to scale diffusion models for planning in extended temporal, state, and task dimensions to tackle long-horizon control problems conditioned on natural language instructions. Specifically, they take a hierarchical diffusion approach by training diffusion policy to plan in the latent plan (induced by a frozen low-level policy) every c steps (temporal abstraction). They leverage the language-conditioning capabilities of existing diffusion architecture to learn language-conditioned hierarchical policies."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ The proposed approach achieves SOTA performance on a recently proposed language robotics benchmark\n+ The method is well-motivated and reasonable"
                },
                "weaknesses": {
                    "value": "The weakness comes from a combination of lack of originality and broadness of the experiments. While the approach is very reasonable (applying language-conditioned latent diffusion in the abstracted state and action space for high-level planning), its general idea is similar to the ones in the literature (e.g., [1]). The major differences are the use of diffusion models and the specific choice of temporal abstraction. Based on this, I would like to see more experiment evidence, e.g., beyond the CALVIN benchmark, or real-world experiments (as in SPIL).\n\n[1] Parrot: Data-Driven Behavioral Priors for Reinforcement Learning"
                },
                "questions": {
                    "value": "See \u201cweaknesses\u201d"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3982/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3982/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3982/Reviewer_z6e9"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3982/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698999254250,
            "cdate": 1698999254250,
            "tmdate": 1699636359710,
            "mdate": 1699636359710,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LjlH2fieRd",
                "forum": "0H6DFoZZXZ",
                "replyto": "7yiZml58ZC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3982/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3982/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "> We are grateful to the reviewer for their valuable comments, which allows us to emphasize the novelty of our diffusion model framework. We also justify our choice of the CALVIN benchmark as a testing ground and respond to requests for more extensive experimental evidence.\n\n**Weaknesses:**\n\nThe weakness comes from a combination of lack of originality and broadness of the experiments. While the approach is very reasonable (applying language-conditioned latent diffusion in the abstracted state and action space for high-level planning), its general idea is similar to the ones in the literature (e.g., [1]). The major differences are the use of diffusion models and the specific choice of temporal abstraction. \n\n> We respectfully disagree with the reviewer's assessment. We would like to clarify that our main novelty comes from being the first to propose utilizing the implicit encoder of a pretrained low level policy for use in a latent language diffusion model and demonstrating both the effectiveness and efficiency of such an approach. On the other hand, PARROT [1] does not incorporate language and therefore must learn a new high level policy per task. In addition, it uses a generative model (normalizing flow) for the low-level policy (LLP), which is a more restrictive class of models than general low level policies. We are able to generalize [zero-shot to new tasks](https://i.imgur.com/zniB6aD.png) through language, and do not need to make such assumptions on the LLP.\n\n> Our method innovatively integrates diffusion models into hierarchical RL as a high-level policy, overcoming common pitfalls. A naive approach combining the two grapples with an unprincipled nonstationary objective [2] if trained end-to-end, which we show in [Table 1](https://i.imgur.com/PqpVOGx.png) as Diffuser-1D and Diffuser-2D. These baselines significantly underperform all other models. Alternative strategies, like two-stage training a text-to-video diffusion model after training the LLP, are not only resource-intensive but also capture unnecessary details that impede generalization [3, 4]. \n\n> Our approach crafts a novel solution to these challenges by leveraging a frozen, pretrained low-level policy representation \u2013 a non-obvious choice that we defend with our suboptimality theory (Proposition 3.1). We further address the nonstationarity issue with a latent two-stage training protocol, enhancing both efficiency and performance. Empirically our model significantly outperforms all other methods, and does so 3.3x to 15x faster than other diffusion-based approaches.\n    \n> To the best of our knowledge, no other paper has proposed or instantiated a successful latent diffusion planner, let alone with language conditioning. In our work, we are able to demonstrate both the theoretical and empirical effectiveness of such an approach.\n\n>  [1] Parrot: Data-Driven Behavioral Priors for Reinforcement Learning\n>  [2] Sohl-Dickstein et al. Deep Unsupervised Learning using Nonequilibrium Thermodynamics. ICML, 2015.\n> [3] Rombach et al. High resolution image synthesis with latent diffusion models. In  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 10684\u201310695, 2022.\n> [4] Du et al. Video Language Planning. arxiv, 2023. (Please see their [Appendix A.1](https://i.imgur.com/1lDr7uh.png))\n    \nBased on this, I would like to see more experiment evidence, e.g., beyond the CALVIN benchmark, or real-world experiments (as in SPIL).\n\n> Our work stands out as the first to leverage a pretrained latent encoding within a new diffusion planning framework, offering unique efficiency and effectiveness as substantiated by our results.\n\n> We would like to emphasize that we believe the current experimental evaluation is sufficient for showing the effectiveness of our LCD approach. The choice of the CALVIN benchmark was deliberate; it is a well-established and challenging benchmark that tests for both the efficacy and efficiency of high-level planning and control in a complex environment. Our results on this benchmark clearly demonstrate the practical benefits of the proposed LCD method over existing techniques, thereby validating our contributions despite the perceived overlap with earlier works.\n\n> Moreover, we are also aware of the imperative to demonstrate the generalizability and applicability of LCD. To this end, we are in the process of setting up additional experiments on the CLEVR Robot Env and will update you later with these findings. These will further substantiate our claims and illustrate the versatility and robustness of the LCD framework beyond the CALVIN benchmark.\n\n> In conclusion, while we acknowledge the reviewer\u2019s call for further experimental evidence, we maintain that our current experiments are both relevant and convincing for the scope of this study. Additional experiments, though underway, should be seen as extending rather than essential to the core contributions of the work."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700060076115,
                "cdate": 1700060076115,
                "tmdate": 1700060076115,
                "mdate": 1700060076115,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gvNyV0EzQF",
                "forum": "0H6DFoZZXZ",
                "replyto": "7yiZml58ZC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3982/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3982/Authors"
                ],
                "content": {
                    "title": {
                        "value": "New benchmark results"
                    },
                    "comment": {
                        "value": "Dear z6e9,\n\nWe wish to bring to your attention that we have posted new benchmark results, providing new data that may have a bearing on the evaluation of our work. These results have been rigorously obtained and we believe they contribute positively to the overall strength and validity of our research. \n\nWe trust that the supplementary results and thorough answers provided sufficiently address the issues highlighted, prompting a reevaluation of the initially given score. Thank you very much for your time and thoughtful consideration. We are grateful for the expertise and effort you bring to the review process."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700702803260,
                "cdate": 1700702803260,
                "tmdate": 1700702803260,
                "mdate": 1700702803260,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "pImdNaXavL",
            "forum": "0H6DFoZZXZ",
            "replyto": "0H6DFoZZXZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3982/Reviewer_fAWH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3982/Reviewer_fAWH"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a novel hierarchical framework called LCD, which leverages a language-conditioned diffusion model as a high-level goal planner on top of HULC. The proposed model achieves scalability in the spatial, time, and task dimensions. It outperforms other baselines on the CALVIN benchmark."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed method is simple and effective, achieving scalability in the spatial, time, and task dimensions.\n2. By employing a hierarchical decision-making approach, the algorithm reduces the model size and inference time.\n3. The authors experimentally demonstrate that vanilla Diffuser fails to successfully replan in high-dimensional state spaces when using a Variational Autoencoder (VAE). This provides insights for researchers interested in using Diffuser for planning tasks with image state spaces."
                },
                "weaknesses": {
                    "value": "1. In Section 4.5 of the experiments, the parameter sizes of MLP and Transformer are significantly smaller than the parameters of Diffusion. This may introduce unfairness in the experiments. Additionally, I did not notice a detailed explanation of how the authors perform inference using MLP and Transformer. Since the authors employ a Diffusion planning paradigm as HLP, it may be worth considering a better comparison with planning-based MLP (e.g., model-based RL) and Transformer (e.g., Decision Transformer)."
                },
                "questions": {
                    "value": "1. The experimental results seem to indicate that HULC plays an important role in the success of LCD. Do the authors believe that the performance of LCD necessarily relies on a well-trained HULC baseline? Can LCD still achieve excellent performance with a simple goal-conditioned policy and a well-designed RL encoder representation? Alternatively, if a HULC baseline is used, can a Transformer with a parameter size comparable to the Diffusion HLP achieve similar performance?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3982/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699009036759,
            "cdate": 1699009036759,
            "tmdate": 1699636359589,
            "mdate": 1699636359589,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wMpO7YHEPA",
                "forum": "0H6DFoZZXZ",
                "replyto": "pImdNaXavL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3982/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3982/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "**fAWH**\n\n> We thank the reviewer for their perceptive questions and feedback on the performance of inference using the MLP and Transformer ablation, considerations of parameter size in making comparisons, and the role of HULC as a baseline in LCD. In the responses following, we have sought to address each point in detail. We hope our clarifications will elucidate a better understanding of our approach and its potential to influence this research field.\n> \n**Weaknesses:**\n\n1.  Additionally, I did not notice a detailed explanation of how the authors perform inference using MLP and Transformer.\n\n> Regarding the inference procedure using MLP and Transformer, we have since added a [new section](https://i.imgur.com/MwzAO6s.png) in Appendix E that provides a detailed explanation. Appendix E also includes a more detailed treatment of the hyperparameters for the transformer ablation. \n\n In Section 4.5 of the experiments, the parameter sizes of MLP and Transformer are significantly smaller than the parameters of Diffusion. This may introduce unfairness in the experiments.\n> We would like to note that for this experiment we rigorously tested several model sizes for the Transformer to ensure a fair comparison, ultimately reporting results for the most performant Transformer; this Transformer has a smaller parameter count than our Diffusion model. The hyperparameters for this gridsearch can be found in [Appendix E.2](https://i.imgur.com/bBuJJPf.png). However, we found the performance of the Transformer is still significantly lower than LCD, as evidenced in Section 4.5.   Notably, we have since run [further experiments](https://i.imgur.com/b4vmUgj.png) with a similar-sized MLP (25.5M params vs LCD 20.1M params) that further reinforce our original findings.\n\n Since the authors employ a Diffusion planning paradigm as HLP, it may be worth considering a better comparison with planning-based MLP (e.g., model-based RL) and Transformer (e.g., Decision Transformer).\n \n > In this setting, we strove to give the ablations as much advantage as possible, and in order to keep simplicity and ease the learning objective for the ablations we did next-state prediction rather than planning. Generally, it has been found empirically that the MLP does not work well in MBRL and trajectory generation [1, 2], so we chose only next-state prediction as the objective. We gave the same objective for the transformer to ensure uniformity.\n\n >[1] Janner, et al. Offline reinforcement learning as one big sequence modeling problem,  Advances in neural information processing systems 2021.\n\n> [2] Chen, et al. Decision transformer: Reinforcement learning via sequence  modeling.  Advances in neural information processing systems, 2021\n> \n**Questions:**\n\n3.  The experimental results seem to indicate that HULC plays an important role in the success of LCD. Do the authors believe that the performance of LCD necessarily relies on a well-trained HULC baseline? Can LCD still achieve excellent performance with a simple goal-conditioned policy and a well-designed RL encoder representation? Alternatively, if a HULC baseline is used, can a Transformer with a parameter size comparable to the Diffusion HLP achieve similar performance?\n\n>  We would like to clarify that we used HULC for our low-level policy for two main reasons. First, we aimed to leverage the strongest existing baseline to maximize our chances of creating a SOTA model. Second, we encountered issues replicating the results for the GCBC flat policy from its original paper, making it less favorable for our approach. It is important to note that there is, in principle, no reason why LCD cannot work with a flat policy, and this would be a straightforward addition for future work. We kindly refer you to [Appendix C](https://i.imgur.com/Fl1mYy2.png), where we have also explicitly clarified this point in our paper.\n\n> We want to reiterate that we did not find a Transformer with a comparable parameter size that was able to achieve similar performance to LCD.\n\n---\n> We are confident that our thorough response and amendments underscore the robustness and scalability of our work, potentially driving future progress in the field. We trust that these responses adequately address your concerns. We believe that this paper's potential to further scale to longer horizons and improved generalization could make a significant impact on this research topic, and are extremely grateful for your review of our work. We look forward to your continued feedback."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700059853962,
                "cdate": 1700059853962,
                "tmdate": 1700059853962,
                "mdate": 1700059853962,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]