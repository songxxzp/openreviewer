[
    {
        "title": "Poly-View Contrastive Learning"
    },
    {
        "review": {
            "id": "dnOEn2ndwM",
            "forum": "iHcTLIor0m",
            "replyto": "iHcTLIor0m",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6489/Reviewer_PqKH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6489/Reviewer_PqKH"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies contrastive learning by matching more than two related views, which is called poly-view contrastive learning. Unlike traditional contrastive learning methods that take pairs of tasks, it increases the view multiplicity and investigates the design of SSL tasks that use many views. Experiments show that it is beneficial to decrease the number of unique samples while increasing the number of views of each sample."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The idea of designing contrastive learning methods using poly-view seems novel. It utilizes an observation from the prior works that using multiple positive views improves the performance. The paper is well-written."
                },
                "weaknesses": {
                    "value": "Although there are prior works showing that multiplicity improves generalization and convergence of neural networks, it lacks rigorous theory on the relation between contrastive learnability and the number of views on each sample."
                },
                "questions": {
                    "value": "I wonder how strong the theory on multiplicity can be. Is it possible to specify how exactly the number of views on each example improves the algorithmic performance? Would it be essential on the average number of views, or maximal number? Does there exist a threshold on the number of views, such that once it exceeds the threshold, more views do not help?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6489/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698637800327,
            "cdate": 1698637800327,
            "tmdate": 1699636727339,
            "mdate": 1699636727339,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0apIKsS7qo",
                "forum": "iHcTLIor0m",
                "replyto": "dnOEn2ndwM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6489/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6489/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for taking the time to read our work. We are happy you found the paper well-written and that you appreciate the benefits of being able to trade off batch size against views as well as the additional insights we provide about self-supervised learning algorithm design.\n\nPlease find below our comments on the raised issues and questions: \n\n### *W1/Q1: Although there are prior works showing that multiplicity improves generalization and convergence of neural networks, it lacks rigorous theory on the relation between contrastive learnability and the number of views on each sample. I wonder how strong the theory on multiplicity can be.*\n\nTwo-view MI objectives found in prior works on contrastive learning are a proxy to the InfoMax objective for representation learning. Our theory shows that one need not limit themselves to two-view MI to achieve InfoMax, but rather many other alternatives exist that use more positive views. Our paper studies One-vs-Rest MI, multiplicity being a controllable parameter and two-view being the case when the multiplicity $M=2$, yielding the following theoretical and empirical results:\n1. Using multiple views in a pairwise comparison as in Multi-Crop, while reducing the variance of the MI estimator, does *not* result in a better bound for InfoMax (Proposition 2.1 and 2.2).\n2. New contrastive losses that include multiple positive views, such as Arithmetic and Geometric PVC provide a tighter lower-bound on InfoMax  (Theorem 2.3).\n3. Sufficient statistics with minimal assumption also introduce a way of including more positive views into account. For a specific choice of sufficient statistics, we prove a connection between sufficient statistics and One-vs-Rest MI (Theorem 2.4) which shows that sufficient statistics also benefit from the above properties of One-vs-Rest MI.\n4. Using synthetic and real-world (ImageNet1k) datasets, these theorems were validated in practical settings.\n\nPlease provide clarification regarding definitions of:\n- Strength of multiplicity theories, and\n- Contrastive learnability\n\nin the case where we have not addressed your concerns.\n\n### *Q2: Does there exist a threshold on the number of views, such that once it exceeds the threshold, more views do not help?*\n\nIn the Growing Batch case (Figure 3, top row), one should always maximize the multiplicity $M$ as this provides the tightest bound on InfoMax (Theorem 2.3, 2.4). \n\nIn the Fixed Batch case where the total number of views $V=K\\times M$ is held constant as $M$ increases, the answer is more interesting.\nPrompted by your comment, in Appendix E.5 we investigate this scenario in more detail with a simplified form of Geometric PVC, and are able to prove there does exist an optimal multiplicity $M^*$. Thank you for prompting us with this comment.\n\nThank you again for the time you took reading our work and providing the questions above. The additions to the work regarding Fixed Batch view multiplicity in particular have improved the work's overall completeness."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6489/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700097983340,
                "cdate": 1700097983340,
                "tmdate": 1700097983340,
                "mdate": 1700097983340,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rlUOvp9vhI",
            "forum": "iHcTLIor0m",
            "replyto": "iHcTLIor0m",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6489/Reviewer_P4Q6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6489/Reviewer_P4Q6"
            ],
            "content": {
                "summary": {
                    "value": "The paper investigates the effect when introducing view multiplicity in contrastive learning. Specifically, the paper gives a generic information-theoretic derivation of such multi-view framework and shows that SimCLR loss is a special case of the derived `poly-view' contrastive learning. The paper concluded from the theoretical foundation that higher view multiplicity enables a new contrastive learning where, surprisingly, it is beneficial to reduce the batchsize and increase multiplicity. The paper also associate their  theoretical findings with experiments."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper delves into the impact of incorporating multiple perspectives in contrastive learning. The strength include: \n\nS1: it presents a comprehensive information-theoretic analysis of this multi-view approach and establishes that the SimCLR loss can be considered as a special case of the resulting 'poly-view' contrastive learning. \n\nS2: Based on the theoretical framework, the research concludes that greater view multiplicity facilitates a novel form of contrastive learning, wherein it proves unexpectedly advantageous to decrease the batch size while augmenting the multiplicity. \n\nS3: Furthermore, the paper justifies these theoretical discoveries with empirical experiments."
                },
                "weaknesses": {
                    "value": "However, the paper has several weakness that worths further discussion. \n\nW1: What is the exact loss function the paper used to define the poly-view contrastive learning? It seems the Eq. (22) is the poly-view contrative loss, whereas it is in a very high level abstract and implicit form, making it hard to interprete how to compute the empirical loss for the terms, and why M=2 links to SimCLR. I recommend to make the loss in a more explicit form of empirical losses and interpretation (e.g., what is the used sufficient statistics for M=2 for SimCLR? ) \n\nW2: Empirical evidence lacks suitable interpretation and linkage to the significance of the theorems. For significance, I mean how we can use the theorem takeaways to practically improve the SSL algorithms? I expect to see the evidence on larger dataset with mainstream architecture such as ResNet and ViT/transformer with longer epochs. \n\nW3: It is unclear to me if the multiplicity of views simply benefits from more equivalent of epochs (in the experiments) or whether the exposure to the number of data has been constrained to be exactly same between the poly-view contrastive learning and other baselines. \n\nW4: There is no comparison between the proposed method and SOTA method, in terms of how the method contributes to and improves the SOTA methods under the theoretical foundations."
                },
                "questions": {
                    "value": "Please see the 4 weakness above for questions to be addressed."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6489/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6489/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6489/Reviewer_P4Q6"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6489/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698776859511,
            "cdate": 1698776859511,
            "tmdate": 1700624480468,
            "mdate": 1700624480468,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qtnxKKeaie",
                "forum": "iHcTLIor0m",
                "replyto": "rlUOvp9vhI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6489/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6489/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer P4Q6 (1/2)"
                    },
                    "comment": {
                        "value": "Thank you for taking the time to read and review our work. We are happy you appreciated the theoretical analysis of view multiplicity and the empirical justifications of the theoretical analysis.\n\nPlease find below our comments on the raised issues and questions: \n\n### *W1.1: What is the loss for PVC?*\nMinimizing the PVC losses maximizes the MI lower bounds of Theorem 2.2. Based on your comment we have clarified the corresponding equations, making it clear what the loss is. Additionally, the full pseudo-code for all loss computations is provided in Appendix F.2.5, allowing any reader to follow the loss computation line by line and reproduce our results.\n\n### *W1.2: How does M=2 link to SimCLR?*\nIn Appendix E.2 we show how $M=2$ gives SimCLR for PVC. We have now added an equivalent derivation for sufficient statistics.\n\n### *W2.1: Empirical evidence lacks suitable interpretation and linkage to the significance of the theorems. For significance, I mean how we can use the theorem takeaways to practically improve the SSL algorithms?*\nThe PVC and Sufficient Statistic algorithms are a direct consequence of Theorems 2.2 and 2.4 respectively. These theorems tell you how to construct a Poly-View loss function. Without the theorems, one can use heuristics and develop Multi-Crop, which Poly-View methods outperform in all of our experiments.\n\nIn the synthetic case (Section 3.1) we observe experiments directly following theorems from Section 2. For example, increasing multiplicity $M$ increases One-vs-Rest MI as derived in Section 2.3.1 on data processing inequality. We also observe One-vs-Rest MI empirically converges to $\\mathcal I(x_\\alpha; c)$ which, as discussed in Section 2.3.1, is the upper bound for One-vs-Rest MI.\n\nThe ImageNet1k experiments follow similarly. Geometric and Sufficient Statistics with higher multiplicity $M$ provide tighter MI bounds and a better proxy for InfoMax, resulting in improved performance when holding other hyperparameters fixed (Figure 3a).\n\n### *W.2: I expect to see the evidence on larger dataset with mainstream architecture such as ResNet and ViT/transformer with longer epochs*\nPlease see Figure 3a for training and evaluation on ImageNet1k dataset, with a ResNet50 architecture trained for up to 1024 epochs.\n\n### *W.3: It is unclear to me if the multiplicity of views simply benefits from more equivalent epochs (in the experiments) or whether the exposure to the number of data has been constrained to be exactly the same between the poly-view contrastive learning and other baselines*\nWe were also concerned about this, and chose to focus on it in Section 3.2.\n\nFor Figure 3b, we train $M=2$ SimCLR models and $M=8$ Poly-View for 64, 128, 256, 512 and 1024 epochs. We do this either by holding the total number of views fixed (Fixed Batch. bottom row) which means we drop the batch size $B$ with increasing $M$, or allow total views to increase (Growing Batch, top row).\n\n1. To answer whether it is the total number of samples seen by the model, we can look at the leftmost column of Figure 3a. We see that Poly-View methods always outperform SimCLR.\n2. To answer whether it is the total number of updates seen by the model, we can look at the center column of Figure 3a. We see that Poly-View methods always outperform SimCLR.\n3. To answer whether it is the total compute spent on the model, we can look at the right column of Figure 3a. Poly-View methods outperform SimCLR only in the Fixed Batch case, but not in the Growing Batch.\n\nIf *effective epochs* corresponds to *total steps* then in the above scenario 2 we see that for the same amount of effective epochs, Poly-View methods still outperform non-Poly-View methods.\n\nWe have also added a fourth way of comparing models in Appendix F.2.4 where we show the Total FLOPs used to produce each model. The conclusion is consistent with comparisons based on Relative Compute.\n\nPlease let us know if anything else is still not clear."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6489/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700096108322,
                "cdate": 1700096108322,
                "tmdate": 1700096108322,
                "mdate": 1700096108322,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MTmtFhYi5C",
                "forum": "iHcTLIor0m",
                "replyto": "rlUOvp9vhI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6489/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6489/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Request for remaining issues"
                    },
                    "comment": {
                        "value": "Dear Reviewer P4Q6,\n\nWe thank you again for taking the time to read and review our work. We really appreciated your comments and questions that prompted a number of clarifications and missing section links to be included in the paper, which has improved the overall readability of the paper. In particular, the section discussing the Geometric and Arithmetic PVC loss definitions is now much clearer, thank you.\n\nPlease let us know if you have any issues remaining with the work.\n\nBest,\n\nThe Authors"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6489/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700519676262,
                "cdate": 1700519676262,
                "tmdate": 1700519756074,
                "mdate": 1700519756074,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dGlBkUxF0u",
                "forum": "iHcTLIor0m",
                "replyto": "MTmtFhYi5C",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6489/Reviewer_P4Q6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6489/Reviewer_P4Q6"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the further clarification"
                    },
                    "comment": {
                        "value": "As the authors adequately pointed out the concerns in both the theoretical part and empirical part, I have increased my score. I hope the updated version could make the explicit loss and its linkage to SimCLR clearer in the main paper, rather than in the appendix."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6489/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700624433458,
                "cdate": 1700624433458,
                "tmdate": 1700624433458,
                "mdate": 1700624433458,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "pconQFN5RO",
            "forum": "iHcTLIor0m",
            "replyto": "iHcTLIor0m",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6489/Reviewer_AhEA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6489/Reviewer_AhEA"
            ],
            "content": {
                "summary": {
                    "value": "Although it is possible to design tasks that drawn arbitrary number of views, contrastive works typically focus on pairwise tasks. So, this paper investigates how to match more than two related views in contrastive learning, and derive new learning objectives by information maximization and sufficient statistics. They show that multi-crop reduces the variance of corresponding paired objective but fail to improve bounds on MI; Then they derive new objectives which solve tasks across all views through information theory, and show that the MI Gap is monotonically non-increasing with respect to the number of views. Also, the poly-view contrastive method is beneficial to reduce the batch size and increase multiplicity."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Generalizing the information-theoretic foundations to poly-view is an interesting idea, and the One-vs-Rest MI seems to be quite reasonable.\n\n2. Those theoretical results are clear, the derivation process of the One-vs-Rest objective is convincing.\n\n3. The paper is well written and easy to follow."
                },
                "weaknesses": {
                    "value": "1. The assumption 3 in section 2.4.1 is kind of strong.\n\n2. The experiments do not show the superiority of poly-view contrastive learning. The computation time is not evaluated by real time, and the downstream performance is not displayed."
                },
                "questions": {
                    "value": "1. The experiments shown in section 3 display the relative compute of algorithms and show One-vs-Rest objectives could beat simCLR with the same relative compute, how about the real training complexity. And how does it perform on real downstream tasks.\n\n2. I cannot fully understand why the One-vs-Rest loss could effectively reduce the training epoch and batch size.\n\n3. The Geometric loss is actually also an extension of simCLR loss, just like Multi-Crop, but Geometric loss could be a tighter bound of MI while Multi-Crop cannot. It seems to be theoretically correct, but how can we understand it empirically.\n\n4. An extension of simCLR loss outperforms the carefully designed SUFFICIENT STATISTICS loss in section 3, does it mean that the poly-view contrastive learning works mainly because the superiority of simCLR loss?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6489/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699023137468,
            "cdate": 1699023137468,
            "tmdate": 1699636727093,
            "mdate": 1699636727093,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TnvHIg989s",
                "forum": "iHcTLIor0m",
                "replyto": "pconQFN5RO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6489/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6489/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer AhEA (1/2)"
                    },
                    "comment": {
                        "value": "Thank you for taking the time to read our work. We are happy you found the paper easy to read and you appreciate the benefits of tighter MI bounds, lower batch size, and reduced computational cost enabled by the Poly-View objectives, as well as the additional insight we provide about Multi-Crop.\n\nPlease find below our comments on the raised issues and questions: \n\n### *W1: Exponential family assumption is strong*\n\nOur representations are given by a neural network and are therefore finite-dimensional (2048 in the ResNet50 case), typical in self-supervised learning. As the sufficient statistics is a map to the representation space, according to the Fisher-Darmois-Koopman-Pitman (FDKP) theorem, for smooth nowhere vanishing probability densities, a finite-dimensional sufficient statistic exists if and only if the densities are from an exponential family (https://ieeexplore.ieee.org/document/4048925).\nI.e. the sufficient statistics are distributed according to the exponential family because they map to finite-dimensional representations.\n\nThe assumption of finite-dimensional representations is not strong in the context of self-supervised learning. \nThe exponential families that follow from this assumption are widely used in machine learning due to the availability of efficient methods as well as their tractability and interpretability. Many traditional distributions are in the exponential family, e.g. normal, exponential, log-normal, gamma, chi-squared, beta, Dirichlet, Bernoulli, categorical, Poisson, geometric, inverse Gaussian, von Mises, and von Mises-Fisher distributions.\nFinally, in self-supervised learning, the exponential families have appeared in many recent works, e.g. https://arxiv.org/abs/2102.08850, https://arxiv.org/abs/2203.07004, and https://proceedings.mlr.press/v89/hyvarinen19a.html.\n\nWe have reworded assumption 3 to make it clear it is a consequence of modeling representations using a neural network, and *not* an assumption. Thank you for highlighting this to us.\n\n### *W2: The experiments do not show the superiority of Poly-View contrastive learning*\n\nThe goal of our work is to understand how view multiplicity should be incorporated into contrastive learning from first principles and to investigate in a controlled ImageNet1k setting if there is any benefit to doing so in this way. Achieving state-of-the-art performance is not a goal of our work.\n\nWe found:\n- Increasing multiplicity of Poly-View methods always gives better performance than the fixed multiplicity method SimCLR (Fig 3a top row first two columns, Fig 3b)\n- Poly-View methods enable more compute-efficient design space than fixed multiplicity methods (Fig 3a bottom row final column).\n\nWe hope this helps clarify the purpose of our work and the benefits of a Poly-View approach which may be incorporated with orthogonal methods for increasing performance, e.g. increasing model size. We will continue to improve the clarity of the paper on this particular point. Please let us know if there is anything else you are looking for.\n\n### *W3/Q1: Computation time is not evaluated by real time*\n\nIn Figure 3 we evaluate computation time using:\n- Total training epochs  \n- Total updates\n- Relative Compute\n\nThese metrics capture different notions of time, as choosing only one or two of these metrics paints an incomplete picture. E.g., displaying only total updates does not take into account the practical consideration that a single update for one setting may require more computation than a single update for another, which would be captured by also including Relative Compute.\n\nThe three metrics above were also chosen as they are ML framework agnostic and hardware agnostic. Wall-clock time on the other hand can vary according to CUDA version, GPU model/compute capability network interconnect (e.g. infiniband/EFA availability). This makes wall-clock time difficult to use reproducibly.\n\nBased on your comment, we have included total FLOPs, another popular, reproducible measure of computation time, in Appendix F.2.4, to complete the picture. We have also added a comment that, assuming an optimal hardware setting and fully-parallel implementation, total updates is proportional to wall-clock time, which we hope addresses your primary concern. Thank you again for your comment."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6489/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700095527103,
                "cdate": 1700095527103,
                "tmdate": 1700095646209,
                "mdate": 1700095646209,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ystE9fXnjP",
                "forum": "iHcTLIor0m",
                "replyto": "pconQFN5RO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6489/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6489/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Request for remaining issues"
                    },
                    "comment": {
                        "value": "Dear Reviewer AhEA,\n\nWe thank you again for your thoughtful comments and questions. The resulting changes have increased the completeness and readability of the work.\n\nWe are still working to produce the requested fine-tuning results and will post them upon completion.\n\nPlease let us know if you have any other issues remaining with the work.\n\nBest,\n\nThe Authors"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6489/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700519229044,
                "cdate": 1700519229044,
                "tmdate": 1700519243183,
                "mdate": 1700519243183,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Rr6ltMTdwz",
                "forum": "iHcTLIor0m",
                "replyto": "pconQFN5RO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6489/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6489/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Requested results for fine-tuning on transfer tasks"
                    },
                    "comment": {
                        "value": "Dear Reviewer AhEA,\n\nWe are happy to let you know that the majority of our fine-tuning transfer evaluations are complete and have been added to Appendix F.2.2.\n\nFor equivalent hyperparameters, we compared SimCLR against Growing Batch and Shrinking Batch variations of Geometric PVC. We did this for both small and large amounts of pre-training epochs, then fine tuning on a suite of natural tasks.\n\nOn the majority of natural tasks, Geometric PVC significantly outperforms SimCLR, and for the remaining tasks they are statistically equivalent according to standard statistical tests. This demonstrates the utility of Poly-view methods on real tasks, addressing the outstanding W4/Q1. Thank you again for suggesting this investigation to us.\n\nPlease let us know if you have any other issues remaining with the work.\n\nBest,\n\nThe Authors"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6489/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700586777629,
                "cdate": 1700586777629,
                "tmdate": 1700594466061,
                "mdate": 1700594466061,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zVPU448ixd",
            "forum": "iHcTLIor0m",
            "replyto": "iHcTLIor0m",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6489/Reviewer_ymcZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6489/Reviewer_ymcZ"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposed a multi-view (against the previous 2-view) contrastive learning, they provide theoretical and empirical evidence that their derived multi-view loss is better than previous multi-crop loss, as it provides a tighter lower bound on the generalized mutual information. They also provide real data evidence showing that their multi-view loss allows more efficient learning compared with previous two-view contrastive learning like SimCLR."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper investigated an interesting angle of contrastive learning: instead of increasing batch size, they increase the number of views. They provide a solid theoretical framework for their proposal, linking their proposed multi-view loss with previous SimCLR loss and the InfoMax framework. They also provide detailed analysis for comparing these two losses both theoretically and empirically. Overall it is clearly written and easy to follow, and the theoretical analysis aligns with the empirical findings is another big plus. Overall, they provide a new angle to improve the contrastive learning idea, which I believe might unleash further power of self-supervised learning."
                },
                "weaknesses": {
                    "value": "I just have one suggestion: maybe you can comment (or leave for future work) about how other self-supervised learning can fit in your framework, or how your idea can be extended to other SSL methods like BYOL etc."
                },
                "questions": {
                    "value": "I have no questions."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6489/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6489/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6489/Reviewer_ymcZ"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6489/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699041651304,
            "cdate": 1699041651304,
            "tmdate": 1699636726986,
            "mdate": 1699636726986,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "m9h5zSMHu8",
                "forum": "iHcTLIor0m",
                "replyto": "zVPU448ixd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6489/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6489/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for taking the time to read our work. We are happy you appreciate the empirical and theoretical validation of the Poly-View contrastive methods, their practical benefits as measured by efficiency, and recognize the broad applicability for improving self-supervised learning.\n\nPlease find below our answer to your raised question.  \n\n### *Q1: I just have one suggestion: maybe you can comment (or leave for future work) about how other self-supervised learning can fit in your framework, or how your idea can be extended to other SSL methods like BYOL etc.*\n\nOur primary contributions use the frameworks of information theory and sufficient statistics to investigate what is possible in the presence of a view multiplicity $M>2$, and derive the different Poly-View objectives from first principles.\n\nIt is possible to incorporate multiplicity $M>2$ into a distillation setup like BYOL (https://arxiv.org/abs/2006.07733). For example, DINOv1 (https://arxiv.org/abs/2104.14294), which shares many algorithmic parts of BYOL, benefits a lot from using the pair-wise Multi-Crop task that we describe in Section 2.2 and Appendix D (although in DINOv1, there is more than one augmentation policy).\n\nOne option for extending distillation methods like BYOL/DINOv1 from Multi-Crop to Poly-View type tasks in a One-vs-Rest sense is to have the EMA teacher produce $M-1$ logits, which are aggregated into a single logit (similar to the sufficient statistics choice for $Q$ in Equation 24) for producing the target pseudo-label distribution.\nThe gradient-based student could then be updated based on its predictions from the held-out view, and this procedure aggregated over all the view hold-outs.\n\nSuch a procedure is very interesting and definitely worth future consideration.\nThe core difference between the distillation procedure above and the Poly-View contrastive methods is that the large-view limit of Poly-View contrastive methods is provably a proxy for InfoMax (Section 2.1 and Equation 27). There may be a way to obtain theoretical guarantees for the large-view distillation methods (using for example tools from https://arxiv.org/abs/2307.10907), and could prove an interesting future direction for investigation.\n\nWe have included a discussion regarding extensions of other self-supervised learning methods in Appendix H. Again, we appreciate the time you took to read our work and share your valuable comments and enthusiasm."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6489/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700094335479,
                "cdate": 1700094335479,
                "tmdate": 1700094372054,
                "mdate": 1700094372054,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]