[
    {
        "title": "Emergent Communication with Conversational Repair"
    },
    {
        "review": {
            "id": "7qW0ZGPwSC",
            "forum": "Sy8upuD6Bw",
            "replyto": "Sy8upuD6Bw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5874/Reviewer_3F5Q"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5874/Reviewer_3F5Q"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a basic notion of communication failure and opportunity\nfor recovery into the standard emergent communication signalling game.\nCommunication failure occurs when one of the sender's tokens is replaced with\na special noise token, and the listener is provided with a binary feedback\nchannel that could be used to indicate the need for recovery.  The empirical\nresults show that the binary feedback channel provides an increase in\nperformance in the presence of such noise but is not necessary in the noiseless\ncases.  This effect is robust across different hyperparameters as well as with\nboth symbolic and image embedding-based observations."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is coherent: it has a simple, well-defined scope that is explained\nwell, pursued with reasonable methods, and has empirical data with supports the\nmain contribution with appropriate ablations.  While the contributions are not\nextensive or revolutionary, I do not see this as a problem because the\ncontributions are sufficient and the quality of the paper as a whole makes\na good building block in the field's body of literature."
                },
                "weaknesses": {
                    "value": "I do not see any major weaknesses in the paper as a whole.  Any specific areas\nthat could be improved upon are mentioned in \"Questions\".  What puts my rating\nat an 8 instead of 10 is primarily the modest significance of the\ncontributions.\n\nA minor weakness is that there is no robust/empirical explanation for the cause\nof the drop in topographic similarity in the feedback-enabled agents."
                },
                "questions": {
                    "value": "- Page 2:\n    - Section 2.2: [Travis LaCroix's paper](https://www.semanticscholar.org/paper/Biology-and-Compositionality%3A-Empirical-for-LaCroix/6422d5e83caec99487936035cfbb2b0d18f2a76d) on reflexivity could be relevant\n- Page 5:\n    - \"instable\" -> \"unstable\"\n    - It would be better to use 95% confidence intervals instead of raw standard error\n    - Discussion: \"jointly co-constructing\" seems pretty relevant to Kottur et al. (2017), maybe a sentence connecting the two works would be appropriate\n    - \"lack vision-and-language\" -> \"lack of vision-and-language\"?\n    - Would it be possible to give a sense of what the correlation between the\n      presence of the noise token and the feedback request from the receiver\n      is?  It's not necessary for all of the experiments, maybe just the\n      initial basic ones."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5874/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698531508653,
            "cdate": 1698531508653,
            "tmdate": 1699636622503,
            "mdate": 1699636622503,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LQ4F2n00GS",
                "forum": "Sy8upuD6Bw",
                "replyto": "ZX3Wn3Go1U",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5874/Reviewer_3F5Q"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5874/Reviewer_3F5Q"
                ],
                "content": {
                    "title": {
                        "value": "Responding to above weaknesses"
                    },
                    "comment": {
                        "value": "While I believe that this review brings up good points to consider about the\npaper, I think it over-weights the degree to which the potential weaknesses\nundermine the contributions.\n\n> Methods: The most significant concern is that the apparent lack of\n> compositionality (arguably the 'headline' result) is an artifact of the\n> specific choice of how to inject noise (via random i.i.d. replacement with\n> a special token).\n\nI do not think the lack of compositionality is or should be the headline\nresult.  I believe that it is a good ancillary finding, but overall,\ncompositionality---especially something as simple as toposim---is not an\nadequate measure of how \"good\" or \"human like\" or \"important\" an emergent\nlanguage is (cf. [1] for issues with toposim directly and [2] for\ncompositionality in EC more generally).  Thus, I would argue that it acceptable\nfor the paper to make the observation it does without spending much time\ndigging deeper.\n\n> Modeling misunderstanding, uncertainty over meaning or interpretation at the\n> message level, rather than uncertainty over the literal content of each\n> message token, would better reflect the cases where repair arises in\n> real-world communication.\n\nUncertainty over meaning is certainly an interesting topic, but uncertainty\nover content is highly relevant to human communication (e.g., having\na conversation at loud party, talking to someone who mumbles).\n\n> Originality: While some details of the specific implementation here is novel,\n> a number of prior works have also introduced interactive repair mechanisms\n> into signaling games and are not discussed.examples.\n\nThe paper would definitely benefit from positioning itself explicitly vis-a-vis\nthe paper mentioned in the review, but so far as I can tell, these paper are\nnot specifically within the domain of \"deep learning-based emergent\ncommunication\" which has its own unique methods and concerns.  Therefore,\nI would argue that it is actually helpful to use a framework which has been\nstudied before in closely related contexts (although, again, mentioning them\nand contextualizing itself are important here).\n\n### References\n\n- [1] Korbak et al., 2020, https://arxiv.org/abs/2010.15058\n- [2] Kharitonov & Baroni, 2020, https://aclanthology.org/2020.blackboxnlp-1.2/"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5874/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700163986277,
                "cdate": 1700163986277,
                "tmdate": 1700163986277,
                "mdate": 1700163986277,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TJOANFnvT7",
                "forum": "Sy8upuD6Bw",
                "replyto": "7qW0ZGPwSC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5874/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5874/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks a lot for your thorough review!\n\nRegarding the drop in topsim scores:\n- As mentioned by Reviewer p6xc, the sender\u2019s messages in the feedback case depend on both the input object and the receiver\u2019s feedback. In our response to this review, we investigated whether calculating topsim scores that also take into account the receivers messages (by concatenating the sender messages and the receiver messages) leads to improved topsim scores. This is however not the case: These scores are even lower than the original topsim scores (model with $p_{noise}=0.7$, $(|A|, |V|) =  (4, 4)$: topsim_sender_receiver=0.15+-0.02 | topsim=0.19+-0.02). One possible confound with this approach however is that the dimensionality of the meaning space is increased in the feedback case, which makes the topsim scores not directly comparable anymore to the scores in the non-feedback case.\n- We believe that topographic similarity is actually not an appropriate measure for compositionality in this game. As you also mentioned in your response to Reviewer R7xc (\u201cResponding to above weaknesses\u201d), there is increasing evidence for the inadequateness of this measure. Most recently, [1] proposed 4 measures of linguistic variation, which are more appropriate as they correlate (negatively) with generalization performance. One possible explanation for the drop in topographic similarity is therefore that it is simply not the adequate measure. Future work should explore whether other measures such as linguistic variation are better at reflecting the compositionality/ regularity of emerging languages. Most related to the work at hand, new metrics that take into account the feedback messages of the listener will be required.\n\nRegarding Travis LaCroix's paper on reflexivity\n- Thanks, this paper offers new interesting perspectives. We integrated it into the discussion of the updated manuscript. The lack of compositionality found in our study could indeed provide further evidence that other aspects of human languages, such as reflexivity, should be taken into account. \n\nRegarding the discussion: \"jointly co-constructing\" seems pretty relevant to Kottur et al. (2017), maybe a sentence connecting the two works would be appropriate\n- This is indeed very related, we added a footnote (Footnote 7) to the updated version of the manuscript.\n\n\nWould it be possible to give a sense of what the correlation between the presence of the noise token and the feedback request from the receiver is? It's not necessary for all of the experiments, maybe just the initial basic ones.\n- We made efforts to analyze the semantics of the feedback messages of the receiver agents in the updated version of the manuscript. (See also response to Reviewer p6xc and Section 4.1.1. in the updated paper)\n\n\nOther points/typos:\n- \"instable\" -> \"unstable\" and \"lack vision-and-language\" -> \"lack of vision-and-language\": Done\n\n- It would be better to use 95% confidence intervals instead of raw standard error: Done\n\n\n[1] Conclin & Smith 2023 Compositionality with Variation Reliably Emerges between Neural Networks"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5874/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700674731268,
                "cdate": 1700674731268,
                "tmdate": 1700674731268,
                "mdate": 1700674731268,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "G5sP2JcpdO",
            "forum": "Sy8upuD6Bw",
            "replyto": "Sy8upuD6Bw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5874/Reviewer_p6xc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5874/Reviewer_p6xc"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduced a new Lweis signaling game setup with a noisy communication channel for emergent communication. Through experiments in logical and pixel-level input, they showed that setups with the receiver\u2019s feedback can achieve better generalization performance in a noisy environment. By reporting the topographical similarity, it also points out that a better generation does not usually mean a higher compositionality."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This paper considers a novel setup with multi-step communication with the receiver\u2019s feedback. It changes the original unidirectional communication to bidirectional communication, which can better resemble realistic human communication scenarios.\n\n2. The experiments designed multiple evaluation groups to test how a feedback channel helps alleviate the effects of noise, influence generalization, and compostionality. The experiments introducing realistic image referential tasks with objects in the same visual background also look interesting. The performance contrast between compositionality and generalizability and the potential cause of the receiver\u2019s feedback is worth further investigation."
                },
                "weaknesses": {
                    "value": "The current experiments only show that communication with the receiver\u2019s feedback will generalize better in a noisy environment. It would be more comprehensive to understand this feedback behavior with further analysis:\n\n    a. The semantics of the feedback token: for example, is it more related to interaction regulation (continue to talk, no need to talk) or the attribute of the objects (clarification on some attributes)? \n\n    b. The messages updated by the sender: based on the receiver\u2019s feedback, how the sender\u2019s messages vary across different time steps. \n\n    c. Through multiple iterations, will the receiver provide less feedback or less informative feedback while they gradually build their common ground?\n\n    d. Will the emerged languages with additional feedback make the sender\u2019s messages of different objects more separatable?"
                },
                "questions": {
                    "value": "1. How does the game end? Will they communicate a fixed number of time steps?\n2. How does the receiver generate the feedback token, through another MLP layer besides the one used in the final target selection?\n3. The drops in the compositionality are interesting. Since the sender\u2019s message now depends on both the symbolic input and the receiver\u2019s feedback, the semantic spaces could be disturbed. Have you tried to let the sender and the receiver share the same vocabulary?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5874/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5874/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5874/Reviewer_p6xc"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5874/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698625629490,
            "cdate": 1698625629490,
            "tmdate": 1699636622389,
            "mdate": 1699636622389,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "eaxXfztj5X",
                "forum": "Sy8upuD6Bw",
                "replyto": "G5sP2JcpdO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5874/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5874/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Many thanks for your review!\n\nRegarding the weaknesses:\n- a: We made efforts to try and understand the semantics of the feedback token in the latest updated version of the manuscript (Section 4.1.1). In short, the feedback messages are most likely used for both (1) a form of message acknowledgement, signaling the received message back to the sender and (2) to signal some information about the input objects back to the sender (who does not have access to both objects). The exact semantics of the feedback signals are not trivially decodable, but we demonstrate through additional experiments that the models come up with a messaging protocol that is more efficient than a simple signal indicating the presence of noise back to the sender.\n- b: This is very related to the previous question, and is depending on a better understanding of the feedback signal of the receiver.\n- c: This is a very important point. The nature of feedback during the training iterations is surely developing, however, we do not have a notion of what is \u201cmore\u201d or \u201cless\u201d feedback as the feedback signal of the receiver is not directly interpretable (also the receiver is always sending a feedback message, there is currently no option to stay silent implemented). More generally, in the current setup there is always noise on the communication channel, which means that some form of feedback will stay useful even for 2 agents who already established a common ground. Future work could additionally explore agent populations, in which some agents speak more often to some than to others, in order to explore effects of pre-established common ground between speakers. (see also [1])\n- d: More distinct messages for different objects allow for a higher discrimination performance. As we indeed observe a higher test accuracy, we conclude that most likely these senders produce more separatable messages.\n\nRegarding the other questions:\n- 1: Yes, limited by the message length |M|\n- 2: Yes, the feedback token is generated using a separate linear layer dedicated only for the feedback production.\n- 3: We do not intend to have the sender and receiver share the same vocabulary, as the idea is to create independent agents that only exchange information using the communication channel. As we are attempting to model human language evolution, we do not consider that a shared vocabulary is pre-existing between different agents.\nIt is true that the sender\u2019s messages in the feedback case depend on both the input object and the receiver\u2019s feedback. We tried calculating topsim scores that also take into account the receivers messages (by concatenating the sender messages and the receiver messages) and found that these scores are even lower than the original topsim scores (e.g. model with $p_{noise}=0.7$, $(|A|, |V|) =  (4, 4)$: topsim_sender_receiver=0.15+-0.02 | topsim=0.19+-0.02). \nMore recently, a number of works also started criticizing the use of topsim to measure compositionality in emergent communication [2,3]. Our work adds additional evidence for the weakness of this metric.\n\n[1] Graesser et al. 2020 Emergent Linguistic Phenomena in Multi-Agent Communication Games\n\n[2] Conclin & Smith 2023 Compositionality with Variation Reliably Emerges between Neural Networks\n\n[3] Korbak et al. 2020 Measuring non-trivial compositionality in emergent communication"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5874/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700653789964,
                "cdate": 1700653789964,
                "tmdate": 1700653789964,
                "mdate": 1700653789964,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZX3Wn3Go1U",
            "forum": "Sy8upuD6Bw",
            "replyto": "Sy8upuD6Bw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5874/Reviewer_R7xc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5874/Reviewer_R7xc"
            ],
            "content": {
                "summary": {
                    "value": "The paper explores the effects of conversational repair mechanisms on emergent communication in signaling games. The basic Lewis signaling game setup is extended to allow bidirectional communication through an interleaved feedback channel from receiver to sender. Noise is added to the communication channel by replacing tokens at random. Models trained with a feedback channel are found to achieve higher generalization performance under noisy conditions, even though the resulting languages are less compositional."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The experiments are interesting, testing multiple game configurations and noise levels. The code is open-sourced. Results are robust across settings and replicated in two different game paradigms. The paper clearly explains the methods, results, and implications. Allowing conversational repair is clearly an important step towards better models of human language evolution."
                },
                "weaknesses": {
                    "value": "Methods: The most significant concern is that the apparent lack of compositionality (arguably the 'headline' result) is an artifact of the specific choice of how to inject noise (via random i.i.d. replacement with a special token). Modeling *misunderstanding*, uncertainty over *meaning* or *interpretation* at the message level, rather than uncertainty over the literal content of each message token, would better reflect the cases where repair arises in real-world communication. \n\nOriginality: While some details of the specific implementation here is novel, a number of prior works have also introduced interactive repair mechanisms into signaling games and are not discussed. Even the classic Steels (1995) simulations included a form of (binary) repair. Here are some salient examples from the more recent literature. \n\n- van Arkel, Woensdregt, Dingemanse, & Blokpoel. (2022). A simple repair mechanism can alleviate computational demands of pragmatic reasoning: simulations and complexity analysis. CoNLL.\n- Tria, Galantucci, & Loreto (2012). Naming a structured world: A cultural route to duality of patterning. Plos ONE. \n- de Ruiter & Cummins. (2012). A model of intentional communication: AIRBUS (Asymmetric Intention Recognition with Bayesian Updating of Signals). SemDial. \n- Silva & Roberts. (2016). Exploring the role of interaction in the emergence of linguistic structure. EVOLANG.\n- White, Poesia, Hawkins, Sadigh, & Goodman. (2022). Open-domain clarification question generation without question examples. EMNLP. \n\nAdditional weaknesses:\n\n* The feedback channel only allows binary signals. It's unclear how the results would be affected by a higher-dimensional space of feedback. \n* Noise is only added to sender messages, but realistically noise would affect receiver feedback too, possibly shrinking the gap between the feedback vs. no-feedback models.\n* No comparison to recent related work like van Arkel et al. is provided to situate the advances here.\n\nIn summary, while this work provides a good first investigation, the contributions are somewhat modest and incremental given prior exploration of feedback channels. It's difficult to know which aspects of the findings are general consequences of repair mechanisms, and which aspects are artifacts of specific choices about how noise is injected in this task setup. Addressing the above limitations would strengthen the novelty and significance of the study."
                },
                "questions": {
                    "value": "* Typo: \u201cdefined by the number of symbols in the vocabulary V\u201d \u2014 the vocabulary was previously denoted by X; V was defined was the set of possible values the attributes may take."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5874/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5874/Reviewer_R7xc",
                        "ICLR.cc/2024/Conference/Submission5874/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5874/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699242434316,
            "cdate": 1699242434316,
            "tmdate": 1700248436299,
            "mdate": 1700248436299,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "eOcc3qWaiI",
                "forum": "Sy8upuD6Bw",
                "replyto": "ZX3Wn3Go1U",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5874/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5874/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your thoughtful review! \n\n- We share the concern that the lack of compositionality could be an artifact of the specific implementation of noise. The goal of this project was to investigate the effect of conversational repair in the most basic setting (random replacement of message tokens with a noise token), which could e.g. translate to the real-world phenomenon of a listener not understanding a word because of some increased background noise. Indeed, there are many other possible situations in which conversational repair routines are employed, such as misunderstandings. The most basic implementation to model this phenomenon is to randomly permute a message token with another token from the vocabulary (instead of a special noise token). We ran the main experiments from the paper with this alternative noise implementation, and report the results in Section 4.1.3 of the updated version. The main conclusions hold: Models trained with feedback generalize better but produce less compositional languages. Future work should investigate the effect of even more noise implementations, such as combinations of non-understanding (noise token) and misunderstanding, as well as non-uniform distributions of noise. \n\n- Thanks for the very relevant references. We integrated them in the related work section of the updated manuscript and contextualize our work respectively. Our main contribution in comparison to these works is that we explicitly investigate the effect of a feedback channel by directly comparing models with and without feedback. Further, we employ deep-learning based modeling which scales to more realistic input, instead of only small-scale toy-language setups. This enabled us to perform the experiments described in Section 4.3.\n\n- It is true that the nature of the feedback will most likely change if the dimensionality of the feedback channel is increased. Instead of simple open clarification requests and/or acknowledgements, the model could leverage mechanisms such as restricted clarification requests or restricted offers. However, as the vocabulary size of the speaker is currently set to 2, we don\u2019t think that an increase in the feedback channel dimensionality is actually useful in our setup. (We verify this claim by running a model with a feedback vocabulary size of 10, and find that it does not improve generalization performance: For a noise level of 0.9, the test accuracy drops from 0.75 (stddev: 0.07) to 0.70 (stddev: 0.07). As this slight drop is within the standard deviation, we assume it's caused by effects of the random initialization. Future work should investigate models with higher vocabulary sizes combined with increased feedback channel sizes.\n\n- Regarding noise on the feedback messages from the receiver: Yes, this has been discussed as a meaningful extension in Section 5, and will definitely be subject of future work.\n\n- Thanks as well for spotting the typo, this has been fixed."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5874/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700240639901,
                "cdate": 1700240639901,
                "tmdate": 1700657651118,
                "mdate": 1700657651118,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8Q6DjmBCG7",
                "forum": "Sy8upuD6Bw",
                "replyto": "eOcc3qWaiI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5874/Reviewer_R7xc"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5874/Reviewer_R7xc"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the thoughtful response, and the additional experiments. I still believe this work is somewhat 'undercooked' compared to other ICLR papers, but I will increase my score by a few points to reflect the strength of the revisions."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5874/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700248403408,
                "cdate": 1700248403408,
                "tmdate": 1700248403408,
                "mdate": 1700248403408,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]