[
    {
        "title": "A Neural Framework for Generalized Causal Sensitivity Analysis"
    },
    {
        "review": {
            "id": "XWW9ODWetS",
            "forum": "ikX6D1oM1c",
            "replyto": "ikX6D1oM1c",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3435/Reviewer_ijNf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3435/Reviewer_ijNf"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a neural framework for generalized causal sensitivity analysis that aims to achieve lower and upper bounds for some causal queries when exact identification is not possible due to unobserved confounding. Specifically, the framework leverages two normalizing flows to encode the latent distributions that are compatible with the observed ones and optimize the causal quantities of interest and can be used to approximate previous sensitivity analysis models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The writing is clear, and the paper is easy to follow.\n2. The proposed neural network-based causal sensitivity analysis method is effective and general, which is compatible with previous studies like MSM and f-sensitivity models and can be easily extended to other models by modifying the constraints that specify the strength of unobserved confounding."
                },
                "weaknesses": {
                    "value": "The experiments, to some extent, appear to be lacking in comprehensiveness. The semi-synthetic datasets utilized in this study are exclusively derived from the MIMIC-III dataset. The findings derived from this single source may not offer an adequate illustration of the model's performance."
                },
                "questions": {
                    "value": "I noticed that the authors apply the augmented Lagrangian method to incorporate the sensitivity constraints in the optimization process. I wonder to what extent could the constraints be satisfied since the constraint now becomes a soft one that may well be violated. It is possible that the effective constraint parameter $\\Gamma$ achieved by the optimization significantly deviates from the intended value, which may make the final bounds less useful. Additionally, I am concerned about the stability of training the normalizing flows, as instability in this aspect could further exacerbate the situation."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3435/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3435/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3435/Reviewer_ijNf"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3435/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697877855507,
            "cdate": 1697877855507,
            "tmdate": 1699636295812,
            "mdate": 1699636295812,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wEugayPVgT",
                "forum": "ikX6D1oM1c",
                "replyto": "XWW9ODWetS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3435/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3435/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ijNf"
                    },
                    "comment": {
                        "value": "Thank you for your helpful review! We took all your comments at heart and improved our paper as follows.\n\n\n## Response to \u201cWeaknesses\u201d\n\n\n\n* Semi-synthetic experiments: We would like to emphasize that we not only evaluate NeuralCSA on semi-synthetic but also on various purely synthetic datasets (as common in causal inference [1, 2]). Nevertheless, we agree that additional experiments on semi-synthetic data are a great opportunity to demonstrate the effectiveness of our method.\n\n    **Action:** We provided **additional experimental** results using a semi-synthetic dataset based on the IHPD dataset [5] (see **new Appendix H.3**). The results confirm the validity of our bounds obtained via NeuralCSA.\n\n\n\n## Response to \u201cQuestions\u201d\n\n\n\n* Violation of sensitivity constraints: You are correct in that we leverage the Augmented Lagrangian method (AL) to incorporate the sensitivity constraints into Stage 2 of NeuralCSA (Algorithm 1). One reason why we chose AL is that **AL is specifically designed not to violate the constraint set** for a fixed constraint parameter. This is in contrast to other methods for constrained optimization (e.g., adding the sensitivity constraint as a penalty to the Stage 2 loss). Intuitively, the parameter $\\mu^{(i)}$ is growing exponentially with respect to the number of epochs $i$, ensuring that the sensitivity violation $s_{x, a}$ converges to $0$. In practice, it is not necessary to let $\\mu^{(i)}$ converge infinity to satisfy the constraint [3], which is what we also observe in our experiments. For a more comprehensive discussion on this and AL in general, we refer to [3]. Furthermore, the violation of the sensitivity constraint can be estimated during training, such that the number of epochs may be adjusted accordingly. In summary: **The achieved sensitivity parameter $\\Gamma$ in our experiments always coincides with its intended value** (up to small numerical errors). As such, the bounds we obtain in our experiments directly correspond to the chosen sensitivity parameters.\n\n    **Action**: We added a clarification for the above point in our implementation paragraph (see Sec. 5.3).\n\n* Training of normalizing flows: It is true that our learning algorithm is more complex than comparable closed-form solutions (e.g., for MSM). However, even such closed-form solutions often require estimating a conditional distribution. As such, neural methods for conditional density estimation are common in the sensitivity analysis literature [1, 2]. We also would like to emphasize that we do not claim that NeuralCSA archives better performance than existing closed-form solutions. Rather, we propose our NeuralCSA as a method for causal sensitivity analysis whenever bounds are not analytically tractable (see Table 1). We argue that, in such settings, a certain complexity is expected by any approach that aims at deriving bounds. In our experiments, we observed that the training of NeuralCSA was very stable, as indicated by a low variance over different runs (see e.g., Fig. 4). Furthermore, there are a variety of methods available to improve training stability for conditional normalizing flows, e.g. noise regularization [4], which could be applied if necessary.\n\n    **Action:** We added a discussion to Appendix E.\n\n\n\n## References\n\n[1] Frauen et al. (2023). \u201cSharp Bounds for Generalized Causal Sensitivity Analysis\u201d. NeurIPS\n\n[2] Jesson et al. (2021). \u201cQuantifying Ignorance in Individual-Level Causal-Effect Estimates under Hidden Confounding\u201d. ICML.\n\n[3] Nocedal and Wright (2006). Numerical optimization. Springer series in operations research. Springer, New York, 2nd ed. edition, 2006. ISBN 0387303030 \n\n[4] Rothfuss et al. (2020). \u201cNoise Regularization for Conditional Density Estimation\u201d \tarXiv:1907.08982\n\n[5] Hill (2011). \u201cBayesian nonparametric modeling for causal inference\u201d. Journal of Computational and Graphical Statistics"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3435/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700160443886,
                "cdate": 1700160443886,
                "tmdate": 1700230737700,
                "mdate": 1700230737700,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "M7wJb8Fbk9",
            "forum": "ikX6D1oM1c",
            "replyto": "ikX6D1oM1c",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3435/Reviewer_MpUG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3435/Reviewer_MpUG"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a generalized sensitivity analysis framework that is compatible with many different sensitivity models, including the marginal sensitivity model, f-sensitivity model, and Rosenbaum's sensitivity model. The framework is suitable for different treatment types and different causal queries. The authors propose to learn the latent distribution shift with two separately trained conditional normalizing flows."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The concise summary of sensitivity models enhances the paper's readability and flow.\n- The authors introduce a novel learning strategy to model the latent distribution.\n- Experiments with both synthetic and real-world data are used to demonstrate the validity and effectiveness of the proposed method."
                },
                "weaknesses": {
                    "value": "- It is not very obvious how does the bounds the proposed framework compares with some existing works such as GMSM. \n- The section 5.1 might be a little hard to follow. Please find some questions I have below."
                },
                "questions": {
                    "value": "- Regarding the color coding in equation (4), does it indicate the parameters for the optimization problem? Does the right supremum also maximize over $P(U|x,a)$?\n- I'm not fully understand the two-stage procedure. Could you to provide a more detailed explanation about replace the right supremum with \n fixed of $\\mathbb{P}^*(U|x,a)$ and $\\mathbb{P}^*(Y|x,u,a)$?\n- In relation to the optimization problem presented in equation (5), are there specific constraints placed on the functional $\\mathcal{D}_{x,a}$ to ensure that the global optimal can be achieved?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3435/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3435/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3435/Reviewer_MpUG"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3435/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698651593251,
            "cdate": 1698651593251,
            "tmdate": 1699636295740,
            "mdate": 1699636295740,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "cWMzAwgw4D",
                "forum": "ikX6D1oM1c",
                "replyto": "M7wJb8Fbk9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3435/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3435/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer MpUG"
                    },
                    "comment": {
                        "value": "Thank you for your positive review and your helpful comments! \n\n\n## Response to \u201cWeaknesses\u201d\n\n\n* The GMSM (proposed by [1]) extends the standard MSM/ CMSM in two major ways: (i) It allows for _mediators_, thus enabling sensitivity analysis for direct/indirect/path-specific effects, and (ii) it allows for the incorporation of _weights_ into the sensitivity model that represent prior knowledge about the confounding structure. Point (i) is not relevant in our setting as we do not consider mediators. Extending NeuralCSA to settings with mediators may be an interesting direction for future work. For point (ii), we kindly refer you to Appendix C: Therein, **we show that the weighted GMSM can be reformulated as a GTSM, which makes NeuralCSA applicable**. For example, NeuralCSA could be used to perform sensitivity analysis for multiple outcomes under a weighted GMSM, which was previously not possible using the bounds in [1]. We would like to emphasize that we do not claim that NeuralCSA archives better performance than existing closed-form solutions (e.g., bounds for the GMSM in single-outcome settings). Rather, we propose our NeuralCSA as a method for causal sensitivity analysis whenever bounds are not analytically tractable (see Table 1). Furthermore, note that the bounds in [1] are not applicable to sensitivity models beyond MSM-type (e.g., $f$-sensitivity models, Rosenbaum\u2019s sensitivity model), yet for which our NeuralCSA is applicable.\n\n\n## Response to \u201cQuestions\u201d\n\n* In Eq. (4), the coloring highlights the components of the joint probability distribution that appear in the causal query, i.e., the optimization objective. The optimization happens over the components that appear just below the suprema, that is, both $\\mathbb{P}(U \\mid x, a)$ and  ${\\mathbb{P}(Y \\mid x, u, a)\\}$ for the right supremum, and $\\{\\mathbb{P}(U \\mid x, a^\\prime)\\}_{a^\\prime \\neq a}$ for the left supremum.\n\n    **Action:** We added a clarification below Eq. (4) where we explain the choice behind the coloring.\n\n* Two-stage procedure: Theorem 1 has two major implications: (1) It is sufficient to fix the distributions $\\mathbb{P}^\\ast(U \\mid x, a)$ and $\\mathbb{P}^\\ast(Y \\mid x, u, a)$; and (2) it is sufficient to choose $\\mathbb{P}^\\ast(Y \\mid x, u, a) = \\delta(Y - f^\\ast_{x, a}(u))$ as a delta-distribution induced by an invertible function $f^\\ast_{x, a} \\colon \\mathcal{U} \\to \\mathcal{Y}$, which satisfies the data-compatibility constraint $\\mathbb{P}(Y \\mid x, a) =  \\mathbb{P}^\\ast(f^\\ast_{x, a}(U) \\mid x, a)$. Point (1) implies that we can fix the components in the right supremum of Eq.~(4) and only optimize over the left supremum. Point (2) implies that the causal query $\\mathcal{F} \\left(\\int \\mathbb{P}(Y \\mid x, u, a) \\mathbb{P}(u \\mid x) du\\right)$ reduces to $\\mathcal{F} \\left(\\mathbb{P}(f^\\ast_{x, a}(U \\mid x) \\right)$. Eq.(5) shows the corresponding Stage 2 optimization for discrete treatments (maximizing over $\\mathbb{P}(u \\mid x, A \\neq a)$ to ensure data compatibility). For continuous treatments, we can directly maximize over $\\mathbb{P}(u \\mid x)$.\n\n    **Action:** We added a clarification to Sec. 5.2. Please let us know if you have further questions/suggestions regarding the clarification of our two-stage procedure.\n\n* Global optimum: A sufficient condition for the existence of a global solution in Eq.(5) is the continuity of the objective/causal query as well as the compactness of the constraint set. Continuity holds for many common causal queries such as the expectation. The compactness of the constraint set depends on the properties functional $\\mathcal{D}_{x, a}$, i.e., the choice of the sensitivity model. Compactness (and thus the existence of global solutions) has been shown for many sensitivity models from the literature, e.g., MSM [2] and $f$-sensitivity models [3]. We would like to emphasize that, in Theorem 1, we do not assume the existence of a global solution. In principle, our two-stage procedure is valid even if a global solution to Eq.(5) does not exist. In this case, we can apply our Stage 2 learning algorithm (Algorithm 1) until convergence and obtain an approximation of the desired bound, even if it is not contained in the constraint set.\n\n    **Action:** We added the above discussion to Appendix E of our paper.\n\n\n\n## References\n\n[1] Frauen et al. (2023). \u201cSharp Bounds for Generalized Causal Sensitivity Analysis\u201d. NeurIPS\n\n[2] Dorn et al. (2022). \u201cDoubly-Valid/Doubly-Sharp Sensitivity Analysis for Causal Inference with Unmeasured Confounding\u201d. arXiv:2112.11449.\n\n[3] Jin et al. (2022). \u201cSensitivity analysis under the f-sensitivity models: Distributional robustness perspective\u201d. arXiv:2203.04373."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3435/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700160317080,
                "cdate": 1700160317080,
                "tmdate": 1700230674853,
                "mdate": 1700230674853,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wguZ6WjIAF",
            "forum": "ikX6D1oM1c",
            "replyto": "ikX6D1oM1c",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3435/Reviewer_9LA1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3435/Reviewer_9LA1"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes NeuralCSA, a framework for performing causal sensitivity analysis, i.e., partially identification of a causal functional under assumptions on the unmeasured confounders. They propose a 2-stage training procedure, modeling the latent distributions using normalizing flows."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper overall is well-written and easy to understand. I found the motivation and setup to be clear. I also appreciated comparisons to existing sensitivity models.\n- The GTSM framework subsumes many of the existing sensitivity models and thus is more generally applicable. In principle, the framework also applies to arbitrary functionals (e.g., quantiles) of the interventional outcome distributions.\n- The clarity of the two-stage procedure can be improved (see Weaknesses section), but overall, the procedure is simple and easy to follow. It is also nicely motivated using Theorem 1."
                },
                "weaknesses": {
                    "value": "- I found Sec 5.1 and 5.2 difficult to read and I think clarity can be improved. What confused me initially was that you suggest fixing $P^*(U|x, a)$ but then the $\\sup$ in Eq. 5 is also over the distributions $p(u|x, A)$. Reading it further, the sup is only for $A \\neq a$ but I think clarifying that you only fix for the treatment $a$ that enters into $Q$ would be useful. Maybe this is obvious, but it will still make it easier to understand what is being optimized over in the $\\sup$.\n- It would also be nice to have some intuition of the proof of Theorem 1. Also, the invertible function $f^*$ would depend on the fixed $P^*$. Does certain distributions $P^*$ make it easier to determine $f^*$. In practice, how should you determine which $P^*$ to fix?"
                },
                "questions": {
                    "value": "See weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3435/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698848481859,
            "cdate": 1698848481859,
            "tmdate": 1699636295674,
            "mdate": 1699636295674,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "OFdWNW9YEJ",
                "forum": "ikX6D1oM1c",
                "replyto": "wguZ6WjIAF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3435/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3435/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 9LA1 #1"
                    },
                    "comment": {
                        "value": "Thank you for your positive evaluation of our paper! We took all your comments at heart and improved our paper accordingly.\n\n## Response to \u201cWeaknesses\u201d\n\n\n* Thank you for pointing out the ambiguous notation in Eq. (5). You are correct in that we optimize the objective in Eq. (5) over the distribution $\\mathbb{P}(u \\mid x, A \\neq a)$ for fixed $a$, and not directly over $\\mathbb{P}(u \\mid x)$. The variable $a$ is indeed the fixed treatment intervention that enters the causal query $Q$. Framing the optimization problem in this way ensures that the corresponding joint distribution $\\mathbb{P}(u, a \\mid x)$ induces the observational distribution $\\mathbb{P}_\\mathrm{obs}(a \\mid x)$, which guarantees sharpness of our bounds without the need to incorporate additional constraints into our learning algorithm. If we would also optimize over distributions $\\mathbb{P}(u \\mid x)$ that are not compatible with the observational distribution, our bounds may become overly conservative.\n\n    **Action:** We added a clarification to Eq. (5) in order to improve the clarity of Sec. 5.1."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3435/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700159715624,
                "cdate": 1700159715624,
                "tmdate": 1700159715624,
                "mdate": 1700159715624,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZAfsenZseX",
                "forum": "ikX6D1oM1c",
                "replyto": "wguZ6WjIAF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3435/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3435/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 9LA1 #2"
                    },
                    "comment": {
                        "value": "* **Intuition for Theorem 1:** We agree that Sec. 5.1 and 5.2 can be improved by providing further intuition for Theorem 1. We believe that the following two aspects of Theorem 1 may need further clarification (for a rigorous proof, we refer to Appendix B.3):\n    * _Why is it sufficient to only consider invertible functions $f: \\mathcal{U} \\to \\mathcal{Y}$, i.e., model $\\mathbb{P}^\\ast(Y \\mid x, a, u) = \\delta(Y - f(u))$  as a Dirac delta distribution?_ Here, it is helpful to have a closer look at Fig. 1: Intervening on the treatment $A$ causes a shift in the latent distribution of $U$, which then leads to a shifted interventional distribution $\\mathbb{P}(Y(a) = y \\mid x)$. The question is now: How can we obtain an interventional distribution that results in a maximal causal query (for the upper bound)? Let us consider a structural equation of the form $Y = g(U, \\epsilon)$, where $\\epsilon$ is some independent noise. Hence, the \u201crandomness\u201d (entropy) in $Y$ comes from both $U$ and $\\epsilon$; however, the distribution shift only arises through $U$. Intuitively, the interventional distribution should be maximally shifted if $Y$ only depends on the unobserved confounder and not on independent noise, i.e., $g(U, \\epsilon) = f(U)$ for some invertible function $f$. One may also think about this as achieving the maximal \u201cdependence\u201d (mutual information) between the random variables $U$ and $Y$. Note that any GTSM only restricts the dependence between $U$ and $A$, but not between $U$ and $Y$.\n    * _Why can we fix $\\mathbb{P}^\\ast(U \\mid x, a)$ and $f$ without losing the ability to achieve the optimum in Eq. (4)?_ The basic idea is as follows: Let $\\widetilde{\\mathbb{P}}(\\widetilde{U} \\mid x, a)$ and $\\widetilde{f}$ be optimal solutions to Eq. (4) for a potentially different latent variable $\\widetilde{U}$. Then, we can define a mapping $t = {f}^{-1} \\circ \\widetilde{f} \\colon \\widetilde{U} \\to U$ between latent spaces that transforms $\\widetilde{\\mathbb{P}}(\\widetilde{U} \\mid x, a)$ into our fixed $\\mathbb{P}^\\ast(U \\mid x, a)$ (because both $\\widetilde{f}$ and $f$ respect the observational distribution). Furthermore, we can use $t$ to push the optimal shifted distribution $\\widetilde{\\mathbb{P}}(\\widetilde{U} \\mid x)$ (under treatment intervention) to the latent variable $U$ (see Eq. (46)). In our proof in Appendix B.3. we show that this is sufficient to obtain a distribution  $\\mathbb{P}^\\ast$ that induces $\\mathbb{P}^\\ast(U \\mid x, a)$ and $\\mathbb{P}^\\ast(Y \\mid x, u, a) = \\delta(Y - f(u))$ and which satisfies the sensitivity constraints. For the latter property, we require the sensitivity model to be \u201cinvariant\u201d with respect to the transformation $t$. We formalize this via our transformation-invariance assumption (Definition 3).\n\n    **Choice of the fixed distribution $\\mathbb{P}^\\ast(U \\mid x, a)$ in Stage 1:** You are correct in that the function $f^\\ast_{x, a}$ depends on the choice of $\\mathbb{P}^\\ast(U \\mid x, a)$ (we sightly abused notation here for improved readability). In practice, Stage 1 reduces to fitting a (conditional) normalizing flow (NF) to learn the observational distribution $\\mathbb{P}_\\mathrm{obs}(Y \\mid x, a)$. **Hence, the problem of choosing  $\\mathbb{P}^\\ast(U \\mid x, a)$ in Stage 1 of NeuralCSA is equivalent to choosing the latent distribution when fitting an NF**. Common choices from the literature are the standard Gaussian or uniform distribution [1]. In our implementation, we chose a standard Gaussian for the following reason: Stage 2 requires fitting a second NF to model a distribution in the latent space with the same support as $\\mathbb{P}^\\ast(U \\mid x, a)$. By using a Gaussian, we avoid the need to hard-code support constraints into our Stage 2 NF. \n\n\n    **Action:** We extended our intuition paragraph in Sec. 5.2. and included some of the arguments provided above. Furthermore, we added an extensive discussion to Sec.B.3 in the appendix (see our proof of Theorem 1).\n\n\n\n## References\n\n[1] Papamakarios et al. (2021). \u201cNormalizing Flows for Probabilistic Modeling and Inference\u201d. JMLR"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3435/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700159746979,
                "cdate": 1700159746979,
                "tmdate": 1700230813561,
                "mdate": 1700230813561,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rtIY5OshRf",
                "forum": "ikX6D1oM1c",
                "replyto": "ZAfsenZseX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3435/Reviewer_9LA1"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3435/Reviewer_9LA1"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "Thank you for your detailed responses. After reading this and the other reviews, I continue to be positive about the paper."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3435/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700664235320,
                "cdate": 1700664235320,
                "tmdate": 1700664235320,
                "mdate": 1700664235320,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qYUBbQR2qS",
            "forum": "ikX6D1oM1c",
            "replyto": "ikX6D1oM1c",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3435/Reviewer_i97n"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3435/Reviewer_i97n"
            ],
            "content": {
                "summary": {
                    "value": "The authors provide a framework for generalized causal sensitivity analysis, an approach that subsumes three previous methods and provides additional advantages."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The key advantage of the authors' approach (according to the authors) is that it is much more widely applicable than any other single approach (which typically focus on a specific sensitivity model, treatment type, and causal query).\n\nThe paper is well-written, and it provides substantial background about existing methods for causal sensitivity analysis.\n\nThe experiments appear consistent with the existing literature, well-motivated, and useful."
                },
                "weaknesses": {
                    "value": "The generality of the approach appears to come at a substantial cost in terms of complexity (with a corresponding potential for unexpected sources of error, bias, or misspecification). The single advantage over MSM appears to be allowing causal queries with multiple outcomes. \n\nIt is unclear the extent to which alternative (non-neural) implementations of the GTSM are possible. The paper would be improved by clearly describing what advantages the neural implementation provides over alternatives.\n\nIt seems somewhat odd to cite D'Amour 2019 (an excellent paper about a very specific topic) for the idea that \"unobserved confounding often renders causal inference challenging.\" That has been known for more 50 years, going back at least to Reichenbach's common cause principle."
                },
                "questions": {
                    "value": "Are alternative (non-neural) implementations of the GTSM possible? What advantages does the neural implementation provides over alternatives? How does the complexity (e.g., number of hyper-parameters and other implementation choices) of NeuralCSA compare to MSM?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3435/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699144319401,
            "cdate": 1699144319401,
            "tmdate": 1699636295597,
            "mdate": 1699636295597,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Zqi2aCoE0S",
                "forum": "ikX6D1oM1c",
                "replyto": "qYUBbQR2qS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3435/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3435/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer i97n #1"
                    },
                    "comment": {
                        "value": "Thank you for your positive review and your helpful comments. We improved our paper in the following ways:\n\n## Response to \u201cWeaknesses\u201d\n\n* We agree that fitting NeuralCSA is more complex than using closed-form solutions. For practical usage, we recommend using closed-form solutions whenever available (e.g., for the MSM with a single outcome). However, for many settings, such closed-form solutions do **not** exist (see Table 1). This is where NeuralCSA (our framework) is of great value: it allows \u2013 for the first time \u2013 to obtain bounds that would otherwise be intractable. \n   We would also like to emphasize that our paper not only provides practical solutions for causal sensitivity analysis but also offers new perspectives for the development of future methods on partial identification/sensitivity analysis. To the best of our knowledge, we are the first to obtain bounds by explicitly learning the distribution shift in the latent unobserved confounders due to treatment intervention (Fig. 1). We suspect that this basic idea could also be applied in other settings where closed-form solutions are not available (e.g., mediation or IV settings), thus enabling potential follow-up works. **Action**: We expanded our discussion (Sec. 7) and included advice for when to employ NeuralCSA in practice.\n\n* Non-neural alternatives: This is an interesting question. First, our two-stage procedure is agnostic to the estimators used, which, in principle, allows for non-neural instantiations. However, we believe that there are important reasons why our **neural instantiation** (NeuralCSA, Sec. 4) has **several advantages** over possible non-neural alternatives:\n    * **Solving Stage 1**: Stage 1 requires learning an invertible function $f: \\mathcal{U} \\to \\mathcal{Y}$ that transforms the fixed latent distribution $\\mathbb{P}^\\ast(U \\mid x, a)$ (e.g., Gaussian) to the observed distribution $\\mathbb{P}\\mathrm{obs}(Y \\mid x, a)$. Normalizing flows (NFs) are specifically designed for this task and, hence, are a natural choice for learning $f$. In particular, NFs allow for inverting $f$ analytically, which enables tractable optimization of the log-likelihood (see Appendix F). In principle, $f$ could also be obtained by estimating the conditional c.d.f. $\\hat{F}(y \\mid x, a)$ using some arbitrary estimator (e.g., non-neural [1]) and then leveraging the inverse transform sampling theorem, which states that we can choose $f = \\hat{F}^{-1}$ whenever we fix $\\mathbb{P}^\\ast(U \\mid x, a)$ to be uniform. However, this approach only works for one-dimensional $Y$ and requires inverting the estimated $\\hat{F}(y \\mid x, a)$ numerically. \n    * **Solving Stage 2**: Stage 2 requires to optimize the causal query $\\mathcal{F} \\left(\\mathbb{P}(f^\\ast_{x, a}(U) \\mid x) \\right)$ over a latent distribution $\\mathbb{P}(U \\mid x)$, where $f^\\ast_{x, a}$ is learned in Stage 1. In NeuralCSA, we achieve this by fitting a second NF in the latent space $\\mathcal{U}$, which we then concatenate with the NF from Stage 1 to backpropagate through both NFs. **Standard density estimators are not applicable** in Stage 2 because we fit a density **in the latent space** to optimize a causal query that is dependent on Stage 1 (and **not** a standard log-likelihood). While there may exist non-neural alternatives for solving the optimization in Stage 2, this goes beyond the scope of our paper, and we leave this for future work.\n    * **Analytical interventional density**: Using NFs in both Stages 1 and 2 enables us to obtain an analytical interventional once NeuralCSA is fitted. Hence, we can perform sensitivity analysis for the whole interventional density (see Fig. 6 and 7) in a scalable manner, without the need for Monte Carlo approximations through sampling. \n    * **Universal density approximation**: NFs are universal density approximators, which means that we can account for complex (e.g., multi-modal, skewed) observational distributions.\n\n    **Action:** We added a section Appendix E in which we discuss the advantages of our neural implementation and outline the possibility of non-neural alternatives.\n\n* D'Amour (2019) citation: We followed your suggestion and removed the citation. Instead, we now cite the causality book by Judea Pearl."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3435/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700159290288,
                "cdate": 1700159290288,
                "tmdate": 1700230978868,
                "mdate": 1700230978868,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dXDWTHW4cP",
                "forum": "ikX6D1oM1c",
                "replyto": "qYUBbQR2qS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3435/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3435/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer i97n #2"
                    },
                    "comment": {
                        "value": "## Response to \u201cQuestions\u201d\n\n* Non-neural alternatives -> see our \u201cResponse to weaknesses\u201d\n* Complexity of NeuralCSA vs the MSM (closed-form solutions): \n    * **Stage 1**: Stage 1 requires fitting an NF to estimate the observational distribution $\\mathbb{P}\\mathrm{obs}(Y \\mid x, a)$. This step is also necessary for MSMs, where the closed-form solutions for bounds depend on the observational distribution (see [2]). Hence, the complexity of MSM (closed-form solutions) and Stage 1 of our NeuralCSCA is **equivalent**. \n    * **Stage 2**: While closed-form solutions under the MSM allow for computing bounds directly using the observational distribution, NeuralCSA fits an additional NF that is trained using Algorithm 1. Hence, Stage 2 introduces additional hyperparameters, namely: the hyperparameters of the second NF and the learning rates of the augmented Lagrangian method (used to incorporate the sensitivity constraint). In our experiments, NeuralCSA was able to effectively recover the closed-form bounds under the MSM despite the additional complexity due to Stage 2 (see Fig. 4). We would like to emphasize that we do not claim that NeuralCSA archives better performance than existing closed-form solutions. Rather, we propose our NeuralCSA as a method for causal sensitivity analysis whenever bounds are not analytically tractable.\n\n    **Action:** We added the above comparison to Appendix E of our paper. We also emphasized in our introduction and discussion that we primarily propose NeuralCSA for settings in which bounds are not analytically tractable.\n\n## References\n\n[1] Chernozhukov et al. (2013). \u201cInference on counterfactual distributions\u201d. Econometrica.\n\n[2] Frauen et al. (2023). \u201cSharp Bounds for Generalized Causal Sensitivity Analysis\u201d. NeurIPS"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3435/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700159321180,
                "cdate": 1700159321180,
                "tmdate": 1700230854050,
                "mdate": 1700230854050,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]