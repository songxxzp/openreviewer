[
    {
        "title": "Sparsistency for inverse optimal transport"
    },
    {
        "review": {
            "id": "QOuJa13iLF",
            "forum": "wpXGPCBOTX",
            "replyto": "wpXGPCBOTX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5106/Reviewer_rfzP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5106/Reviewer_rfzP"
            ],
            "content": {
                "summary": {
                    "value": "This article addresses the problem of inverse optimal transport, which involves estimating the transport cost from an optimal (noisy) transport plan. The authors focus on the 'penalized' $\\ell_1$ cost formulation, parametrized by a matrix of parameters (the cost is parametrized as linear combination of individual costs, such as in the Mahalanobis setting). The article provides two types of guarantees:\n\nThe first type of guarantee, referred to as the \"finite sample case,\" is an estimation guarantee obtained from dual certificates when the observed transport plan is an entropic regularized plan between two empirical measures.\n\nThe second type, in the \"Gaussian case,\" deals with the scenario where the measures involved are Gaussian distributions (a well-known case in transport that admits a closed-form solution). In this case, the article demonstrates that the cost estimation can be solved as a graphical lasso problem, especially when the entropic regularization is small."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- I find the introduction and contextualization of the article to be very well done. The related work appears comprehensive, and the problem is well-situated.\n\n- The theoretical results in this article are interesting. For the discrete case, the authors demonstrate that, with a small $\\ell_1$ regularization and a sufficiently large number of samples, the ill-posed problem of invOT can indeed recover the costs.\n\n- The connections between graphical lasso and invOT are also intriguing and interesting."
                },
                "weaknesses": {
                    "value": "- I find that the article doesn't put in enough effort to explain the practical implications of the various theoretical results, which remain somewhat abstract. It's quite challenging to understand how these results can be practically applied.\n\nFirstly, the concept of a pre-certificate condition is rather very abstract (unlike the case of Lasso that we can somehow interpret). It would be interesting to provide the reader with a bit more guidance to offer a small interpretation of this quantity.\n\nAnother example is Proposition 8. It's difficult for me to extract something from this result, aside from the qualitative interpretation that \"for small regularization, under somewhat abstract assumptions of certificates, and with a sufficiently large number of samples, solving the invOT problem yields a good solution.\" To make these results more applicable in practice, it would be helpful to either provide experiments or guarantees that demonstrate how to understand these pre-certificate assumptions or ensure that the level of regularization is appropriate. I realize that these may be challenging questions, but I find that not much intuition is given, and the practical use of these results does not appear straightforward.\n\n- My main criticism concerns the experiments section. I find the experiments too limited and somewhat confusing, making it difficult to obtain meaningful information.\n\nFirst, only the Gaussian with an identity covariance is considered. The idea is to study the impact of entropic regularization on invOT estimation. The presentation is somewhat unclear, and I struggle to understand from Figure 1 how it quantifies the influence of $\\epsilon$ on the estimation. There is no legend for the y-axis, and while it's understood to be the certificate value between two nodes, it's unclear how it serves as a good performance measure for the invOT problem. \n\nFigure 2 is equally unenlightening. It aims to determine the influence of the number of samples on the estimation in the very simple case of a circular graph and Gaussian measures. However, what is the x-axis on these three figures? Is it the number of iterations? The geodesic distance? If it's the geodesic distance, it's not clear because the y-axis is a global performance measure over C, while the x-axis appears to be a local measure, so it's unclear how one evolves with the other.\n\nThe conclusion appears to be that the estimation is \"good\" when the entropic regularization is sufficiently large, and the number of samples is also large. More importantly, there seems to be a significant gap: when $\\epsilon \\leq 10$, the estimation is consistently poor. Is this a result expected by the theory regarding $\\epsilon$?"
                },
                "questions": {
                    "value": "I'm curious to know whether the Gaussian results really require entropic regularization. Without regularization we also have a closed form: can't we deduce good invOT estimation guarantees in the non-regularized case?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5106/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698762820705,
            "cdate": 1698762820705,
            "tmdate": 1699636502726,
            "mdate": 1699636502726,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "cS9PXSfJ4G",
                "forum": "wpXGPCBOTX",
                "replyto": "QOuJa13iLF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5106/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5106/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your comments.\n\n> I find that the article doesn't put in enough effort to explain the practical implications of the various theoretical results [...] to provide the reader with a bit more guidance to offer a small interpretation of this quantity.\n\n\nWe have added an ``intuitions'' section to explain the relation between the certificate and optimality conditions. There is also now an \"interpretation\" after Propositions 8 and 9.\n\n> Another example is Proposition 8. It's difficult for me to extract something from this result,  [...] I realize that these may be challenging questions, but I find that not much intuition is given, and the practical use of these results does not appear straightforward.\n\nProposition 8 is the main technical result required for proving Theorem 3 which tells us that sparsistency is possible under the abstract assumption on the certificate. Theoretically proving whether the certificate is nondegenerate is challenging and in this paper, we analyse this condition only in the Gaussian setting (Prop 8 and 9 in the updated version): Some practical insights is that in the small epsilon regime, recoverability is equivalent to recoverability in the graphical lasso setting while for large epsilon, recoverability is approximated by the lasso setting (e.g. diagonal covariance matrix in alpha and beta will always lead to this condition being satisfied). We added comments on ``interpretation'' after Prop 8 and 9. In our opinion, the result here is inline with general intuition that small epsilon leads to more dependent couplings (and hence graphical lasso in the limit) while large epsilon leads to independent couplings, so the interaction matrix recovers has a different interpretation in each setting.\n\n> My main criticism concerns the experiments section. I find the experiments too limited and somewhat confusing, [...]  There is no legend for the y-axis, and while it's understood to be the certificate value between two nodes, it's unclear how it serves as a good performance measure for the invOT problem.\n\nThe purpose of Figure 1 was to numerically illustrate the behaviour of certificates in the Gaussian setting. One of the messages of our analysis is that in the large epsilon regime, the OT coupling becomes increasingly independent and iOT approximates a Lasso problem; in the small epsilon regime, the OT coupling becomes more dependent and iOT approximates graphical Lasso which is ``harder'' for sparsistency. The identity covariance is chosen because in this case, as $\\epsilon$ increases, our theory tells us that the certificate becomes nondegenerate so sparsistency will be guaranteed. We added also another figure to illustrate the setting where one attempts to recover a nonsymmetric cost function: the connection to graphical lasso is only in the case of symmetric matrices A and when A is not symmetric, the certificate in fact is not guaranteed to have a limit as epsilon goes to 0; this corroborates with numerical observations made in previous works where it has been noted that the recovery of non-symmetric costs is harder (page 23 https://arxiv.org/pdf/2002.09650.pdf and section 4.4 of https://arxiv.org/pdf/1905.03950.pdf).\n\n\n> Figure 2 is equally unenlightening. It aims to [...] what is the x-axis on these three figures? Is it the number of iterations? The geodesic distance? If it's the geodesic distance, [...] it's unclear how one evolves with the other.\n\nWe have added labels to the axis. The x-axis is $\\lambda$. For each regularisation parameter $\\lambda$, we solve iOT and record the number of wrongly estimated positions.\n\n\n> The conclusion appears to be that the estimation is ``good'' when the entropic regularization  is sufficiently large [...] this a result expected by the theory regarding $\\epsilon$?\n\nWhen $\\epsilon$ is small, the certificate is degenerate and hence support recovery is unstable. We added a remark on this: `` in particular,\none can observe from (7) that for large $\\epsilon$, the certificate is trivially non-degenerate whenever\n$\\Sigma_\\alpha$, $\\Sigma_\\beta$ are diagonal.\"\n\n\n> I'm curious to know whether the Gaussian results really require entropic regularization. Without regularization we also have a closed form: can't we deduce good invOT estimation guarantees in the non-regularized case?\n\nIt is true in the $\\epsilon=0$ case that the OT coupling has a closed form solution, however, it is unclear how to directly estimate the matrix A from the sample covariance matrix. \nFor instance, the $\\ell^1$--iOT method collapses in this case: the optimal transport function $W(A)$ becomes 1-homogeneous in $A$ when $\\epsilon=0$, and so,  the loss function we have $L(A,\\hat \\pi)$ is also 1-homogeneous. As a result, if one considers $L(A,\\hat \\pi) + \\lambda\\|{A}\\|_1$, zero is trivially a solution. So, the $\\epsilon=0$ case is challenging because it is unclear if one can apply convex regularization to handle the ill-posedness of the problem."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5106/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700000060959,
                "cdate": 1700000060959,
                "tmdate": 1700000147404,
                "mdate": 1700000147404,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vopjeVfbeA",
            "forum": "wpXGPCBOTX",
            "replyto": "wpXGPCBOTX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5106/Reviewer_2C9j"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5106/Reviewer_2C9j"
            ],
            "content": {
                "summary": {
                    "value": "This paper deals with the problem of inverse optimal transport on compact (but not necessarily finite) state space to find the cost function from a given empirical probability coupling. It establishes a connection to lasso and produces the sample complexity of solving the corresponding primal-dual method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Finding the cost function from the empirical process induced by the optimal transport algorithm is an important open question. In that respect, this paper addresses an important open question. The connection of the non-degenerate precertificate assumption with irrepresentability assumption in lasso is an interesting insight. Finally, I found the connections to the SVD of the covariance matrix illuminating. The gaussian example also serves to demonstrate the theory through the lenses of an example."
                },
                "weaknesses": {
                    "value": "Although the sample complexity bound is good, there was no discussion about the tightness of the said bound. I wonder if the $1/\\sqrt{n}$ is also the best lower bound. Observing that the empirical density acts like a ``plug-in\" for the unknown true coupled density, can the statistical guarantees of the plug-in be translated to the guarantees for the cost function?"
                },
                "questions": {
                    "value": "Can the authors please elaborate more on the penalty term $\\lambda$? Is $\\lambda$ given for a given problem? Is it shrinking with $n$? \n\nAlso, do the authors implicitly assume that we can sample from the coupled empirical density? Or do we just have access to some samples?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5106/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5106/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5106/Reviewer_2C9j"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5106/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698872741353,
            "cdate": 1698872741353,
            "tmdate": 1699636502569,
            "mdate": 1699636502569,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kZQ8I78GTC",
                "forum": "wpXGPCBOTX",
                "replyto": "vopjeVfbeA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5106/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5106/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your comments.\n\n> Although the sample complexity bound is good, there was no discussion about the tightness of the said bound. I wonder if the is also the best lower bound. \n\nAlthough we have no rigorous proof of this, the sample complexity of $1/\\sqrt{n}$ is known to be tight for the direct estimation of eOT (https://arxiv.org/abs/1905.11882), so it should be expected that this sample complexity rate should also be tight for inverse eOT. We will comment about this in the revised version of the paper.\n\n\n> Observing that the empirical density acts like a ``plug-in\" for the unknown true coupled density, can the statistical guarantees of the plug-in be translated to the guarantees for the cost function?\n> Also, do the authors implicitly assume that we can sample from the coupled empirical density? Or do we just have access to some samples?\n\nWe assume that we have $n$ iid samples from some probability coupling $\\hat\\pi$, which is an eOT coupling between $\\alpha$ and $\\beta$ for some $\\epsilon>0$ with underlying cost $c_{\\hat A}$. The question we are addressing is whether $\\hat A$ can be stably recovered from $n$ samples. \n\nTo clarify, we do not observe $\\hat \\pi = \\mathrm{Sink}(c_{\\hat A}, \\epsilon)$ but only $n$ iid samples $(x_i,y_i)\\sim \\hat \\pi$ and our main result is concerned with the approximation of $\\hat A$ (and hence $c_{\\hat A}$) by solving the iOT problem with the plug in $\\hat \\pi_n = \\frac{1}{n} \\sum_{i=1}^n \\delta_{(x_i,y_i)}$. We have modified Section 2.2 to clarify this and moved some of the technical details on how to set up the finite dimensional problem to the appendix.\n\n\n> Questions:\nCan the authors please elaborate more on the penalty term $\\lambda$? Is given for a given problem? Is it shrinking with ?\n\n\n$\\lambda$ is a regularization parameter in our inverse problem which should be balanced with the \"noise\" (in this case, number of samples) for accurate reconstructions. The relation between lambda and $n$ is given in Theorem 5 where we see that $e^{C/\\lambda}/\\lambda \\leq  \\sqrt{n}$. So, the smaller lambda is, the larger $n$ needs to be."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5106/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699999635464,
                "cdate": 1699999635464,
                "tmdate": 1700000085091,
                "mdate": 1700000085091,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "bdIolQC1ef",
            "forum": "wpXGPCBOTX",
            "replyto": "wpXGPCBOTX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5106/Reviewer_akqu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5106/Reviewer_akqu"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the regularized inverse entropic optimal transport problem. Inverse optimal transport (iOT) is the problem of recovering the ground cost given samples from the (potentially, noisy) joint distribution. Recent works have proposed solvers to solve the primal and dual formulations of the iOT and regularized iOT problem. This paper studies the recovery guarantees for the L1-regularized iOT problem. They further explore a special case where the densities are Gaussian, and show that in some cases, iOT results in the graphical LASSO problem."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- Inverse optimal transport is an interesting problem and an interesting take on the metric learning problem, this work takes a significant step forward in establishing a theoretical grounding for the regularized iOT problem.\n- I really enjoyed reading the paper, the writing is very clear, the background, method, and the results are well presented.\n- Showing that graphical LASSO as a special case of inverse OT is very interesting and makes sense."
                },
                "weaknesses": {
                    "value": "- Nothing that I can think of."
                },
                "questions": {
                    "value": "- How practical is inverse OT? I understand that the current work considers linear cost functions. Can one, albeit without strong theoretical guarantees, learn a general (perhaps, regular) cost function from the samples drawn from the coupling?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5106/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5106/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5106/Reviewer_akqu"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5106/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699005656558,
            "cdate": 1699005656558,
            "tmdate": 1699636502469,
            "mdate": 1699636502469,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pBMG5L0O1f",
                "forum": "wpXGPCBOTX",
                "replyto": "bdIolQC1ef",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5106/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5106/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your comments.\n\n>  How practical is inverse OT? I understand that the current work considers linear cost functions. Can one, albeit without strong theoretical guarantees, learn a general (perhaps, regular) cost function from the samples drawn from the coupling?\n\niOT can indeed be applied to recover other types of cost functions. There are works in this direction such as https://arxiv.org/abs/2002.09650 which considers cost functions and Kantorovich potentials given by neural networks.  We have cited several of these works in the introduction, but to clarify, we also added a footnote on page 4. Note however that, in this setting it is far from trivial to give theoretical guarantees, our main goal with this work."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5106/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699999529161,
                "cdate": 1699999529161,
                "tmdate": 1699999529161,
                "mdate": 1699999529161,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ssoAub2Ktg",
            "forum": "wpXGPCBOTX",
            "replyto": "wpXGPCBOTX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5106/Reviewer_gfhu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5106/Reviewer_gfhu"
            ],
            "content": {
                "summary": {
                    "value": "The paper is about inverse optimal transport (iOT), that is the task of inferring a ground cost from the sampling of an (entropy-regularized) optimal transport plan.\nFor linear parametrizations of the cose, iOT is a convex inverse problem (Dupuy et al 2019), that the authors propose to regularize with the $\\ell_1$ penalty.\n\nThe paper first derives an irrepresentability condition (IC) for the iOT problem,\nbased on non degeneracy of a \"precertificate\" (Def 1).\nFirst, the authors show that the solution of the regularized \"infinite samples\" problem shares the same sign as the true parameters under IC, for low enough regularization value (Thm 3).\nThen the more interesting \"Sparsistency\" results are then derived: in the finite sample case, the correct support is still recovered (under IC) for small regularization values and sufficiently many samples (Theorem 7).\n\nAdditional details in the case of Gaussian distributions are provided, with interpretation as Lasso and Graphical Lasso respectively for vanishing or exploding entropic regularization strength.\nExperiments on limited size graphs (80 nodes) conclude this theoretical paper."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Inverse optimal transport has recently attracted attention in the community due to its potential impact in ML.\nProposing better alternatives to solve this nonlinear inverse problem is thus of interest.\nThe paper provides results on both \"full distribution\" and finite sample problems.\nI did not spot any mathematical error, but could not check all of the paper."
                },
                "weaknesses": {
                    "value": "The authors could really afford to improve the pedagogy of the paper, which is quite heavy in terms of notation. Theory is quite involved, require background references to other works such as Carlier or Galichon.\nThe experiment description is a big block which, in my opinion, does not bring as many insights as it could."
                },
                "questions": {
                    "value": "Questions:\n- why does Proposition 8 imply that $z_\\infty$ is nondegenerate? Why, given its definition 1 line above, is it of the form written in (PrC)?\n- In prop 9 shouldn't the limit of $\\epsilon_n$ be $\\infty$?\n\n\nMinor:\n- In theorem 3, $\\hat A$ is such that $\\hat \\pi = \\text{Sink}(\\hat A, \\epsilon$; this has been introduced earlier but given the large number of variables defined in the paper, it may not hurt to recall it here; in addition, before, Sink was applied to $c$, so it should be $\\text{Sink}(c_{\\hat A}, \\epsilon$. In prop 10, prop 11 the order of the arguments is reversed.\n- can the authors explain the name \"precertificate\" (what's \"pre\" about it? Is there a difference with what Dunner and coauthors call \"Dual certificate\" in https://arxiv.org/abs/1602.05205)?\n- The authors refer to \"condition PrC\", but that is just an equality. Condition PrC would be that the dual norm of the precertificate outside the support is $< \\lambda$\n- what's \"the convex dual of W (A)\"? convex conjugate of a function (as in Proposition 4)/convex dual of a convex optimization problem?\n- is the notation $\\langle c, A \\rangle$ for a non scalar result?\n- In theorem 7 I spent quite some time looking for what the number $m$ was in other parts of the paper (because of the analogy $m/n$ in compressed sensing) before realizing that it was a free paramert; maybe replacing it by $\\ln(1/\\delta)$ is more common (that is only a suggestion).\n- below 9, in $A_n$ definition, both $\\epsilon$'s should be $\\epsilon_n$? Same in Prop 11\n- it follows (see e.g. Hiriart-Urruty et al. (1993)) : can you point to a specific result in the book? Also in the bibliography, the authors names appear twice for this book.\n\nTypos:\n- the paper does not seem to use the unmodified iclr template, the font differs from that of other papers\n- in Problem iOT L1 hat Pi, the first argument of L should be $A$ not $c_A$ (see def of L 2 equations above)\n-  The iOT problem of iOT\n- in a series of paper*s*\n- Thm 3: the solution ... satisf*ies*\n-  minimial norm\n- sufficinetly$\n- result above implies that for provided that the number\n- as exposed in Section ??\n- Cauchy Schwartz\n- see Proposition PrC (it's an equation not a proposition, and I don't see why pRC shows that W is $C^2$)"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5106/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699023517988,
            "cdate": 1699023517988,
            "tmdate": 1699636502377,
            "mdate": 1699636502377,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rshqGsZX80",
                "forum": "wpXGPCBOTX",
                "replyto": "ssoAub2Ktg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5106/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5106/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your comments.\n\n> The authors could really afford to improve the pedagogy of the paper, which is quite heavy in terms of notation. Theory is quite involved, require background references to other works such as Carlier or Galichon. The experiment description is a big block which, in my opinion, does not bring as many insights as it could.\n\nWe have added an ``intuitions'' section to explain the relation between the certificate and optimality conditions. There is also now an \"interpretation\" after Propositions 8 and 9. Regarding the experiments, we added an additional example for the anti-symmetric case and clarified the interpretation of the results. \n\n> Why does Proposition 8 imply $z_\\infty$ is non-degenerate? Why, given its definition 1 line above, is it of the form written in (PrC)?\n\n$z_\\infty$ is actually the dual solution for $\\lambda$ fixed. It corresponds, in the original submission, to $z^\\lambda$ of Proposition 5. We don't claim that $z_\\infty$ has the form  written in (PrC) in the original solution. What we have is that $\\lim_{\\lambda \\to 0} z_\\infty\\to z_A^\\ast$ and hence, non-degeneracy of $z_A^\\ast$ implies that the magnitude of $z_\\infty$ outside the support of $A$ is less than one (for $\\lambda$ sufficiently small). \n\nWe agree with the reviewer that this was not  clear in the original submission and we have changed this in the new submission it to make it so.\n\n> In prop 9 shouldn't the limit of $\\epsilon_n$\t be $\\infty$ ?\n\nThere was in fact a typo and in the $\\epsilon\\to \\infty$ proposition in the Gaussian case. We have corrected this.\n\n> In theorem 3, $\\hat A$\nis such that $\\text{Sink}(\\hat{A},\\epsilon)$ ; this has been introduced earlier but given the large number of variables defined in the paper, it may not hurt to  recall it here; in addition, before, Sink was applied to $c$, so it should be $\\text{Sink}(c_{\\hat{A}},\\epsilon$. In prop 10, prop 11 the order of the arguments is reversed.\n\nWe agree with the reviewer and we have modified the new submission accordingly.\n\n> Can the authors explain the name ``precertificate'' (what's ``pre'' about it? Is there a difference with what Dunner and coauthors call  ``Dual certificate'' in https://arxiv.org/abs/1602.05205)?\n\nThe use of ``pre'' was to make a distinction with the minimal norm certificate defined afterwards. Under non-degeneracy the two are the same but not necessarily in the degenerate case. As this distinction was hurting readability, we have changed the name and reformulated the section. Moreover, we moved to the appendix the connection with duality.\n\n> The authors refer to ``condition PrC'', but that is just an equality. Condition PrC would be that the dual norm of the precertificate outside the support is $<\\lambda$\n\nWe agree with the reviewer and this now reflected in the reformulated section.\n\n>  what's ``the convex dual of $W (A)$''? convex conjugate of a function (as in Proposition 4)/convex dual of a convex optimization problem?\n\nWe agree with the reviewer that this was not the best terminology and we modified it.\n\n>  is the notation $\\langle c,A\\rangle$ for a non scalar result?\n\nThe notation $\\langle c, A\\rangle$ corresponds to a function: given a set of fixed cost functions $\\lbrace C_1(\\cdot,\\cdot),\\ldots, C_t(\\cdot,\\cdot)\\rbrace$, the notation meant a linear combination of those with coefficients given by the vector $A$, \\emph{i.e.,}\n\\begin{align*}\n    \\langle c, A\\rangle(x,y):= \\sum_j A_j C_j(x,y)\n\\end{align*}\nIn fact, $\\langle c,A\\rangle(\\cdot,\\cdot)$ was just another notation for $c_A(\\cdot,\\cdot)$ that was meant to highlight the linear dependence of $c_A(\\cdot,\\cdot)$  on $A$. Given that it was never re-used, we decided to drop it to avoid confusion with the inner product notation.\n\n> In theorem 7 I spent quite some time looking for what the number $m$ was in other parts of the paper (because of the analogy $m/n$ in compressed sensing) before realizing that it was a free paramert; maybe replacing it by $\\log(1/\\delta)$ is more common (that is only a suggestion).\n\nWe welcome the suggestion which was integrated in the new submission.\n\n> below 9, in $A_n$ definition, both $\\epsilon$'s should be $\\epsilon_n$? Same in Prop 11\n\nYes. This was a typo that is now corrected.\n\n> it follows (see e.g. Hiriart-Urruty et al. (1993)) : can you point to a specific result in the book? Also in the bibliography, the authors names appear twice for this book.\n\nthe specific result is now mentioned and the bibliography was corrected.\n\n\n> Typos \n\nAll the typos suggested by the reviewer were corrected."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5106/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699999468998,
                "cdate": 1699999468998,
                "tmdate": 1700070674283,
                "mdate": 1700070674283,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]