[
    {
        "title": "On the Possibilities of AI-Generated Text Detection: A Sample Complexity Analysis"
    },
    {
        "review": {
            "id": "9zofG5ezim",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6790/Reviewer_6pNs"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6790/Reviewer_6pNs"
            ],
            "forum": "oxEER3kZ9M",
            "replyto": "oxEER3kZ9M",
            "content": {
                "summary": {
                    "value": "This paper presents a theoretical and empirical analysis of the feasibility of AI-generated text detection as LLMs become more powerful. Overall, the paper shows that even with the most powerful LLMs, AI-generated text detection will always feasible with enough samples / long-enough generated sequences.\n\nAs some background, Sadasivan et al. 2023 [1] recently showed in their work that AI-generated text detection performance is fundamentally bounded by the total variation norm between human-written and machine-generated text. Sadasivan et al. 2023 hypothesize that as LLMs become stronger, this variation will reduce, eventually making AI-generated text impossible.\n\nThis paper builds on the theoretical analysis of Sadasivan et al. 2023, but instead includes the *number of available AI-generated / human-written samples* into their proof. The paper argues that in many real-life scenarios (like AI Twitter bot detection), it is always possible to access multiple samples of AI-generated text. The paper finds that the bound on AI-generated text detection performance exponentially increases with the number of samples. The paper also provides an equation to obtain the required number of samples to achieve a particular AU-ROC score.\n\nThe paper further supports the theoretical results with several empirical experiments, showing that AI-generated text can be better detected with more samples or with longer sequences. The experiments include 4 datasets and evaluate 5 different LLMs with classification-based detection methods.\n\n[1] - https://arxiv.org/abs/2303.11156"
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Given the growing risk of plagiarism in college essays and the spread of misinformation using large language models, the topic of the paper is timely and very important.\n\n2. The paper presents an optimistic theoretical take on the feasibility AI-generated text detection, and in a sense, their proof conflicts with the impossibility result of Sadasivan et al. 2023. This proof is a good motivation for researchers to continue working on AI-generated text detection, despite the fear of LLMs approach human performance.\n\n3. The paper provides the exact theoretical bounds on AU-ROC performance, measures its tightness, and provides an equation to derive the required samples for a desired AU-ROC performance (however, also see weakness #1 on how this could be more practical).\n\n4. The paper supports their theoretical analysis with comprehensive experimental results, showcasing the benefit of longer sequences and more samples in 4 datasets and with 5 large language models.\n\n5. The paper is well written and a fair amount of intuition is added before/after the theoretical analysis to make it more accessible to a general audience."
                },
                "weaknesses": {
                    "value": "Overall, I liked the sentiment in the paper and thought the theoretical and empirical analysis was thorough. While I am leaning accept, I had some concerns about the real-world takeaways from the work, and would love to hear the author's thoughts on it (please let me know if this was mentioned somewhere in the paper or appendix and I missed it!).\n\n1. The theoretical analysis in the paper has a nice overall takeaway, but I am not sure how helpful the bounds are for practioners who are developing these algorithms / trying to detect AI-generated text. Specifically,\n\n* How does one go about computing the variation between machine-generated text and human-written text (`TV(m,h)^n`) for some SoTA LLMs like ChatGPT or GPT4, perhaps in a restricted domain? This is needed in both proposition 1 (for AU-ROC upperbound calculation), and in Theorem 1 (for sample estimation). I wonder if the authors could walkthrough an example in their paper: calculate `TV(m,h)^n` for ChatGPT for different output lengths, and then provide the corresponding upperbounds for AU-ROC for different values of the output length. I wonder if the method used in the MAUVE text evaluation paper (https://arxiv.org/abs/2102.01454) may be helpful for this calculation, who propose a clever approximation for measuring the divergence between human/machine-written text.\n\n* Is it possible to derive a bound on the true-positive rate (TPR) for a fixed false-positive rate (FPR), instead of a bound on AU-ROC? This may be a more practical metric, since practioners will want to optimize TPR for a fixed low FPR.\n\n2. I feel like the authors are under-selling themselves in the title/abstract/introduction, by focusing on the \"number of samples\" rather than \"sequence length\". Overall, I think in many AI-generated text detection scenarios only 1 sample will be available (like essay plagiarism detection, fake news detection). However, these individual samples are likely to have multiple sentences (or even paragraphs) in them. Moreover, the general empirical consensus seems to be that longer AI-generated sequences are easier to detect (https://arxiv.org/pdf/2306.04634.pdf). Does a multi-sentence output result in `n > 1` in the author's theoretical analysis? I am suspecting this is true, since a number of empirical experiments iterate on the output length rather than the number of samples. If feasible, I recommend the authors to make output length the first-class citizen of the work, rather than number of samples."
                },
                "questions": {
                    "value": "I was wondering how the retrieval-based defense from Krishna et al. 2023 (https://arxiv.org/abs/2303.13408) fits in the theoretical analysis of this paper. While I appreciate the discussion in Appendix A, I think the analysis in both Sadasivan et al. 2023 and this paper does not directly apply to retrieval-based detection. If I understand the retrieval-based detection algorithm correctly, it does not leverage the difference in properties between `m(s)` and `h(s)`. In other words, I think retrieval-based detection will work with `h_1(s)` and `h_2(s)` as well, where `h_1` and `h_2` are two identically distributed human writers. Is it fair to say that in retrieval-based detection, the support (`S` in this paper's 3.1) of `m(s)` and `h(s)` is almost disjoint, and hence the `TV(m,h)` will be quite high / infinity? With a bigger database there may be a few collisions between `m(s)` and `h(s)`, so `TV(m,h)` will slightly drop?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6790/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697407045912,
            "cdate": 1697407045912,
            "tmdate": 1699636784710,
            "mdate": 1699636784710,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "yPjuXsoPBH",
                "forum": "oxEER3kZ9M",
                "replyto": "9zofG5ezim",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6790/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6790/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 6pNs (Part 1)"
                    },
                    "comment": {
                        "value": "**General Response** We sincerely appreciate the reviewer's thoughtful feedback on our paper. We would like to acknowledge the reviewer for acknowledging the major motivation, theoretical contribution, and empirical analysis of our work, especially emphasizing that our results can motivate researchers to continue working on AI-generated text detection, despite the fear of LLMs approaching human performance --> this was our exact motivation.\n\n**Important Highlights:** We want to specifically highlight the reviewer's extremely important comment \"authors are under-selling themselves in the title/abstract/introduction focusing on the \"number of samples\" rather than \"sequence length\". We absolutely agree that our non-iid results are much more general and generalize to relating the sample complexity with sequence length and not just more samples (Th 1) which is practical and more general. We will be updating our draft with special emphasis on this point as we believe this contribution was missed by some of the reviewers.\n\n### Weakness\n\n> Comment: Overall, I liked the sentiment in the paper and thought the theoretical and empirical analysis was thorough. While I am leaning accept, I had some concerns about the real-world takeaways from the work, and would love to hear the author's thoughts on it (please let me know if this was mentioned somewhere in the paper or appendix and I missed it!).\n\n**Response to Comment** Thanks a lot for the comment. We provide a detailed discussion below.\n\n> Weakness 1 : The theoretical analysis in the paper has a nice overall takeaway, but I am not sure how helpful the bounds are for practitioners who are developing these algorithms / trying to detect AI-generated text. We try to discuss some implications of our \n\n**Response to Weakness 1** Thanks for this comment and we agree that it is indeed very important to discuss the significance and practical implications of our result. We attempt to provide certain insights of our results in Appendix A (remarks 1, 2, 3). Here we highlight how practitioners can leverage our results in designing reliable and more robust watermarks & detectors (currently susceptible to attacks) with information gain and human-machine distribution distance, and also discuss on the task-specific detectability with our results. We give two examples for simplicity\n\nWatermark Design: Our analysis suggests adaptive watermark designs based on Chernoff information and sample complexity, enhancing robustness against attacks\u2014a future research avenue.\n\nLength Constraints in Exams: Our bounds inform optimal summary lengths for easier cheating detection, leveraging the Chernoff metric.\n\nHowever, we agree that a more specific and detailed discussion on the practicality will be critical and we will add the same in our updated draft.\n\n> Weakness 2: How does one go about computing the variation between machine-generated text and human-written text (TV(m,h)^n) for some SoTA LLMs like ChatGPT or GPT4, perhaps in..... corresponding upper bounds for AU-ROC for different values of the output length. I wonder if the method used in the MAUVE text evaluation paper (https://arxiv.org/abs/2102.01454) may be helpful for this calculation, who proposes a clever approximation for measuring the divergence between human/machine-written text.\n\n**Response to Weakness 2** This is a very interesting point. We agree that computing the total variation distance in exactness for a real detector for text generated from LLMs or humans is hard and hence we evaluate the performance w.r.t AUC similar to what was used in prior works on detection (Sadasivan et. al, Krishna et. al, Mitchell et al.). \n\nHowever, it is important to note that we do validate the AUC upper-bound (in exactness, missing from concurrent works) for the best detector with an n-gram bag of words based on discretized feature space in Figure 2a. Since, in a finite discretized feature space, TV distance can be computed using the definition [1] and then we plot the AUC upper bounds by varying the value of n in n-grams as in Figure 2a. \n\nOn the other hand, the MAUVE metric leverages a modified KL/JS type divergence as in Equation 2 (Pillutla et al 2021), which can be an alternate measure of divergence replacing TV distance. Thanks for this very interesting suggestion and we agree that due to the piecewise constant approximation of the human (machine) distributions as done in Equation 3 (Mauve paper), we can estimate the KL divergence (or TV distance) under some approximations (depending on the clustering), and is a valid scope of future research. Additionally, one can also show theoretically by replacing TV with KL using Pinsker's inequality and obtaining the equivalent upper bound like ours in Theorem 1,2."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6790/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700204013421,
                "cdate": 1700204013421,
                "tmdate": 1700204013421,
                "mdate": 1700204013421,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5hVfnLVLPU",
                "forum": "oxEER3kZ9M",
                "replyto": "6RFccEd1YQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6790/Reviewer_6pNs"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6790/Reviewer_6pNs"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your detailed response"
                    },
                    "comment": {
                        "value": "Dear authors,\nThank you for your detailed response to my comments. After carefully reviewing them, I don't think I'll be able to raise my score to the next highest rating of 8, since my concerns on the real-world implications of the bounds remain. \n\nMy assessment is more like a 6.5-7, and I continue to support the acceptance of the paper. I will look forward to the changes in the next version of the paper!"
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6790/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700675818840,
                "cdate": 1700675818840,
                "tmdate": 1700675818840,
                "mdate": 1700675818840,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "jw1i2YidEp",
            "forum": "oxEER3kZ9M",
            "replyto": "oxEER3kZ9M",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6790/Reviewer_JMFi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6790/Reviewer_JMFi"
            ],
            "content": {
                "summary": {
                    "value": "This paper provides a theoretical analysis of the feasibility of AI-generated text detection based on sample complexity and TV distance. The paper includes two main theorems, one on the possibility of sample complexity in general (which I believe is an existing known result) and the second which extends to non-IID cases. The paper also includes a few experiments on the effect of document length on detection accuracy."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper is clear and well-written and provides a clear justification for a known result, i.e., that AI-generated text detection is easier with longer documents. The argument that Sadasivan, et al. 2023 (\u201cCan AI-generated Text Be Reliably Detected?\u201d) ignores the effect of document length and the possibility of having multiple sampled documents is reasonable and well-taken."
                },
                "weaknesses": {
                    "value": "My main concern is that the results in this paper are general facts about sample complexity and not specific to detection of AI-generated text. For example, Theorem 1 is included here: https://github.com/ccanonne/probabilitydistributiontoolbox/blob/master/testing.pdf. As this paper is outside of my area, I am less confident about the novelty of Theorem 2, but its formulation is not dependent on the domain of AI-generated text detection. It is also unclear from the paper whether the \u201cmultiple samples\u201d required by this theorem are meant to be individual words, sentences, or documents. \n\nThe experiments also replicate known results, namely, that AI-generated text detectors perform better on longer sequences and that they perform worse with paraphrasing. As far as I can tell, the main novel finding is the \u201cpairwise with IID samples\u201d condition (Figure 2c). It would be interesting to see a more controlled experiment here, which compares the performance of detectors on two IID documents of lengths X,Y versus one single document of length X+Y."
                },
                "questions": {
                    "value": "1. Could you provide additional details on the process used to generate Figure 2a? How were documents tokenized and how was AUC computed? I am also confused by the statement in Section 4.1 that this analysis \u201capproaches sentence to paragraph level\u201d while the maximum value of n seems to be 6 (which is shorter than most sentences, let alone paragraphs)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6790/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698724336666,
            "cdate": 1698724336666,
            "tmdate": 1699636784595,
            "mdate": 1699636784595,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "x6hkKoPbTJ",
                "forum": "oxEER3kZ9M",
                "replyto": "jw1i2YidEp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6790/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6790/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer JMFi (Part 1)"
                    },
                    "comment": {
                        "value": "**General Response:** Thank you for your review. We appreciate your recognition of the clarity of our paper. Your insights on the significance of document length and the consideration of multiple sampled documents are valuable and will further enrich the discussion in this paper.\n\n\n### Weakness\n\n> Weaknesses 1: My main concern is that the results in this paper are general facts about sample complexity and not specific to the detection of AI-generated text. For example, Theorem 1 is included here: https://github.com/ccanonne/probabilitydistributiontoolbox/blob/master/testing.pdf. As this paper is outside of my area, I am less confident about the novelty of Theorem 2, but its formulation is not dependent on the domain of AI-generated text detection. It is also unclear from the paper whether the \u201cmultiple samples\u201d required by this theorem are meant to be individual words, sentences, or documents.\n\n**Response to Weakness 1** We thank the reviewer for the reference but there seems to be a confusion regarding the novelty of our work. We note that the upper bound in the Total variation distance of the distribution (product distribution) is deep-rooted in the fundamentals of Information theory more specifically Lecam's lemma (as clearly highlighted at multiple places in our paper such as in the start of Section 3.2, before Equation (9),  and Appendix B.1). We never claim the novelty regarding the same, whereas ***our main novelty*** lies in deriving a precise sample complexity bound in the context of AI-generated text detection for both iid and non-iid scenarios, which is novel.\n\n***Our Results are for AI-generated Text Detection (as acknowledged by [Reviewer 6pNs](https://openreview.net/forum?id=oxEER3kZ9M&noteId=9zofG5ezim)):*** We illustrate our results precisely in the context of LLMs through several instances, provide key insights and also empirical evaluation ***in the text domain***. For example in Section 3.4, we develop the ***novel connection between non-iid sample complexity and increasing sequence length in generation***, illustrate the implication of $\\sum_k s_k$ (Equation 16) and novel insights on dependence of topics/contexts present in the paragraph with sample complexity results and empirical evaluations with several SOTA generators and detectors. We want to highlight that our results and comparisons are inline with the recent results in the field of AI-generated text detection (Sadasivan et. al, Krishna et. al, Mitchel et al etc.)\n\n***Clarification Regarding the use of the term 'multiple samples':*** Our result does not depend on the specific choice of the unit (for samples) to represent i.e., it can be a bag of words, sentences, or paragraphs, but rather emphasizes on the impact of product distribution on the sample complexity. ***To highlight the point we empirically demonstrate*** with several such instances like bag of words (Figure 2), sentences (Figure 3, 4), etc."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6790/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700379367601,
                "cdate": 1700379367601,
                "tmdate": 1700379367601,
                "mdate": 1700379367601,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "FlJ35t0Fkt",
            "forum": "oxEER3kZ9M",
            "replyto": "oxEER3kZ9M",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6790/Reviewer_Xeu7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6790/Reviewer_Xeu7"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the possibility of detecting machine-generated texts. With a theoretical analysis of true positive rate/false positive rate, the high-level message is that detecting MGT is possible if we have sufficient examples from humans and the machine. Empirical study on four datasets with a wide range of combinations between generation models and detection models demonstrate the utility of the theoretical results."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The research problem is important and very challenging\n- The theoretical analysis is strong and sounding\n- The results support the high-level conclusion, although I am not sure whether it directly supports the conclusion about sample complexity  (please refer to the question section)"
                },
                "weaknesses": {
                    "value": "- Interesting method and conclusion; however not sure how much we can connect this with MGT detection. It seems like the conclusion is generally applicable. This means the proposed method itself is not necessarily a weakness, but the disconnection is.\n- Equation 7 is not surprising. As pointed out by Sadasivan et al. (2023), it is impossible to get a reliable detector (high TPR, e.g., 90% and lower FPR, e.g., 1%), when the overlap of two distributions is relatively small.\n- Furthermore, equation 7 does not depend on sample complexity. So, I am not sure I understand how increasing the number of examples can get around this issue pointed out by the previous comment.\n- More generally, the real challenge of detecting MGT is the lack of information on generative models. In practice, it\u2019s hard to predict whether a collection of texts is from the same generation model. Furthermore, a gray area of this research question: how we should treat the texts generated by machines and edited by humans."
                },
                "questions": {
                    "value": "- What is the \u201cPercentage of Sequence used for Detection\u201d?\n- What does \u201cexponentially fast\u201d mean in the caption of Figure 1?\n- Are there any experiment results on non-IID data?\n- Maybe I missed something from the paper, but is there any sample complexity directly related to equation 15?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6790/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698811043552,
            "cdate": 1698811043552,
            "tmdate": 1699636784482,
            "mdate": 1699636784482,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tHRGcvugFy",
                "forum": "oxEER3kZ9M",
                "replyto": "FlJ35t0Fkt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6790/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6790/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Xeu7 (Part 1)"
                    },
                    "comment": {
                        "value": "**General Response:** We thank the reviewer for appreciating the research problem and theoretical analysis. We address the additional concerns in detail as follows. \n\n### Weaknesses:\n\n> Weakness 1: Interesting method and conclusion; however not sure how much we can connect this with MGT detection. It seems like the conclusion is generally applicable. This means the proposed method itself is not necessarily a weakness, but the disconnection is.\n\n\n**Response to Weakness 1** We are thankful that you find our formulation and methodology interesting. \n\nRegarding the generality of the results, we agree that certain theoretical results for example used in Eq 6, 7, and 9 have their roots in Information theory and Large deviation theory ***but a precise connection to the context of AI-generated text detection was missing from literature.*** Specifically, our sample complexity analysis for iid samples (Theorem 1) and non-iid samples (Theorem 2) are novel and provide a ***first step towards showing possibility*** results (in a theoretically rigorous manner) of MGT detection. \n\nWe illustrate our results precisely in the context of LLMs through several instances, key insights, and empirical evaluation. For example in Section 3.4, we develop the connection between non-iid sample complexity and increasing sequence length in the generation, illustrate the implication of $\\sum_k s_k$ (Equation 16), and novel insights on the dependence of topics/contexts present in the paragraph with sample complexity results and empirical evaluations with several SOTA generators and detectors.  \n\n> Weakness 2: Equation 7 is not surprising. As pointed out by Sadasivan et al. (2023), it is impossible to get a reliable detector (high TPR, e.g., 90% and lower FPR, e.g., 1%), when the overlap of two distributions is relatively small.\n\n**Response to Weakness 2** We agree that Equation 7 trivially follows and it comes from an application of Lecam's Lemma from Information Theory which we have clearly cited (and not first appeared in Sadasivan et al. (2023)). But we respectfully point out that there seems to be a slight confusion here. Our point is not about Equation (7). We would like to highlight the **hidden possibility** part which starts around Equation (8) (which is different from Sadasivan et al. (2023)).\n\n**Our Focus:** Our result in this paper focuses on Equation (9), which helps to conclude that even if the overlap of distribution in Equation (7), is small, increasing the samples/sequence length helps to increase the TPR because TV norm increases exponentially with respect to $n$ as highlighted in (12). This is rigorously connected with bounds developed in Theorem 1 (iid) and Theorem 2 (non-iid) cases. \n\n> Weakness 3: Furthermore, equation 7 does not depend on sample complexity. So, I am not sure I understand how increasing the number of examples can get around this issue pointed out by the previous comment.\n\n**Response to Weakness 3:** Equation 7 is mentioned to lay the foundation of our discussion but our results follow from the expression in Equation (9) which clearly depends upon the values of $n$ (samples/sequence length). We apologize for the confusion, we will highlight this fact in the revised version of our manuscript. \n\n> Weakness 4: More generally, the real challenge of detecting MGT is the lack of information on generative models. In practice, it\u2019s hard to predict whether a collection of texts is from the same generation model. Furthermore, a gray area of this research question: how we should treat the texts generated by machines and edited by humans.\n\n**Response to Weakness 4** This is a very interesting point. We agree that texts generated by machines and edited by humans is a very challenging setting and is very hard to detect in that case. However, ***our result provides a first step to rigorously show the possibility of detection*** where the text comes from either human/machine distribution. However, texts generated by machines and edited by humans are an extremely important and valid source of future research."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6790/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700202762516,
                "cdate": 1700202762516,
                "tmdate": 1700202762516,
                "mdate": 1700202762516,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sEJOeIEj44",
                "forum": "oxEER3kZ9M",
                "replyto": "FlJ35t0Fkt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6790/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6790/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Xeu7 (Part 2)"
                    },
                    "comment": {
                        "value": "### Questions\n\n> Question 1. What is the \u201cPercentage of Sequence used for Detection\u201d?\n\n**Response to Question 1** We vary the sequence length from 10% to 95% as shown in Figures 3a-f, and it is evident the detection performance improves significantly.\n\n> Question 2: What does \u201cexponentially fast\u201d mean in the caption of Figure 1?\n\n**Response to Question 2** In Figure 1, the value of Total variation distance (best detector) increases at an exponential rate as a function of the number of samples, which is also evident from our theoretical analysis as shown in Equation 12. In equation 12, it is evident that as we increase n, TV exponentially approaches 1.\n\n> Question 3: Are there any experiment results on non-IID data?\n\n**Response to Question 3:** ***Yes, We want to highlight that all our experimental*** ablations including Figures 2 (a,b) 3 (a->f) ***are for non-iid scenarios only***, as you can see that the performance (AUC) is measured with increasing sequence length. This is exactly what we discuss in Theorem 2, when we increase the sequence length (which is equivalent to having more dependent samples) the detection performance varies, which is novel and not covered in past literature. \nWe apologize if this point didn't come out clearly and will be updating the draft with a specific focus on this point as also highlighted by Reviewer 6pNs: \"I feel like the authors are under-selling themselves in the title/abstract/introduction, by focusing on the \"number of samples\" rather than \"sequence length\"\n\n> Question 4: Maybe I missed something from the paper, but is there any sample complexity directly related to equation 15?\n\n**Response to Question 4** Equation 15 represents the sample complexity results for the iid case (Theorem 1) which states that to achieve an AUROC of $\\epsilon$, we will need $O(\\frac{1}{\\delta^2} \\log \\frac{1}{1 - \\epsilon})$ samples (iid case, non-iid in Theorem 2). This precisely represents the sample complexity of detection i.e how the detection performance varies (in terms of AUC) with number of samples or sequence length. Hope this clears the confusion."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6790/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700202824315,
                "cdate": 1700202824315,
                "tmdate": 1700203024146,
                "mdate": 1700203024146,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bZ85vvKPVD",
                "forum": "oxEER3kZ9M",
                "replyto": "FlJ35t0Fkt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6790/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6790/Authors"
                ],
                "content": {
                    "title": {
                        "value": "New Experimental Results"
                    },
                    "comment": {
                        "value": "**New Experimental Results ([Figure 11 in Appendix E in the updated draft](https://openreview.net/pdf?id=oxEER3kZ9M)):** We would like to provide an update that we have also validated the detection performance on Question-answering style task with OpenAI's Roberta classifier and observe that with the increase in sequence length for detection, the zero-shot detection performance of both the models improves significantly from around 55\\% to 98\\% validating our theorem for QA tasks. \n\nPlease let us know if we can address any more concerns before the rebuttal period ends. Thank you so much. We look forward to your feedback."
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6790/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700706673109,
                "cdate": 1700706673109,
                "tmdate": 1700706673109,
                "mdate": 1700706673109,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "cOoiSztcg1",
            "forum": "oxEER3kZ9M",
            "replyto": "oxEER3kZ9M",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6790/Reviewer_hkaL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6790/Reviewer_hkaL"
            ],
            "content": {
                "summary": {
                    "value": "This work tackles the possibility of the detection of AI-generated texts from a perspective of increasing sample sizes (length). Specifically, the authors argue that there is a hidden possibility of the detection even with the machine and human text distributions close to each other, if more samples can be collected/used. They derive sample complexity bounds for their finding and corroborate the results with empirical experiments in conditional generation (e.g., on news or Wikipedia articles)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper is tackling an important problem on the possibility of detecting machine-generated text. The writing of the paper is overall clear, and the authors explore several empirical experiments to support the theoretical findings (on the hidden possibility of detection)."
                },
                "weaknesses": {
                    "value": "The novelty of the finding. While the \"hidden possibility\" argument over the increasing sample size and increasing detectability of machine-generated texts is valid and intuitive, the novel insight in the argument is rather limited. The assumption and use of an increasing sample size/length in the machine-generated text detection problem is regular, for example, in watermarking (Kirchenbauer et al., 2023). The practical takeaway of the finding is relatively vague.\n\nThe experimental setup. In (1) and (2) of Section 4.1, the detector setup is very basic, for example, with n-gram features and linear classifiers. Then, if a 6-gram detector (in the basic setup) can achieve 97% accuracy in detection, is the possibility of detection still a relevant concern? Additionally, the experiments can be conducted on question-answering/instruction-following based tasks (e.g., generating chatbot-style answers) instead of only performing completions on news or Wikipedia articles."
                },
                "questions": {
                    "value": "Please see the weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6790/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699536778107,
            "cdate": 1699536778107,
            "tmdate": 1699636784384,
            "mdate": 1699636784384,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CwJeYmfVQ6",
                "forum": "oxEER3kZ9M",
                "replyto": "cOoiSztcg1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6790/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6790/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer hkaL (Part1)"
                    },
                    "comment": {
                        "value": "**General Response:** Thank you for your review and recognition of the importance of our work in detecting AI-generated texts. We are glad you found the paper clear and the empirical experiments supportive of our theoretical findings. Your feedback is invaluable in highlighting the strength and importance of our research.\n\n## Weakness\n\n> **Weakness 1:** The novelty of the finding. While the \"hidden possibility\" argument over the increasing sample size and increasing detectability of machine-generated texts is valid and intuitive, the novel insight in the argument is rather limited. The assumption and use of an increasing sample size/length in the machine-generated text detection problem is regular, for example, in watermarking (Kirchenbauer et al., 2023). The practical takeaway of the finding is relatively vague.\n\n**Response to Weakness 1**: Thanks for appreciating our finding regarding the \"hidden possibility\" of AI-generated text detection. Regarding the novelty, we want to point out that ***our work is the first attempt to theoretically show the \"hidden possibility\" of AI-generated text detection*** and derive the precise sample complexity analysis for the detection problem. These theoretical results provide the insight that the detectability increases as the ***number of samples (tokens)(Theorem 1)/sequence length (Theorem 2)*** increases and also derive the rate of increment. The referred work by Kirchenbauer et al., 2023 is a concurrent work (can't provide more details on the timeline due to anonymity violation) and provides no theoretical analysis, rather provides empirical demonstrations that even validate our theorems for iid and non-iid cases.\n\n***The primary takeaway*** of our approach is to provide theoretically rigorous evidence (connecting it with the text sequence length) that the detection of AI-generated text detection is possible, which is in contrast to recently developed impossibility results in Sadasivan et. al. As highlighted by the Reviewer 6pNs: *\"I feel like the authors are under-selling themselves in the title/abstract/introduction, by focusing on the \"number of samples\" rather than \"sequence length\"*, we will specifically highlight this aspect in our revised version of our work. \n\n**Importance of Our Results.** Additionally, we want to highlight that our theoretical results of characterizing the sample complexity with Chernoff information (for iid and non-iid scenarios) are critical and provide additional insights (detailed in Appendix A) for example\n\n1. Watermark Design: Our analysis suggests adaptive watermark designs based on Chernoff information and sample complexity, enhancing robustness against attacks\u2014a future research avenue.\n2. Length Constraints in Exams: Our bounds inform optimal summary lengths for easier cheating detection, leveraging the Chernoff metric."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6790/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700202352481,
                "cdate": 1700202352481,
                "tmdate": 1700202352481,
                "mdate": 1700202352481,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "i5k0ZsnISb",
                "forum": "oxEER3kZ9M",
                "replyto": "cOoiSztcg1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6790/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6790/Authors"
                ],
                "content": {
                    "title": {
                        "value": "New Experimental Results on Question-Answering Based Task"
                    },
                    "comment": {
                        "value": "**New Experimental Results ([Figure 11 in Appendix E in the updated draft](https://openreview.net/pdf?id=oxEER3kZ9M)):** As requested by the reviewer, we have also validated the detection performance on Question-answering style task with OpenAI's Roberta classifier and observe that with the increase in sequence length for detection, the zero-shot detection performance of both the models improves significantly from around 55\\% to 98\\% validating our theorem for QA tasks. \n\nPlease let us know if we can address any more concerns before the rebuttal period ends. Thank you so much. We look forward to your feedback."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6790/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700706567059,
                "cdate": 1700706567059,
                "tmdate": 1700706567059,
                "mdate": 1700706567059,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]