[
    {
        "title": "A Simple and Scalable Representation for Graph Generation"
    },
    {
        "review": {
            "id": "JN5XIzCplP",
            "forum": "nO344avRib",
            "replyto": "nO344avRib",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3577/Reviewer_aPij"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3577/Reviewer_aPij"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a molecule graph generation model GEEL, whose backbone can be LSTM or Transformer. GEEL is scalable to relatively large graphs in molecule generation. GEEL reduces the vocabulary size of the edge list representation by using intra- and inter-edge gap encodings. This proposed edge encoding method is novel."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. It is good to have a table like Table 9 to show reproduced datasets.\n2. The intra- and inter-edge gap encoding is delicate and useful.\n3. The use of LSTM reduces the time complexity."
                },
                "weaknesses": {
                    "value": "1. There is a problem in Appendix C.1 Table 11 (b) Large graphs (|V|max \u2264 187).\n\n2. For the molecule generation task, it is important to generate some novel molecules for further filtering in drag design and other real-world scenarios. This paper does not evaluate the portion of the novel-generated molecules in Table 4. In the extreme case, the model may only be able to generate molecules in the training set.\n\n3. It is hard to claim that GEEL outperforms BiGG. In Table 1, the performance is close. In terms of speed, BiGG runs on GeForce GTX 1080 Ti while GEEL runs on GeForce RTX 3090, which makes Table 2\u2019s result unfair."
                },
                "questions": {
                    "value": "If this paper includes some ablation study of replacing the intra- and inter-edge gap encoding with traditional encodings, it will be better. Table 6 could include more experiment results. The parameter size can be adjusted to avoid Out-Of-Memory."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3577/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698676643042,
            "cdate": 1698676643042,
            "tmdate": 1699636312608,
            "mdate": 1699636312608,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dKa2Xej6y2",
                "forum": "nO344avRib",
                "replyto": "JN5XIzCplP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3577/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3577/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear reviewer aPij,\n\nWe sincerely appreciate your comments and efforts in reviewing our paper. We think our paper has much improved in terms of clarity and rigorous evaluation, thanks to your comment. We especially found your comment **W3** to be critical to correct our unclear description of the computational environment! \n\nWe address your question as follows. We also updated our manuscript which is highlighted in $\\color{red}{\\text{red}}$. \n\n---\n\n**W1. There is a problem in Appendix C.1 Table 11 (b) Large graphs (|V|max \u2264 187).**\n\nThank you for pointing out the typo. We fixed this to $399 \\leq |V|_{\\max} \\leq 5037$ in our manuscript.\n\n---\n\n**W2. Provide the novelty and uniqueness rates achieved by GEEL in the molecular generation experiments.**\n\nThank you for pointing out additional metrics for molecular graph generation. We provide the novelty and uniqueness in the following table and updated the performance of molecular graph generation in our manuscript. One can observe that our GEEL shows competitive novelty and uniqueness compared to the baselines. We updated Table 16 in Appendix F of our manuscript.\n\n\n|                 |             |   QM9 |       |  ZINC |        |\n| --------------- | ----------- | -----:| -----:| -----:| ------:|\n|                 |             | Uniq. |  Nov. | Uniq. |   Nov. |\n| Molecule        | MoFlow      | 98.65 | 94.72 | 99.99 | 100.00 |\n|                 | STGG        | 96.76 | 72.73 | 99.99 |  99.89 |\n| Domain-agnostic | DiGress     | 96.67 | 25.58 | 99.97 |  99.89 |\n|                 | DruM        | 96.90 | 24.15 | 99.97 |  99.99 |\n|                 | GEEL (Ours) | 96.08 | 22.30 | 99.97 |  99.98 |\n\nWe note that the models make a tradeoff between the quality (e.g., NSPDK and FCD) and novelty of the generated graph since the graph generative models that faithfully learn the distribution put a high likelihood on the training dataset. In particular, the tradeoff is more significant in QM9 due to the large dataset size (134k) compared to the relatively small search space (molecular graphs with only up to nine heavy atoms). We also note that one can compensate for the non-unique and non-novel molecules by filtering them out and generating new molecules.\n\n---\n**W3. It is hard to claim that GEEL outperforms BiGG. In Table 1, the performance is close. In terms of speed, BiGG runs on GeForce GTX 1080 Ti while GEEL runs on GeForce RTX 3090, which makes Table 2\u2019s result unfair.**\n\nThank you for pointing out the unclarity. We conducted the inference time analysis in Table 2 on the same computational environment (GTX 1080 Ti) for all the models including GEEL and BiGG. We have clarified this in our updated manuscript in Appendix B.3.\n\nHence, one can safely conclude that GEEL is faster than BiGG. Furthermore, we claim that GEEL slightly outperforms BiGG in Table 1 since GEEL is marked bold for 20 out of 24 metrics in Table 1, while BiGG is marked bold for 14 out of 24 metrics. As mentioned in Section 4.1, we mark the numbers in bold if it is comparable to the metrics of the training graphs.\n\n---\n\n**Q1. If this paper includes some ablation study of replacing the intra- and inter-edge gap encoding with traditional encodings, it will be better. Table 6 could include more experiment results. The parameter size can be adjusted to avoid Out-Of-Memory.**\n\nThe ablation study of replacing the intra- and inter-edge gap with traditional encodings (i.e., original edge list) is in Table 6.  The edge list (second row) indicates the traditional encodings and the edge list + intra gap (third row) indicates employing only intra-edge gap. We updated our manuscript to clarify what each row in Table 6 means.\n\nNotably, the traditional encoding encounters out-of-memory in our computational environment even after adjusting the parameters or even setting the batch size to 1. This supports the superiority of our GEEL, concerning the memory requirement."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700186954222,
                "cdate": 1700186954222,
                "tmdate": 1700186954222,
                "mdate": 1700186954222,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GEnZnBjcRL",
                "forum": "nO344avRib",
                "replyto": "JN5XIzCplP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3577/Reviewer_aPij"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3577/Reviewer_aPij"
                ],
                "content": {
                    "comment": {
                        "value": "I have read the responses from the authors. I maintain my rating. The responses only addressed some of my concerns.\n\nBTW, it should be \"Related Work\", instead of \"Related Works\"."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700676678833,
                "cdate": 1700676678833,
                "tmdate": 1700712923443,
                "mdate": 1700712923443,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fsgVHOSPEn",
                "forum": "nO344avRib",
                "replyto": "JN5XIzCplP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3577/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3577/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for acknowledging our response and the efforts to review our paper. \n\nWe would be grateful if you could let us know your unresolved concern. The concern might be something we could resolve easily, e.g., miscommunication during the rebuttal phase. It would also help us improve our work.\n\n~~We were unsure of what you meant by *it should be \"Related Work\", instead of \"Related Work\".*,  but we changed our \"Related Works\" to \"Related Work\" section. Please let us know if we wrongly interpreted your comment.~~"
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700697447932,
                "cdate": 1700697447932,
                "tmdate": 1700728468971,
                "mdate": 1700728468971,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "3vLCUCmjdb",
            "forum": "nO344avRib",
            "replyto": "nO344avRib",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3577/Reviewer_RDfu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3577/Reviewer_RDfu"
            ],
            "content": {
                "summary": {
                    "value": "Good paper, extensive evaluations.\n\nThe paper proposes a simple and scalable graph representation i.e  gap encoded edge list (GEEL) for graph generative modeling.\nThe  representation size  aligns with the number of edges instead of nodes, consequently low size and more applicable for sparse graphs.\n\nThere do exists works which use O(#edges) for representation, however, the proposed work GEEL further reduces the edge list representation by reducing vocabulary size from N^2 to B^2, where B is graph bandwidth.\n\nThe authors extend their approach to attributed graphs(having labels).\n\nEmpirical evaluation is performed on a large number of attributed and non-attributed datasets on a diverse set of graph similarly metrics.\nThe approach also scales better in terms of inference speed when compared to existing works.\n\nOverall the approach shows significant improvements over existing methods for graph generative modeling tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Novel approach for graph generative modeling-> compact representation of data.\n\n2. Paper is easy to read. The authors clarify the need of each component. Diagrams are provided for better understanding of the method.\n\n3. Ablation studies are conducted to understand  impact of different sequence encoding(DFS, BFS etc.), diff architectures for sequence modeling such as LSTM, Transformers etc.\n\n4.High reproducibility: The experimental section is very detailed  with respect to the current work as well as baselines. Code is also provided.\n\n5. The authors also visualize generated graphs.\n\nSignificance:\nThe proposed method could pave way for advancing research in context of graph generative modeling especially w.r.t to larger graphs( which are also attributed)."
                },
                "weaknesses": {
                    "value": "I would point to the questions section for details\n\n1. Not clear how many graphs are generated for comparison.\n\n2. Results on uniqueness and novelty metric seem to be missing.\n\n3. Scalability analysis doesn't seem to be complete.\n\nI request the authors to look into the questions section for details on each of the above point."
                },
                "questions": {
                    "value": "1. It is not clear or I could not find out how many graphs were generated by the proposed method/ baselines for each dataset? I agree MMD is computed but how many graphs were generated? Request the authors to add this.\n\n2. Results on Uniqueness and Novelty seem to be missing. It is not clear whether the generated graphs have duplicacy etc.\nRefer metrics section of [A] for details.\nAdding these metrics(atleast for few datasets) could further improve the quality of the manuscript.\n\n3. Could the authors clarify how scalaibiltiy results are computed? I mean is batch size etc. set to 1? \nAlso since GraphGen[A] also works at edge list level O(#Edges), I would expect the authors to compare with GraphGen for scalability comparison.\nCan the authors justify why generation time is shown for one graph? Could it be an outlier?  I see only one number without any standard deviation etc.\nWould it make sense to generate a batch of graphs and report mean+std dev.\n\n\n\n\n\n[A]Goyal et al. GraphGen: A Scalable Approach to Domain-agnostic Labeled Graph Generation, WWW 2020"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3577/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3577/Reviewer_RDfu",
                        "ICLR.cc/2024/Conference/Submission3577/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3577/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698765993063,
            "cdate": 1698765993063,
            "tmdate": 1700577906201,
            "mdate": 1700577906201,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hwRrnZKMix",
                "forum": "nO344avRib",
                "replyto": "3vLCUCmjdb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3577/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3577/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear reviewer RDfu,\n\nWe sincerely appreciate your comments and efforts in reviewing our paper. We address your question as follows. We also updated our manuscript which is highlighted in $\\color{red}{\\text{red}}$. We think our paper has much improved in terms of clarity and rigorous evaluation, thanks to your comment. \n\n---\n\n**W1/Q1. It is not clear how many graphs were generated for evaluation.**\n\nThank you for pointing out the unclarity. Following prior works [1, 2], we generated graphs with the same number of test graphs. We updated our manuscript to clarify this in Section 4.1.\n\n---\n\n**W2/Q2. Results on uniqueness and novelty metrics seem to be missing.**\n\nThank you for such an insightful comment! Following your suggestion, we evaluated the validity, novelty, and uniqueness of GEEL and the considered baselines. We report the new results in Table 15 and Table 16 of Appendix F. We think our empirical results are now much more comprehensive and reliable, thanks to your review.\n\nIn our new experiments, GEEL achieves the 30\\% \\~ 90\\% novelty, which is better than autoregressive models like GRAN and BiGG, but lower than the diffusion-based graph generative models as the reviewer anticipated. This is partially due to the inherent trade-off between novelty and the capability of generative models to faithfully learn the data distribution. Even diffusion models suffer from this trade-off, e.g., DiGress achieves 30\\% novelty for the QM9 dataset. We also note that this trade-off is less severe for harder problems, e.g., point cloud and ZINC250k, which is the main target of our work.\n\nFinally, we note the minor modification of GEEL in the new experiments. Our GEEL now samples a new C-M ordering for a graph at each training step (instead of fixing a unique ordering per graph). We found this to improve novelty without a decrease in performance and changing the architecture. We updated all of our experimental results to incorporate this change. Note that the results for the Ego dataset are to be updated, as the experiments have not yet been completed.\n\n\n\n---\n\n**W3/Q3-1. Could the authors clarify how scalability results are computed?**\n\nWe conducted inference time analysis by setting the batch size to 10 and dividing the total inference time by 10 to compute the generation time for a single graph. Therefore, the reported inference time is not an outlier that shows the time for a single graph generation. We updated our manuscript to clarify this in Appendix B.\n\n**Q3-2. Since GraphGen works at the edge list level, I would expect the authors to compare with GraphGen in Table 6.**\n\nTo incorporate your suggestion, we will add a comparison with GraphGen in our future manuscript. Please understand that we are unable to provide the result during the rebuttal phase. Unfortunately, we currently do not have the computational environment (GeForce GTX 1080 Ti) used for Table 6, which is necessary for a fair comparison.  \n\n\n**References**\n[1] Jo, J., et al., Score-based generative modeling of graphs via the system of stochastic differential equations. ICML 2022.\n\n[2] Martinkus, K., et al., SPECTRE: Spectral conditioning helps to overcome the expressivity limits of one-shot graph generators. ICML 2022."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700186880160,
                "cdate": 1700186880160,
                "tmdate": 1700186880160,
                "mdate": 1700186880160,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5O2OjBvwQB",
                "forum": "nO344avRib",
                "replyto": "3vLCUCmjdb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3577/Reviewer_RDfu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3577/Reviewer_RDfu"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for the detailed feedback and rebuttal.\n\n1. I am happy the authors added additional results on novelty and uniqueness. The metrics don't seem to be very good. So does that mean, they are replicating training data and not generating diverse samples? \n\n2. I appreciate the authors for clarifying the novelty w.r.t BWR baseline of ICML 2023.\n\n3. I don't see any comparison with BWR baseline for any tables in the appendix and Tab 2 and 4 in main paper. Is there any specific reason?\n\n\nCan the authors clearly justify the gains their method has against BWR( in terms of quality and scalability demonstrating on multiple datasets under  ) to make the manuscript more clear. \n\n I am not sure if the manuscript is ready for publication yet. If the authors can better clarify things, it would be better.\n\nI am changing my score to weak accept for now."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700577878009,
                "cdate": 1700577878009,
                "tmdate": 1700577948707,
                "mdate": 1700577948707,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oDV8S34tlY",
                "forum": "nO344avRib",
                "replyto": "3vLCUCmjdb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3577/Reviewer_RDfu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3577/Reviewer_RDfu"
                ],
                "content": {
                    "title": {
                        "value": "Thank you :)"
                    },
                    "comment": {
                        "value": "I thank the authors for the clarifications.\nMost of my concerns have been resolved. \n\nI keep my score to 6 and would recommend acceptance of the paper for their interesting ideas \nOverall it's a good paper :)."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700669814470,
                "cdate": 1700669814470,
                "tmdate": 1700669862864,
                "mdate": 1700669862864,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "JlkgoGukwO",
            "forum": "nO344avRib",
            "replyto": "nO344avRib",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3577/Reviewer_kVSU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3577/Reviewer_kVSU"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes GEEL, a novel method to generate graphs starting from their sorted edge list. In particular, the edge list is encoded through gaps: each pair of nodes representing an edge becomes a pair where the first element is the gap from the previous pair's first element, while the second element encodes the gap from the current pair's first element. This has the advantage of reducing the vocabulary size from $N^2$ (where $N$ is the number of graph nodes) to $B^2$ (where $B$ is the graph bandwidth), while maintaining the cost of training and inference to be $O(M)$ (where $M$ is the number of edges). The method is extended to deal with attributed graphs by proposing a simple grammar whose elements are triplets of the form (node type token, gap-encoded edge, edge type token), plus rules to compose them meaningfully. \n\nThe generative model is an auto-regressive LSTM that is trained to maximize the likelihood of the training graphs (represented as sequences of gap-encoded edge pairs). The model is evaluated extensively in task of generating a) standard non-attributed graphs such as lobster, ego, community and b) molecules. The experiments show that a) the proposed approach achieves good generative performance with respect to a wide pool of competitors, b) it uses a parsimonious representation which allows reduced vocabulary size and competitive training/inference cost. Lastly, ablation studies are presented to justify the architectural choices."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "I am very pleased with this paper: it is written clearly and easy to follow. On the technical side, it presents a simple but empirically effective contribution, which addresses most of the challenges of edge-list based graph generative methods, namely the large vocabulary sizes and the burden of having to learn long-term dependencies as a consequence. Following, a list of things I identify as strengths:\n\n- The main contribution (the gap-encoded edge list) is novel.\n- The proposed approach is extremely simple yet very effective.\n- The literature review is satisfactory (although it is missing [1] as another edge-list based generative method, but that is a minor omission).\n- The experiments are thorough, spanning across different graph types and a not common wide range of baselines.\n- I appreciated the ablation study which help understanding why certain modelling choices were taken.\n\n\n\n[1] Bacciu et al., Edge-based sequential graph generation with recurrent neural networks. Neurocomputing 2020."
                },
                "weaknesses": {
                    "value": "The weaknesses I have found are by no means fatal, and I believe they could be addressed through proper rebuttal. In particular:\n\n- perhaps this article is not well-suited for ICLR, since the focus should be on learning representations, but this paper does not revolve around representation learning. Again, I don't think this is fatal, and I would like to hear how this work places itself in the context of this conference by the authors.\n\n- while very effective, this method has also limitations which are not mentioned by the authors. The main one being the fact that it is still a vocabulary-based approach that cannot generalize to graphs with gap-encoded edges not present in the vocabulary. Another one is the dependency on the bandwidth $B$, which can sometimes be $\\approx N$ due to outliers. I understand that this can be bypassed by removing the outliers, but then again it restricts the applicability of the method to a certain class of graphs (those with low bandwidth) to exploit the concise gap-encoding."
                },
                "questions": {
                    "value": "I have some:\n\n- What do the asterisks placed after Graphgen and Graphgen-redux in Table 1 mean?\n- What is meant by \"comparable\" MMD? Which criteria is used to define two MMDs comparable?\n- In Figure 4, what is the value of the $c_1$ and $c_2$ constants? Have they been explicitly calculated?\n- What are the novelty and uniqueness rates achieved by GEEL in the molecular generation experiments? How do they compare to the competitors? For example, I recall CharRNN has a novelty rate of about 84% on the MOSES benchmark, while STGG has a novelty rate of 67% on the same benchmark.\n- Speaking of which, I think it would be better to add the performances of the method in the MOSES benchmark. It should be fairly doable in a short time since the method is fast both in training and inference.\n- What are the vocabulary sizes for the molecular generation experiments (on QM9 and ZINC250k)?\n- Which order is used to encode the edge list of molecules? Is it the SMILES canonical order?\n- If the answer to the question above is yes: as you might know, SMILES works by generating a spanning tree, and then adding the edges that close the rings at the end. Don't you think this kind of process is not ideal to gap-encode the edge list of molecules (since the second element of the closing ring edges would have an abnormally wider gap with respect to the other edges)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None."
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3577/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3577/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3577/Reviewer_kVSU"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3577/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698837174576,
            "cdate": 1698837174576,
            "tmdate": 1700667111929,
            "mdate": 1700667111929,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lsICdKctHi",
                "forum": "nO344avRib",
                "replyto": "JlkgoGukwO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3577/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3577/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear reviewer kVSU,\n\nWe sincerely appreciate your comments and efforts in reviewing our paper. We think our paper has much improved in terms of clarity and positioning our work, thanks to your comment. \n\nWe address your question as follows. We also updated our manuscript which is highlighted in $\\color{red}{\\text{red}}$.\n\n---\n\n**W1. The work is perhaps not well-suited for ICLR since it does not include any learning representations.**\n\nThank you for checking this. We would like to point out that ICLR 2024 mentions \"generative models\" as one of the relevant topics in its call for papers (https://iclr.cc/Conferences/2024/CallForPapers). Hence we believe our work (graph generative model) aligns with the context of ICLR.\n\nWe also provide a few examples of similar works in previous ICLRs:\n- Shi, C., et al., GraphAF: a Flow-based Autoregressive Model for Molecular Graph Generation, ICLR 2020.\n- Liu, M., et al., GraphEBM: Molecular Graph Generation with Energy-Based Models, ICLR 2021.\n- Vignac, C., et al., DiGress: Discrete Denoising diffusion for graph generation, ICLR 2023.\n\n---\n\n**W2-1. It is not mentioned that GEEL cannot generate graphs with unseen tokens, since it is a vocabulary-based approach.**\n\nWe agree with your comment and mentioned this in our updated manuscript in Appendix G. Nonetheless, we believe the generalization capability of our GEEL is strong enough in practice. In all the experiments, we verified that our vocabulary obtained from the training dataset entirely captures the vocabulary required for generating graphs in the test dataset. \n\n**W2-2. It is not mentioned that GEEL depends on the bandwidth $B$, which can be $\u2248N$ for outliers.** \n\nWe agree with your comment and mentioned this in our updated manuscript in Appendix G. As you mentioned, one could bypass this issue by removing the outlier graph or even removing the particular edge that increases the bandwidth. One also could consider (a) decomposing the graph into subgraphs with small bandwidth and (b) separately generating the subgraphs using GEEL. This would be an interesting future avenue of research. \n\nFinally, as the reviewer mentioned, we would like to re-emphasize how the case $N\\approx B$ is quite rare in practice.\n\n---\n\n**Q1. What do the asterisks placed after Graphgen and Graphgen-redux in Table 1 mean?**\n\nThank you for pointing out this typo. The asterisks indicated edge list-based graph generative models, but we deleted them since they are not very informative. We instead mention that Graphgen and Graphgen-redux are edge list-based graph generation methods in Section 4. \n\n---\n\n**Q2. What is meant by \"comparable\" MMD? Which criteria is used to define two MMDs comparable?**\n\nThe comparability of MMD values is determined by examining whether the MMD falls within a range of one standard deviation (reported in Table 11 of Appendix C.1). This was explained in the evaluation protocol in Section 4.1, but we also added this to the caption of Table 1 to further be more clear. \n\n---\n\n**Q3. In Figure 4, what is the value of the c1 and c2 constants? Have they been explicitly calculated?**\n\nThe constants $c_1$ and $c_2$ in Figure 4 are 0.5 and 2, respectively. We added the lines for visual alignment between the inference time and the theoretical computational complexity $O(M)$, where $M$ is the number of edges. We tried a few values to select the visually plausible constants.\n\n---\n\n**Q4. What are the novelty and uniqueness rates achieved by GEEL in the molecular generation experiments?**\n\nThank you for pointing out additional metrics for molecular graph generation. We provide the novelty and uniqueness in the following table and updated the performance of molecular graph generation in our manuscript. We can observe that our GEEL shows competitive novelty and uniqueness compared to the baselines. We reported the new results in Table 16 of Appendix F.\n\n|                 |             |   QM9 |       |  ZINC |        |\n| --------------- | ----------- | -----:| -----:| -----:| ------:|\n|                 |             | Uniq. |  Nov. | Uniq. |   Nov. |\n**Molecule-specific**       | MoFlow      | 98.65 | 94.72 | 99.99 | 100.00 |\n|                 | STGG        | 96.76 | 72.73 | 99.99 |  99.89 |\n| **Domain-agnostic** | DiGress     | 96.67 | 25.58 | 99.97 |  99.98 |\n|                 | DruM        | 96.90 | 24.15 | 99.97 |  99.99 |\n|                 | GEEL (Ours) | 96.08 | 22.30 | 99.97 |  99.89 |\n\nWe note that the models make a tradeoff between the quality (e.g., NSPDK and FCD) and novelty of the generated graph since the graph generative models that faithfully learn the distribution put a high likelihood on the training dataset. In particular, the tradeoff is more significant in QM9 due to the large dataset size (134k) compared to the relatively small search space (molecular graphs with only up to nine heavy atoms). We also note that one can compensate for the non-unique and non-novel molecules by filtering them out and generating new molecules."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700186604707,
                "cdate": 1700186604707,
                "tmdate": 1700186604707,
                "mdate": 1700186604707,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZiKMmYu2Vc",
                "forum": "nO344avRib",
                "replyto": "rKyV8d8k3a",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3577/Reviewer_kVSU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3577/Reviewer_kVSU"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "I have read your responses, the overall conversations and the updated manuscript. I was aware of the existence of BwR, and I understand that the attribution of BwR was a bit unclear to anyone who didn't know about the method. I'm glad you fixed it and that is now clearly expressed. My concerns are resolved, so I'm raising my score to an 8. Good luck!"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700667082098,
                "cdate": 1700667082098,
                "tmdate": 1700667082098,
                "mdate": 1700667082098,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "eNFkdlEnkI",
            "forum": "nO344avRib",
            "replyto": "nO344avRib",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3577/Reviewer_EmZF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3577/Reviewer_EmZF"
            ],
            "content": {
                "summary": {
                    "value": "Authors introduce a new parametrization for sequential generation of graphs. The parametrization is based on edge-lists with the main trick being encoding not the node IDs but difference between them. The use of C-M ordering is promoted and shown to be better than the usual DFS or BFS orderings used in the previous autoregressive models. Overall the proposed architecture is shown to be much faster than existing approaches and offer better or competitive results in graph generation quality."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The proposed representation is very interesting and efficient. It also meshes well with the C-M ordering. \nThe choices are extensively ablated and shown to be better than alternatives. The experimental performance overall seems strong and experimental scalability is good. \nThe paper is well written and easy to follow."
                },
                "weaknesses": {
                    "value": "My main concern with the paper are the evaluation metrics reported for the graph generation. First, only local MMD scores are reported (e.g. no Spectral MMD as used in GRAN or SPECTRE), but mainly that the novelty and uniqueness of the generated examples is not reported. As shown in the SPECTRE paper, autoregressive models such as GRAN can overfit the training set to a point, where effectively no novel samples are produced, while at the same time producing amazing MMD metrics. Since this work is essentially turbocharging the autoregressive generation, especially with the relative node ID representation, one could imagine that such overfitting would be a problem. After all this overfitting is one of the main motivations for using one-shot generative models without a given node ordering. Uniqueness and novelty is also commonly reported for the molecule generation as well.\n\nIt would also be interesting to see how some of the one-shot methods (e.g. DiGress) would perform with the C-M ordering and node IDs. As they tend to make GNNs more powerful. Actually a recent paper (https://arxiv.org/pdf/2307.01646.pdf) showed quite some improvements in the one-shot graph generators by using a known ordering. It would make sense to include this in the baselines."
                },
                "questions": {
                    "value": "I would really like to see the uniqueness and novelty for all the models in the datasets that were tested. Validity as introduced in SPECTRE is also an interesting measure to have, that's maybe more easy to interpret than the MMDs, where it is available.\n\nI'll raise my score if this is addressed. I just don't think we can accept the paper without this information.\n\n### After Rebuttal\nI thank the authors for all the additional experiments and adjustments, esp. w.r.t. BwR.\nWhile the novelty and uniqueness of generated graphs is mediocre and performance is not really better than the newest one-shot models (e.g. SwinGNN), the proposed change is neat and does improve upon autoregressive baselines. Thus I raise my score."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3577/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3577/Reviewer_EmZF",
                        "ICLR.cc/2024/Conference/Submission3577/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3577/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698841517097,
            "cdate": 1698841517097,
            "tmdate": 1700815941007,
            "mdate": 1700815941007,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mMvXuX35tP",
                "forum": "nO344avRib",
                "replyto": "eNFkdlEnkI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3577/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3577/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear reviewer EmZF,\n\nWe sincerely appreciate your comments and efforts in reviewing our paper. We think our paper has much improved in terms of comprehensive evaluation and clarity, thanks to your comment. We especially found your comment **W1** very insightful!\n\nWe address your question as follows. We also updated our manuscript which is highlighted in $\\color{red}{\\text{red}}$.\n\n---\n\n**W1/Q1. The novelty, uniqueness, and validity of the generated examples are not reported.** \n\nThank you for such an insightful comment! Following your suggestion, we evaluated the validity, novelty, and uniqueness of GEEL and the considered baselines. We report the new results in Table 15 and Table 16 of Appendix F. We think our empirical results are now much more comprehensive and reliable, thanks to your review.\n\nIn our new experiments, GEEL achieves around 30\\% \\~ 90\\% novelty, which is better than autoregressive models like GRAN and BiGG, but lower than the diffusion-based graph generative models as the reviewer anticipated. This is partially due to the inherent trade-off between novelty and the capability of generative models to faithfully learn the data distribution. Even diffusion models suffer from this trade-off, e.g., DiGress achieves around 30\\% novelty for the QM9 dataset. We also note that this trade-off is less severe for harder problems, e.g., point cloud and ZINC250k, which is the main target of our work.\n\nFinally, we note the minor modification of GEEL in the new experiments. Our GEEL now samples a new C-M ordering for a graph at each training step (instead of fixing a unique ordering per graph). We found this to improve novelty without a decrease in performance and changing the architecture. We updated all of our experimental results to incorporate this change. Note that the results for the Ego dataset are to be updated, as the experiments have not yet been completed.\n\n---\n\n**W2. A recent paper (SwinGNN) showed quite some improvements in the one-shot graph generators by using a known ordering.**\n\nThank you for the suggestion. We provide the comparison below and in our updated manuscript. \n\n|         |           | Ego-small |           |           | Com-small |           |\n| ------- |:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|\n|         |   Deg.    |   Clus.   |  Orbit.   |   Deg.    |   Clus.   |  Orbit.   |\n| SwinGNN | 0.000 | 0.021 | 0.004 | 0.003 | 0.051 | 0.004 |\n| GEEL (Ours)    | 0.020 | 0.035 | 0.012 | 0.020 | 0.022 |   0.006   |\n\n|         |       | Grid |        |       | Proteins |        |\n| ------- |:-----:|:---------:|:------:|:-----:|:---------:|:------:|\n|         | Deg.  |   Clus.   | Orbit. | Deg.  |   Clus.   | Orbit. |\n| SwinGNN | 0.000 |   0.000   | 0.000  | 0.002 |   0.016   | 0.003  |\n| GEEL (Ours)    |   0.000    |  0.000         |     0.000   |    0.002   |   0.001        |    0.004    |\n\nNote that SwinGNN does not provide any novelty or uniqueness, hence it is unclear whether if SwinGNN bypasses the overfitting issue. For the considered metrics, both GEEL and SwinGNN showed high graph generation quality."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700186416987,
                "cdate": 1700186416987,
                "tmdate": 1700186416987,
                "mdate": 1700186416987,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kDu3BtMNdv",
                "forum": "nO344avRib",
                "replyto": "eNFkdlEnkI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3577/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3577/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Additionally, we clarify that the usage of C-M ordering for autoregressive graph generation is first proposed by BwR [1], not by us. To avoid confusion, we updated our manuscript to clarify this.\n\n[1] Diamant et al., Improving Graph Generation by Restricting Graph Bandwidth, ICML 2023."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3577/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700545561385,
                "cdate": 1700545561385,
                "tmdate": 1700545780920,
                "mdate": 1700545780920,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]