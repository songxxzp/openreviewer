[
    {
        "title": "ReLiK: Retrieve, Read and LinK: Fast and Accurate Entity Linking and Relation Extraction on an Academic Budget"
    },
    {
        "review": {
            "id": "ucX6pk7TSU",
            "forum": "b0IRscfEOb",
            "replyto": "b0IRscfEOb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9353/Reviewer_5PKz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9353/Reviewer_5PKz"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes ReLiK, a retriever-reader model for entity linking and relation extraction. ReLiK encodes input text with retrieved candidate entities/relations and can link entities or extract relations in one pass. ReLiK achieves state-of-the-art results on multiple benchmarks while being faster, more parameter efficient, and trainable on a smaller budget than prior art."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper generally has a good presentation that clearly allows readers to understand what was done.\n2. ReLiK establishes state-of-the-art results on benchmarks for entity linking and relation extraction. The joint model for closed IE is also insightful.\n3. ReLiK is faster than prior state-of-the-art models, with gains of 10-40x reported on inference speed. This makes it much more usable in real applications."
                },
                "weaknesses": {
                    "value": "1. Although ReLiK integrates entity linking and relation extraction together into one framework, the design for each module is relatively simple and similar to previous works.\n2. As one of the emphases of this paper is the integration of EL and RE tasks. The mutual influence between EL and RE should be more clearly demonstrated in the experimental analysis section."
                },
                "questions": {
                    "value": "1.\"Recent approaches only focus on at most two out of the three properties simultaneously.\" I don't quite understand this sentence. What are the \"three properties\" referring to\uff1f\n2. I recognize the efficiency gains achieved by linking entities and extracting relations in just a single forward pass. Yet, I'm curious about what is the core design that enables the model to achieve state-of-the-art performance?I recognize the efficiency gains achieved by linking entities and extracting relations in just a single forward pass. Yet, I'm curious about what is the core design that enables the model to achieve state-of-the-art performance?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9353/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9353/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9353/Reviewer_5PKz"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9353/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698665792273,
            "cdate": 1698665792273,
            "tmdate": 1699637176625,
            "mdate": 1699637176625,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kEPidFQ4mi",
                "forum": "b0IRscfEOb",
                "replyto": "ucX6pk7TSU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9353/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9353/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 5PKz"
                    },
                    "comment": {
                        "value": "We first want to thank you for your review. We hope to address some of the concerns and answer your questions.\n\n**Weaknesses**\n\n> \u201cAlthough ReLiK integrates entity linking and relation extraction together into one framework, the design for each module is relatively simple and similar to previous works.\u201d\n\nTo the best of your knowledge, we are the first to design an architecture capable of performing EL and RE in a single forward step in the Retriever-Reader paradigm, while achieving state-of-the-art performances and inference speed. Furthermore, **simplicity, in our view, is not a drawback**. While individual components might bear resemblance to existing models (such as using a Retriever for EL), the real innovation of ReLiK lies in the synergy of these components, which, to the best of our knowledge, we are the first to consider for closed Information Extraction. Moreover, the modularity of ReLiK is a key advantage with respect to other approaches, since ReLiK can be easily enhanced and expanded by leveraging any improvement on each of its components separately.\n\n> \u201cAs one of the emphases of this paper is the integration of EL and RE tasks. The mutual influence between EL and RE should be more clearly demonstrated in the experimental analysis section.\u201d\n\nWe agree, and that is why **we explored such interaction in Appendix A.4.2** and showed how EL helped RE, evidenced by a notable drop in F1 score when RE is isolated. Performance in Table 2 for EL is reported solely on entities present in triplets, but if we check the F1 score for entities in general, validation F1 reached 87.46 for ReLiK small. We ran an experiment where EL was trained with the same data without RE (similar to the experiment reported in A.4.2) and F1 reached 87.5. While, in this case, RE doesn\u2019t seem to provide a benefit to EL, it does not affect negatively either. We would have liked to devote more space to such interactions in the main body; however, in its current shape, the paper already contains a vast array of experiments and ablations that we considered more relevant, at least within the main body. We welcome suggestions for additional experiments to explore this interaction further, and we will happily provide results if there\u2019s time during this rebuttal period, or in the final version of the paper otherwise.\n\n**Questions:**\n> \"Recent approaches only focus on at most two out of the three properties simultaneously.\" I don't quite understand this sentence. What are the \"three properties\" referring to\uff1f\n\nIt refers to \u201cSpeed, Flexibility, and Performance.\u201d, which are mentioned in the previous paragraph. We will make it more clear.\n\n> \u201cI recognize the efficiency gains achieved by linking entities and extracting relations in just a single forward pass. Yet, I'm curious about what is the core design that enables the model to achieve state-of-the-art performance?\u201d\n\n**The inclusion of verbalized labels in the input was crucial**, enabling not only the efficiency of a single forward pass but also enhancing overall performance. We theorize that the Reader benefits from contextualizing the linking task with all candidates, rather than considering each in isolation, as some previous work did. This approach allows the Reader to leverage both the other candidates as well as the order in which they are given by the Retriever. Our ablation studies in A.4.2 show a performance decline when the Retriever's order is disregarded for the RE task. This drop was even more significant for EL, 85.8 for ReLiK Large, vs. 86.5 F1 reported in Table 2, a 0.7 drop which we will report in the final version of the paper. This indicates the Retriever's dual role in both filtering and ranking, which significantly contributes to ReLiK's effectiveness. Moreover, it is also important to point out that using a verbalized label as part of the input allows the model to be more flexible for unseen entities, as the hidden representations are always contextual, whether seen during training or not, rather than fixed for each entity. We believe this is one of the key reasons of the strong Out-of-domain performance reported in Table 2."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9353/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699975266039,
                "cdate": 1699975266039,
                "tmdate": 1699975266039,
                "mdate": 1699975266039,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Uhi3FtaPLV",
            "forum": "b0IRscfEOb",
            "replyto": "b0IRscfEOb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9353/Reviewer_2r4r"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9353/Reviewer_2r4r"
            ],
            "content": {
                "summary": {
                    "value": "This article introduces Retriever & Reader pipeline to Entity Linking (EL) and Relationship Extraction (RE) tasks. ReLiK uses retriever instead of classifiers to discover entities and entity relationships in text, the reader module's role is to identify relevant entities or relations retrieved and align them with the corresponding textual spans. The experimental results show that the proposed methodology strikes a balance between effectiveness and efficiency."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The proposed method has several practical advantages. The reader greatly improve the efficiency of entity linking and relationship extraction.\n\nEmpirical evaluation thoroughly covers a substantial number of datasets."
                },
                "weaknesses": {
                    "value": "The baseline systems used for comparison were not comprehensive enough in Section 4,  and it was recommended that more baseline systems be added for comparison[1], [2], [3].  \n\nSince the contribution of this paper lies in the novel paradigm, the authors could have devoted a chapter to a brief overview of the developmental lineage of the relevant paradigm in order to describe more clearly the special features of this paper.\n\n[1] Johannes M. van Hulst, Faegheh Hasibi, Koen Dercksen, Krisztian Balog, and Arjen P. de Vries. 2020. REL: An Entity Linker Standing on the Shoulders of Giants. In *Proceedings of SIGIR* \n\n[2] Nikolaos Kolitsas, Octavian-Eugen Ganea, and Thomas Hofmann. End-to-end neural entity linking. In *Proceedings of the 22nd Conference on Computational Natural Language Learning*\n\n[3] Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen Fu \u0308rstenau, Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, and Gerhard Weikum. Robust disambiguation of named entities in text. In *Proceedings of the EMNLP*"
                },
                "questions": {
                    "value": "The author mentioned that \u201cReLiK excels in this regard, surpassing previous systems in terms of performance, memory requirements, and speed\u201d, but did not provide a quantitative comparison of memory requirements with other systems.\n\nIn the textual description of Section 3, the word \"passage\" is confusing - does it refer to the entities and relationships obtained by the retriever? The authors need further clarification.\n\nIs there error propagation when the retriever fails to retrieve relationships and entities from top-k results?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9353/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698806785521,
            "cdate": 1698806785521,
            "tmdate": 1699637176521,
            "mdate": 1699637176521,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ru20fDTwsQ",
                "forum": "b0IRscfEOb",
                "replyto": "Uhi3FtaPLV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9353/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9353/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 2r4r"
                    },
                    "comment": {
                        "value": "Thank you for the time taken to review our work. We hope we can address your concerns.\n\n**Weaknesses**\n\n> \u201cThe baseline systems used for comparison were not comprehensive enough in Section 4, and it was recommended that more baseline systems be added for comparison[1], [2], [3].\u201d\n\nUnfortunately, we prioritized including the most current and impactful EL systems for our baseline/comparison systems due to the limited space available. The systems suggested by the reviewer, although valuable, exhibit lower performance than our baselines. However, we will include these lower baselines in a more comprehensive EL comparison in the Appendix.\n\n> \u201cSince the contribution of this paper lies in the novel paradigm, the authors could have devoted a chapter to a brief overview of the developmental lineage of the relevant paradigm in order to describe more clearly the special features of this paper.\u201d\n\nAgain, space constraints led us to focus on the previous trends and systems for each task in sections 4.1.2  and 5.1.2, but we did not have the space to delve into the explanation of Retriever-Reader systems in general. We will add a more detailed explanation of the \u201cdevelopmental lineage\u201d of RR systems in the Appendix.\n\n**Questions:**\n> \u201cThe author mentioned that \u201cReLiK excels in this regard, surpassing previous systems in terms of performance, memory requirements, and speed\u201d, but did not provide a quantitative comparison of memory requirements with other systems.\u201d\n\nWe reported on the GPU requirements of each system, which is indirectly related to memory. However, we will make sure to include a more quantitative comparison for memory. For our systems, training never requires more than 24GB of memory. At inference time, the retriever with e5 base and batch size of 128 uses 881 MB of VRAM. The reader on its larger model (debate-v3-large) with a batch size of 4096 tokens uses 3985 MB of VRAM for EL, 4497 MB of VRAM for RE. As for the passages index for the retriever, it takes 10 GB of VRAM if loaded on the GPU with fp16, and 17 GB of RAM if loaded on the CPU with fp32. For comparison, [Zhang et al. (2022)] index takes 22 GB of RAM with fp32.\n\n> \u201cIn the textual description of Section 3, the word \"passage\" is confusing - does it refer to the entities and relationships obtained by the retriever? The authors need further clarification.\u201d\n\n**Short answer: Yes.** More in general, a \u201cquery\u201d is the input text that will be annotated, while the \u201cpassages'' are the textual representations of the entities or relations to be retrieved using the input query. In Section 3, we adopted the terminology from DPR [Karpukhin et al., 2020] to maintain consistency with prior literature on retriever systems and, therefore, not to be specific on the tasks tackled later, to avoid referring to entities and relations and keep the description of the Retriever-Reader paradigm as general as possible. However, we do understand that it might be confusing. Thanks for pointing it out. We will clarify this in the final version of the paper.\n\n> \u201cIs there error propagation when the retriever fails to retrieve relationships and entities from top-k results?\u201d\n\nYes, whenever the Reader component fails to retrieve an entity/relation, the Reader component cannot link/extract it, and thus either it does not predict it at all (false negative) or it links/extracts a wrong one. However, the retriever has a very high recall, as shown in Table 6 of the Appendix: 99.2 R@100 and 98.8 R@50, and it rarely is the source of errors. We didn\u2019t report on recall for cIE in the paper, but it is R@20 of 99% for relations and R@25 of 98% for entities on the REBEL dataset. We will add these numbers to the paper as well."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9353/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699974951141,
                "cdate": 1699974951141,
                "tmdate": 1699974951141,
                "mdate": 1699974951141,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "EjhiYaDJAD",
            "forum": "b0IRscfEOb",
            "replyto": "b0IRscfEOb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9353/Reviewer_5D75"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9353/Reviewer_5D75"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes ReLiK, a new Retriever-Reader architecture for EL and/or RE. Given an input text, ReLiK allows to extract relations between entities given a reference knowledge base in a single forward pass. The proposed approach achieves state-of-the-art performance for the closed information extraction task (EL + RE) on standard datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The proposed approach offers fast inference and state-of-the-art performance at a reasonably low budget, which is important for various settings. The paper is well-written and easy to follow. The adaptation of the Retriever-Reader paradigm to cIE is original and, to the the best of my knowledge, has not been proposed before."
                },
                "weaknesses": {
                    "value": "The proposed approach is underpinned by access to external knowledge since ReLiK is given as input the text together with entities and relations from the KB. This impacts the performance and efficiency of the model and raises concerns about the fairness of the proposed benchmarks.\n\nMore specifically, the fact that ReLiK relies on the entities and relations from the KB already provides the model with the set of possible entities that can be extracted from the text, which can help for demarcating and disambiguating entities, and also for extracting relations.\n\nThe access to this non-parametric memory is also what enables to considerably lower the number of parameters, thereby offering faster inference time.\n\nAlso, the following recent prior work [1], which uses an end-to-end Reader-Retrieval approach for EL, should be cited in the paper. It would be interesting to see how both methods compare.\n\n\nMinor comments:\n\n- Xs and Xt are not defined in section 3.2, in the definition.\n- The wrong template was used for submission (ICLR 2023)\n\n[1] Bidirectional End-to-End Learning of Retriever-Reader Paradigm for Entity Linking, Li et al., arXiv:2306.12245, 2023"
                },
                "questions": {
                    "value": "What is the point of $<ST_{0}>$ ? It is not associated with any passage and we already have the [SEP] special token to dissociate between the text and the retrieved passages."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9353/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9353/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9353/Reviewer_5D75"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9353/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698928788900,
            "cdate": 1698928788900,
            "tmdate": 1699637176419,
            "mdate": 1699637176419,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CMfWaKX0yy",
                "forum": "b0IRscfEOb",
                "replyto": "EjhiYaDJAD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9353/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9353/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 5D75"
                    },
                    "comment": {
                        "value": "We first want to thank you for your review and hope to answer your questions as well as clear some possible misunderstandings.\n\n**Weaknesses**\n\nThe statements:\n\n>  1. \u201cThe proposed approach is underpinned by access to external knowledge since ReLiK is given as input the text together with entities and relations from the KB. **This impacts the performance and efficiency of the model and raises concerns about the fairness of the proposed benchmarks.**\u201d, and \n2. \u201cMore specifically, the fact that ReLiK relies on the entities and relations from the KB already provides the model with the set of possible entities that can be extracted from the text, which can help for demarcating and disambiguating entities\u201d\n\nMakes us believe this viewpoint might stem from a misunderstanding, which we are eager to resolve. **Every system under comparison uses external knowledge and has access to the possible entities that can be extracted from the text**. Specifically, systems in [De Cao et al. 2021 a] and [De Cao et al. 2021b] both use an external mention-entity index in which, as stated in our paper, every possible mention (e.g., Barack Obama or Washington) is associated with the list of possible entity classes (i.e. Wikipedia titles) that can be associated with them. [Zhang et al. (2022)] and [1], sharing our Retriever approach, access the same non-parametric external knowledge as ours and the set of extractable entities from the text. Therefore, within the tasks of EL and RE, **external knowledge in the form of entity and relation titles, or their definitions, is not a source of unfairness but rather available information for the task**, analogous to a training set with labels. Finally, along with the previous reasoning, we want to be very clear that, **at inference time, ReLiK receives the text as input, and solely the text**. It is the combination of the Retriever and the Reader that is able first to reduce the number of candidates and then link them. The initial search space encompasses the entire set of entities or relations, as is standard in EL and RE systems, thus ensuring fairness in task comparisons against other systems.\n\n\n> *\u201cAlso, the following recent prior work [1], which uses an end-to-end Reader-Retrieval approach for EL, should be cited in the paper. It would be interesting to see how both methods compare.\u201d*\n\n[1] was published in July 2023 as a preprint on Arxiv, with the deadline for ICLR 2024 being in September, and therefore, we were not able to discuss it in the paper at submission time. It is an extension of [Zhang et al. (2022)] with an interesting new end-to-end training approach. Unfortunately, they do not report results on datasets other than AIDA, and the absence of publicly available code impedes direct comparison. Their results on AIDA are in the same ballpark as ours, but the model suffers from the same shortcomings as [Zhang et al. (2022)] in terms of efficiency, or even worse, as they discuss in their Limitations section. For instance, their system requires 50GB of GPU memory, and takes 3.5 hours per epoch on 4 A100 GPUs, while ours can be trained on a single 4090 and takes half an hour per epoch for the Retriever, and the same for the Reader, on its largest version. Exploring the potential integration of our lightweight paradigm into their end-to-end approach remains an intriguing prospect. We will make sure to cover this paper in the final version of the paper.\n\n**Minor Comments**\n> Xs and Xt are not defined in section 3.2, in the definition.\n\nWe will make it more explicit that *s* and *t* denote the indices of start and end tokens of a span in *X*.\n\n> The wrong template was used for submission (ICLR 2023)\nWe are sorry for using the wrong year, and thanks for noticing it. We will update the year number. Luckily, except for the year, the template itself is the same as the 2024 one. \n\n**Questions**\n\n> What is the point of \u27e8ST$_0$\u27e9? It is not associated with any passage and we already have the [SEP] special token to dissociate between the text and the retrieved passages.\n\nThis is explained in the third footnote, found in page 4:\nHere e$_0$ symbolizes NME, i.e. mentions for which the gold entity is not in E, represented by \u27e8ST$_0$\u27e9\n\nTherefore, it is used for EL and cIE when a span cannot be linked to any entity candidate because either it is not in the KB or the Retriever module failed to retrieve it, and therefore it is not present in the candidates. To avoid confusion we will make sure to mention it earlier, where it is first shown in Equation 2."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9353/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699974781526,
                "cdate": 1699974781526,
                "tmdate": 1699974805763,
                "mdate": 1699974805763,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]