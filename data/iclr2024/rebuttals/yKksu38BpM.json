[
    {
        "title": "Faithful and Efficient Explanations for Neural Networks via Neural Tangent Kernel Surrogate Models"
    },
    {
        "review": {
            "id": "9fVryfqT9J",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1902/Reviewer_LB8S"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1902/Reviewer_LB8S"
            ],
            "forum": "yKksu38BpM",
            "replyto": "yKksu38BpM",
            "content": {
                "summary": {
                    "value": "This is an empirical paper on Neural Tangent Kernel (NTK) surrogate models. The content of the paper is two-folded:\n\n1. Several approximations of NTK are introduced and evaluated quantitatively by various metrics through different experiments, showing how theses approximations capture the decision mechanism of Neural Networks (NN) on classification problem.\n2. Then the paper argues how the NTK surrogate models give explanation for NN decision and states its limitation on SVM and adversarial attacks.\n\nThe paper includes a detailed and motivated introduction to Trace NTK and pseudo NTK, and experimental results on various data sets and  NN models. Its appendix contains a detailed section explaining the relationships between different kernels introduced in the paper, and a detailed result of the experiments together with visualisations."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Originality: The paper is innovative to use the Kendall-$\\tau$ rank correlation to evaluate the approximation, such as TrNTK, pNTK, CK...,  on the empirical NTK (eNTK). The angle to experiment on explaining NN by surrogate NTK is also novel. \n\nQuality: The paper is written nicely with rigorous definitions and detailed descriptions on the experiments. \n\nClarity: The paper clearly states the problem and presents their experiments. Also the motivation of the paper is clearly elaborated. \n\nSignificance: The paper is important in the area of explainable AI through the lens of surrogate NTK. This paper could lead to more research on related topics."
                },
                "weaknesses": {
                    "value": "There is barely any flaws in the paper, and the limitation of the experiments is clearly stated in the limitations subsection in section 5."
                },
                "questions": {
                    "value": "I have only one question:\nIn section 5, You mentioned: \"...an interesting follow-on work would investigate using kernel functions in K-Nearest Neighbors surrogate models.\" How much argument of this paper can transfer to KNN or generally any other surrogate models on explaining NN decision?\n\nAlso, there are some of the minor typos in the paper:\n\nSection 2 PRELIMINARIES Neural Networks for Classification third line: it should be \\mathcal{Y} instead of Y.\n\nAppendix F FORMAL DEFINITION OF EVALUATION METRICS last equation: it should be SS_res instead of SS_ret."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1902/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697457725298,
            "cdate": 1697457725298,
            "tmdate": 1699636120758,
            "mdate": 1699636120758,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "IGRNLsXawI",
                "forum": "yKksu38BpM",
                "replyto": "9fVryfqT9J",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1902/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1902/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "1. We thank the reviewer for their time, and echo their excitement about the results. We believe the core strengths of the paper are: a) identifying a metric Kendall-$\\tau$ that is a better measure of faithfulness over the previously used test accuracy in comparison of similarity between models, and b) presentation of the evidence we collect that challenge the assumption of sparsity in data attribution/explain by example explainability work. To build upon its significance and relate to the question posed below: The choice of the structure of the surrogate model can be an implicit assumption on the kind of data attribution that NN model performs. We chose to use a kGLM because it does not assume sparsity-- we could have in principle observed that the resulting kGLM was effectively sparse, but do not. In contrast, a choice like a KNN would be assuming that the data attribution is local in the feature space and sparse. We continue this discussion below.\n\n2. Re:  In section 5, You mentioned: \"...an interesting follow-on work would investigate using kernel functions in K-Nearest Neighbors surrogate models.\" How much argument of this paper can transfer to KNN or generally any other surrogate models on explaining NN decision?\n    * An excellent question that we invite the reviewer to discuss with us. We have conducted some preliminary work investigating the roles other surrogate models (kernel-SVM and kernel-KNN) can play in investigating the NN model. So far we understand that the choice of surrogate model can have profound impact on what we might infer. For example, with the kernel-KNN we would specifically be modeling that only the local structure of the feature space matters to the classification; in effect, assuming sparsity a priori. However, it is not yet clear how we should assign a class probability/logit value to utilize the Kendall-$\\tau$ measure. We do include some analysis with kernel-SVMs as well looking into adversarial examples. We infer that kSVMs are not a good surrogate for modeling the effect of adversarial examples since the robustness scales differently between the NN and the kSVM. This may be in part due to the structure of the kSVM itself: in the kSVM, only a sparse number of data points near the decision boundary matter for classification (i.e., the support vectors). Perhaps it is easier for an adversarial example to fool the kSVM given fewer samples the kSVM is utilizing than the NN (under our hypothesis that the NN is not sparse).\n3. Re: also, there are some of the minor typos in the paper\n    * We thank the reviewer for pointing out the mistakes and will fix them in the revision"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1902/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700335636646,
                "cdate": 1700335636646,
                "tmdate": 1700335636646,
                "mdate": 1700335636646,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LuyctMK6pE",
            "forum": "yKksu38BpM",
            "replyto": "yKksu38BpM",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1902/Reviewer_dXvz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1902/Reviewer_dXvz"
            ],
            "content": {
                "summary": {
                    "value": "This paper contributes to the growing literature of approximating NNs with simpler, more interpretable, models. A common approach is to approximate NNs with the empirical Neural Tangent Kernel (eNTK). However, computing the eNTK can be computationally unfeasible so simpler approximations have been proposed in the literature. The authors focus on this problem by studying the empirical properties of one such approximation, the trace NTK, and adapt random projection methods to make it more computationally attractive. Furthermore, the authors propose the Kendall rank correlation as a new measure to assess the faithfulness of the surrogate kernel method to the NN. \n\nThe main contribution of the paper is to show that the trace NTK and projected trace NTK can be used to generate faithful surrogate models of the underlying NNs. The authors show this through a variety of empirical exercises across different benchmark datasets (MNIST, CIFAR) and models (CNNs, ResNet18, BERT). They compare how good different NTK approximations are with respect to the underlying NN in terms of prediction error and rank correlation and find that trace NTK has good performance. Additionally, the authors compare the different models representations through a data attribution exercise and a poisoned data attribution exercise and identify which surrogate models perform better in each case.  Finally, the authors show the practicality of the projected NTK methods by analyzing computational complexity of each method. The most relevant finding is that the trace NTK and projected trace NTK  perform similarly in settings in which the projected trace NTK required an order of magnitude less computation time."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper tackles a common problem in an active area of research: that of finding computationally attractive NTK approximations to NNs. While the main proposed methods in the paper are drawn from the literature, the authors are original in adapting random projection methods to the trace NTK and pseudo NTK and considering the rank correlation as a sensible alternative to prediction error for assessing faithfulness.\n\nThe main strength of the paper lies in the extensive set of empirical evidence comparing various NTK approximations with different NNs architectures across tasks and datasets. Furthermore, the authors provide an extensive appendix with additional exercises and comparisons. Overall, researchers looking to use NTK approximations may find these exercises useful in choosing which method to use depending on their task and their computational constraints."
                },
                "weaknesses": {
                    "value": "While the paper offers a wealth of empirical evidence for the methods it investigates, its central weakness is that it is unclear what the main findings and contributions are. The paper does a lot of things and it would benefit from more succinctly explaining what it is trying to achieve and how each exercise demonstrates it.  \n\n* The paper should be more clear about its relative contribution to the literature (and what its main contribution is). The paper gives confusing statements about what is new and what is taken from the literature. The authors state that the 3 main contributions are (1) new kernel functions for NTK approximation, (2) first to show that eNTK models are consistently correlated with NNs across experiments, (3) first to compare NNs decisions through NTKs through a data attribution and explain by example strategy. \n\n\n* For point (1) however the authors also state that the tr NTK was introduced in Chen et al. 2021 (end of page 2) and that the random projections approach is based on Park et al. 2023 (end of page 1).  Is the main contribution of the paper proposing a new NTK method or evaluating empirical exercises? \n\n* The authors consider different alternative NTKs to compare to the trNTK, but never compare in the main text the methods to the eNTK or the pNTK. Given that the motivation of the paper in the abstract, introduction etc is to approximate the eNTK it is odd that this not done in the main text of the paper. While computational constraints are important, maybe it could be done a simpler dataset (MNIST)? \n\n* For point (2) if using the rank correlation is new it should be clearly stated as a major contribution. The paper repeatedly expresses that other measures are flawed and while the authors give some reasons why, without a proper theoretical statement the authors should at least relate these notions more directly to the findings of the empirical examples. For example, what is a clear case in which using fit or pearson correlation would be misleading in the sense that two NTK models give you very different attributions despite having the same fit to the NN, but rank correlation is not misleading.\n\n* For point (3) the paper should explain more carefully why these are carried out. If the goal is to assess how good a NTK approximation is by considering whether it performs similarly to the NN in a data attribution task then this should be the focus of the results. It seems that the authors do these exercises in the appendix, but in the main write up they just give an instance of this and its unclear how much we can learn from it. If well addressed I would be inclined to raise my score.\n\n* The paper could benefit from better exposition and more clear presentation. For example, the choice of what is defined in the main text vs appendix and when it is defined is sometimes odd. The eNTK, while being referenced to extensively, is never properly defined in the main text. The, trNTK0 is introduced in Additional Kernel Functions after the trNTK without motivation, despite featuring prominently in the appendix when the different methods are compared.\n\n* The paper may also suffers from typos and plots are sometimes misleading (squished axis in Figure 1). Some typos include pseudo vs psuedo, missing points, figure labels that overlap, subscripts in mathematical notation etc. Some references are also repeated."
                },
                "questions": {
                    "value": "Besides the questions raised in the weakness section regarding the key contributions. I also have some additional questions:\n\n* Which Chen et al. paper is the main reference for trace NTK, I was confused by the reference. \n* Is it true that when rank correlation <1 there exists not invertible mapping? \n* In the case in which the rank correlation is 1 is the invertible mapping unique? How does this result translate to the exercises and neural net behavior? Should we expect the same data attributions as the NN? Expanding on the implications of a good rank correlation vs test accuracy seems key to show the usefulness of the paper for researchers.\n* Given the data attribution with kernels theory in page 3, wouldn\u2019t you be able to test directly whether a kGLM is an \u201cideal surrogate\u201d (according to eq 2) by comparing across all data points the NN confidence in each class with the data attribution for each class? Is there a way beyond fit/correlation measures to more systematically compare how well the kernel performs in the data attribution exercise besides evaluating individual examples?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1902/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1902/Reviewer_dXvz",
                        "ICLR.cc/2024/Conference/Submission1902/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1902/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698517307729,
            "cdate": 1698517307729,
            "tmdate": 1700664373667,
            "mdate": 1700664373667,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0x7HzRNlBr",
                "forum": "yKksu38BpM",
                "replyto": "LuyctMK6pE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1902/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1902/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Clarification"
                    },
                    "comment": {
                        "value": "Good afternoon, we are still preparing our response, but today we realized we were not sure of the meaning of the following question. Could the reviewer please clarify? \"Given the data attribution with kernels theory in page 3, wouldn\u2019t you be able to test directly whether a kGLM is an \u201cideal surrogate\u201d (according to eq 2) by comparing across all data points the NN confidence in each class with the data attribution for each class?\""
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1902/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700428431791,
                "cdate": 1700428431791,
                "tmdate": 1700428431791,
                "mdate": 1700428431791,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FxD85fhmlq",
                "forum": "yKksu38BpM",
                "replyto": "0x7HzRNlBr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1902/Reviewer_dXvz"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1902/Reviewer_dXvz"
                ],
                "content": {
                    "comment": {
                        "value": "Hi, I think my question is the same as question 2 of reviewer yHxi. Given your definition of ideal surrogate, why not compare the probabilities of all classes at each data point, instead of just the probability of the true label?"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1902/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700494492387,
                "cdate": 1700494492387,
                "tmdate": 1700494492387,
                "mdate": 1700494492387,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JKcjpJh7lF",
                "forum": "yKksu38BpM",
                "replyto": "LuyctMK6pE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1902/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1902/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "1. We thank the reviewer for their detailed comments. Before we clarify some of the specific issues raised, we want to echo one of the main strengths the reviewer identifies in the paper. Part of our contributions are the implementation of projection variants of approximate eNTK. We show in Table 4 how these projection variants achieve a massive reduction in total computation time with exponentially decaying residuals to the non-projected variant (Appendix E). We are excited to see how researchers will build off this work to conduct eNTK research enabled by our software and TRAK.  \n2. Re: Contributions are unclear. For point (1) however the authors also state that the trNTK was introduced in Chen et al. 2021 (end of page 2)...\n    * The full story is somewhat complex and in editing to meet page limits it became less clear. Chen et al. (2021) never formally defined the trNTK and never mentions it in their main body. They only describe trNTK in a single sentence in the appendix: (Appendix G, first sentence: \"We approximate the neural tangent kernel on the i1k (1/10) subset by averaging over block diagonal entries ... in the full NTK.\"). Therefore, we feel our wording is accurate albeit slightly confusing: we are the first to formally define the trNTK. In Chen's work, the trNTK was a (hidden) computational convenience to enable their experiment for a single data set; in contrast, our work treats the trNTK to be the central object of study as an approximation of the NTK. We believe that this is a novel contribution but at the same time we should give proper credit to Chen et al. We will look to revise the contribution section and introduction to make this point clearer.\n3. Re: ... and that the random projections approach is based on Park et al. 2023 (end of page 1).\n    * We copy from our comment to all on this topic for the reviewer's convenience: we would like to take this opportunity to delineate our contributions from that of Park et al 2023 (TRAK). To begin, we want to acknowledge that TRAK is software at the foundation of our projection kernel functions, so it rightly takes a prominent role in our paper. The TRAK paper references the eNTK and devotes a section to show how it is an explicit part of the TracIn kernel, but its actual calculation is not implemented in their code. You can view the lines of code [here](https://github.com/MadryLab/trak/blob/main/trak/modelout_functions.py#L84)  \n    * Notice that the model output functions implemented are only the loss (as this serves their use case for counterfactual analysis), rather than the neural network function itself. TRAK does not compute the eNTK or any approximation of the eNTK (p-, tr-, etc.). We have been in direct communication with the maintainer of TRAK to bring the capabilities we describe in this work to the TRAK software package.\n4. Is the main contribution of the paper proposing a new NTK method or evaluating empirical exercises?\n    * We view the paper as having three major contributions: a) We describe methods, building off recent successes from TRAK, that use projection matrices to compute efficient approximations to the eNTK. b) We establish the faithfulness metric Kendall-$\\tau$ and detail how it is superior to previous methods relying on test accuracy. c) We identify the trNTK kernel function as the best performing surrogate model to the NN across a variety of experiments. Analyzing this choice of kernel in a data attribution context, we find that many training data points influence the output on any new data input.\n5. Re: The authors consider different alternative NTKs to compare to the trNTK, but never compare in the main text the methods to the eNTK or the pNTK...\n    *  Our goal was to develop surrogate model methods that scale to large computer vision experiments and transformer models with potentially large number of classes. This implies we will need to find an approximation to the eNTK as the eNTK scales quadratically with the number of classes. A direct comparison to the eNTK is an important topic, but we did not consider it part of this paper's scope.\n    * We understand the reviewer's concern that we did not compare with the pNTK. Our rational is that we \"brute-forced\" the computation of several trNTK and compared them with the proj-trNTK. After observing that the proj-trNTK had exponentially decaying residuals (Appendix E) with the trNTK, we felt secure in evaluating the proj-pNTK alone.\n\n(continued below)"
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1902/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700591826185,
                "cdate": 1700591826185,
                "tmdate": 1700591826185,
                "mdate": 1700591826185,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GxMqixyatu",
                "forum": "yKksu38BpM",
                "replyto": "RwLN3fBq1X",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1902/Reviewer_dXvz"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1902/Reviewer_dXvz"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their careful answers to my questions. In light of this I am raising my score."
                    }
                },
                "number": 27,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1902/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700664335737,
                "cdate": 1700664335737,
                "tmdate": 1700664335737,
                "mdate": 1700664335737,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "tey6gwytxC",
            "forum": "yKksu38BpM",
            "replyto": "yKksu38BpM",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1902/Reviewer_e28a"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1902/Reviewer_e28a"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes to use the approximate empirical neural tangent kernel (eNTK) as a faithful surrogate model for neural networks. Focusing on NNs for classification, the authors define the trace neural tangent kernel (trNTK), which is the cosine similarity between the concatenated gradients of all logits with respect to the parameters for a trained NN. The trNTK is then plugged into a kernel general linear model (kGLM) to obtain a surrogate model for the NN, which can be used to attribute the prediction of the NN to the training data points. To evaluate the faithfulness of such surrogate models, the authors argue that a preferred way is to measure the rank correlation between the softmax probabilities of the surrogate model and the NN for the correct class. A random projection variant of the trNTK is also proposed to reduce the computational cost. The experiments show that the proposed surrogate model is generally more faithful than other kernel-based surrogate models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is clearly written and easy to follow.\n- The proposed surrogate model is simple and easy to implement. trNTK performs consistently better than other neural kernels.\n- The rank correlation seems to be a better metric than existing alternatives for evaluating the faithfulness of surrogate models for classification NNs. It takes into account the global structure of the predictions.\n- Based on the proposed surrogate model and data attribution method, the authors observe that the attribution is NOT dominated by a few data points. This is an interesting observation and has practical implications."
                },
                "weaknesses": {
                    "value": "- Only the rank correlation of the softmax probabilities for the **correct** class is considered. However, to be faithful enough, the surrogate model should also behave similarly to the NN for the **incorrect** classes. An important application of data attribution is to explain why a NN makes a wrong prediction. This is not considered in the paper.\n- Eq. (4) is confusing. In the denominator, the $\\cdot ^ {\\frac{1}{2}}$ is applied to the inner product. However, according to Appendix C and the definition of cosine similarity, the $\\cdot ^ {\\frac{1}{2}}$ should be applied to the sum, not the inner product.\n- The quality of Figure 2 could be improved."
                },
                "questions": {
                    "value": "- Is the non-sparsity of the attribution a general phenomenon or just a property of trNTK? Is it a consequence of the statement \"It has been suggested that this normalization helps smooth out kernel mass over the entire training dataset\"?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1902/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1902/Reviewer_e28a",
                        "ICLR.cc/2024/Conference/Submission1902/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1902/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698600416189,
            "cdate": 1698600416189,
            "tmdate": 1700663362726,
            "mdate": 1700663362726,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "WJedabOHJV",
                "forum": "yKksu38BpM",
                "replyto": "tey6gwytxC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1902/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1902/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "1. We thank the reviewer for their insightful comments: we also believe that one of the main strengths of our paper is our use of the Kendall-$\\tau$ metric because it allows us to go beyond test accuracy measures of similarity. This allows us to identify the trNTK as the most faithful kernel function. This in turn allows us to show that data attribution is actually not sparse. That conclusion could help move the field, as previous works have assumed sparsity in various data attribution/explain-by-example techniques.\n2. Re: Only the rank correlation of the softmax probabilities for the correct class is considered...\n    * We agree with the reviewer that a current limitation of Kendall-$\\tau$ is that it does not consider the logit value of incorrect classes. We think that an ideal faithfulness measure would include this information,  we will add a discussion of Kendall-$\\tau$ the limitation of Kendall-$\\tau$ to our limitation section; however, we feel despite our use of Kendall-$\\tau$ is a significant step away from previous works that rely on test accuracy to measure the similarity of surrogate functions to the neural network. \n3. Re: ... However, to be faithful enough, the surrogate model should also behave similarly to the NN for the incorrect classes.\n    * We agree with the reviewer's intuition. While this set of experiments have not appeared in the paper, we conducted an investigation into a \"misclassification coincidence rate\" as an additional line of evidence suggesting that the kGLM can mimic the behavior of the NN on misclassifications. The misclassification coincidence rate, $R_{\\textrm{miss}}$, is the ratio of the number of times the kGLM and NN predict the same class out of all times either are incorrect over the number of times either the NN or the kGLM are incorrect\n    \\begin{equation}\n    R_{\\textrm{miss}} = \\frac{ |\\{ i : \\textrm{kGLM}(\\mathbf{x}_i) = \\textrm{NN}(\\mathbf{x}_i) \\ne y_i \\}| }{ | \\{i : \\textrm{kGLM}(\\mathbf{x}_i) \\ne y_i\\} \\cup  \\{i : \\textrm{NN}(\\mathbf{x}_i) \\ne y_i\\}| }\n    \\end{equation}\n    * This rate is actually very high (about 75\\% coincidence of misclassifications on ResNet18 for trNTK), which is powerful evidence suggesting that the kGLM can mimic the NN overall for both correct classification and misclassifications. We will include this analysis in the revision.\n4. Re: An important application of data attribution is to explain why a NN makes a wrong prediction. This is not considered in the paper.\n    * While our main body is primarily concerned on establishing our framework for data attribution and then an initial analysis re. the assumption of sparsity of the attribution scores, our framework can be extended to study misclassification. Our current status is to try and understand holistically from all the visualization generated why the NN made a misclassification by investigating the kGLM as proxy. Take as example figures 20, 31, and 42: In figure 20, we see that the mean plane and horse attribution score are highest driving the classification in their respective logits, but with the mean attribution from the remaining classes having higher negative impact on the plane logit. Figure 31 zooms into the horse logit for the trNTK, showing that the logit horse value is dependent upon the horse class. Even though our analysis shows that a sparse number of representations do not best describe the NN predictions, we can still leverage the most similar data points to help us form hypothesis of NN behavior. In figure 42, we show the most similar images are of people riding horses. This was quite the realization, since we had not noticed that the initial test image is actually of a person siting on top of an airplane! While we still must find a way to test this hypothesis, we believe that helping researchers form these hypothesis is a valuable tool in understanding misclassification. \n5. Re: Eq. (4) is confusing. In the denominator, the sqrt is applied to the inner product. However, according to Appendix C and the definition of cosine similarity, the sqrt should be applied to the sum, not the inner product.\n    * We thank the reviewer for pointing out mistake; we will add parenthesis to Eq (4) and to ensure the equation matches the definition of cosine similarity. \n6. Re: The quality of Figure 2 could be improved.\n    * We agree; there are rendering errors that we will fix in the revision and double check that boxes do not move in front of the axis labels.\n\n(continued below)"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1902/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700591086735,
                "cdate": 1700591086735,
                "tmdate": 1700591086735,
                "mdate": 1700591086735,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "h4YtxVIFhA",
                "forum": "yKksu38BpM",
                "replyto": "3seqNUn2yf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1902/Reviewer_e28a"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1902/Reviewer_e28a"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your detailed response. I have updated my rating accordingly."
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1902/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700663640895,
                "cdate": 1700663640895,
                "tmdate": 1700663640895,
                "mdate": 1700663640895,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vL5v90bcV2",
            "forum": "yKksu38BpM",
            "replyto": "yKksu38BpM",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1902/Reviewer_zBfF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1902/Reviewer_zBfF"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes new variants of eNTK and implements faster approximate versions as well, and then evaluates them on a few different tasks / visualizations."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Paper evaluates variants of eNTK in further depth compared to prior work\n- Paper is relatively well written, though missing some important details"
                },
                "weaknesses": {
                    "value": "- Content: Surfacing similar images is a not a meaningful evaluation of attribution. It is a good sanity check, but doesn't say anything about surrogacy. For example, finding similar images using CLIP similarity would also show similar images, though CLIP is in no way a \"surrogate\" to the model being studied\n\n- More broadly, I'd be more careful about making any claims of \"data attribution\" (which has a specific meaning as used in recent ML) as the paper does carry out any counterfactual evaluations.\n\n- Overall, the contributions seems somewhat marginal. Also, the fast approximate versions implemented primarily rely on prior work (Park et al.)'s implementation, so not sure there is much to claim as contribution there (since Park et al. also used it for faster approximations to eNTK).\n\n- Writing: is hard to follow at times and doesn't provide the relevant details (see Questions).\nOn one hand, the paper goes into more detail than necessary in defining rank correlation / R2, etc from scratch,\nand at the same time, doesn't actually provide details about what those measures are computed over exactly.\nIt's possible I missed it, but at least doesn't seem very clearly written based on my multiple attempts to parse this information."
                },
                "questions": {
                    "value": "- Confused by what the rank correlation is measured over exactly. I understand it's measured between the truth model outputs and surrogate model outputs, but what is it varied over? Are you measuring across different inputs x?\n- A bit confused by what the message/takeaway of the box/distribution plots are. Can the authors elaborate?\n- It seems that the eNTK is only defined in Appendix D, so it's a bit hard to contextualize pNTK and trNTK when they are introduced"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1902/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698952909141,
            "cdate": 1698952909141,
            "tmdate": 1699636120506,
            "mdate": 1699636120506,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "INj630EIyz",
                "forum": "yKksu38BpM",
                "replyto": "vL5v90bcV2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1902/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1902/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "1. We thank the reviewer for their thoughtful review. Part of the importance of our work is to explore the space of scalable approximations to the eNTK that retain intrinsic properties of the eNTK. Our hope is that our research will enable eNTK research on larger datasets and models. As an example of the analysis this software enables, we perform investigations into data attribution problems using kernel surrogate models on large computer vision and language models. We think the software will enable many new analyses and are excited to see how other researchers build off our work. \n2. Re: Surfacing similar images is a not a meaningful evaluation of attribution.\n    * We wholeheartedly agree with the limitations of surfacing similar images as the reviewer states --- in fact, this is a major conclusion we draw in the paper. See the end of section 5 paragraph 1: \"Therefore, presenting the top highest attribution training images without the context of the entire distribution of attribution is probably misleading.\" Our kernel machine surrogate framework goes beyond simply surfacing similar images to show how the surrogate model, which is deeply correlated with the underlying neural network, leverages **all of the training data** to make classification on new test data.\n3. Re: I'd be more careful about making any claims of data attribution ... as the paper does carry out any counterfactual evaluations.\n    * We acknowledge the historical context of data attribution in classical statistics, and recent research in data attribution that have utilized counterfactual experiments; however, it is not the only sense in which \"data attribution\" is used. We subscribe to the framework given in Park et al 2023 (TRAK): \"a data attribution method computes a score for each training input indicating its importance to the output of interest.\" Specifically, they cite the approach of Yeh et al 2018 (i.e. Representer Points) as a form of data attribution, and we mirror the same sense of data attribution in our work. We describe how we compute our data attribution score in great detail in the comment to all reviewers.\n4. Re: Overall, the contributions seems somewhat marginal. Also, the fast approximate versions implemented primarily rely on prior work (Park et al.)'s implementation, so not sure there is much to claim as contribution there (since Park et al. also used it for faster approximations to eNTK).\n    * We politely but strongly disagree: Park et al. (TRAK) neither compute the eNTK nor any approximation of the eNTK. While Park et al. do reference the eNTK and devote a section to show how it is a part the TracIn kernel, the actual calculation of the eNTK itself is not implemented in their code. You can view the relevant lines of code from TRAK [here](https://github.com/MadryLab/trak/blob/main/trak/modelout\\_functions.py\\#L84]).  Notice that the model output functions implemented are only the loss, rather than the neural network function itself. We have been in direct communication with the maintainer of TRAK to bring the capabilities we describe in this work to the TRAK software package.\n    * It is true that our fast approximation would not be possible without TRAK (and so  TRAK rightfully takes a prominent position in our paper); however, building off each other's work is a success story of the open-source community and is at the foundation of AI research. We see this as a major strength rather than a weakness.\n5. Re. Writing ... the paper goes into more detail than necessary in defining rank correlation / R2, etc from scratch...\n    * We thank the reviewer for pointing out the confusion. We agree that the space devoted to the Kendall-$\\tau$ definition could be saved by moving it to the appendix. We would instead use this space to discuss the motivation for the Kendall-$\\tau$, which we believe is more important than discussing why Pearson is flawed. If it interests the reviewer, we provide additional information in the comment to all reviewers about our argument for why we use Kendall-$\\tau$.\n6. Re: Confused by what the rank correlation is measured over exactly. I understand it's measured between the truth model outputs and surrogate model outputs, but what is it varied over? Are you measuring across different inputs x?\n    * Yes: we are varying it over the different model inputs x from the test dataset. For cases beyond binary classification (single logit), we also must make a choice for which output of the neural network/ surrogate model to use. We chose to use the output corresponding to the correct class (as given by the ground-truth labels).\n\n(continued in next comment)"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1902/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700335299721,
                "cdate": 1700335299721,
                "tmdate": 1700335299721,
                "mdate": 1700335299721,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Fvy0f7tIYb",
            "forum": "yKksu38BpM",
            "replyto": "yKksu38BpM",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1902/Reviewer_yHxi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1902/Reviewer_yHxi"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates kernel-based surrogate models based on various approximations of the Neural Tangent Kernel (NTK) to provide explanations for deep neural networks. A primary contribution is showing that computationally-feasible approximations to the empirical NTK provide high-fidelity surrogate models, and that much cheaper projection-based approximations provide accurate estimates of the empirical NTK. Appealing to existing literature on explanation-by-example, the paper develops a simple score for data attribution. A synthetic data experiment shows that the proposed attribution score accurately attributes erroneous model predictions to poisoned data, giving some confidence that the proposed score is capturing some notion of similarity between data points."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The paper provides a potential solution to a very important problem, i.e. data attribution based on a trained neural network checkpoint.\n* The authors draw a very important distinction\u2014which is somewhat obvious but not well-reflected in the literature\u2014between difference in test accuracy (TAD) and correlation of model outputs. The addition of Kentall-$\\tau$ is important, and will hopefully shift the way future works evaluate the fidelity of surrogate models.\n* The paper provides a clear definition of proposed kernel approximations, with strong computational justification for the speedup e.g. of the trace approximation. Equation 2 clearly defines the working definition of a \u201chigh-fidelity model\u201d and adds to the clarity of exposition.\n* The experiments include a sufficient diversity of alternative kernel estimates to demonstrate the value of the proposed projected-trace-NTK approach. The inclusion of uncertainty based on multiple runs is highly appreciated.\n* The inclusion of experiments on Bert-base significantly strengthens the paper, indicating that the method is not specific to the computer vision domain.\n* The discussion that explanations are not sparse is an important acknowledgement of the proposed data attribution method. In particular, the following statement is poignant: \u201cpresenting the top highest attribution training images without the context of the entire distribution of attribution is probably misleading.\u201d\n* The paper\u2019s title is very strong and well reflects the work\u2019s primary contributions."
                },
                "weaknesses": {
                    "value": "* The paper relies on previous work to establish credibility of attribution-based scores for neural network explanation. It doesn\u2019t seem obvious that attribution is the same as similarity for learned kernel functions.\n* I find the second sentence in the abstract confusing. I expected this trend to have to do with using kernel-based models for data attribution rather than to \u201cinvestigate a diverse set of neural network behavior\u201d. Isn\u2019t the goal of your paper exactly to apply kernel models to investigate network behavior?\n* The 3rd experiment on qualitative evaluation of attribution is weak. A user study is probably beyond the scope of this paper, and I believe the work is strong enough to stand without such a study. However, the paper would significantly benefit from some discussions about how these attributions could be better qualitatively evaluated in the future.\n* The claim about Peason correlation is not very well explained: \u201cThese point clouds serve as anchors that force the covariance, and therefore Pearson correlation, to be large. We require a measure that does not conflate the covariance with faithfulness.\u201d Is the problem here that correlation is not computed between model logits for each test point?\n* The paper never explicitly defines the empirical NTK in its own notation. Could you add this prior to defining the trNTK or pNTK in order to allow an easier discussion of the approximations introduced?\n* The take-away from Figure 2 is not exactly clear. Is this just meant to show that attribution scores are not sparse?\n* Your Chen ICML\u201922 reference is duplicated. Did you intend to cite two different papers?\n* The notation is non standard. Most papers use $y$ not $z$ for ground-truth labels. I can see this causing some readers mild confusion.\n\nSmall issues:\n* In the last paragraph of the \u201cRelationship to the Pseudo Neural Tangent Kernel\u201d section, the reference to Eq 3 is to the wrong equation.\n* The inclusion of all four panes in Figure 1 seem a bit superfluous, I\u2019m not sure what this is supposed to show that cannot be shown in a single figure.\n* Given that one of the 3 experiments claimed in the paper is a qualitative evaluation, I think it is important to include one of the data attribution figures from the supplemental material in the main text.\n* The main text cites Figure 4.a, which is in Supplemental Material.\n\nSmall typos:\n* 2nd paragraph of the Introduction: \u201cIts well established\u201d should be \u201cit\u2019s\u201d (or better yet spell out \u201cit is\u201d to be less colloquial.\n* Undefined reference (?) at the bottom of page 2."
                },
                "questions": {
                    "value": "1. Have you considered using the kernel function directly to evaluate sample similarity? Why do you choose to include the weights from the kernel machine in all attribution scores?\n2. You fit the parameters $W, b$ on the ground-truth labels $z$ from the  training dataset. If the goal is to create a surrogate that emulates a neural network, why don\u2019t you fit these parameters on cross-entropy loss with the class probabilities predicted by the NN? This would be consistent with your objective in Eq. 2.\n3. It is not totally clear how the Kendall-$\\tau$ statistic is computed. A couple of sentences would make this portion more reproducible. Do you take the matrix of all the logits produced on a test set ($N x C$) for the NN and for the surrogate model, flatten these two matrices into vectors, and compute the rank correlation? Is the rank correlation computed per-test-output and averaged over the test set?\n4. Why is trNTK initially introduced with cosine normalization and projNTK not? Don\u2019t your experiments include cosine normalization for all kernels?\n5. Is there any theoretical statement you can add about the variance of the projection-based kernel estimates, e.g. based on JLS? The choice of 10240 dimensions seems arbitrary and model-dependent.\n6. Does the introduction of cosine normalization explain the experimental result \u201cthat the highest attributed images from the trNTK (and furthermore all evaluate kernel functions) have relatively small mass compared to the bulk contribution, suggesting that the properties of the bulk\u201d?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1902/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1902/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1902/Reviewer_yHxi"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1902/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699111973356,
            "cdate": 1699111973356,
            "tmdate": 1699636120441,
            "mdate": 1699636120441,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "szOw4bRR0t",
                "forum": "yKksu38BpM",
                "replyto": "Fvy0f7tIYb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1902/Reviewer_yHxi"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1902/Reviewer_yHxi"
                ],
                "content": {
                    "title": {
                        "value": "Question 2 is important"
                    },
                    "comment": {
                        "value": "I would like to know the answer to my Question 2. It seems like a surrogate model should be fit with the outputs of the model it is emulating, not with ground-truth labels. I doubt this change would alter the results in the paper. But I think the authors should consider making this chance, if feasible, for the final paper draft."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1902/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700451764139,
                "cdate": 1700451764139,
                "tmdate": 1700451764139,
                "mdate": 1700451764139,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LgBkdnrifz",
                "forum": "yKksu38BpM",
                "replyto": "Fvy0f7tIYb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1902/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1902/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Good Morning,\n\nWe aim to post a thread of answers to each of your points today. To answer this specific question now: it is a very reasonable suggestion. The reason we did not attempt this is we were worried about overfitting the kGLM onto the NN's outputs, so we investigated using the ground truth labels first. After finding that the fits were very reasonable, we moved ahead. We were surprised that even without using the NN's outputs there would be such high alignment between the NN and the kGLM.\n\nWe now think that even if the model were to overfit onto the NN's outputs, this would become apparent when evaluating Kendall-$\\tau$ on the test data, so overfitting would be observable and therefore not represent a great risk. In addition, we recently became aware of some contemporaneous work that was accepted at Neurips23 [Tsai et al 2023] that utilize the NN's outputs to derive ideal weights.\n\nDue to all of this, we resolve to include this experiment in our final paper and compare to the existing results. We think it would add an interesting comparison to Tsai et al.'s methodology.\n\nTsai, C.-P., et al., \u201cSample based Explanations via Generalized Representors\u201d 2023"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1902/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700495740630,
                "cdate": 1700495740630,
                "tmdate": 1700501167473,
                "mdate": 1700501167473,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "otdZp4jG2C",
                "forum": "yKksu38BpM",
                "replyto": "Fvy0f7tIYb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1902/Reviewer_yHxi"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1902/Reviewer_yHxi"
                ],
                "content": {
                    "comment": {
                        "value": "I don't understand the concern with \"overfitting\". Wouldn't you expect a reasonable surrogate to at least match the NN exactly on training points?\n\nI appreciate the authors' willingness to add experiments training the surrogate to directly emulate the NN. I look forward to reading the full rebuttal."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1902/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700500279021,
                "cdate": 1700500279021,
                "tmdate": 1700500353035,
                "mdate": 1700500353035,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lT6hLHF98p",
                "forum": "yKksu38BpM",
                "replyto": "Fvy0f7tIYb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1902/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1902/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "1. We thank the reviewer for their time and appreciate the breadth of topics covered. They have identified what we consider to be the major strength of this paper: bringing in new ideas to modeling surrogacy and data attribution: i.e., challenging both the use of test accuracy to measure the similarity of models as well as the a priori assumption that neural network classifications can be explained using a sparse number of training data exemplars.\n2. Re The paper relies on previous work to establish credibility of attribution-based scores for neural network explanation.\n    * We have expanded upon our argument to establish the credibility of our attribution scores in the comment to all (point 2). We resolve to present this in the revision so our work is more self-contained.\n3. Re It doesn\u2019t seem obvious that attribution is the same as similarity for learned kernel functions.\n    * In Eq (3) we describe how attribution is the product of the kernel similarity with the learned weights, so is \\textbf{not} just the similarity. We expand upon this in the comment to all reviewers as well (point 3), since it was a shared confusion. We will be more explicit in our revision. \n4. Re I find the second sentence in the abstract confusing. I expected this trend to have to do with using kernel-based models for data attribution rather than to \u201cinvestigate a diverse set of neural network behavior\u201d. Isn\u2019t the goal of your paper exactly to apply kernel models to investigate network behavior?\n     * Our explicit goal is to use kernel methods as a surrogate for neural networks, and the application we focus on in this paper is data attribution. We agree that our attempt to remain general in the second sentence of the abstract reads overly pedantic for the sake of the narrative device used in the third sentence. We will address this sentence in the revision.\n5. Re The 3rd experiment on qualitative evaluation of attribution is weak. A user study is probably beyond the scope of this paper, and I believe the work is strong enough to stand without such a study. However, the paper would significantly benefit from some discussions about how these attributions could be better qualitatively evaluated in the future.\n    * We share a preference for stronger quantitative evaluation as well; however, we believe the qualitative evidence we have collected is still important to share because researchers often generate new hypotheses from looking at the data in a new qualitative way.\n    * We seek to publish this result without human-subjects testing. We will add a short discussion of the limitations of explainability and caution the reader that a user-study must be performed in the revision.\n\n(continued below)"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1902/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700590035688,
                "cdate": 1700590035688,
                "tmdate": 1700590035688,
                "mdate": 1700590035688,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]