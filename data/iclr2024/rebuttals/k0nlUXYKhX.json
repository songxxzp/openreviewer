[
    {
        "title": "A Fault Forecasting Approach Using Two-Dimensional Optimization (TDO)"
    },
    {
        "review": {
            "id": "XAi2YfEAVY",
            "forum": "k0nlUXYKhX",
            "replyto": "k0nlUXYKhX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3395/Reviewer_SqTT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3395/Reviewer_SqTT"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors address data preparation for fault detection within the automotive industry. Confronted with the challenge of high-dimensional feature spaces and imbalanced data, they introduce a two-dimensional optimization technique. Utilizing the Genetic Algorithm, they aim to concurrently reduce both data point tuples and the feature space. Additionally, the paper explores Particle Swarm Optimization (PSO) and Whale Optimization Algorithms (WOA).\n\nEvaluating the GA, PSO, and WOA algorithms, they simplify tuple and feature space. The experimental results showed the method's capabilities in enhancing the classification performance."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "Originality:\nThe paper introduces a two-dimensional optimization method for the application of fault detection in the automotive sector, by integrating the Genetic Algorithm with PSO and WOA. This approach offers the handling of high-dimensional data and imbalances.\n\nQuality:\nThe paper is well-structured and methodologically sound clear, it presents the optimization techniques applied in the context of automotive fault detection. \n\nClarity:\npaper is generally well written.\n\nSignificance:\nThe study achieves promising results. Observations regarding GA's speed compared to WOA have practical implications."
                },
                "weaknesses": {
                    "value": "* **Lack of Comparative Analysis:**\nWhile the paper does explore GA, PSO, and WOA for the automotive fault detection problem, it lacks a comparison with other existing methods or state-of-the-art techniques. Providing such a comparative study would have offered more context to the results. Also, adding references to the previous works/results in the domain would add to the paper results validation.\n\n* **Dataset Concerns:**\nThe paper could have benefited from a more comprehensive analysis using multiple datasets or a more diversified dataset. Relying on a single dataset might limit the generalizability of the method and findings. Moreover, the paper lacks in describing the stats of the dataset in findings, it didn't provide comprehensive results that include the percentage/number of useful/selected features/tuples. \n\n\n* **Parameterization Details:**\nThe authors mention parameterizing the three optimization algorithms as per values shown in \"Table 1\", yet they didn't explain how these optimal values were derived. Understanding the selection process for these parameters is essential for reproducibility and validation of the results.\n\nTo enhance the paper's standing, the authors could provide a broader comparative analysis by diversifying the datasets used, investigating the parameter selection, investigating PSO's behavior in more depth, and possibly expanding on the optimization objectives."
                },
                "questions": {
                    "value": "1- Could you elaborate on the reason that the paper lacks a comparison with existing methods or state-of-the-art techniques related to fault detection in the automotive industry?\n\n2- Could you elaborate on the reason that only a singular dataset was chosen for this study, especially given its number of features?\n\n3- In the results section, there seems to be limited detailed statistics about the dataset. Could you provide more statistics, especially the percentage/number of useful features/tuples?\n\n4- How were the optimal parameter values of the three optimization algorithms determined?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3395/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698624289858,
            "cdate": 1698624289858,
            "tmdate": 1699636290670,
            "mdate": 1699636290670,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Sw8kCvJRvy",
                "forum": "k0nlUXYKhX",
                "replyto": "XAi2YfEAVY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3395/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3395/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the comments"
                    },
                    "comment": {
                        "value": "Many thanks for the valuable comments. The four bullet points you mentioned are quite right and pretty crucial for our study. Thus, to answer your questions, we are running our approach on other datasets together with other ML algorithms to assess our approach in different contexts. We are updating the paper with a section to show the comparison results. We are also describing how we reached the optimal parameters illustrated in the tables.  Regarding the statistics about the dataset, we are pretty limited in providing such detailed information since the data is quite sensitive for the company we are collaborating with. However, we try to add more information that can answer your concerns and follow the company regulations."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3395/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700407407716,
                "cdate": 1700407407716,
                "tmdate": 1700407407716,
                "mdate": 1700407407716,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zr0GxjHMad",
            "forum": "k0nlUXYKhX",
            "replyto": "k0nlUXYKhX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3395/Reviewer_5nRP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3395/Reviewer_5nRP"
            ],
            "content": {
                "summary": {
                    "value": "This paper present a fault prediction method in automotives that uses optimizations on the recorded data of a vehicle and associate features. The selectionof the most appropriate data and features results in better predictions. For the data selection these optimization algorithms are used: Genetic Algorithm (GA) Whitley (1994), Particle Swarm Optimization (PSO) Marini & Walczak (2015), and Whale Optimization Algorithm (WOA) Mirjalili & Lewis (2016). The main ideas to to findout the relevant data that provides the better performance. Therefore, the above optimization algorithms are compared for that purpose."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "a. The details of the use of GA for selection of data for fault prediction\nb. Experiments comparing GA, PSO and WOA algorithms."
                },
                "weaknesses": {
                    "value": "a. The details about optimization algorithms are not necessary, rather good references should be enough. \nb. No details are provide on how the PSA and WOA are used in the proposed methods\nc. No comparisons ar shown with state of the art (SOA)methods.\nd. Nor the Data used is described neither the data source."
                },
                "questions": {
                    "value": "a. Why only the details of GA applications are give but not the PSA and WOA?\nb. Why the propsoed methods is not comapred with SOA methods?\nc. What is the source of the data used?\nd. What is an example of the data?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3395/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3395/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3395/Reviewer_5nRP"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3395/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698911374829,
            "cdate": 1698911374829,
            "tmdate": 1700549430296,
            "mdate": 1700549430296,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1ZivZqPb5M",
                "forum": "k0nlUXYKhX",
                "replyto": "zr0GxjHMad",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3395/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3395/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the comment"
                    },
                    "comment": {
                        "value": "Thank you for the comment. We are updating the paper with more explanation to answer the question."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3395/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700407545553,
                "cdate": 1700407545553,
                "tmdate": 1700407545553,
                "mdate": 1700407545553,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CcAepx7rJl",
                "forum": "k0nlUXYKhX",
                "replyto": "zr0GxjHMad",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3395/Reviewer_5nRP"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3395/Reviewer_5nRP"
                ],
                "content": {
                    "title": {
                        "value": "MISTAKE CORRECTION"
                    },
                    "comment": {
                        "value": "I accidentally entered the wrong (another paper) review. Now I have corrected it. I sincerely apologize for this mistake."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3395/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700549768631,
                "cdate": 1700549768631,
                "tmdate": 1700549768631,
                "mdate": 1700549768631,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "pKv1yuDmOl",
            "forum": "k0nlUXYKhX",
            "replyto": "k0nlUXYKhX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3395/Reviewer_wBRJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3395/Reviewer_wBRJ"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents the relevant issue of training data imbalance and poses it as an optimization problem. A comprehensive set of heuristic techniques have been employed and results on XGboost are presented. The paper examines the GA, PSO,and WOA algorithms with the aim of simultaneously reducing both the tuple andf eature space to facilitate the construction of predictive models."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The comparison with several metaheusristics on a particular data set."
                },
                "weaknesses": {
                    "value": "The importance of the fat-shattering dimension in explaining the beneficial effect of a large margin on generalization performance is discussed in existing literature (John Shawe-Taylor, Algorithmica, 22,157-172,1998; J John Shawe-Taylor, Peter Bartlett, Robert Williamson and Martin Anthony, IEEE Trans. Inf. Theory, 44 (5) 1926-1940, 1998. ). In the past, adaboost and thetaboost have been proposed to tackle this problem with theoretical results on maximum margin likelihood estimation under class imbalance. The problem statement is therefore not novel. Weighted loss functions are also proposed to solve this kind of optimization problems. The experimentation is not diverse. A carefully chosen data set is used. Since there is no theoretical guarantee of the method, it is difficult to ascertain the efficacy unless the experimentation net is widened to include some anomaly detection data sets."
                },
                "questions": {
                    "value": "My question is how different is this approach except for superior performance on some some chosen data sets. Will this approach work if there is heavy imbalance (<1% in one class, rest in other classes) or SVM ensemble training?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3395/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698944662998,
            "cdate": 1698944662998,
            "tmdate": 1699636290488,
            "mdate": 1699636290488,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "F2pjweaY8L",
                "forum": "k0nlUXYKhX",
                "replyto": "pKv1yuDmOl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3395/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3395/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the comments"
                    },
                    "comment": {
                        "value": "Thank you for the comments.  I think the question was quite important to show the generality of the approach. Thus, to answer your concerns, we are implementing our approach (and other machine learning algorithms) on different datasets to see how the approach performs for different problems. We will update the paper with these results."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3395/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700407790204,
                "cdate": 1700407790204,
                "tmdate": 1700407790204,
                "mdate": 1700407790204,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "TeSnZjAj0E",
            "forum": "k0nlUXYKhX",
            "replyto": "k0nlUXYKhX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3395/Reviewer_gDy3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3395/Reviewer_gDy3"
            ],
            "content": {
                "summary": {
                    "value": "Interesting paper that focuses on developing specialised techniques for tackling the challenge of high-dimensionality in real-world industrial data on the face of class-imbalance. The authors use popular algorithms like GA, PSO etc. and integrate it with common ML models to evaluate it on a sensors and repairs dataset from China. The paper has limited novelty and the proposed methodology does not consider the explainability and trustworthiness aspects to a sufficient level for a safety-critical industrial application."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The topic is interesting, the use of real-world dataset for experiments is promising. This reviewer appreciates the utilisation of simpler ML models like XGBoost for experimental purposes."
                },
                "weaknesses": {
                    "value": "Lack of baseline models is one of the major weaknesses of the paper. The authors only consider XGBoost for classification purposes and do not compare it with any other ML model. The dataset under consideration (about 10k samples) is quite small and the authors do not clearly mention the rationale behind specifically using XGBoost and not any other model for classification task. Another major issue this reviewer spotted is the lack of focus on explainability in the paper - GA+XGBoost or PSO+XGBoost is mentioned in the paper and a graph shown with the AUC, however, it is clearly not enough to be convinced of how the GA+XGBoost framework is actually working and learning in the background on the face of high dimensional data with high class imbalance."
                },
                "questions": {
                    "value": "It would have been nice to see the authors to have performed additional experiments with more traditional and popular algorithms like SMOTE (which the paper does mention of in the introduction section), however, lack of comparison with any kind of baseline dimensionality reduction or class-balancing/synthetic data augmentation algorithm or ML model (other than XGBoost) makes the paper lack novelty and has limited contribution."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3395/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698956690188,
            "cdate": 1698956690188,
            "tmdate": 1699636290411,
            "mdate": 1699636290411,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XmUuR3cVSx",
                "forum": "k0nlUXYKhX",
                "replyto": "TeSnZjAj0E",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3395/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3395/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the valuable comments.\nWe carefully review your comments and try to answer them. \nThus, we have started to train different models to have more baselines to compare with our proposed approach.   We also agree that there is a lack of explanation to justify the machine learning approach we used, so we try to clarify and rationalize using our approach and the results we obtained. We are also implementing our proposed approach on other datasets to assess the generality of the approach. This will definitely strengthen the study by showing how general the proposed ML approach is. We will update the manuscript with the above points. \nWe hope the new version will answer your concerns about the points."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3395/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700225482719,
                "cdate": 1700225482719,
                "tmdate": 1700225655877,
                "mdate": 1700225655877,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hbMKuDFR2b",
                "forum": "k0nlUXYKhX",
                "replyto": "TeSnZjAj0E",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3395/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3395/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the comments"
                    },
                    "comment": {
                        "value": "Thank you for the valuable comments you provided for our studies. We carefully reviewed the comments and attempt to answer most of them. From the comments, we found two major points that we needed to answer as follows:\n1) The lack comparison with other ML algorithm:\nTo answer this question, we run other ML algorithms and reported their results in Table 2. \n\n2) The lack of implementing our approach on other datasets:\nTo answer this question we also implement our approach and other ML algorithms on two more datasets to assess generality of the proposed approach. \n\nRegarding the data. As we mentioned, the data is from a company which a confidential and must anonymize the sensitive statistics so that why we couldn't report those numbers. \n\nWe have edited and added more explanation how we reach the best parameters in our study. All the changes and information added in the paper have been highlighted in blue so you can see them.\n\nWe hope the new implementations and clarifications could answer your concerns to accept the paper for the publication. \n\nRegards\nAuthors"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3395/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700574430615,
                "cdate": 1700574430615,
                "tmdate": 1700574430615,
                "mdate": 1700574430615,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]