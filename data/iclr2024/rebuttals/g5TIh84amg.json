[
    {
        "title": "A Curriculum View of Robust Loss Functions"
    },
    {
        "review": {
            "id": "QvEy8yo8VW",
            "forum": "g5TIh84amg",
            "replyto": "g5TIh84amg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3009/Reviewer_gQaq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3009/Reviewer_gQaq"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new perspective for robust losses when learning with noisy labels. The authors show that most robust loss functions differ only in the sample-weighting curriculums they implicitly define with an optional implicit regularizer. This fills in the explanation of the dynamic performance of robust losses in training. Then the authors show the effects of loss functions and regularizers on learning through empirical studies, respectively."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The motivation for understanding empirical phenomenons of robust losses against label noise is interesting. The common features different losses shown make the understanding significant. Good motivation, especially since the data are becoming larger and learning with noisy labels is becoming a pressing challenge.\n\n- The empicial results echo the theoretical study. This paper conducts extensive experiments and comprehensive studies to evaluate the losses and regularizers, which helps give suggestions for using them.\n\n- Experiments are well designed. The theoretical statements in this paper seem correct. I think this work is valuable."
                },
                "weaknesses": {
                    "value": "- The robust losses involves the curriculum view, i.e., a sample-weighting perspective, the paper should include more discussion and empirical comparisons with curriculum and reweighting noisy-label learning methods.\n\n- Eq.3 appears to rely on a number of assumptions, which should be clarified in the formulation of these assumptions.\n\n- As one of the main formulas of the paper, it is not quite clear how Eq.4 was obtained. More details should be provided."
                },
                "questions": {
                    "value": "The results and findings in this paper are insightful and would be useful for future research. The paper is also well-written with solid theoretical exposition and strong results. Overall, this is a good paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3009/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697729123823,
            "cdate": 1697729123823,
            "tmdate": 1699636245518,
            "mdate": 1699636245518,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "IMGbNOsX2H",
                "forum": "g5TIh84amg",
                "replyto": "QvEy8yo8VW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your comments!\n\n### Regarding the Weaknesses\n\n> Q1: The robust losses involves the curriculum view, i.e., a sample-weighting perspective, the paper should include more discussion and empirical comparisons with curriculum and reweighting noisy-label learning methods.\n\nWe have discussed the relation to existing curriculum approaches in the related work section (now the second paragraph in the revised version). \n\nWe believe that empirical comparisons with existing sample-weighting curricula is optional, or even orthogonal to our experiments aiming to **understand existing loss functions**:\n\n- Results in section 4.1 analyze the effects of different implicit sample-weighting functions $w(\\boldsymbol{s}, y)$ of loss functions **considered in this work**. We do no claim for a comprehensive analysis of all sample weighting curricula.\n- Results in section 4.2 analyze the effects of the identified regularizers within loss functions considered in this work. They are orthogonal to existing sample-weighting curricula.\n- Results in section 4.3 aim to identify the cause of underfitting. We first establish the relation between minimal sample weights to underfitting. We then theoretically connects minimal sample weights to the increased number of classes, which leads to minimal $\\Delta(\\boldsymbol{s}, y)$ and thus minimal weights at initialization with robust loss functions. We then test whether increasing the sample weights with small $\\Delta(\\boldsymbol{s}, y)$ helps mitigate underfitting:\n  - Better results with our fixes compared to the underfitting loss functions support our explanation.\n  - Results of previous state-of-the-art under the same experiment settings reflect the significance of the improvement  (we choose results from \"Asymmetric loss functions for learning with noisy labels\")\n  - We never claim for a \"novel approach for new state-of-the-art performance\", which does require comprehensive comparison with major approaches of noisy-robust learning.\n\nGiven the page limitation, including additional empirical results of sample-weighting curriculums requires remove other important discussions of our unified standard form. We will reproduce some sample-weighting curricula in the appendix in later revisions.\n\n> Eq.3 appears to rely on a number of assumptions, which should be clarified in the formulation of these assumptions.\n\nWe have thoroughly revised our derivations in Section 3 to clarify the assumptions and intuitions. Eq.3 $L'(\\boldsymbol{s}, y) = - w(\\boldsymbol{s}, y) \\cdot \\Delta(\\boldsymbol{s}, y)$ is based on a mild assumption that we are using first order optimizers based on gradients.\n\n> As one of the main formulas of the paper, it is not quite clear how Eq.4 was obtained. More details should be provided.\n\nAs mentioned above, the revised derivations in Section 3 makes Eq. 4 much clearer. We describe the example derivation of NCE towards Eq.4 before presenting the detailed standard form of Eq.4. Intuitively, we extract the regularizer $R(\\boldsymbol{s})$ and rearrange other terms depending only on $\\Delta(\\boldsymbol{s}, y)$ into the primary loss function. If there is no explicit way to rearrange in the original loss terms, we turn to the gradients of $\\boldsymbol{s}$, try rearranging the gradient terms, and then integrate over $\\boldsymbol{s}$ after detaching weighting terms from derivative and integral. See the Appendix A.5 for detailed derivation for each loss functions."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3009/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700473215254,
                "cdate": 1700473215254,
                "tmdate": 1700473288092,
                "mdate": 1700473288092,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ONQGN4wxC4",
            "forum": "g5TIh84amg",
            "replyto": "g5TIh84amg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3009/Reviewer_pjXu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3009/Reviewer_pjXu"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates robust loss functions used in learning with noisy labels. This paper unifies a broad array of loss functions into a novel standard form, which consists of a primary loss function inducing a sample-weighting curriculum and an optional implicit regularizer. The resulting curriculum view leads to a straightforward analysis of the training dynamics, which may help demystify how loss functions and regularizers affect learning and noise robustness. This paper shows that robust loss functions implicitly sift and neglect corrupted samples, and analyze the roles of regularizers with different loss functions. Finally, this paper proposes effective fixes to address the underfitting issue of robust loss functions."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- A novel curriculum perspective of robust loss functions is proposed, which consists of a primary loss function inducing a sample-weighting curriculum and an optional implicit regularizer.\n- A sufficient number of robust loss functions are reviewed.\n- The proposed simple fix seems to work well."
                },
                "weaknesses": {
                    "value": "- Although a novel perspective that includes many loss functions is proposed, this perspective is unable to guide us to obtain any better robust loss functions, except for the simple fix to alleviate the underfitting issue.\n- To me, the fix derived from the curriculum view is the central part of this paper. However, this paper did not provide extensive experiments to empirically validate this method. Is this method versatile enough? Can any robust loss functions (excluding MAE) be equipped with this method? Can this method work well on a variety of large-scale datasets? Without clearly and extensively demonstrating the effectiveness, the key contribution this paper seems limited."
                },
                "questions": {
                    "value": "- Is the proposed fix versatile enough? \n- Can any robust loss functions (excluding MAE) be equipped with this method? \n- Can this method work well on a variety of large-scale datasets?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3009/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698677892123,
            "cdate": 1698677892123,
            "tmdate": 1699636245432,
            "mdate": 1699636245432,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZYWg0RRFTr",
                "forum": "g5TIh84amg",
                "replyto": "ONQGN4wxC4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Weakness 1"
                    },
                    "comment": {
                        "value": "Thanks for your comments!\n\n### Regarding the weaknesses\n\n> Q1: Although a novel perspective that includes many loss functions is proposed, this perspective is unable to guide us to obtain any better robust loss functions, except for the simple fix to alleviate the underfitting issue.\n\nIt would be unfair to state that \n\n> this perspective is unable to guide us to obtain any better robust loss functions, except for the simple fix to alleviate the underfitting issue\n\nWe should stress that:\n\n- Unifying loss functions **with different theoretical motivations** into the **same** dimensions of design choices\n- Connecting the design of loss functions to the design of learning curricula, which are commonly considered as distinct approaches.\n\nare theoretically **nontrivial**. These approaches are previously understood and analyzed with **distinct** approaches and motivations. Our theoretical derivations provide a **common** ground to understand and analyze them.\n\nAs loss functions can be viewed as sample-weighting curricula, our findings suggest plenty of approaches to directly design them. As a quick list:\n\n1. Blending the implcit curricula of robust loss functions to those explicitly designed, e.g., approach proposed in \"DivideMix: Learning with Noisy Labels as Semi-supervised Learning\"\n2. We can use other metrics than $\\Delta(\\boldsymbol{s}, y)$ to identify the constantly unlearned samples, e.g., $\\Delta(\\boldsymbol{s}, y) - m$  where $m$ is a running average of $\\Delta(\\boldsymbol{s}, y)$, and assign small weights to small $\\Delta(\\boldsymbol{s}, y) - m$, which can avoid the underfitting issue due to minimal initial sample weights.\n3. Use a proper regularizer for a good $\\Delta(\\boldsymbol{s}^*, y)$ with $\\boldsymbol{s}^* = \\arg\\min_{\\boldsymbol{s}} R(\\boldsymbol{s})$ to facillitate learning with a large number of classes and avoid overfitting noisy samples. Existing confidence reducing regularizers all share the same minimum with $\\Delta(\\boldsymbol{s}^*, y) = - \\log k$ where $k$ is the number of classes, which may risk underfitting with robust loss functions under large $k$.\n4. Utilize the sample sifting effect of robust loss functions to **select** corrupted samples and either drop them or utilize semi-supervised learning to obtain surrogate labels."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3009/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700472305267,
                "cdate": 1700472305267,
                "tmdate": 1700472305267,
                "mdate": 1700472305267,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MMdo4yZrZf",
                "forum": "g5TIh84amg",
                "replyto": "ONQGN4wxC4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to weakness 2 and questions"
                    },
                    "comment": {
                        "value": "> Q2: To me, the fix derived from the curriculum view is the central part of this paper. However, this paper did not provide extensive experiments to empirically validate this method. Is this method versatile enough? Can any robust loss functions (excluding MAE) be equipped with this method? Can this method work well on a variety of large-scale datasets? Without clearly and extensively demonstrating the effectiveness, the key contribution this paper seems limited.\n\nIt would be unfair to view the fixes for underfitting the central part of the paper, which ignores the significance of our theoretical framework and the following empirical insights:\n\n1. Robust loss functions act as a sift to neglect corrupted samples. This finding provides a distinct view compared to the theoretical bounds of these loss functions.\n2. Regularizers like weight decay is important to the learning of robust loss functions. It suggests that one should carefully tune the regularization with robust loss functions.\n3. Underfitting is due to minimal sample weights at initilizations, which is empirically supported by our fixes.\n\nWe have make these points more pronounced in the revised Introduction. \n\nWe focus more on comphrehensively understand the loss functions considered in this work. The empirical performance of our fix aims to confirm whether avoiding minimal initial samples weights can improve the underfitting loss functions. The effectiveness on the underfitting MAE (and TCE in our revision) supports our explanation.\n\n\n\nAs for the questions,\n\n> Is this method versatile enough? \n\nWe don't understand what \"versatile\" means. Our fixes apply to underfitting with minimal intial sample weights. Nevertheless, our analysis of underfitting can help diagnose the cause in other settings. Notably, the novel curriculum view and the resulting analysis are more versatile than methods tailored for specific settings.\n\n> Can any robust loss functions (excluding MAE) be equipped with this method? \n\nYes. As shown in Table 4, TCE also suffers to moderate underfitting. We include the results of our fixes to TCE on CIFAR100 in the revised Tables 5,8,9:\n\n|                         | Clean            | Symmmetric       | Symmetric        | Asymmetric       | Human            |\n| ----------------------- | ---------------- | ---------------- | ---------------- | ---------------- | ---------------- |\n|                         | $\\eta=0$         | $\\eta =0.4$      | $\\eta =0.8$      | $\\eta =0.4$      | $\\eta =0.4$      |\n| CE                      | 77.44 $\\pm$ 0.13 | 49.96 $\\pm$ 0.02 | 11.23 $\\pm$ 0.45 | 45.73 $\\pm$ 0.49 | 54.40 $\\pm$ 0.35 |\n| GCE                     | 73.88 $\\pm$ 0.25 | 64.67 $\\pm$ 0.49 | 23.90 $\\pm$ 2.69 | 45.14 $\\pm$ 0.13 | 56.95 $\\pm$ 0.63 |\n| NCE+AGCE                | 76.37 $\\pm$ 0.25 | 64.55 $\\pm$ 0.46 | 26.19 $\\pm$ 1.14 | 40.93 $\\pm$ 1.22 | 53.67 $\\pm$ 0.18 |\n| TCE                     | 58.04 $\\pm$ 1.15 | 45.91 $\\pm$ 1.25 | 20.47 $\\pm$ 1.45 | 28.35 $\\pm$ 0.74 | 32.22 $\\pm$ 1.22 |\n| TCE shift, $\\tau = 4.2$ | 77.14 $\\pm$ 0.11 | 60.17 $\\pm$ 0.47 | 18.16 $\\pm$ 0.37 | 44.56 $\\pm$ 0.71 | 55.07 $\\pm$ 0.19 |\n| TCE scale, $\\tau = 4.2$ | 75.79 $\\pm$ 0.17 | 62.88 $\\pm$ 0.59 | 20.78 $\\pm$ 1.53 | 43.57 $\\pm$ 1.19 | 56.13 $\\pm$ 0.22 |\n| MAE                     | 7.46 $\\pm$ 1.92  | 4.65 $\\pm$ 1.55  | 3.21 $\\pm$ 0.57  | 1.61 $\\pm$ 0.53  | 1.54 $\\pm$ 0.47  |\n| MAE shift, $\\tau = 3.4$ | 76.65 $\\pm$ 0.30 | 61.29 $\\pm$ 0.49 | 19.30 $\\pm$ 1.00 | 44.06 $\\pm$ 1.23 | 54.83 $\\pm$ 0.49 |\n| MAE scale, $\\tau = 3.4$ | 73.54 $\\pm$ 0.32 | 64.92 $\\pm$ 0.20 | 23.00 $\\pm$ 2.44 | 48.88 $\\pm$ 0.79 | 57.56 $\\pm$ 0.41 |\n\nResults on WebVision will be included in later revision as they requires weeks to converge.\n\n> Can this method work well on a variety of large-scale datasets?\n\nYes. To our knowledge, WebVision is the largest noisy dataset of image classification. We have extend the standard mini setting (50 classes) to include more classes (200 and 400), which are much more challenging than settings in previous research."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3009/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700472501177,
                "cdate": 1700472501177,
                "tmdate": 1700472501177,
                "mdate": 1700472501177,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "UOaeZQz0PB",
            "forum": "g5TIh84amg",
            "replyto": "g5TIh84amg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3009/Reviewer_L9A1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3009/Reviewer_L9A1"
            ],
            "content": {
                "summary": {
                    "value": "The goal of the paper is to study the behaviour of robust loss functions during training from a sample reweighting perspective. To do this, the authors propose to rewrite each loss on a common form that has the same gradients as the original loss. This common form is of a gradient weight $w$ times a margin difference $\\Delta$ (they also consider a more general form taking regularization into account). The authors then study these two quantities for different loss functions during training for clean and noisy labelled examples separately. For example, i) they find that gradient weights are higher for clean samples for the losses that generalize the best, ii) Mean Absolute Error (MAE) first learns easy examples which causes lower $\\Delta$ of noisy examples (\u201csample sifting\u201d), iii) label smoothing increases convergence and separations in $\\Delta$. Finally, the authors study the underfitting issues of MAE via $w$ and $\\Delta$ and proposes an effective fix.\n\nTherefore, the contributions of the paper are to rewrite the losses on a common form, their observations, as well as the modification of MAE."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "I find the paper has a well-organized structure which makes the high-level ideas easy to follow. I did not notice any technical issues in the paper. Furthermore, I like that mean and standard deviation were reported in Table 6, to show have some indication of variance between runs. The results are reproducible as the training setup (architecture, learning rate, weight decay, etc) are clearly stated including what hyperparameters were used and how they were selected. As far as I know, there is theoretical novelty in rewriting of the losses into a common form, and algorithmically in the proposed change to MAE."
                },
                "weaknesses": {
                    "value": "I immensely value research papers improving our understanding and not just present a new method, which I believe is the goal of this paper. Having said that, I believe the significance of this work could be improved considerably by making the explanations, findings, and conclusions **clearer**:\n* What is the motivation for rewriting the losses in this particular way? What novel perspective does this form give over something more intuitive like the $p_y$ and the gradient magnitude of the loss wrt to the logits? For example, in Figure 1, couldn\u2019t one see the same thing with an x-axis with $p_y$ instead of $\\Delta$, and the y-axis being the gradient magnitude wrt the logits for the MAE green curve instead of $w$?\n* How isn\u2019t it trivial that different loss functions have different gradient weights, and therefore different sample weights? If all loss functions penalized the same, there would be no reason to have different ones?\n* A single sentence motivating the inequality in Equation 5 would make it clearer.\n* The clarity of several equations could be improved:\n  * The equation between Equations 2 and 3 is crucial and could be made much clearer: i) a single sentence discussion or motivation for using stop gradient, ii) what $\\Delta_y$ is, iii) why two additional minus signs are added in the middle equation, iv) and as $w$ is a key component of the paper, I believe it deserves a proper definition.\n  * The equation at the end of page 3: i) why are stop gradients used in that derivation? ii) why is a factor of k and 1/k introduced?\n* It was unclear to me, why the more general form that accounts for regularization was introduced, when its properties like $R(s)$ never were studied.\n\n**Experimental Rigor.**\n\nReporting mean and standard deviation would improve the conclusiveness of the observations in the tables. Furthermore, the network predictions from several runs could be used to have more reliable histogram estimates (more data).\n\n**Novelty and Significance.**\n* What novelty and significance does this work add over that of Wang et al. [1]?\n  * What are the benefits of viewing the losses in terms of the gradient of $\\Delta$ rather than the more natural gradient magnitude wrt to the logits?\n  * The following finding is not novel: \u201cZhang & Sabuncu (2018) attribute underfitting of MAE to the lack of the 1/py term in sample gradients, which \u201ctreats every sample equally\u201d and thus hampers learning. In contrast, we show that MAE emphasizes samples with moderate \u2206(s, y).\u201d That MAE does not treat samples equally and instead focus on examples with moderate loss/$\\Delta$, is not novel in this work. This is one of the main findings of Wang et al., which is clearly shown in their Figure 1 (or 2 depending on version of the paper), where examples with low and high $p_y$ have small gradients.\n  * I believe the following quote is misrepresenting the related work: \u201c.. attribute underfitting to their low variance, making clean and noise samples less distinguishable. But as shown in Table 4 MAE can underfit data with clean labels.\u201d. Wang et al. did not mention that the variance was low between clean and noisy samples, but rather the more general \u201cinformative\u201d and \u201cuninformative\u201d examples. Furthermore, the finding that MAE underfits clean examples is not novel, and even Wang et al. clearly shows this in their Table 1.\n  * Finally, Wang et al. already proposed a fix for MAE. Therefore, the novelty and significance of the proposed fix in this paper is unclear. A proper comparison (theoretically and experimentally) with other fixes for MAE is required.\n* What\u2019s the significance of the proposed way of rewriting the loss functions? If one instead does similar studies in terms of loss values (e.g., Figure 3 in [1], and Figure 2 in [2]) or gradients (e.g., Theorem 1 in [3]), it seems many of the findings in the paper are already well-known. For example, that the gradients of clean examples dominates the early learning phase and then the gradients for noisy labelled examples take over, resulting in overfitting [3]. Another example, that regularization methods If there are any novel and significant findings, I believe the authors should much more clearly state, relate, and discuss the significance of them compared to related work. That MAE focuses on moderate loss examples, as shown by Wang et al. (2019a).\n\n\n**Missing related work.**\n\nThe list of robust loss functions is comprehensive, but missing some relevant ones based on information theory: i) f-divergences [5], ii) Bregman divergences [6], and iii) Jensen-Shannon divergences [7].\n\n**References.**\n\n[1] Wang X, Hua Y, Kodirov E, Robertson NM. Imae for noise-robust learning: Mean absolute error does not treat examples equally and gradient magnitude's variance matters.\n\n[2] Chen P, Chen G, Ye J, Heng PA. Noise against noise: stochastic label noise helps combat inherent label noise.\n\n[3] Li J, Socher R, Hoi SC. Dividemix: Learning with noisy labels as semi-supervised learning.\n\n[4] Liu S, Niles-Weed J, Razavian N, Fernandez-Granda C. Early-learning regularization prevents memorization of noisy labels.\n\n[5] Wei J, Liu Y. When optimizing $ f $-divergence is robust with label noise.\n\n[6] Amid E, Warmuth MK, Anil R, Koren T. Robust bi-tempered logistic loss based on bregman divergences.\n\n[7] Englesson E, Azizpour H. Generalized jensen-shannon divergence loss for learning with noisy labels."
                },
                "questions": {
                    "value": "Why would one use your rewriting of the loss function to study the training dynamics of robust loss functions over say the gradient perspective in Wang et al. or that in the GCE paper? What novel findings do you, and can you, make only because of this framework?\n\nMost experiments, and the only proposed fix based on the analysis, are related to MAE. As Wang et al. has studied and proposed a fix for MAE, could you clarify what novelty you bring to the understanding of MAE, and why it is significant?\n\nWhy would one use your fix for MAE over the fix proposed by Wang et al.?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3009/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3009/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3009/Reviewer_L9A1"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3009/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699001524802,
            "cdate": 1699001524802,
            "tmdate": 1699636245367,
            "mdate": 1699636245367,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KCo7yIYBoz",
                "forum": "g5TIh84amg",
                "replyto": "UOaeZQz0PB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the weaknesses"
                    },
                    "comment": {
                        "value": "Thanks for your incisive comments! Your questions really help make our contributions clearer in our revision:\n\n- Introduction now clearly states the core contribution\n- The derivation in section 3 is intuitively much clearer\n- The empirical results in section 4 are clearly compared to related findings.\n\n### Regarding the weaknesses\n\n>  Q1: What is the motivation for rewriting the losses in this particular way? What novel perspective does this form give over something more intuitive like the $p_y$ and the gradient magnitude of the loss wrt to the logits? For example, in Figure 1, couldn\u2019t one see the same thing with an x-axis with $p_y$ instead of $\\Delta$, and the y-axis being the gradient magnitude wrt the logits for the MAE green curve instead of $w$?\n\nThe key motivation is to unify loss functions **with different theoretical motivations** into the **same** dimensions of design choices: the sample-weighting strategy and the output regularizer, where the shared implicit loss function $\\Delta(\\boldsymbol{s}, y)$ provides a common ground to analyze their properties\n\nRegarding the mentioned metrics for analysis,\n\n- Although $p_y$ and $\\Delta$ can both track the learning of samples, $p_y$ applies a sigmoid transform on top of $\\Delta$ that ignores the change of large $\\|\\Delta\\|$, making the change around initialization and convergence too subtle to be noticed. For example, with CE + NLS (Figure 2 f), one cannot notice the improper scale and risk of numerical overflow when viewing the distributions in $p_y$.  We discuss the benefits of $\\Delta$ in the revised paragraph after Eq. (3).\n\n- Gradient magnitude can compare the loss functions **only when the shared gradient direction are extracted**, i.e., $\\nabla_\\boldsymbol{s} \\Delta$. When regularizers are involved, e.g., MSE, our standard form helps separate the effects of regularizers, which is hard to achieve when only considering the gradient magnitude.\n\n> Q2: How isn\u2019t it trivial that different loss functions have different gradient weights, and therefore different sample weights? If all loss functions penalized the same, there would be no reason to have different ones?\n\nDifferent loss functions can have different gradient **directions** and **sample weights** simultaneously. The fact that loss functions with distinct theoretical motivations share the same $\\nabla_\\boldsymbol{s} \\Delta$ gradient component is **nontrivial**.\n\n> Q3: A single sentence motivating the inequality in Equation 5 would make it clearer.\n>\n\nIn our revision, we remove the inequality in Equation 5 and add \"where $\\mathbb{E}_k[\\Delta(\\boldsymbol{s}, y)]< 0$ with standard initialization $\\sigma \\approx 1$ and a large $k$.\" right after it.\n\n> Q4: The clarity of several equations could be improved:\n>\n\nWe have thoroughly revised Section 3 for clearer intuition of our derivations.\n\n> Q4.1: The equation between Equations 2 and 3 is crucial and could be made much clearer: i) a single sentence discussion or motivation for using stop gradient, ii) what $\\Delta_y$ is, iii) why two additional minus signs are added in the middle equation, iv) and as $w$ is a key component of the paper, I believe it deserves a proper definition.\n>\n\ni): what we really mean is to detach $w(\\boldsymbol{s}, y)$ from any computation of derivative & integral, thus preserving the same gradient in the standard form. We have rephrased \"stop gradient operator\" to \"detach operator\".\n\nii): $\\Delta_y$ is simply a typo for $\\Delta(\\boldsymbol{s}, y)$\n\niii): it aims to make $w(\\boldsymbol{s}, y)$ a positive function, and facilitates a direct substitution given that we do not explicitly define $w(\\boldsymbol{s}, y)$\n\niv): we dub $w(\\boldsymbol{s}, y)$ the **sample-weighting function** and include its definition in our revision right after Eq. (3)\n\n> Q4.2: The equation at the end of page 3: i) why are stop gradients used in that derivation? ii) why is a factor of k and 1/k introduced?\n>\n\ni): the stop gradient issue is similar to Q4.1, i).\n\nii): it makes the later extraction of $R_{\\mathrm{NCE}}(\\boldsymbol{s}) = \\sum_{i=1}^{k} \\frac{1}{k}\\log p_i$ more straightforward. It shares similar form as confidence regularizer $R_{\\mathrm{CR}}(\\boldsymbol{s}) =\\sum_{i=1}^{k} P(y = i) \\log p_{i}$, helping the readers to observe their connection -- we can obtain $R_{\\mathrm{NCE}}(\\boldsymbol{s})$ by setting $P(y = i) = \\frac{1}{k}$.\n\n> Q5: It was unclear to me, why the more general form that accounts for regularization was introduced, when its properties like $R(\\boldsymbol{s})$ never were studied.\n>\n\nWe devote the entire section 4.2 to study the effect of different $R(\\boldsymbol{s})$. At the beginning of section 4, we mention that $R(\\boldsymbol{s})$ constrains the distributions of $\\Delta(\\boldsymbol{s}, y)$ towards a predefined optimum $\\Delta(\\boldsymbol{s}^*, y)$ where $\\boldsymbol{s}^* = \\arg\\min_{\\boldsymbol{s}} R(\\boldsymbol{s})$. In our revision, we make it more pronounced right after the introduction of the standard form in Eq. (4)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3009/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700465634542,
                "cdate": 1700465634542,
                "tmdate": 1700477687110,
                "mdate": 1700477687110,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iEuCRcvEGj",
                "forum": "g5TIh84amg",
                "replyto": "UOaeZQz0PB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Q1 of Novelty and Significance"
                    },
                    "comment": {
                        "value": "### Regarding Novelty and Significance\n\n> Q1: What novelty and significance does this work add over that of Wang et al. [1]?\n\n> Q1.1: What are the benefits of viewing the losses in terms of the gradient of $\\Delta$ rather than the more natural gradient magnitude wrt to the logits?\n\nThis question is similar to Weakness Q1 and Q2. Gradient magnitude can compare the loss functions **only when a shared gradient direction are extracted**, i.e., $\\nabla_\\boldsymbol{s} \\Delta(\\boldsymbol{s},y)$. We explicitly factorize the scale $w(\\boldsymbol{s}, y)$ and direction $\\nabla_\\boldsymbol{s} \\Delta(\\boldsymbol{s}, y)$ of the gradient wrt logits $\\boldsymbol{s}$ for a wide range of loss functions.\n\nWhen no output regularizer $R(\\boldsymbol{s})$ is involved, $w(\\boldsymbol{s}, y)$ and gradient magnitude are equivalent. When $R(\\boldsymbol{s})$ is implicitly involved, e.g., MSE and NCE, loss functions can have different gradient directions, making comparisons of gradient magnitudes improper. In contrast, $w(\\boldsymbol{s}, y)$ and $R(\\boldsymbol{s})$ leads to a proper comparison among loss functions.\n\n> Q1.2: The following finding is not novel: \u201cZhang & Sabuncu (2018) attribute underfitting of MAE to the lack of the $1/p_y$ term in sample gradients, which \u201ctreats every sample equally\u201d and thus hampers learning. In contrast, we show that MAE emphasizes samples with moderate $\\Delta(s, y)$.\u201d That MAE does not treat samples equally and instead focus on examples with moderate loss/$\\Delta$, is not novel in this work. This is one of the main findings of Wang et al., which is clearly shown in their Figure 1 (or 2 depending on version of the paper), where examples with low and high $p_y$ have small gradients.\n\nWe modify the statement to \"In contrast, we show that MAE emphasizes samples with moderate $\\Delta(\\boldsymbol{s}, y)$ which is also observed by Wang et al. (2019a).\"\n\n> Q1.3: I believe the following quote is misrepresenting the related work: \u201c.. attribute underfitting to their low variance, making clean and noise samples less distinguishable. But as shown in Table 4 MAE can underfit data with clean labels.\u201d. Wang et al. did not mention that the variance was low between clean and noisy samples, but rather the more general \u201cinformative\u201d and \u201cuninformative\u201d examples. Furthermore, the finding that MAE underfits clean examples is not novel, and even Wang et al. clearly shows this in their Table 1.\n\nWe do misinterpret their statement.  In our revision in the first paragraph of section 4.3, we rephrased our statement to \"Wang et al. (2019a) view $\\|\\nabla_{\\boldsymbol{s}} L(\\boldsymbol{s}, y)\\|_1$ as weights for sample gradients and argue that their low variance makes informative and uninformative samples less distinguishable. However, it is unclear how low variance of gradient magnitudes leads to underfitting.\" Indeed, they do not explicitly explain why low variance of gradients can lead to underfitting.\n\nWe do not claim that MAE underfits clean data is novel -- it is well known in previous research.\n\n> Q1.4: Finally, Wang et al. already proposed a fix for MAE. Therefore, the novelty and significance of the proposed fix in this paper is unclear. A proper comparison (theoretically and experimentally) with other fixes for MAE is required.\n\nWe should emphasize that we focus more on how our unified framework helps understanding the underfitting issue. Previous explanations have been thoroughly reviewed at the beginning of section 4.3, which are all flawed in various aspects. The proposed fixes merely aim to support the validity of our explanation:\n\n- that minimal initial sample weight leads to underfitting as shown in our analysis\n- that increasing initial sample weight indeed addresses underfitting\n\nWe stress this point in the revised abstract and introduction. A comparable performance of our fixes to selected state-of-the-art results already serves our purpose. Comparisons to other fixes would be nice to have but unnecessary. \n\nWe include discussions and empirical comparisons of IMAE to Wang et al. in the revised section 4.3 using our experimental settings.  See the updated Figure 4(c) for a visualization of $w(\\boldsymbol{s},y)$ and Table 5,8,9 for results on CIFAR100. We find that IMAE is very sensitive to hyperparameters. Results on WebVision requires a thorough tuning of hyperparameters for IMAE, which requires more time than the rebuttal period. We will include them in later revisions."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3009/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700468304710,
                "cdate": 1700468304710,
                "tmdate": 1700468304710,
                "mdate": 1700468304710,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xy51OvzHtN",
                "forum": "g5TIh84amg",
                "replyto": "UOaeZQz0PB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Q2 of Novelty and Significance"
                    },
                    "comment": {
                        "value": "> Q2: What\u2019s the significance of the proposed way of rewriting the loss functions? If one instead does similar studies in terms of loss values (e.g., Figure 3 in [1], and Figure 2 in [2]) or gradients (e.g., Theorem 1 in [3]), it seems many of the findings in the paper are already well-known. For example, that the gradients of clean examples dominates the early learning phase and then the gradients for noisy labelled examples take over, resulting in overfitting [3]. Another example, that regularization methods If there are any novel and significant findings, I believe the authors should much more clearly state, relate, and discuss the significance of them compared to related work. That MAE focuses on moderate loss examples, as shown by Wang et al. (2019a).\n\nWe should again stress that:\n\n- Unifying loss functions **with different theoretical motivations** into the **same** dimensions of design choices\n\n- Connecting the design of loss functions to the design of learning curricula, which are commonly considered as distinct approaches. \n\nare theoretically **nontrivial**. These approaches are previously understood and analyzed with **distinct** approaches and motivations. Our theoretical derivations provide a **common** ground to understand and analyze them.\n\nWe have summarized our key empirical findings in the last paragraph of the revised introduction:\n\n- Robust sample-weighting functions act as a sift to neglect corrupted samples\n- Regularizers can help the learning of robust loss functions\n- Underfitting is due to minimal sample weights at initializations\n\nRegarding the listed minor empirical findings:\n\n> \"that the gradients of clean examples dominates the early learning phase and then the gradients for noisy labelled examples take over, resulting in overfitting\" in [4]\n\nYes, our observation is similar to [4]. They conduct theoretical analysis on linear binary classification and intuitively extend it to the multiclass setting. We remove the emphasis of this point in our revised introduction.\n\nThe discussion of the relation between $\\lim_{\\Delta(\\boldsymbol{s}, y) \\to \\infty} w(\\boldsymbol{s}, y) = 0$ and the memoization effect is necessary for a comprehensive analysis of sample weighting functions $w(\\boldsymbol{s}, y)$. We relate our results to [4] by commenting \"Such explanation complements the theoretical analysis for binary linear classification in [4], which reach similar conclusion that corrupted samples dominate the expected gradients in the late training stage.\" in the revised last paragraph of section 4.1. \n\n> \"Another example, that regularization methods If there are any novel and significant findings, \"\n\nWe don't understand the meaning of this question. As a speculative response, we only briefly mention that regularization preventing the memorization stage helps noise-robustness of CE in the last paragraph of section 4.1. It is included only for a more thorough discussions on the properties of $w(\\boldsymbol{s}, y)$. We never claim that this observation is novel.\n\n> \"That MAE focuses on moderate loss examples, as shown by Wang et al. (2019a).\"\n\nIn our revision, this point is clearly stated in the first paragraph of section 4.3, \"In contrast, we show that MAE emphasizes samples with moderate $\\Delta(\\boldsymbol{s}, y)$ which is also observed by Wang et al. (2019a).\"\n\nWe should stress that our analysis shows that **ALL** robust loss functions has sample-weighting function $w(\\boldsymbol{s}, y)$ focusing on samples with moderate $\\Delta(\\boldsymbol{s}, y)$ while Wang et al. (2019a) made similar observation **ONLY** for MAE. See the visualization of Figure 5 in appendix A. We mention this point in the revised caption of Table 1."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3009/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700468882354,
                "cdate": 1700468882354,
                "tmdate": 1700468882354,
                "mdate": 1700468882354,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ABrCIIoyg6",
                "forum": "g5TIh84amg",
                "replyto": "UOaeZQz0PB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to experimental rigor and missing related work"
                    },
                    "comment": {
                        "value": "### Regarding experimental rigor\n\n> Reporting mean and standard deviation would improve the conclusiveness of the observations in the tables. Furthermore, the network predictions from several runs could be used to have more reliable histogram estimates (more data).\n\nResults in table 3-4 are reported with 3 different runs but there is no enough space to include the std. Results of WebVIsion in Table 6 are too expensive to conduct multiple random runs as stated in the caption.\n\nWe would update the histogram estimates in later revisions. However, the size of training set already bears a statistically reliable estimation of the histograms.\n\n### Regarding the missing related work\n\n> The list of robust loss functions is comprehensive, but missing some relevant ones based on information theory: i) f-divergences [5], ii) Bregman divergences [6], and iii) Jensen-Shannon divergences [7].\n\nThanks for providing the list of related work! We include Jensen-Shannon divergences in the revised Table 2, which involves a new implicit output regularizer $R(\\boldsymbol{s}) = \\sum_i p_i$. \n\nOur analysis does not apply to f-divergences [5] and Bregman divergences [6] without closed-form expressions. We clearly state this in the third paragraph of the revised section 3, \"We examine a broad array of loss functions with closed-form expressions in this work\", and the first paragraph of the related work, \"We only consider loss functions with closed-form expressions and leave others (Amid et al., 2019; Wei & Liu, 2021) to future work.\""
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3009/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700469139776,
                "cdate": 1700469139776,
                "tmdate": 1700471249870,
                "mdate": 1700471249870,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rC1tpmySgl",
                "forum": "g5TIh84amg",
                "replyto": "UOaeZQz0PB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Questions"
                    },
                    "comment": {
                        "value": "### Regarding the questions\n\n> Q1: Why would one use your rewriting of the loss function to study the training dynamics of robust loss functions over say the gradient perspective in Wang et al. or that in the GCE paper? What novel findings do you, and can you, make only because of this framework?\n\nBy only considering the gradient magnitude, both Wang et al. and the GCE paper \n\n- cannot identify the effects of the implicit regularizers of loss functions, e.g., MSE, NCE\n- cannot correctly compare different loss functions. Gradient directions of the implicit regularizers makes $\\|\\nabla_{\\boldsymbol{s}} L({\\boldsymbol{s}}, y)\\|_1$ of Wang et al. not comparable. Even without implicit regularizers, $\\mathrm{d}L({\\boldsymbol{s}}, y)/\\mathrm{d} p_y$ of the GCE paper has an additional $p_y(1-p_y)$ factor in the sample gradients.\n\nOur standard form leads to proper comparison among loss functions with $w(\\boldsymbol{s}, y)$ and $R(\\boldsymbol{s})$.\n\n\n> Q2: Most experiments, and the only proposed fix based on the analysis, are related to MAE. As Wang et al. has studied and proposed a fix for MAE, could you clarify what novelty you bring to the understanding of MAE, and why it is significant?\n\n> Most experiments, and the only proposed fix based on the analysis, are related to MAE. \n\nIn the first paragraph of the revised section 4, we explicitly state that \"We mainly use MAE and CE for illustration as they exhibit typical empirical observations. Similar analysis of other loss functions are left to Appendix B.\" \n\n> Could you clarify what novelty you bring to the understanding of MAE, and why it is significant?\n\nWang et al. does not provide an explicit explanation for the underfitting of MAE. Their empirical results only support the fact that their fix helps mitigate underfitting. However, their claim that \"gradient magnitude\u2019s variance matters\" is not empirically supported. Based on their empirical results, one can also attribute other metrics varied due to their fix, e.g., \"the expected gradient magnitude matters\". Thus in the first paragraph of the revised section 4.3, we comment that \"Wang et al. (2019a) view $\\|\\nabla_{\\boldsymbol{s}} L({\\boldsymbol{s}}, y)\\|_1$ as weights for sample gradients and argue that their low variance makes informative and uninformative samples less distinguishable. However, it is unclear how low variance of gradient magnitudes leads to underfitting.\"\n\nIn contrast, we support our explanation explicitly with empirical and theoretical results. \n\n- We first establish the connection between underfitting (measured by train/test accuracy) to small sample weights (measured by effective learning rate $\\alpha^*$ ).\n- We then theoretically connects the increased number of classes to the decreased $\\Delta(\\boldsymbol{s},y)$ and sample weights at initialization, and empirically support it with results in Figure 3. \n- We finally establish the causal relation between minimal initial sample weights and underfitting. The fact that increased initial sample weights with our fixes eliminates underfitting support this claim well.\n\n> Q3: Why would one use your fix for MAE over the fix proposed by Wang et al.?\n\nOur fix are less sensitive to the hyperparameter $\\tau$: the same $\\tau = 3.4$ works well for a wide range of noise rates with MAE, while IMAE Wang et al. requires careful hyperparameter tuning for each noise setting (stated in the appendix D of their paper). In addition, under the same settings, our fix achieves better results than IMAE.\n\nNonetheless, we recommend designing new learning curricula based on our framework and empirical findings instead of sticking with the classic but flawed MAE. As loss functions can be viewed as sample-weighting curricula, our findings suggest plenty of approaches to design good curricula. As a quick list:\n\n1. Blending the implicit curricula of robust loss functions to those explicitly designed, e.g., approach proposed in \"DivideMix: Learning with Noisy Labels as Semi-supervised Learning\"\n2. We can use other metrics than $\\Delta(\\boldsymbol{s}, y)$ to identify the constantly unlearned samples, e.g., $\\Delta(\\boldsymbol{s}, y) - m$  where $m$ is a running average of $\\Delta(\\boldsymbol{s}, y)$, and assign small weights to small $\\Delta(\\boldsymbol{s}, y) - m$, which can avoid the underfitting issue due to minimal initial sample weights.\n3. Use a proper regularizer for a good $\\Delta(\\boldsymbol{s}^*, y)$ with $\\boldsymbol{s}^* = \\arg\\min_{\\boldsymbol{s}} R(\\boldsymbol{s})$ to facilitate learning with a large number of classes and avoid overfitting noisy samples. Existing confidence reducing regularizers all share the same minimum with $\\Delta(\\boldsymbol{s}^*, y) = - \\log k$ where $k$ is the number of classes, which may risk underfitting with robust loss functions under large $k$.\n4. Utilize the sample sifting effect of robust loss functions to **select** corrupted samples and either drop them or utilize semi-supervised learning to obtain surrogate labels."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3009/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700471230522,
                "cdate": 1700471230522,
                "tmdate": 1700471230522,
                "mdate": 1700471230522,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "lpi2rEmU3k",
            "forum": "g5TIh84amg",
            "replyto": "g5TIh84amg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3009/Reviewer_CdpW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3009/Reviewer_CdpW"
            ],
            "content": {
                "summary": {
                    "value": "The authors examine the challenges of underfitting and the factors influencing the robustness of loss functions in the context of training with noisy labels. They approach these questions by analyzing robust loss functions through a lens that emphasizes the importance of sample-weighting strategies and an optional implicit regularizer. To address underfitting, they suggest modifying these sample-weighting approaches. Additionally, they present evidence that refining the schedule of learning rate adjustments can enhance the robustness of the loss functions."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* This work connects several popular robust loss designs to a sample-weighting curriculum.\n\n* Empirically, the authors explain the two open questions in the literature of learning with noisy labels. The introduce of a marginal effective learning rate looks interesting and helps with explaining the underfitting issue. And the shifting of soft-margin mitigates the underfitting, especially when the number of classes is large."
                },
                "weaknesses": {
                    "value": "* The presentation of experiments could be further improved, i.e., what is $\\tau$ in Figure 4.\n\n* The proposed strategy for shifting and rescaling appears to hold potential; however, its design is somewhat heuristic and depends heavily on a crucial hyper-parameter. This may hinder the efficient usage of the proposed method in practice."
                },
                "questions": {
                    "value": "My main concerns are from the empirical sections:\n\n* what is $\\tau$ in Figure 4?\n\n* In Table 3, why MAE has such pretty bad performances under CIFAR-100?\n\n* Maybe I missed some important details, I was wondering how authors pick  $\\tau$ for reporting experiment results in Table 5, 6."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3009/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699257083647,
            "cdate": 1699257083647,
            "tmdate": 1699636245290,
            "mdate": 1699636245290,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "nVQ2Jhn0bY",
                "forum": "g5TIh84amg",
                "replyto": "lpi2rEmU3k",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3009/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your comments! We have carefully revised our submission for better clarity.\n\n### Regarding the weakness\n\n> Q1: The presentation of experiments could be further improved, i.e., what is $\\tau$ in Figure 4.\n\n$\\tau$ is the hyperparameter of the shifted/scaled weighting function $w^{+}(\\boldsymbol{s}, y)$ and  $w^{*}(\\boldsymbol{s}, y)$. It is denoted in the caption of Figure 4 in our revision\n\n> Q2: The proposed strategy for shifting and rescaling appears to hold potential; however, its design is somewhat heuristic and depends heavily on a crucial hyper-parameter. This may hinder the efficient usage of the proposed method in practice.\n\nIn fact, we deliberately keep our fixes simple instead of more intricate designs. The scaling&shifting fixes aim to show that by avoiding minimal initial samples weights, underfitting loss functions can become as performant as previous state-of-the-art results, thus supporting our explanation of the underfitting issue. \n\nWe do not claim for a general well-performing approach in the present work that focus on comprehensively understanding existing loss functions, which can facilitate the design of better loss functions and learning curricula in future work. We have stressed these points in our revised Introduction.\n\nA good hyperparameter $\\tau$ can be generally applicable to most noise settings as shown by our results. It only requires a mild adjustment when changing tasks with different difficulties.\n\n### Regarding the questions\n> Q1: what is $\\tau$ in Figure 4?\n\nSee response for weakness Q1\n\n> Q2: In Table 3, why MAE has such pretty bad performances under CIFAR-100?\n\nIt is due to the minimal sample weights that $w_{\\mathrm{MAE}}$ assign to samples at initialization, which has been thoroughly discussed in section 4.3:\n- the first paragraph provide a quick review of existing observations and explanations\n- the second confirms and intuitively explains it\n- the third reveals the cause with increased number of classes $k$ and how it leads to minimal initial sample weights\n- the fourth provide fixes to address it, further confirming that underfitting is indeed caused by minimal initial sample weights\n\n> Q3: Maybe I missed some important details, I was wondering how authors pick $\\tau$ for reporting experiment results in Table 5, 6.\n\n$\\tau$ in Tables 5,8,9 is tuned on CIFAR100 with symmetric noise rate $\\eta = 0.4$. Due to the excessive training time required to train on WebVision, $\\tau$ in Table 6 is roughly tuned for each setting based on the observation that smaller $\\tau$ helps avoid underfitting but undermines noise robustness."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3009/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700463638708,
                "cdate": 1700463638708,
                "tmdate": 1700463638708,
                "mdate": 1700463638708,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]