[
    {
        "title": "On Error Propagation of Diffusion Models"
    },
    {
        "review": {
            "id": "trhuJ1LAbT",
            "forum": "RtAct1E2zS",
            "replyto": "RtAct1E2zS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4099/Reviewer_ebh3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4099/Reviewer_ebh3"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a theoretical framework to quantify per iteration error in variational inference within the backward pass of difussion models.\nThe authors introduce metrics to theoretically quantify these errors and convincingly demonstrate their increase with iteration number. \nConsequently, the model's performance deteriorates as the number of iterations increases. \nTo mitigate this issue, the authors propose to add the error as a regularization term upon the original loss function. \nEmpirical experiments are conducted to validate the effectiveness of this proposed methodology."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is very well written and I really enjoys reading this paper.\n\n- The concept of error quantification presented by the authors is both innovative and well-conceived."
                },
                "weaknesses": {
                    "value": "- Modular Error Definition: The modular error is defined as the expected KL divergence from $p_{\\theta}$ to $q$. However, the KL divergence is not symmetric. Could the authors please explain why the modular error is defined in such a way? Why not using the reversed KL divergence as in the original loss function?\n\n\n- Assumptions in Theorem 3.1: The assumptions regarding the output distribution of the neural network (NN) following a standard Gaussian distribution and the entropy reduction with iteration number appear quite strong. Can the authors justify these two assumptions empirically?\n    \n\n- Technical Issues in the Proof:\n\n    - In the proof of Proposition A.1 in Appendix A, equation (19) holds only in the limit as $T\\to\\infty$. The current proof falls short of demonstrating Proposition A.1 for finite values of $T$.\n\n    - Several typographical errors in equation (24) in Appendix B raise concerns about the validity of the proof. Specifically, the $p_{\\theta}$ term in both the numerator and denominator should be consistent and denoted as $p_{\\theta}(x_{t-1}|x_{t})$ in order for equation (29) to hold. Additionally, the first term in the second line of (24) appears to be missing a logarithmic notation, and the third line of (24) appears inconsistent with the current notation.\n\n- Hyper-Parameter Selection: The authors should provide further clarification on the process for selecting hyper-parameters. Notably, the weight assigned to the regularization term is a critical factor that requires elucidation.\nHow to select the hyper-parameters? One such important factor is the weight of the regularization term, could the authors please clarify?\n\n- Minor Issues:\n\n    - The notation for conditional expectation should be corrected throughout the paper to $E_{X_{t}|X_{t+1}}$.\n    \n    - In Section 3.2, second paragraph, \"get ride of\" should be corrected to \"get rid of\".\n    \n    - The proof for (14), establishing the boundedness of the KL divergence by the MMD, rests on the assumption that $\\log(1-x/4)$ is well-defined, which only holds when $x<4$. The authors should address and clarify this point."
                },
                "questions": {
                    "value": "Please refer to the questions in the previous section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4099/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698459884437,
            "cdate": 1698459884437,
            "tmdate": 1699636374902,
            "mdate": 1699636374902,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YYOrPQghKv",
                "forum": "RtAct1E2zS",
                "replyto": "trhuJ1LAbT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4099/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4099/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part-1 of Our Response"
                    },
                    "comment": {
                        "value": "Dear Reviewer ebh3,\n\nWe thank you for your kind, constructive, and comprehensive feedback. In the following, we have answered all your concerns in a point-by-point manner.\n\n### Comment-1: Modular Error Definition \u2026 the KL divergence is not symmetric. Could the authors please explain why the modular error is defined in such a way?\u00a0\u2026\n\nAnswer-1: Thanks for raising this insightful point. We did consider the asymmetry of KL divergence. The key is that **the error propagation happens to the learnable backward process $p_{\\theta}$** (instead of the predefined forward process $q$). Therefore, it makes more sense to define the module error as\n\n$E_{x_t \\sim p_{\\theta}(x_t)}[ D_{KL} ( p_{\\theta}(x_{t-1} | x_t) \\mid\\mid q(x_{t-1} | x_t) ] = \\int p_{\\theta}(x_t) ( \\int p_{\\theta}(x_{t-1} | x_t) \\ln (\\cdot) dx_{t-1}) dx_t = E_{x_t \\sim p_{\\theta}(x_t)}[ E_{x_t \\sim p_{\\theta}( x_{t-1} | x_t)}[ \\ln(\\cdot) ]  ] $,\n\nsuch that **expectation integrals are operated on the distributions $p_{\\theta}(x_t), p_{\\theta}(x_{t-1} | x_t)$ of the backward process** to average the distribution gap $\\ln(\\cdot)$. For your mentioned reversed case, the expectation operations will be mistakenly applied to the distributions $q(x_t), q(x_{t-1} | x_t)$ of the forward process.\n\n### Comment-2: Assumptions in Theorem 3.1 \u2026 Can the authors justify these two assumptions empirically?\n\nAnswer-2: Thanks for raising this point. For our assumption on $\\epsilon_{\\theta}(x_t, t)$, **we first weaken it into a new assumption from a theoretical angle and then perform experiments to empirically verify its validity**.\n\nSince neural network $\\epsilon_{\\theta}(x_t, t)$ is designed to fit Gaussian noise $\\epsilon$ in the loss function $L^{nll}$, we previously supposed that the output distribution of $\\epsilon_{\\theta}(x_t, t)$ follows a standard Gaussian. In our proof to Theorem 3.1, **that assumption is applied to indicate that $E[\\| \\epsilon_{\\theta}(x_t, t) \\|^2] = K$** ($K$ is the vector dimension). However, considering Eq. (27) and Eq. (28) in the proof, **our theorem still holds for $E[\\| \\epsilon_{\\theta}(x_t, t) \\|^2] \\ge K$**.\n\nTo derive a new assumption, we first set a term \n\n$r_t = E[ \\| \\epsilon - \\epsilon_{\\theta}(\\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon, t) \\|^2 ]$, \n\nwhich indicates the prediction error of neural network $\\epsilon_{\\theta}(x_t, t)$. The term will vanish to $0$ if $\\epsilon_{\\theta}(x_t, t)$ is fully accurate in backward denoising. According to the Triangle Inequality, we then have \n\n$r_t \\ge E[ \\| \\epsilon \\|^2 - \\| \\epsilon_{\\theta}(\\cdot) \\|^2  ] = E [\\| \\epsilon \\|^2] - E[ \\| \\epsilon_{\\theta}(\\cdot) \\|^2 ] $. \n\nSince the second moment of Gaussian distribution $E[\\| \\epsilon \\|^2]$ is $K$, we further have \n\n$(1 / K) E[ \\| \\epsilon_{\\theta}(\\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon, t) \\|^2 ] \\ge 1 - (r_t / K) $. \n\nFinally, consider the fact [1] that $x_t$ can be reparameterized as $\\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon, \\epsilon \\sim N(0, I) $ and let the prediction error $r_t$ vanish, **the above equation motivates us to make the following new assumption**: \n\n$(1 / K) E[ \\| \\epsilon_{\\theta}(x_t, t) \\|^2 ] \\ge 1$, \n\n**which is much weaker than the previous assumption but still makes our Theorem 3.1 hold**.\n\nWe conduct experiments on 2 datasets to verify our new assumption. For every dataset, we sample $10000$ trajectories $x_{0:T}$ from a well-trained diffusion model. In this process, we collect $10000$ outputs from neural network $\\epsilon_{\\theta}(x_t, t)$ at every step $t$ and use them to estimate $(1 / K) E[ \\| \\epsilon_{\\theta}(x_t, t) \\|^2 ]$. Below are the experiment results.\n\n| Dataset  | t=1000 | t=800 | t=600 | t=400 | t=200 | t=1   |\n|----------|--------|-------|-------|-------|-------|-------|\n| CIFAR-10 | 1.17   | 1.19  | 1.15  | 1.11  | 1.08  | 1.05  |\n| CelebA   | 1.25   | 1.21  | 1.23  | 1.17  | 1.11  | 1.09  |\n\nFrom this table, we can see that **the estimated value of $(1 / K) E[ \\| \\epsilon_{\\theta}(x_t, t) \\|^2 ]$ is consistently larger than $1$ at every backward iteration for both datasets**. Therefore, our new assumption $(1 / K) E[ \\| \\epsilon_{\\theta}(x_t, t) \\|^2 ] \\ge 1$ has firm empirical support.\n\nBecause it is computationally infeasible to estimate the probabilistic density $p_{\\theta}(x_t)$ for discrete-time diffusion models (e.g., DDPM [1]), we find it hard to empirically verify our assumption on the entropy $H_{p_{\\theta}(x_t)}$. However, we believe that assumption is very intuitive because the uncertainty of variable $x_t$ (i.e., entropy) should decrease as the denoising process progresses. For example, if we are sampling from a diffusion model and find that $x_{100}$ seems like a dog, it\u2019s less likely that the final outcome $x_0$ (that is denoised from $x_{100}$) will be a cat.\n\nWe will add the above new assumption, derivation, experiment, and discussion to the revised version."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4099/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699994959017,
                "cdate": 1699994959017,
                "tmdate": 1699997778964,
                "mdate": 1699997778964,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "p3zUJ1GPf3",
                "forum": "RtAct1E2zS",
                "replyto": "trhuJ1LAbT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4099/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4099/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part-2 of Our Response"
                    },
                    "comment": {
                        "value": "### Comment-3: In the proof of Proposition A.1 in Appendix A \u2026 The current proof falls short \u2026 for finite values of T.\n\nAnswer-3: Thanks for pointing out this. We address your concern by **introducing a weaker precondition, which still makes our proposition hold and is also supported by current works [1,2]**.\n\nIn our proof to Proposition A.1, the use of that precondition $T \\rightarrow \\infty$ is to let $q(x_T | x_0) \\rightarrow N(x_T; 0, I)$. Considering the fact that \n\n$q(x_t | x_0) = N(x_t; \\sqrt{\\bar{\\alpha}_t} x_0, \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon)$, \n\nwe can achieve the goal with a much weaker assumption: $\\lim_{t \\rightarrow T} \\bar{\\alpha_t} \\rightarrow 0$. Notably, **this new assumption is a standard configuration in current diffusion models** (e.g., DDPM [1] and SGM [2]), which lets $x_T$ contain no information about $x_0$.\n\n### Comment-4: Several typographical errors in equation (24) in Appendix B \u2026 both the numerator and denominator should be consistent \u2026 \u00a0the first term in the second line of (24)\u00a0\u2026 the third line of (24) appears inconsistent\u00a0 \u2026\n\nAnswer-4: Thanks for pointing out this. The correct forms of the first two lines of our Eq. (24) are\n\n$ E_{x_t \\sim p_{\\theta}(x_{t})} [E_{x_{t-1} \\sim  p_{\\theta}(x_{t-1} \\mid x_{t}) } [\\ln ( \\frac{p_{\\theta}(x_{t-1} \\mid x_{t})} {q(x_{t-1} \\mid x_{t})} \\frac{q(x_{t} \\mid x_{t-1})} {p_{\\theta}(x_{t-1} \\mid x_{t})} ) ] ] = E_{x_t \\sim p_{\\theta}(x_{t})} [E_{x_{t-1} \\sim  p_{\\theta}(x_{t-1} \\mid x_{t}) } [\\ln  \\frac{p_{\\theta}(x_{t-1} \\mid x_{t})} {q(x_{t-1} \\mid x_{t})}  ] ] + E_{x_t } [E_{x_{t-1}} [ \\ln \\frac{q(x_{t} \\mid x_{t-1})} {p_{\\theta}(x_{t-1} \\mid x_{t})} ] ]$.\n\nWe also fix the last line of Eq. (24) as\n\n$E_{x_t \\sim p_{\\theta}(x_{t})} [ D_{KL} (p_{\\theta}(x_{t-1} \\mid x_{t}) || q(x_{t-1} \\mid x_{t})) ] + E_{x_t \\sim p_{\\theta}(x_{t})} [E_{x_{t-1} \\sim  p_{\\theta}(x_{t-1} \\mid x_{t}) } [ \\ln \\frac{q(x_{t} \\mid x_{t-1})} {p_{\\theta}(x_{t-1} \\mid x_{t})} ] ]$.\n\nWe will add the above corrections to the revised version. \n\n### Comment-5: \u2026 clarification on the process for selecting hyper-parameters \u2026 the weight assigned to the regularization term \u2026\n\nAnswer-5: We applied the grid search to hyper-parameter selection. For the weights of regularization terms, we respectively construct candidate sets $[ 0.2, 0.4, 0.6, 0.8 ]$ and $[ 1 \\times 10^{-3}, 3 \\times 10^{-3}, 6 \\times 10^{-3}, 9 \\times 10^{-3} ]$ for $\\lambda^{reg}$ and $\\rho$. As mentioned in Sec. 6.1 of our paper, the experiments turned out that this combination $\\lambda^{reg} = 0.2, \\rho = 3 * 10^{-3}$ performed the best.\n\n### Comment-6: Minor Issues: \u2026 The notation for conditional expectation \u2026 \"get ride of\" should be corrected to \"get rid of\" \u2026 \u00a0rests on the assumption that\u00a0log(1 - x/4)\u00a0is well-defined, which only holds when\u00a0x < 4 \u2026\n\nAnswer-6: Thanks for raising these points. We will accept your suggestions about the notation and the typo in the revised version.\n\nFor your comment \u201cx < 4\u201d, we prove that $D_{t}^{cumu} < 4$ such that $x = D_{t}^{cumu} < 4$. Recall that the definition of $D_{t}^{cumu}$ is as\n\n$|E_{p_{\\theta}(x_{t-1})}[\\phi(x_{t-1})] - E_{q(x_{t-1})}[\\phi(x_{t-1})]|^2$,\n\nwhere $|\\phi| = \\sup_{x} |\\phi(x)| < 1$. According to the Triangle Inequality, we have\n\n$D_{t}^{cumu} \\le (|E_{p_{\\theta}(x_{t-1})}[\\phi(x_{t-1})]|+ |E_{q(x_{t-1})}[\\phi(x_{t-1})]|)^2$,\n\nSince $|x|$ is a convex function, we can apply Jensen's inequality to the above equation:\n\n$D_{t}^{cumu} \\le (E_{p_{\\theta}(x_{t-1})}[|\\phi(x_{t-1})|]+ E_{q(x_{t-1})}[|\\phi(x_{t-1})|])^2 < (E_{p_{\\theta}(x_{t-1})}[1]+ E_{q(x_{t-1})}[1])^2 = (1 + 1)^2 = 4$,\n\nshowing that our claim holds.\n\nBesides the above proof, the experiments in Fig. 2 of our paper also empirically confirmed that $D_{t}^{cumu} < 4$.\n\n## References\n\n[1] Ho et al., Denoising Diffusion Probabilistic Models, NeurlPS-2020.\n\n[2] Song et al, Score-Based Generative Modeling through Stochastic Differential Equations, ICLR-2021."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4099/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699995305039,
                "cdate": 1699995305039,
                "tmdate": 1700237238233,
                "mdate": 1700237238233,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JXIGKLfz6e",
                "forum": "RtAct1E2zS",
                "replyto": "trhuJ1LAbT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4099/Reviewer_ebh3"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4099/Reviewer_ebh3"
                ],
                "content": {
                    "comment": {
                        "value": "The authors have addressed my concerns and I will keep my rating as before."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4099/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700523837270,
                "cdate": 1700523837270,
                "tmdate": 1700523837270,
                "mdate": 1700523837270,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Ts6C7fokxK",
            "forum": "RtAct1E2zS",
            "replyto": "RtAct1E2zS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4099/Reviewer_hknr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4099/Reviewer_hknr"
            ],
            "content": {
                "summary": {
                    "value": "This paper analyses the error propagation/accumulation in DMs across iterations. The authors prove and empirically verify that the error in DMs cumulatively increases. To minimize this cumulative error as regularization, the authors prove tractable estimates which tightly bound this error, which is then used as a proxy. The authors empirically show the proposed method reduces the cumulative error, and increases generation quality across multiple datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The theoretical framework and the bounds on error propagation through DMs are useful for analyzing robustness of DMs.\n1. The proposed method results in strong significant improvements across a range of datasets.\n1. The proposed method successfully decreases cumulative error in DMs"
                },
                "weaknesses": {
                    "value": "1. The proposed method requires significant compute overhead, so gains need to be weighed against this increase in compute."
                },
                "questions": {
                    "value": "1. Contemporaneous work[1] (released after submission deadline) also analyses the sensitivity of DMs to error propagation, and aims to bound this error by scaling the long skip-connections. While the method in [1] is sufficiently different to the proposed method, could the authors comments on this? It would appear that [1] also bounds the error, without the computational overhead.\n2. The proposed method has significant computational overhead (Figure 4). How does the comparisons to  baselines (Table 1) change at equal wall-clock time?\n\n\n\n[1] https://arxiv.org/abs/2310.13545"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4099/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4099/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4099/Reviewer_hknr"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4099/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698767736081,
            "cdate": 1698767736081,
            "tmdate": 1700823549167,
            "mdate": 1700823549167,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AcicMtF26f",
                "forum": "RtAct1E2zS",
                "replyto": "Ts6C7fokxK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4099/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4099/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer hknr,\n\nWe thank you for your kind and constructive feedback.\n\n### Comment-1: Contemporaneous work[1] (released after submission deadline) also analyses the sensitivity of DMs to error propagation \u2026 could the authors comments on this? \u2026\n\nAnswer-1: Thanks for pointing out this interesting paper. The paper studied how the coefficient scales of skip connections affect the training stability of U-Net and introduced two new scaling schemes (one is predefined scales and the other is learnable ones) to better model the skip connections. For the experiment, the paper showed that their proposed methods stabilized and accelerated the training of U-Net.\n\nYour mentioned paper differs from our work in the following 3 points:\n1) In terms of **research topic**, the paper focused on the training stability of U-Net (which is inside the denoising model $\\epsilon_{\\theta}$), while our work concentrates on the error accumulation of the backward process (which is outside the model);\n2) In terms of **method**, the paper proposed to better scale the skip connections of U-Net (which makes its training more stable and faster), while our work introduces a regularization loss to reduce the error propagation of the backward process (which improves the generation quality);\n3) In terms of **theory**, the paper developed theorems that estimated the feature norms and gradient magnitudes of U-Net (which is inside the model $\\epsilon_{\\theta}$), while our work builds a theoretical framework to analyze the error propagation of backward process (which is inside the model).\n\nFor your comment \u201c[1] also bounds the error\u201d, note that **the error defined in that paper (i.e., the sensitivity of U-Net w.r.t. the input perturbation) is different from our defined errors** (i.e., the denoising error and its accumulation along the backward process). Regarding your concern about the computational overhead, our model indeed has a higher time cost for training, but the generation quality of diffusion models is also improved accordingly.\n\nWe will cite your mentioned paper and include the above discussion in the revised version.\n\n### Comment-2: \u2026 gains need to be weighed against this increase in compute. The proposed method has significant computational overhead (Figure 4). How does the comparisons to baselines (Table 1) change at equal wall-clock time?\n\nAnswer-2: Thanks for raising this point. A reminder is that **the y-axis in Fig. 4 of our paper actually represents the time cost of $200$ training steps**, rather than just $1$ step. We apologize if this mistake has misled you to the impression that our method is very inefficient.\n\nAs you suggested, **we have compared our model with the two most efficient baselines** (i.e., DDPM and DDIM) on CIFAR-10 with the same training time. For Consistent DM and FP-Diffusion, our model performs better than them and has a lower time cost per training step. The experiment results of FID scores and time costs are as follows.\n\n| Model                  | Training Steps | Total Training Time | FID Score |\n|------------------------|----------------|---------------------|-----------|\n| DDPM                   | 200K           | 10hrs               | 3.61      |\n| ADM-IP                 | 190K           | 10hrs               | 3.29      |\n| **DDPM w/ Our Method** | **98K**            | **10hrs**               | **3.16**      |\n| DDPM w/ Our Method     | 200K           | 20hrs               | 2.93      |\n\nFrom the above table, we can see that **our proposed method still outperforms the baselines with the same amount of training time**. For example, our method reduces the FID score of DDPM on CIFAR-10 by 12.47%, using no more than half of its training steps. Besides, while leading to a higher time cost per training step, **our method has no impact on the inference speed of diffusion models, which is more important in practical applications**."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4099/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699994034713,
                "cdate": 1699994034713,
                "tmdate": 1699994637403,
                "mdate": 1699994637403,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IrKzpq7Uh5",
                "forum": "RtAct1E2zS",
                "replyto": "1QLryMpgpp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4099/Reviewer_hknr"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4099/Reviewer_hknr"
                ],
                "content": {
                    "title": {
                        "value": "Regarding gaussian distribution of gradients"
                    },
                    "comment": {
                        "value": "Perhaps the authors could simply measure the gradients, and compare its histogram's R2 to the best fit gaussian?\nThat may provide an alternative path to using the gaussian assumption."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4099/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700676676023,
                "cdate": 1700676676023,
                "tmdate": 1700676676023,
                "mdate": 1700676676023,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1QLryMpgpp",
            "forum": "RtAct1E2zS",
            "replyto": "RtAct1E2zS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4099/Reviewer_e2Ed"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4099/Reviewer_e2Ed"
            ],
            "content": {
                "summary": {
                    "value": "This work analyze the error propagation of diffusion models by introducing the modular error (KL divergence between the reverse conditional distribution at each step), the cumulative error (KL divergence between the marginal distribution at each step). And then introduce an regularization loss based on MMD estimation for the cumulative loss to reduce the cumulative error and improve the sample quality of the trained diffusion model."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The proposed method is easy to understand and the writing is clean and easy to follow.\n- The error propagation of diffusion models is an important question and worth to be studied. The topic is important."
                },
                "weaknesses": {
                    "value": "Major:\n\n- The assumption in the core theorem is absolutely wrong.\n  - \"suppose that the output of neural network $\\epsilon_\\theta$ follows a standard Gaussian\", which cannot be true. Because the noise-pred model corresponds to the denoising score matching loss, it is proved that the ground truth of such model is propotional to the score function of the distribution, i.e., $\\nabla_{x_t} \\log q_t(x_t)$. For a small $t$, such score function is quite complex and cannot be a simple and single-mode Gaussian distribution, and is far different.\n- Remark 3.2 is not rigorous. The proof requires $T$ goes to infty, but it is not true in practice.\n- Lack of detailed settings of experiments: what is the sampling algorithm for obtaining the FID results? What is the detailed network structure (e.g., layer structure and number of hidden neurons) and amount of parameters?"
                },
                "questions": {
                    "value": "1. Please address and fix the proof of the main theorem.\n\n2. Please add more detailed descriptions of the experiment settings to ensure reproducibility.\n\n=====================\n\nI've carefully read the authors' responses to other reviewers and AC. I deeply appreciate the authors' efforts to address the concerns, and now I don't have more questions. I think it is a quite interesting and useful technique for improving the training procedure of diffusion models, with the validation of the fine-tuning experiment results and the EDM results. So I raise the score to 6."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4099/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4099/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4099/Reviewer_e2Ed"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4099/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698779850809,
            "cdate": 1698779850809,
            "tmdate": 1700666866107,
            "mdate": 1700666866107,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MLX9nMWd4n",
                "forum": "RtAct1E2zS",
                "replyto": "1QLryMpgpp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4099/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4099/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part-1 of Our Response"
                    },
                    "comment": {
                        "value": "Dear Reviewer e2Ed,\n\nThanks for your review and the constructive feedback.\n\nIn the following, we have answered all your concerns in a point-by-point manner. Importantly, **to address your concern about the two preconditions of our theorems, we introduce alternative assumptions that are much weaker but still make the theorems hold**. Our new assumptions are also very solid because we derive them from a theoretical angle and find support from either empirical experiments or existing works [1,2].\n\n### Comment-1: \u2026 \u201csuppose that the output of neural network\u00a0$\\epsilon_{\\theta}$ follows a standard Gaussian\", which cannot be true. Because the noise-pred model corresponds to the denoising score matching \u2026\n\nAnswer-1: Thanks for raising this point. In this answer, **we first explain the role of your mentioned assumption in Theorem 3.1 and then replace it with a much weaker assumption**, which is derived from a theoretical perspective and still makes the theorem hold. **Lastly, we perform experiments to show that our new assumption is indeed valid in practice**.\n\nSince neural network $\\epsilon_{\\theta}(x_t, t)$ is tasked to fit Gaussian noise $\\epsilon$ in the loss function $L^{nll}$, we previously assumed that the output distribution of $\\epsilon_{\\theta}(x_t, t)$ follows a standard Gaussian. In our proof to Theorem 3.1, **that assumption is applied to indicate that $E[\\| \\epsilon_{\\theta}(x_t, t) \\|^2] = K$** ($K$ is the vector dimension). However, considering Eq. (27) and Eq. (28) in the proof, **our theorem still holds for $E[\\| \\epsilon_{\\theta}(x_t, t) \\|^2] \\ge K$**.\n\nTo derive a new assumption, we first set a term \n\n$r_t = E[ \\| \\epsilon - \\epsilon_{\\theta}(\\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon, t) \\|^2 ]$, \n\nwhich indicates the prediction error of neural network $\\epsilon_{\\theta}(x_t, t)$. The term will vanish to $0$ if $\\epsilon_{\\theta}(x_t, t)$ is fully accurate in backward denoising. According to the Triangle Inequality, we then have \n\n$r_t \\ge E[ \\| \\epsilon \\|^2 - \\| \\epsilon_{\\theta}(\\cdot) \\|^2  ] = E [\\| \\epsilon \\|^2] - E[ \\| \\epsilon_{\\theta}(\\cdot) \\|^2 ] $. \n\nBecause the second moment of Gaussian distribution $E[\\| \\epsilon \\|^2]$ is $K$, we further have \n\n$(1 / K) E[ \\| \\epsilon_{\\theta}(\\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon, t) \\|^2 ] \\ge 1 - (r_t / K) $. \n\nFinally, consider the fact [1] that $x_t$ can be reparameterized as $\\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon, \\epsilon \\sim N(0, I) $ and let the prediction error $r_t$ vanish, **the above equation motivates us to make the following new assumption**: \n\n$(1 / K) E[ \\| \\epsilon_{\\theta}(x_t, t) \\|^2 ] \\ge 1$, \n\n**which is much weaker than the previous assumption but still makes our Theorem 3.1 hold**.\n\nWe perform experiments on 2 datasets to verify our new assumption. For every dataset, we sample $10000$ trajectories $x_{0:T}$ from a well-trained diffusion model. In this process, we collect $10000$ outputs from neural network $\\epsilon_{\\theta}(x_t, t)$ at every step $t$ and use them to estimate $(1 / K) E[ \\| \\epsilon_{\\theta}(x_t, t) \\|^2 ]$. Below are the experiment results.\n\n| Dataset | t=1000 | t=800 | t=600 | t=400 | t=200 | t=1   |\n|---------|--------|-------|-------|-------|-------|-------|\n| CIFAR-10 | 1.17   | 1.19  | 1.15  | 1.11  | 1.08  | 1.05  |\n| CelebA  | 1.25   | 1.21  | 1.23  | 1.17  | 1.11  | 1.09  |\n\nFrom the above table, we can see that **the estimated value of $(1 / K) E[ \\| \\epsilon_{\\theta}(x_t, t) \\|^2 ]$ is consistently larger than $1$ at every backward iteration for both datasets**. Therefore, our new assumption $(1 / K) E[ \\| \\epsilon_{\\theta}(x_t, t) \\|^2 ] \\ge 1$ has strong empirical support."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4099/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699993491690,
                "cdate": 1699993491690,
                "tmdate": 1699998617095,
                "mdate": 1699998617095,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8dTd9LqWjZ",
                "forum": "RtAct1E2zS",
                "replyto": "1QLryMpgpp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4099/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4099/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part-2 of Our Response"
                    },
                    "comment": {
                        "value": "### Comment-2: Remark 3.2 is not rigorous. The proof requires\u00a0$T$ goes to infty, but it is not true in practice.\n\nAnswer-2: Thanks for pointing out this. We address your concern by **introducing an alternative precondition that is weaker than the previous one but still makes our proposition hold**. Importantly, our new precondition is supported by current works [1,2].\n\n In our proof to Proposition A.1, the use of that precondition $T \\rightarrow \\infty$ is to let $q(x_T | x_0) \\rightarrow N(x_T; 0, I)$. Considering the fact [1] that \n\n$q(x_t | x_0) = N(x_t; \\sqrt{\\bar{\\alpha}_t} x_0, \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon)$, \n\n**we can achieve the goal with a much weaker assumption: $\\lim_{t \\rightarrow T} \\bar{\\alpha_t} \\rightarrow 0$**. Notably, **this new assumption is a standard configuration in current diffusion models** (e.g., DDPM [1] and SGM [2]), which lets $x_T$ contain no information about $x_0$.\n\n### Comment-3: Lack of detailed settings of experiments: what is the sampling algorithm for obtaining the FID results? What is the detailed network structure (e.g., layer structure and number of hidden neurons) and amount of parameters?\n\nAnswer-3: For computing the FID scores, we adopt the same sampling procedure as DDPM (see Algo. 2 of [1]) and generate $50000$ samples with $1000$ backward iterations. For the network structure, we typically use U-Net with $4$ layers, $192$ channels, and channel multipliers as $\\\\{1,2,3,4\\\\}$, leading to a model size of 300M. We use Adam as the optimization algorithm with a learning rate of $10^{-4}$ and set the dropout ratio as $0.2$. \n\nSec. 6.1 of our paper has some other details of the experiment setup. We will merge this answer into that section in the revised version.\n\n## References\n\n[1] Ho et al., Denoising Diffusion Probabilistic Models, NeurlPS-2020.\n\n[2] Song et al, Score-Based Generative Modeling through Stochastic Differential Equations, ICLR-2021."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4099/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699993757508,
                "cdate": 1699993757508,
                "tmdate": 1699993820649,
                "mdate": 1699993820649,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nSpKRzgZIV",
                "forum": "RtAct1E2zS",
                "replyto": "1QLryMpgpp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4099/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4099/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer e2Ed,\n\nWe thank you for your time in reviewing our paper. With only 2 days left, we would like to know whether our previous response has addressed your concerns. Looking forward to your feedback!\n\nBest regards,\n\nThe Authors"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4099/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700495341835,
                "cdate": 1700495341835,
                "tmdate": 1700495341835,
                "mdate": 1700495341835,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NjXyBm9pcO",
                "forum": "RtAct1E2zS",
                "replyto": "nSpKRzgZIV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4099/Reviewer_e2Ed"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4099/Reviewer_e2Ed"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the rebuttal!"
                    },
                    "comment": {
                        "value": "I've carefully read the authors' responses to other reviewers and AC. I deeply appreciate the authors' efforts to address the concerns, and now I don't have more questions. I think it is a quite interesting and useful technique for improving the training procedure of diffusion models, with the validation of the fine-tuning experiment results and the EDM results. So I raise the score to 6."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4099/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700667205266,
                "cdate": 1700667205266,
                "tmdate": 1700667205266,
                "mdate": 1700667205266,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XXeaoySM8b",
                "forum": "RtAct1E2zS",
                "replyto": "1QLryMpgpp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4099/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4099/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you, and thanks for your constructive review!"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4099/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700668809132,
                "cdate": 1700668809132,
                "tmdate": 1700668922370,
                "mdate": 1700668922370,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZODaO4t25T",
            "forum": "RtAct1E2zS",
            "replyto": "RtAct1E2zS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4099/Reviewer_MiNJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4099/Reviewer_MiNJ"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors investigate error propagation in diffusion models. They develop a framework to define error propagation for diffusion and connect error propagation to generation quality. This enables them to use the measured error as a regularization term during the diffusion model training, improving the generation results of models in small-scale experiments."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The proposed method is a novel approach to measuring error propagation in diffusion models and offers a new perspective on diffusion model training. The authors argue that apart from making the denoiser network more accurate, which has been the main focus of the literature so far, it is also important to regularize such that the denoiser is also robust to errors in the input during inference. This could have significant impacts on the broader diffusion generative model community.\n\n- The presented methodology is principled and well-explained. The experiments clearly demonstrate the success of the proposed solution in mitigating error propagation in diffusion models."
                },
                "weaknesses": {
                    "value": "- The authors briefly address the trade-off between increased training time and reduced error propagation (resulting in better FID) for the 32x32 images of CIFAR and ImageNet but do not mention their CelebA experiments on 64x64 images. It is not clear if the benefits scale with the image sizes without an increased overhead as it is possible that the error estimate requires more samples or a larger sampling length $L$."
                },
                "questions": {
                    "value": "- Would it be possible to fine-tune pre-trained diffusion models with the regularization term to mitigate this error propagation a-posteriori? If the training time of adding the regularization makes training larger models prohibitive it would be interesting to explore whether it is possible to tune the denoiser network after having trained with just the $L^{nll}$ loss."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4099/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4099/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4099/Reviewer_MiNJ"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4099/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698857926809,
            "cdate": 1698857926809,
            "tmdate": 1699636374663,
            "mdate": 1699636374663,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lRIXhW87hB",
                "forum": "RtAct1E2zS",
                "replyto": "ZODaO4t25T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4099/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4099/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer MiNJ,\n\nThank you for your kind and constructive comments. In particular, the idea of fine-tuning a trained diffusion model with our proposed regularization is very interesting and useful, which can potentially reduce the training time of our model. We have conducted experiments to show that your idea indeed works in practice.\n\n### Comment-1: \u2026 do not mention their CelebA experiments on 64x64 images \u2026 It is not clear if the benefits scale with the image sizes without an increased overhead \u2026\n\nAnswer-1: Thanks for pointing out this. As a reminder, **the y-axis in Fig. 4 of our paper in fact represents the time cost of $200$ training steps** (not just $1$ step). We apologize if this mistake might mislead you to the impression that our method is very inefficient.\n\nTo address your concern, we have performed an additional trade-off study (showing how the FID score and the time cost change w.r.t. increasing bootstrapping steps $L$) on CelebA. The results are in the following:\n\n| Bootstrapping Steps $L$ | 2      | 3      | 4      | 5      | 6      | 7      | 8      |\n|-------------------------|--------|--------|--------|--------|--------|--------|--------|\n| FID Score                  | 1.51   | 1.39   | 1.29   | 1.22   | 1.18   | 1.16   | 1.15   |\n| **Decrement of FID Score**  | N.A.   | 0.12   | 0.10   | 0.07   | 0.04   | 0.02   | 0.01   |\n| Time Cost Per Training Step | 0.37s | 0.45s | 0.55s | 0.63s | 0.72s | 0.81s | 0.92s |\n\nFrom the above table, we can see the FID scores tend to converge after $L=7$, which is similar to the situations of CIFAR-10 and ImageNet. **The results imply that the performance improvements contributed by our proposed regularization scales with the image size**. Importantly, while our method incurs an extra time cost per training step, it has no impact on the sampling speed of diffusion models, which is more important in practice.\n\n### Comment-2: Would it be possible to fine-tune pre-trained diffusion models with the regularization term \u2026 it would be interesting to explore whether it is possible to tune the denoiser network \u2026\n\nAnswer-2: Thanks for providing such an interesting idea. To verify the feasibility of your idea, we have trained a diffusion model on CIFAR-10 in a way that **only the last 10% training steps involve our proposed regularization**. The results are as below.\n\n| Model                   | All Training Steps | Steps with Regularization | Training Time | FID Score |\n|-------------------------|---------------------------|---------------------------|----------------|-----------|\n| DDPM                    | 200K |0                         | 10hr           | 3.61      |\n| **DDPM w/ Our Proposed Reg.** | **200K** | **20K**                     | **11hr**          | **3.21**      |\n| DDPM w/ Our Proposed Reg.      | 200K |200K                      | 20hr           | 2.93      |\n\n\nFrom the above table, we can see that the diffusion model is still improved much (i.e., a reduction of the FID score by 11.08%) by partly applying our method, with a minor increase in training time. Therefore, **your idea indeed works empirically and is very useful in improving the efficiency of our proposed regularization**. \n\nWe will include the above experiment and discussion in the revised version."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4099/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699994523511,
                "cdate": 1699994523511,
                "tmdate": 1699997671129,
                "mdate": 1699997671129,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BzTJQgk4UP",
                "forum": "RtAct1E2zS",
                "replyto": "lRIXhW87hB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4099/Reviewer_MiNJ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4099/Reviewer_MiNJ"
                ],
                "content": {
                    "comment": {
                        "value": "I would like to thank the authors for taking the time to address my comments. I would strongly encourage you to include the fine-tuning results in the main text as it significantly helps with the presentation of the method. Given that my score is already high, I will be maintaining my rating."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4099/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700499342096,
                "cdate": 1700499342096,
                "tmdate": 1700499342096,
                "mdate": 1700499342096,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]