[
    {
        "title": "Mini-batch Submodular Maximization"
    },
    {
        "review": {
            "id": "2r3icsMOor",
            "forum": "TGaFO0YglG",
            "replyto": "TGaFO0YglG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission786/Reviewer_qFjC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission786/Reviewer_qFjC"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies maximizing a submodular function F that is decomposable into N submodular functions. It provides a method to sample a subset of these N functions and form a weighted sum to approximate F. They show that with enough samples, they can get the optimal guarantees of the Greedy algorithm for cardinality constraint and also p-systems. Their algorithm becomes better than the naive approach if N is larger than n times k where n is the number of items in the ground set and k is the cardinality constraint."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "They provide a sampling method to approximate decomposable function F with a weighted sum of its member functions such that the number of terms is independent of N. Here N is the number of submodular functions contributing to F. The number of terms depend polynomially on the size of the ground set."
                },
                "weaknesses": {
                    "value": "Their algorithm becomes better than the naive approach if N is larger than n times k where n is the number of items in the ground set and k is the cardinality constraint. \n\nQuestion to authors: Could you provide a practical example that N is substantially larger than n times k to motivate your algorithms?\n\nApproximation of function F:\nIn line 6 of algorithm 2, you look for an approximate version of the function F_{S_j}. The description of how you use 3 to achieve that is not completely clear. But the likeliest interpretation that comes to mind is the following. You call algorithm 3 with function F initialized as F_{S_j} in the j\u2019th iteration of the Greedy algorithm. This requires O(Nn) oracle calls because of line 1 of Alg 3 every time you call Alg 3. Since you need k approximate functions for the k iterations of the greedy algorithm, overall you have O(Nnk) oracle calls which makes the whole motivation point of your paper irrelevant.\n\nThe statement of Lemma 8 suggests that you had the above interpretation in mind (\\hat{F} sampled after S is fixed).\n\nIf you had another way of calling Alg 3 in mind, you should completely rewrite the presentation of Alg 3 and its description. For instance, if you want to call Alg-3 k times but want to perform its first line only once, you need to separate that as a preprocessing step in another pseudo code and explicitly explain it. It sounds counterintuitive to have the same probably vector <p_1, \u2026, p_N> and do the sampling (lines 3-6 of Alg 3) k separate times. Even if you want to do that, it takes O(N) to find this approximate function. I note that O(N) is not mentioned in the (non-preprocessing) runtime of your algorithm because you only count the number of oracle calls. Nevertheless you pay the O(N) in runtime and you should mention it. \n\nThere is a third interpretation which is calling Alg 3 only once and using the same approximate function in all k iterations of greedy. I strongly recommend correcting the presentation to reflect this ambiguity. \n\nRelated work:\nThe problem of submodular maximization in the case of multiple underlying submodular functions has been studied previously in the context of probabilistic submodular maximization or two stage submodular maximization. \nProbabilistic Submodular Maximization in Sub-Linear Time, Stan et al. ICML 2017\nLearning Sparse Combinatorial Representations via Two-stage Submodular Maximization\nEric Balkanski et al. ICML 2016.\n\nIn this setting, the submodular function we want to optimize is sampled from a distribution (e.g. each user has a submodular valuation function and a user is drawn from the distribution). Their approach is to compute a compact subset of items in the ground set and study the compression and approximation errors separately. These methods are not necessarily directly applicable to your setting but doing a more thorough compare and contrast seems necessary. In particular, their results are constant approximations strictly below the 1-1/e target approximation in your paper. I should mention that this connection is different from the relevance of your work to Mini-batch methods you reviewed in the related work section.\n\nTypos:\n1. The equation after theorem 1: \\hat{F}^j_{S_j} \u2192 \\hat{F}^j_{S_j}(e)\n2. Last inequality in page 4: The lower bound on F(S_{k+1}) should have the extra error term, gamma epsilon\u2019 F(S^*) as a deductive term not addition. The current form is a stronger guarantee even though we have the additive error term. I believe it should be:\nF(S_{k+1}) \\geq F(S^*)\\beta - \\gamma \\epsilon\u2019 F(S^*) \n3. Page 5, Mini-batch setting paragraph: \u2026 its is \u2026 \u2192 it is"
                },
                "questions": {
                    "value": "Their algorithm becomes better than the naive approach if N is larger than n times k where n is the number of items in the ground set and k is the cardinality constraint. \n\nQuestion to authors: Could you provide a practical example that N is substantially larger than n times k to motivate your algorithms?\n\nApproximation of function F:\nIn line 6 of algorithm 2, you look for an approximate version of the function F_{S_j}. The description of how you use 3 to achieve that is not completely clear. But the likeliest interpretation that comes to mind is the following. You call algorithm 3 with function F initialized as F_{S_j} in the j\u2019th iteration of the Greedy algorithm. This requires O(Nn) oracle calls because of line 1 of Alg 3 every time you call Alg 3. Since you need k approximate functions for the k iterations of the greedy algorithm, overall you have O(Nnk) oracle calls which makes the whole motivation point of your paper irrelevant.\n\nThe statement of Lemma 8 suggests that you had the above interpretation in mind (\\hat{F} sampled after S is fixed).\n\nIf you had another way of calling Alg 3 in mind, you should completely rewrite the presentation of Alg 3 and its description. For instance, if you want to call Alg-3 k times but want to perform its first line only once, you need to separate that as a preprocessing step in another pseudo code and explicitly explain it. It sounds counterintuitive to have the same probably vector <p_1, \u2026, p_N> and do the sampling (lines 3-6 of Alg 3) k separate times. Even if you want to do that, it takes O(N) to find this approximate function. I note that O(N) is not mentioned in the (non-preprocessing) runtime of your algorithm because you only count the number of oracle calls. Nevertheless you pay the O(N) in runtime and you should mention it. \n\nThere is a third interpretation which is calling Alg 3 only once and using the same approximate function in all k iterations of greedy. I strongly recommend correcting the presentation to reflect this ambiguity. \n\nQuestion: which of the above interpretations did you have in mind?\n\nTypos:\n1. The equation after theorem 1: \\hat{F}^j_{S_j} \u2192 \\hat{F}^j_{S_j}(e)\n2. Last inequality in page 4: The lower bound on F(S_{k+1}) should have the extra error term, gamma epsilon\u2019 F(S^*) as a deductive term not addition. The current form is a stronger guarantee even though we have the additive error term. I believe it should be:\nF(S_{k+1}) \\geq F(S^*)\\beta - \\gamma \\epsilon\u2019 F(S^*) \n3. Page 5, Mini-batch setting paragraph: \u2026 its is \u2026 \u2192 it is"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission786/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission786/Reviewer_qFjC",
                        "ICLR.cc/2024/Conference/Submission786/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission786/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698265575252,
            "cdate": 1698265575252,
            "tmdate": 1700065148167,
            "mdate": 1700065148167,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Z6CDn7Afvx",
                "forum": "TGaFO0YglG",
                "replyto": "2r3icsMOor",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission786/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for carefully reading our paper and for the constructive feedback! Please allow us to address your main concerns here first, and implement them in a revision later.\n\n> Could you provide a practical example that N is substantially larger than n times k to motivate your algorithms?\n\nIndeed, we did not provide proper motivation for our work. Thank you for pointing this out.\n\nAs noted by Rafiey and Yoshida the most natural example is welfare maximization. We provide an intuitive explanation below:\n\nImagine you are tasked with deciding on a meal menu for a large group of N people (e.g., all students in a university, all high school students in a country). You need to choose k ingredients to use from a predetermined set (chicken, fish, beef, etc...) of size n. Every student has a specific preference, modeled as a monotone submodular function $F_i$. Our goal is to maximize the welfare of all students: $\\sum_i^N F_i$. Note that in this case, N is much larger than n times k.\n\nThe standard algorithm will require asking every student k questions. That is, you would start by asking all students: \"Rate how much you would like to see food X on the menu\" for n possible options. You would then need to wait for all of their replies, and continue with \"Given that chicken is on the menu, rate how much you would like to see food X on the menu\" for n-1 possible options and so on. Even if you do an online poll, this is still very time-consuming (as you will need to wait for everyone to reply in every step, repeating for k steps). \n\nUsing the sparsifier approach of Rafiey and Yoshida the preprocessing step is not practical as it will require asking every student poly(N) questions. Furthermore, the dependence on B means that you might end up having to poll all of the students anyway.\n\nOn the other hand, our approach only requires every student to answer how much he likes any specific food (chicken, beef, fish, etc...). Then for k steps, we poll a much smaller set of students asking them which food they would like to see added to the menu. \n\nA few more points:\n- In this example, it is also clear that the computation time (deciding on the subset of students to poll at every step) is negligible compared to the query time (asking for their opinion and waiting for them to answer).  \n\n- If there is a set of constraints, and they suddenly change, we do not need to perform the preprocessing step again. \n\n- While this might seem like a toy example, welfare maximization is an extremely important and useful problem. It is easy to see that the above translates to much more important scenarios, like allocating public resources (e.g., including medical treatments in a medical insurance program, designing a curriculum of classes in a school, etc...). A more CS-oriented example might be adding features to an online service such as to maximize user utility.\n\n> Approximation of function F:\n\nIndeed, what we meant was that line 1 of Alg 3 is called only once as a preprocessing step and then Algorithm 3 is called in every iteration of Alg 2 to get an approximate version of the function $F_{S_j}$. You are correct in noting that the running time of Alg 3 is $O(N)$. So the total running time of the algorithm (not oracle calls) depends on N. It is standard in the literature to take oracle calls as the main complexity measure of the algorithm. But we completely understand your point. We will add this point to our paper and clarify the presentation."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699760548216,
                "cdate": 1699760548216,
                "tmdate": 1699760548216,
                "mdate": 1699760548216,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8Bw2KdbCc8",
                "forum": "TGaFO0YglG",
                "replyto": "Z6CDn7Afvx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission786/Reviewer_qFjC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission786/Reviewer_qFjC"
                ],
                "content": {
                    "title": {
                        "value": "Example provided to support the motivation of the setting"
                    },
                    "comment": {
                        "value": "The example provided in the rebuttal helps a bit the case that the number of users is much larger than other input factors. In light of that I am changing my score from reject to weak reject. I still don't think this paper qualifies to be accepted in ICLR."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700065268973,
                "cdate": 1700065268973,
                "tmdate": 1700065268973,
                "mdate": 1700065268973,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "cewItRWyCM",
            "forum": "TGaFO0YglG",
            "replyto": "TGaFO0YglG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission786/Reviewer_ev1Q"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission786/Reviewer_ev1Q"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a mini-batch algorithm for maximizing a non-negative decomposable submodular function under a set of constraints. The algorithm reduces the number of oracle evaluations compared to previous methods and achieves good approximation guarantees. The paper provides a proof for the algorithm's effectiveness and compares it to other algorithms. The algorithm is shown to be effective for cardinality and p-system constraints. Overall, the paper contributes a new algorithm that efficiently optimizes submodular functions with good approximation guarantees."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper introduces a mini-batch algorithm that maximizes non-negative decomposable submodular functions under constraints, which reduces the number of oracle evaluations in some cases. The methodology is sound and the results are well-supported. Furthermore, the paper underscores the potential for applying the mini-batch approach to other constraints and functions beyond submodularity, indicating its broader applicability."
                },
                "weaknesses": {
                    "value": "1.\tThe paper posits that the time complexity of the na\u00efve greedy algorithm is dependent on N, which leads to high time complexity when N is large. The motivation behind their algorithm is to eliminate this dependence on N. It would be beneficial for the authors to provide a substantial number of examples demonstrating scenarios in real life where N is exceptionally large. This would strengthen their motivation, especially considering that there are few published papers with a similar motivation, indicating that such a motivation has not yet been widely accepted.\n2.\tThe results obtained by the paper under the unbounded curvature case do not seem to significantly improve upon the results of Rafiey & Yoshida (2022). The superiority or inferiority between the two depends on the values of B, n, p, and k.\n3.\tThe paper lacks experiments to validate the performance of the proposed algorithm. It would be advantageous for the authors to include empirical evidence supporting their theoretical claims.\n4.\tThe organization of the paper appears to be chaotic, giving an impression of an unprepared manuscript rather than a ready-to-publish paper."
                },
                "questions": {
                    "value": "Please refer to weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission786/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission786/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission786/Reviewer_ev1Q"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission786/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698483755448,
            "cdate": 1698483755448,
            "tmdate": 1699636006068,
            "mdate": 1699636006068,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3KOr44WdZq",
                "forum": "TGaFO0YglG",
                "replyto": "cewItRWyCM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission786/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for taking the time to read our paper! Please allow us to address your main concerns here first, and implement them in a revision later.\n\n1) Please refer to our reply to Reviewer qFjC.\n\n2) Our main contribution is removing the dependence on B. In doing so we improve the worst case query complexity from exponential to polynomial in n. Indeed when k or p are very large and B is constant our results do not improve over Rafiey & Yoshida. However, it is often the case that $k,p \\ll n$ (e.g, for submodular maximum matching on dense graphs $n = |V|^2, p=2, k=|V|$), and it is not clear why B should be small in general.\n\n3) We believed that a theoretical result presenting an exponential improvement in query complexity was sufficient. Clearly, we were mistaken. May we ask the reviewer what would be a good experimental setup for our case? Specifically, which dataset would you suggest, and how would you compare the query complexity between a mini-batch algorithm and a sparsifier? \n\n4) We would be more than happy to improve the readability of our paper! May we ask for concrete issues that we can improve upon?"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699760862165,
                "cdate": 1699760862165,
                "tmdate": 1699760862165,
                "mdate": 1699760862165,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iwvbfQYLB8",
                "forum": "TGaFO0YglG",
                "replyto": "3KOr44WdZq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission786/Reviewer_ev1Q"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission786/Reviewer_ev1Q"
                ],
                "content": {
                    "comment": {
                        "value": "I would suggest that the authors provide a more detailed discussion on the contributions of this paper to the machine learning community, including some specific application examples and experimental results. This is particularly important considering that the paper addresses non-traditional submodular maximization problems, which may not be well-known in the machine learning community. Additionally, I would recommend that the authors dedicate a section specifically to formally defining the problem studied in the paper and introducing other relevant symbols. \n\nThese are just some friendly suggestions from my personal perspective."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700104889739,
                "cdate": 1700104889739,
                "tmdate": 1700104889739,
                "mdate": 1700104889739,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "4RoxoRKVZL",
            "forum": "TGaFO0YglG",
            "replyto": "TGaFO0YglG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission786/Reviewer_dUP7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission786/Reviewer_dUP7"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the problem of maximizing a decomposable monotone submodular function $F$ over a ground set of size $n$. By decomposable it means that $F=\\sum_{i=1}^N f_i$, where each $f_i$ is monotone submodular and can be accessed via a value oracle. The paper presents fast algorithms for the problem under the cardinality constraint and the $p$-system constraint. More specifically, for the cardinality constraint, a na\u00efve greedy algorithm needs $O(Nnk)$ queries, where $k$ denotes the constraint parameter. In contrast, the paper presents an algorithm using $O(Nn+k^3n^2/\\epsilon^2)$ queries up to a logarithmic term. Furthermore, when the function has a bounded curvature, the algorithm uses $O(Nn+kn^2/\\epsilon^2)$ queries up to a logarithmic term. This improves over two previous results. For the $p$-system constraint, a similar improvement can be obtained."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThe basic idea for solving the problem is to construct a sparsifier of $F$ which approximates $F$ at all subsets. The paper observes that one can construct a sparsifier which only approximates the marginal values of each single element during the execution of the greedy algorithm. The observation is clever and general. I believe it can be applied for more general functions and various constraints.\n2.\tThe algorithm and analysis are presented in a transparent and readable way."
                },
                "weaknesses": {
                    "value": "1.\tThe motivation of the paper is problematic. Since the problem itself is a traditional combinatorial optimization problem, it is strange to consider the preprocessing part. In my understanding, the preprocessing part is meaningful if we consider one decomposable submodular function under a large number of different constraints, since the preprocessing part is not related to the constraint. But I am not sure about the motivation of this kind of setting. Besides, even in the case where the preprocessing part is necessary, the proposed algorithm is superior to the na\u00efve $O(Nnk)$ algorithm only when $N$ is large. However, since the Nn term looks inevitable, I suspect that for large $N$, the proposed algorithm is still too slow in practice. Unluckily, the authors do not explain more about this. Specifically, the authors do not suggest any applications where $N$ is in fact large and the paper lacks experiments to demonstrate the advantage of their algorithm for solving such instances.\n2.\tThe paper has few technical contributions. It builds on a simple observation. Although this observation is clever, it is more like a trick and does not need many insights into the problem.\n3. The proof of Theorem 3 is problematic. Note that the sparsifier is determined before the greedy algorithm is executed. So it\u2019s unknown which $S_j$\u2019s the greedy algorithm will reach. Consequently, to ensure that the incremental value of $S_j$ can be estimated accurately, one needs to combine the union bound with Lemma 8 to show the estimate is accurate for all subsets of size at most $k$. This means that $\\alpha$ should be $\\Theta(\\epsilon^2 k \\log n)$ and now the number of oracle evaluations is $O(k^2n^2 \\log n)$. So, under the cardinality constraint, the proposed algorithm has no advantage over Kudla & Zivny (2023), which further reduces the contribution of the paper.\n4.\tThe paper is presented in a TCS rather than an ML style, which makes it less attractive to AI researchers. I suggest the authors to rewrite the Introduction and explain why the paper\u2019s results are important to the AI community."
                },
                "questions": {
                    "value": "1.\tThe sentence \u201cThe expected number of oracle evaluations of our algorithm only depends on the size of the ground set\u201d in the Abstract is misleading. I understand the authors regard the Nn term as the preprocessing time. However, it will not disappear in practice. And it\u2019s unfair to compare with previous algorithms while omitting this term.\n2.\tRafiey & Yoshida (2022) is published in AAAI22, please update the reference.\n3.\tI suggest the authors to moving the Related Work to the beginning of the Introduction, and explain more about the reason why the paper\u2019s results are important to the AI community.\n4.\tPage 2, in the second to last paragraph, I can not figure out why the sentence \u201cWhile the mini-batch approach results\u2026\u201d can imply the sentence \u201cThis means that we need to reestablish\u2026\u201d."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission786/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission786/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission786/Reviewer_dUP7"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission786/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698752664543,
            "cdate": 1698752664543,
            "tmdate": 1699636005953,
            "mdate": 1699636005953,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1jXq4AQRR0",
                "forum": "TGaFO0YglG",
                "replyto": "4RoxoRKVZL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission786/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the valuable feedback! Please allow us to address your main concerns here first, and implement them in a revision later.\n\n1) Please refer to our reply to\u00a0Reviewer qFjC for motivation regarding $N \\gg n,k$.\u00a0We are not sure we understand your concern regarding the preprocessing time. Our motivation is exactly the same as Rafiey & Yoshida. Specifically, assume you would like solve the problem over many different constraints, you would only need to perform the preprocessing step once. This is why we follow the approach of Rafiey & Yoshida and account for it separately. Please let us know if we misunderstood what you meant here.\n\n2) Indeed our solution is technically very simple, and our main contribution is a different perspective overlooked by previous papers. Nevertheless, this provides an exponential improvement in the worst-case query complexity which we believe to be a significant result. The significance of our results is of course subjective, but wouldn't you agree that if the result is significant then simpler is better (e.g., the 2 page mini-batch k-means paper by Sculley)?\u00a0\n\n3) We are not sure we understand your concerns here. At every iteration of the greedy algorithm we sample a \"fresh\" sparsifier (i.e., mini-batch) after $S_j$ is fixed before we sample the mini-batch for each iteration and therefore we only need to union bound over all possible extensions\u00a0of $S_j$ by one element. As\u00a0Reviewer qFjC pointed out, it might be the case that our algorithm description is not sufficiently clear, and we will improve this in the revision.\n\n4) Indeed, we are theoreticians :) As submodular maximization is well studied in the ML community, do you mean we should elaborate more on the importance of decomposable submodular functions? If so, please see our\u00a0reply to\u00a0Reviewer qFjC. If not, could you please provide more details on changes you would like to see made?\n\n>The sentence \u201cThe expected number of oracle evaluations of our algorithm only depends on the size of the ground set\u201d in the Abstract is misleading. I understand the authors regard the Nn term as the preprocessing time. However, it will not disappear in practice. And it\u2019s unfair to compare with previous algorithms while omitting this term.\n\nWe understand the concern, please see our response to question (1). Anyway, we will change the wording in the abstract.\n\n>Page 2, in the second to last paragraph, I can not figure out why the sentence \u201cWhile the mini-batch approach results\u2026\u201d can imply the sentence \u201cThis means that we need to reestablish\u2026\u201d.\n\nWhat we meant to say here is that although our approach has better query complexity computing a sparsifier has the benefit that you do not need to reprove the approximation\u00a0 guarantees of known results."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699761234290,
                "cdate": 1699761234290,
                "tmdate": 1699761234290,
                "mdate": 1699761234290,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jszayE8ZI9",
                "forum": "TGaFO0YglG",
                "replyto": "1jXq4AQRR0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission786/Reviewer_dUP7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission786/Reviewer_dUP7"
                ],
                "content": {
                    "comment": {
                        "value": "After reading the example in the  reply to Reviewer qFjC, I think the motivation to consider the case N>>n is interesting and meaningful. I still suggest the author to thoroughly discuss the motivation of the whole setting in the paper, not only the importance of decomposable submodular functions, but also the motivation of the case N>>n and the case where the preprocessing only runs once but the optimization runs several times."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700489259566,
                "cdate": 1700489259566,
                "tmdate": 1700489259566,
                "mdate": 1700489259566,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "i2sq2TktM0",
            "forum": "TGaFO0YglG",
            "replyto": "TGaFO0YglG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission786/Reviewer_QSfG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission786/Reviewer_QSfG"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors present a new algorithm for maximizing monotone decomposable submodular functions subject to cardinality and p-system constraints."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The improvement in preprocessing time and the main algorithm for unbounded curvature is beneficial when $N \\gg n$.\n2. Removing the dependence on $B$ is also beneficial in the bounded curvature setting.\n3. Although \"mini-batching\" ideas have been used in this context before, the way they are used in this work is novel."
                },
                "weaknesses": {
                    "value": "1. The paper is poorly written and difficult to understand in some places. Algorithm 2 is not an algorithm, line 4 does not make sense, and line 7 at least needs a pointer.\n2. The paper does not provide sufficient justification for the importance of the problem or their algorithms improvements.\n3. The paper does not compare the results in an experimental setting, which, combined with the above issue, raises significant concerns about the applicability of the authors' algorithms.\n4. The authors claim that \"The expected number of oracle evaluations of our algorithm only depends on the size of the ground set,\" which is clearly impossible. Their preprocessing still has linear dependency on N. I believe this type of overreaching claims is very confusing and can give the false impression of the quality of the work."
                },
                "questions": {
                    "value": "Please provide responses for the above concerns."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission786/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission786/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission786/Reviewer_QSfG"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission786/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698765643869,
            "cdate": 1698765643869,
            "tmdate": 1700045773689,
            "mdate": 1700045773689,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KCL9v8g3Zo",
                "forum": "TGaFO0YglG",
                "replyto": "i2sq2TktM0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission786/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission786/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your comments.\n\n1) Please see our response to Reviewer qFjC.\n2) Please see our response to Reviewer qFjC.\n3) Please see our response to Reviewer ev1Q.\n4) Please see our response to Reviewer dUP7."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699761484885,
                "cdate": 1699761484885,
                "tmdate": 1699761484885,
                "mdate": 1699761484885,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KqhF3Q8JaS",
                "forum": "TGaFO0YglG",
                "replyto": "KCL9v8g3Zo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission786/Reviewer_QSfG"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission786/Reviewer_QSfG"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "After reading the authors response and other reviewers comments I think:\n\n1- The presentation of the paper should be significantly improved.\n2- The importance of the problem and its applications is not clear. Authors explanations are not convincing.\n3- The contribution of the work is below the expectations for this conference.\n\nI updated my score accordingly."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission786/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700046286251,
                "cdate": 1700046286251,
                "tmdate": 1700046286251,
                "mdate": 1700046286251,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]