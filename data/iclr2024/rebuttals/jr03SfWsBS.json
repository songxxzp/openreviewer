[
    {
        "title": "Unprocessing Seven Years of Algorithmic Fairness"
    },
    {
        "review": {
            "id": "oHTqaUcKxl",
            "forum": "jr03SfWsBS",
            "replyto": "jr03SfWsBS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission289/Reviewer_4YF6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission289/Reviewer_4YF6"
            ],
            "content": {
                "summary": {
                    "value": "The problem the paper considers is building accurate models subject to a fairness constraint. There are many ways of building models but it is difficult to compare between different methods because a) the model performance depends on the underlying classifier and b) the models satisfy the fairness constraint up to different relaxations.\n\nThis paper seeks to solve both problems and run a large experiment on many different methods and models. They start with an approach they call \"unprocessing\" which takes the underlying classifier and removes the fairness constraint. In this way, different models can then reasonably be compared to each other. They then postprocess the classifiers to achieve the fairness constraint. There is an optimal way to achieve the postprocessing so this step also lets different models be compared to each other."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. A simple way of comparing models with different fairness constraints. I hope this becomes widely adopted and used before people introduce their XYZ fairness algorithm.\n\n2. A comprehensive evaluation of lots of models on four data sets. I especially liked two observations from their results:\n\n* Models subject to a fairness constraint can actually achieve higher accuracy than models not subject to a fairness constraint when compared fairly (pun intended). The explanation they give is that fair training can take longer and use more resources because of the complexity in the algorithms.\n\n* In their words: \n\n\"Crucially, postprocessing the single most accurate model resulted in the fair optima for all values of fairness constraint violation on all datasets, either dominating or matching other contender models (within 95% confidence intervals). That is, all optimal trade-offs between fairness and accuracy can be retrieved by applying different group-specific thresholds to the same underlying risk scores.\"\n\nI think this is intuitively obvious and it's nice to see experimental confirmation.\n\n3. A technical description of how to achieve relaxed parity."
                },
                "weaknesses": {
                    "value": "1. I found the technical description of how to achieve relaxed parity jarring from the rest of the paper. I would have liked this section to be longer and for more explanations there. I did find the figures quite helpful in understanding it.\n\n2. A big selling point of the paper is the extent of their experiments. I think the reason they were able to do this is because they had access to a ton of compute. All the data sets and models (I believe) are easily accessible. If this is the case, I'm not sure that \"having lots of compute\" is really something we should reward as a contribution.\n\n3. I found their approach intuitively obvious: Of course given a classifier, you can vary how much it violates a reward constraint in an optimal way. So I think the contribution here would be because (it seems like) no one has done this before rather than because it is so interesting."
                },
                "questions": {
                    "value": "Is there anything in my assessment you disagree with?\n\nHave you considered putting your approach into a popular package so that researchers can quickly and easily compare their models?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission289/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission289/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission289/Reviewer_4YF6"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission289/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697817956449,
            "cdate": 1697817956449,
            "tmdate": 1700686272337,
            "mdate": 1700686272337,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wZsRXJDjPg",
                "forum": "jr03SfWsBS",
                "replyto": "oHTqaUcKxl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission289/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission289/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your encouraging review and valuable feedback. We address each question in the following paragraphs.\n\n**Q2**\n> Have you considered putting your approach into a popular package so that researchers can quickly and easily compare their models?\n\nThank you for bringing this up. We've open-sourced our implementation in a standalone python package (link to [anonymized repository](https://anonymous.4open.science/r/error-parity-8550/README.md) in the paper). Our implementation is easy-to-use and compatible with any score-based classifier (examples [here](https://anonymous.4open.science/r/error-parity-8550/examples/relaxed-equalized-odds.usage-example-folktables.ipynb)). Additionally, to reach a potentially wider audience, we have open Pull Requests to include our implementation on a popular algorithmic fairness python package (will be linked in the paper after deanonymization period), although this will expectedly still take some weeks of work to be made compatible with that package's API and structure.\n\n**W1**\n\nThank you for raising this concern.\n\nAchieving error-rate parity was detailed by Hardt et al. (2016). The relaxed solution is more nuanced (since we can no longer rely on the intersection of all group-specific ROC curves), but the key idea is similar: using randomized thresholds allows us to access the convex hull of each group-specific ROC curve (while deterministic thresholds only allow us to access specific discrete ROC points). This makes it so the optimization domain is convex (the group-specific ROC convex-hulls), and hence easy to optimize over. While this is an efficient solution to the problem, a simple brute-force approach would also be possible (brute force implementation example [here](https://anonymous.4open.science/r/error-parity-8550/examples/brute-force-example_equalized-odds-thresholding.ipynb)). \nAs linear optimization has been widely studied in the literature, we cite reference works such as Boyd and Vandenberghe (2004) for details on how to solve the LP.\nAccording to reviewer feedback, we were in fact torn between keeping this section in the paper or in the appendix, but as per your feedback we will maintain it in the main paper body.\n\n**W2**\n\nThank you for raising this point. Appendix B details the infrastructure we used to conduct our experiments. Note that the run-times in Fig. 5 correspond to model training times using a single CPU-core per job (to allow for high job parallelization and a more efficient use of CPU nodes). We do believe that the variety of datasets and models tested significantly contributes to the generalizability of our findings. For full transparency, we will further detail the compute usage of our experiments in Appendix B.\n \n**W3**\n\nWe agree that our approach is definitely intuitive. At the same time, the algorithmic fairness literature contains a wide range of fairness-aware inprocessing and preprocessing methods that claim to dominate results achieved by a simple postprocessing baseline. In our work, we show that this outperformance can be due to (1) comparing models at different levels of constraint violation, or (2) postprocessing a lower-performance model; both are arguably instances of unfair evaluation standards. Acting on each stage of the ML pipeline undoubtedly has specific advantages (e.g., preprocessing is potentially compatible with any downstream task/model, and can be useful when you have to hand over the data to a third party). With this meta study, we hope to have made the advantage of postprocessing clear: given accurate risk-score estimates, postprocessing can retrieve any optimal fairness-accuracy trade-off."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission289/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700515594725,
                "cdate": 1700515594725,
                "tmdate": 1700515594725,
                "mdate": 1700515594725,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "41FuVxjYMR",
                "forum": "jr03SfWsBS",
                "replyto": "wZsRXJDjPg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission289/Reviewer_4YF6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission289/Reviewer_4YF6"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your detailed response!\n\nI am concerned about the overlap with Hardt et al. as per the review of RSrR. Nonetheless, from your response to **W1**, it sounds like your theoretical result is sufficiently different. As such, I will increase my rating to 8.\n\nIf RSrR or the other reviewers are not persuaded that the theoretical result is sufficiently novel and different from Hardt et al., I will revise my recommendation back down to 6."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission289/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700686258512,
                "cdate": 1700686258512,
                "tmdate": 1700686258512,
                "mdate": 1700686258512,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "4LGyD8ke3u",
            "forum": "jr03SfWsBS",
            "replyto": "jr03SfWsBS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission289/Reviewer_tygt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission289/Reviewer_tygt"
            ],
            "content": {
                "summary": {
                    "value": "This work performs an extensive benchmark for 1000 models to compare the error rate disparity and accuracy trade-offs. To make a fair comparison, the constrained models, either trained with pre-processing techniques or in-processing learning constraints, are unprocessed to yield the corresponding optimal unconstrained model. Through these assessments, the authors convey a straightforward yet crucial finding: achieving fairness is best attained by training the most effective unconstrained model available and subsequently employing post-processing techniques to fine-tune the thresholds."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- I like the way the authors pose the narrative of this work. The structure is well-defined, presenting experimental details clearly. \n-  I think the concept of \"unprocessing\" is a novel and effective method to discover the optimal unconstrained model corresponding to the constrained models.\n- In general, the evaluation is solid and can provide enough insights to the practitioners.\n- In my personal opinion, this paper satisfies my standard of acceptance but does not reach the rating of 8. So I would rather recommend a rating of 6."
                },
                "weaknesses": {
                    "value": "- I would like to see a comparison between the real unconstrained model and the unprocessed version of the constrained model. This comparison is necessary and could enhance the claim that unprocessing can be applied to find the optimal unconstrained model.\n- Section 4 is just a standard LP problem in solving Equal Odds with post-processing. It is not novel and there is no need to write down it in the main paper.\n- The author has admitted that their evaluation is only applied to tabular data, with a focus on 5 different partitions of the FolkTables dataset. It would be interesting to see how the conclusions can still be generalized to tasks with rich representations."
                },
                "questions": {
                    "value": "- How efficient is it to solve the LP problem? Can I just exhaustively search all the combinations of the thresholds and plot the Pareto frontiers of the fairness-accuracy trade-offs?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission289/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698629452985,
            "cdate": 1698629452985,
            "tmdate": 1699635954755,
            "mdate": 1699635954755,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ugaVbf4KMF",
                "forum": "jr03SfWsBS",
                "replyto": "4LGyD8ke3u",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission289/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission289/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your encouraging review and valuable feedback. We address each question in the following paragraphs.\n\n**Q1**\n\nThank you for bringing this up. The LP formulation is actually paramount to the usefulness of our method, as an exhaustive search over all threshold combinations scales exponentially with the number of groups, and scales quadratically with the number of thresholds that the underlying predictor accepts. To clarify, an exhaustive search would have to span all combinations of group-specific _randomized thresholds_ in order to access the interior of each group's ROC curve (by using deterministic single-value thresholds we can only access specific discrete points in the exterior of each group's ROC curve). That is, each group\u2019s decision function is represented by 2 values, $\\{(\\underline{t}_s, \\overline{t}_s) : (\\underline{t}_s, \\overline{t}_s) \\in \\mathcal{T}^2 \\land  \\underline{t}_s \\leq \\overline{t}_s\\}, \\mathcal{T} \\subseteq \\mathbb{R}$. Samples of group $s$ whose score is lower than $\\underline{t}_s$ are classified negatively ($\\hat{Y}=0$), samples whose score is higher than $\\overline{t}_s$ are classified positively ($\\hat{Y}=1$), and samples whose score is in the range $\\left[\\underline{t}_s, \\overline{t}_s\\right]$ are classified randomly by a coin toss [Hardt et al., 2016, Section 3.2].\n\nFor example, a coarse search grid over deterministic thresholds of $\\mathcal{T} = \\{0, 0.1, 0.2, ..., 1.0\\}$, includes randomized thresholds $\\{ (0.0, 0.0), (0.0, 0.1), ..., (0.0, 1.0), (0.1, 0.1), (0.1, 0.2), ... \\}$, a total of $\\frac{\\left|\\mathcal{T}\\right|(\\left|\\mathcal{T}\\right|+1)}{2}$ combinations (scales quadratically with $\\left|\\mathcal{T}\\right|$). Perhaps more importantly, if $\\mathcal{A}$ is the set of randomized thresholds, the search space will span $\\mathcal{A}^{|\\mathcal{G}|}$ different threshold combinations, where $|\\mathcal{G}|$ is the number of sensitive groups.\n\nWe've implemented an exhaustive-search solver and **added an example notebook** to the examples folder in the anonymized repository linked in the paper ([link here](https://anonymous.4open.science/r/error-parity-8550/examples/brute-force-example_equalized-odds-thresholding.ipynb)). Running an extremely coarse grid of $|\\mathcal{T}|=11$ thresholds on our main experiment ($|\\mathcal{G}|=4$) leads to over $9\\text{M}$ combinations. With our implementation, a small experiment using $|\\mathcal{G}|=2$ and $|\\mathcal{T}|=8$ takes 3 minutes to run over the $4356$ combinations with an exhaustive-search solver, while the LP solver takes 109ms to achieve a superior solution (because the search grid is finer).\n\n**W1**\n\nThank you for this suggestion. We've **added these comparisons in a new Appendix A.6** to the latest paper revision. Namely, we compare fairness and accuracy results for postprocessing and fairness-constraining the same model class (e.g., FairGBM compared to postprocessed GBM), or unprocessing and unconstrained training of the same model class (e.g., unprocessed FairGBM compared to GBM).\n\nPlease let us know of any further suggestions you'd find beneficial for the presentation of our work.\n\n**W2**\n\nWe agree that our most significant contributions are empirical, and describing the LP is not particularly novel. However, as all our findings rely on the proposed relaxed postprocessing method, we believe that a clear definition of this optimization problem should be in the body of the paper; additionally clarifying how exactly relaxed postprocessing differs from strict postprocessing (whose LP solution is detailed by Hardt et al. (2016)). We admit that a balance between lack of context and unnecessarily detailed explanations is hard to strike, as other reviewers even suggest that this section should be lengthened.\n\n---\n\nThank you for your insightful recommendations. We believe the latest paper additions have definitely improved our work."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission289/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700515572486,
                "cdate": 1700515572486,
                "tmdate": 1700515572486,
                "mdate": 1700515572486,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ahvDizJl6t",
                "forum": "jr03SfWsBS",
                "replyto": "ugaVbf4KMF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission289/Reviewer_tygt"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission289/Reviewer_tygt"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the authors for the detailed response and the extending experiments. I will retain my score and recommend for acceptance as indicated."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission289/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700684061116,
                "cdate": 1700684061116,
                "tmdate": 1700684061116,
                "mdate": 1700684061116,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Y3RxJ9zg4F",
            "forum": "jr03SfWsBS",
            "replyto": "jr03SfWsBS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission289/Reviewer_QHJ8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission289/Reviewer_QHJ8"
            ],
            "content": {
                "summary": {
                    "value": "There have been many proposals in the recent literature to train fair ML models. This paper evaluates thousands of such models, and finds that a simple postprocessing technique achieves the fairness-accuracy Pareto frontier."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "This type of comprehensive benchmarking of thousands of models adds a ton of value to the algorithmic fairness literature. I think the result that a simple postprocessing step achieves the Pareo frontier is very significant. I applaud the authors for taking on this task."
                },
                "weaknesses": {
                    "value": "None"
                },
                "questions": {
                    "value": "None"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission289/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission289/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission289/Reviewer_QHJ8"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission289/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698806868067,
            "cdate": 1698806868067,
            "tmdate": 1699635954687,
            "mdate": 1699635954687,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "l9m7SkrO3w",
                "forum": "jr03SfWsBS",
                "replyto": "Y3RxJ9zg4F",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission289/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission289/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your encouraging review. We are very glad to know that you appreciate the significance of our work."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission289/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700515523885,
                "cdate": 1700515523885,
                "tmdate": 1700515523885,
                "mdate": 1700515523885,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ngmy5jMDXK",
            "forum": "jr03SfWsBS",
            "replyto": "jr03SfWsBS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission289/Reviewer_RSrR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission289/Reviewer_RSrR"
            ],
            "content": {
                "summary": {
                    "value": "The paper considers the relation fairness-accuracy tradeoff. In particular, the paper considers the relation between fairness (in terms of Equalized Odds) violation and accuracy of the predictor, before and after \"unprocessing\", and claims based on empirical observations that any Pareto-optimal tradeoff between accuracy and empirical EOdds violation can be achieved by postprocessing.\n\n---\n\n**Post-rebuttal**\n\nThe authors claim that Theorem 5.6 of Hardt et al. (2016) strengthens the result of empirical studies considered in the work. It would be helpful if such discussion can be incorporated in the manuscript to help readers understand this connection. After engaging with authors and going through comments by other reviewers, I have increased my evaluation from 5 to 6."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The strength of the paper comes from the extensive empirical experiments and the efforts to present the observation (that Pareto-optimal tradeoff can potentially be achieved by postprocessing. The experiments are conducted on a relatively new data set (compared to standard baseline data sets in the literature), and the setup includes exact and relaxed EOdds (Hardt et al., 2016)."
                },
                "weaknesses": {
                    "value": "The weakness of the paper comes from the lack of a certain level of theoretical derivation to justify the empirical findings. The proposed term \"unprocessing\", as noted by authors, \"roughly corresponds to the inverse of postprocessing\", is more of less confusing (for reasons detailed in Section __Questions__). While one can observe from extensive empirical evaluations that Pareto-optimal tradeoffs can be achieved (setting aside numerical indeterminacy), there is a worry that the results can only provide limited insight regarding the not-clearly-motivated unprocessing procedure."
                },
                "questions": {
                    "value": "__Question 1__: what is the exact relation between unprocessing and postprocessing?\n\nBased on Hardt et al. (2016), the postprocessing strategy for EOdds is trading off True Positive Rates (TPRs) and False Positive Rates (FPRs) across different demographic groups. Such procedure is _oblivious_, in the sense that only the joint distribution $(A, Y, \\hat{Y})$ are utilized in the postprocessing procedure. If this specific way of postprocessing is of interest in the paper, I am not sure how to understand the relation between unprocessing and postprocessing. I can see why authors draw an analogy between unprocessing and the inverse of postprocessing. According to Equation 1, unprocessing starts from the postprocessed $\\hat{Y}$ and aims to find the unconstrained optimized predictor. How can we do that with obliviously postprocessed $\\hat{Y}$? How to make sure the unprocessed predictor has a sensible mapping from input features to target variable?\n\n\n\n__Question 2__: regarding the claim that _any_ Pareto-optimal tradeoff can be achieved by postprocessing\n\nFollow up to Question 1, if the postprocessing is defined as in Hardt et al. (2016), it would be very helpful if authors can provide a clear characterization of the relation between unprocessing and such definition of postprocessing, so that readers can understand why unprocessing is a helpful analyzing tool to understand the importance of postprocessing. Empirical evaluations can be strengthened by some certain level of theoretical analysis to make the results and message more convincing."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission289/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission289/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission289/Reviewer_RSrR"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission289/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698863650769,
            "cdate": 1698863650769,
            "tmdate": 1701010814218,
            "mdate": 1701010814218,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vtpgY6w3rg",
                "forum": "jr03SfWsBS",
                "replyto": "ngmy5jMDXK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission289/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission289/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review and valuable feedback. We address each question in the following paragraphs.\n\n---\n> According to Equation 1, unprocessing starts from the postprocessed \u0176 and aims to find the unconstrained optimized predictor. How can we do that with obliviously postprocessed \u0176?\n\nThank you for raising this question. The postprocessing procedure we propose is analogous to that  of Hardt et al. (2016), only with a partially relaxed fairness constraint. Specifically, both procedures operate on _the scores_ of a score-based predictor, by finding the optimal group-specific decision-boundary (minimal loss while fulfilling the constraint). As such, these procedures are \"oblivious\", in the sense that they are functions of the joint distribution of $(Y, A, R)$, and do not consider the features $X$ directly.\n\n> How to make sure the unprocessed predictor has a sensible mapping from input features to target variable?\n\nUnprocessing (or, more generally, postprocessing) does not consider the features, only the scores of the underlying predictor. If the underlying predictor does not sensibly map features to the target variable, then postprocessing that predictor will expectedly have very poor results. For this reason, to unconfound our results with the performance of the base model, we pick the predictor whose scores can achieve the highest accuracy ($m^*$).\n\n> (...) I am not sure how to understand the relation between unprocessing and postprocessing.\n> \n> (...) provide a clear characterization of the relation between unprocessing and such definition of postprocessing, so that readers can understand why unprocessing is a helpful analyzing tool to understand the importance of postprocessing.\n\nThe proposed postprocessing method is solely a more general version of the method of Hardt et al. (2016) that is now compatible with relaxed fairness constraint fulfillment. We call _unprocessing_ to the specific case of postprocessing where the fairness constraint was infinitely relaxed, $r=+\\infty$. That is, unprocessing boils down to minimizing each group's loss over each independent group threshold (finding which point in the group's ROC achieves minimal loss).\n\nStrict postprocessing will map an *unconstrained* score-based predictor to a *fairness-constrained* classifier. We use the term \"unprocessing\" to intuitevely capture the reverse procedure: mapping a *constrained* score-based predictor to a *fairness-unconstrained* classifier. Of course, either procedure can be applied to any predictor, constrained or unconstrained alike, but applying unprocessing to an unconstrained predictor will expectedly not significantly change its accuracy/fairness (discussed in the last paragraph of Sec. 2.2).\n\nTo clarify with an example: given a standard unconstrained classifier (e.g., GBM), strict postprocessing will map it to the fairness-accuracy space of constrained classifiers (e.g., FairGBM); on the other hand, given a constrained classifier such as FairGBM, _unprocessing_ will do the inverse mapping, outputting a classifier that will approximately sit in the fairness-accuracy space of unconstrained GBM models.\n\nWe have added a **new Appendix A.6** with detailed comparisons between unprocessed models that were trained in a fairness-constrained manner, and standard unconstrained models; as well as comparisons between postprocessed models that were trained in an unconstrained manner and inprocessing fairness-constrained models.\nHopefully this will further clarify the motivation behind unprocessing and postprocessing.\n\n---\n\nThank you for your feedback. Please let us know if your questions were addressed, or of any further questions you may have."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission289/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700515507612,
                "cdate": 1700515507612,
                "tmdate": 1700515507612,
                "mdate": 1700515507612,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SUtXakaslR",
                "forum": "jr03SfWsBS",
                "replyto": "vtpgY6w3rg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission289/Reviewer_RSrR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission289/Reviewer_RSrR"
                ],
                "content": {
                    "title": {
                        "value": "Follow-Up on Responses"
                    },
                    "comment": {
                        "value": "Thank authors for the response, and for confirming that the proposed postprocessing procedure is \"analogous to that of Hardt et al. (2016), only with a partially relaxed fairness constraint.\" The post-/un- processing involves $(Y, A, R)$ but not $X$, where $R$ is the (potentially) continuous score instead of binary or discrete prediction itself, and $X$ are features.\n\nPrevious results on _Near Optimality_ (Theorem 5.6, Hardt et al., 2016) already provides theoretical analysis of this setting. In particular, it is showed that if we can approximate the (unconstrained) Bayes optimal regressor well enough, then we can also construct a nearly optimal non-discriminating (in terms of Equalized Odds) classi\ufb01er.\n\nWhat is the contribution of the current work, as compared to the aforementioned theoretical result?\n\nFurthermore, since unprocessing does not consider features, can authors clarify why should we use the unprocessed predictor when we are not sure if such mapping can be attained? Specifically, how to derive prediction on new data with the unprocessed predictor?"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission289/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700602027256,
                "cdate": 1700602027256,
                "tmdate": 1700602027256,
                "mdate": 1700602027256,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]