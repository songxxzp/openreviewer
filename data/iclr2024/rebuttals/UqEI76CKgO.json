[
    {
        "title": "Amphibian: A Meta-Learner for Rehearsal-Free Fast Online Continual Learning"
    },
    {
        "review": {
            "id": "3jeicghStl",
            "forum": "UqEI76CKgO",
            "replyto": "UqEI76CKgO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6637/Reviewer_kAVs"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6637/Reviewer_kAVs"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes a continual learning approach called Amphibian, which is based on MAML-style model updates.\nUnlike existing MAML-based approaches (e.g., Gupta et al., 2020), it does not rely on a replay buffer.\nIt assumes that the training examples are provided as a sequence of batches, each with dozens of examples.\n\nThe basic training scheme can be summarized as follows.\nWhen a new batch comes in, it performs gradient descent for each example in the batch one by one (the inner-loop updates), producing a temporary model fitted to the batch.\nThe temporary model is then evaluated on the entire examples in the batch to yield the meta-loss.\nFinally, the original model parameters are updated with the gradient w.r.t. the meta-loss (the outer-loop update), and the training proceeds to the next batch.\n\nThe main novelty of Amphibian is to introduce a gradient scaler $\\lambda_i$ for each parameter $i$.\nWhenever gradient descent is performed, this value is multiplied to the gradient, acting as a per-parameter learning rate.\nThis $\\lambda_i$ is updated every batch by accumulating the products of the outer-loop gradient and the inner-loop gradient."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "This paper dedicated significant effort to ensure reproducibility.\nThe appendix includes experimental details, and the code is provided in the supplementary material."
                },
                "weaknesses": {
                    "value": "### Lack of Justification for the Method\n\nOverall, the proposed method does not seem to have a solid theoretical basis.\nThe key idea of this work is to adjust the per-parameter learning rate with the cumulative sum of the products between the inner-loop gradients and the outer-loop gradients.\nIf the inner and outer gradients have the same sign in the current batch, the learning rate for the corresponding parameter is increased, and vice versa.\nHowever, there is no justification for how such learning rate updates can be helpful to continual learning.\n\nInterestingly, if we consider the case where the batch size is reduced to 1, this algorithm seems to become almost the opposite of EWC (Kirkpatrick et al., 2017).\nIn EWC, squared gradients are accumulated for each parameter, and the parameter becomes less flexible as the accumulated value grows.\nIn Amphibian with a batch size of 1, the inner gradient and the outer gradient are both computed with the only example in the batch.\nAssuming the inner gradient does not incur drastic changes in the parameters, their product can be likened to the squared gradient in EWC.\nHowever, Amphibian encourages the changes in the parameters with larger accumulated gradient products, which is the opposite of EWC.\n\n### Confusing Notations\n\nStarting from Eq. (7), $\\ell_{in}$ and $\\ell_{out}$ take only $\\theta_0^j$ as input.\nThis ambiguates the meaning, especially for $\\ell_{in}$.\nAccording to the description under it, the inner loss $\\ell_{in}$ is computed with a single example in a batch, but which example is it?\nAnd why isn't there a summation of multiple $\\ell_{in}$ from each example in the batch?\n\nSimilar confusion continues, even in the appendices.\nFor instance, $g_k$ in Eq. (14) and $g_{k'}$ in Eq. (16) seem to have the same definition with a different index, but their definitions are completely different.\n\nI also do not see any utility in adopting the concept of gradient space.\nSince the authors simply use $e_i$ as basis vectors, all the scaling is independently performed for each individual parameter.\nTherefore, many equations can be simplified without introducing $e_i e_i^T$, which causes unnecessary confusion.\nSimilarly, the scale matrix $\\Lambda$ can be simplified to per-parameter scale values.\n\nAdditionally, there is inconsistency in the subscripts for $\\lambda$ and $e$.\nThe use of $i$ and $m$ is mixed in various instances, as seen in Equation (8) and (9).\n\nI strongly recommend that the authors carefully restructure the overall notation in a systematic manner.\n\n\n### Technically Incorrect Statements\n\n#### Online Setting?\n\nAlthough Amphibian is proposed as an online continual learning approach, one of its key assumptions is that the training examples are provided as a series of batches.\nI think this is far from a truly online setting.\nGenerally, an online learning algorithm should be able to update a model meaningfully, even with a single example.\nHowever, this is not the case for the proposed method.\n\n#### Equivalence between Eq. (6) and (7)\nThe authors argue that Eq. (7) is *equivalent* to minimizing Eq. (6).\nHowever, it seems to be an approximation, according to Appendix A.\n\n---\n\nIn summary, I find limited value in the proposed method, and there is ample room for improvement, even in terms of its presentation. Consequently, I believe this paper does not meet the standards expected for an ICLR publication."
                },
                "questions": {
                    "value": "How does Amphibian work in a fully online setting where each example is given individually, i.e., when $|\\mathcal B_i| = 1$?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6637/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698563862398,
            "cdate": 1698563862398,
            "tmdate": 1699636758270,
            "mdate": 1699636758270,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HTLqKgdwE6",
                "forum": "UqEI76CKgO",
                "replyto": "3jeicghStl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6637/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6637/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for taking the time and review our paper. We provide responses to the reviewer\u2019s questions/concerns below:\n\nAccording to the reviewer - \u201cthe key idea of this work is to adjust the per-parameter learning rate\u201d and \u201call the scaling is independently performed for each individual parameter\u201d. These statements are not true. As we clearly mentioned in the paper that our method learns a diagonal scale matrix at each layer and scale (adjust) the gradient directions with this matrix accordingly. To elaborate on this point, let\u2019s assume we have a fully connected layer of a network having weight, W of size $m\\times n$. Here, $m$ and $n$ are the numbers of output and input neurons respectively. There is a total of $mn$ parameters in this weight. Instead of learning $mn$ learning rate parameters, for this layer, we learn a diagonal scale matrix of size $n\\times n$, thus only learning $n$ parameters. (Table 7 in the appendix lists the actual number of scale parameters learned by our methods in different experiments.) Alternatively, we can think of this as gradients of a group of $m$ parameters are scaled by a common factor ($\\lambda_i$), and there are $n$ such groups in $W$ matrix. As we adopt the concept of low-dimensional gradient space (please see section 3 in the paper for details) such scaling is possible. This low-dimensional gradient representation requires the introduction of basis vectors, $e_i$. Because, in conventional representation, the gradient space would be $mn$ dimensional for the weight matrix. However, in our low-dimensional representation, it is $n$ dimensional. The $e_i$ vectors describe the basis of this space. The scales, $\\lambda_i$ are associated with each of these vectors, which are learned/computed from the alignment history along the basis directions (Equation 8, 9). \n\n*On the justification of method*: \n\nWe are using a bi-level (inner-loop and outer-loop)/meta optimization method for CL. In inner loop, we take $k$ number of gradient steps, where each step uses a (non-overlapping) subset of data from the current batch $\\mathcal{B_i}$. These inner loop updates intuitively simulate a \u2018mini continual\u2019 learning scenario. At the end point of inner-loop update the outer-loop loss on the whole batch $\\mathcal{B_i}$ is computed. This loss indicates how well the current samples are learned and how much forgetting is there due to such (mini continual) learning. The outer-loop update then adjusts the weight to minimize forgetting and ensure good learning on the given batch. Now, to have learning synergy among different sequential batches, we use scale matrix that stores directional gradient alignment information. The direction along which samples in the online sequence have positive (negative) cumulative gradient alignment, model updates along those directions are encouraged (prevented). With extensive experiments with diverse datasets and architectures, we have shown the effectiveness of this method. Also, we show that loss on the previous tasks has minimal to no increase due to such updates which further justifies our method for CL.\n\nNow, $\\mathcal{|B_i|}=1$ ($k=1$) is not an ideal scenario for an meta-learning method like ours. This would mean there is no mini-CL sequence to observe in inner loop. Thus in the outer-loop no meaningful gradient information (for CL) will be generated for model update. For the same reason, the scale update would not be useful, as we won\u2019t be able to measure and store any cross-sample gradient alignment information (Eq 8,9), which plays a key role in Amphibian. This also explains the alleged inconsistency between functionality of EWC and Amphibian. In  $\\mathcal{|B_i|}>1$ ($k>1$) case, however, Amphibian produced expected CL performance. In Section 6.2 (and in Figure 5(c)-(d)) we show how Amphibian and EWC become functionally equivalent methods for CL with an added constraint with hyperparameter $\\beta$. \n\nTo enable Amphibian work with  $\\mathcal{|B_i|}=1$, a temporary memory buffer of size $B$ would be needed. Typically, $B$ would be of size of 5 to 10 samples. For each incoming example, the model would take an inner gradient step and that example will be stored in that buffer. Once the buffer is full, outer gradient will be computed on the entire buffer data and then the buffer will be cleared out immediately. This is how Amphibian would work in the reviewer-suggested truly/fully online setup. \n\n*On the confusing notations*: We thank the reviewer for pointing this out. We will correct the typos (e.g. $i$ vs $m$) and restructure the notations (wherever applicable) in the revised manuscript.\n  \n*On the technically incorrect statements*: (1) We used the definition of online setting as per literature (La-MAML, A-GEM, ASER ) where training examples are provided as a series of batches. (2) Yes, Eq. (6) and 7 are equivalent under approximations (Appendix A). We will highlight this point in the manuscript."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6637/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700726475805,
                "cdate": 1700726475805,
                "tmdate": 1700726598695,
                "mdate": 1700726598695,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ksRkn3QWir",
            "forum": "UqEI76CKgO",
            "replyto": "UqEI76CKgO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6637/Reviewer_esZ7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6637/Reviewer_esZ7"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a rehearsal-free continual learning algorithm, based on La-MAML. It employs bi-level optimization to learn a diagonal scale matrix in each layer, aiming to prevent catastrophic forgetting. Comprehensive experiments and analyses demonstrate its superior experimental performance. However, there may be an unfair comparison setting that needs clarification."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ The paper focuses on Task-IL incremental learning and significantly improves performance in the realm of rehearsal-free methods.\n+ I commend the authors for conducting comprehensive analysis experiments to evaluate the proposed Amphibian. These include Task Learning Efficiency, visualization of the loss landscape, and a comparison of few-shot forward transfer."
                },
                "weaknesses": {
                    "value": "+ I have concerns about the fairness of the comparable online setting. In both La-MAML and the code provided in your appendix, you have the hyper-parameter 'self.glances', which allows your online training batch to be optimized multiple times. While it's understandable that the early CL work La-MAML adopts this 'single-pass' setting due to the lack of clear definitions for online and offline CL settings, if you're adopting the online CL setting, you need to clearly highlight the differences between your experimental setting and the standard online CL setting where each example can only be seen once. Furthermore, you should provide results of other comparable methods under this setting or set your hyperparameter 'self.glances' to 1 for a fair comparison.\n+ La-MAML, as the most important baseline, also learns the learning rate through bi-level optimization, similar to your learned diagonal scaled matrix. Despite the results provided in Table 3, I'm still unclear if the learned diagonal scaled matrix truly outperforms the learned learning rate for each parameter of La-MAML. The differences between La-MAML and the proposed Amphibian are:\n    - La-MAML uses samples from the memory buffer, while Amphibian does not.\n    - Both La-MAML and Amphibian apply the ReLU operation on the learned learning rate or the diagonal scaled matrix. However, La-MAML only applies this ReLU operation during the outer loop, while Amphibian uses it in both the inner and outer loops. Existing research [1] shows that using the ReLU operation on the learning rate during both inner-loop and outer-loop can effectively improve performance. So it is unclear if your performance gains lies in this different operation.\nIn Table 3, you only show the ablation study on the first point. Therefore, it doesn't convince me that the learned diagonal scaled matrix is truly superior to the learning rate learned by La-MAML.\n    ```\n    Reference: [1] Learning where to learn: Gradient sparsity in meta and continual learning.  NeurIPS, 2021\n    ```\n+ In my view, the learned diagonal scaled matrix is equivalent to learning the important weights for the current task. However, like EWC, it learns the important weights (i.e., the Fisher information matrix) for each task and suppresses the model\u2019s updates in these directions. I'm still unsure how the timely learned diagonal matrix can prevent catastrophic forgetting of previous tasks. I believe the authors need to provide more explanations. Is the proposed method, Amphibian, only applicable in the relatively simple Task-IL setting? Providing the Class-IL online CL performance could be much more convincing."
                },
                "questions": {
                    "value": "+ If you're adopting the online CL setting, you need to clearly highlight the differences between your experimental setting and the standard online CL setting where each example can only be seen once.\n+ It's unclear how the timely learned diagonal matrix can prevent catastrophic forgetting of previous tasks.\n+ Is the proposed method, Amphibian, only applicable in the relatively simple Task-IL setting? Could you provide the Class-IL online CL performance?\n\nPlease see the weakness section for more details."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6637/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698631759550,
            "cdate": 1698631759550,
            "tmdate": 1699636758141,
            "mdate": 1699636758141,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AiimKxVkhn",
                "forum": "UqEI76CKgO",
                "replyto": "ksRkn3QWir",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6637/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6637/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for taking the time and review our paper. We provide responses to the reviewer\u2019s questions/concerns below:\n\n*On the Weaknesses*: \n\n1. As per La-MAML we used the online (single epoch) learning setup where there is a glance hyperparameter. To have a fair comparison, in Table 1 we have reported results for all the other baselines in the same setup where multiple glances are allowed. Table 6 in the Appendix lists all the hyperparameters for these baselines, which contains the glance values as well.  \n\n2. In their implementation, La-MAML used ReLU operation in both inner and outer loops (Please see official La-MAML implementation [1] lines 55 and 99). In Table 1 we showed results for La-MAML (with rehearsal) and in Table 3 La-MAML (without rehearsal). Comparing these results we see that La-MAML with replay performs significantly better in terms of accuracy and forgetting mitigation. Since our method does not use any rehearsal and outperforms La-MAML (with rehearsal), learned diagonal matrices (unique component of our method) play a major role in preventing catastrophic forgetting.  \n\n3. The proposed method can also work in Class-IL online setup and the results are given already in the manuscript (in Figure 4, section 6.1). \n\n[1] https://github.com/montrealrobotics/La-MAML/blob/main/model/lamaml.py"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6637/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700725656046,
                "cdate": 1700725656046,
                "tmdate": 1700725656046,
                "mdate": 1700725656046,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5RZdGkP77n",
            "forum": "UqEI76CKgO",
            "replyto": "UqEI76CKgO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6637/Reviewer_ebWh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6637/Reviewer_ebWh"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a new algorithm tailored for the online continual learning paradigm, which operates without the need for rehearsal. It also offers a theoretical analysis of the approach. The method is characterized by its learning of a layer-wise diagonal scale matrix that captures the historical trajectory of gradient updates. The paper conducts a comparative evaluation of the proposed algorithm against established methods in the field of continual learning and provides a detailed analysis of the outcomes."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The experimental section of this article is quite comprehensive and theoretical analysis are provided.\n\n2. The authors design a novel rehearsal-free algorithm for continual learning, which achieves commendable results."
                },
                "weaknesses": {
                    "value": "1. This work just adds an adaptive diagonal scale matrix in each layer, which seems trivial. The contribution is somewhat limited.\n\n2. The authors allocate a substantial portion to the analysis of experimental results. Although the necessity of the experiment is clear, the analysis could benefit from being more concise to avoid redundancy.\n\n3. The presentation could be improved to get better readability."
                },
                "questions": {
                    "value": "1. Could you please provide a more detailed explanation of how the proposed method differs from La-MAML?\n\n2. Could you explain the rationale behind constraining the matrix to a scale matrix?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6637/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6637/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6637/Reviewer_ebWh"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6637/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699414020458,
            "cdate": 1699414020458,
            "tmdate": 1699636758026,
            "mdate": 1699636758026,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PtpJRhzLfG",
                "forum": "UqEI76CKgO",
                "replyto": "5RZdGkP77n",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6637/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6637/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for taking the time and review our paper. We provide responses to the reviewer\u2019s questions/concerns below:\n\n*Answer to Q1*: The main differences between our method (Amphibian) and La-MAML are: (1) La-MAML uses a replay buffer for storing old data, whereas Amphibian does not use any replay buffer. Thus La-MAML is a rehearsal-based method whereas Amphibian is a rehearsal-free method. (2) LA-MAML learns per parameter learning rate using data from both current and past tasks, whereas Amphibian learns layer-wise diagonal scale matrix using only the current batch data. Thus, the number of extra learnable parameters (memory overhead) in La-MAML is very high compared to Amphibian (Please see Figure 4(c)). (c) Amphibian minimizes a meta-objective that encourages alignments of gradients among given data samples along selected basis directions in the gradient space (Eq 7), La-MAML optimizes a different meta-objective. \n\n*Answer to Q2*: We adopted a low-dimensional gradient space representation in each layer of the network (please see section 3 for details). For each basis describing this space, we wanted to assign a scale by which incoming gradients will be modified during CL training. For this purpose, we introduced a diagonal scale matrix (in Eq. 4,5)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6637/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700725467763,
                "cdate": 1700725467763,
                "tmdate": 1700725467763,
                "mdate": 1700725467763,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]