[
    {
        "title": "Rethinking Test-time Likelihood: The Likelihood Path Principle and Its Application to OOD Detection"
    },
    {
        "review": {
            "id": "c2nCnBxtGz",
            "forum": "LjygLD0AkT",
            "replyto": "LjygLD0AkT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8717/Reviewer_Jhho"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8717/Reviewer_Jhho"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers the OOD detection problem, where likelihood and scores either performs poorly or lack of provable guarantees. Under the VAE setup, the authors introduce the likelihood path (LPath) principle, suggesting that minimal sufficient statistics of VAEs\u2019 conditional likelihoods are enough for OOD detection. Under several assumptions, the authors prove OOD detection guarantees for the chosen minimal sufficient statistics. Empirical results are also provided, suggesting the applicability of the proposed LPath principle."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The authors give a provable unsupervised OOD detection method that achieves good empirical performance, showing their work's high originality and significance. They also introduce several new concepts to facilitate the theoretical analysis."
                },
                "weaknesses": {
                    "value": "1. I have the concern of whether the assumptions (essential separation concepts) are too strong, so that they can easily imply the theoretical guarantee. Also, I am not sure whether these \"separations\" are reasonable in realistic dataset. \n\n2. The writing is unclear in the sense that some notation seems not to be defined, such as $p\\_{\\theta}$, $\\mu\\_z$. This makes me sometimes a little bit confusing."
                },
                "questions": {
                    "value": "I am wondering whether the Definitions can be interpreted in a more standard way using conventional languages such as total variation distance (or some other distances) between OOD and IID distributions is large?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8717/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8717/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8717/Reviewer_Jhho"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8717/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698366771261,
            "cdate": 1698366771261,
            "tmdate": 1699637093535,
            "mdate": 1699637093535,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4drjFUrBki",
                "forum": "LjygLD0AkT",
                "replyto": "c2nCnBxtGz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8717/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8717/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Jhho"
                    },
                    "comment": {
                        "value": "> I have the concern of whether the assumptions (essential separation concepts) are too strong, so that they can easily imply the theoretical guarantee. Also, I am not sure whether these \"separations\" are reasonable in realistic dataset.\n\nWe thank you for pointing this confusion out. We would like to invite you to Main Responses 7 and 8, and further clarify below.\n\n**[Essential separation is no stronger than prior literature]**\n\nThe assumptions of essential separation and distance are no stronger than any other prior works, theoretical or empirical. To our best knowledge, Essential separation and distance strictly include \u201cnear\u201d OOD and \u201cfar\u201d OOD settings considered in most if not all prior literature [1, 2, 3]. If they were too strong, prior informal and rigorous attempts would all become too strong. \n\nWe remark that prior arts consider either \u201cfar OOD\u201d (total separation) or \u201cnear OOD\u201d (not much separation). Essential separation is separation with a specified level of probability, which incorporates both. We invite you to explore the generality of our definitions via examples from B.2 to B.5.\n\n\n**[Our definitions work for any any metric including realistic datasets, e.g. SVHN v.s. CIFAR10]**\n\nThey are also developed for any abstract metric spaces, in theory including human-like perceptual distances (proxied by perceptual distance in [4]). Take SVHN vs. CIFAR10 as an example, they are clearly separable (no one confuses digits with cars), as a result they are by definition essentially separable.\n\n\n**[Our proof mainly uses VAEs\u2019 structure, not the essential separation]** \n\nAs for whether these general assumptions can imply theoretical guarantees, we invite you to check our proof in the Appendix. First, our proof mostly uses VAEs\u2019 unique structure, not the essential separation themselves. Second, since our definitions strictly include prior ones, prior assumptions are stronger. If the proof for VAEs simply follows from the definitions, prior works would have proved similar results. To our best knowledge, ours is the first provable work in the unsupervised OOD detection setting.\n\n\n>The writing is unclear in the sense that some notation seems not to be defined, such as $p_{\\theta},  \\mu_z$\nThis makes me sometimes a little bit confusing.\n\nWe thank you for improving our exposition. We assume familiarity to the VAEs literature where we recall Equation 1. $p_{\\theta}$ is defined there. We also assumed familiarity with the minimal sufficient statistics of VAEs on page 4, where we defined the sufficient statistics $T$ including $\\mu_z$. We will make these dependencies more explicit.\n\n\n[1] Zhen Fang, Yixuan Li, Jie Lu, Jiahua Dong, Bo Han, and Feng Liu. Is out-of-distribution detection learnable? Advances in Neural Information Processing Systems, 35:37199\u201337213, 2022.\n\n[2] Hendrycks, Dan, and Kevin Gimpel. \"A baseline for detecting misclassified and out-of-distribution examples in neural networks.\" arXiv preprint arXiv:1610.02136 (2016).\n\n[3] Fort, Stanislav, Jie Ren, and Balaji Lakshminarayanan. \"Exploring the limits of out-of-distribution detection.\" Advances in Neural Information Processing Systems 34 (2021): 7068-7081.\n\n[4] Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. \"Image style transfer using convolutional neural networks.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8717/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700724165546,
                "cdate": 1700724165546,
                "tmdate": 1700724213467,
                "mdate": 1700724213467,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LsAJaYMIN9",
            "forum": "LjygLD0AkT",
            "replyto": "LjygLD0AkT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8717/Reviewer_hPfm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8717/Reviewer_hPfm"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a novel approach to out-of-distribution (OOD) detection in Variational Autoencoders (VAEs) by leveraging minimal sufficient statistics within the encoder and decoder. This method differs from Morningstar et al. (2022) by focusing on the mean and variance of $q(z|x)$ instead of the posterior entropy and KL divergence for the latent variable $z$. Theoretical guarantee is derived by assuming there is essential separation between in distribution and OOD samples w.r.t. the $L_2$ norm, and the encoder/decoder in VAEs are Lipschitz. But in practice the assumptions are not always realistic. The experiment results are sometimes surpass SOTA and sometimes perform worse when the assumptions broke. \n1. **Proposed Methodology**:\n  - The paper suggests the utilization of the minimal sufficient statistics in both the encoder and decoder of the VAE for OOD detection.\n  - The work is reminiscent of Morningstar et al. (2022), but distinguishes itself by emphasizing the mean and variance of $q(z\u2223x)$ and derive theoretical guarantee of OOD under assumptions.\n2. **Assumptions and Implications**:\n  - Essential separation of in-distribution (ID) and OOD data based on L2 norm distance is assumed.\n  - The encoder and decoder must satisfy Lipschitz type conditions.\n  - Under these conditions, detection using reconstruction error or L2 norm distance in the latent space between a sample and ID samples is reliable with high probability.\n    - Practical implementation does not calculate distance by sampling IID samples. Instead, it is approximated using $\\mid || \\mu_{{z}}\\left({x}_{\\mathrm{OOD}}\\right) \\|-r_0 \\mid$.\n3. **Experimental Outcomes**:\n  - The method proves effective when the assumption on essential separation is likely met.\n  - On datasets with minor separations, like horizontally and vertically flipped variants, the technique is less effective compared to some state-of-the-art (SOTA) methods."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed sufficient statistics used for OOD detection are different from Morningstar et al. (2022) by focusing on the mean and variance of $q(z|x)$ instead of the posterior entropy and KL divergence for the latent variable $z$."
                },
                "weaknesses": {
                    "value": "- The utilization of  $\\mid || \\mu_{z} (x_{{OOD}}) \\|-r_0 \\mid$ to approximate the distance between test and ID samples is questioned for its lack of a principled basis. If ID samples have a wide spread in $\u03bc(x_{IID})$ in the latent space, the absence of a singular reference point makes the approximation meaningless. The reliance on VAEs' regularization of the posterior on $z$ towards a Gaussian (typically zero mean) implies the technique may not be generalizable to other generative models with distinct latent variable regularization.\n\n- The assumptions for essential separation and Lipschitz conditions are too strong. The separation (defined by the $L_2$ norm)  may not hold for real world problems. The Lipschitz conditions are not enforced during training of VAEs (or in other generative models) as well.\n\n- The idea of using reconstruction error for OOD detection was proposed in [1]. It is worth discussing the difference and what are the new interpretations. \n\n- The paper's presentation quality needs improvements.\n    \n  - Some concepts are articulated in an imprecise, non-rigorous manner. For example, the phrase \u201cbreak in the right way\u201d from Section 2 lacks clarity.\n  - Several explanations are relegated to appendices, compromising the fluidity and comprehension of the main text. Definitions, like B.6 and B.7, are cited without main text elaboration.\n  - The excessive use of bold text and protracted informal subtitles detract the reader.\n\n[1] Osada, Genki, Tsubasa Takahashi, Budrul Ahsan, and Takashi Nishide. \"Out-of-Distribution Detection with Reconstruction Error and Typicality-based Penalty.\" In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 5551-5563. 2023."
                },
                "questions": {
                    "value": "- When the assumptions will hold and measure it empirically if possible to validate?\n- Explain the use of $\\mid || \\mu_{z} (x_{{OOD}}) \\|-r_0 \\mid$, when does this serve as a good approximate? Is this limited to methods like VAE that regularize posterior distribution of $z$?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8717/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698775917661,
            "cdate": 1698775917661,
            "tmdate": 1699637093402,
            "mdate": 1699637093402,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZSWFZlZsv9",
                "forum": "LjygLD0AkT",
                "replyto": "LsAJaYMIN9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8717/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8717/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer hPfm"
                    },
                    "comment": {
                        "value": ">The utilization of  |$\\lvert \\mu_{z}(x_{\\text{OOD}}) - r_0 \\rvert$| to approximate the distance between test and ID samples is questioned for its lack of a principled basis. If ID samples have a wide spread in in the latent space, the absence of a singular reference point makes the approximation meaningless. \n\nThank you for pointing this our and improving our rigor. We invite you to Main Response 8 to see our now fully rigorous justification. In particular, the aforementioned approximations, as in Equations 13 and 14, enjoy similar provable guarantees (Proposition B 16 and Corollary B 17) as Theorem 3.8. The gap between Equation 10 (main theorem) and Equations 13 +14 (experimental version) depends on empirically verifiable concentration phenomenon (discussed in Section 3.2, illustrated on Figure 2. In light of these observations, we also strengthen this concentration via regularization (Section 3.2)).\n\nFor the DC-VAEs we used, even without regularization, we empirically observe that the latent code concentrates. You are correct that when IID samples have a wide spread, our experiments without regularization showed minor performance degradation. But the unregularized model still delivers strong performances.\n\nTheoretically, this is related to our essential definitions. Many false statements in fact are true with high probability. The widespread latent code is an example: while the latent code norm can spread a wide range, most of them are concentrated near a narrow range. In sum, widespread latent codes might weaken an absolute logical statement to a high probability one. But it does not make it meaningless. These are experimentally verified and rigorously proved (Proposition B 16 and Corollary B 17).\n\n\n>The reliance on VAEs' regularization of the posterior on towards a Gaussian (typically zero mean) implies the technique may not be generalizable to other generative models with distinct latent variable regularization.\n\nYou are correct that the regularization is VAEs specific, but we would like to invite you to visit Main Response 4 for why our VAEs model specific techniques are useful in the present unsupervised OOD detection we consider.\nThe no free lunch principle, stating no single algorithm works the best in all cases, also discussed in Footnote 3, suggests dependence on VAEs can also be a strength, making our dependence on VAEs a double-edged sword. Whether it is a weakness or not highly depends on the applications of interest.\n\nWhen a few current SOTA sits below AUC 0.7, we are willing to trade off generality for empirical performances. Looking at Table 1, we believe taking advantage of VAEs\u2019 structural uniqueness is exactly why our empirical performances match or exceed SOTA benchmarks which are based on arguably more sophisticated models (Glow, DDPM, etc.). This implicitly shows our method is more sophisticated, since our model is much smaller. The sophistication probably comes from our model specific choice. For the present application (IID v.s. OOD), while the benefits of richer latent structures remain unclear (geometrically, we only need to carve the latent or visible spaces into IID v.s. OOD, it is less clear richer latent structure surely helps), our methods\u2019 performances are demonstrated.\n\nMoreover, as discussed previously, our performances only degraded a little without such concentration regularizations. This is because the unregularized VAEs already exhibit concentration phenomenon when VAEs have high latent dimensions, which motivates us to further strengthen it."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8717/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700722630519,
                "cdate": 1700722630519,
                "tmdate": 1700723818384,
                "mdate": 1700723818384,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0hH9uNdyQ3",
            "forum": "LjygLD0AkT",
            "replyto": "LjygLD0AkT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8717/Reviewer_tps4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8717/Reviewer_tps4"
            ],
            "content": {
                "summary": {
                    "value": "The submission #8717  presents a new perspective on out-of-distribution detection with the introduction of the \"Likelihood Path Principle\". The principle is based on the observation that traditional likelihood measures can be ineffective for OOD detection due to their reliance on static data snapshots. The authors suggest a dynamic path-wise likelihood integration method to capture the evolving nature of data distributions. \n\nThe paper asserts that this method more accurately differentiates between in-distribution (ID) and OOD samples by considering the trajectory of the likelihood as data moves from ID to OOD. To substantiate their claims, the authors provide experimental results that demonstrate an improvement over existing methods such as ODIN across several benchmarks. Additionally, they offer theoretical insights into why considering the path of likelihood can be beneficial for OOD detection."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper introduces new theoretical tools (section 2, section3) that provide a solid foundation for their proposed LPath principle and OOD detection approach. Unlike some previous work, the proposed method comes with non-asymptotic provable guarantees for OOD detection.\n\n- The paper claims state-of-the-art empirical results, suggesting a significant advancement over existing methods."
                },
                "weaknesses": {
                    "value": "- *Complexity of implementation*. While not explicitly mentioned, the introduction of new theoretical concepts might imply a more complex implementation and understanding, potentially limiting accessibility for practitioners. The author has not provided any valid implementations for reviewing.\n\n- *Dependence on VAEs*. The method's effectiveness may be highly dependent on the performance and tuning of the underlying VAEs, which can be sensitive to hyperparameters and data quality.\n\n- *Presentation*. I feel that the presentation quality of the manuscript could still be improved, especially some illustrations/figures are difficult to read.\n\nAdditionally, please refer to the \u2018Questions\u2019 section for my other potential concerns."
                },
                "questions": {
                    "value": "- What is the computational overhead introduced by the path-wise likelihood calculation, and how does it scale with the complexity of the model and the size of the dataset?\n\n- Continuing above, in high-dimensional spaces, traditional likelihood methods often struggle due to the curse of dimensionality. How does the Likelihood Path Principle mitigate these issues, and is there a threshold where the method becomes computationally infeasible?\n\n- How does the LPath algorithm perform under different types of data distributions and noise levels? How does the method handle cases where the OOD data is deliberately designed to mimic ID data, as in adversarial attacks?\n\n- Can the principles introduced in the paper be extended to other types of generative models beyond VAEs? Also, is there potential for the Likelihood Path Principle to be integrated into a wider array of model architectures beyond those tested, including unsupervised and semi-supervised learning scenarios?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8717/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699076369958,
            "cdate": 1699076369958,
            "tmdate": 1699637093293,
            "mdate": 1699637093293,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oJjkoOVCJY",
                "forum": "LjygLD0AkT",
                "replyto": "0hH9uNdyQ3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8717/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8717/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer tps4"
                    },
                    "comment": {
                        "value": "> Complexity of implementation. While not explicitly mentioned, the introduction of new theoretical concepts might imply a more complex implementation and understanding, potentially limiting accessibility for practitioners. The author has not provided any valid implementations for reviewing.\n\nWe did not provide implementations because there is dependency on private repos. We have attached a self-contained jupyter notebook that illustrates the pipeline on synthetic datasets. We would like to emphasize that although it takes some math to derive our algorithm, its implementation is simple, similar to DoSE [1] as we mentioned in the paper.\n\n\n> Dependence on VAEs. The method's effectiveness may be highly dependent on the performance and tuning of the underlying VAEs, which can be sensitive to hyperparameters and data quality.\n\nWe would like to invite you to visit Main Response 4 for our choice of VAEs based algorithm, per no free lunch principle. We believe model specific OOD detection is advantageous when a few SOTA sits below AUC 0.7. The no free lunch principle is also discussed in Footnote 3, which suggests dependence on VAEs can also be a strength, making our dependence on VAEs a double-edged sword. Whether it is a weakness or not highly depends on the applications of interest. \n\nOn one hand, you are right that this dependence makes our detection algorithm less general. On the other hand, we believe taking advantage of VAEs\u2019 structural uniqueness is exactly why our empirical performances match or exceed SOTA benchmarks which are based on arguably more sophisticated models (Glow, DDPM, etc.). This implicitly shows our method is more sophisticated, since our model is much smaller.\n\nWe note that however that the proposed LPath principle is general and orthogonal to improving VAEs. This showcases the opportunity to conduct research and improve upon the aforementioned directions independently.\n\nLast but not the least, under practical constraints, it can be difficult to further improve the quality of many generative models (e.g. their robustness to hyperparameters, etc. See Introduction, the works of Behrmann et al., 2021; Dai et al.) in practice. When we cannot further improve the underlying model, our method can still yield significant improvement on the OOD detection performance (we performed targetted experiments to empirically verify it in Table 3, Section D.1, in Appendix). We believe this is our method\u2019s added value and it is orthogonal to model improvements, and it is one of the main motivations behind this work.\n\n\n[1] Morningstar, Warren, et al. \"Density of states estimation for out of distribution detection.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2021."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8717/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700721257007,
                "cdate": 1700721257007,
                "tmdate": 1700721257007,
                "mdate": 1700721257007,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8kFK4H199L",
            "forum": "LjygLD0AkT",
            "replyto": "LjygLD0AkT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8717/Reviewer_6idB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8717/Reviewer_6idB"
            ],
            "content": {
                "summary": {
                    "value": "The paper develops a generalization of Likelihood principle that comes with provable guarantees for OOD detection in deep generative models. Applying this new principle to VAEs, the authors propose using minimal sufficient statistics for OOD detection with non asymptotic guarantees. Empirical results show the suggested approach can outperform or perform on par with other OOD detection methods in an unsupervised setting."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper analyzes different types of OOD samples and the reason behind the difficulty of some of OOD cases in a principled way. \n- It provides a theory and a simple computational approach for identifying OODs."
                },
                "weaknesses": {
                    "value": "- The intuition behind the theorem and the illustration in Figure 1 can be further improved. As the main figure of the paper which is introducing the idea, Figure 1 is not easy to follow. You need to read the paper all the way to the end of page 7 so you can understand the 4 cases and their connection to the idea presented in the paper. \n- As the authors have mentioned, Equation 10 is non-trivial to compute and an approximation is provided. The effect of the error of this approximation on the performance of the algorithm can be further studied in synthetic cases. \n- Setting the decision criteria in the proposed algorithm is non-trivial and can be further studies in the paper. \n- The fact that the method outperforms other VAE baselines but doesn\u2019t perform as well as more sophisticated baselines makes the practical usage of the method in safety critical domains less feasible."
                },
                "questions": {
                    "value": "- Minor: Fix the references to Equations 19 and 18 in section 3.2. \n- Fix \u201c\u2225x_OOD \u2212 x_OOD\u2225_2 is large\u201d on page 7\n- How does the approximation error of Equation 12 affect the performance?\n- The motivation behind the paired VAE idea in section 4 is unclear. The idea has been introduced in few lines and the reasoning behind it is deferred to the appendix. Can you either expand the motivation in the main text or move these few lines to the appendix?\n- What are the hyperparameters that are needed for the OOD decision rule? \n- Minor: I think the citations for DDPM and LMD are flipped"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8717/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699237801999,
            "cdate": 1699237801999,
            "tmdate": 1699637093170,
            "mdate": 1699637093170,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Arq4hD4gUd",
                "forum": "LjygLD0AkT",
                "replyto": "8kFK4H199L",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8717/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8717/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 6idB - I"
                    },
                    "comment": {
                        "value": "> The intuition behind the theorem and the illustration in Figure 1 can be further improved. As the main figure of the paper which is introducing the idea, Figure 1 is not easy to follow. You need to read the paper all the way to the end of page 7 so you can understand the 4 cases and their connection to the idea presented in the paper.\n\nWe thank you for pointing this out. We will work on a revised figure with modified caption to better illustrate the LPath principle.\n\n> As the authors have mentioned, Equation 10 is non-trivial to compute and an approximation is provided. The effect of the error of this approximation on the performance of the algorithm can be further studied in synthetic cases.\n\nWe believe you are referring to the gap between Equation 10 and Equations 13+14. We have now provided a more detailed justification with rigorous proofs. Equation 13 and 14 now come with similar guarantees (Proposition B 16 and Corollary B 17). The gap between Equation 10 and Equations 13+14 depends on empirically verifiable concentration phenomenon (discussed in Section 3.2, illustrated on Figure 2). In light of these observations, we also strengthen this concentration via regularization (Section 3.2).\n\n\n> Setting the decision criteria in the proposed algorithm is non-trivial and can be further studied in the paper.\n\nWe are unsure what criteria Reviewer 6idB refers to. We believe this is related to the hyperparameters needed for the OOD decision rule, in the Question section. If we are wrong, we would like to ask for more elaborations. Note that we also discussed training and inference hyperparameters/configurations in Appendix C.3. Our neural feature extraction stage (Section 4) is quite standard, except that we tune latent dimensions (Appendix B 4.2, C.3). Our second stage statistical algorithm requires no hyperparameter.\n\n> The fact that the method outperforms other VAE baselines but doesn\u2019t perform as well as more sophisticated baselines makes the practical usage of the method in safety critical domains less feasible.\n\nWe would like to emphasize that while we do not perform better in all cases, we surpass or match all others except SVHN (IID) vs CIFAR 10/VFlip/HFlip (OOD). Among these mostly widely used benchmarks, our method is at least as good as all others overall. \n\nAs for practical application in safety critical domains, we invite you to Main Response 2 for our advantage. In safety critical domains, theoretical guarantees are arguably more important in OOD detection, because in deployment, there is no way to control the streaming data. Offline validations such as the ones every paper performs are not guarantees to translate to the real world.\n\nIn contrast, as a provable method, even if we are not the best in the deployment environment, we can theoretically identify the factors that caused the degradation. The co-Lipschitz degrees (K, k) are the most difficult to estimate in practice, which is a separate topic itself. We now developed Lemma B.12 that suggests a way of estimating those, related to the adversarial robustness certification literature.\n\nFor the above reasons, we believe our method is more interpretable and reliable than other SOTA methods. We would like to hear from reviewer 6idB whether this discussion has addressed the aforementioned concern.\n\n> How does the approximation error of Equation 12 affect the performance?\n\nApproximation occurs in Equation 13 and 14, where justification heuristically is provided in Footnote 10 and fully rigorously in Proposition B 16 and Corollary B 17 in the new version. They also come with provable guarantees.\n\n> The motivation behind the paired VAE idea in section 4 is unclear. The idea has been introduced in few lines and the reasoning behind it is deferred to the appendix. Can you either expand the motivation in the main text or move these few lines to the appendix?\n\nWe thank you for improving our exposition. We propose adding the following to Section 4. The idea behind VAEs pairing is that Equation 10 in Theorem 3.8 prefers smaller K, while Equation 11 prefers bigger K. These two conditions cannot be satisfied by a single VAE, but can be achieved with a paired VAEs. More details and discussion are given in the Appendix B 4.2 and B 4.3.\n\nWe appreciate your additional thoughts on the change. Any further suggestions would be welcomed."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8717/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700720447197,
                "cdate": 1700720447197,
                "tmdate": 1700720447197,
                "mdate": 1700720447197,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]