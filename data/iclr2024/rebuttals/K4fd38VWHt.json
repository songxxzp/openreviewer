[
    {
        "title": "Assessing Robustness via Score-based Adversarial Image Generation"
    },
    {
        "review": {
            "id": "GM8zc7Imq2",
            "forum": "K4fd38VWHt",
            "replyto": "K4fd38VWHt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7774/Reviewer_4m9f"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7774/Reviewer_4m9f"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes ScoreAG, a novel method that leverages score-based generative model to find adversarial samples. State-of-the-art methods can generate examples under the l-p-norm constraints, but such adversarial examples may be unrealistic due to the ignorance of semantic difference. To overcome these, the proposed ScoreAG introduces the diffusion models into adversarial example generation. Such score-based method is evaluated on CIFAR and TinyImagenet in its capability to synthesise from scratch, transform existing ones and purification to counter attack. Their results reveal that ScoreAG outperforms baselines in attacking effectiveness and defence competence after adversarial purification."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "By introducing ScoreAG, the authors bridge the gap between adversarial attack methods and score-based generative models. This intersection is not only innovative but also timely. In contrast to the limitations seen with traditional l_p norm-based methods, ScoreAG addresses the key issue of ignoring semantic shifts during image classification tasks. This addresses a crucial gap in existing methods, ensuring that adversarial examples remain contextually relevant and semantically consistent. \n\nMoreover, the flexibility of ScoreAG is evident in its ability to not only generate adversarial examples from pre-existing images but also to craft them from scratch. This versatility extends to its capability to purify blurry/noised samples, further emphasizing its practical utility. \n\nBy ensuring that ScoreAG aligns closely with real-world scenarios, the authors have underscored the framework's potential impact, emphasizing its relevance in practical settings. Overall, ScoreAG, unites diffusion models and adversarial attack, and offers tangible solutions for semantic-preserving image alterations."
                },
                "weaknesses": {
                    "value": "Interaction between Different Tasks: The authors could explore and elucidate the interactions between different tasks such as GAS, GAT, and purification. Specifically, it would be insightful to understand the impact of applying purification post-GAS or GAT. A discussion on whether purification enhances the robustness of the adversarial examples generated by GAS or GAT would be valuable. This could provide readers with a deeper understanding of the potential synergies or trade-offs between these tasks.\n\nSemantic Preservation: The paper could benefit from a clearer explanation and justification of the semantic requirements (\u03a9) used in the experiments. The methodology and criteria used to ensure semantic coherence and relevance in the generated adversarial examples should be thoroughly discussed. Consider discussing and comparing the semantic perturbations introduced by ScoreAG with those from other image-based semantic perturbation adversarial attack methods, such as the one mentioned (\"SemanticAdv: Generating Adversarial Examples via Attribute-conditioned Image Editing\"). Including detailed results or comparisons concerning semantic preservation could bolster the reliability and credibility of the proposed method.\n\nComparative Analysis in Human Study:  The human study results presented in Table 4 only focus on ScoreAG without including comparisons with the baseline methods used in other parts of the evaluation. For a more comprehensive understanding and evaluation, it would be beneficial to include a comparative analysis showcasing the performance of ScoreAG against other established methods. Consider including a discussion on the variance in naturalness or the extent of perceptual shifts observed across different methods. This could provide a more nuanced view of ScoreAG\u2019s performance in maintaining image naturalness while generating adversarial examples. \n\nOverall, while the paper presents an innovative approach in ScoreAG and provides a comprehensive set of experiments, there are areas where it could go deeper in comparative analysis, semantic preservation, and the discussion on task interactions."
                },
                "questions": {
                    "value": "- Could you provide results and discussions comparing ScoreAG to other baseline methods in the human study section?\n\n- Could you elaborate on the relationship between different tasks such as GAS, GAT, and purification within the ScoreAG framework? Can they be integrated into an ensemble for attack or defense?\n\n- How does ScoreAG ensure that the generated adversarial examples maintain semantic coherence and relevance?\n\n- Could you elaborate the perceptual shifts or changes in the naturalness of adversarial images from ScoreAG compared to other methods?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7774/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7774/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7774/Reviewer_4m9f"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7774/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698682559543,
            "cdate": 1698682559543,
            "tmdate": 1699636949905,
            "mdate": 1699636949905,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "BUng2hW8yM",
                "forum": "K4fd38VWHt",
                "replyto": "GM8zc7Imq2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7774/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7774/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for their constructive and valuable feedback. In the following, we address their remarks and questions.\n\n**Comment:** Could you elaborate on the relationship between different tasks such as GAS, GAT, and purification within the ScoreAG framework? Can they be integrated into an ensemble for attack or defense?  \n**Response:** In our framework, GAS and GAT are different forms of diffusion-based attacks, and GAP is a diffusion-based defense. The purification task GAP can be applied to defend against attacks generated by GAS and GAT. In Tab. 2, we show the performance of GAT on GAP. For convenience, we show it in the following table with the accuracy of GAS on GAP.\n\n| Method | GAT | GAS |\n| ------ | -------- | -------- |\n| GAP    | $90.74 \\pm 0.67$ | $83.14\\pm 1.50$     |\n\nGAP is capable of successfully defending against both attacks, GAT and GAS. \n\n\n**Comment:** How does ScoreAG ensure that the generated adversarial examples maintain semantic coherence and relevance?  \n**Response:** ScoreAG ensures the semantic coherence and relevance of generated adversarial images through two key mechanisms. Firstly, we employ a class-conditional score function, i.e., $\\nabla\\_{\\mathbf{x}\\_t}\\log p\\_{t,y^*} (\\mathbf{x}\\_t)$ (see Eq. 7), ensuring that the adversarial images retain the semantic attributes of the target class $y^*$. Secondly, the guidance term, i.e., $\\nabla\\_{\\mathbf{x}\\_t}\\log p\\_{t,y^*}(\\mathbf{x}^*,f(\\mathbf{x}\\_0)=\\tilde{y}|\\mathbf{x}\\_t)$ (see Eq. 7) ensures that the generated image preserves core-semantics of $x^*$ and is classified as $\\tilde{y}$. Together, these two mechanisms generate semantic-preserving adversarial images of $x^*$.\n\n**Comment:** Could you provide results and discussions comparing ScoreAG to other baseline methods in the human study section?  \n**Response:** To ensure semantic preservation, we extended the evaluation of ScoreAG with a human evaluation. While we agree that these results would be interesting for other methods, human studies have significant financial costs, and thus, we think it is the responsibility of the corresponding authors to provide these. Hence, due to financial constraints, it is not feasible for us to include other baselines.\n\n**Comment:** Could you elaborate on the perceptual shifts or changes in the naturalness of adversarial images from ScoreAG compared to other methods?  \n**Response:** Existing works show that diffusion models are able to capture the diversity of the training distribution [1, 2]. Furthermore, we show that our synthetic adversarial attacks have a competitive FID, indicating a high similarity between the adversarial synthetic images and real images. We can also observe a high degree of realism and diversity in our qualitative examples.\n\nWe thank the reviewer again for their comments and feedback. We hope that we have satisfactorily answered the reviewer's questions. If you have any open concerns, please let us know.\n\n[1] **Bayat, Reza.** \"A Study on Sample Diversity in Generative Models: GANs vs. Diffusion Models.\" (2023).\n\n[2] **Dhariwal, Prafulla, and Alexander Nichol.** \"Diffusion models beat gans on image synthesis.\" Advances in neural information processing systems 34 (2021): 8780-8794."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700338360308,
                "cdate": 1700338360308,
                "tmdate": 1700338360308,
                "mdate": 1700338360308,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GYYSrLHiMb",
                "forum": "K4fd38VWHt",
                "replyto": "BUng2hW8yM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7774/Reviewer_4m9f"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7774/Reviewer_4m9f"
                ],
                "content": {
                    "comment": {
                        "value": "Dear authors,\n\nThank you for you answers and the clarification.\n\nI would suggest describing semantic coherence in more details in the paper, perhaps with short experiments to illustrate the correlation between the two terms and the claimed semantic preservation.\n\nI do not understand your answer regarding human study. Your answer states that  \"it is the responsibility of the corresponding authors to provide these (financial costs)\". Isn't the corresponding author among you? I would also argue that there are means to conduct simple human studies at reasonable cost, especially when it is only about comparing images."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700722299796,
                "cdate": 1700722299796,
                "tmdate": 1700722299796,
                "mdate": 1700722299796,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bMbcJSBPvS",
                "forum": "K4fd38VWHt",
                "replyto": "rCvyiXIZp4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7774/Reviewer_4m9f"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7774/Reviewer_4m9f"
                ],
                "content": {
                    "comment": {
                        "value": "I previously misunderstood what you meant by \"the corresponding author\". I know understand that you mena the authors of the previous work. Thanks for the clarification."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740076578,
                "cdate": 1700740076578,
                "tmdate": 1700740076578,
                "mdate": 1700740076578,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wzs38xUdTT",
                "forum": "K4fd38VWHt",
                "replyto": "bMbcJSBPvS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7774/Reviewer_4m9f"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7774/Reviewer_4m9f"
                ],
                "content": {
                    "comment": {
                        "value": "Regarding the human study, I appreciate the fact that they can be costly. A reasonable compromise is to conduct a smaller study on the baselines. This would provide supporting evidence that the score-based approach preserves semantics better than the compared baselines."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700741303400,
                "cdate": 1700741303400,
                "tmdate": 1700741303400,
                "mdate": 1700741303400,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "2rwAQN0voA",
            "forum": "K4fd38VWHt",
            "replyto": "K4fd38VWHt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7774/Reviewer_rCh2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7774/Reviewer_rCh2"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes ScoreAG, a framework for generating unrestricted adversarial examples using score-based generative models with diffusion guidance. The key idea is to leverage the generative capabilities of these models to synthesize new adversarial images from scratch (GAS), transform existing images into adversarial ones (GAT), and purify images to enhance classifier robustness (GAP)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well-written and the proposed method is novel. Generating semantic-preserving adversarial examples beyond standard threat models is an important research direction, and the use of score-based diffusion models is a promising approach. The experiments are extensive, comparing ScoreAG to several state-of-the-art attacks and defenses across multiple datasets. The results demonstrate ScoreAG's effectiveness in crafting unrestricted adversarial examples."
                },
                "weaknesses": {
                    "value": "- The notion of \"unrestricted\" adversarial examples needs more discussion. While ScoreAG does not use an explicit lp norm, the samples are still constrained to the manifold learned by the generative model. Analyzing the diversity/range of examples is important.\n\n- More analysis is needed on why ScoreAG outperforms the other diffusion-based attack DiffAttack. The reasons are not fully clear.\n\n- The lack of certified or provable robustness guarantees for the purified models is a limitation. Evaluating security empirically is difficult.\n\n- The human study provides useful insights but is limited in scope. Expanding this to quantify semantic similarity and diversity of examples would strengthen the evaluation.\n\n- Lacking important references like \"Content-based Unrestricted Adversarial Attack\""
                },
                "questions": {
                    "value": "see weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7774/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698740521919,
            "cdate": 1698740521919,
            "tmdate": 1699636949785,
            "mdate": 1699636949785,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MpnWKpiXlY",
                "forum": "K4fd38VWHt",
                "replyto": "2rwAQN0voA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7774/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7774/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We want to thank the reviewer for their feedback and questions. In the following, we address their comments.\n\n**Comment:** Notion of \"unrestricted\" needs more discussion. Samples are still constrained to the manifold learned by the generative model. Analyzing the diversity/range of examples is important.  \n**Response:** \nWe use the term \"unrestricted\" to emphasize that the adversarial attacks generated by ScoreAG are not bounded by any common $\\ell_p$-norm. Thereby, we maintain a consistent terminology with related work [1, 2]. As correctly pointed out by the reviewer, it is important to clarify that while ScoreAG transcends traditional $\\ell_p$-norm constraints, it still operates within the learned manifold of the generative model. This approach aligns with our goal of creating adversarial examples that are semantically meaningful and realistic rather than strictly adhering to normative limitations. We clarified this in the updated manuscript.\n\n**Comment:** Why does ScoreAG outperform DiffAttack?  \n**Response:** While the ScoreAG and DiffAttack have many differences, we assume ScoreAG's key advantage is the ability to go through the whole latent space by utilizing diffusion guidance, while DiffAttack is limited to the last few steps. To verify this empirically, we compare how the performance of ScoreAG changes in the GAT setting when only denoising the last few steps.\n\n\n\n| Full reverse | 5 reverse steps | 10 reverse steps | 20 reverse steps |\n| -------- | -------- | -------- | ---- |\n| 0.0     | 0.28     | 0.21     | 0.09 |\n\nThe table shows the accuracy after applying GAT on the first 100 images of Cifar-10. As expected, 5 and 10 reverse steps, i.e., the values used by DiffAttack, are not sufficient for a successful attack.\n\n\n**Comment:** Lack of certifiable robustness is a limitation.  \n**Response:** We now calculated certifiable robustness using randomized smoothing. See the general comment for more information.\n\n**Comment:** The human study is limited in scope. Expanding this to quantify semantic similarity and diversity of examples would strengthen the evaluation.  \n**Response:** We agree with the reviewer that quantifying semantic similarity and diversity of the adversarial examples are important but not trivial as well. In our human study, we implicitly quantify similarity by capturing the semantic preservation through the human accuracy. For the GAT task, the human accuracy reaches 94%, implying semantic preservation of the images. The diversity, however, is correlated with the capabilities of the generative model and the dataset itself. We quantify the diversity of the generative model using the FID score in Fig.4 (left). \n\n**Comment:** Missing references to unrestricted methods.  \n**Response:** We thank the reviewer for that reference. We added it in the updated manuscript. \n\nWe thank the reviewer again for their comments and feedback. We hope that we have satisfactorily answered the reviewer's comments. If you have any open concerns, please let us know.\n\n[1] **Chen, Jianqi, Hao Chen, Keyan Chen, Yilan Zhang, Zhengxia Zou, and Zhenwei Shi.** \"Diffusion Models for Imperceptible and Transferable Adversarial Attack.\" arXiv preprint arXiv:2305.08192 (2023).\n\n[2] **Song, Yang, Rui Shu, Nate Kushman, and Stefano Ermon.** \"Constructing unrestricted adversarial examples with generative models.\" Advances in Neural Information Processing Systems 31 (2018)."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700337820394,
                "cdate": 1700337820394,
                "tmdate": 1700337820394,
                "mdate": 1700337820394,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZLDUYCGbDw",
            "forum": "K4fd38VWHt",
            "replyto": "K4fd38VWHt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7774/Reviewer_dx4f"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7774/Reviewer_dx4f"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a novel framework called Score-Based Adversarial Generation (ScoreAG) for generating adversarial examples beyond the constraints of $\\ell_p$-norms. The authors leverage advancements in score-based generative models to synthesize semantic-preserving adversarial examples, transform existing images into adversarial ones, and purify images to achieve adversarial robustness. They conduct an empirical evaluation on CIFAR-10, CIFAR-100, and TinyImageNet datasets to demonstrate the effectiveness of ScoreAG."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The main contribution of this paper is the introduction of Score-Based Adversarial Generation (ScoreAG) and the following three uses of it: Synthesis (Generative Adversarial Synthesis, GAS), transformation (Generative Adversarial Transformation, GAT), and purification (Generative Adversarial Purification, GAP). This paper is well-structured and the method is described clearly."
                },
                "weaknesses": {
                    "value": "This work is subject to several weaknesses that need to be addressed. \n\n1. Although GAS aims to generate the adversarial example from scratch that would be misclassified by the classifier while preserving the semantics of the truth class, it is disappointing to see that even human fails to classify the adversarial examples. As shown in Table 4, Human accuracy on the adversarial synthetic images is only 70%, this results do not support the argument that it preserves the semantics of a certain class. \n\n2. The paper argues that GAS provides a more *comprehensive robustness assessment*, but lacks quantitative results to support this assertion. \n\n3. A comparison with similar work [1] should be provided, along with an explanation of the differences in approach and findings. \n\n4. GAT transforms clean images into adversarial examples, but the comparison is limited to DiffAttack. Including other unrestricted attacks [2, 3, 4] in the comparison would provide a more thorough assessment. Additionally, reporting the mean and standard deviation for the results would enhance statistical robustness.\n\n5. It is unclear what the \"ScoreAG\" column represents in Table 2. If it indicates GAP, it is unclear what the given adversarial image ($\\mathbf{x}_\\text{ADV}$) is used to purify. If it is GAT, isn\u2019t the higher robust accuracy representing the weaker attack efficacy? Further clarifications are needed to understand the evaluation\n\n6. The robustness results (Table 2) should be compared with more baselines, including both attacks and defenses, such as DiffAttack and [1, 2, 3, 4]. Additionally, results should be reported for all datasets, not just CIFAR-10, to provide a comprehensive view.\n\n7. The claim that GAP further enhances the adversarial robustness of the model is not sound. Since, generally, adversarial robustness is to evaluate the model\u2019s accuracy under perturbations, the purification seems to serve merely as a defense approach. Therefore, it should be compared with other adversarial defense methods, such as [5, 6].\n\n8. In Section 4.2, the author argues that the $\\ell_p$-bounded methods display noticeable noisy fragments. However, I think it is because of cherry-picking. Also, I do not understand where the statement \u201c*the removal of a small fish \u2014 which prove to be important classification cues*\u201d comes from.\n\n9. The authors did not submit the code for review. If the authors want to avoid releasing publicly before acceptance, submitting to AC privately is a viable option.\n\n10. The practical application of the proposed approach should be discussed. How can it be used in real-world scenarios? How is it different from other approaches in practice?\n\n11. The visualization on ImageNet seems to have high quality, it would be great to report the experimental results on it to demonstrate the generalizability of the proposed approach.\n\n>   [1] Chen et al. AdvDiffuser: Natural Adversarial Example Synthesis with Diffusion Models (ICCV 2023)\n> \n>   [2] Hsiung et al. Towards Compositional Adversarial Robustness: Generalizing Adversarial Training to Composite Semantic Perturbations (CVPR 2023)\n>\n>   [3] Laidlaw et al. Perceptual Adversarial Robustness: Defense Against Unseen Threat Models (ICLR 2021)\n>\n>   [4] Bhattad et al. Unrestricted adversarial examples via semantic manipulation (ICLR 2020)\n>\n>   [5] Frosio and Kautz. The Best Defense is a Good Offense: Adversarial Augmentation against Adversarial Attacks (CVPR 2023)\n>\n>   [6] Cohen et al. Certified Adversarial Robustness via Randomized Smoothing (ICML 2019)"
                },
                "questions": {
                    "value": "Please refer to the weakness. In addition, please also address the following questions.\n\n1. Table 1 only considers one model architecture (WRN-28-10), please provide more models to verify the efficacy of the proposed method.\n2. What is the computational cost of ScoreAG compared to other methods?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7774/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698792681449,
            "cdate": 1698792681449,
            "tmdate": 1699636949680,
            "mdate": 1699636949680,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5yOuS09aI2",
                "forum": "K4fd38VWHt",
                "replyto": "ZLDUYCGbDw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7774/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7774/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for their valuable feedback. In the following, we address their raised concerns.\n\n**Comment:** Human accuracy on the adversarial synthetic images is only 70%.  \n**Response:** The generative adversarial transformations (GAP) achieve an almost perfect human accuracy of 94%, equal to the accuracy on the non-adversarial synthetic images. This indicates that the adversarial attack does not degrade the semantic coherence for humans. We respectfully disagree with the reviewer that humans fail to classify the synthetic adversarial images. This is a novel task, and the human accuracy is 70%, which is 60% higher than guessing, implying a success. We expect future work to further improve these results with the development of better generative models. \n\n**Comment:** Lack of quantitative results for the claim of a *more comprehensive robustness assessment*.  \n**Response:** GAS and GAT conceptually provide a more comprehensive robustness assessment than $\\ell_p$-bounded adversarial attacks, as (i) all semantic-preserving adversarial examples within the $\\ell_p$-balls are part of GAS and GAT given a reasonably trained generative model, and (ii) further incorporate semantic-preserving adversarial examples not captured by common $\\ell_p$-threat models. Therefore, our claim of a more comprehensive robustness assessment stems from the inherent capability of GAS and GAT to cover a wider spectrum of adversarial examples, including those restricted by $\\ell_p$-norm constraints. We want to note that we do not necessarily see GAS and GAT as a replacement for traditional attack methods but as complementary to explore semantic-preserving areas that are not included in common $\\ell_p$-balls.\n\n**Comment:** Comparison with similar work should be provided.   \n**Response:** We would like to thank the reviewer for the interesting reference. However, as the referenced paper was only recently published at ICCV2023, we would like to remind the reviewer that this work is categorized as concurrent under ICLR guidelines: \n> We consider papers contemporaneous if they are published (available in online proceedings) within the last four months. That means, since our full paper deadline is September 28, if a paper was published (i.e., at a peer-reviewed venue) on or after May 28, 2023, authors are not required to compare their own work to that paper. \n\nHowever, we include a discussion of it in the related work section. Unfortunately, we are not able to include it in our experiments, as the code is not publicly available yet.\n\n**Comment:** Unclear what Table 2 represents.  \n**Response:** The column labeled \"ScoreAG\" represents the attack GAT, while the corresponding row represents the purification GAP. We added this information to the table. While GAT aims to achieve a low robust accuracy, GAP aims to achieve a high accuracy. GAT achieves a slightly better accuracy than APGD and APGDT in many cases, implying a more comprehensive robustness assessment."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700338791542,
                "cdate": 1700338791542,
                "tmdate": 1700494371846,
                "mdate": 1700494371846,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "35bXXxf34c",
                "forum": "K4fd38VWHt",
                "replyto": "ZLDUYCGbDw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7774/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7774/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Comment:** Table 1 and Table 2 should contain more baselines, classifiers, and standard deviations.  \n**Response:** We added standard deviations to Table 1 and Table 2. Furthermore, we now added two more attacks to Table 1, resulting in a total of 13 (excluding ScoreAG) evaluated attacks. Additionally, we also added four more classifiers evaluated on ScoreAG (GAT) to further demonstrate its efficacy. The following table shows the adversarial accuracy of GAT in % using the same hyperparameters as for the WRN-28-10 architecture.\n\n| Classifier | Cifar-10 | Cifar-100 |\n| -------- | -------- | -------- |\n| ResNet-20 | 0.01 | 0.10     |\n| ResNet-56 | 0.03 | 0.13     |\n| VGG-19 | 0.52 |  1.94  |\n| RepVGG-A2 | 0.04 | 0.26 |\n\nNote that the models are obtained from PyTorch Hub. Therefore, we cannot report standard deviations. As we can observe, ScoreAG successfully generates adversarial attacks using different classifiers. We added these results to the updated manuscript.\n\nIn Table 2, we already compare ScoreAG to six state-of-the-art defenses and purification methods. However, we added an additional comparison to evaluate the certified robustness of GAP and randomized smoothing (see general comment). Note that the purification experiments require unconditional generative models as the ground-truth class labels are unknown. Therefore, our purification experiments are focused on the CIFAR-10 dataset, given the availability of unconditional pre-trained EDM models and extensive prior work [1, 2].\n\n\n**Comment:** Authors claim that $\\ell_p$-bounded methods display noticeable noisy fragments. Was it cherry-picking? Also, where does the *the removal of a small fish* statement come from?  \n**Response:** The images were not cherry-picked, and we observed the same noisy fragments across all samples. [We uploaded more **randomly chosen** example images for APGD, APGDT, Square, and ScoreAG to Figshare.](https://figshare.com/s/117b453e5289311df4c7) The importance of the removal of the small fish refers to Fig. 1a and 1b, meaning the observation that many of the images generated by ScoreAG remove or modify the fish next to the shark (representing the image class) in the image.\n\n**Comment:** Practical application of ScoreAG.  \n**Response:** ScoreAG only requires a pre-trained score-based generative model and the gradients of a classifier. Therefore, it can be applied in any scenario where other attacks are currently used. Furthermore, traditional $\\ell_p$-threat models often do not capture important semantics-preserving corruption relevant to real-world applications [3, 4, 5]. As ScoreAG effectively overcomes this limitation, it can be highly interesting for evaluating robustness in real-world scenarios. \n\n**Comment:** Why are there no experimental results on ImageNet?  \n**Response:** Many methods in our comparison already reach a near-perfect success rate on TinyImageNet, which is a subset of ImageNet. As ImageNet contains five times as many labels and a higher resolution, it is an easier target. However, we included ImageNet in our qualitative evaluation due to its high resolution.\n\n**Comment:** What is the Runtime of ScoreAG?  \n**Response:** We added a runtime comparison to other baselines and the EDM generative model itself. See the general comment for more information.\n\nWe again thank the reviewer for their comments and hope that we satisfactorily addressed them. If not, we are happy to address any remaining concerns.\n\n[1] **Wang, Zekai, Tianyu Pang, Chao Du, Min Lin, Weiwei Liu, and Shuicheng Yan.** \"Better diffusion models further improve adversarial training.\" arXiv preprint arXiv:2302.04638 (2023).\n\n[2] **Karras, Tero, Miika Aittala, Timo Aila, and Samuli Laine.** \"Elucidating the design space of diffusion-based generative models.\" Advances in Neural Information Processing Systems 35 (2022): 26565-26577.\n\n[3] **Eykholt, Kevin, Ivan Evtimov, Earlence Fernandes, Bo Li, Amir Rahmati, Chaowei Xiao, Atul Prakash, Tadayoshi Kohno, and Dawn Song.** \"Robust physical-world attacks on deep learning visual classification.\" In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1625-1634. 2018.\n\n[4] **Kar, O\u011fuzhan Fatih, Teresa Yeo, Andrei Atanov, and Amir Zamir.** \"3d common corruptions and data augmentation.\" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 18963-18974. 2022.\n\n[5] **Hendrycks, Dan, Nicholas Carlini, John Schulman, and Jacob Steinhardt.** \"Unsolved problems in ml safety.\" arXiv preprint arXiv:2109.13916 (2021)."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700338797889,
                "cdate": 1700338797889,
                "tmdate": 1700494467438,
                "mdate": 1700494467438,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "UY8qAi5a0K",
            "forum": "K4fd38VWHt",
            "replyto": "K4fd38VWHt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7774/Reviewer_3Sog"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7774/Reviewer_3Sog"
            ],
            "content": {
                "summary": {
                    "value": "This work presents a framework, ScoreAG, designed for adversarial example generation beyond \\mathcal{l}_{p}-norm constraints. By integrating Score-based Generative Modelling with Diffusion Guidance techniques, ScoreAG effectively addresses the limitations of conventional adversarial generation approaches. By applying various conditional guidance terms in the reverse-time SDE process, ScoreAG can 1) synthesize adversarial images (GAS), 2) transform adversarial images (GAT), and 3) purify adversarial images (GAP). Experimental results show that ScoreAG can outperform leading benchmarks in adversarial attack and defense, generating adversarial examples while preserving their original semantic meaning."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper is well-organized and easy to follow.\n\n2. Conducting adversarial attacks using semantic-bounded examples offers an interesting viewpoint on robustness evaluation.\n\n3. As demonstrated in the experimental section, the proposed framework attains promising performance across three tasks."
                },
                "weaknesses": {
                    "value": "1. Some formulas in this paper were derived incorrectly, such as equation 7 on page 4. The authors should check the methodology section to ensure correctness.\n\n2. The authors compare the attack effectiveness of GAT with other benchmark methods in Section 4.1. Given that generation efficiency is also an essential factor in evaluating the effectiveness of adversarial attacks, it is recommended that the authors add a discussion on the efficiency of adversarial sample generation to this part of the experiment.\n\n3. In Table 2, the evaluation results are displayed for Cifar-10. To ensure the applicability of the proposed method, evaluations on datasets of more categories or higher resolution, such as Cifar-100 and TinyImageNet, are advisable. Experimental results in Table 2 also compare the efficacy of various adversarial training and purification methods. However, the distinct architectures used by these methods raise concerns about the fairness of this comparison.\n\n4. This paper lacks details of the experimental implementation environments, which limits the reproducibility of the proposed method.\n\n5. As pointed out in Section 4.3, some misclassification cases are due to the low resolution of Cifar-10\u2019s images, indicating that employing higher-resolution datasets for testing would have been more appropriate."
                },
                "questions": {
                    "value": "1. How time-efficient is the method you\u2019ve proposed?\n\n2. With the distinct architectures used by methods presented in Table 2, can we still view this comparison as fair?\n\n3. Why not use images from higher-resolution datasets for testing in Section 4.3?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7774/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698827530095,
            "cdate": 1698827530095,
            "tmdate": 1699636949549,
            "mdate": 1699636949549,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YN94z46EGX",
                "forum": "K4fd38VWHt",
                "replyto": "UY8qAi5a0K",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7774/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7774/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We want to thank the reviewer for their constructive and valuable feedback. In the following, we address their remarks and questions.\n\n**Comment:** Equation 7 is incorrect.  \n**Response:** We corrected the typo in the new manuscript.\n\n**Comment:** Table 2 does not include Cifar-100 and TinyImagenet. Architectures are different for various methods; is the comparison fair?  \n**Response:** Our method uses the WRN-28-10, a widely used architecture for adversarial attacks and robustness. To make a fair comparison, we selected the best models using the same architecture and the best models overall, which use the WRN-70-16 architecture. Therefore, this is a biased comparison in favor of the WRN-70-16 architectures and the baselines. Note that the purification experiments require unconditional generative models as the ground-truth class labels are unknown. Therefore, our purification experiments are focused on the CIFAR-10 dataset, given the availability of unconditional pre-trained EDM models and extensive prior work [1, 2].\n\n**Comment:** Why not use higher-resolution datasets for the human study?  \n**Response:** While selecting the dataset for the human trial, we prioritized maintaining the participant's accessibility, attention, and engagement. Moreover, datasets such as ImageNet contain classes that require specialized domain knowledge, e.g., \"barn spider\" and \"garden spider\". Although selecting a subset of ImageNet classes is an option, we ultimately decided against it to avoid introducing selection bias, which could skew the study's outcomes. This led us to select a dataset with a limited number of classes.\n\n**Edit (20.11):**\n\n**Comment:** Lack of details of the experimental implementation environment.  \n**Response:** We added a reproducibility statement and uploaded the code of ScoreAG. See the general comment for more information.\n\n**Comment:** What is the runtime of ScoreAG?  \n**Response:** We added a runtime comparison to the appendix. For more details, see the general comment.\n\nWe thank the reviewer again for their comments and feedback. We hope that we have satisfactorily answered the reviewer's questions. If you have any open concerns, please let us know.\n\n[1] **Wang, Zekai, Tianyu Pang, Chao Du, Min Lin, Weiwei Liu, and Shuicheng Yan.** \"Better diffusion models further improve adversarial training.\" arXiv preprint arXiv:2302.04638 (2023).\n\n[2] **Karras, Tero, Miika Aittala, Timo Aila, and Samuli Laine.** \"Elucidating the design space of diffusion-based generative models.\" Advances in Neural Information Processing Systems 35 (2022): 26565-26577."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700337745094,
                "cdate": 1700337745094,
                "tmdate": 1700505343302,
                "mdate": 1700505343302,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QhX3fkbenT",
                "forum": "K4fd38VWHt",
                "replyto": "YN94z46EGX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7774/Reviewer_3Sog"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7774/Reviewer_3Sog"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response. Most of my concerns have been addressed. However, for the human study, even a small-scale experiment on a higher-resolution dataset would significantly strenghthen the soundness of this paper."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740335389,
                "cdate": 1700740335389,
                "tmdate": 1700740335389,
                "mdate": 1700740335389,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]