[
    {
        "title": "DER-Solomon: A Large Number of CVRPTW Instances Generated Based on the Solomon Benchmark Distribution"
    },
    {
        "review": {
            "id": "nG22VJO0CI",
            "forum": "HTH3HnJeRC",
            "replyto": "HTH3HnJeRC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission875/Reviewer_D9sp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission875/Reviewer_D9sp"
            ],
            "content": {
                "summary": {
                    "value": "This is a dataset and benchmarking paper. The author proposes DER-Solomon, an expanded CVRPTW dataset, by approximating the original Solomon dataset with backward derivation. Experiments are conducted on traditional and DL-based algorithms to demonstrate its merits."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* Compared with Solomon-like datasets, the proposed method could better approximate the original Solomon dataset.\n* The proposed dataset has values for further research in CVRPTW."
                },
                "weaknesses": {
                    "value": "* The practicality is not clear. \n  * Is there any evidence to demonstrate that, with only 56 instances, the original Solomon benchmark is complex enough to test *all aspects* of (traditional or DL-based) algorithms? If a company trains a DL-based model on DER-Solomon, could we guarantee its reliability in practice?\n  * Besides Solomon, is the proposed method generalizable to approximate other datasets?\n* It seems only the distribution of the time window is approximated. However, other attributes, such as the customer location, may significantly affect the learned policy as well. Have you considered the variations of all attributes in DER-Solomon?\n* For the traditional algorithms, it would be better to add HGS. For the DL-based method, some recent studies [1, 2] demonstrate superior performance on CVRPTW, it would be better to benchmark them as well.\n* The provided link to the source code cannot be opened.\n* The writing and presentation of this paper should be improved:\n  * All figures should use PDF format. The current version is blurry when zooming in.\n  * Better to provide some visualizations of the generated instances.\n  * The best result (e.g., in all tables) should be in bold for a better view.\n\n[1] Learning to delegate for large-scale vehicle routing. In NeurIPS 2021.   \n[2] RBG: Hierarchically solving large-scale routing problems in logistic systems via reinforcement learning. In KDD 2022.\n\n----\n\n**Overall,** this paper only focuses on *one dataset of a single problem (i.e., CVRPTW)*, and therefore the contribution may not be enough for ICLR. Currently, I lean towards rejection, and I may adjust the evaluation after reading other reviews and the author's rebuttal."
                },
                "questions": {
                    "value": "* Will you release the source code and datasets?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission875/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697635222901,
            "cdate": 1697635222901,
            "tmdate": 1699636014032,
            "mdate": 1699636014032,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9eL2B57qHB",
                "forum": "HTH3HnJeRC",
                "replyto": "nG22VJO0CI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission875/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission875/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer D9sp"
                    },
                    "comment": {
                        "value": "Thank you for your helpful comments and great efforts in helping improve our work. The responses to your comments are listed as follows.\n\n> Q1. The practicality is not clear: Is there any evidence to demonstrate that, with only 56 instances, the original Solomon benchmark is complex enough to test all aspects of (traditional or DL-based) algorithms? If a company trains a DL-based model on DER-Solomon, could we guarantee its reliability in practice?\n\nA1. Thank you for your insightful comments. It\u2019s challenging to directly apply the model trained on the Solomon benchmark to real-world problems. We need to further collect real-world data and use our method to expand the collected data as training instances. Since most traditional algorithms demonstrate their performance on the Solomon benchmark, our work in this paper mainly constructs a dataset for training so that DRL algorithms can also show their inherent performance on the Solomon benchmark. This allows for a fair comparison between traditional algorithms and DRL algorithms, accelerating algorithm research in this field.\n> Q2. Is the proposed method generalizable to approximate other datasets?\n\nA2. Thank you for your helpful comments. We have included additional expanded instances, validated through a comparison experiment on the Homberger benchmark, in the appendix of the updated manuscript. In the final version of the paper, we will add approximations for most of the public test benchmark in the VRP field. Due to time limits, experiments on them will be gradually released in the open-source code.\n\n> Q3. It seems only the distribution of the time window is approximated. However, other attributes, such as the customer location, may significantly affect the learned policy as well. Have you considered the variations of all attributes in DER-Solomon?\n\nA3. Thank you for your thoughtful comments. We did take into account the point you raised, but we concluded that for a DRL method, it is not necessary to account for variations in customer coordinates between instances of the same series in the Solomon benchmark, as they remain fixed.\n\n> Q4. For the traditional algorithms, it would be better to add HGS. For the DL-based method, some recent studies [1, 2] demonstrate superior performance on CVRPTW, it would be better to benchmark them as well.\n\nA4. Thank you for your thoughtful comments. Both papers used HGS, thus, we believe it should be a very useful solver. However, we noticed that HGS only has CVRP code implementation, and we are unsure whether it can be applied to CVRPTW. Article [1] is a great work, and the key is that there is a source code implementation. The README file is written in great detail, and the author have put a lot of effort into it. Thank you very much for recommending this article. We are very willing to use this algorithm in our experiment. Article [2] is also a great work, but we do not know whether it has source code published. If no source code is published and the author has not published the experimental results of the algorithm on the Solomon benchmark, it is challenging to conduct an experiment on it.\n\n> Q5. The provided link to the source code cannot be opened.\n\nA5. Thank you for your insightful comments. Please compare the link you entered into the browser with the link in the pdf file. Because the underscore \u201c_\u201d may be lost during the pasting process, we made a reminder at the first source code reference on page 7 of the article."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission875/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700485075350,
                "cdate": 1700485075350,
                "tmdate": 1700485075350,
                "mdate": 1700485075350,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QbKf6xUrt0",
                "forum": "HTH3HnJeRC",
                "replyto": "9eL2B57qHB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission875/Reviewer_D9sp"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission875/Reviewer_D9sp"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Rebuttal"
                    },
                    "comment": {
                        "value": "Hi authors, thanks for your detailed responses. Please see the comments below:\n\n> We concluded that for a DRL method, it is not necessary to account for variations in customer coordinates between instances of the same series in the Solomon benchmark, as they remain fixed.\n\nIt seems that the practicality is not the first concern of this paper. Since in real-world cases, customer coordinates or demands may vary a lot. I still think considering more variations in different dimensions may improve the significance of the proposed dataset.\n\n> However, we noticed that HGS only has CVRP code implementation, and we are unsure whether it can be applied to CVRPTW.\n\nSee https://github.com/ortec/euro-neurips-vrp-2022-quickstart/tree/main/baselines/hgs_vrptw"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission875/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700535388579,
                "cdate": 1700535388579,
                "tmdate": 1700535388579,
                "mdate": 1700535388579,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Huld670tfQ",
                "forum": "HTH3HnJeRC",
                "replyto": "1B3CtLZ8V8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission875/Reviewer_D9sp"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission875/Reviewer_D9sp"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal Ack"
                    },
                    "comment": {
                        "value": "Thanks for considering my comments. Unfortunately, based on the current version, I cannot recommend acceptance. I hope the authors could further improve the presentation of the paper. Building a project page may help as well. Then, submit it to another venue (e.g., the benchmark track of NeurIPS)."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission875/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700631299861,
                "cdate": 1700631299861,
                "tmdate": 1700631299861,
                "mdate": 1700631299861,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "PGfe7S5AOU",
            "forum": "HTH3HnJeRC",
            "replyto": "HTH3HnJeRC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission875/Reviewer_c63s"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission875/Reviewer_c63s"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies to use deep reinforcement learning to solve the classic optimization problem of capacitated vehicle routing problem with time windows. To make DRL possible, the paper proposes to create a training dataset that is based on the Solomon dataset that is small but comprehensive to test algorithms for CVRPTW problem. The paper creates the new DER-Solomon dataset by first estimating the probability distributions of the essential parameters of the Solomon dataset and then generating new problem instances by using the estimated distributions. The paper then trains a DRL model on the DER-Solomon dataset and shows comparable performance on the testing instances compared to optimization-based approaches."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper proposes a approach to effectively enlarge the training data for DRL on a specific classic optimization problem given a small but comprehensive instance set.\n\n2. The paper shows that the learned DRL with the enriched dataset could achieve comparable performance compared to classic optimization methods."
                },
                "weaknesses": {
                    "value": "1. The paper lacks background descriptions of the CVRP and CVRPTW problems and also probably some more detailed introductions on the existing traditional algorithm approaches. Given there is plenty of space for the paper, such background information could be very beneficial to the audience. VRP may be well-known in the community, but the variants are probably not.\n\n2. A lot of details are not presented in the paper. E.g., given the estimated distributions of the parameters, how are the new instances sampled? Are all parameters considered independently? Why generate 1280k instances? Moreover, there are no given details on how the DRL model is trained using DER-Solomon.\n\n3. The technical contribution is limited. It mainly estimates the distributions of a given small dataset to generate instances to form a larger dataset. It does not compare the proposed sampling method to some more basic methods. For example, what if we just add Gaussian noises to parameters in Solomon or use some uniform sampling to generate the instances?\n\n4. Curretly I think parameters of the dataset are assumed to be independently samples (correct me if that is wrong). Is there a reason to make such an assumption? Would it be beneficial to consider a more complex distribution of the parameters?\n\n5. The studied problem has a relative restricted scope. Could such techniques explored in the paper get applied to solving other classic optimization problems as well? Or what special properties of the Solomon dataset makes the approach most effective?\n\n\nMinor:\n1. Page 3:  \"its frequency histogram is shown in Figure 2(a)\" but there is no index of (a) or (b) in Figure 2.\n2. X-axis of Figure 5 is not labeled."
                },
                "questions": {
                    "value": "Please check the weaknesses part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission875/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698478284503,
            "cdate": 1698478284503,
            "tmdate": 1699636013942,
            "mdate": 1699636013942,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JL4yfIrckb",
                "forum": "HTH3HnJeRC",
                "replyto": "PGfe7S5AOU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission875/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission875/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer c63s"
                    },
                    "comment": {
                        "value": "Thank you for your insightful comments and great efforts in helping improve our work. The responses to your comments are listed as follows.\n\n> Q1. The paper lacks background descriptions of the CVRP and CVRPTW problems and also probably some more detailed introductions on the existing traditional algorithm approaches. Given there is plenty of space for the paper, such background information could be very beneficial to the audience. VRP may be well-known in the community, but the variants are probably not.\n\nA1. Thank you for your helpful comments. To make the background descriptions clearer, we have added more background information on the CVRP and CVRPTW, as well as detailed introductions to existing traditional algorithm approaches in the updated manuscript.\n\n> Q2. A lot of details are not presented in the paper. E.g., given the estimated distributions of the parameters, how are the new instances sampled? Are all parameters considered independently? Why generate 1280k instances? Moreover, there are no given details on how the DRL model is trained using DER-Solomon.\n\nA2.  Thank you for your insightful comments. We sincerely apologize for any lack of detail in certain areas. Given the complexity of the subject matter, it can be challenging to cover every aspect in depth. To address this, we plan to release the source code in the final version of the paper. This will allow for a more comprehensive understanding as many details can be directly gleaned from the code.\n\n- New instances are generated by random sampling from the estimated distributions.\n- All parameters are considered independently. However, in Solomon's public test instance and another public test instance of CVRPTW, Homberger changes between instances, except for the time window variable, while other variables remain fixed. So, we also kept other variables fixed in the new instance, and only one variable changed. Whether other variables are independent of each other is irrelevant.\n- The reason for generating 1280k instances is that most of the DRL algorithms solving VRP after 2019 are based on the transformer network and attention mechanism. The first author [1] to use this method set the training dataset to 1280k instances in his open-source code, so most subsequent researchers have followed suit.\n- We didn\u2019t mentioned in this paper how the DRL model is trained using DER-Solomon because the cited DRL algorithms, AM, MDAM, POMO, and MARDAM, all have source code released, and their articles also detailed their network structure and training methods. As for the training process, in short, the coordinates, demand, and time window data of DER-Solomon are input into the DRL network, and then the DRL network will plan a path that meets the time window and load constraints for each instance. The negative value of the average path length is used as the reward value, and the DRL network is trained using the gradient optimization algorithm.\n\n\n[1] Kool, W, Van Hoof H, and Welling M. \"Attention, Learn to Solve Routing Problems!.\" International Conference on Learning Representations. 2018.\n\n\n> Q3. The technical contribution is limited. It mainly estimates the distributions of a given small dataset to generate instances to form a larger dataset. It does not compare the proposed sampling method to some more basic methods. For example, what if we just add Gaussian noises to parameters in Solomon or use some uniform sampling to generate the instances.\n\nA3. Thank you for your thoughtful comments. In fact, not only public test instances, but our original starting point was to consider the problems that may be encountered in actual situations when the available dataset is small. Imagine there is a logistics company, or a company that provides decision system solutions to logistics companies. In order to seize the first-mover advantage in the market, it\u2019s crucial to act proactively when there are indications of a developing business scenario. This involves implementing an intelligent logistics and transportation planning system even before the scenario fully matures. At this time, the instances that can be collected in the business scenario are very few, and it may not even represent the characteristics of all future instances, but it needs to speculate on all future instances. Therefore, we assumed 11 forms of popular distribution functions and selected the one with the best goodness of fit. The 11 forms of distribution functions are the crystallization of human statistical technology over the past hundreds of years, not just a summary of the current few instances. This cannot be achieved by adding Gaussian noise and random sampling. The instances generated by Gaussian noise can only represent the characteristics of the current few instances, to a certain extent, they are just replicas of the current instances."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission875/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700484942244,
                "cdate": 1700484942244,
                "tmdate": 1700484942244,
                "mdate": 1700484942244,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "HwnIGwsRck",
            "forum": "HTH3HnJeRC",
            "replyto": "HTH3HnJeRC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission875/Reviewer_Cpep"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission875/Reviewer_Cpep"
            ],
            "content": {
                "summary": {
                    "value": "To deal with the limited scale of the well-known Solomon benchmark of the capacitated vehicle routing problem with time windows (CVRPTW) for learning-based approaches, this paper proposes a large set of new instances with a similar distribution to the Solomon benchmark, called DER-Solomon benchmark."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "To deal with the limited scale of the well-known Solomon benchmark of the capacitated vehicle routing problem with time windows (CVRPTW) for learning-based approaches, this paper proposes a large set of new instances with a similar distribution to the Solomon benchmark, called DER-Solomon benchmark."
                },
                "weaknesses": {
                    "value": "Besides the Solomon benchmark, the Gehring & Homberger benchmark is also a famous one of CVRPTW. It is better to further apply the proposed data generation method to the Gehring & Homberger benchmark."
                },
                "questions": {
                    "value": "1. How many instances are included in the DER-Solomon benchmark?\n2. How many DER-Solomon instances are used to train the learning-based method?\n3. What and how many original Solomon instances are used to train the learning-based method?\n4. How to calculate the std gaps reported in Table 1? They seem to be unequal to the relative gaps between the std values of two benchmarks."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission875/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission875/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission875/Reviewer_Cpep"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission875/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698740457346,
            "cdate": 1698740457346,
            "tmdate": 1699636013862,
            "mdate": 1699636013862,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CBzNqlv743",
                "forum": "HTH3HnJeRC",
                "replyto": "HwnIGwsRck",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission875/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission875/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Cpep"
                    },
                    "comment": {
                        "value": "Thank you for your encouraging comments and great efforts in helping improve our work. The responses to your comments are listed as follows.\n\n> Q1. Besides the Solomon benchmark, the Gehring & Homberger benchmark is also a famous one of CVRPTW. It is better to further apply the proposed data generation method to the Gehring & Homberger benchmark.\n\nA1. \nThank you for your insightful suggestion. We have recorded the expanded dataset of the Gehring & Homberger benchmark in the appendix of the updated manuscript, along with some of our experimental results. The experimental verification process is time-consuming, given that each of the six series requires individual training. Furthermore, each series encompasses five different customer point scales, which also necessitate separate training. This results in a total of 30 training models, and that is just for one Deep Reinforcement Learning (DRL) method.\n\nIf we consider all three DRL methods mentioned in the article (i.e. AM, POMO, and MDAM), we would need to train a staggering 90 models. However, we will continue to update the remaining experiments and those extended to other optimization problems periodically on the source code, much like the author of AM, who has diligently maintained his source code for over two years.\n\n\n> Q2. How many instances are included in the DER-Solomon benchmark.\n\nA2. As briefly mentioned in Appendix A.3, we used 1,280,000 DER-Solomon instances as the training set. In addition, during testing, 1024 instances were used as the test set in Tables 1 and 2. However, it's important to note that the DER-Solomon benchmark is not a fixed set of instances. It is more of an instance generation method that provides a distribution function of instances, generating a large number of training instances through random sampling to help the DRL method test its performance on Solomon.\n\n> Q3. How many DER-Solomon instances are used to train the learning-based method.\n\nA3. As briefly mentioned in Appendix A.3, we used 1,280,000 DER-Solomon instances as the training set.\n\n> Q4. What and how many original Solomon instances are used to train the learning-based method.\n\nA4.  We opted not to use the original Solomon instances as part of the training set, given that they are ultimately designated as the test set. Instead, all training data exclusively comprises DER-Solomon instances.\n\n> Q5. How to calculate the std gaps reported in Table 1? They seem to be unequal to the relative gaps between the std values of two benchmarks\n\nA5. We always set the denominator to be the mean. The calculation method of the gap is: \n\nstd gap: abs (std on Solomon \u2013 std on DER-Solomon ) / mean on Solomon. \n\nmean gap: abs (mean on Solomon \u2013 mean on DER-Solomon ) / mean on Solomon.\n\nAnd we have explained it in Table 1 in the updated manuscript."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission875/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700484685264,
                "cdate": 1700484685264,
                "tmdate": 1700484685264,
                "mdate": 1700484685264,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ru6qK8XNaD",
                "forum": "HTH3HnJeRC",
                "replyto": "CBzNqlv743",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission875/Reviewer_Cpep"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission875/Reviewer_Cpep"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your responses. I keep my borderline rating due to three points as follows.\n\n1. The contribution is relatively limited. The proposed method should be applied to more problems besides CVRPTW.\n2. Other data generation method to better train the DRL method should be compared.\n3. When the dataset is small in some realistic situations, do we really need to separately train a DRL method? Instead, a conventional OR method might be a better choice.\n\nI encourage the authors to further improve the paper in the next version."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission875/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700638615919,
                "cdate": 1700638615919,
                "tmdate": 1700638615919,
                "mdate": 1700638615919,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "UR2esPjfNz",
            "forum": "HTH3HnJeRC",
            "replyto": "HTH3HnJeRC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission875/Reviewer_mp8y"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission875/Reviewer_mp8y"
            ],
            "content": {
                "summary": {
                    "value": "This work scales up the Solomon benchmark with backward deriving.  Distribution consistency has been verified between the generated dataset and the original one."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Effect solution to scale up the Solomon benchmark. \n2. Code is publicly available."
                },
                "weaknesses": {
                    "value": "1. While effective, the contribution of this work is quite limited. I suggest authors consider applying this algorithm to scale more benchmarks.\n2. The comparison with neural solvers is missed in Table  1."
                },
                "questions": {
                    "value": "The figures are not well presented. Also hard to find the relevant descriptions. This paper is not ready to be published."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission875/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission875/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission875/Reviewer_mp8y"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission875/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698907413190,
            "cdate": 1698907413190,
            "tmdate": 1699636013767,
            "mdate": 1699636013767,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Chb46FRXjV",
                "forum": "HTH3HnJeRC",
                "replyto": "UR2esPjfNz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission875/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission875/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer mp8y"
                    },
                    "comment": {
                        "value": "Thank you for your thoughtful comments and great efforts to help improve our work. The responses to your comments are listed as follows.\n\n> Q1. The comparison with neural solvers is missed in Table 1.\n\nA1. The purpose of Table 1 is to compare the differences between DER-Solomon and Solomon, not the differences between different algorithms. To clarify the manuscript, we have added vertical lines between algorithms and have made annotations at the bottom of Table 1. In addition, the comparison between algorithms are recorded in appendix Table 5.\n\n\n> Q2. The figures are not well presented. Also hard to find the relevant descriptions. This paper is not ready to be published.\n\nA2. Thank you for your thoughtful comments. To make the figures present clear, we have described more content in legends of the figures and have made some essential explanations in the titles of the figures. We have utilized the PDF format for some Figures while rendering others in higher resolution for improved visual quality."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission875/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700484545271,
                "cdate": 1700484545271,
                "tmdate": 1700484545271,
                "mdate": 1700484545271,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "c3mUwdkYgW",
                "forum": "HTH3HnJeRC",
                "replyto": "UR2esPjfNz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission875/Reviewer_mp8y"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission875/Reviewer_mp8y"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your effort and timely reply, I will keep my score. In addition, I strongly encourage authors to consider applying this algorithm to scale more benchmarks."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission875/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740847865,
                "cdate": 1700740847865,
                "tmdate": 1700741070093,
                "mdate": 1700741070093,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]