[
    {
        "title": "SimVAE: Narrowing the gap between Discriminative & Generative Self-Supervised Representation Learning"
    },
    {
        "review": {
            "id": "2MfO3KAAyL",
            "forum": "eJFBMqCE4X",
            "replyto": "eJFBMqCE4X",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1767/Reviewer_xsXw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1767/Reviewer_xsXw"
            ],
            "content": {
                "summary": {
                    "value": "The paper provides a Bayesian perspective on self-supervised learning making an explicit connection to VAE-based models, thus enabling to incorporate properties inherent to both discriminative and generative approaches. The proposed framework highlights an underlying probabilistic graphical model for self-supervised learning (SSL) and a corresponding ELBO-like objective. Experiments are conducted on MNIST, FashionMNIST, CIFAR10 and Celeb-A, against SSL and VAE-based baseline models. The results highlights (i) that the proposed approach is competitive on simple datasets in terms of discrimination performance with SSL, with the advantage of retaining both information about content and style thanks to the generative aspect and (ii) that there exists a gap in discriminative performance between the proposed approach (also VAE models) and SSL on natural images (CIFAR-10)."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The problem of unifying SSL and generative approaches is relevant and timely (**Relevance**)\n2. The paper is clear and well-written (**Clarity**)"
                },
                "weaknesses": {
                    "value": "1. The paper omits important related work [1-6]. At a minimum, a discussion about the similarities and differences should be included (**Quality**).\n2. Parts of the paper, especially on the background of self-supervised learning, are overly simplified and imprecise (for instance regarding the classes of SSL approaches), please refer to [3] and [7] (**Quality**).\n3. Some of the main claims of the paper are not well-supported, especially the ones about the unification between SSL and generative approaches. Please refer to the general analysis in [3] and [4]. The novelty and theoretical contribution is somewhat limited, perhaps lying in specializing the existing framework (GEDI in [3] and [4]) to the VAE setting (**Novelty**).\n4. While the experimental analysis provides evidence on the benefits of the proposed unification, the conclusions drawn from the experiments are rather limited confirming what has been already observed partly in [8] and in [3,4] (**Significance/Novelty**). Perhaps, the authors should focus on deepening the analysis on the existing gap observed on natural images (CIFAR-10), in order to improve in terms of significance and novelty.\n5. The experimental analysis is missing a comparison with other existing generative and discriminative models [3] and [4] (**Quality**).\n\n**MINOR**\n\nIn Section 4.2, all conditional densities should be explicitly defined.\n\n**References**\n\n[1] Learning Symbolic Representations Through Joint Generative and Discriminative Training. ICLR Workshop NeSy-GeMs 2023\n\n[2] Learning Symbolic Representations Through Joint Generative and Discriminative Training (Extended Abstract). IJCAI Workshop KBCG 2023\n\n[3] GEDI: GEnerative and Discriminative Training for Self-Supervised Learning. arXiv 2022\n\n[4] The Triad of Failure Modes and A Possible Way Out. arXiv 2023\n\n[5] D2C: Diffusion-Decoding Models for Few-Shot Conditional Generation. NeurIPS 2021\n\n[6] Guiding Energy-based Models via Contrastive Latent Variables. ICLR 2023\n\n[7] A Cookbook of Self-Supervised Learning. arXiv 2023\n\n[8] Self-Supervised Learning with Data Augmentations Provably Isolates Content From Style. NeurIPS 2021"
                },
                "questions": {
                    "value": "1. Can you please discuss the similarities and differences between the above-mentioned references, especially [3] and [4]?\n2. What are the main reasons behind the existing gap between VAE-like and SSL models observed on CIFAR-10?\n3. What is the equivalent of the notion of \u201ccontent and style\u201d in natural images?\n4. Can you please provide the definition of the conditionals introduced in Section 4.2?\n5. What is the advantage of having a decoder compared to [3], [4], as this introduces additional computation?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1767/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1767/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1767/Reviewer_xsXw"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1767/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697619575512,
            "cdate": 1697619575512,
            "tmdate": 1700840630660,
            "mdate": 1700840630660,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NAyLYXhziO",
                "forum": "eJFBMqCE4X",
                "replyto": "2MfO3KAAyL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1767/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1767/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors"
                    },
                    "comment": {
                        "value": "* **\"Omitting important related work\"**: Thank you for raising these works.\n    * [1-4]: for clarity (and benefit of other reviewers), we note that these are highly related to one another by the same authors:\n        - [4] is a **workshop submission** which further investigates a graphical model proposed in [3]. It appeared **after the ICLR submission date** (due at a [NeurIPS 23 workshop](https://nips.cc/virtual/2023/80847#:~:text=We%20present%20a%20novel%20objective,to%20permutations%20of%20cluster%20assignments.)), so we omit this per ICLR guidelines. \n        - [1, 2] are a **workshop paper and abstract** based on [3], so we restrict comments to [3].\n        - [3] is on Arxiv (not yet cited) and not peer-reviewed, and we were unaware of it. (Please note [ICLR Guidelines](https://iclr.cc/Conferences/2024/ReviewerGuide): \"Authors ... may be excused for not knowing about papers not published in peer-reviewed conference proceedings or journals, which includes papers ... on arXiv.\") [3] is related to Sim-VAE, we provide a detailed comparison below and cite it in our work (section 2).\n    - [5] introduces a VAE with a *diffusion* prior and a discriminative SSL loss (see Eq 4, 5 & Fig 2). This does not compare closely to our generative model for SSL which _unifies_ existing discriminative SSL under a unique ELBO. [5] does combine SSL with VAEs, we therefore cite it as related work in section 2.\n    - [6] trains Energy Based Models with a contrastive component and is less comparable to our generative latent variable approach.\n* **\"Similarity & differences between SimVAE and [3]\"**: SimVAE and [3] both set out to improve self-supervised learning and develop a more principled approach by understanding existing existing SSL methods from a probabilistic perspective. We highlight main differences:\n    - Model:\n        - [3] proposes a **different** graphical model for each class of SSL method considered (Fig 1): contrastive (CL), cluster-based (CB) and negative-free (NF). We note that these are not *generative* models of the data $x$ (e.g. arrows point *away* from $x$) leading to objective functions distinct from SimVAE's.\n        - In SimVAE, we consider the distribution over representations ($z$) induced by several SSL methods and formalise the intuition in a **single** generative hierarchical latent variable model (LVM): $p_{\\theta, \\psi, \\pi}(x)\\!=\\!\\int_{y,z} p_\\theta(x|z)p_\\psi(z|y)p_\\pi(y)$ (Fig 2). This model is general, and it is assumed that $y$ conditions *lower-variance* distributions $p(z|y)$, e.g. *clusters*, in the latent space. We claim that *all* of the SSL methods considered (and related methods, by extension) implicitly assume this *one* latent variable model (Fig 2), i.e. representations are learned by assuming that those of semantically related data share the same $y$ and are therefore clustered together, while clusters are kept apart/preventing *collapse*. Specifically:\n            - instance discrimination (ID) treats the data index $i$ as the latent $y$, hence representations of each sample and its augmentations form clusters. CL methods (e.g. SimCLR) are shown to approximate ID, so exploit the same latent assumption (not their relationship to *mutual information*, as often assumed). NF models, e.g. BYOL, impose similar instance-level latent clustering, and differ algorithmically in how representations are prevented from collapsing. \n            - CB methods (e.g. DeepCluster) directly perform clustering in the latent space, using a large (arbitrary) number of clusters indexed by $y$, relying on the *inductive bias* of the encoder to map representations of semantically related data close together, even at random initialisation (see DeepCluster). \n    - Objective:\n        - [3] proposes a new SSL objective, GEDI (Eq 10), that maximises the likelihood under an **energy-based model** (EBM), $p_\\psi(x) \\propto e^{u^\\top enc(x)}$ and minimises several KL divergences derived from CB & NF methods. This *amalgamates* different aspects of SSL approaches and a model of $p(x)$. GEDI appears to assume (in $p_\\psi(x)$ and $L_{DI}$ terms of Eq 10) that the number of classes $c$, for some ground truth \"class\" is known, which contrastive SSL methods do not assume.\n        - In SimVAE, the proposed **generative LVM** *unifies* the considered SSL methods under one probabilistic model and the proposed objective is the ELBO for that LVM derived from first principles.\n    - Implementation: \n        - [3] uses a 2-stage process to first train the EBM using SGLD *sampling* and then train a discriminative model.\n        - SimVAE follows a single optimisation process (e.g. SGD). \n        - [3] also introduces a novel augmentation strategy (\"DAM\") that improves results, as does the assumption that $c$ is known (Figs 3 and 7). These provide GEDI with additional samples and information relative to other SSL methods (inc SimVAE), obfuscating like-for-like comparison."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1767/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522824733,
                "cdate": 1700522824733,
                "tmdate": 1700522824733,
                "mdate": 1700522824733,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "3vHD2c2oAI",
            "forum": "eJFBMqCE4X",
            "replyto": "eJFBMqCE4X",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1767/Reviewer_DybW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1767/Reviewer_DybW"
            ],
            "content": {
                "summary": {
                    "value": "This paper started with the motivation of a principled understanding of the latent processes of self-supervised learning and then argued that common SSL models learn representations that \u201ccollapse\u201d in latent semantic clusters and lose the nuanced information such as style. To improve this, the authors presented SimVAE to enhance SSL. It is a hierarchical VAE by further factorizing the latent $p(z)$ into $p(z|y)p(y)$, where $y$ is the \u201csemantic content\u201d such as different classes (e.g., different dog breed classes) or different instances (different dog image samples). The choice of $p(y)$ is Gaussian or uniform, and $p(z|y)$ is a low variance Gaussian. The authors derived the ELBO bound for SimVAE and showed promising results on MNIST and FashionMNIST while also showing results not as competitive as other SSL methods on Celeb-A and CIFAR-10.\n\nDespite good efforts, the current shape of the paper lacks many sound technical details to be accepted at ICLR."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Originality: using VAE for self-supervised learning is not particularly new [1-3], but the idea of building a VAE for SSL by considering semantic latent variables in a higher hierarchy and then using it to explain existing SSL algorithms seems new to the reviewer. The authors seem to design the method from first principles.\n\nQuality: there are some promising empirical results on small datasets, such as MNIST and FashionMNIST, where the proposed method surpasses or reaches close to SSL methods such as SimCLR, VicReg, and MoCo. The derivation of the SimVAE method (Eqs. 1-8) is correct despite minor errata (the details are in the Questions section.) \n\nSignificance: bridging together generative and discriminative representation learning is an important topic, and the authors show their effort toward this step by trying to explain the underlying mechanisms of different SSL methods using a hierarchical VAE. \n\n[1] Gatopoulos, Ioannis, and Jakub M. Tomczak. \"Self-supervised variational auto-encoders.\" Entropy 23.6 (2021): 747.\n\n[2] Zhu, Yizhe, et al. \"S3vae: Self-supervised sequential vae for representation disentanglement and data generation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.\n\n[3] Wu, Chengzhi, et al. \"Generative-contrastive learning for self-supervised latent representations of 3d shapes from multi-modal euclidean input.\" arXiv preprint arXiv:2301.04612 (2023)."
                },
                "weaknesses": {
                    "value": "Originality: the authors did not discuss prior VAE SSL work, such as [1, 4].\n\nQuality: this is the biggest weakness of this paper. Despite the good efforts shown by the authors, many important technical details are missing. The details are in the Questions section.\n\nClarity: coupled with the last point, reading certain parts of the draft can be challenging as some terms are not clearly defined or certain steps are missing. The details are also in the Questions section.\n\n \n[1] Gatopoulos, Ioannis, and Jakub M. Tomczak. \"Self-supervised variational auto-encoders.\" Entropy 23.6 (2021): 747.\n\n[4] Nakamura, Hiroki, Masashi Okada, and Tadahiro Taniguchi. \"Representation Uncertainty in Self-Supervised Learning as Variational Inference.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023."
                },
                "questions": {
                    "value": "1. *Page 1, \u201cbut do not fit its posterior due to their discriminative nature\u201d*\n* It is unclear how to define \u201cfit\u201d and why due to the discriminative nature.\n\n2. *Page 5, \u201cand for any $z \\in \\mathcal{Z},$ a distribution $p(x|z)$ is implicity defined by the probabilities of samples mapping to it $\\{ x \\in \\mathcal{X} | f(x) = z \\}$\u201d*\n* It is unclear what it means to be \u201cimplicitly defined by the probabilities of samples mapping to it\u201d. This is a vague statement without mathematical backing.\n\n3. *Page 5, \u201cHence geometric properties of representations implicitly correspond to latent probabilistic assumptions.\u201d* \n* The authors could have shown theoretically rigorous proof to show this. And it is unclear what specific geometric properties the latent probabilistic assumption induced.\n\n4. *Page 5, \u201cAnd $z$ may be only identifiable up to certain symmetries\u201d* \n* The authors may specify what \u201csymmetries\u201d mean exactly in terms of the identifiability results and may cite related works.\n\n5. *Page 5, \u201cand insight into the information captured by representations from their regenerations\u201d*\n* The reviewer is not sure this claim is valid without further explanation; why do generative models have better insights into the information captured by the representation? It is better to define the \u201cinformation\u201d here, as in SSL literature, there are numerous works studying the information the representation captures (some of which the authors rightfully cited) [5-9].\n\n6. *Page 5, \u201cNote that if the variance of each $p(z|y)$ is low relative that of $p(z)$, this fits with the notion that contrastive methods \u2018pull representations of related samples together and push those of random samples apart.\u2019\u201d* \n* It would be much more valid if the authors showed proof of this. Also, it is not clear how to define rigorously \u201cfits with the notion,\u201d e.g., via asymptotic analysis. And how to quantify \u201clow relative that of p(z)\u201d is unclear.\n\n7. *Page 5, \u201cThus, the model (Equation 4) justifies representation learning methods that heuristically perform clustering\u201d.*\n* It is unclear how it is justified. Factorizing $p(x)$ into the form of Equation 4 is a good start, but it did not justify why heuristic clustering methods are working well or necessarily capturing $p(x)$ well, e.g., through a tight error bound.\n\n8. *Page 6, \u201csamples of each class differ only in style (and classes are mutually exclusive) this collapse leads to style-invariant representations.\u201d* \n* Despite correct intuition, this statement is, in general, very strong; Dosovitskiy et al. did not explicitly claim anything about the style vs. semantic information in the representations, and the authors did not cite any other work supporting this claim nor specify any assumptions.\n\n9. *Page 6, \u201cUnder softmax cross entropy loss for mutually distinct classes (cf mixed membership), all representations of a class $y$ converge to class parameter $w_y$.\u201d*\n* It is quite unclear what \u201crepresentations converging to class parameter\u201d means without any additional context. Also, the authors did not show any convergence analysis.\n\n10. *Page 6, \u201cIn expectation, $z^T z\u2019$ for stochastically sampled $z\u2019$ of the same class approximates $z^T w_y$, without the need to store $w_y$.\u201d*\n* It is not mentioned at all why it $z^T z\u2019$ approximates $z^T w_y$, and what \u201cstore $w_y$\u201d means.\n\n11. *Page 6, \u201cIn effect, representations are comparable to those learned by softmax, subject to unit length constraint.\u201d: the authors may clarify how to define \u201ccomparable.\u201d* \n* It may be helpful to at least cite related work directly, or show empirical evidence to show under what tasks the representations are comparable.\n\n12. Typos: Eq.(5) the support could be simply $y$ for the last integral, and in the paragraph below Eq.(5) the lower bound should be $\\log p_{\\theta}(z) \\geq \\int_{y} \\mathbf{q_{\\phi}(y|z)} \\log \\frac{p_{\\theta}(z|y)p(y)}{q_{\\phi}(y|z)}$ (the main result in Eq.(5) is correct).\n\n[5] Tschannen, Michael, et al. \"On mutual information maximization for representation learning.\" ICLR 2020,\n\n[7] Wu, Mike, et al. \"On mutual information in contrastive learning for visual representations.\" arXiv preprint arXiv:2005.13149 (2020).\n\n[6] Sordoni, Alessandro, et al. \"Decomposed mutual information estimation for contrastive representation learning.\" ICML 2021.\n\n[8] Tsai, Yao-Hung Hubert, et al. \"Self-supervised learning from a multi-view perspective.\" ICLR 2021.\n\n[9] Mohamadi, Salman, Gianfranco Doretto, and Donald A. Adjeroh. \"More synergy, less redundancy: Exploiting joint mutual information for self-supervised learning.\" ICIP 2023."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1767/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1767/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1767/Reviewer_DybW"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1767/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698764736624,
            "cdate": 1698764736624,
            "tmdate": 1699636106023,
            "mdate": 1699636106023,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1dMyXdhs42",
                "forum": "eJFBMqCE4X",
                "replyto": "3vHD2c2oAI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1767/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1767/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors"
                    },
                    "comment": {
                        "value": "* **\"Originality: the authors did not discuss prior VAE SSL work.\"**: Thank you for raising these works. After carefull consideration, we cited [3] and [4] in the updated manuscript, in section 2 while we do not believe [1] is closely related to our work for the following reasons: \n[1] does not tackle the typical self-supervised learning problem we consider, of learning representations from semantically related data. Instead, they target richer and higher-quality generation using VAEs, by applying a \"self-supervised\" *lossy* augmentation to the data (e.g. downscaling or edge detection) that is assumed part of the generative process, allowing that process to be considered in stages (resembling a diffusion-like approach). \n[3] combines several loss components from SSL and VAEs to arrive at a comparable training objective to SimVAE's but does not propose a hierarchical latent variable model for SSL and does not derive its associate lower bound. \n[4] is related to our work but differs from SimVAE as it does not propose a generative latent variable model for SSL in the same way, rather their model $p(x|z)p(z)$ is defined in terms of a posterior and the data distribution itself (their Eq 9).\n\n* **Clarity & Quality**: we have reworded key sections of the paper to improve clarity and we address specific questions below.\n\n1. **\"but do not fit its posterior due to their discriminative nature\"**: this has been rephrased as it is an unecessary level of detail for the introduction.\n2. **\"$p(x|z)$ is implicity defined by ...\"** we have reworded this for clarity.\n3. **\"geometric properties of representations implicitly correspond to latent probabilistic assumptions\"**: we have reworded this for clarity and more clearly defined the relationship between an encoder $f$ and the latent distribution it induces $p_f(z)$.\n4. **\"$z$ ... only identifiable up to certain symmetries\"** this has been noted previously for generative models (c.f., Locatello et al. 2019), in particular VAEs, and we have added citations.\n5. **\"insight into the information captured by representations\"**: we mean this less quantitatively than suggested and have amended the wording to make this clear.\n6. **\"variance of each $p(z|y)$ is low relative that of $p(z)$\"**: at this point in the paper, we aim to be intuitive and motivate the steps we take. Note that we do not *prove* properties of the latent space learned by SSL methods, but draw intuition from the latent structure they impose, design a latent variable model based on that and aim to justify our choices empirically. We have rephrased \"low relative to that of $p(z)$\" as \"more concentrated\" and a concrete example of what we mean is if $p(z|y)$ and $p(z)$ are both Gaussian and the variance of former is lower than the latter.\n7. **\"the model (Equation 4) justifies representation learning methods that heuristically perform clustering\"**: we have rephrased this section to hopefully make the explanation more clear. Maximising Eq 4 learns the model in Eq 3, and is a prinicipled means of training a VAE with mixture model prior. Methods that take a similar but heuristic approach can therefore be interpreted as also (approximately) learning the model in Eq 3.\n8. **\"samples of each class differ only in style (and classes are mutually exclusive) this collapse leads to style-invariant representations\"**: we have reworded for clarity. We reference \"Variational Classification\" [Dhuliawala et al., 2023,] regarding the latent perspective and \"collapse\" of representations of each class under softmax. We agree that Dosovitskiy et al. do not reference content/style, we meant to refer to their reference to \"transformation invariance\" and have made this more clear.\n9. **\"representations of a class $y$ converge to class parameter\"**: we have reviewed this wording and removed this part as it is unnecessary for the point we hope to make.\n10. **\" $z^T z\u2019$ approximates $z^T w_y$, ... what \u201cstore $w_y$\u201d means.\"** we have reviewed this wording and removed this part as it is unnecessary for the point we hope to make.\n11. **\"representations are comparable to those learned by softmax\"**: we have re-worded to make this more clear. We aim to highlight common high-level clustering of representations of semantically related samples across various SSL methods.\n13. typos: thank you, these have been fixed.\n\nWe hope we have answered all your queries and improved the paper. Let us know if we can address any additional questions or concerns and please consider updating your score if appropriate."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1767/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522409362,
                "cdate": 1700522409362,
                "tmdate": 1700522409362,
                "mdate": 1700522409362,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "iw9CtO17Hf",
            "forum": "eJFBMqCE4X",
            "replyto": "eJFBMqCE4X",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1767/Reviewer_2gEb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1767/Reviewer_2gEb"
            ],
            "content": {
                "summary": {
                    "value": "This article is placed in the context of representation learning using self-supervised learning (SSL) algorithms. It insists on the distinction between discriminative and generative SSL algorithms. The authors claim that while the former are generally easier to implement & train, and seem to generally produce better latent representation, they are actually very opinionated on which information is kept in the latent representation and which is discarded. The author argue that this is a result of the discriminative nature of the training process, which tends to only keep information necessary for the discriminative task and discard the rest. On the other hand, generative algorithms must retain as much information about the data as possible to fulfill their reconstruction training objective, and thus are theoretically capable of producing richer representation that contain more of the information from the data.\n\nTo try and bridge the empirical gap between those two families, the authors propose a graphical model representation that generalize the structure of many discriminative SSL algorithms, and use it to build a generative SSL model: SimVAE. It uses a hierarchical latent structure to encode the information that some training examples are related to each other without encouraging the model to discard information differing between them.\n\nThe proposed SimVAE is show to improve over other generative SSL models for downstream classification from their learned representation, in some cases being competitive with discriminative algorithms. Evidence is also given to the fact that SimVAE does learn richer representations than discriminative models, allowing better classification performance on secondary characteristics of the data."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This article seems rather solid. The proposed model is well motivated and theoretically sound.\n\nThe proposed latent construction for SimVAE is well adapted to problem of interest, and is and adequate answer to the claim that discriminative SSL tends to discard any information not relevant to the implicitly assumed class of downstream tasks.\n\nThe empirical evaluation of the proposed SimVAE is detailed, and performed against many relevant models. I am overall confident in the correctness of the results and relevance of the model."
                },
                "weaknesses": {
                    "value": "**Observation model:**\n\nAs is unfortunately very common in the VAE literature, barely any discussion is done regarding the probabilistic model of the decoder, $p(x|z)$ (in this case, that would be the variance associated with the MSE loss). It has been shown that it controls the signal/noise trade-off of the model, and thus how much information is stored in the latent representation of VAEs, which is of particular interest here (see for example [Dosovitskiy and Brox, 2016](https://proceedings.neurips.cc/paper/2016/hash/371bce7dc83817b7893bcdeed13799b5-Abstract.html), [Rezende and Viola, 2018](https://arxiv.org/abs/1810.00597), [Loaiza-Ganem and Cunningham, 2019](https://proceedings.neurips.cc/paper/2019/hash/f82798ec8909d23e55679ee26bb26437-Abstract.html), [Berger and Sebag, 2020](https://arxiv.org/abs/2003.01972), or [Langley et al, 2022](https://arxiv.org/abs/2205.12533) for discussions about the observation model).\n\nAs a result, I believe that this parameter has potentially a large impact on SimVAE's performance as a representation learning method, and leaving it to $1.0$ (according to appendix A.4.3) is likely to be too large a value, causing the model to discard significantly more information than appropriate.\n\n**Hierarchical VAEs:**\n\nThe idea of hierarchical VAEs built on a chain of latent variables is not new, and there is a wealth of models build on latent structures similar (if not identical) to SimVAE. While as far as I remember SimVAE is not redundant with these works, I find it lacking that they are not mentioned in the paper, and that SimVAE is not positioned relative to them. A few non-exhaustive examples: [Rolfe, 2016](https://arxiv.org/abs/1609.02200), [Dilokthanakul et al, 2017](https://arxiv.org/abs/1611.02648), [Edwards and Storkey, 2016](https://arxiv.org/abs/1606.02185), [Bouchacourt et al, 2018](https://ojs.aaai.org/index.php/AAAI/article/view/11867) or [He et al, 2019](https://openreview.net/forum?id=SJgsCjCqt7).\n\n**Minor points:**\n\nI think it would be an improvement to explicitly state what models of $p(y)$ and $p(z|y)$ are used in your experiments among the various possibilities that are suggested in Section 4, and how the training loss given in Algorithm 1 is derived from them."
                },
                "questions": {
                    "value": "I don't have more questions beyond the points raised above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1767/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698765327231,
            "cdate": 1698765327231,
            "tmdate": 1699636105918,
            "mdate": 1699636105918,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "shOU1KiMfI",
                "forum": "eJFBMqCE4X",
                "replyto": "iw9CtO17Hf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1767/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1767/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors"
                    },
                    "comment": {
                        "value": "* **Impact of $p(x|z)$ variance** Thank you, we agree with the role this parameter has in governing the amount of information representations learn. We had considered this parameter in preliminary experiments but not fine tuned it for final experiments. We note that, for unsupervised representation learning, one should be cautious about tuning hyperparameters to a particular downstream task. However, following the reviewer's suggestion, we have re-run experiments for several values of $\\sigma^2=Var[X|Z]$ ($\\sigma^2 = 1.0$ in the paper) and include results in Figure 7 for downstream CIFAR10 classification. This shows a slight performance improvement ($+2\\%$) from using $\\sigma^2=0.6$. We are testing lower values to see if there is a better value \"in general\" (i.e. across various datasets) and if so will update the results. (We do not expect this change the overall picture, e.g. to \"brige the gap\" to discriminative performance.)\n* **Hierarchical VAE missing references**: Thank you for your feedback. We agree SimVAE fits within the wider hierarchical VAE literature and this was an omission. The related work (section 2) has been updated to include prior relevant hierarchical latent variable models ( Valpola, 2015; Ranganath et al., 2016; Rolfe, 2017; He et al., 2018; S\u00f8nderby et al., 2016; Edwards & Storkey, 2016) and how they relate to SimVAE. The closest work by Edwards & Storkey (2016), proposes a very similar hierarchical graphical model for modelling data*sets*. The main differerences to our work are (a) that we present a hierarchical latent variable to **unify existing SSL methods** (purpose); and (b) how the posterior is factorised, which is crucual for representations $z$ to be inferred for each sample $x$ independently of related $x'$ (note that Edward & Storkey first learn a global statistic $c$ from a dataset via $q(c|D)$ and only then infer a representation of the data $q(z|x,c)$).\n* **Model specifications**: We have clarified the distribution assumptions used in the  model in \u00a75. Section A.3 has been reworded to tie the ELBO formulation to Algorithm 1.\n\nWe hope we have answered all your queries and improved the paper. Let us know if we can address any additional questions or concerns and please consider updating your score if appropriate."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1767/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522394843,
                "cdate": 1700522394843,
                "tmdate": 1700522394843,
                "mdate": 1700522394843,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "RhFbLgq2kl",
            "forum": "eJFBMqCE4X",
            "replyto": "eJFBMqCE4X",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1767/Reviewer_Tr95"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1767/Reviewer_Tr95"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a hierarchical latent variable model for self-supervised representation learning. The lower-level latent variables correspond to the learned representations while the higher-level latent variables correspond to class/clusters. The authors propose an ELBO to the marginal log-likelihood and propose an algorithm to optimize the ELBO. The authors demonstrate that the resultant representations outperform representations learned by VAE.\n\nOther than that, the authors propose variational approaches for performing instance discrimination, deep clustering etc."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The primary strength of the model is that it follows from first principles.  The learned features are diverse and preserve stylistic information as compared to discriminative approaches."
                },
                "weaknesses": {
                    "value": "There are several weaknesses in this paper:\n\n1) The paper is very hard to read. The primary contribution of the paper is equation (7) defined over J semantically related samples. The rest of the paper is filled with a lot of claims that do not belong to the paper. For instance, section 4.1 has a latent variable approach to instance discrimination. It is neither interesting nor surprising that a latent-variable version of instance discrimination or any other model can be created. Unless it serves some purpose or offers extra insights, it should be removed.\nEverything except 4.2 needs to be removed from section 4. \n\n2) Having an entire section for representation learning is again wasteful. The representation learning section needs to be moved to related work.\n\n3) The authors should include the algorithm in their main paper rather than keeping it in the appendix.\n\nI have put other issues in the Questions section"
                },
                "questions": {
                    "value": "1) What is the purpose of adding equation 9) since J=6 is used during training and J=2 is never used?\n2) Which equation is used during training? Which equation corresponds to Algorithm 1? If it is equation 8), what is q(y|z1, ..., zJ). Infact it is necessary to show how  each of the distribution is represented."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1767/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1767/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1767/Reviewer_Tr95"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1767/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699356973499,
            "cdate": 1699356973499,
            "tmdate": 1700756936077,
            "mdate": 1700756936077,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KgbojLUmRJ",
                "forum": "eJFBMqCE4X",
                "replyto": "RhFbLgq2kl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1767/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1767/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors"
                    },
                    "comment": {
                        "value": "* **\"Authors propose variational approaches for performing instance discrimination, deep clustering\"/\"Equation 7 is the primary contribution of the paper\"** \n    Thank you for your feedback. As described in Section 1, our contributions are two-fold: \n    * [Section 3 \\& 4.1] we perform an analysis of existing discriminative SSL methods (i.e., contrastive learning, instance discrimination, latent clustering). By taking a latent variable perspective, we show how these methods can be tied back to a common framework. \n    * [Section 4.2] we leverage this analysis to formally define the graphical latent variable model (i.e., Figure 2) which unifies the aforementioned methods and for which we perform experimental validation to verify its soundness and how it can help improve downstream prediction over existing generative and SSL methods.\n    \n    We do not propose novel variational approaches for instance discrimination or deep clustering, but rather a latent variable model to unify these methods. \u00a73 & \u00a74.1 formalise a relationship between discriminative and generative methods and define the latent variable model to motivate SimVAE.\n    \n\n* **\"Hard to read\"**: Thank you for this feedback, which we have taken seriously and reworded the manuscript (in particular \u00a71-4) to improve clarity. Additional care was given to the detailed derivation of the proposed objective as well as its connection to the computational steps performed in practice (c.f., section A.3).\n\n* **\"Claims that do not belong to the paper\"**: As suggested, part of the representation learning section (\u00a73) has been moved to Background & Related Work (\u00a72). Sections 3 & 4.1 have been reworded to make clearer their contribution and connection to the rest of the paper. \u00a73 focuses on the relationship between generative and discriminative approaches to representation learning, makes this more formal than previously and is hopefully more clear. This shows that both methods can induce latent structure, hence we analyse various discriminative SSL methods (\u00a74.1) to show that they induce comparable latent structure, then take a generative approach to achieve the same (\u00a74.2). Without this link, we wouldn't provide a rationale for those existing SSL methods, we would simply be proposing a new approach.\n    \n* **\"Algorithm in the main paper\"**: Agreed, we have reformatted the paper to accommodate this.\n  \n     \n* **\"Purpose of equation 9\"**\n    This was included for clarity since many SSL methods compare pairs of data ($J=2$). However, we agree this is not necessary and have removed it to the appendix. \n    \n* **\"Equation used during training\"**\n    Thank you for your feedback. We reworded section 4.2, 5 and A.3 for greater clarity regarding the SimVAE objective, the involved distribution (including $q(y|z)$) and the connection between the ELBO and Algorithm 1, respectively.\n    * Equation 7 refers to the ELBO used to train SimVAE in the general case.\n    * In the paragraph below Eq. 7 we specify assumptions that we make (which for different data sets may be varied).\n    * In particular, we assume following: \n        * $q(z|x)$ and $p(x|z)$ are Gaussian, as in in typical VAE.\n        * $p(z|y) = \\mathcal{N}(z; \\mu_{y}, \\sigma^2)$ are Gaussian, with (small) fixed common variance $\\sigma^2$.\n        * that $y$ is continuous and uniformly distributed, allowing $y$ to be integrated out (as described in \u00a74.2).\n\n    These assumptions are reflected in Algorithm 1, which we implement in the experiments.\n    \nWe hope we have answered all your queries and improved the paper. Let us know if we can address any additional questions or concerns and please consider updating your score if appropriate."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1767/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522352991,
                "cdate": 1700522352991,
                "tmdate": 1700522352991,
                "mdate": 1700522352991,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]