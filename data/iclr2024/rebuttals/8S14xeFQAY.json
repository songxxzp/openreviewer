[
    {
        "title": "Segmenting the Unknown: Discrete Diffusion Models for Non-Deterministic Segmentation"
    },
    {
        "review": {
            "id": "WKY3Ov1Of2",
            "forum": "8S14xeFQAY",
            "replyto": "8S14xeFQAY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5672/Reviewer_ofDT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5672/Reviewer_ofDT"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces discrete diffusion models to address ambiguity and uncertainty in semantic segmentation, specifically for applications in oncology and autonomous driving. The authors propose a unified solution for two tasks: future prediction and medical image segmentation. This solution leverages the discrete diffusion framework to model segmentation annd prediction uncertainty. They also introduce an auto-regressive diffusion framework for future forecasting. Experimental evaluations were conducted on a Lung Cancer medical Imaging Dataset (LIDC) and two future prediction tasks, demonstrating the efficacy of their proposed generative framework."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper presents a unified approach to handle future prediction and image segmentation, reducing the need for distinct solutions for each task.\n\n- Experimental evaluations show that their model consistently outperforms equivalent deterministic models in all tasks. Additionally, the proposed generative framework surpasses existing VAE-based methods on LIDC and is on par with state-of-the-art methods on Cityscapes future prediction."
                },
                "weaknesses": {
                    "value": "- There is a heavy reliance on existing ideas, with incremental adaptation to an existing discrete diffusion model. The paper simply employs input conditioning via concatenation to adapt the generative model for segmentation. Moreover, autoregression for future prediction is just conditioned on past segmentations, leaving out crucial technical details that would illuminate the depth of the contribution.\n\n- The paper did not explicitly define the type of uncertainty being captured, leaving ambiguity between aleatoric (data) and epistemic (model) uncertainty.\n\n- While the paper compares its approach to deterministic methods, it lacks comprehensive comparisons with existing work in uncertainty quantification in semantic segmentation.\n\n- Results show samples of the posterior, yet uncertainty is not explicitly quantified."
                },
                "questions": {
                    "value": "- Given the lack of clarity on the type of uncertainty captured, can the authors specify whether it is aleatoric or epistemic uncertainty?\n\n- The title suggests the capability to segment unknown classes. Can the authors clarify this claim?\n\n- The paper discusses the potential for forcing diversity in the sampling process. Can the authors elaborate on possible methods to achieve this?\n\n- Why is there a lack of comprehensive comparisons with existing uncertainty quantification methods in semantic segmentation?\n\n- With the heavy reliance on existing ideas, can the authors provide further technical details or novel contributions that differentiate their approach from previous work?\n\n- Considering the importance of understanding and reporting both types of uncertainties, why was this aspect not heavily emphasized in the paper? Furthermore, can the authors shed light on how uncertainty is being evaluated and calibrated?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5672/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5672/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5672/Reviewer_ofDT"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5672/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698603757970,
            "cdate": 1698603757970,
            "tmdate": 1700695356171,
            "mdate": 1700695356171,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "IGuy2XeHp3",
                "forum": "8S14xeFQAY",
                "replyto": "WKY3Ov1Of2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5672/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5672/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank you for your comments.  \nWe wanted to emphasize that, while one can see some connections between our work and uncertainty estimation, our work is not about uncertainty estimation. We introduce a concrete novel way to leverage discrete generative diffusion models for segmenting ambiguous contexts, and we assess their performance. We expand more on that point below.\n\n---\n## Detailed Answers:\n\n> Given the lack of clarity on the type of uncertainty captured, can the authors specify whether it is aleatoric or epistemic uncertainty?\n\nWe consider aleatoric uncertainty, as we use experimental setups where the input has multiple possible valid segmentations.\n\n> The title suggests the capability to segment unknown classes. Can the authors clarify this claim?\n\nNo, we do not make such a claim. The \u201dunkwown\u201d refers to the ambiguity present in the contexts we consider. In\nparticular, when doing future prediction, the future state is unknown, yet\nwe propose a way to segment it.\n\n> The paper discusses the potential for forcing diversity in the sampling\nprocess. Can the authors elaborate on possible methods to achieve this?\n\nIn our concluding remarks, we indeed identified encouraging diversity as a\nfuture research direction. A feasible initial approach would be to slightly\npenalize the previously predicted classes when generating the new segmentation. This serves as a baseline in our ongoing research.\n\n> Why is there a lack of comprehensive comparisons with existing uncertainty quantification methods in semantic segmentation?\n\n> Considering the importance of understanding and reporting both types of\nuncertainties, why was this aspect not heavily emphasized in the paper?\nFurthermore, can the authors shed light on how uncertainty is being evaluated and calibrated?\n\nWe will add a section in our literature review on the most related uncertainty estimation methods for segmentation.  \n**However, uncertainty estimation is not the focus of our work**. We do not evaluate it.  \nWe present a concrete way to leverage discrete generative diffusion models for ambiguous contexts, and we assess whether these models follow the data distribution and have the capacity to generate different predictions.\nWe have chosen our experimental setup to be contexts where there is true uncertainty so that multiple different predictions could be equally valid. Estimating the model uncertainty in these contexts would be a proxy for estimating the dataset uncertainty, but we believe it would not reveal more useful information about the model.\n\n> With the heavy reliance on existing ideas, can the authors provide further technical details or novel contributions that differentiate their approach from previous work?\n\nOur work builds on existing ideas, but we propose an adaptation of these to segmentation, both as an image-to-segmentation model with LIDC and as an autoregressive segmentation-to-segmentation model with our two other experiments.\nWe proposed these modifications and implemented and evaluated the use of discrete diffusion segmentation models in 3 diverse ambiguous setups to showcase their viability for this purpose.\nIn fact, a very recent work [1] proposes a quite similar method, but applied only on LIDC, and was recently accepted at ICCV.  \n\nWe also refer you to our answers to Reviewer 1 (qH1j) regarding discussions with some similar and related works.\n\n[1] Stochastic Segmentation with Conditional Categorical Diffusion Models (https://arxiv.org/abs/2303.08888)"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5672/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700528207630,
                "cdate": 1700528207630,
                "tmdate": 1700528207630,
                "mdate": 1700528207630,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "OSKfZNNsYT",
                "forum": "8S14xeFQAY",
                "replyto": "IGuy2XeHp3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5672/Reviewer_ofDT"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5672/Reviewer_ofDT"
                ],
                "content": {
                    "comment": {
                        "value": "Thank to the authors for their responses to the concerns I initially raised. In light of these clarifications, and also considering the perspectives presented in other reviews, I have decided to revise my evaluation and raise my score for your submission."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5672/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700695484516,
                "cdate": 1700695484516,
                "tmdate": 1700695484516,
                "mdate": 1700695484516,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "TOK7P2ZBWD",
            "forum": "8S14xeFQAY",
            "replyto": "8S14xeFQAY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5672/Reviewer_27GV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5672/Reviewer_27GV"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces discrete diffusion models to capture uncertainty in semantic segmentation, with application in both oncology and autonomous driving. Unlike prior approaches that tackle these tasks in distinct ways, the proposed method formulates both as estimating a complex posterior distribution over images, and presents a unified solution that leverages the discrete diffusion framework. The contributions include the adaptation of discrete diffusion for semantic segmentation to model uncertainty and the introduction of an auto-regressive diffusion framework for future forecasting. Experiments have been conducted on both medical imaging data and real-world future prediction tasks to demonstrate the superiority of the proposed generative framework over deterministic models and its competitive performance compared to methods specific to these domains separately."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The idea of presenting a unified solution for both future prediction and medical image segmentation is interesting, by leveraging diffusion models.\n- This paper proposes the first method to model the uncertainty of predictions using discrete diffusion models in semantic segmentation.\n- The proposed method is quite straightforward to follow."
                },
                "weaknesses": {
                    "value": "- The experimental section is limited. I expect to see the results of more baselines. For example, how the proposed method is compared with GAN-based methods? \n- There are lots of works regarding uncertainty estimation in (semantic) segmentation [1,2,3], just list a few. I would like to see the authors do a thorough review of these kinds of methods and provide a comprehensive comparison with the proposed method.  \n- Beyond the segmentation evaluation metrics, I am expecting the see more empirical results regarding uncertainty estimation. Some of the metrics can be found in [4,5].\n\n[1] Nair, Tanya, et al. \"Exploring uncertainty measures in deep networks for multiple sclerosis lesion detection and segmentation.\" Medical image analysis 59 (2020): 101557.\n\n[2] Fleuret, Francois. \"Uncertainty reduction for model adaptation in semantic segmentation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\n\n[3] Czolbe, Steffen, et al. \"Is segmentation uncertainty useful?.\" Information Processing in Medical Imaging: 27th International Conference, IPMI 2021, Virtual Event, June 28\u2013June 30, 2021, Proceedings 27. Springer International Publishing, 2021.\n\n[4] Moon, Jooyoung, et al. \"Confidence-aware learning for deep neural networks.\" international conference on machine learning. PMLR, 2020.\n\n[5] Li, Chen, Xiaoling Hu, and Chao Chen. \"Confidence Estimation Using Unlabeled Data.\" International Conference on Learning Representations. 2023."
                },
                "questions": {
                    "value": "N/A"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5672/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698815172963,
            "cdate": 1698815172963,
            "tmdate": 1699636591454,
            "mdate": 1699636591454,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wixQi7kEee",
                "forum": "8S14xeFQAY",
                "replyto": "TOK7P2ZBWD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5672/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5672/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank you for your comments, and for pointing to uncertainty estimation literature.  \nWe are pleased that you noted the simplicity of our solution and its ability to work in diverse settings, and that you found it interesting.  \nWe wanted to emphasize that, while one can see some connections between our work and uncertainty estimation, our work is not about uncertainty estimation. We introduce a concrete novel way to leverage discrete generative diffusion models for ambiguous segmentation contexts, and we assess their performance. We expand more on that point below.\n\n---\n## Detailed Answers:\n\n> The experimental section is limited. I expect to see the results of more\nbaselines. For example, how the proposed method is compared with GAN-based methods?\n\nWe will add more related works on LIDC experiments.\nTo our knowledge, no GAN-based method has been\napplied to this problem, and our work focuses on showing the ability of\ndiffusion models to handle ambiguity. GANs are known to have mode\ncollapse issues when learning distribution and can additionally be particularly hard to train.\nWhile it would be interesting to check how a particular GAN architecture would perform in our experimental setup, this is\nnot the focus of this study and could be viewed as another contribution in itself.\n\n> There are lots of works regarding uncertainty estimation in (semantic)\nsegmentation [1,2,3], just list a few. I would like to see the authors do\na thorough review of these kinds of methods and provide a comprehensive comparison with the proposed method.\n\nThank you for the pointers to relevant literature! We will definitely add a section to our literature review of the most related uncertainty estimation methods for segmentation. We want to emphasize though that the focus of our work is not on uncertainty estimation, but rather on presenting a concrete way to leverage discrete generative diffusion models for ambiguous contexts, and on assessing whether these models are able to follow the data distribution.\n\n> Beyond the segmentation evaluation metrics, I am expecting the see more\nempirical results regarding uncertainty estimation. Some metrics\ncan be found in [4,5].\n\nAs said above, we focus on the segmentation task and the capacity of the network to generate different predictions.\nWe have chosen our experimental setup to be contexts where there is true uncertainty, so that multiple different predictions could be equally valid. Estimating the model uncertainty in these contexts would be a proxy for estimating the dataset uncertainty, but we believe it would not reveal more useful information about the model. However, any metric measuring the model uncertainty at the image level to assess the model confidence on a specific image could still be applied. In the case of the LIDC dataset, we could consider adding a correlation analysis of the model uncertainty per image with the ground-truth variations."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5672/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700528203271,
                "cdate": 1700528203271,
                "tmdate": 1700528203271,
                "mdate": 1700528203271,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YPG61g22YY",
                "forum": "8S14xeFQAY",
                "replyto": "TOK7P2ZBWD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5672/Reviewer_27GV"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5672/Reviewer_27GV"
                ],
                "content": {
                    "comment": {
                        "value": "If the authors argue that this submission is about using the diffusion model for segmentation instead of uncertainty estimation, I would suggest the authors reorganize the paper and clarify the point. And also, if this is the case, the value of this submission to me is even more limited."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5672/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700711308950,
                "cdate": 1700711308950,
                "tmdate": 1700711343217,
                "mdate": 1700711343217,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "jov44eczBg",
            "forum": "8S14xeFQAY",
            "replyto": "8S14xeFQAY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5672/Reviewer_qH1j"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5672/Reviewer_qH1j"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents an approach to apply discrete diffusion models to model uncertainty for both semantic segmentation and future forecasting semantic segmentation. The authors evaluate their method on both simulated data an real data and claim competitive performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The work mostly clearly contextualizes and motivates its approach in relation to prior work. The work cleverly transfers existing methods to new problems. \\\nThe method is evaluated for multiple settings, showing that it is versatile and not restricted to a single problem setting, and for multiple datasets. The selection is motivated well. \\\nThe supplement provides thorough information regarding experimental details."
                },
                "weaknesses": {
                    "value": "A number of results with better performance for the LIDC dataset are missing, giving the impression that the results are sota (see Table 1 in [1]) \\\nA prior work [1] has previously proposed the use of discrete diffusion for handling uncertainty in semantic segmentation. This somewhat limits the novelty, however I think the two works can still be counted as concurrent work. \\\nA more detailed qualitative evaluation for Cityscapes would have been interesting. Where does the method perform well, where does it show weaknesses, does it learn something about the movement of other entities in the scene, where does the performance improvement from 1 to 100 samples evaluation come from? \\\nThe work shows in the car simulator dataset that the method does generate a variety of future scenarios, however it is not shown for the more complex Cityscapes dataset. Showing it quantitatively is of course difficult with the existing data, however it is also not clearly shown qualitatively. \\\nFor scenarios like the mentioned \"Is there a scenario in which the child crosses the road?\" to be applicable real-time performance is essential. The inference time for the method on the Cityscapes data is not mentioned. \n\n[1] https://arxiv.org/abs/2303.08888"
                },
                "questions": {
                    "value": "Questions \n\nRegarding the motivating example, how is it defined which rectangle is \"rectangle 1\" and which is \"rectangle 2\"? In other words, given an image, how can I distinguish the two categories of \"the rectangles have different classes\"? Secondly, what are the two categories the deterministic model predicts? \\\n[1] was made public earlier this year. Can you please elaborate on the differences to the work at hand? \\\nChen et al. (2022a) (referenced by you) was made public last year. While they do not show results regarding handling ambiguity, at first glance it seems to be applicable. Does the approach at hand have specific properties that would make it more advantageous for this task compared to their approach? \\\nFor clarification, in 4.2.2: For each car in each validation example 10 samples are generated. The best of the 10 samples is selected according to FDE. 84% of those FDE values are less then 2 (a \"hit\"). And then the mean of the best FDE values (hit and miss) is computed. Is this correct? I am not sure the mean is very informative then as the distribution seems to be quite skewed.\n \nGeneral Notes \n\nThere seems to be quite a bit of interesting information in the supplement that is never referenced in the main paper, e.g., the MO results for Cityscapes, making it difficult for the reader to be aware of it. \\\nIn Sec 3.1/2 it is not always fully clear to me what parts are from Austin et al. and what parts are adaptations by the authors.\n\nMost issues have been addressed satisfactorily in the Discussion Phase, thus I've updated my rating from 5 to 6."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5672/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5672/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5672/Reviewer_qH1j"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5672/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698839312337,
            "cdate": 1698839312337,
            "tmdate": 1700691677598,
            "mdate": 1700691677598,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "QVfAxQ20X5",
                "forum": "8S14xeFQAY",
                "replyto": "jov44eczBg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5672/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5672/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank you much for your comments and pointing to relevant literature we missed!  \nWe are happy that you noted our diverse experimental setting and found it was well-motivated.  \nWe took into account your general notes: we will better reference the\ninteresting supplementary results and clarify the difference with Austin et al.  \nAdditionnaly, we will include in the paper our discussion below regarding the Cityscapes results.\n\n---\n## Detailed Answers:\n\n> Regarding the motivating example, the definition of the rectangles and the prediction of the deterministic model:\n\n*Differentiation of Rectangles*: The rectangles within the images\nare not assigned fixed identifiers such as \u201dRectangle 1\u201d or \u201dRectangle 2\u201d.\nFor each image, we create 2 rectangles, randomly assigned to one of 4\nclasses. However, the classes 1 and 2 have the same color in the input\nimage, just as the classes 3 and 4. In practice, on the generation plots,\nthe color mapping we use for each class is: {1: blue, 2: orange, 3: green,\n4: red}. In the input image, the class 1 and 2 are in red while the class\n3 and 4 are in green.  \n*Categories Predicted by the Deterministic Model*:\nThe deterministic model was trained to predict categories based on the\ncolors of the rectangles. However, due to the inherent randomness in our\ndataset, where each color can correspond to two different categories, the\ndeterministic model tends to predict only one of the two possible classes,\nnamely classes 1 and 4 as seen in Figure 2b.\n\n> Regarding the difference with [1]:\n\nWe were unaware of [1] and apologize\nfor failing to cite the other relevant related papers. We will include these\nin the related works and the LIDC results table when relevant. The work in\n[1] is indeed very close to ours. They also use a discrete diffusion model,\nwhich they name categorical, and add image conditioning in a similar\nway. Our methods are very similar, however the two papers overall have\nmultiple differences: (1) we additionally propose an autoregressive\nscheme for doing future prediction. In this case, our network is performing\n\u2018segmentation to segmentation\u2019, which means the input to the network\nis only one or multiple previous segmentation maps. (2) we provide a\nmotivating example that clearly shows the sampling ability of the model\nand in particular the fact that it properly follows the data distribution.\n(3) we evaluate on different datasets: LIDC aside, we introduce a new car\nintersection simulation dataset designed to offer a finite set of valid future\n trajectories; we evaluate on the future prediction task on the Cityscapes Dataset.\n\n> Regarding the applicability of Chen et al. (2022a):\n\nTheir approach would also be applicable but is significantly\ndifferent. First, their way of handling the discrete aspect of segmentation\nis different. In fact, they do not use discrete diffusion, they are instead\nmapping discrete classes to a continuous vector representation and then\ndoing continuous diffusion. Also, note that their work focuses on panoptic\nsegmentation, which might necessitate modifications to the network structure. Nonetheless, leveraging instance data from datasets where it exists\ncould prove advantageous.\n\n> For each car in each validation example 10 samples\n are generated. The best of the 10 samples is selected according to\nFDE. Then the\nmean of the best FDE values (hit and miss) is computed. Is this correct?\nI am not sure the mean is very informative as the distribution seems to be quite skewed.\n\nYou are correct, we select the best FDE of the ten\nsamples and then perform the mean over the validation set. The mean is\ninformative, but you are correct in saying that a high miss can influence\nit strongly, which is why we also report the miss rate and consider it as\nour main ranking measure, and we will emphasize it more in the updated\npaper.\n\n> Regarding the Cityscapes experiment:\n\nThank you for this relevant question.\nWe noticed that there is not as much ambiguity in the Cityscape's future\nsegmentation task as one could expect. Indeed, given 3 past frames,\nthe long-term future (1.5s) has little space for unexpected events, and we\nshould note that Cityscapes does not feature a very chaotic environment,\nwith disciplined German pedestrians. Therefore, a deterministic model\ncan already do a very good job at predicting future segmentation, and\nthe differences will mostly lie in slight speed variations, which will result\nin slight displacements of object boundaries. Multiple sampling allows to\ncover more of these possible speed variations, but do not generate completely\n different scenarios, as in the car intersection simulation. While we\nwould ideally be able to answer a question such as \u201dwill the child cross the\nroad\u201d, the nature of Cityscapes and the relatively short time delta of the prediction with the current frame does not allow us to showcase such things happening, but we hope our work is a step in that direction."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5672/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700528196485,
                "cdate": 1700528196485,
                "tmdate": 1700528196485,
                "mdate": 1700528196485,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fPGWo0lCUO",
                "forum": "8S14xeFQAY",
                "replyto": "QVfAxQ20X5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5672/Reviewer_qH1j"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5672/Reviewer_qH1j"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your replies to my comments and the comments of the other reviewers.\nOverall most concerns have been addressed sufficiently, and I update my score respectively.\n\nSome more notes:\n* If there is not a lot of ambiguity in the CityScapes dataset, maybe it is not a good choice for this paper?\n* I am still not sure what a mean FDE of 68 or 11.9 is supposed to tell me. Yes, higher is worse, but beyond that? Even for the deterministic model with a mean of 68 the median is still ~2. In addition, why is it better to choose a wrong exit that is closer than one that is further away? (wrt to the question how well the ambiguity is modeled) Which wrong exit is chosen has a strong impact on the mean.\n* Wrt Chen et al. (2022a), panoptic segmentation is in the end just semantic+instance, not using the instance part should be trivial. It would still be interesting if there are pros and cons to your approach vs their approach or if there is no difference."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5672/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700691558195,
                "cdate": 1700691558195,
                "tmdate": 1700691558195,
                "mdate": 1700691558195,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]