[
    {
        "title": "Which Examples to Annotate for In-Context Learning? Towards Effective and Efficient Selection"
    },
    {
        "review": {
            "id": "q41Ksq1xSU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8269/Reviewer_LBWT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8269/Reviewer_LBWT"
            ],
            "forum": "npf3gREtf7",
            "replyto": "npf3gREtf7",
            "content": {
                "summary": {
                    "value": "This paper explores in-context learning (ICL) for Large Language Models (LLMs) where the goal is to adapt the model to new tasks with minimal annotation. It introduces ADAICL, an active learning approach that efficiently selects examples for annotation within a limited budget. ADAICL identifies uncertain examples for the model and uses semantic diversity-based selection. This approach, treated as a maximum coverage problem, dynamically adapts based on the model's feedback. Experiments across datasets and LLMs demonstrate ADAICL's superiority, improving accuracy over state-of-the-art works and being up to 3 times more budget-efficient than random annotation. It also outperformed existing methods with half the number of annotated examples."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The motivation is clear. It is significant to study how to determine which unlabeled instances should be labeled. This is important to reduce the cost of annotations in in-context learning. \n- Experimental results are overall great. On a series of tasks, the proposed method can achieve the best performance."
                },
                "weaknesses": {
                    "value": "- The contributions are somewhat overclaimed.\n- Technical contributions are not sufficient. \n- The writing also should be polished. For the current form, there are a series of unclear justifications.\n\nMore details about the above weaknesses can be checked below."
                },
                "questions": {
                    "value": "- It is possible to meet outliers if the method overemphasizes the selection of diverse data. However, in the current form, it is not clear how to address the issue. \n- Does the $k$-NN retriever equal the similar retriever in the Vote-$k$ paper?\n- This paper claims that \"However, these approaches do not consider which examples help the LLM learn new information and may waste resources for annotating examples whose answers are already within the model\u2019s knowledge.\" I am somewhat confused about this claim. The method Vote-$k$ also uses the feedback of LLMs. Could the paper give more details about this?\n- Does the uncertain with respect to one example equal that the LLM can learn it accurately?\n- The paper argues that previous work assumes a high-resource setting, where a large set of ICL examples is already annotated. Could the paper provide some detailed examples for better understanding?\n- For Section 4.1, could the paper provide more details about how to obtain the probability with respect to the label or demonstrations?\n- Compared with previous work such as Vote-$k$, the method proposed by this work is more complex. It introduces a series of hyper-parameters. How to balance them in practice? Also, is there a time advantage of the proposed method over baselines?\n- What is the definition of \"egonet\" in this paper?\n- For Figure 5, could the paper supplement the comparison between all methods not just the best baseline?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8269/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697340465195,
            "cdate": 1697340465195,
            "tmdate": 1699637028396,
            "mdate": 1699637028396,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FuW0JjXhhF",
                "forum": "npf3gREtf7",
                "replyto": "q41Ksq1xSU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8269/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8269/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer LBWT (1/2)"
                    },
                    "comment": {
                        "value": "We thank the Reviewer for their appreciation of the presentation and the motivation and also acknowledging the strong experimental results across multiple datasets and tasks over contemporaneous baselines. We proceed here below in replying to the comments in specific.\n\n**W1: The contributions are somewhat overclaimed.**\n\n**A1**. We study active learning for ICL in the practical low-resource scenario, and highlight the importance of diversity-based uncertainty sampling. All AdaICL variants (AdaICL-base, AdaICL, AdaICL) are shown to be effective for ICL, while our optimization formulation (Section 4.2 and 4.3) provides a new framework for combining uncertainty and diversity sampling.\n\n**W2: Technical contributions are not sufficient.**\n\n**A2**. AdaICL performs subset selection based on the hard examples for the LLM, and solves a submodular maximization (MaxCover) problem that captures interactions of different hard examples and their effect during retrieval-based ICL. We believe these are important technical contributions, with connections to previous AL works for kNN classifiers [1].\n\n[1] Wei, Kai, Rishabh Iyer, and Jeff Bilmes. \"Submodularity in data subset selection and active learning.\" ICML, 2015. [(link)](xhttp://proceedings.mlr.press/v37/wei15.pdf)\n\n**W3: The writing also should be polished. For the current form, there are a series of unclear justifications.**\n\n**A3**. We hope that our response addresses the Reviewer's comment and provides more clarifications. We will update the manuscript accordingly.\n\n**Q1: It is possible to meet outliers if the method overemphasizes the selection of diverse data. However, in the current form, it is not clear how to address the issue.**\n\nAs we mention in Section 4.1, AdaICL-base uses kmeans clustering that may be affected by outliers. We then propose AdaICL (Section 4.2) that mitigates the effect of outliers by preferring representative examples of dense regions. Finally, AdaICL+ (Section 4.3) aims at avoiding some failing cases of AdaICL, e.g., the case in Figure 9 (Appendix).\n\n**Q2: Does the k-NN retriever equal the similar retriever in the Vote-k paper?**\n\nExactly, all the methods (Random, Votek, AdaICL variants) use the exact same retriever during inference (e.g., retrieval based on SBERT embeddings). Tables 2 and 8 show that AdaICL is robust with respect to the retriever employed.\nPlease also refer to \u201cGeneral Response: Pipeline of the compared methods\u201d.\n\n\n**Q3: This paper claims that \"However, these approaches do not consider which examples help the LLM learn new information and may waste resources for annotating examples whose answers are already within the model\u2019s knowledge.\" I am somewhat confused about this claim. The method Vote-k also uses the feedback of LLMs. Could the paper give more details about this?**\n\nVotek does not perform uncertainty sampling, but uses the LLM\u2019s feedback to partition the examples into $B$ bins (budget equals to $B$) and selects one example from each bin. This might select easy examples for the model, which lead to poor calibration (as it is shown in Section 6.3) or waste annotation resources (Table 1).  In contrast, AdaICL solves a MaxCover problem iteratively, which is adapted to the LLM\u2019s feedback, and does not assume any predefined data partition, e.g., to $B$ bins."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8269/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700076425814,
                "cdate": 1700076425814,
                "tmdate": 1700076425814,
                "mdate": 1700076425814,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JpvbT3m30a",
                "forum": "npf3gREtf7",
                "replyto": "q41Ksq1xSU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8269/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8269/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer LBWT (2/2)"
                    },
                    "comment": {
                        "value": "**Q4: Does the uncertain with respect to one example equal that the LLM can learn it accurately?**\n\nWe optimize the MaxCover problem, which assumes that if we annotate an example that the model is uncertain about, it will provide new information to the LLM which can improve its predictions on its neighboring examples (hard examples included in its region).\n\n**Q5: The paper argues that previous work assumes a high-resource setting, where a large set of ICL examples is already annotated. Could the paper provide some detailed examples for better understanding?**\n\nIn this work, we focus on the \u201ccold-start\u201d problem, similar to Votek, where we are given an unlabeled set to select examples from. Most of the related works in AL for ICL assume they are given an annotated validation set, which needs to be statistically large and is not practical for real world few-shot applications [2]. The validation set is leveraged for measuring the informativeness of each individual example as well as for hyperparameter tuning. For example, [3] employs reinforcement learning, which requires one set of labeled examples for policy training and another set of labeled examples for reward estimation.\n\n[2] Ethan Perez, Douwe Kiela, and Kyunghyun Cho. \u201cTrue few-shot learning with language models\u201d. NeurIPS, 2021. [(link)](https://arxiv.org/pdf/2105.11447.pdf) \\\n[3] Zhang, Yiming, Shi Feng, and Chenhao Tan. \"Active example selection for in-context learning.\" EMNLP, (2022). [(link)](https://arxiv.org/pdf/2211.04486.pdf)\n\n**Q6: For Section 4.1, could the paper provide more details about how to obtain the probability with respect to the label or demonstrations?**\n\nWe follow previous works (MetaICL, Votek), but we would like to make our writing more clear: We feed the model by concatenating the kNN retrieved demonstrations $ [ (x_1, y_1), \u2026 (x_k, y_k), x_{k+1} ] $ to compute the negative log-probability for each label $y \\in \\mathcal{Y}$ for $x_{k+1}$. We keep the prediction with the highest negative log-probability (model\u2019s predicted label with highest confidence) and use its negative log-probability as the uncertainty score. We select the examples with the highest uncertainty scores for the set $U_h$.\n\n**Q7: Compared with previous work such as Vote-k, the method proposed by this work is more complex. It introduces a series of hyper-parameters. How to balance them in practice? Also, is there a time advantage of the proposed method over baselines?**\n\nGreat questions, we have proposed a heuristic-based rule (Appendix A.3) for determining these hyper-parameters in practice. Moreover, AdaICL-base does not have many hyper-parameters (apart from the number of clusters $K$ and the uncertainty threshold $\\theta$), but outperforms Votek in many tasks (Tables 6 and 7).\n\n**Q8: What is the definition of \"egonet\" in this paper?**\n\nThe egonet is the set of nodes that connect to a central node within N-hops. In our work, the hard region $S_i$ centered around node $i$ includes either hard nodes within 1-hop or within 2-hops.  We will omit the wording \u201cegonet\u201d in the new version to avoid any confusion.\n\n**Q9: For Figure 5, could the paper supplement the comparison between all methods not just the best baseline?**\n\nYes, thank you for the suggestion. We are working on collecting the experimental results and will update the manuscript accordingly before the rebuttal deadline."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8269/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700076481128,
                "cdate": 1700076481128,
                "tmdate": 1700095085831,
                "mdate": 1700095085831,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "FIfVd2Rw0K",
            "forum": "npf3gREtf7",
            "replyto": "npf3gREtf7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8269/Reviewer_6M3N"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8269/Reviewer_6M3N"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a method to select samples to present for ICL based on set coverage in an embedding space. The proposed method, AdaICL, uses a greedy approximation for the MaxCover problem to select sets that cover as many hard problems as possible. AdaICL outperforms baselines on a wide variety of tasks and does not appear to be too expensive to run.\n\nI think this paper is closer to a 7 than 6 but unfortunately 7 is not an option on the rating scale."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Good empirical performance on a wide variety of LLMs and datasets.\n- AdaICL appears to outperform kMeans based retrievers such as Votek and AdaICL base\n- AdaICL appears to be more robust to sample presentation order than the baselines on some tasks"
                },
                "weaknesses": {
                    "value": "- Why is the semantic similiarity space determined by a 3rd party embedding model such as SBERT? Shouldn't this be from the LLM itself, such as from an embedding layer?\n- How does overall performance depend on $m$ in $G_m$?\n- My understanding is that AdaICL queries a LLM many times to get confidence scores *before* feeding the final prompt in to get $y_{test}$. How do the various baselines and AdaICL compare when limited to the same LLM query budget? For example, random selection requires 0 queries, which could be far cheaper than running AdaICL."
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8269/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8269/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8269/Reviewer_6M3N"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8269/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698009053317,
            "cdate": 1698009053317,
            "tmdate": 1699637028292,
            "mdate": 1699637028292,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "W1xWOckekV",
                "forum": "npf3gREtf7",
                "replyto": "FIfVd2Rw0K",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8269/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8269/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 6M3N (1/1)"
                    },
                    "comment": {
                        "value": "We thank the Reviewer for their appreciation of the strong experimental results across multiple datasets and tasks over contemporaneous baselines as well as the robustness of AdaICL. We proceed here below in replying to the comments in specific.\n\n**W1: Why is the semantic similiarity space determined by a 3rd party embedding model such as SBERT? Shouldn't this be from the LLM itself, such as from an embedding layer?**\n\n**A1**. Thank you for raising this point. We use 3rd party embeddings due to their applicability in practice. First, small-scale LMs, such as SBERT, are much faster at computing embeddings, compared to the LLMs with billions of parameters. Second, for many black-box LLMs, we do not have access to their intermediate layers (or parameters) but only to their outputs (predictions and token logprobabilities). Finally, we have performed experiments with different embedding models (Table 2 and 8), which show that AdaICL is robust to the embedding model selection.\n\n**W2: How does overall performance depend on m in $\\mathcal{G}_m$?**\n\n**A2**. We have performed extensive AdaICL ablation studies in Appendix D. Table 11 shows the overall performance with respect to different m values in G_m. In addition, Table 12 compares alternative ways of constructing $\\mathcal{G}$.\n\n**W3: My understanding is that AdaICL queries a LLM many times to get confidence scores before feeding the final prompt in to get $y_{test}$ . How do the various baselines and AdaICL compare when limited to the same LLM query budget? For example, random selection requires 0 queries, which could be far cheaper than running AdaICL.**\n\n**A3**. This is an important point. All model-based selection methods (\u201cHardest\u201d, Votek, AdaICL variants) query the LLM on all candidate examples to get their confidence scores. We have performed a time analysis in Appendix C5 for the example selection process (Random selection has zero cost). With the downsampled version of data, AdaICL outperforms Random without involving many LLM queries.\nDuring inference, all methods (Random, Votek, AdaICL) have the same cost.\nPlease also refer to \u201cGeneral Response: Pipeline of the compared methods\u201d."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8269/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700076322954,
                "cdate": 1700076322954,
                "tmdate": 1700076322954,
                "mdate": 1700076322954,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "OGz8eKE16C",
            "forum": "npf3gREtf7",
            "replyto": "npf3gREtf7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8269/Reviewer_m5zU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8269/Reviewer_m5zU"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose an example selection method for in-context learning via active learning techniques. Given an unlabeled set $\\mathcal{U}$ of examples, the authors first choose the set of hard examples $\\mathcal{U}_h$ based on model's confidence score $u_i$. Then choose examples up to a given budget $B$ from centroids of each k-mean cluster, which is termed as $\\texttt{AdaIcl-base}$. To improve the method, the Maximum Coverage problem is applied. The goal is then to choose $B$ most representative example that cover the most semantic space by building a global graph based on the semantic embedding space ($\\texttt{AdaIcl}$). To further improve the method, hard examples are selected from denser regions (instead of outliers) by implementing the re-weighting schema ($\\texttt{AdaIcl+}$). The results show effective improvement over nine datasets and seven LLM models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "+ The authors provide an intuitive approach which does make sense with additional efficiency.\n+ The paper is well structured.\n+ Results over many models and datasets showing great performance of variants of $\\texttt{AdaICL}$."
                },
                "weaknesses": {
                    "value": "- The construction of the graph is highly dependent on other off-the-shelf encoders, which might not be representative of the target model.\n- The method requires multiple prompts to get LLM feedbacks (probability scores) for each example, which is expensive.\n- Quite outdated models used (even given the ICLR submission date), so it is hard to verify if the method is applicable to more up-to-date LLMs."
                },
                "questions": {
                    "value": "- How are you performing k-mean clustering for $\\texttt{AdaIcl-base}$? \n\n- What embedder are you using for choosing top-k examples?\n\n- Have you compared to any similarity based baselines?\n\n- Have you compared to any retriever-based baselines?\n\n- Question about the practical setting. If we need to annotate the selected examples on demand based on the query, then why not annotate directly the query? \n\n- Why are you choosing top-$N_{\\theta}$ examples based on probability scores? Would uncertain examples mean bottom-$N_{\\theta}$? \n\n- RQ4. is provided but not addressed in the main paper nor referred to Appendix?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8269/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8269/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8269/Reviewer_m5zU"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8269/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698801967405,
            "cdate": 1698801967405,
            "tmdate": 1699637028178,
            "mdate": 1699637028178,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "owU5LY6cF2",
                "forum": "npf3gREtf7",
                "replyto": "OGz8eKE16C",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8269/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8269/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer m5zU (1/2)"
                    },
                    "comment": {
                        "value": "We thank the Reviewer for their appreciation of the well structured presentation of the paper and for acknowledging the strong experimental results. We proceed here below in replying to the comments in specific.\n\n**W1: The construction of the graph is highly dependent on other off-the-shelf encoders, which might not be representative of the target model.**\n\n**A1**. AdaICL\u2019s graph construction depends on embedding space, which is also true for other methods that use semantic diversity (kmeans, Votek, AdaICL-base). Tables 2 and 8 show that AdaICL is robust to the selection of the embedding model. Moreover, as raised by reviewer 6M3N, we use 3rd party embeddings due to their applicability in practice. First, small-scale LMs, such as SBERT, are much faster at computing embeddings, compared to the LLMs with billions of parameters. Second, for many black-box LLMs, we do not have access to their intermediate layers (or parameters) but only to their outputs (predictions and token logprobabilities).\n\n**W2: The method requires multiple prompts to get LLM feedbacks (probability scores) for each example, which is expensive.**\n\n**A2**. This is an important point. All model-based selection methods (\u201cHardest\u201d, Votek, AdaICL variants) query the LLM on all candidate examples for annotation to get their confidence scores. We have performed a time analysis in Appendix C5 for the example selection process (Random selection has zero cost). With the downsampled version of data, AdaICL outperforms Random without involving many LLM queries. During inference, all methods (Random, Votek, AdaICL) have the same cost. \\\nPlease also refer to \u201cGeneral Response: Pipeline of the compared methods\u201d.\n\n\n**W3: Quite outdated models used (even given the ICLR submission date), so it is hard to verify if the method is applicable to more up-to-date LLMs.**\n\n**A3**. Our experiments (Figs. 4 and 6) show that our AdaICL selection strategy generalizes across different LLMs with varying sizes, which --we believe-- make AdaICL\u2019s contributions clear."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8269/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700076143581,
                "cdate": 1700076143581,
                "tmdate": 1700076143581,
                "mdate": 1700076143581,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QFP51eeYFK",
                "forum": "npf3gREtf7",
                "replyto": "OGz8eKE16C",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8269/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8269/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer m5zU (2/2)"
                    },
                    "comment": {
                        "value": "**Q1: How are you performing k-mean clustering for AdaICL-Base?**\n\nDuring the selection process, we select which examples to annotate (set $\\mathcal{L}$) by (i) identifying hard examples for the model (default is 50% most uncertain) , (ii) cluster them into $K$ clusters with $K=B$ ($B$ is the budget), and (iii) selecting the examples closest to each cluster centroid to be added to $\\mathcal{L}$. The algorithm is summarized in Appendix A.1.\n\nDuring inference, set $\\mathcal{L}$ is used for retrieval-based ICL. To compare AdaICL-base with random selection, Random creates the set $\\mathcal{L}$ drawing $B$ examples at random. Inference is the same for both AdaICL-base and Random ($k$-shot retrieval), but they differ during the selection process.\n\n**Q2: What embedder are you using for choosing top-k examples?**\n\nThe default embedder is SBERT, and is the same for all competing methods during retrieval-based ICL. Tables 2 and 8 provide additional ablations on the embedder used, verifying AdaICL\u2019s robustness.\n\n**Q3: Have you compared to any similarity based baselines?**\n\nWe are not sure which similarity based baselines the Reviewer refers to. We include diversity-based selection (such as fast-votek). During inference, all methods (Random, Votek, AdaICL) will retrieve the $k$ most similar examples from the annotated set $\\mathcal{L}$ as demonstrations for a test query $x_{test}$ .\n\n\n**Q4: Have you compared to any retriever-based baselines?**\n\nYes, all compared methods use retrieval during ICL inference (including Random, Votek, AdaICL), which has been shown to be the most effective for ICL [1]. We would like to clarify on the pipeline of the compared methods: All methods have a \u201cSelection Phase\u201d, which selects which examples to annotate, and an \u201cInference Phase\u201d, which is the $k$-shot retrieval-based ICL and is the same for all.\nWe summarize the key differences between methods below:\n| Method | Selection |  Inference  |\n| ------------------- | -------------------  | ------------------- |\n| | (how $\\mathcal{L}$ is constructed, $B$ examples) |  (using examples from $\\mathcal{L}$ for ICL) |\n| Random | random | $k$-shot  ($k \\ll B$) retrieval |\n| Hardest | uncertainty | $k$-shot  ($k \\ll B$) retrieval |\n| Votek | votek | $k$-shot  ($k \\ll B$) retrieval |\n| AdaICL | AdaICL | $k$-shot  ($k \\ll B$) retrieval |\n\nPlease also refer to \u201cGeneral Response: Pipeline of the compared methods\u201d.\n\n[1] Katerina Margatina, Timo Schick, Nikolaos Aletras, and Jane Dwivedi-Yu. \"Active learning principles for in-context learning with large language models\", 2023. [(link)](https://arxiv.org/pdf/2305.14264.pdf)\n\n**Q5: Question about the practical setting. If we need to annotate the selected examples on demand based on the query, then why not annotate directly the query?**\n\nAs we note above, the selection phase (which examples we choose to annotate) and the inference phase (downstream ICL) are two distinct phases. There is no annotation involved during inference.\n\n\n**Q6: Why are you choosing top-$N_{\\theta}$ examples based on probability scores? Would uncertain examples mean bottom-$N_{\\theta}$ examples?**\n\nThank you for raising this. Similar to previous works (MetaICL, Votek), we transform probabilities to negative log-probabilites $u_i$.  Higher $u_i$ means higher uncertainty, that is why we choose top-$N_{\\theta}$. We will add this important clarification to the paper.\n\n\n**Q7: RQ4. is provided but not addressed in the main paper nor referred to Appendix?**\n\nThank you for raising this, there is a typo in the title of Section 6.3, it should be \u201cRQ4: \u2026\u201d. In this section, we investigate how well the model understands the task through the lens of its calibration, i.e., whether higher confidence correlates with higher accuracy. Experimental analysis in Section 6.3 and Appendix C.4, show that AdaICL improves the model\u2019s calibration."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8269/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700076236182,
                "cdate": 1700076236182,
                "tmdate": 1700076236182,
                "mdate": 1700076236182,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mgNojuFcYE",
                "forum": "npf3gREtf7",
                "replyto": "QFP51eeYFK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8269/Reviewer_m5zU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8269/Reviewer_m5zU"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the authors' response.\n\n1. SBERT performance is highly reliant on the selected model. Even for commonly used models like bert-base-uncased and roberta-large, the clustered neighbors exhibit large differences. This problem raises questions about the generalizability of any embedding model. Strangely, the effectiveness of the Random baseline varies for the same dataset, regardless of the embedder employed (as observed in Table 2). Furthermore, Table 8 fails to address variations related to different embedders. Moreover, another limitation arises when relying on SBERT models for obtaining embeddings with a restricted sequence length. This limitation makes the method impractical for processing longer context texts. Thus, the proposed approach seems to be suited only for simpler datasets characterized by shorter contextual information.\n\n2. You have not addressed the problem of expensive multiple querying of the LLMs. Also Table 11 shows that AdaICL (T=2) requires double time compared to Vote k.\n\n3. You have also not addressed the answer directly. Based on the results, I agree with Reviewer LBWT that AdaICL requires hyperparameter tuning. Your observations indicate that different adaptations of AdaICL demonstrate different performance on different datasets. Additionally, different hyperparameters applied to the graph result in varying results across different datasets."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8269/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700642928076,
                "cdate": 1700642928076,
                "tmdate": 1700642928076,
                "mdate": 1700642928076,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zvwf1hEq2p",
            "forum": "npf3gREtf7",
            "replyto": "npf3gREtf7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8269/Reviewer_hvtd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8269/Reviewer_hvtd"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an active learning approach for ICL, which combines diversity-based sampling and uncertainty-based sampling. It introduces three versions of the proposed framework, including ADAICL-BASE, ADAICL, and ADAICL+. The base version performs k-means clustering over the identified hard examples, while ADAICL quantifies whether each example can help the model learn new information, and the plus version further equips a reweighting schema for the MAXCOVER problem to ensure dense regions with hard examples are preferred. Experiments study nine NLP datasets and GSM8K, with 1.3B to 65B LLMs across several model families."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. The paper is presented in a coherent manner and easy to follow.\n2. The logical progression connecting the various methodological variants is well-articulated. \n3. The improvements over the baseline is good."
                },
                "weaknesses": {
                    "value": "1. Active learning for NLP is a well-studied area. This paper lacks the illustration of why AL for ICL is challenging or the key difference compared to AL for fine-tuning based NLP. Otherwise, why do not directly apply multiple sophisticated query policies proposed in AL to the ICL example selection problem?\n\n2. Although not for ICL, combining diversity and uncertainty for data selection have been studied in previous literature:\\\nEntropy-Based Active Learning for Object Detection With Progressive Diversity Constraint;\\\nCold-start data selection for few-shot language model fine-tuning: A prompt-based uncertainty propagation approach;\\\nACTUNE: Uncertainty-Based Active Self-Training for Active Fine-Tuning of Pretrained Language Models.\n\n3. The baseline methods are limited. Although the related work discusses a batch of work for active learning in ICL/NLP, only a few simple baselines are compared in experiments. How does ADAICL compare to other AL methods? Meanwhile, I am also wondering about the performance of zero-shot GPT-4 or GPT-3.5-turbo.\n\n4. The method relies on the estimation of model uncertainty, which is only suited for the LLMs with moderate scales, For those most recent LLMs with hundreds billions parameters, usually we do not have a way to obtain its uncertainty."
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8269/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699164287686,
            "cdate": 1699164287686,
            "tmdate": 1699637028074,
            "mdate": 1699637028074,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "eNxXO2gnHA",
                "forum": "npf3gREtf7",
                "replyto": "zvwf1hEq2p",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8269/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8269/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer hvtd (1/3)"
                    },
                    "comment": {
                        "value": "We thank the Reviewer for their appreciation of our paper's presentation and the progression of our methodological variants. We proceed here below in replying to the comments in specific.\n\n**W1: Challenges in active learning (AL) for ICL, compared to fine-tuning based NLP** \n\n**A1**:\n Recent theoretical works relate ICL with nonparametric kernel regression [1,2], which is similar to $k$NN classifiers. Designing AL for non-parametric classifiers has been recently highlighted to be challenging [3], as new information cannot be directly incorporated into the model\u2019s parameters. The seminal work for AL for $k$NN classifiers [4] performs subset selection (set of hard examples) and maximizes a submodular function to capture the interactions of different examples and their effect on the non-parametric classifier. Our AdaICL method follows a similar framework, but employs a MaxCover optimization which can generalize to both classification and generation tasks, as it does not require a finite set of label classes.\n\nFurthermore, although active learning for NLP is well-studied, most of the recent approaches fine-tune the model during different AL rounds. This allows the model to incorporate information from the newly labeled examples into its parameters, which can gradually improve its predictions. However, LLMs with billions of parameters are used for ICL. In this case, computing gradient updates is costly and requires additional fine-tuning  for every new task. Finally, ICL with wisely-selected labeled samples is shown to be a better few-shot practice than supervised finetuning ([5], Section 4.1).\n\n[1] Chi Han et al., \"In-context learning of large language models explained as kernel regression\", 2023. [(link)](https://arxiv.org/pdf/2305.12766.pdf) \\\n[2] Yu Bai et al., \"Transformers as statisticians: Provable in-context learning with in-context algorithm selection\", 2023. [(link)](https://arxiv.org/pdf/2306.04637.pdf) \\\n[3]: Rittler, Nicholas, and Kamalika Chaudhuri. \"A two-stage active learning algorithm for k-nearest neighbors.\" ICML, 2023. [(link)](https://arxiv.org/pdf/2211.10773.pdf) \\\n[4]: Wei, Kai, Rishabh Iyer, and Jeff Bilmes. \"Submodularity in data subset selection and active learning.\" ICML, 2015. [(link)](http://proceedings.mlr.press/v37/wei15.pdf) \\\n[5] Su, Hongjin, et al. \"Selective annotation makes language models better few-shot learners.\" ICLR, 2023. [(link)](https://arxiv.org/pdf/2209.01975.pdf)"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8269/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700075880408,
                "cdate": 1700075880408,
                "tmdate": 1700455485211,
                "mdate": 1700455485211,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QDdc9dbY3R",
                "forum": "npf3gREtf7",
                "replyto": "zvwf1hEq2p",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8269/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8269/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer hvtd (2/3)"
                    },
                    "comment": {
                        "value": "**W2: Related work combining diversity and uncertainty sampling**\n\n**A2**. We thank the reviewer for bringing forward these important related works. We will make sure to include them in our Related Work section of the updated manuscript.\n\nWe note that [2] is specifically designed for object detection and cannot be trivially adapted for NLP, while [3] aims at selecting the best pseudo-labels (where budget B=0), which is not optimal for retrieval-based ICL as our experiments show (Table 2 \u201cPseudo-labeling\u201d).\nWe highlight the key differences between our work (AdaICL) and Patron [1], which also targets for selective annotation at the cold-start problem:\n\n*Optimization*. Patron computes an uncertainty score (based on model\u2019s feedback)  and a diversity score (based on kmeans clustering) for each example (Eq.(8)/(10) in [1]). Then, it selects the examples with the highest aggregate score from each cluster (similar to our AdaICL-base).\nIn our AdaICL method, we solve MaxCover (a submodular function maximization) over the data subset with hard examples.  The MaxCovar avoids selecting examples that will have similar effect during retrieval-based ICL, which leads to a dynamic (NP-hard) optimization. This optimization does not depend on pre-defined clusters, but focuses on examples that can convey new information to the model during inference, even if they would belong to the same cluster.\n\n*Multi-step adaptation*. At each step (AL round), AdaICL estimates the model\u2019s uncertainty and solves MaxCover over the new subset with hard examples. As the sets of hard examples may be completely different during successive steps, AdaICL can capture broad interactions of the examples and their effect during ICL. Patron combines uncertainty and diversity in a linear manner, which may lead to preferring examples with specific properties (e.g., ones that are close to the cluster centers).\n\nTo empirically verify our hypothesis, we adapt Patron to our tasks, and compare AdaICL with Patron in the multi-step setting (Figure 5):\n|  Topic Classif.(AGNews, TREC) | B=5  |  B=15 |  B=25 |  \n| -------- | ------- |  ------- |  -------- |\n| Patron  | 39.11 | 39.35 | 49.64 |\n| AdaICL | 38.89 | 52.40 | 62.57 |\n\n|  Sent. Analysis (SST2, Amazon) | B=5  |  B=15 |  B=25 |  \n| -------- | ------- |  ------- |  -------- |\n| Patron  | 61.45 | 74.75 | 79.79 |\n| AdaICL | 61.38 | 79.35 | 80.51 |\n\nWe believe these to be good results and that they positively address the Reviewer\u2019s request. Moreover, our results show that Patron is not suitable for tasks where semantic diversity is less important, i.e., RTE, MRPC, and MNLI:\n\n|  Nat. Lang. Inf. | RTE  |  MRPC |  MNLI |  \n| -------- | ------- |  ------- |  -------- |\n| Random  | 48.30 | 64.48 | 40.99 |\n| Patron | 48.16 | 65.04 | 38.89 |\n| AdaICL | 53.12 | 67.05 | 42.96 |\n\n[1] Yu, Yue, et al. \"Cold-start data selection for few-shot language model fine-tuning: A prompt-based uncertainty propagation approach.\" ACL, 2023. [(link)](https://arxiv.org/pdf/2209.06995.pdf) \\\n[2] Wu, Jiaxi, Jiaxin Chen, and Di Huang. \"Entropy-based active learning for object detection with progressive diversity constraint.\" CVPR. 2022.  [(link)](https://arxiv.org/pdf/2204.07965.pdf) \\\n[3] Yu, Yue, et al. \"AcTune: Uncertainty-based active self-training for active fine-tuning of pretrained language models.\" NAACL. 2022. [(link)](https://aclanthology.org/2022.naacl-main.102.pdf)"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8269/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700075938518,
                "cdate": 1700075938518,
                "tmdate": 1700075938518,
                "mdate": 1700075938518,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HU9V9IxC8w",
                "forum": "npf3gREtf7",
                "replyto": "zvwf1hEq2p",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8269/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8269/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer hvtd (3/3)"
                    },
                    "comment": {
                        "value": "**W3: Baseline methods for active learning in ICL**\n\n**A3**. In this work, we focus on the \u201ccold-start\u201d problem, similar to Votek, where we are given an unlabeled set to select examples from. Most of the related works in AL for ICL assume they are given an annotated validation set, which needs to be statistically large and is not practical for real world few-shot applications [1]. The validation set is leveraged for measuring the informativeness of each individual example as well as for hyperparameter tuning. For example, [2] employs reinforcement learning, which requires one set of labeled examples for policy training and another set of labeled examples for reward estimation. Moreover, as suggested, we compare AdaICL with Patron, showcasing the benefits that AdaICL offers for ICL.\n\nGPT-4 or GPT-3.5-turbo are not open-sourced and we currently do not have access to. However, we agree that comparing (i) smaller LLMs combined with AL against (ii) larger LLMs with zero-shot is an important direction.\n\n[1] Ethan Perez, Douwe Kiela, and Kyunghyun Cho. \u201cTrue few-shot learning with language models\u201d. NeurIPS, 2021. [(link)](https://arxiv.org/pdf/2105.11447.pdf) \\\n[2] Zhang, Yiming, Shi Feng, and Chenhao Tan. \"Active example selection for in-context learning.\" EMNLP, (2022). [(link)](https://arxiv.org/pdf/2211.04486.pdf)\n\n**W4: Obtaining model uncertainty for LLMs**\n\n**A4**. We can obtain uncertainty for large  black-box LLMs through their APIs. For example, ChatGPT provides the `logprobs` outputs, while other LLMs have other [ways](https://huggingface.co/bigscience/bloom/discussions/89). AdaICL can be applied to any LLM from which we can access its output logits/probabilities (we discuss this in Appendix F)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8269/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700075979487,
                "cdate": 1700075979487,
                "tmdate": 1700075979487,
                "mdate": 1700075979487,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]