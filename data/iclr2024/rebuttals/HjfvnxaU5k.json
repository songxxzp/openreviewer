[
    {
        "title": "Enhanced Bayesian Optimization via Preferential Modeling of Abstract Properties"
    },
    {
        "review": {
            "id": "f0FbpX4hH0",
            "forum": "HjfvnxaU5k",
            "replyto": "HjfvnxaU5k",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6608/Reviewer_hhJX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6608/Reviewer_hhJX"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose to ease black-box optimization tasks by integrating both black-box function evaluations over input designs as well as human preferences between different designs. In the Bayesian framework, this boils down to a combination between Bayesian Optimization (BO) and Preferential BO (PBO). Human preferences can be of significant interest as 1) they are cheaper with respect to black-box function evaluations for costly objectives and 2) humans perform comparisons at an abstract level using concepts that may not be easily measurable. The proposed method, Bayesian Optimization with Abstract Properties (BOAP), integrates human preferences directly into the statistical surrogate used during BO by extending the input space with additional dimensions that contain learned human preferences. To further account for unreliable human feedback, BOAP keeps track of two surrogates, with and without human preferences, and selects which one should be used to obtain a new design at every iteration based on a criterion.\n BOAP is then evaluated on a range of problems and demonstrates an improvement over the vanilla BO setting, even for unreliable experts."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The method is easy to understand and well-described throughout the paper. It provides a simple way to leverage different kinds of data (scalar values of a black box function and human preferences).\n- The authors give some hints from a theoretical perspective as to why using expert feedback might lead to faster convergence."
                },
                "weaknesses": {
                    "value": "- There is no notion of human query cost compared to the black-box function evaluation cost. For expensive black-box functions, I can easily imagine that querying the human is cheaper, but if many comparisons are needed. However, as such, it is difficult to assess the benefit of the method. BOAP provides a way to integrate expert preferences, and yes this yields an improvement for relevant preferences, but this is assuming a null human query cost, and perhaps things would be different \nThis is even more salient for unreliable expert feedback. For instance, Figure 6 shows the performances of the method for noisy expert preferences. While it seems that BOAP is somehow robust to noisy expert feedback, reverting back to vanilla BO in the worst case, it most likely would be the worst competitor if the expert query cost is now added. \nThis being said, this \"weakness\" is directed towards the evaluation protocol rather than the method itself.\n\nThis is more of a remark than a weakness properly speaking: I believe that the ICLR conference is generally skewed towards Deep Learning methods and the many approaches that revolve around that field. Bayesian Optimization has been quite successful for hyperparameter optimization of complex deep learning models and therefore fits the scope. However, the present submission does not seem to aim for such applications. In particular, no deep learning-related applications were provided in the experiments. Furthermore, as this submission proposes a way to integrate human preferences to the BO setting, I would say that comparing hyperparameter sets is probably not the most manageable problem for human experts, hence I think that the submission may not wholly fit the scope of ICLR."
                },
                "questions": {
                    "value": "Q1: During experiments, we begin with $p = (t' 2)$ preferences, ``that gets updated in every iteration of the optimization process''. Can you clarify this? If we begin with 5 initial observations, there are 10 preferences. Once the 6th sample is acquired, is it compared with the 5 previous ones, so that we now have 15 preferences, and 21 in the next iteration, and so on? If so, this leads to a great number of comparisons, which again raises the question of the human query cost w.r.t. black-box function evaluation cost mentioned above.\n\nQ2: In all the experiments considered, the expert is simulated, and considered to reason over high-level features which are then used to perform the comparisons and learn the preferential Gaussian process whose posterior mean is then added as additional input dimensions to the BO surrogate. How would this method compare with actually using the high-level features directly as additional dimensions? e.g. for Benchmark-1d, the input space would be $[x, \\exp(2-x)^2, \\frac{1}{x^2}]$. I think this can be intriguing specifically given that preferences are only ''identifiable'' up to a monotonous transformation (e.g. if an expert would have latent utility function $x \\mapsto x$ or $x \\mapsto \\sqrt{x}$, he would still give the same answer for a given comparison). If performances are significantly different, one could investigate whether this has to do with this identifiability issue or not. This can also be done in \"real-world experiments\" as high-level features are also derived in this case.\n\nQ3: P5 of the appendix, it is mentioned that ``if we use all training instances for the computation of the log marginal likelihood, there are chances that only Control arm may get selected in majority of the rounds. Therefore, to avoid this, instead of using all the training instances for computing the marginal likelihood, we use only the subset of the original training data for finding the optimal hyperparameter set and then we use the held-out instances from the original training set to compute the (predictive) likelihood''. I must say that I don't fully understand this phenomenon, could you clarify why this happens?\n\nQ4: To select which GP surrogate to follow (with or without human preferences and additional dimensions), the predictive likelihood of both models is compared. But the latter does not incorporate a notion of model complexity, right? I would have thought that the augmented model better fits the data given that it has more flexibility, even though for Gaussian Processes in a low-data regime (as in BO), having extra dimensions might not be a blessing. \nFrom a more general perspective, I think that mentioning additional ways of selecting which surrogate to use would have benefited the paper. I can think of at least one: placing a sparsifying-prior on the (squared-inverse) lengthscales, such as the horseshoe prior, as was done by Eriksson and Jankowiak [1]. \n\nSome additional remarks:\n\n- Simple regret and Bayes Regret are never defined formally in the paper, adding a definition in supplementary would be valuable.\n- On the contrary, the UCB acquisition function is defined in the supplementary, but nowhere used in the paper.\n- In the Supplementary, Eq.17 involves two different notations for a function $\\Gamma$\n- I don't think the search space for the synthetic experiments is mentioned anywhere in the text.\n\n[1] High-Dimensional Bayesian Optimization with Sparse Axis-Aligned Subspaces, David Eriksson, Martin Jankowiak, https://arxiv.org/abs/2103.00349"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6608/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6608/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6608/Reviewer_hhJX"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6608/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697730036356,
            "cdate": 1697730036356,
            "tmdate": 1699636753499,
            "mdate": 1699636753499,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hPboRZ57ZT",
                "forum": "HjfvnxaU5k",
                "replyto": "f0FbpX4hH0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6608/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6608/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer hhJX"
                    },
                    "comment": {
                        "value": "We thank our reviewer's time and effort for providing a detailed review and raising interesting key points.\n\n- **BOAP assumes null human query cost**_\n    - Bayesian optimization (BO) is the workhorse of scientific experimentation and product design. It provides a rich platform for human-AI collaboration because the nature of BO applications ensures that there would be an expert running the optimization process. In BOAP, the expert inputs considered are qualitative and available as pairwise design preferences\nbased on some abstract properties. Eliciting such pairwise rankings from the human expert should not add significant overhead, in contrast to specifying the complex explicit knowledge. \n    -  BOAP allows an expert to intervene only when they are willing to provide any preferential input thereby allowing them to evolve their knowledge over the course of optimization. Therefore, we have not considered any human query costs in the current version of the manuscript. However, it is an interesting direction to pursue that makes our proposed BOAP framework even more robust. In our experiments, at each iteration, we randomly choose $n/2$ datapoints to generate preferential data with the newly suggested datapoint.\n\n- _**Formal definitions: Bayes regret, simple regret; Search space for the synthetic experiments**_\n    - We thank our reviewer for the suggestions, and we will provide them in the updated version of the manuscript.\n\n- **How would this method compare with actually using the high-level features directly as additional dimensions?**_\n    - We would like to clarify to our reviewers that high-level features are not known directly to be used as an additional dimension, instead in practice an expert would reason about a system only qualitatively. However, we have conducted additional experiments to directly use high-level features as additional dimensions (BOAP-AD) and we have found that it outperforms BOAP by a small margin we believe this phenomenon is due to the fact that explicit measurements are always better than approximate qualitative measurements.\n\n     -----------------------------------------------------\n      |                 |      BOAP-AD     |       BOAP     |\n     -----------------------------------------------------\n      | Benchmark - 1D  |     0.01\u00b10.002   |     0.05\u00b10.01  | \n      | Rosenbrock - 3D |     3.16\u00b11.19    |     5.32\u00b10.12  | \n     -----------------------------------------------------"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6608/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700641288251,
                "cdate": 1700641288251,
                "tmdate": 1700641288251,
                "mdate": 1700641288251,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "VLI5XmCAoI",
            "forum": "HjfvnxaU5k",
            "replyto": "HjfvnxaU5k",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6608/Reviewer_cKDa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6608/Reviewer_cKDa"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes an approach for incorporating abstract properties, a novel form of prior information, into of the objective function into the Bayesian optimization loop. Abstract properties refer to auxiliary, immeasurable traits of the objective, which by assumption are indicative of performance. User preferences over abstract properties are modeled by a rank GP. The rankings are subsequently incorporated by adding dimensions to a conventional GP regression that is subsequently used for BO."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "__Interesting idea:__ Querying the user for feedback (specifically for ranking-based feedback) appears useful and digestible for practitioners.\n\n__Novel quantities:__ I have not seen abstract properties be discussed as a concept previously, and while I am not convinced of their prevalence in practical applications, the notion of incorporating _immeasurable_ auxiliary quantities is enticing."
                },
                "weaknesses": {
                    "value": "Unfortunately, I believe this paper has substantial flaws in terms of the validity of the method, the presented theory, results and communication. As such, I believe this paper needs substantial re-work for it to be publishable. \n\n\n- __Convergence remarks:__ This subsection is rather informal. I do not believe that postulation is appropriate when considering theoretical convergence, but the assumption also appears incorrect based on existing theory.\n_(...) accurate feedback of relevant abstract properties should, we postulate, reduce the eluder dimension of the model_.\n\nRegarding convergence of the proposed method, I believe there is only one certainty: the proposed method _adds_ dimensions to the problem. As shown by Srinivas. et. al. (2009), the information gain scales exponentially in the dimensionality of the problem, assuming equal lengthscales (Bergenkamp et. al. 2017). Furthermore, the eluder dimension clearly increases in the dimensionality of the problem ($\\mathcal{F}$ changes with the added dimensions) so the above statement is, to the best our knowledge, incorrect.\n\nLastly, the bounds on _information gain_ (IG) only hold for a select few kernels, and spatially-varying kernels are not included in this class. As such, IG bounds do not hold, either.\n\nThe entirety of Sec. 3.4 is based on seemingly incorrect assumptions. Further, it contains no _proven_ theoretical insights. As such, I believe this section should be fundamentally reworked or removed.  \n\n- __Addition of dimenions:__ I struggle to see how adding dimensions to the problem aids in optimization. This is a counterintuitive action, and the authors should undertake great effort to shed light on this. This is currently missing from the paper altogether.\n\n- __Obscure aspects of method:__ I believe a collection of methodological choices are not sufficiently communicated. These are all outlined in the questions section.\n\n- __The concept of abstract properties:__ Moreover, the abstract properties that are introduced appear measurable, and as such, amenable to multi-objective (or multi-fidelity, depending on the property) optimization. Since these properties are _abstract_, I would encourage the authors to further motivate why they are abstract (i.e. immeasurable) and why existing BO approaches are ill-suited. \n\n- __Structure of the methodology section:__ A substantial part of this section (3.1.1, 3.1.2) appears to be background work, and 3.1.2 (MAP estimation) specifically is standard BO convention. The methodology should primarily cover the novel aspects of the work, so including these here blurs the contributions of the work. I suggest for 3.1.1. to be moved to Sec. 2 and 3.1.2 to be moved to the Appendix. The same goes for ARD (3.2 second paragraph).\n\n- __Notation:__ The set $\\mathcal{D} = \\{(\\mathbf{x}, y = h(\\mathbf{\\hat{x}}) \\approx f(\\mathbf{x})\\})$ is incorrect notation and difficult to parse regardless. Moreover, observations are occasionally denoted $(\\mathbf{x}, f(\\mathbf{x}))$, should be $(\\mathbf{x}, y)$.\n- __Results:__ Few tasks, very few iterations and low repetitions (as seen by the very non-smooth regret plots) yield results that have low credibility and offer few substantial takeaways. Moreover, the high-level features seem _very helpful_, so I believe these should be substantially ablated.\n\n\n__Minor:__ \n- Variables are re-declared multiple times throughout\n- The rank GP is frequently referred to as _\"Rank (preferential) GP\"_. Please use either rank or preferential, as the dual naming and parentheses do not add clarity.\n- _Information gain_ versus _information-gain_. Please use the former."
                },
                "questions": {
                    "value": "__Methodology-related questions - should be clarified:__\n- Why are the lengthscales fixed (as opposed to the conventional ARD) for the original input dimensions? How are they fixed?\n- What is the _\"maximum predictive likelihood\"_ by which the model is chosen -  the one with the highest marginal log likelihood? \n- One model strictly has more capacity than the other, so how would the non-user input model ever be chosen? \n - How frequently is each model chosen?\n- How is the next input chosen along the added $m$ dimensions, which are dictated by human feedback? \n- Are the $m$ dimensions amenable to typical acquisition function optimization, and do they actually result in a point to query?  (it seems like _output_, rather than _input_)\n\n__General questions__:\n- What is the procedure for providing abstract features in the results? Can these be provided as continous functions, or are they given pointwise? If pointwise, how are they provided for the synthetic functions?\n- What is the definition of an abstract property? Immeasurable? If so, I would suggest calling it \"immeasurable\", as calling it \"abstract\" is, quite fittingly, a bit abstract.\n- How frequently does the user have to be queried for feedback / how many user queries does a 20 iteration run entail?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6608/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6608/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6608/Reviewer_cKDa"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6608/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698576602200,
            "cdate": 1698576602200,
            "tmdate": 1699636753326,
            "mdate": 1699636753326,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3FIWim60tt",
                "forum": "HjfvnxaU5k",
                "replyto": "VLI5XmCAoI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6608/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6608/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer cKDa"
                    },
                    "comment": {
                        "value": "We appreciate our reviewer's patience, time and effort to provide us with detailed feedback and raise interesting key points.\n\n- _**Why properties are abstract (i.e. immeasurable) and why existing BO approaches are ill-suited**_\n    - In numerous scenarios, experts often reason about a system based on their approximate or qualitative knowledge of the system at different abstraction levels. They reason using intermediate physical properties that may not be measurable directly. Using such high-level abstractions the expert compares designs and the reason why a design is better than another.\n    - The existing BO approaches aim at capturing the expert preferential input directly on the objective function, in contrast to the preferences based on the aforesaid intermediate properties. Therefore we propose a human-AI collaborative framework to incorporate such expert preferential data about unmeasured abstract properties into BO.\n\n- _**Why are the lengthscales fixed for the original input dimensions?**_\n    - We would like to clarify to our reviewer that in the augmented GP ($\\mathcal{GP}_{h}$), we still tune the hyperparameters of the original input dimensions by maximizing the log marginal likelihood. We use a modified ARD kernel that uses a spatially varying kernel with a parametric lengthscale function for each of the input dimensions. For each un-augmented feature, we set the lengthscale function to be a constant lengthscale value $l(\\mathbf{x})=l$, whereas for each of the augmented auxiliary features we set the lengthscale function to be $l(x)=\\alpha\\sigma(\\mathbf{x})$, where $\\alpha$ is the scale parameter and $\\sigma(\\mathbf{x})$ is the normalized standard deviation predicted using the rank GP.\n\n- _**How would the non-user input model ever be chosen? How frequently it is chosen?**_\n\n    - During the initial phase of optimization the un-augmented control arm is pulled as the augmented arm may have insufficient data to reduce uncertainty in posteriors, making the augmented features only slightly better than noise. However, the augmented features become more accurate through the optimization process as we accumulate more data, so we observe the augmented arm to be more accurate at the end of the optimization. \n    - Based on the empirical results we could verify that the augmented model was chosen more than the un-augmented arm. In an ideal scenario with accurate preferential data, we have recorded the percentage of times each was pulled and the results are as follows.\n     -----------------------------------------------------\n      |            |   Augmented Arm   |   Control Arm   |\n     -----------------------------------------------------\n      | Benchmark  |     76.23\u00b12.5     |     24.22\u00b11.2   | \n      | Rosenbrock |     71.87\u00b14.6     |     25.67\u00b12.75  | \n      | Griewank   |     63.95\u00b13.1     |     35.73\u00b12.6   | \n\n\n- _**{How is the next input chosen along the added dimensions?**_\n    - In the augmented search space we have $d+m$ features in total, here we Thompson sampling method operating in $d+m$ dimensions to find the next promising candidate for the function evaluation. In the case when the augmented arm is pulled, we randomly draw a sample from its GP and find its corresponding maxima $\\mathbf{x}_{t}^{\\mathfrak{h}}$.\nThe objective function in the augmented space $h(\\tilde{\\mathbf{x}})$ is a simpler form of $f(\\mathbf{x})$ with auxiliary features in the\ninput, and therefore we observe $h(\\tilde{\\mathbf{x}})$ via $f(\\mathbf{x})$. \n\n- _**How frequently does the user have to be queried for feedback, and how many user queries do a 20-iteration run entail.**_\n    - BOAP allows an expert to intervene only when they are willing to provide any preferential input thereby allowing them to evolve their knowledge over the course of optimization. The preferential feedback is provided by experts at their discretion i.e., when they feel they can make a clear judgement or that the algorithm has gone astray. How the expert intervenes in giving preferential feedback is not controlled by the algorithm. \n    - In our studies with simulated experts (zero query cost), at each iteration, we randomly choose a subset of datapoints containing $n/2$ datapoints to compare with the new candidate suggested for function evaluation. Therefore in a $20$ iteration run, we generate $133$ preferences in total.\n\n- _**Procedure for providing abstract features**_\n    - For synthetic functions, based on their mathematical formulation, we have considered the high-level features as mentioned in Table 1 of the main paper. We treat such high-level features as a continuous function $\\omega(\\cdot$) and generate the preference data $P$. For real-world experiments, due to the cost and access limitations of experimental facilities we have used a few columns $(\\omega)$ in the published dataset as high-level features. We generate preference data by comparing those columns values $(\\omega(\\mathbf{x}))$ for two datapoints $(\\mathbf{x},\\mathbf{x}')$."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6608/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700640743537,
                "cdate": 1700640743537,
                "tmdate": 1700640743537,
                "mdate": 1700640743537,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Xh9LZnKvzA",
            "forum": "HjfvnxaU5k",
            "replyto": "HjfvnxaU5k",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6608/Reviewer_4RNk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6608/Reviewer_4RNk"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes novel human-AI collaboration BO algorithm: Bayesian Optimization with Abstract Properties (BOAP) where the input of the main GP f in BO is augmented with latent preference GPs posterior means to construct an augmented GP h. BOAP then adaptively switch between f and h when performing BO. The author examined BOAP via theoretical discussion and empirical evaluation."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Incorporating human feedback into BO is an interesting and important problem.\n- The proposed method is well-motivated as it seeks to incorporate human feedback.\n- The paper has contained both theoretical and empirical evaluation, with the experimental results consist of both various synthetic and real-world problems"
                },
                "weaknesses": {
                    "value": "While this work presented a well-motivated method, many design choices throughout the algorithm appears to be arbitrary, and the author did not provide enough theoretical or experimental justification to those choices. Some examples include:\n\n- (in 3.1) \u201cTo do this, we utilize an Automatic Relevance Determination (ARD) kernel where we set the lengthscales of the augmented input dimensions in proportion to the rank GP uncertainties\u201d \u2014> why this instead of learning the parameters as one would typically do with GP models? Have we run ablation studies on how exactly we are choosing the scale parameter \\alpha? inverse std? inverse var? or some other notion of uncertainty? The author has provided some explanation to that choice, but it is not convincing that this is the best choice here without additional evidence.\n- If we are able to model those abstract properties with preference models that we believe are compositional parts (or contain important information) of the function of interest f, why don\u2019t we explicitly exploit this compositional structure as done in Astudillo and Frazier (2020)?\n- Similar to above points, the author does not describe how the preference P is constructed and updated (i.e., how are the queries selected. Randomly?). Does P gets updated? If yes, how (L13 in algorithm 1 is unclear) If not then the number of possible comparisons entirely depend on the initial dataset, and are either very limited or we need a large init set, which isn\u2019t feasible.?\n- Theoretical discussion seems a bit hand-wavy and are based not entirely justified assumptions (e.g., \u201cIf neither model has a consistently higher likelihood\u2026\u201d)\n\nThe experiments section can also be significantly improved by exploring\n\n- The paper would benefit more from investigating the impact of preference data P. Querying human experts is an expensive procedure, and in the BOAP algorithm, we have to query human expert p times for each of the\n- Human mistakes are mentioned multiple times throughout the paper but the author doesn\u2019t investigate how different kinds/scales of human errors can affect the performance of BOAP. Similarly, different human preference querying strategies are not explored. Astudillo and Frazier (2020) and Lin et al. (2022) have shown that querying the DM different questions (e.g., using the EUBO acquisition function) can have significant impact on the downstream model performance.\n\nThe writing, particularly implementation and design choices details (e.g., how are expert preferences dataset being constructed precisely), can be improved.\n\nFinally, while the author has experimented with different test functions, there are only two real-world problems and the performance of BOAP in those problems are only marginally better than the baseline methods.\n\nMinor points:\n\n- L12-13 should be indented to be inside the loop.\n\nReferences:\n\nAstudillo, R., & Frazier, P. (2019, May). Bayesian optimization of composite functions. In\u00a0*International Conference on Machine Learning*\u00a0(pp. 354-363). PMLR.\n\nAstudillo, R., & Frazier, P. (2020, June). Multi-attribute Bayesian optimization with interactive preference learning. In International Conference on Artificial Intelligence and Statistics (pp. 4496-4507). PMLR.\n\nLin, Z. J., Astudillo, R., Frazier, P., & Bakshy, E. (2022, May). Preference exploration for efficient bayesian optimization with multiple outcomes. In\u00a0*International Conference on Artificial Intelligence and Statistics*\u00a0(pp. 4235-4258). PMLR."
                },
                "questions": {
                    "value": "- \u201cAlthough we anticipate that experts will provide accurate preferences on abstract properties, the expert preferential knowledge can sometimes be misleading\u201d \u2014> what does misleading mean here?\n- Have the author compared the impact of using log-likelihood of rank GP instead of Evidence, as the former appears not to take uncertainty in \\omega into consideration, where the latter marginalize out the (latent) GP function distribution, arguably a more principled Bayesian treatment.\n- (in 3.2) \u201cTo handle different scaling levels in rank GPs, we normalize its output in the interval [0, 1], such that \u03bc(\u03c9_i (x)) \u2208 [0, 1]\u201d \u2192 how is the normalization being done\n- (Algorithm 1):\"Augment data D = D \\union (x_t ,y_t ) and update expert preferences P\u03c9 1:m with respect to x_t\u201d How exactly are the expert preferences data updated? How are pairwise comparisons being constructed?\n- Other questions mentioned in Weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6608/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6608/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6608/Reviewer_4RNk"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6608/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698809180670,
            "cdate": 1698809180670,
            "tmdate": 1699636753110,
            "mdate": 1699636753110,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qq6KduP2uA",
                "forum": "HjfvnxaU5k",
                "replyto": "Xh9LZnKvzA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6608/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6608/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer 4RNk"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer's time and efforts to provide detailed feedback and raise a few interesting points. \n\n- _**Why this instead of learning the parameters as one would typically do with GP models?**_\n     - Tuning the human augmented GP ($\\mathcal{GP}_{h}$) using the traditional loglikelihood/evidence maximization does not account for the expert uncertainties for the augmented features. Incorporating expert uncertainties from the individual rank GPs can be crucial for modelling as the expert feedback may be inaccurate and thus can adversely affect the overall optimization performance.\n\n- _**why don't we explicitly exploit this compositional structure as done in Astudillo and Frazier (2020)?**_\n    - Our idea is fundamentally different from Astudillo and Frazier (2020) as we try to incorporate expert preferential feedback about the immeasurable abstract properties in modelling the given objective function $f$. To the best of our knowledge, Astudillo and Frazier (2020) capture expert preferences (along with their uncertainties) directly on $f$ and fail to account for auxiliary abstract properties that can be crucial for improving the optimization performance.\n\n\n- _**The choice of scale parameter $\\alpha$**_\n    - The predictive variance ($\\sigma^{2}$) in the rank GP is a measure of uncertainty in the expert model. In our proposed approach, the scale at which this uncertainty is to be considered in modelling the overall objective function is dictated by the scale parameter $\\alpha$ and $\\alpha\\times\\sigma$ will be the underlying lengthscale. We tune the scale parameter for each of the augmented dimensions by maximizing the log-likelihood. Alternatively, we could treat $\\alpha$ as an overall \"average\" lengthscale, such that $\\alpha$ is the underlying lengthscale when there is no uncertainty and with expert uncertainty the overall lengthscale is $\\alpha+\\sigma$.\n\n- _**Different kinds of human errors can affect the performance of BOAP}**_\n    - We would like to refer our reviewer to the additional experiments mentioned in the supplementary material (Section A.4). We have conducted experiments to account for the human expert errors in providing preferential feedback. We have done this ablation study in two-fold. First, we show the robustness of our proposed approach against human errors in the selection of higher-order abstract properties. Second, we account for the human errors in providing the expert preferential feedback by flipping the preference between two input designs with some probability $\\delta=0.3$. The ablation results and the experimental details are provided in the supplementary material (A.4.2).\n\n\n- _**Expert preferential knowledge can sometimes be misleading**_\n    - We expect that the human expert preferential input is accurate and thus likely to accelerate BO. But, in some cases, this preferential feedback may be inaccurate due to the wrong/incorrect assumptions on the given search space. Therefore, such misguided preferential data given by an expert could potentially slow down the optimization. On the other hand, our method has some immunity to such inaccurate feedback.\n\n- _**Normalization in Rank GPs**_\n    - The individual rank GPs (${\\mathcal{GP_{\\omega_i}}}$) operate at different output scales (as dictated by MAP) and thus different scaling levels in their corresponding predictions. Therefore, before we augment the main GP with the mean predictions ($\\mu_{\\omega_{i}}(\\mathbf{x})$) of the individual rank GPs, we min-max scale their outputs to be normalized in the interval $[0,1]$."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6608/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700632877127,
                "cdate": 1700632877127,
                "tmdate": 1700632877127,
                "mdate": 1700632877127,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vrTzgDlSKs",
            "forum": "HjfvnxaU5k",
            "replyto": "HjfvnxaU5k",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6608/Reviewer_NPJR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6608/Reviewer_NPJR"
            ],
            "content": {
                "summary": {
                    "value": "This paper explores a new Bayes Opt method that incorporates human rank-based feedback as well as direct experimental feedback. As such, it is a human-in-the-loop algorithm. To achieve this, multiple GP models are trained. For the human feedback, $m$ rank GPs are trained. The mean values of each rank GP are then incorporated as additional predictor variables in the main GP that predicts the overall objective. The uncertainty in the rank GPs are used to guide the lengthscales in the kernel of the main GP. Finally, a GP trained without any of the human-derived extra features is also trained, in case expert feedback turns out to be inaccurate. Experiments conducted: synthetic experiments, real dataset experiments where some data fields are regarded as expert derived ranks instead."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper clearly describes the scenario that it is designed for\n- The authors have attempted to use the uncertainty from the rank GPs in the main GP by incorporating the uncertainties into the lengthscale\n- Some theoretical discussion is advanced to suggest that the convergence rate of BOAP will be the maximum of the convergence rates that one would find with the augmented and unaugmented GP models in isolation"
                },
                "weaknesses": {
                    "value": "- The concatenation of different GP models, using some as inputs to others, is not rigorously investigated. What happens when kernel lengthscales are dynamically set based on a different model at different inputs? Is this provably a positive definite kernel still? \n- The approach is based on modelling both the objective functions and the user-derived feedback given $\\mathbf{x}$ where neither are yet observed. What assumptions tell us that predicting the $\\omega$ properties first and then predicting $y$ is easier than predicting $y$ directly? In the synthetic experiments this is clear- the functional relationship between $y$ and the $\\omega$ is somehow simpler than the relationship between $y$ and $\\mathbf{x}$ directly. It would be nice to clarify and understand these assumptions more carefully. \n- The theory quoted in this paper from Russo & Van Roy, 2014 may not be directly applicable. The theory assumes the model is a GP, which is not guaranteed with this input-dependent lengthscale. The theory further assumes the GP model itself is fixed, whereas in the paper both GP hyperparameter optimization and updates to the $\\omega$-GPs are applied at each step. (Cf. Section 6.3 of the Russo & Van Roy paper)\n- The real-world experiments synthesise human feedback by converting some columns of real data into unobserved rank data. No actual human-in-the-loop experiment is conducted"
                },
                "questions": {
                    "value": "- what existing work has been done on using GP-predicted values as inputs to another GP? Has anyone studied this model? Do we know if it is actually a (mathematical) GP?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6608/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699024172297,
            "cdate": 1699024172297,
            "tmdate": 1699636752966,
            "mdate": 1699636752966,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "n3GmsvOtnV",
                "forum": "HjfvnxaU5k",
                "replyto": "vrTzgDlSKs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6608/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6608/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer NPJR"
                    },
                    "comment": {
                        "value": "We thank our reviewer's time and effort invested in understanding the paper to raise some interesting points. \n\n- _**GP-predicted values as inputs to another GP? Has anyone studied this model?**_\n\n    - Using GP predictive distribution to model another GP has been explored in the past. [1] proposed a two-layered hierarchical model for GP regression that partitions the input data points such that the upper layer is responsible for coarse modelling and the lower layer is responsible for fine modelling. \n    - [1] Park, Sunho, and Seungjin Choi. \\textquotedbl Hierarchical Gaussian process regression.\\textquotedbl{} In Proceedings of 2nd Asian Conference on Machine Learning, pp. 95-110. JMLR Workshop and Conference Proceedings, 2010. \n\n- _**Why predicting the properties f\u00ecrst and then predicting $y$ is easier than predicting directly?**_\n    - The abstract properties can be simple physical properties or even a combination of multiple physical properties that an expert uses\nto reason about why one design is better than another. A well-chosen abstract property captures the input space of a system sufficiently\nenough that enable the domain expert to better reason about the output of the system in terms of such higher-order abstract properties. The main objective of augmenting abstract properties into the input space is to capture the inherent transformations of the function space $\\mathcal{F}$ that significantly reduce the complexity and thereby simplify the\ntask of GP modelling, thus a better overall optimization performance. \n    - Furthermore, human expert feedback is not available always, thus we cannot simply use expert-derived feedback as input. However we model this (intermittent) expert feedback using a GP, and that model will act as a proxy for the expert in experiments where no expert feedback is given.\n  \n- _**The theory quoted in this paper from Russo \\& Van Roy, 2014 may not be directly applicable?**_\n\n    - At every step of a typical BO, the kernel hyperparameters are updated, so technically speaking the model is different at each step. Nevertheless, the results of papers like Russo and Van Roy, while not precisely matched to reality, are considered \\textbf{indicative} of performance, typically in big-O form (no one expects exact predictions, just an indication of expected performance). The only real distinction in this case is that our kernel - which in effect includes the posterior mean/variance of the expert models in the kernel definition - varies more radically in the early stages of optimization. We discuss Russo and Van Roy in this sense - a guide to what we might expect, not a limiting framework.\n\n- -**Dynamically setting kernel lengthscales based on a different model at different inputs? Is this provably a p.d kernel still?**_\n    - Spatially varying lengthscales have already been explored in the past literature. [2] proved the positive definiteness of the spatially\nvarying kernel by showing that it has the required property of spatial variation of the lengthscales by suitably replacing the constant lengthscale with an arbitrary parameterized function of x. We refer our reviewer to \\textquotedblleft Non-stationary Covariance Functions\\textquotedblright{} Section (2.3.2) of [2] for the detailed discussion on spatially varying lengthscales and the resultant positive definite kernels.\n\n    - [2] Gibbs, Mark N. \"Bayesian Gaussian processes for regression and classification\", PhD diss., University of Cambridge, 1998.\n\n- _**No actual human-in-the-loop experiment is conducted**_\n   - Level of expertise required to conduct these experiments is high and access to such real experts is very difficult. Due to the cost and access limitations of experimental facilities, we rely on numerical simulations and simulated data."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6608/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700626264942,
                "cdate": 1700626264942,
                "tmdate": 1700626264942,
                "mdate": 1700626264942,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1OOmDqZHEx",
                "forum": "HjfvnxaU5k",
                "replyto": "n3GmsvOtnV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6608/Reviewer_NPJR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6608/Reviewer_NPJR"
                ],
                "content": {
                    "title": {
                        "value": "Reply to authors' response"
                    },
                    "comment": {
                        "value": "> GP-predicted values as inputs to another GP? Has anyone studied this model?\n\nThank you for your answer. The work by Park et al. seems a bit different to what you do- specifically their equations (7)-(8) imply that inputs $\\mathbf{c}$ are used to set the mean for a second GP using inputs $\\mathbf{x}$, whereas in the submission you augment $\\mathbf{x}$ to $\\mathbf{\\tilde{x}}$ by concatenation. This is not necessarily a problem, but I think more explanation around this would be very beneficial to the paper.\n\n> Why predicting the properties f\u00ecrst and then predicting $y$ is easier than predicting directly?\n\nThank you for your reply, which makes sense on an intuitive level. I was wondering whether you could codify your assumptions more formally, but I take it that this is not possible.\n\n> Dynamically setting kernel lengthscales based on a different model at different inputs? Is this provably a p.d kernel still?_\n\nThank you for this reference. I had a quick read of the paper and indeed it seems that it is always permissible to set the kernel matrix in a Gaussian kernel to $(\\Sigma_i + \\Sigma_j)/2$, which applies to your case with diagonal matrices. I do suggest including a reference to this"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6608/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700733637752,
                "cdate": 1700733637752,
                "tmdate": 1700733637752,
                "mdate": 1700733637752,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]