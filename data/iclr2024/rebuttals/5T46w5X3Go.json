[
    {
        "title": "Theoretical Analysis on the Generalization Power of Overfitted Transfer Learning"
    },
    {
        "review": {
            "id": "31q4rDZdvi",
            "forum": "5T46w5X3Go",
            "replyto": "5T46w5X3Go",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7587/Reviewer_onS3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7587/Reviewer_onS3"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies transfer learning under the noisy linear regression setting. The authors split the features into two distinct sets: a common part shared across tasks and a task-specific part. The paper studies two transfer learning settings, Option A: directly copy the learned common feature to the target task; Option B: use the learned common part as an initial training point. Then, considering different noise levels, the authors claim that, when the total number of features in the source task\u2019s learning model is fixed, it is more advantageous to allocate a greater number of redundant features to the task-specific part rather than the common part."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper studies an important topic. Nowadays, transfer learning is become the new standard paradigm. For example, training a foundation model by self-supervised learning and adapting the model to a specific supervised downstream task. Thus, some important topics include but are not limited to how to select features, how to select the aulixray dataset, how to adapt the models efficiently, and so on. \n\nThe paper\u2019s motivation is clear and the analysis is concise."
                },
                "weaknesses": {
                    "value": "- The major concern I have is that the paper can separate the common features and task-specific features explicitly. In other words, in Option A and Option B, we can directly know that $w$ is a common feature, while $q$ is not. In practice, we do not have any idea about which part of the feature should be useful and we should try to figure out the common features and task-specific features rather than assuming we know that. From my perspective, one practical Option C should use all the learned features, e.g., $w$ and $q$  as an initial training point rather than $w$ only in Option B.\n- The problem setup is simple, not practical, and not novel. The linear regression setting seems not surprising and the transfer learning conclusion directly depends mostly on the assumption we made. The paper only considers one source supervised training task, while in practice, we mostly consider multiple source tasks [1,2] or different pretraining objectives, e.g., self-supervised learning [3,4] (no objective gap between source and target). Splitting the data feature space into common features and task-specific features is quite commonly used [4,5]. While in [4,5] they do not know which part is a common feature during pretraining and transfer learning. \n- The claim in Proposition 4 is not significant. From my perspective, it just says that we should only keep the common features in the transferred feature, where the take-home message is not interesting. I cannot get more insights or intuitions. \n- Some minor weaknesses in writing. Assumption 1 should be Definition 1. $\\mathcal{R}$ and $\\mathbb{R}$ are mixed used. \n\n[1] Nilesh Tripuraneni, Michael Jordan, and Chi Jin. On the theory of transfer learning: The importance of task diversity. NeurIPS 2020.\n\n[2] Zhao, Yulai, Jianshu Chen, and Simon Du. Blessing of Class Diversity in Pre-training. AISTATS 2023.\n\n[3] HaoChen, Jeff Z., Colin Wei, Adrien Gaidon, and Tengyu Ma. Provable guarantees for self-supervised deep learning with spectral contrastive loss.  NeurIPS 2021.\n\n[4] Shi, Zhenmei, Jiefeng Chen, Kunyang Li, Jayaram Raghuram, Xi Wu, Yingyu Liang, and Somesh Jha. The Trade-off between Universality and Label Efficiency of Representations from Contrastive Learning. ICLR 2023.\n\n[5] Rosenfeld, Elan, Pradeep Kumar Ravikumar, and Andrej Risteski. The Risks of Invariant Risk Minimization. ICLR 2021."
                },
                "questions": {
                    "value": "In Remark 1, it is unclear what missing features mean. Providing a toy example will be good."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7587/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698526074079,
            "cdate": 1698526074079,
            "tmdate": 1699636919210,
            "mdate": 1699636919210,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ODCRPITz23",
                "forum": "5T46w5X3Go",
                "replyto": "31q4rDZdvi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7587/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7587/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer onS3 (part 1)"
                    },
                    "comment": {
                        "value": "> The major concern I have is that the paper can separate the common features and task-specific features explicitly. In other words, in Option A and Option B, we can directly know that $w$ is a common feature, while $q$ is not. In practice, we do not have any idea about which part of the feature should be useful and we should try to figure out the common features and task-specific features rather than assuming we know that. From my perspective, one practical Option C should use all the learned features, e.g., $w$ and $q$ as an initial training point rather than $w$ only in Option B.\n\n**Response**: We thank the reviewer for raising this important concern. For several modern ML applications, knowing features in advance is very common via pre-training over a big collection of tasks (generally referred to as feature engineering), so that these features can benefit later downstream tasks without the need to reconstruct these features again in each individual task. In particular, recent huge successes such as contrast learning and pre-training large language models (LLMs) can provide powerful pre-trained and general-purpose features/representations (e.g., [ref a], [ref b]). These new ML advances motivate/justify the line of research on transfer learning (which our paper follows) to leverage those well-trained features beforehand and focus on designing the transfer of other model parameters to benefit target tasks. In addition to [ref a] and [ref b], the idea of incorporating **known** features into the learning formulation has become popular in other ML studies (such as in few-shot learning [ref b]) and has been well accepted in the ML community. We will improve our discussion of these points in the paper to address this important concern raised by the reviewer. \n\n[a] Kaiming He, et. al, \u201cMomentum Contrast for Unsupervised Visual Representation Learning\u201d CVPR 202.\n\n[b] Tom Brown et. al, \u201cLanguage Models are Few-Shot Learners\u201d NeurIPS 2020.\n\n---\n\n> The problem setup is simple, not practical, and not novel. The linear regression setting seems not surprising and the transfer learning conclusion directly depends mostly on the assumption we made. The paper only considers one source-supervised training task, while in practice, we mostly consider multiple source tasks [1,2] or different pretraining objectives, e.g., self-supervised learning [3,4] (no objective gap between source and target). Splitting the data feature space into common features and task-specific features is quite commonly used [4,5]. While in [4,5] they do not know which part is a common feature during pretraining and transfer learning.\n\n> [1] Nilesh Tripuraneni, Michael Jordan, and Chi Jin. On the theory of transfer learning: The importance of task diversity. NeurIPS 2020.\n\n> [2] Zhao, Yulai, Jianshu Chen, and Simon Du. Blessing of Class Diversity in Pre-training. AISTATS 2023.\n\n> [3] HaoChen, Jeff Z., Colin Wei, Adrien Gaidon, and Tengyu Ma. Provable guarantees for self-supervised deep learning with spectral contrastive loss. NeurIPS 2021.\n\n> [4] Shi, Zhenmei, Jiefeng Chen, Kunyang Li, Jayaram Raghuram, Xi Wu, Yingyu Liang, and Somesh Jha. The Trade-off between Universality and Label Efficiency of Representations from Contrastive Learning. ICLR 2023.\n\n> [5] Rosenfeld, Elan, Pradeep Kumar Ravikumar, and Andrej Risteski. The Risks of Invariant Risk Minimization. ICLR 2021.\n\n**Response**: We thank the reviewer for raising these important concerns. However, using a linear model and only one source task as an initial step is common in the field of theoretical transfer learning in order to glean important insights. Note that although the model is simplified, the analysis is already quite complex and provides interesting insights. Possible future work using more realistic models will also benefit from our work with the simple model. Gaining an understanding of the simple model is fundamentally important to gaining an understanding of more realistic models.\n\nThe source task in [4] pre-trains a representation using unlabeled data, while ours uses labeled data. This is exactly why we need to know features but [4] does not (since the goal of [4] is to learn representations but ours is to learn the parameters). [5] focuses on out-of-distribution generalization and is not related to transfer learning.\n\n---\n\n**Followed by \"Response to Reviewer onS3 (part 2)\"**"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7587/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700678449355,
                "cdate": 1700678449355,
                "tmdate": 1700678449355,
                "mdate": 1700678449355,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iL3OMRfas7",
                "forum": "5T46w5X3Go",
                "replyto": "xY4dEWNwJT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7587/Reviewer_onS3"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7587/Reviewer_onS3"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response. My first two concerns are not fully solved and I tend to keep my original score."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7587/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700682569025,
                "cdate": 1700682569025,
                "tmdate": 1700682569025,
                "mdate": 1700682569025,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "an0Kmm0OkG",
            "forum": "5T46w5X3Go",
            "replyto": "5T46w5X3Go",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7587/Reviewer_6fkR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7587/Reviewer_6fkR"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a theoretical analysis of transfer learning in the under-parameterized and over-parameterized scenarios. The paper explores two options for transfer: 1) option A, where the common parameters are copied and only the task specific parameters are trained for the target task, 2) option B, where the common parameters are initialized for the target task and both the common and task specific parameters are trained during that task. The paper presents theoretical results, along with some experiments, for the parameter transfer setting, such as when benign overfitting occurs, what are the effects of noise, and the comparison of the common vs. task-specific parameters for both options."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- The paper presents a much needed theoretical analysis of some interesting scenarios in parameter transfer. The contributions seem original and of significance for researchers in transfer learning and related areas. \n- The paper is very well-written and structured. \n- The paper presents the ideas in a clear way for a theoretical paper. The concepts are presented in a structured manner, and some experimental results are provided to support the theoretical claims."
                },
                "weaknesses": {
                    "value": "- Understandability of some key parts of the paper could be improved. For example, for \"Option A\" and \"Option B\", considering how relevant these are for the main results of the paper, perhaps more meaningful names could have been used so it is easy to grasp and associate theoretical results with what's going on in these of these \"options\"."
                },
                "questions": {
                    "value": "- Is there any connection between your work and well-known theoretical studies in multitask learning? [1] Or is your analysis also applicable to multitask learning scenarios? There may be a strong connection since a lot of approaches in multitask learning also rely on the common/task-specific features paradigm.\n\n[1] Baxter, J. (2000). A model of inductive bias learning. Journal of artificial intelligence research, 12, 149-198."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7587/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698804439736,
            "cdate": 1698804439736,
            "tmdate": 1699636919100,
            "mdate": 1699636919100,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ADTg1mDbJH",
                "forum": "5T46w5X3Go",
                "replyto": "an0Kmm0OkG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7587/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7587/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> Understandability of some key parts of the paper could be improved. For example, for \"Option A\" and \"Option B\", considering how relevant these are for the main results of the paper, perhaps more meaningful names could have been used so it is easy to grasp and associate theoretical results with what's going on in these of these \"options\".\n\n**Response**: We thank the reviewer for these helpful suggestions. In light of the reviewer\u2019s suggestion, in Sec. 2.4 of the revision, we have now renamed the options as Option A \u2013 \u201cTransfer and Fix\u201d, Option B \u2013 \u201cTransfer and Train\u201d.\n\n---\n\n> Is there any connection between your work and well-known theoretical studies in multitask learning? [1] Or is your analysis also applicable to multitask learning scenarios? There may be a strong connection since a lot of approaches in multitask learning also rely on the common/task-specific features paradigm.\n\n> [1] Baxter, J. (2000). A model of inductive bias learning. Journal of artificial intelligence research, 12, 149-198.\n\n**Response**: We thank the reviewer for these important questions and suggestions. To the best of our knowledge, there is no multitask learning result similar to ours that studies the overfitted generalization performance with common/task-specific features separation. \n\nIn [1] and an extensive line of research on multi-task learning, the focus was on the **under-paraemeterized** regime, where the sample size should be large enough (larger than the complexity of the model class in terms of, e.g., VC-dimension or covering number). In contrast, our focus is on the **over-parameterized** regime, where we characterize that the desirable test performance is still achievable, i.e., benign overfitting can occur.\n\nIf the reviewer has any specific work in mind, we are more than happy to cite and make comparisons with this work. We also plan to investigate the case of multiple source/target tasks as future work, building on and exploiting our current analysis.\n\n---"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7587/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700678189731,
                "cdate": 1700678189731,
                "tmdate": 1700678189731,
                "mdate": 1700678189731,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "19TwrRpNmD",
            "forum": "5T46w5X3Go",
            "replyto": "5T46w5X3Go",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7587/Reviewer_hznS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7587/Reviewer_hznS"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the generalization of transfer learning in linear regression models under both underparameterized and overparameterized regimes. This work proposes to partition the feature space into common and task-specific parts and analyze the influence of the number of parameters on the generalization performance. This paper presents the transferring errors for two types of transfer learning: the first one fixes the common features and the second one further trains the model initializes from the parameters corresponding to the common features. This paper provides two insights: First, this paper shows that allocating more features to task-specific parts benefits the target task more than allocating to the common part. Second, This paper finds that under high noise and small parameter regimes, sacrificing certain features in the common part and adding more to the task-specific part can yield better generalization."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "This work proposes to partition the feature space into common and task-specific parts and analyze the influence of the number of parameters on the generalization performance. The results provide insights into choosing different transferring methods under linear regression settings."
                },
                "weaknesses": {
                    "value": "- It is unclear what the contributions this paper makes to the existing literature. It would be better to specify which existing works are compared to when discussing them in the introduction and the main text. \n- The terms used in this paper need further specification. For example, it would be better to provide formal definitions of generalization performance, transferring errors, benign overfitting, and descent floors."
                },
                "questions": {
                    "value": "- What does the second step (\"extract and transfer the learned parameters of the common features\")  of parameter transfer mean? It would be better to elaborate on this step. \n- It would be better to provide a formal definition of the transferring error presented in Theorem 1. \n- Can the insights from the presented theorems be extended to transfer learning with deep neural networks? Although the theorems are presented for linear regression settings, it would be better to discuss the potential implications for deep neural networks."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7587/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698807162849,
            "cdate": 1698807162849,
            "tmdate": 1699636918989,
            "mdate": 1699636918989,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5BecpLypma",
                "forum": "5T46w5X3Go",
                "replyto": "19TwrRpNmD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7587/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7587/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer hznS (part 1)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their valuable and constructive comments.\n\n> It is unclear what the contributions this paper makes to the existing literature. It would be better to specify which existing works are compared to when discussing them in the introduction and the main text.\n\n**Response**: We thank the reviewer for these valuable comments. Our contribution is as follows:  In this paper, we investigate the generalization performance of transfer learning in linear regression models under both the underparameterized and overparameterized regimes. \nCompared to the existing literature that considers a general noisy linear relation between the true parameters of the source and target tasks, we delve into the separation between common and task-specific features in greater detail.\nSpecifically, we partition the feature space into a common part and a task-specific part. This setup enables us to analyze how the number of parameters in different parts influences the generalization performance of the target task. By characterizing the generalization performance, we offer insightful findings on transfer learning. For instance, when the total number of features in the source task's learning model is fixed, our analysis reveals the advantage of \\emph{allocating more redundant features to the task-specific part rather than the common part}. Additionally, in specific scenarios characterized by high noise levels and small true parameters, *sacrificing certain true features in the common part in favor of employing more redundant features in the task-specific part can yield notable benefits*.\n\nThe most related work to ours is [ref 1]. Specifically, [ref 1] studies the double descent phenomenon in transfer learning, which is also our focus in this paper. However, [ref 1] does not consider an explicit separation of the feature space by the common part and the task-specific part like we do in this paper. As we show, such a separation in the system model enables us to analyze the double descent phenomenon under different options for transfer learning, including two options for parameter transfer and two options for data transfer. In contrast, [ref 1] only studies one option of parameter transfer. Therefore, our analysis is quite different from that of [ref 1].\n\nWhile the contributions of this paper are summarized in the last paragraph of the Introduction and the comparison to the existing works are introduced in Sec. 1.1, we will improve our discussion in the paper to clarify these important points.\n\n[1] Yehuda Dar and Richard G Baraniuk. Double double descent: on generalization errors in transfer learning between linear regression tasks. SIAM Journal on Mathematics of Data Science, 4(4): 1447\u20131472, 2022.\n\n---\n\n> The terms used in this paper need further specification. For example, it would be better to provide formal definitions of generalization performance, transferring errors, benign overfitting, and descent floors.\n\n**Response**: Thank you for these valuable suggestions. Please note that the formal definitions of performance evaluation and transferring errors are given in Sec. 2.5. \u201cBenign overfitting\u201d means that the test error of the overparameterized regime is lower than that of the underparameterized regime. \u201cDescent floor\u201d means that (in the overparameterized regime) the descent of the test error stops at a certain point (which is like a floor). We have revised the presentation in the paper to make these points clear.\n\n---\n\n> What does the second step (\"extract and transfer the learned parameters of the common features\") of parameter transfer mean? It would be better to elaborate on this step.\n\n**Response**: We thank the reviewer for this question and suggestion. The second step means selecting the parameters for the common features $S_{co}$ from the learned result of the source task and then sending them to the target task model. We have improved our discussion in the paper to clarify this important point.\n\n---\n\n> It would be better to provide a formal definition of the transferring error presented in Theorem 1.\n\n**Response**: Thank you for this valuable suggestion. The formal definition of the transferring error is given by Eq. (5). We have clarified this important point in the revision.\n\n---\n**Followed by \"Response to Reviewer hznS (part 2)\"**"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7587/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700678011271,
                "cdate": 1700678011271,
                "tmdate": 1700678011271,
                "mdate": 1700678011271,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "HAzDIJlmj2",
            "forum": "5T46w5X3Go",
            "replyto": "5T46w5X3Go",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7587/Reviewer_kvri"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7587/Reviewer_kvri"
            ],
            "content": {
                "summary": {
                    "value": "The paper explores transfer learning in a linear regression model, wherein certain features are shared between the source and target, while other features are specific to each. Then it analyzes two transfer options:\n A) The learner first learns the source parameter and transfers the parameters corresponding to the shared feature to the target. Afterward, it learns only the parameters corresponding to the target-specific features.\n B) The learner first learns the source parameters and then uses the learned source parameters as an initialization for the target parameters corresponding to the shared features.\n\nThen, by considering both overparameterized and underparameterized settings, it analyzes the behavior of target generalization error as the number of features and parameters varies."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper analyzes the target generalization error as a function of the number of common and task-specific features and parameters as well as the variance of the noise in the model. Furthermore, it characterizes the regimes in which benign overfitting happens. For instance, they show that in some cases it would be more beneficial to allocate more redundant features to the task-specific part rather than the shared one."
                },
                "weaknesses": {
                    "value": "The model assumed in the paper is quite restrictive. Firstly, it only considers a linear model. Even more restrictive is the assumption that exact shared features exist between the source and target datasets. Additionally, the paper assumes that the shared features are included in the training examples, and the training examples may contain at most some redundant features. In other words, by eliminating only some of the features, one can recover both the shared features and task-specific features.\n\nCertainly, when the source and target share the same features, they become transferable. However, the reverse is not necessarily true. In a previous study [1], it was demonstrated that in a linear regression model, transferability can still occur even if the datasets lack exact shared features, as long as their ground truth parameters have a small distance according to the Frobenius norm.\n\nFurthermore, the literature on transfer learning contains numerous results where source and target training examples do not initially include shared common features. However, through certain transformations, it is possible to find a subspace in which the source and target datasets share common features.\n\nMoreover, the paper has only derived some formulas for generalization error, and it only explains what would happen if one varies the parameters. It does not provide insight into why varying the parameters in certain regimes results in an increase or decrease in generalization error. The paper does not go beyond explaining the algebraic relationships.\n\n\n[1] SM Mousavi Kalan, Z Fabian, S Avestimehr, M Soltanolkotabi; Minimax Lower Bounds for Transfer Learning with Linear and One-hidden Layer Neural Networks."
                },
                "questions": {
                    "value": "I recommend the authors generalize their results to the case where initially the source and target training examples do not contain shared and task-specific features. However, there exists an unknown transformation after which one can discover exact shared features.\nAlternatively, if some of the ground truth parameters between the source and target are close to each other, though not necessarily the same, it would be interesting to investigate and characterize benign overfitting in these more practical scenarios."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7587/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699039794545,
            "cdate": 1699039794545,
            "tmdate": 1699636918870,
            "mdate": 1699636918870,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oYcezIRloV",
                "forum": "5T46w5X3Go",
                "replyto": "HAzDIJlmj2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7587/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7587/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their valuable and constructive comments.\n\n1. **Linear model**: Using a linear model as an initial step is common in the field of theoretical study. Possible future work using more realistic models will also benefit from our work with the linear model. Gaining an understanding of the simple model is fundamentally important to gaining an understanding of more realistic models.\n\n2. **Assumptions of knowing features**: For certain applications of machine learning, knowing features in advance is very common in modern machine learning (ML), via pre-training over a big collection of tasks (generally referred to as feature engineering), so that these features can benefit later downstream tasks without the need of reconstructing these features again in each individual task. In particular, recent huge successes such as contrast learning and pre-training large language models (LLMs) can provide powerful pre-trained and general-purpose features/representations (e.g., [ref a], [ref b]). These new ML advances motivate/justify the line of research on transfer learning (which our paper follows) to leverage those well-trained features beforehand and focus on designing the transfer of other model parameters to benefit target tasks. In addition to the above references, the idea of incorporating **known** features into the learning formulation has become popular in other ML studies (such as in few-shot learning [ref b]) and has been well accepted in the ML community. We will improve our discussion of these points in the paper to address this important concern raised by the reviewer. \n\n[a] Kaiming He, et. al, \u201cMomentum Contrast for Unsupervised Visual Representation Learning\u201d CVPR 202.\n\n[b] Tom Brown et. al, \u201cLanguage Models are Few-Shot Learners\u201d NeurIPS 2020.\n\n\n3. **\u201c..the training examples may contain at most some redundant features..\u201d**: We also allow missing features by Remark 1. \n\n4. **\u201cCertainly, when the source and target share the same features, they become transferable. However, the reverse is not necessarily true.\u201d**: We agree that from a mathematical point of view, as long as the transferred parameters are the same or similar, transfer learning is beneficial even if there are no shared features. However, in practice, many use cases of transfer learning still rely on the similarity of shared features. This is why we use the current setting that there exists a partial similarity between the source and the target tasks. We will revise the text to make these points clear.\n\n5. **\u201cThe paper does not go beyond explaining the algebraic relationships.\u201d**: The algebraic relationships are very important to understanding the fundamental properties of transfer learning and to the design of transfer learning strategies. Besides the algebraic relationships, we also provide intuitive reasonings, e.g., in Sec. 4.1, we give an intuitive comparison of Options A and B: *An intuitive explanation of the reason for these differences is that Option B does train the common part learned by the source task but Option A does not. Thus, Option B should do better to learn the common part. At the same time, since Option B uses more parameters ($p+p_{(2)}$) than Option A ($p$) to learn the target task's samples, the noise effect is spread among more parameters in Option B than in Option A, and thus Option B can mitigate the noise better than Option A. \u2026*\n\n\n\n\n\n6. **\u201cfind a subspace/transformation in which the source and target datasets share common features.\u201d**: We agree that learning a feature representation shared across tasks itself is already an important research direction, e.g., [ref c]. Of course, generalizing our results to this setting will also be meaningful. Since our current analysis under known features is already very complicated, we plan to leave it to the future work. Moreover, such generalization of our results to the suggested setting will be able to build on and exploit our current analysis. We will revise the paper to comment on this important point.\n\n[c] Nilesh Tripuraneni, Michael Jordan, and Chi Jin. On the theory of transfer learning: The importance of task diversity. NeurIPS, 2020."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7587/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700677734802,
                "cdate": 1700677734802,
                "tmdate": 1700677734802,
                "mdate": 1700677734802,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]