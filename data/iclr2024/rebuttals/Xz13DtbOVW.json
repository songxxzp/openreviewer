[
    {
        "title": "Balancing Act: Sparse Models with Constrained Disparate Impact"
    },
    {
        "review": {
            "id": "tH6SfUDtf4",
            "forum": "Xz13DtbOVW",
            "replyto": "Xz13DtbOVW",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1562/Reviewer_qBid"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1562/Reviewer_qBid"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a method for mitigating disparate effect on model accuracy by formulating the task as a constrained optimization problem and solving it via alternative gradient descent. The introduced approach manages to decrease the gap between average model performance and worst performance on a subgroup of data while preserving the mean accuracy on the target task."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The problem being addressed is quite novel in sparsification community and is of significant interest to practitioners, especially in safety-critical applications. The approach looks very reasonable and directly optimizes the imposed constraints via solving a min-max problem. The method is quite non-trivial and comprises several interesting ideas - alternating between non-differentiable accuracy constrain term and excess loss term, as well as use of replay buffers for stabilization of optimization. \n\nCEAG outperforms existing alternatives on a couple of benchmarks - UTKFace and CIFAR100. The method doesn\u2019t add significant computation overhead compared to the standard training procedure."
                },
                "weaknesses": {
                    "value": "While the proposed method manages to keep train accuracy on subgroups within desired tolerance bounds, seems it has hard to achieve on the test data, especially in the setting with many classes and subgroups (for example in the provided CIFAR-100 experiment). \n\nThe difference between $\\mathrm{max}_g \\psi_g $ on the hold-out-data between NFT and CEAG doesn\u2019t seem to be very significant in many cases - 2.0 vs 2.1 on 99% sparsity UTKFace *(Table1)*, 3.3 vs 3.6 for 92.5% *(Table2)*, 13.8 vs 14.3 on CIFAR-100 *(Table3)*. Given the standard deviation of the runs, improvement of CEAG appears to be statistically insignificant. \n\nExperimental validation is not exhaustive enough. To demonstrate the efficiency in a more large scale and practically relevant scenario one could consider more diverse and large-scale dataset, such as ImageNet (or ImageNet-LT version), or one of the iNaturalist versions, considering only large hierarchy groups to make the task computationally tangible. \n\n*Minor*. The pruning strategy called in the paper is customary named **Gradual Magnitude Pruning** (GMP) [2], where after each pruning step one continues training the model from the current state. **Iterative Magnitude Pruning** (IMP) [3] adopted in discovery of Lottery Tickets rewinds the weights to initialization after pruning step. I would suggest calling the method GMP to avoid confusion. \n\n---\n[1] Liu, Ziwei, et al. \"Large-scale long-tailed recognition in an open world.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019.\n\n[2] Zhu, Michael, and Suyog Gupta. \"To prune, or not to prune: exploring the efficacy of pruning for model compression.\" arXiv preprint arXiv:1710.01878 (2017).\n\n[3] Frankle, Jonathan, and Michael Carbin. \"The lottery ticket hypothesis: Finding sparse, trainable neural networks.\" arXiv preprint arXiv:1803.03635 (2018)."
                },
                "questions": {
                    "value": "How sensitive is the algorithm to the initialization of dual parameters $\\lambda_g$ and the corresponding update rule?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1562/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1562/Reviewer_qBid",
                        "ICLR.cc/2024/Conference/Submission1562/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1562/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698344111769,
            "cdate": 1698344111769,
            "tmdate": 1700244174464,
            "mdate": 1700244174464,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SNqH5Q1MBD",
                "forum": "Xz13DtbOVW",
                "replyto": "tH6SfUDtf4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for acknowledging the novelty of our method and the importance of the research to the community. \n\n---\n\n> While the proposed method manages to keep train accuracy on subgroups within desired tolerance bounds, seems it has hard to achieve on the test data, especially in the setting with many classes and subgroups (for example in the provided CIFAR-100 experiment).\n\n\nWe agree with the reviewer's observation about the issue of generalization to the test data. In fact, we had highlighted this issue explicitly in the final paragraph of the introduction. We have rephrased our statement to make it clearer:\n\n> Our experimental results indicate that _all methods considered in this paper (including ours) fail to mitigate pruning-induced disparities on unseen data_. To the best of our knowledge, we are the first to document this generalization challenge. Despite this, our proposed method constitutes a step in the right direction since our approach is _the only one_ that reliably mitigates the disparate impact of pruning on the training set. We hope our empirical observations will motivate further research on improving the generalization properties of methods for mitigating the disparate impact of pruning. \n\nWe hypothesize this behavior was not observed before due to:\n* the previous papers did not report the performance of the model in training, and\n* they were relying on heuristic metrics for quantifying disparate impact (for example, measuring the standard deviation of the group accuracy gaps $  std_{g \\in \\mathcal{G}} (\\Delta_g  )$  ), rather than measuring  $\\Psi_{\\text{PW}}$ directly.\n\nWe completely agree with the reviewer on the importance of tackling the issue of generalization for disparity-mitigation techniques. We would like to highlight the role our paper has in documenting the generalization issue as a main challenge for the field.\n\n---\n\n>The difference between $\\max_g \\Psi_g$ on the hold-out-data between NFT and CEAG doesn\u2019t seem to be very significant in many cases - 2.0 vs 2.1 on 99% sparsity UTKFace (Table1), 3.3 vs 3.6 for 92.5% (Table2), 13.8 vs 14.3 on CIFAR-100 (Table3). Given the standard deviation of the runs, improvement of CEAG appears to be statistically insignificant.\n\nAs mentioned before, all considered methods, including ours, struggle to mitigate disparity on the test data. In that sense, we agree with the reviewer's claim about the lack of statistical significance of our improvements **in the test set**. \n\nHowever, despite the challenges on the test set, we would like to emphasize that, all else being equal, our method should be preferred to existing alternatives since it is **the only one to reliably mitigate the disparate impact on the training set**."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700176699496,
                "cdate": 1700176699496,
                "tmdate": 1700176699496,
                "mdate": 1700176699496,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "n4I5hN6dqi",
                "forum": "Xz13DtbOVW",
                "replyto": "tH6SfUDtf4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> Experimental validation is not exhaustive enough. To demonstrate the efficiency in a more large-scale and practically relevant scenario one could consider more diverse and large-scale dataset, such as ImageNet (or ImageNet-LT version), or one of the iNaturalist versions, considering only large hierarchy groups to make the task computationally tangible.\n\nWe respectfully disagree with the reviewer's assessment of the scale and thoroughness of our experimental results. \n\nTo the best of our knowledge, existing papers in the literature about *mitigating* the disparate impact of pruning, focus on the UTKFace, FairFace, and CelebA datasets. Besides UTKFace, Tran et al. [A] carry out additional experiments on small-scale datasets such as MNIST or SVHN. Hooker et al. [B] consider the ImageNet dataset, but *limit themselves to documenting the existence of pruning-induced disparate impact*, and do not propose a mitigation scheme.\n\nOur paper contains experiments on UTKFace and FairFace, as in existing works. Additionally, we executed experiments for these datasets on the \"intersectional setting\", leading to a larger number (2x) of protected groups than considered in previous papers. **The intersectional setting was not previously considered in this literature**.\n\nWe decided against the CelebA task in Lin et al. [C] since it is a multi-attribute prediction task, which could make the assessment of disparate impact challenging (since overall accuracy is aggregated across prediction attributes).\n\nImportantly, we introduced the CIFAR100 task to demonstrate the *scalability of our method to hundreds of constraints*. This is an important contribution taking into account that prior work explored tasks with only up to 10 protected groups. Moreover, existing methods such as FairGRAPE [C] require prohibitive costs in terms of computation and storage, increasing with the number of constraints. In Appendix D2 \"Additional Experiments > Computational Overhead\" (in revised version), we provide time measurements which demonstrate that our method seamlessly scales to hundreds of constraints.\n\nWe understand the reviewer's interest in testing our method on ever-larger tasks such as ImageNet or iNaturalist. We would like to highlight that our method can be directly applied to these larger tasks without significant overhead. However, we believe that our experimental validation is more than sufficient *in the context of the existing literature*. \n\nFinally, **Reviewer KSs2** requested experiments on structured sparsity. This setting is practically relevant (as **Reviewer qBid** requested) since it yields sparsity patterns that can be leveraged for fast computation in existing hardware (unlike unstructured sparsity). Arguably, good performance of a mitigation method on both the structured and unstructured settings is more indicative of the method's benefits than testing it on a new dataset.\n**Please see additional experiments** executed during the discussion phase using structured sparsity in our response to **Reviewer KSs2**.\n\n\n[A] Cuong Tran, Ferdinando Fioretto, Jung-Eun Kim, and Rakshit Naidu. Pruning has a disparate impact on model accuracy. In NeurIPS, 2022.\n\n[B] Sara Hooker, Nyalleng Moorosi, Gregory Clark, Samy Bengio, and Emily Denton. Characterising Bias in Compressed Models. arXiv:2010.03058, 2020.\n\n[C] Xiaofeng Lin, Seungbae Kim, and Jungseock Joo. FairGRAPE: Fairness-Aware GRAdient Pruning mEthod for Face Attribute Classification. In ECCV, 2022.\n\n---\n\n> Minor. The pruning strategy called in the paper is customary named Gradual Magnitude Pruning (GMP) [2], where after each pruning step one continues training the model from the current state. Iterative Magnitude Pruning (IMP) [3] adopted in discovery of Lottery Tickets rewinds the weights to initialization after pruning step. I would suggest calling the method GMP to avoid confusion.\n\nWe thank the reviewer for the suggestion. We will adjust the paper and refer to the method proposed by Zhu and Gupta as Gradual Magnitude Pruning (GMP) to avoid confusion with Iterative Magnitude Pruning (IMP) popularized by Frankle and Carbin."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700176769402,
                "cdate": 1700176769402,
                "tmdate": 1700176769402,
                "mdate": 1700176769402,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "voHKhWe8qG",
                "forum": "Xz13DtbOVW",
                "replyto": "n4I5hN6dqi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1562/Reviewer_qBid"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1562/Reviewer_qBid"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your answer and clarifications.\nNow I understand that the work has significant phenomenological contribution in addition to the introduction of a new method. Structured sparsity experiments provide an additional validation of the CEAG approach and contain several interesting findings. \nWhile from the practical point of view one is interested in preserving the accuracy uniformly across the **unseen**, **hold-out** data rather than the train set, I think that the obtained results are valuable for the research community.\n\nI agree, that the evaluation presented in the work follows the previous work and introduces some new results. However, since the problem considered is quite generic, potentially arising in many real-world scenarios, I think an experiment on a large-scale dataset would significantly strengthen the experimental section of the paper. \n\nNevertheless, I decide to raise my score after reading responses addressed to me and other reviewers."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700244150719,
                "cdate": 1700244150719,
                "tmdate": 1700244150719,
                "mdate": 1700244150719,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BB6Dm9qkz2",
            "forum": "Xz13DtbOVW",
            "replyto": "Xz13DtbOVW",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1562/Reviewer_KSs2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1562/Reviewer_KSs2"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes a new approach for fine-tuning sparse models after pruning. The proposed approach involves formulating a constrained problem, where loss function is optimized subject to a group-wise accuracy constraint (that is, the accuracy drop for each group should be bounded by a tolerance $\\varepsilon$). This Lagrangian of this constrained problem is then optimized with standard gradient-based methods. This approach is empirically shown to reliably generate models where the differences in the group-wise impact of sparsity on accuracy is minimized."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper has several strengths:\n\n* The proposed approach is interesting, novel, and flexible, and reliably reduces group wise disparities in accuracy after pruning.\n* The empirical evaluation is very thorough.\n* Limitations of the proposed methods and ethical considerations are discussed thoroughly as well.\n* In the appendix, variations of the main results are discussed as well.;/\n* The writing and presentation is clear."
                },
                "weaknesses": {
                    "value": "The paper has a few weaknesses. \n\n* This method is independent of the choice of pruning strategy. However, it would have been nice to see the experiments replicated for other pruning strategies, including structured pruning methods. \n* A more detailed discussion on the feasibility of the constrained problem given in equation (4) would have been useful for readers."
                },
                "questions": {
                    "value": "* Have the authors tried applying this technique to other pruning methods? For instance, how well would this fine-tuning method work if structured pruning was used instead of unstructured pruning? How well would the method work if other unstructured pruning methods were used instead of IMP (i.e. SynFlow [1] or SNIP [2])?\n* Is there a sparsity level at which the method fails to achieve models with the desired worst-case groupwise accuracy loss? Put another way, is there a sparsity level at which the constrained optimization problem described in eq. (5) become infeasible? Can the authors comment on how this might play out in the case of structured pruning?\n* Are there any formal results that can be provided for solving the CEAG (eq (5))? For instance, is Algorithm 1 guaranteed to find a solution provided the feasible set is nonempty?\n* Have the authors considered ways by which the test-case performance can be improved, say by dataset splits?\n* Is the CEAG method affected by dataset imbalance? Suppose certain groups have comparatively fewer samples in the dataset. How, if at all, would this affect the efficacy of the method?\n\n[1] \"Pruning neural networks without any data by iteratively conserving synaptic flow\", Tanaka et al, 2020.\n\n[2] \"SNIP: Single-shot Network Pruning based on Connection Sensitivity\" Lee et al, 2019."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1562/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1562/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1562/Reviewer_KSs2"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1562/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698833862775,
            "cdate": 1698833862775,
            "tmdate": 1699636084489,
            "mdate": 1699636084489,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4iKkOGlxdc",
                "forum": "Xz13DtbOVW",
                "replyto": "BB6Dm9qkz2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for highlighting the importance of the research and the thoroughness and novelty of our paper. We would also like to thank the reviewer for their thorough review and insightful questions about our work.\n\n---\n> Is there a sparsity level at which the method fails to achieve models with the desired worst-case groupwise accuracy loss? Put another way, is there a sparsity level at which the constrained optimization problem described in eq. (5) become infeasible? Can the authors comment on how this might play out in the case of structured pruning?\n\nIt has been previously documented [A, B, C] that deep neural networks are robust to high levels of sparsity, but their training dynamics become challenging. Our constrained formulation suffers from similar challenges, and we would expect that these difficulties become more pronounced in the constrained setting\u2014as per the reviewer's intuition.\n\nFor our experiments, we chose commonly used sparsity levels for the different architectures and we were able to find feasible solutions that achieved disparity below that of the (unconstrained) NFT baseline. Empirically, the \"breaking point\" for the tolerance level did not increase as a result of adding the constraints. \n\nNote that when increasing the sparsity level, we sometimes had to increase the constraint level (e.g. Table 25 in revision [UTKFace > Intersectional]). However, this is mostly due to the loss of model capacity, as is observed in the increase in $\\max_g \\psi_g$ experienced by the *unconstrained* NFT baseline. \n\n\n[A] Song Han, Jeff Pool, John Tran, William J. Dally. Learning Both Weights and Connections for Efficient Neural Network. In NeurIPS, 2015.\n\n[B] Trevor Gale, Erich Elsen, and Sara Hooker. The State of Sparsity in Deep Neural Networks. arXiv:1902.09574, 2019.\n\n[C] Utku Evci, Fabian Pedregosa, Aidan Gomez, and Erich Elsen. The Difficulty of Training Sparse Neural Networks.\" arXiv:1906.10732, 2019.\n\n---\n>Are there any formal results that can be provided for solving the CEAG (eq (5))? For instance, is Algorithm 1 guaranteed to find a solution provided the feasible set is nonempty?\n\nNo, even if the feasible set is non-empty, there is no guarantee that Algorithm 1 will find a solution. The possibility for analysis is limited as we consider a non-convex, non-differentiable constrained optimization problem. Viewed from the min-max angle, the use of proxy-constraints results in a non-zero-sum game. Providing convergence guarantees for these optimization problems is a challenging, open area of research, beyond the scope of our work.\n\nWe invite the reviewer to read our response to **Reviewer Cvd6**, including some pointers to local convergence results under idealized problem conditions.\n\n---\n\n> Have the authors considered ways by which the test-case performance can be improved, say by dataset splits?\n\nThis is an interesting idea. In the development of the paper, we considered an early-stopping approach based on constraint and objective estimates on a validation set. Due to the reasons detailed below, we decided not to proceed with this approach in our main experiments. However, exploring techniques to improve test-case performance for disparity-mitigation methods is an important research direction.\n\nThe early-stopping approach mentioned above required creating validation splits, which were unfortunately not available for the datasets we considered. In order to make fair comparisons with existing methods, we decided to retain the same choice of model architecture and train/test split. However, in some tasks, we make use of models that have been pre-trained on the entire training set (containing our self-made validation datapoints). Thus the constraint and objective estimates on the validation set would be unreliable due to data leakage. Since these challenges would have prevented us from executing a proper ablation study on the benefits of this technique, we decided not to pursue this."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700175825667,
                "cdate": 1700175825667,
                "tmdate": 1700175825667,
                "mdate": 1700175825667,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "E5fpcjRZ8a",
                "forum": "Xz13DtbOVW",
                "replyto": "BB6Dm9qkz2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> Is the CEAG method affected by dataset imbalance? Suppose certain groups have comparatively fewer samples in the dataset. How, if at all, would this affect the efficacy of the method?\n\nThis is an important question and of great importance in fairness. Our proposed CEAG method is designed specifically with this issue in mind.\n\nData imbalance affects training of fairness-aware methods in two main ways:\n* Under-represented groups might not have enough samples to sway the model's updates toward satisfying their constraints.\n* Estimating the constraints associated with under-represented groups may be challenging due to the low number of samples in the stochastic estimates.\n\nCEAG directly addressed both of these challenges by (1) introducing explicit per-group constraints and (2) using Replay Buffers (RB, Section 4.2) to reduce estimation noise.\n\n* If a constraint for any group (under-represented or not) is violated persistently, its associated Lagrange multiplier will increase, biasing the model gradient towards achieving the satisfaction of the constraint.\n* On the other hand, RBs allow our method to scale to a large number of constraints (even in the data imbalance setting) by constructing less noisy estimates of the constraint violations. Moreover, RBs also improve the stability of the training dynamics under an imbalanced dataset with few protected groups. \n\nWe would like to highlight that the use of RBs was one of the key components for improving the scalability and stability of Equalized Loss, originally proposed by Tran et al. [A].\n\nExperimentally, our method excels in tasks with high data imbalance (such as intersectional fairness) compared to all other techniques\u2014see Table 2 at 92.5% sparsity.\n\n[A] Cuong Tran, Ferdinando Fioretto, Jung-Eun Kim, and Rakshit Naidu. Pruning has a disparate impact on model accuracy. In NeurIPS, 2022."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700175989052,
                "cdate": 1700175989052,
                "tmdate": 1700175989052,
                "mdate": 1700175989052,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Jtesst1CzB",
                "forum": "Xz13DtbOVW",
                "replyto": "BB6Dm9qkz2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Structured Sparsity Experiments"
                    },
                    "comment": {
                        "value": "> Have the authors tried applying this technique to other pruning methods? For instance, how well would this fine-tuning method work if structured pruning was used instead of unstructured pruning? How well would the method work if other unstructured pruning methods were used instead of IMP (i.e. SynFlow [1] or SNIP [2])?\n\nAs the reviewer acknowledged, our proposed method is agnostic to the choice of pruning method. We expect it to behave well under popular pruning techniques like those mentioned by the reviewer.\n\nIn particular, structured sparsity is practically relevant since it enables fast inference on existing hardware. Following the reviewer's suggestion, **we conducted additional experiments** demonstrating the behavior of our proposed technique (and all other baselines) in this setting.\n\n**Experiment set-up**\n- UTKFace dataset with target=race and protected attribute=race.\n- Same experimental setting as other UTKFace experiments in the main paper.\n- Metrics averaged over 5 seeds.\n- Layerwise structured output-channel sparsity at 85%.\n\n**Results**\n*Please read the clarifications below the table to adequately interpret the behavior of $\\Psi_{\\text{PW}}$ in test for EL+RB and CEAG!*\n\n| Sparsity |  Method  |            |        Train         |                 |                  |           |        Test        |                 |\n|----------|----------|------------|----------------------|-----------------|------------------|-----------|--------------------|-----------------|\n|          |          |  Accuracy  | $\\Psi_{\\text{PW}}$   | $\\max_g \\psi_g$ | Tol ($\\epsilon$) | Accuracy  | $\\Psi_{\\text{PW}}$ | $\\max_g \\psi_g$ |\n|85        | NFT      | 89.1\u00b10.39  |      50.6\u00b11.08       |    45.8\u00b10.82    |        \u2013         | 80.7\u00b10.27 |       4.1\u00b11.7      |    2.0\u00b10.61     |\n|85        | NFT + ES | 87.7\u00b10.71  |      58.3\u00b13.08       |    52.7\u00b12.91    |        \u2013         | 81.5\u00b10.11 |       4.7\u00b12.06     |    3.2\u00b11.52     |\n|85        | EL + RB  | 86.9\u00b10.47  |      3.7\u00b11.38        |    1.2\u00b10.53     |        \u2013         | 77.9\u00b10.44 |       27.3\u00b12.58    |    3.2\u00b10.65     |\n|85        | CEAG     | 85.6\u00b10.47  |      2.7\u00b10.71        |    1.0\u00b10.36     |        \u2264 1%      | 78.2\u00b10.39 |       30.1\u00b12.19    |    3.7\u00b10.28     |\n\n\n\n\n***Key-points:***\n* CEAG and EL+RB successfully mitigate pruning-induced disparate impact in the structured sparsity setting.\n* The results show that our method CEAG achieves the lowest disparate impact in train.\n* Our method has a high $\\Psi_{\\text{PW}}$ in test because the under-represented group *improved* its test accuracy.\n\n***Clarifications:***\nWe note an unusual pattern in the train-vs-test performance between mitigation methods like EL+RB and CEAG, and the NFT baselines: mitigation methods have very low disparity ($\\Psi_{\\text{PW}}$) in training but very high disparity in test (and vice versa for NFT). \n\nThe reason behind this behavior is the performance of the different models on the under-represented group *\"Others\"*, corresponding to ~3% of the dataset. The relevant metrics (averaged over 5 seeds) are summarized in the table below.\n\n* The pre-trained model had overfitted to the training samples of group *\"Others\"*.\n* In the case of NFT, the training objective allows the models to sacrifice performance on under-represented classes in order to favor more numerous ones. In particular, we observed that NFT caused a hyper-degradation (EAG) in group *\"Others\"* of 45.77%.\n* On the other hand, mitigation techniques like EL+RB and CEAG do **not** yield models that obliviously sacrifice the performance on group *\"Others\"*. For example, for CEAG the loss in performance in group *\"Others\"* (13.4%) in training is similar to the overall training accuracy reduction (14.14%). \n\n\nIn other words, **the mitigation methods successfully prevent the appearance of excessive disparity due to pruning** by making sure no class (under-represented or not) is degraded more than $\\epsilon$ beyond the average model degradation.\n\n\n| Metric (avg. over 5 seeds) | Dense | NFT | EL+RB | CEAG |\n| -------- | -------- | -------- | -------- | -------- |\n| Overall Acc. Train | 99.74 | 89.1  |86.9  | 85.6 |\n| Overall Acc. Test  | 83.82 | 80.7 | 77.9 | 78.2 |\n| Acc. Others Train | 99.37 |42.96  | 88.37 | 85.97 |\n| Acc. Others Test | 29.23 | 26.31 | 47.38 | 49.97 |\n| Overall Acc. Gap Train ($\\Delta$) | 0 | 10.64 | 12.84 | 14.14 | \n| Overall Acc. Gap Test ($\\Delta$) |  0   | 3.12 | 5.92 | 5.62 |\n| Acc. Gap Others Train ($\\Delta_{\\text{Others}}$) | 0 | 56.41 | 11.0 | 13.4 |\n| Acc. Gap Others Test ($\\Delta_{\\text{Others}}$) | 0 | 2.92 | -18.15 | -20.74 |\n| EAG Others Train ($\\psi_{\\text{Others}}$) | 0 | 45.77 \u26a0\ufe0f | -1.84 | -0.74 |\n| EAG Others Test ($\\psi_{\\text{Others}}$) | 0 | -0.2 | -24.07 | -26.36 |"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700178718590,
                "cdate": 1700178718590,
                "tmdate": 1700178718590,
                "mdate": 1700178718590,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7hdNOK3WMi",
                "forum": "Xz13DtbOVW",
                "replyto": "Jtesst1CzB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1562/Reviewer_KSs2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1562/Reviewer_KSs2"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "I would like to thank the authors for their very detailed and clear response - you have answered all my questions. However, at this time, I would like to keep my score at 8."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700318048505,
                "cdate": 1700318048505,
                "tmdate": 1700318048505,
                "mdate": 1700318048505,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "uEJt2M5oZm",
            "forum": "Xz13DtbOVW",
            "replyto": "Xz13DtbOVW",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1562/Reviewer_Haeo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1562/Reviewer_Haeo"
            ],
            "content": {
                "summary": {
                    "value": "This paper provides a new training protocol to manage pruning induced bias. The main aim is to create algorithms in which the difference in accuracy between any two groups is minimised. The authors highlight that their main focus is lessen the effects of compression and thus they treat dense models as baseline."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This is a useful research area. With concerns of AI inclusion and climate change, sparse models are very appealing. The authors provide a method to ameliorate some of the effects of compression by limiting the disparity between group performance.\nThis is a well written paper and the methodology is clear. Implementation and results are well described and the examples in the appendix provide further grounding on their work."
                },
                "weaknesses": {
                    "value": "It is not clear from the analysis provided that solutions always exist given the constraints. Perhaps the authors could more light on this. Is there a relationship between the starting point and how tight the constraints can be?"
                },
                "questions": {
                    "value": "Please see weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1562/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1562/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1562/Reviewer_Haeo"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1562/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699020655232,
            "cdate": 1699020655232,
            "tmdate": 1699636084408,
            "mdate": 1699636084408,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pB6cK0ZxMA",
                "forum": "Xz13DtbOVW",
                "replyto": "uEJt2M5oZm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for highlighting the effectiveness of our method and the usefulness of this research to the community. \n\n> It is not clear from the analysis provided that solutions always exist given the constraints. Perhaps the authors could more light on this.\n\nThe reviewer is correct. The constrained optimization problem in Eq(5) might be infeasible for certain values of the constraint level $\\epsilon$.\nNote that this potential infeasibility depends not only on $\\epsilon$ but also on the data distribution, the model capacity and the sparsity level.\n\nSetting $\\epsilon$ large enough would yield a problem with a non-empty feasible region. However, this may come at the cost of not enforcing the disparity constraints. (For example, asking for the excess accuracy gaps to be less than 2.)\n\nIn the non-convex constrained optimization regime, even if the feasible set is non-empty (and thus a locally optimal solution exists), there is no guarantee that gradient-based methods can converge to it starting from arbitrary initializations. \n\nWe would like to highlight that in practice, we have observed that our method reliably achieves feasible solutions across several datasets, model architectures, and sparsity levels. (The constraint levels were set by asking for lower disparity than observed in the baseline NFT method).  Of course, this practical behavior is not a guarantee on the feasibility of the problem, but it indicates there might be a special structure in the feasible set that makes it amenable to optimization with stochastic gradient-based schemes.\n\n\n---\n\n> Is there a relationship between the starting point and how tight the constraints can be?\n\nWe would like to ask the reviewer to rephrase their question since we are not sure we are interpreting it correctly. Our two current interpretations are:\n\n\n[Interp. 1] Is there relationship between the starting point ($\\theta_0$, $\\lambda_0$) and the lowest constraint level $\\epsilon$ that is achievable?\n\n[Interp. 2] Suppose we are given a fixed constraint level $\\epsilon$, and suppose one were to initialize the algorithm ($\\theta_0$, $\\lambda_0$) close enough to being feasible for the constraint level $\\epsilon$. Is there a relationship between initial closeness to being feasible vs whether the algorithm converges to a feasible point?"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700175459708,
                "cdate": 1700175459708,
                "tmdate": 1700175459708,
                "mdate": 1700175459708,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bAtqCcROjU",
                "forum": "Xz13DtbOVW",
                "replyto": "uEJt2M5oZm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "As the end of the discussion period is coming, we wanted to follow up on our clarification request regarding question:\n> Is there a relationship between the starting point and how tight the constraints can be?\n\nWe would also like to ask the reviewer whether there are additional concerns they would like to bring to our attention?"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700518720538,
                "cdate": 1700518720538,
                "tmdate": 1700518720538,
                "mdate": 1700518720538,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ctFdF2JRoe",
                "forum": "Xz13DtbOVW",
                "replyto": "pB6cK0ZxMA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1562/Reviewer_Haeo"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1562/Reviewer_Haeo"
                ],
                "content": {
                    "title": {
                        "value": "Is there a relationship between the starting point and how tight the constraints can be?"
                    },
                    "comment": {
                        "value": "Interpretation 1"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700576064806,
                "cdate": 1700576064806,
                "tmdate": 1700576064806,
                "mdate": 1700576064806,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "SBnrfujZCB",
            "forum": "Xz13DtbOVW",
            "replyto": "Xz13DtbOVW",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1562/Reviewer_cVd6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1562/Reviewer_cVd6"
            ],
            "content": {
                "summary": {
                    "value": "This paper deals with the problem of pruning models with desire of not decreasing performance on subsets via constraints."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The technique is solid and the experiments are sound."
                },
                "weaknesses": {
                    "value": "Can the paper deals with other pruning techniques to demonstrate the effectiveness of constraint to subsets?"
                },
                "questions": {
                    "value": "Can we give some formal results with Equation(6) like the analytical solution or convergenece guarantee?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1562/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1562/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1562/Reviewer_cVd6"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1562/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699685275548,
            "cdate": 1699685275548,
            "tmdate": 1699685275548,
            "mdate": 1699685275548,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FhxWmYcJSj",
                "forum": "Xz13DtbOVW",
                "replyto": "SBnrfujZCB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for highlighting the effectiveness of our techniques and the soundness of our experiments.\n\n> Can the paper deals with other pruning techniques to demonstrate the effectiveness of constraint to subsets?\n\nYes, during the rebuttal phase, we have carried out additional experiments under the _structured_ sparsity setting. At a high level, we observed similar trends as in the unstructured pruning setting: our method reliably mitigates the disparate impact of pruning in training, while preserving the overall performance of the model. We invite the reviewer to see our response to **Reviewer KSs2** containing the details and results for these experiments. \n\nThe additional results on structured sparsity demonstrate that our technique is agnostic and robust to the choice of pruning method. Therefore, we expect it to perform well under other commonly used sparsity techniques.\n\n----\n\n> Can we give some formal results with Equation(6) like the analytical solution or convergence guarantee?\n\nIn general, the min-max problem in Eq(6) does not have an analytical solution, as is the case for many optimization problems considered in the deep learning field. \n\nUnder idealized circumstances, it is possible to develop convergence guarantees of gradient-based optimization methods for min-max problems. We have already provided pointers to relevant literature on the related work section and Appendix A. \n\nUnfortunately, the existing literature focuses on proving local convergence of gradient-based methods. This analysis relies on the assumption of an initialization close enough to a solution to the min-max problem, which is unrealistic in our specific problem.\n\nDespite the lack of theoretical guarantees, our experimental results clearly demonstrate that we are able to reliably find feasible solutions (i.e. low disparate impact) that are approximately optimal (i.e. model performance close to the dense baseline).\n\nFor the reviewer's convenience, we list the mentioned references here:\n\n[A] Tianyi Lin, Chi Jin, and Michael Jordan. On Gradient Descent Ascent for Nonconvex-Concave Minimax Problems. In ICML, 2020.\n\n[B] Guodong Zhang, Yuanhao Wang, Laurent Lessard, and Roger B Grosse. Near-optimal Local Convergence of Alternating Gradient Descent-Ascent for Minimax Optimization. In AISTATS, 2022."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700175302783,
                "cdate": 1700175302783,
                "tmdate": 1700175302783,
                "mdate": 1700175302783,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "u5wRqQ01Ly",
                "forum": "Xz13DtbOVW",
                "replyto": "SBnrfujZCB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1562/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "As the end of the discussion period is coming, we wanted to know whether we have addressed all of the reviewer\u2019s concerns and whether there are additional changes that the reviewer would like us to bring to the paper?"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700518636137,
                "cdate": 1700518636137,
                "tmdate": 1700518636137,
                "mdate": 1700518636137,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]