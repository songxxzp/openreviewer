[
    {
        "title": "VDC: Versatile Data Cleanser for Detecting Dirty Samples via Visual-Linguistic Inconsistency"
    },
    {
        "review": {
            "id": "oa4JbDyZ22",
            "forum": "ygxTuVz9eU",
            "replyto": "ygxTuVz9eU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission248/Reviewer_vuG8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission248/Reviewer_vuG8"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a general \"label\" cleaning/filtering approach and aims to detect three types of errors: \"poisoned samples\", \"noisy samples\", and \"hybrid dirty samples\". The paper takes advantage of the exceptional capability of multimodal large language model (MLLM) and casts the error detection problem into a three-step scoring pipeline. The pipeline consists of 1) visual question generation, 2) visual question answering, and 3) visual answer evaluation. The main argument is that, unlike prior arts, the proposed approach can detect all three types of label errors and achieves better performance in common benchmarks, including ImageNet-100 and CIFAR-10."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed method leverages the recent trend of MLLM to the label error detection literature\n- The proposed method is training-free"
                },
                "weaknesses": {
                    "value": "- The empirical comparison is not fair.\n    - The propose approach is using instruct-BLIP (larger network trained on larger dataset), while the baseline is usually using less-expressive network trained on smaller datasets, e.g., CL is using ResNet-18 and trained on CIFAR dataset.\n- The claim that the proposed method mitigates all three types of label noises is too strong.\n    - The proposed approach is general, but so do other baselines. For example, SimiFeat-V leverages the feature similarity to detect noisy labels, which is also applicable to the scenario of \u201cpoisoned samples\u201d as long as the feature extractor is trained on a poison-free dataset."
                },
                "questions": {
                    "value": "1. The name of \u201cvisual question generation\u201d is confusing. From my understanding to the paper, there is no visual signal in this stage. Can the author confirm this?\n2. What are the accuracy of each question?\n    - Figure 2 shows the TRR of the general and label-specific questions. I am curious of what specific question is challenging for the instruct-BLIP. Is there any specific question that is always challenging to the instructBLIP and, therefore, removing those questions actually help the overall performance\n3. Given that the method leverages a ensemble of the MLLM responses, instead of taking the average accuracy as score as in Eq. 4, does the author think that using techniques like label aggregation further improves the overall performances?\n4. To make a fair comparison with other baselines, I suggest the authors could compare baselines with MLLM as well. For example, CL usually trains their classifier with leave-one-out or cross validation, which limits the size of the train dataset. However, one can also uses off-the-shelf classifier and apply CL on it.\n5. Do the authors consider the data-leakage problem? Does the train dataset used to train the instruct-BLIP accidentally include the images in ImageNet or CIFAR? If so, how do accurately validate the performances?\n6. Do the authors observe any accumulated error in the three-step pipeline? For example, the label-specific question include some noisy questions, which leads to poisoned answers in the second stage."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission248/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission248/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission248/Reviewer_vuG8"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission248/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698540134807,
            "cdate": 1698540134807,
            "tmdate": 1700533275892,
            "mdate": 1700533275892,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "62PCEgKtaB",
                "forum": "ygxTuVz9eU",
                "replyto": "oa4JbDyZ22",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer vuG8 (Part 1/3)"
                    },
                    "comment": {
                        "value": "Dear Reviewer vuG8,\n\nWe sincerely appreciate your precious time and constructive comments, and we are greatly encouraged by your high recognition of **the innovation of our approach, the unified treatment of noisy data and poisoned data, and extensive experiments**. \n\nIn the following, we would like to answer your concerns separately.\n\n---\n**Q1:** The empirical comparison is not fair. The propose approach is using instruct-BLIP (larger network trained on larger dataset), while the baseline is usually using less-expressive network trained on smaller datasets, e.g., CL is using ResNet-18 and trained on CIFAR dataset.\n\n**R1:** Thanks for your constructive feedback. We would like to clarify this concern from the following points:\n\n- **Determining the fairness of the comparison hinges on whether impediments are imposed on our method. We avoid employing resources inaccessible to others.** Currently, the barriers for utilizing large models have significantly diminished, granting universal access to the capabilities of large  models through APIs. We incorporated this innovative tool into the realm of this challenging task.\n- **We discover that the fundamental commonality of dirty samples lies in visual-linguistic inconsistency.** Grounded in this notion, we propose a pioneering framework adept at harnessing the full potential of visual and language understanding capabilities of large models. **Previous methods neglected this commonality,** required training on noisy datasets, and struggled to harness the potential of large models effectively. This represents a distinctive advantage of  our method. It is reasonable to compare the advantages of our method with previous methods.\n\n---\n\n**Q2:** The claim that the proposed method mitigates all three types of label noises is too strong.\nThe proposed approach is general, but so do other baselines. For example, SimiFeat-V leverages the feature similarity to detect noisy labels, which is also applicable to the scenario of \u201cpoisoned samples\u201d as long as the feature extractor is trained on a poison-free dataset.\n\n**R2:** Thanks for your constructive comment.  We would like to clarify from the following aspects:\n\n- **To the best of our knowledge, we are the first work that designed for detecting three types of dirty samples simultaneously  and empirically evaluated in the literature**. Previous methods were primarily designed for either noisy labels or poisoned samples, lacking consideration for the coexistence of hybrid dirty samples within the dataset. Moreover, **none of them capture the fundamental commonality of such dirty samples -- visual-linguistic inconsistency.**\n- **In our implementation, follow the original paper of SimiFeat, we indeed adopt the image encoder of CLIP as the feature extractor, which is a poison-free method.** Experimental results (see Table 5 in the manuscript) show that SimiFeat  still has a large performance gap of about 25% compared to our LPS, which mainly due to the representations of poisoned samples and benign samples are quite different.\n\n\n---\n\n**Q3:** The name of \u201cvisual question generation\u201d is confusing. From my understanding to the paper, there is no visual signal in this stage. Can the author confirm this?\n\n**R3:** Thanks for this  valuable suggestion. We name this module as \"Visual Question Generation\" because these questions are regarded as \"visual questions\" for the second  \"Visual Question Answering (VQA)\" module. We note that this name may confuse readers, so we will rename this module as \"Question Generation\" in the revised version.\n\n---"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700203531363,
                "cdate": 1700203531363,
                "tmdate": 1700481803136,
                "mdate": 1700481803136,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MGQr3ohefw",
                "forum": "ygxTuVz9eU",
                "replyto": "oa4JbDyZ22",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer vuG8 (Part 2/3)"
                    },
                    "comment": {
                        "value": "---\n\n**Q4:** Figure 2 shows the TPR of the general and label-specific questions. I am curious of what specific question is challenging for the instruct-BLIP. Is there any specific question that is always challenging to the instructBLIP and, therefore, removing those questions actually help the overall performance.\n\n**R4:** Thanks for this constructive comment. Follow your suggstion, we conduct additional experiment to analyze the importance of different questions.\n\n- **Experiment settings:** We choose 1 target label and 3 clean label from ImageNet-100. For target label, we calculate the the accuracy of each question (answer with false) from all poisoned samples. For other clean labels, we calculate the the accuracy of each question (answer with true) from benign samples from the corresponding labels. \n- **Analysis:** \n    - **We find that there are indeed some questions challenging for InstructBLIP for these labels.**  For example, the geographic questions requiring geography knowledge are relatively more challenge.\n    - **We have considered the existing of challenging questions and adopt vote-based ensemble to avoid negative effect.** We remove the last questions of target label, the TPR changes from 99.93% to 99.91%. We also remove the last question of wolf spider, and the FPR of this class changes from 1.8% to 1.4%. The results indicate that the existing of few challenging questions does not have a severe impact on performance.\n\n\n**Target Label: cock**\n| Question| Acc of poisoned sampels  |\n| - | - |\n| Is the object in the image belong to a type of cock?| 0.988  |\n| Does the image feature a cock?| 0.971  |\n| Does the bird in the image typically have a distinctive comb on its head?| 0.942  |\n|Is the object in the image commonly raised for cockfighting in some cultures?|0.91\n| Is the object in the image associated with the dawn and often known for crowing at sunrise?| 0.844  |\n| **Is the object in the image a domesticated fowl commonly found on farms?** | 0.82 |\n\n\n**Clean Label: tree frog**\n\n| Question| Acc of benign sampls  |\n| - | - |\n| Is there a type of frog shown in the image?| 0.95  |\n| Is the creature in the image a type of frog?| 0.95  |\n| Does the image feature a frog?| 0.95  |\n| Is the object in the image belong to amphibian?| 0.90  |\n| Is the creature in the image capable of croaking?| 0.90  |\n| **Is the animal of the image commonly found near the water?** | 0.645 |\n\n\n**Clean Label: centipede**\n\n| Question| Acc of benign sampls   |\n| - | ----- |\n| Is the creature in the image a type of arthropod?| 0.992 |\n| Is the creature in the image known for its many legs?| 0.95  |\n| Is the object in the image a type of centipede?| 0.972 |\n| Does the image feature a centipede?| 0.972 |\n| Is there a centipede in the image?| 0.90  |\n| **Is the object in the image typically found in damp environments?** | 0.792 |\n\n**Clean Label: king penguin**\n\n| Question| Acc of benign sampls   |\n| - | - |\n| Is the bird in the image known for its black and white plumage? | 0.95  |\n| Can the animal in the image survive in  cold temperatures?   | 0.935 |\n| Is there a penguin in the image?| 0.93  |\n| Does the image feature a penguin?| 0.93  |\n| Is the object in the image a type of penguin?| 0.93  |\n| **Is the animal in the image commonly found in Antarctica?** | 0.848 |\n\n---"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700203648487,
                "cdate": 1700203648487,
                "tmdate": 1700482142977,
                "mdate": 1700482142977,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Ir0W7VUgG6",
                "forum": "ygxTuVz9eU",
                "replyto": "oa4JbDyZ22",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer vuG8 (Part 3/3)"
                    },
                    "comment": {
                        "value": "---\n\n**Q5:** Given that the method leverages a ensemble of the MLLM responses, instead of taking the average accuracy as score as in Eq. 4, does the author think that using techniques like label aggregation further improves the overall performances?\n\n**R5:** Thanks for this insightful comment. \n\n- **Actually, in our paper, we adopt majority vote in the vote-based ensemble instead of taking the average accuracy** (see Eq(4) in the manuscript). We find that this baseline ensemble method is sufficient for our framework.\n- **Taking other label aggregations is an insightful suggestion.** In our further work, we will consider the importance of different questions and taking weight-based label aggragation to further improve the overall performance.\n\n---\n\n**Q6:** To make a fair comparison with other baselines, I suggest the authors could compare baselines with MLLM as well. For example, CL usually trains their classifier with leave-one-out or cross validation, which limits the size of the train dataset. However, one can also uses off-the-shelf classifier and apply CL on it.\n\n**R6:** Thanks for your constructive comments. Following your suggestion, we replace the backbone classifier of CL as pre-trained CLIP and the results on CIFAR-10 are shown in the following table. We can see that even though using off-the-shelf classifier, **our proposed method still outperforms CL+CLIP by a considerable gap**, mainly due to the inevitable error in the predicted probability of CLIP.\n\n||Symmetric (TPR %)| Symmetric (FPR %)|Asymmetric (TPR %)|Asymmetric (FPR %)|\n|-| -|-|-|-|\n| CL| 85.05| 8.75| 82.49| 4.50|\n| CL+CLIP|  89.38|  5.80| 89.89| 5.89|\n| **VDC (Ours)** | 98.81| 2.61| 99.60| 2.62|\n\n---\n\n**Q7:** Do the authors consider the data-leakage problem? Does the train dataset used to train the instruct-BLIP accidentally include the images in ImageNet or CIFAR? If so, how do accurately validate the performances?\n\n**R7:** Thank your this insightful comment.\n- **The training datasets used to train the InstructBLIP do not include ImageNet and CIFAR.** We check the publised paper of InstrcutBLIP (see Figure 2) and find that the collected datasets in InstructBLIP used for vision-language instruction tuning exclude ImageNet and CIFAR. \n- **A native validation method is directly using InstrcutBLIP to perform classification task on CIFAR-10.** The used prompt is '*What\u2019s the category of the image? Please choose one category from the following 10 labels [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]*'. The classification accuracy is only **69.36%**. **It turns out that directly applying large models is not sufficient to solve downstream tasks and requires additional non-trivial careful design. This further emphasizes the unique contribution of our work.**\n\n---\n\n**Q8:** Do the authors observe any accumulated error in the three-step pipeline? For example, the label-specific question include some noisy questions, which leads to poisoned answers in the second stage.\n\n**R8:** Thank you for this suggetion. We would like to clarify from the following aspects:\n- **We have considered this accumulated error in our proposed framework.** Actually, the voted-based ensemble in the visual answer evaluation module is designed for preventing this phenomenon. \n- **Our proposed method is robust for noisy questions.** To evaluate it, we artificially replace the last questions of all poisoned samples as wrong answers on CIFAR-10 with BadNets, and the TPR slightly changes from 99.93% to 99.56%, demonstrating that our proposed method is robust for noisy questions.\n\n---\n\nThanks again for your time and attention. We hope the response can address your concerns.\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700204955923,
                "cdate": 1700204955923,
                "tmdate": 1700484173813,
                "mdate": 1700484173813,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ryQvN2Q2Xu",
                "forum": "ygxTuVz9eU",
                "replyto": "Ir0W7VUgG6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission248/Reviewer_vuG8"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission248/Reviewer_vuG8"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Appreciate the authors' further clarification.\n\n1. **The use of foundation models**: I am not complaining the use of foundation models (instruct-BLIP). Instead, I want to point out that the improvements not only come from the approach, but also from the strong visual backbones. The authors should either make this point clear in the submission or adopt the same visual backbone for other baseline approaches.\n2. **Experiments on the question types**: The analysis is great and makes a lot of senses. \n3. **Experiments on CL+CLIP**: Appreciate for the additional efforts from the authors. The improvements are more convincing to me now.\n\nOverall, the authors did a great job clarifying my questions and the additional experiments are convincing that the proposed approach does improve in this setting. Please include these analysis in the paper. I am raising my score to 6."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700533340536,
                "cdate": 1700533340536,
                "tmdate": 1700533340536,
                "mdate": 1700533340536,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LpFKkIcfAp",
            "forum": "ygxTuVz9eU",
            "replyto": "ygxTuVz9eU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission248/Reviewer_481L"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission248/Reviewer_481L"
            ],
            "content": {
                "summary": {
                    "value": "To address common noise data and backdoor attack problems in deep learning, the paper designed a data cleaning tool called VDC using a multimodal large language model. By designing generalized visual question answering questions and label-specific visual question answering questions, VDC can remove dirty and poisoned data from the dataset based on the inconsistency between the semantic of the obtained question results and the semantic of the image itself. The paper compared VDC with backdoor attack methods and noisy learning methods, demonstrating the effectiveness of VDC."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ The paper's approach is innovative, using popular multimodal large models to replace manual data cleaning work.\n+ The paper unified the treatment of noisy data and poisoned data from backdoor attacks, which is relatively rare in previous research.\n+ The paper's extensive experiments demonstrate the effectiveness of VDC in handling dirty data."
                },
                "weaknesses": {
                    "value": "+ The overall content of the paper seems to be more about using out-of-distribution methods to filter data, and perhaps this should be reflected in the accuracy of sample selection.\n+ While the paper effectively addresses the issue of dirty data using MLLM, it seems to have a bias towards reporting the application of MLLM."
                },
                "questions": {
                    "value": "+ How is the threshold for excluding dirty data determined in the paper?\n+ Has the author considered the scenario where MLLM itself serves as a detector rather than a data cleaner?\n+ The paper's method relies heavily on MLLM, which in essence depends on more data and better labeling. Therefore, it may not be necessary to test models that use more clean data on small datasets, as this may go against the goal of advancing deep learning."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission248/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698767240325,
            "cdate": 1698767240325,
            "tmdate": 1699635950212,
            "mdate": 1699635950212,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SiErKsYKR6",
                "forum": "ygxTuVz9eU",
                "replyto": "LpFKkIcfAp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 481L (Part 1/2)"
                    },
                    "comment": {
                        "value": "Dear Reviewer 481L,\n\nWe sincerely appreciate your precious time and constructive comments, and we are greatly encouraged by your high recognition of the innovation of our approach, the unified treatment of noisy data and poisoned data, and extensive experiments. \n\nIn the following, we would like to answer your concerns separately.\n\n---\n\n**Q1:** The overall content of the paper seems to be more about using out-of-distribution methods to filter data, and perhaps this should be reflected in the accuracy of sample selection.\n\n**R1:** Thank you for your constructive comments. Although the multimodal large language model (MLLM) may be out of distribution compared to the noisy dataset at hand, **its remarkable generalization capabilities make it superior to most previous methods in the task of detecting dirty samples**, as demonstrated by the experimental results in the manuscript, **showcasing the effectiveness of our approach.**\n\n---\n\n**Q2:** While the paper effectively addresses the issue of dirty data using MLLM, it seems to have a bias towards reporting the application of MLLM.\n\n**R2:** Thanks for this insightful comment. We would like to explain from the following aspects.\n\n- **This task is crucial and challenging in real-life scenarios.** As Reviewer N7YG pointed out, \"Noisy or dirty data detection and cleaning is an **important** research topic. It is becoming even more **critical** for recent machine learning research.\". Furthermore, the presence of hybrid dirty samples in real-world scenarios poses practical and challenging aspects that surpass the capabilities of established methods. Our paper is dedicated to addressing this challenging task rather than merely extending the application of large models.\n- **We present a new perspective for detecting dirty samples in this field.** We find a notable commonality of noisy labels and poisoned samples lies in visual-linguistic inconsistency, which was overlooked by previous methods. **This revelation can inspire more researchers to continue exploring follow this direction, marking the most significant contribution of our paper to this field.**\n- **Based on the commonality that we discovered, we propose a novel  framework for addressing the task.** We build a bridge between the visual and language foundation models and this task. We observe that the multimodal large language models have excellent visual and language understanding capabilities, which are suitable for the visual-linguistic inconsistency that we discovered. Hence, we propose a novel framework to fully mine this specific potential of large models.\n- **The proposed framework is simple, user-friendly, training-free and effective, and not just the  application of large models.** Based on the commonality of dirty samples and the characteristics of large models, we novelly designe this framework to fully utilize the abilities of large models to solve this task.\n\n\nConsequently, the primary contribution of our work lies not in the mere application of large model but in the proposal of visual-linguistic inconsistency as a key factor and the strategic incorporation of large models to address this task.\n\n---"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700200689555,
                "cdate": 1700200689555,
                "tmdate": 1700481175642,
                "mdate": 1700481175642,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "X7aoaRaRe1",
                "forum": "ygxTuVz9eU",
                "replyto": "LpFKkIcfAp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 481L (Part 2/2)"
                    },
                    "comment": {
                        "value": "---\n\n**Q3:** How is the threshold for excluding dirty data determined in the paper?\n\n**R3:** Thank you for this question. As detailed in Section 5.1 of the manuscript, the threshold $\\alpha$ is set as 0.5 across all experiments.\n\n---\n\n**Q4:** Has the author considered the scenario where MLLM itself serves as a detector rather than a data cleaner?\n\n**R4:** Thank you for your insightful comment.  I find some ambiguity in the term \"detector\" as used in your response. Our proposed VDC serves the purpose of identifying dirty samples without necessitating the training of a classifier on the primary dataset. **Consequently, the VDC functions as a zero-shot detector.**\n\n---\n\n**Q5:** The paper's method relies heavily on MLLM, which in essence depends on more data and better labeling. Therefore, it may not be necessary to test models that use more clean data on small datasets, as this may go against the goal of advancing deep learning.\n\n**R5:** Thanks for your constructive comment. We would like to explain from the following aspects:\n\n- **This paper focuses on solving this challenging task in the real world.** Recognizing the inherent commonalities present in dirty samples serves as the foundation of our approach. Based on this valuable revelation, we then propose a novel framework that leverages large-scale models as an effective tool to solve this task.\n- **Integrating large models to solve domain-specific downstream tasks is expected to become a mainstream trend.** Significantly, advancements in large model technology have facilitated widespread access to their capabilities for ordinary users at relatively economical costs. Our exploration extensively delves into the potential of large models in addressing visual-linguistic inconsistency, thereby fostering progress in the realms of backdoor learning and robust learning.\n\n---\n\nThanks again for your constructive comments and your recognition of our efforts. We hope the response can address your concerns.\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700481210813,
                "cdate": 1700481210813,
                "tmdate": 1700481210813,
                "mdate": 1700481210813,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "euNeRNfwrx",
                "forum": "ygxTuVz9eU",
                "replyto": "LpFKkIcfAp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Appreciation for Review and Request for Feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer 481L,\n\nWe want to convey our sincere appreciation for the valuable insights and suggestions you provided regarding our work.\n\nWe have made efforts to address the concerns and queries you raised during the rebuttal process. It would be immensely helpful to receive feedback on whether our response effectively alleviated any doubts you may have had. Your feedback is crucial to enhancing the quality of our work.\n\nRecognizing the demands of your busy schedule, we genuinely appreciate your contribution to the refinement of our manuscript. As the end of the rebuttal period is approaching, we eagerly await your reply before the end.\n\nOnce again, thank you for your time and consideration.\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700581928735,
                "cdate": 1700581928735,
                "tmdate": 1700581928735,
                "mdate": 1700581928735,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FZ4r0CywnM",
                "forum": "ygxTuVz9eU",
                "replyto": "LpFKkIcfAp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A Kind Reminder of the Final Feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer 481L,\n\nThanks for your assessment and your encouragement of our work. As the deadline for reviewer-author discussion is approaching, we would be happy to take this opportunity to make more discussions about any of our questions or concerns. If our response has addressed your concerns, we would be grateful if you could re-evaluate our paper based on our feedback.\n\nSincerely,\n\nAuthors"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700672897040,
                "cdate": 1700672897040,
                "tmdate": 1700672897040,
                "mdate": 1700672897040,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "VV87JWnLKE",
            "forum": "ygxTuVz9eU",
            "replyto": "ygxTuVz9eU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission248/Reviewer_N7YG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission248/Reviewer_N7YG"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a working pipeline for noisy data detection. Compared with existing works focusing on noisy data or noisy label, this work aims to obtain an integrated framework to handle a comprehensive scenario including various noisy cases. Specifically, it terms it as visual-language inconsistency. Leveraging on several prompt techniques, the proposed framework achieves promising results compared with other baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Noisy or dirty data detection and cleaning is an important research topic. It is becoming even more critical for recent machine learning research since the data scale is always getting larger.\n2. The proposed framework wisely utilize the advantage of current large-scale model to benefit the dirty data detection task.\n3. Comprehensive empirical results show the framework superiority compared with other baselines.\n4. The whole draft is in a good format for readers."
                },
                "weaknesses": {
                    "value": "1. I mainly concern about the technical contribution in this draft. The wise combination of prompting and dirty data detection is interesting. However, it still based on the visual-language understanding from large-scale pretrained model. Only based on such powerful tools relatively diminish this paper novelty. In addition, the key point of this paper is proposing an integrated detection pipeline instead of only focusing on sample or label. This point looks like a trivial combination which is incremental compared with previous settings. Is this setting practical and necessary for real-world scenarios?\n2. Adding more recent published works for comparison may further help to support the paper contribution. Currently, only one or two baselines are published within past one year."
                },
                "questions": {
                    "value": "Please refer to the strengths and weakness for details. Even if I am concerning some points in weakness, I recognize other aspects of this paper mentioned in strengths. Overall, I lean to vote for an acceptance for now and I would like to check other reviewers' comments to discuss and make my final decision."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission248/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698767372031,
            "cdate": 1698767372031,
            "tmdate": 1699635950131,
            "mdate": 1699635950131,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6ut44aEDJ0",
                "forum": "ygxTuVz9eU",
                "replyto": "VV87JWnLKE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer N7YG (Part 1/2)"
                    },
                    "comment": {
                        "value": "Dear Reviewer N7YG,\n\nWe sincerely appreciate your precious time and constructive comments, and we are greatly encouraged by your high recognition of the following aspects:\n- The **significance** of noisy or dirty data detection and cleaning.\n- The **optimal utilization** of large-scale models.\n- The empirical **superiority** over baselines.\n- The **reader-friendly** format of the draft.\n\nIn the following, we would like to answer your concerns separately.\n\n---\n\n**Q1:** I mainly concern about the technical contribution in this draft. The wise combination of prompting and dirty data detection is **interesting**. However, it still based on the visual-linguistic understanding from large-scale pretrained model. Only based on such powerful tools relatively diminish this paper novelty. In addition, the key point of this paper is proposing an integrated detection pipeline instead of only focusing on sample or label. This point looks like a **trivial** combination which is incremental compared with previous settings. Is this setting practical and necessary for real-world scenarios?\n\n**R1:** Thank you for this constructive comment. We would like to share our thoughts from the following aspects:\n- **Dirty samples is a practical threat in the real-world scenarios.** For poisoned samples, malicious attackers intentionally manipulate partical clean samples to inject backdoor by embedding triggers and changing the ground-truth labels. For noisy labels, human annotators or automatic annotation robots may make mistakes accidentally in the crowdsourcing or web crawling. Therefore, **detecting dirty samples is imperative for real-world scenario.**\n- **We present a new perspective for detecting dirty samples in this field.** We find a notable commonality of noisy labels and poisoned samples lies in visual-linguistic inconsistency, which was overlooked by previous methods. This revelation can inspire more researchers to continue exploring follow this direction, marking the most significant contribution of our paper to this field.\n- **Based on the commonality that we discovered, we propose an easy, user-friendly, training-free and effective framework for addressing the task.**  We build a bridge between the visual and language foundation models and this task.  We observe that the multimodal large language models have excellent visual and language understanding capabilities, which are suitable for the visual-linguistic inconsistency that we discovered. Hence, we propose a novel framework to fully mine this specific potential of large models.\n- **The framework that leverages large-scale models is practical in the real-world scenarios:** Recently, with the increasing availability of LLM and MLLM accessible via APIs, VDC can leverage the power of these large models to accomplish the task at relatively low cost (e.g., GPT-4) for ordinary users. Therefore, our method is training-free and does not require training on the entire noisy dataset like previous methods, eliminating the need for extensive computing resources, making our method very practical for ordinary users in the real-world scenarios.\n\nIn summary, while our technical contribution may not be deemed revolutionary, we have introduced a novel perspective and innovative tools to effectively address the task at hand. This substantial contribution merits due consideration and should not be overlooked.\n\n---"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700193227444,
                "cdate": 1700193227444,
                "tmdate": 1700481234043,
                "mdate": 1700481234043,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EzmVCSycSF",
                "forum": "ygxTuVz9eU",
                "replyto": "VV87JWnLKE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer N7YG (Part 2/2)"
                    },
                    "comment": {
                        "value": "--- \n\n**Q2:** Adding more recent published works for comparison may further help to support the paper contribution. Currently, only one or two baselines are published within past one year.\n\n**R2:** Thanks for this constructive comment. Following your suggestion, We have found  two  other papers published at CVPR 2023 and ICML 2023 for comparison [1, 2]. \n\n- **Introduction of baselines:** FREAK[1] is a frequency-based poisoned sample detection algorithm. LogitClip[2] enhances the noise robustness of existing losses by clamping the norm of the logit vector, which can be combined with CORES to filter noise labels and then improve the accuracy of the trained model, as compared in the draft. \n- **Experimental setting:** For FREAK, we add evaluation on poisoned sample detection on CIFAR-10 with BadNets and Blended attacks, where poisoning ratio $\\eta$ is set as 0.09. For LogitClip, we combine it with Cores and evalute on noisy label detection on CIFAR-10. The results are shown in **Table 1 and 2** as follows respectively. \n- **Analysis:**  The results show that VDC outperforms other methods. We can obtain the same conclusion as in the draft: **VDC consistently exhibits superior performance to baselines.**\n\n\nTable 1: TPR and FPR results of poisoned sample detecion on CIFAR-10.\n|| BadNets (TPR %) | BadNets (FPR %) | Blended (TPR %) | Blended (FPR %) |\n| - | - | - | - | - |\n| FREAK [1]| 95.70| 2.98| 10.23| 3.46|\n| **VDC (Ours)** | 99.93| 2.75|99.87|2.75|\n\nTable 2: Testing accuracy after filtering noisy label on CIFAR-10.\n|| Symmetric Noise (ACC %) | Asymmetric Noise (ACC %) |\n| - | - | - |\n| Cores| 84.68| 84.70|\n| Cores + LogitClip [2] | 85.84| 86.28|\n| **VDC (Ours)**| 90.75| 90.89|\n\n\nThanks again for your constructive comments and your recognition of our efforts. I hope this response can address your concerns.\n\nBest regards,\n\nAuthors\n\n--- \n\n**Refenence**\n\n[1] Don\u2019t FREAK Out: A Frequency-Inspired Approach to Detecting Backdoor Poisoned Samples in DNNs, In CVPR 2023\n\n\n[2] Mitigating Memorization of Noisy Labels by Clipping the Model Prediction, In ICML 2023"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700479070981,
                "cdate": 1700479070981,
                "tmdate": 1700481224039,
                "mdate": 1700481224039,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6b8nf3xqaX",
                "forum": "ygxTuVz9eU",
                "replyto": "VV87JWnLKE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Appreciation for Review and Request for Feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer N7YG,\n\nWe want to convey our sincere appreciation for the valuable insights and suggestions you provided regarding our work.\n\nWe have made efforts to address the concerns and queries you raised during the rebuttal process. It would be immensely helpful to receive feedback on whether our response effectively alleviated any doubts you may have had. Your feedback is crucial to enhancing the quality of our work.\n\nRecognizing the demands of your busy schedule, we genuinely appreciate your contribution to the refinement of our manuscript. As the end of the rebuttal period is approaching, we eagerly await your reply before the end.\n\nOnce again, thank you for your time and consideration.\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700581898812,
                "cdate": 1700581898812,
                "tmdate": 1700581898812,
                "mdate": 1700581898812,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NNqahQnHYq",
                "forum": "ygxTuVz9eU",
                "replyto": "VV87JWnLKE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A Kind Reminder of the Final Feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer N7YG,\n\nThanks for your assessment and your encouragement of our work. As the deadline for reviewer-author discussion approaches, we would be happy to take this opportunity to make more discussions about any of our questions or concerns. If our response has addressed your concerns, we would be grateful if you could re-evaluate our paper based on our feedback.\n\nSincerely,\n\nAuthors"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700672825862,
                "cdate": 1700672825862,
                "tmdate": 1700672825862,
                "mdate": 1700672825862,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]