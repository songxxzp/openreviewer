[
    {
        "title": "CI-VAE: a Generative Deep Learning Model for Class-Specific Data Interpolation"
    },
    {
        "review": {
            "id": "qK3PzOXPv5",
            "forum": "yldBrD4nYB",
            "replyto": "yldBrD4nYB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4324/Reviewer_Jd7b"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4324/Reviewer_Jd7b"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a method to enfore linear separability of classes in the latent space of VAEs. It is investigated on the MNIST dataset and compared to a standard VAE."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- The paper is well written and clear and the problem of enabling interpolation and ensuring linear separability of classes in the latent space of VAEs relevant and likely useful.\n\n- The proposed method, at least on the tested dataset, appears to solve the problem of linear separability reasonably well."
                },
                "weaknesses": {
                    "value": "- The method is just investigated on a single and very simple dataset (MNIST) and not compared to other baselines that try to solve the problem at hand.\n\n- While the manuscript references a large number of related works, it does not seem to consider them in much detail. In particular works on the building of generative models where particular considerations are made towards class representations, I would have expected to have been covered in more detail. Such as for instance conditional variational autoencoders or works that focus on learning disentangled representations. There are too many references to cover in detail, but examples include [1, 2].\n\n- \"The weights in the model are trained for over 2000 epochs with a batch size of 512 images until convergence is reached (see Figure 3).\" - how is this determined?\n\n- While figure 6 is interesting, a quantitative assessment of this problem as well as its solution through the proposed CI-VAE would have been stronger.\n\n- The results on colon cancer mentioned in the abstract and introduction is only included in the Appendix.\n\n- References to Figure 1a-c appear to be wrong?\n\n[1] Kingma, Durk P., et al. \"Semi-supervised learning with deep generative models.\" Advances in neural information processing systems 27 (2014).\n\n[2] Paige, Brooks, et al. \"Learning disentangled representations with semi-supervised deep generative models.\" Advances in neural information processing systems 30 (2017)."
                },
                "questions": {
                    "value": "- What is meant by \"female hand-written digits\"?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4324/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698787547927,
            "cdate": 1698787547927,
            "tmdate": 1699636401229,
            "mdate": 1699636401229,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "oPCpQby226",
            "forum": "yldBrD4nYB",
            "replyto": "yldBrD4nYB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4324/Reviewer_UN5b"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4324/Reviewer_UN5b"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes a Class-Informed Variational AutoEncoder (CI-VAE) to interpolate between arbitrary pairs of observations from the same class. The CI-VAE adds a linear discriminator layer to a regular VAE. It can perform class-specific linear traversal and generate synthetic data more robustly compared to a vanilla VAE."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. The manuscript is clearly written. \n\n2. Compared to the vanilla VAE, the CI-VAE outputs latent clusters that are more linearly separable, with a higher linear classification accuracy and a lower reconstruction error. Generated examples also look better qualitatively."
                },
                "weaknesses": {
                    "value": "1. There is no quantitative metric to evaluate between-class interpolation trajectories. How can the linearly interpolated results be validated?\n\n2. The baseline comparison is not sufficient. How does the CI-VAE compare to the other semi-supervised VAE variants?\n\n3. Figures 5 and 6 qualitatively compared 3 examples from VAE and CI-VAE. However, I wonder if quantitative metrics can be applied to compare all samples from VAE and CI-VAE. \n\n4. In Figure 7, it seems that the generated digit 3s are mixed with the digits 5 and 8, so I am not sure if it's practically useful for data generation. \n\n5. I suggest adding key take-aways in the figure captions. It is hard to tell what message that the authors try to convey in some figures such as Figure 5. \n\n6. Minor: \n\n\ti. In Section 2, the authors mentioned Figure 1a/1c, but there is no subfigure in Figure 1. \n\n\tii. In Equations (2) and (3), the operation KL should be explained (Kullback\u2013Leibler divergence). \n\n\tiii. In Equation (2), putting an arrow above a number is usually used to represent a vector. In multivariate Gaussian, the covariance is a matrix instead of a vector, and thus a bold capital letter $\\mathbf{I}$ should be used. The math notations throughout this manuscript don't follow the standard notations, and I suggest the authors to follow the notations in the original VAE paper. \n\n\tiv. In Figure 3, the authors should add x axis label (epoch) and y axis label (loss). In text, the authors mentioned that the models were trained for 2000 epochs, but only 700 or 800 epochs are shown in Figure 3. Was there an early stopping criterion? \n\n\tv. In Section 3 first paragraph, $28 \\times 28 = 784$, instead of $526$."
                },
                "questions": {
                    "value": "1. Code availability: Will the code be made publicly available? \n\n2. Model architecture: Which distance metric was used to measure the reconstruction error? How were hyperparameters ($\\alpha$, $\\beta$) chosen? How was the number of latent dimensions chosen? Just to make sure, the linear discriminator layer only includes weights, but not biases? What was the dropout rate? These details should be mentioned clearly for reproducibility. \n\n3. Were labels balanced in the training, validation, and test sets? \n\n4. What specific cancer development mechanism can we learn from the interpolation result on colon single-cell genomics data?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4324/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4324/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4324/Reviewer_UN5b"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4324/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698808046778,
            "cdate": 1698808046778,
            "tmdate": 1699636401094,
            "mdate": 1699636401094,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]