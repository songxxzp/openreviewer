[
    {
        "title": "NP-GL: Extending Power of Nature from Binary Problems to Real-World Graph Learning"
    },
    {
        "review": {
            "id": "zp22oxj2lx",
            "forum": "qT7DXUmX7j",
            "replyto": "qT7DXUmX7j",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8845/Reviewer_qast"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8845/Reviewer_qast"
            ],
            "content": {
                "summary": {
                    "value": "This paper tackles the issue of the binary nature of existing Ising graph learning by proposing a new Hamiltonian for real-value graph learning problems."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The paper is well-written and easy to follow, more like a report.\n* Solve an important problem in current Ising graph learning using nature-law-based machines, i.e., only supporting binary values.\n*  Efficient training methods with three optimizations that ensure training speed and quality.\n* Achieves the best accuracy compared to three baselines"
                },
                "weaknesses": {
                    "value": "* Over-exaggerated descriptions in the main context. The paper seems to overclaim some parts, like mentioning, \u201cRegrettably, despite their perceived potential, most\nnature-powered ML methods are still predominantly theoretical, outperforming NNs only in toy problems under highly idealized conditions\u201d while the Ising machine is also not quite partial and only applicable for some problems.\n* Out-dated baselines. In comparison, the authors chose three \u201cSOTA\u201d spatial-temporal GNNs, while the earliest was published in 2020. The author should compare with more recent advances."
                },
                "questions": {
                    "value": "*  Could the authors provide more comparison with recent SOTA GNN spatial-temporal GNNs? I found one recent paper,\n    * Jiang, Renhe, et al. \"Spatio-temporal meta-graph learning for traffic forecasting.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 37. No. 7. 2023.\n* What\u2019s the physical meaning of asymmetric weight decomposition? As it is a natural process (Hamitonian), is this symmetric weight decomposition meaningful for the physical system besides the efficiency consideration?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8845/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8845/Reviewer_qast",
                        "ICLR.cc/2024/Conference/Submission8845/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8845/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698730577856,
            "cdate": 1698730577856,
            "tmdate": 1700674009559,
            "mdate": 1700674009559,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Y55fG7fso2",
                "forum": "qT7DXUmX7j",
                "replyto": "zp22oxj2lx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8845/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8845/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank the reviewer for their valuable comments and questions. We also provide a \"general comment\" for all reviewers at the top as a global rebuttal other than the specific answers below.\n\n**Comment 1**. Over-exaggerated descriptions.\\\n**Response:**\n\nWe sincerely thank the reviewer for this comment. We have revised the sentence pointed out by the reviewer and will comprehensively revise the paper and adjust the tone. Again, we thank the reviewer for pointing out this.\n\n**Comment 2 & Question 1**. More recent baseline.\\\n**Response:**\n\nThe reviewer's suggestion is very much appreciated. We have added 2 more recent work, including the work the reviewer suggests in our revision. See table 2. To enrich the evaluation, we also added more latency results and accuracy results of NP-GL equipped with different loss functions for better comparison. The corresponding modifications are highlighted with label \"Reviewer-qast\"\n\n**Question 2**. Physical meaning of symmetric weight decomposition.\\\n**Response:**\n\nThe symmetric weight decomposition acts as a natural constraint such that the spin correlation matrix (the \"J'\" matrix in context) becomes symmetric. In analogy to Newton's 3rd Law, the forces applied to the objects in a pair are the same in magnitude. In the real-world, most of dynamic systems have pair-wise connection among nodes. Such symmetry is very common in physics, including Ising model. To explain in the language of math, after taking the first derivative of the Hamiltonian, the symmetric term (J+J transpose) appears, indicating the symmetric nature of the correlation matrix."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8845/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700375518365,
                "cdate": 1700375518365,
                "tmdate": 1700375518365,
                "mdate": 1700375518365,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "s9ujeWADXQ",
                "forum": "qT7DXUmX7j",
                "replyto": "Y55fG7fso2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8845/Reviewer_qast"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8845/Reviewer_qast"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response. A new series of main results, which can beat the recent baselines, are listed in the rebuttal phase. I will raise my point, but please revise your description carefully and adjust the tone."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8845/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700673992231,
                "cdate": 1700673992231,
                "tmdate": 1700673992231,
                "mdate": 1700673992231,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Dvu9cY0g7R",
                "forum": "qT7DXUmX7j",
                "replyto": "zp22oxj2lx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8845/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8845/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you again for the constructive suggestion! We have revised the description and lowered the tone in the newly uploaded revision for your review (shaded in orange). Your time is very appreciated, and any further comments are very much welcomed. Also, we thank you in advance for your continued efforts in the rest of the review process. If you are celebrating it, we wish you a wonderful Thanksgiving!"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8845/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700690307224,
                "cdate": 1700690307224,
                "tmdate": 1700691429803,
                "mdate": 1700691429803,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "fzKDHMqC7L",
            "forum": "qT7DXUmX7j",
            "replyto": "qT7DXUmX7j",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8845/Reviewer_w2U6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8845/Reviewer_w2U6"
            ],
            "content": {
                "summary": {
                    "value": "**Objective:** The paper aims to extend the capabilities of nature-powered computations from binary problems to real-valued graph learning problems. The authors propose a novel end-to-end Nature-Powered Graph Learning (NP-GL) framework, which leverages the natural power of entropy increase to efficiently solve real-valued graph learning problems.\n\n**Methodology:** The NP-GL framework is designed through a three-dimensional co-design, incorporating a new Hamiltonian that is hardware-friendly, maintains distinct stable states with real values, and ensures high expressivity. The training algorithms of NP-GL adopt an improved conditional likelihood method with optimizations for complexity reduction, convergence expediation, and better learning from temporal information. Additionally, a new nature-based computer is developed to support the NP-GL Hamiltonian, enabling the solution of real-valued graph learning problems.\n\n**Results:** Experimental results across four real-world applications and six datasets demonstrate that NP-GL delivers, on average, a 6.97 \u00d7 10^3 speedup and 10^5\u00d7 energy consumption reduction, with comparable or even higher accuracy than Graph Neural Networks (GNNs).\n\nThe contribution lies in\n\n**Extending Nature-Powered ML to Real-Valued Problems:** The paper introduces NP-GL, an end-to-end nature-powered graph learning method that breaks the binary limitation of existing nature-powered ML methods, extending their applicability to real-valued problems.\n\n**New Hardware-Friendly Hamiltonian:** A new Hamiltonian is designed for real-valued support, coupled with an efficient training method that ensures high training speed and quality.\n\n**Development of a New Nature-Based Computer:** A new nature-based computer is developed for the NP-GL Hamiltonian, using the Ising machine as a backbone, enabling the solution of real-valued graph learning problems using nature\u2019s power.\n\n**Significant Speedup and Energy Savings:** NP-GL demonstrates a substantial speedup (6.97 \u00d7 10^3) and energy savings (10^5\u00d7) compared to GNNs, with even higher accuracy across various real-world applications and datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Originality:\n- Innovative Approach: The paper introduces a novel end-to-end Nature-Powered Graph Learning (NP-GL) framework, extending the capabilities of nature-powered computations from binary problems to real-valued graph learning problems. This is a significant departure from existing nature-powered ML methods, showcasing a high level of originality.\n- Unique Integration: The three-dimensional co-design integrating a new Hamiltonian, training algorithms, and a nature-based computer is a unique approach that has not been explored extensively in previous works.\n2. Quality:\n- Robust Methodology: The paper employs a robust methodology, incorporating a hardware-friendly Hamiltonian, efficient training methods with optimizations, and the development of a new nature-based computer.\n- Comprehensive Evaluation: The experimental results across four real-world applications and six datasets provide a comprehensive evaluation of the NP-GL framework, demonstrating its effectiveness in delivering significant speedup, energy savings, and high accuracy compared to GNNs.\n3. Clarity:\n- Well-Structured: The paper is well-structured, with a clear introduction, background, methodology, results, and conclusion sections. This structure aids in the reader\u2019s understanding of the content.\n- Detailed Explanations: The authors provide detailed explanations of the NP-GL framework, the new Hamiltonian, the training algorithms, and the nature-based computer, ensuring that readers can grasp the complexities of the work.\n4. Significance:\n- Addressing Real-World Problems: By extending the applicability of nature-powered ML methods to real-valued problems, the paper addresses a significant gap in the field, making it highly relevant to real-world applications.\n- Potential for Impact: The demonstrated speedup, energy savings, and accuracy improvements have the potential to make a substantial impact in the field of graph learning, showcasing the significance of the work."
                },
                "weaknesses": {
                    "value": "- Insufficient Discussion on Challenges: While the paper provides a comprehensive overview of the NP-GL framework and its benefits, there could be a more in-depth discussion on the potential challenges and limitations of the proposed approach. Providing such insights would offer a balanced view and help guide future research. \n\nMinor: Add one-liner for the future insights summary to main text from Appendix."
                },
                "questions": {
                    "value": "- Could you elaborate on the adaptation for NP-GL on top of SOTA Ising machine? The hardware implementation, challenges, and potential optimizations could provide valuable insights for readers interested in the practical aspects of the work.\n- To confirm I assume the the engergy and latency are based on the simulation in CAD software?\n- Would this machine be able to generalize beyond GNN?\n\n- How it performs as the size of the graph increases and any potential strategies for handling large-scale graph learning problems?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8845/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698822943168,
            "cdate": 1698822943168,
            "tmdate": 1699637112519,
            "mdate": 1699637112519,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4iI43cLoE5",
                "forum": "qT7DXUmX7j",
                "replyto": "fzKDHMqC7L",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8845/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8845/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank the reviewer for their insightful questions. Apart from the specific answers to the questions listed below, we also include a \"general comment\" attached at the top as a global rebuttal.\n\n**Comment 1 & Question 1**. Limitations and more insights of implementation, challenges, and potential optimizations.\\\n**Response:**\n\n1. **Area:** Although it is much smaller than many other types of nature-based computer, e.g. oscillator-based Ising machines, the major limitation of the proposed method is still the area of machine. The chip is around 5mm^2, much smaller than GPUs and CPUs. However, as a chip with less than 1W power, the area is large. The reason is that the chip is predominantly based on analog circuits that are naturally larger than digital chips with the same power. If the chip works alone, the area is not an issue. However, if the proposed chip is to be integrated with other computers, the area problem is not negligible. For example, integrating the proposed nature-based hardware within GPUs (like tensorcores as a co-processor of CUDA cores) will equip GPUs with huge extra computational capability, but the chip area can be too big to fit in for now.\n\n2. **Formulation:** Currently, due to the complexity of the coupling network, the NP-GL hardware is only capable of representing linear and quadratic terms within the Hamiltonian function. Considering the practicality in chip manufacturing, the quadratic limitation is untapped now. This may be a limitation on accuracy, although quadratic terms perform well with most of the applications we investigated (probably due to dynamic systems in the real-world being mostly pairwise). We are studying how to realistically add complexity to the current Hamiltonian.\n\nWe have added this discussion of weakness in the Appendix of the paper due to page limit. See highlight labeled as \"Reviwer-w2U6\" in the \"Conclusion and Future Insights\" section and Appendix A.5.\n\n**Question 2**. Are the energy and latency based on CAD software?\\\n**Response:**\n\nYes. We will try to provide results based on the actual chip (being taped out) in the final version.\n\n**Question 3**. Would this machine be able to generalize beyond GNN?\\\n**Response:**\n\nYes. Here we list a few examples to demonstrate the deeper influences of our framework. Actually, NP-GL can generate unknown data based on a small amount of observed data. It reads training samples to understand the data distribution of a certain problem and generates data based on probabilities of the distribution. For graph prediction as an example, the observed data are historical time frames, and the unknown data are to be predicted. As NP-GL can impute unknown data as described, it can reasonably do more. Followed are some examples that we have largely validated, though not the focus of the paper.\n\n1. **Data compression.** This framework can complete data based on the partial data stored in memory. This will save bandwidth and storage space, leading to higher performance. For example, this framework can impute a gradient map of deep learning training with 20% known gradient data points rather accurately. Therefore, with this framework, the storage and bandwidth requirement of deep learning training will be reduced by 5x.\n\n2. **3D synthesis.** We already have some preliminary results showing this framework can be used for 3D synthesis and, although so far with lower quality than NeRF, construct pictures with micro-second latency. This is especially useful in AR/VR development, as real-time rendering is highly demanded. Here, the polar and azimuthal angles and some seed pixels are used as the observed data, with the remaining unknown pixels to be completed based on the observed data.\n\nEven within the scope of GNN, this framework can be used to improve GNN. For example, given a graph, we can use GNN to perform inference for only 10% nodes, while letting NP-GL complete the remaining 90% nodes based on the prior 10% results. In addition to speedup and reduction in storage and communication, if the 10% nodes are carefully chosen, e.g., the nodes of the highest accuracy in GNN, the overall accuracy can be improved.\n\n**Question 4**. How to handle larger graphs?\\\n**Response:**\n\nIf the graph is too large, we generally have two solutions: (1) temporal co-annealing \u2013 different nodes are mapped onto the chip for annealing at different time, such that the originally continuous annealing process is broken into several iterative steps. In this scenario, the strongly connected nodes should anneal at the same time for better convergence. (2) multi-chip integration - the system can be scaled up with multiple chips connected, with the strongly connected nodes mapped onto the same chip. For both solutions, there may be slowdowns. Nevertheless, for real-world graphs with community structure, the slowdown is acceptable if the nodes in the same community can be annealed simultaneously or on the same chip (less communication for synchronization)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8845/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700375444028,
                "cdate": 1700375444028,
                "tmdate": 1700375444028,
                "mdate": 1700375444028,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Veu3d9hK4x",
            "forum": "qT7DXUmX7j",
            "replyto": "qT7DXUmX7j",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8845/Reviewer_UYh4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8845/Reviewer_UYh4"
            ],
            "content": {
                "summary": {
                    "value": "This paper propose a novel graphic model architecture by improving the existing ising model. The authors further propose the efficient training and inference algorithm to search for the local minimum of the proposed solution. The paper also shows the potential hardware architecture to implement this novel graphical model. The results demonstrate that the proposed solution can achieve comparable performance as GNN over multiple tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "+ A novel graphical model architecture\n+ Inference and training methods to achieve the local min\n+ Efficient hardware implementation"
                },
                "weaknesses": {
                    "value": "- To me, the most significant problem of this work is insufficient review for the prior work. Section 2.1 and 2.2 is a good background introduction, but not too many prior works on the variation of Ising model are discussed, making the contribution of this work hard to justify.\n- A section is missing to introduce the prior work on hardware implementation for Ising model.\n- Technically, this paper simply propose a modified version of Ising model by using a pure quadratic term to replace the linear term in Ising Hamiltonian. \n- Graphic model may not be well-suited for ICLR, which mostly focus on deep learning."
                },
                "questions": {
                    "value": "Please see the weakness section and solve the problem accordingly."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8845/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698828462513,
            "cdate": 1698828462513,
            "tmdate": 1699637112395,
            "mdate": 1699637112395,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UaAOrVnV0M",
                "forum": "qT7DXUmX7j",
                "replyto": "Veu3d9hK4x",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8845/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8845/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank the reviewer for their valuable insights and comments. Our answers to the specific questions are listed below, and a \"general comment\" is also provided for all reviewers to better express our ideas (attached at the top as a global rebuttal)\n\n**Comment 1 & 2**. More discussion of prior work.\\\n**Response:** \n\nThank you sincerely for pointing this weakness out. We have drafted a new related work section in the paper (section 2). Please see the highlighted text with label \"Reviewer-UYh4\". In addition, we provide more information below about the development stage of using Ising model and Ising machine in solving real-world problems.\n\nWe believe this is a good time now to study novel learning methods based on the Ising model due to the recent emergence of efficient Ising machines. Although the Ising model has been famous and studied for decades, especially in statistical physics (widely used to describe complex dynamic systems), its related research largely remains on the theory level and rarely can be adopted in practice. One of the major reasons is the extreme complexity in solving an Ising model (find the lowest-energy states of a dynamic system) with a large variable space. From the perspective of computational time, solving the Ising model with a digital processor can be over 1000x slower than GNN inference. Fortunately, this situation has changed recently - along with the approaching death of Moore's law, computer architects are inventing new types of computers with diverse computing powers (other than digital processors). Among these computers, a computer that can swiftly solve Ising models at low cost (nanoseconds and milliwatts -- 10^6 faster than being solved on digital computers) has recently emerged. The computer is essentially a CMOS-based Ising machine, which benefits from mature semiconductor manufacturing processes (guaranteeing its easy manufacturing and integration) and attracts much attention to the Ising model in recent 2 years. It has already enabled a wide discussion of using methods rooted from the Ising model and the Ising machine to solve different types of problems. Despite great promise and increasing attention, this type of research is still in its early stage, like quantum computing, waiting for its killer applications, while unlike quantum computing, holding short-term promise of unleashing the power of nature in the real world. In the current stage of the development of this method, the binary limitation is believed to be one of the most important challenges to this adoption in the real world. The essence of this challenge is that the vanilla Ising formulation is already complex enough to be realized and implemented as a CMOS chip \u2013 any augmentation to the Ising formulation/Hamiltonian that complicates the circuit implementation should be very cautious. This paper tries to break this limitation by finding a new Ising formulation with slight augmentation that both enables real-value support and avoids complicating the Ising hardware.\n\n\n**Comment 3**. From linear to quadratic.\\\n**Response:** \n\nAs detailed above, the biggest challenge in extending potentials of Ising method from binary to real value is that the Hamiltonian formulation needs to remain simple, such that the Ising machine can be realistically manufactured \u2013 note that the Ising machine to support vanilla is already very challenging. To this end, our design goal is to make the change as slight as possible into the Hamiltonian while enabling the support of real value (enabling non-polarized voltages in the machine)."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8845/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700372940938,
                "cdate": 1700372940938,
                "tmdate": 1700372940938,
                "mdate": 1700372940938,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]