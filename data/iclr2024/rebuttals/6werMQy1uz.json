[
    {
        "title": "Rethinking the Buyer\u2019s Inspection Paradox in Information Markets with Language Agents"
    },
    {
        "review": {
            "id": "925iEjXVZh",
            "forum": "6werMQy1uz",
            "replyto": "6werMQy1uz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7945/Reviewer_STDL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7945/Reviewer_STDL"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers a model of information markets with LLM based agents to resolve the buyer's inspection paradox. Specifically, the buyer wants to assess the information to determine its value, while the seller wants to limit the access to prevent information leak."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- It appears to me that the information market will become an increasingly important problem in the future, but this problem is not well studied beyond abstract theoretical models. This paper proposes an interesting initiative to solve the problem of inspection paradox in information markets through LLM based agents, as those agents are innate to understand the text in context without the capacity to memorize the information.\n\n- This paper designed a simulated information market to generate text contents for sales and evaluate the potential performance of the proposed method. Several interesting experiments with a good amount of efforts are conducted to evaluate the economic rationality of LLM based agent.\n\n- The findings about debate prompting is interesting by itself --- but should the paper cite the source of this technique if it is not an original invention? At a high level, this observation seems to suggest that decision making, especially those require strategic thinking should involve counterfactual reasoning (obtained from debating or self-questioning); this insight might be useful to improve the strategic reasoning skill of LLMs."
                },
                "weaknesses": {
                    "value": "- The paper only compares the performance between agents powered by different LLMs. Though the \"Evaluating the Evaluator'' experiment made some comparison between GPT4 and humans as evaluators, what about baselines based on algorithmic approaches, e.g., a buyer agent that designs quoting strategy based on keyword-matching? The ability to forget the information from rejected quotes can also be artificially planted in these algorithms. Hence, without these algorithmic or heuristic baselines, it is unclear to me how it is necessary to use LLM based agents in this task.\n\n- The paper focuses on the inspection paradox, but the procedure of inspection, especially in the context of information market, is oversimplified --- it is basically whether to allow the agent to read all the text content. However, there is a rich line of econ/cs/ml literature (see e.g., [1, 2, 3]) on the information market that concerns the power of information design for buyer inspection. \nFor example, the seller could only give out a summary of the content, or only answer certain query questions from the buyer agent --- because it is unclear whether it is reasonable or enforceable to trust the buyer to forget all the information from rejected quotes in reality. \n\n[1] Bergemann, Dirk, Alessandro Bonatti, and Alex Smolin. \"The design and price of information.\" American economic review 108.1 (2018): 1-48.\n\n[2] Ghorbani, Amirata, and James Zou. \"Data shapley: Equitable valuation of data for machine learning.\" International conference on machine learning. PMLR, 2019.\n\n[3] Chen, Junjie, Minming Li, and Haifeng Xu. \"Selling data to a machine learner: Pricing via costly signaling.\" International Conference on Machine Learning. PMLR, 2022.\n\n- To my knowledge, there is no clear evidence so far that an LLM based agent has any reasonable rationality or strategic reasoning skill  --- GPT4 cannot play tic-tac-toe, or even reliably compare two numbers. This is also verified in the paper's experiment. Hence, I am not sure whether it is meaningful for the paper to give LLM based agents the ability to make economic decisions --- these decisions could be left for the human or some simple algorithmic procedures while only asking the LLM to provide its reasoning or evaluation scores on the value of the text."
                },
                "questions": {
                    "value": "Please see my comments above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7945/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698783811196,
            "cdate": 1698783811196,
            "tmdate": 1699636976062,
            "mdate": 1699636976062,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "QsVgTMsM1A",
                "forum": "6werMQy1uz",
                "replyto": "925iEjXVZh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7945/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7945/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer STDL"
                    },
                    "comment": {
                        "value": "Thank you for your detailed review and valuable feedback. We were excited to learn that you found our work an \u201cinteresting initiative\u201d on an \u201cincreasingly important problem [\u2026] that is not well studied beyond abstract theoretical models\u201d, and that you appreciated the effort we invested in our experiments. We address your concerns below. \n\n### Evaluation and Keyword-Matching Baseline\n\nAs you suggested, we added a new baseline experiment with a keyword matching baseline (BM25) and found that 95% of the time it was outperformed by LLama-2-70B. \n\n1. For 95% of the questions, the LLM-powered buyer agent\u2019s answers (based on Llama-2-70b) are preferred to the BM25 agent\u2019s answers by the evaluator. This verifies that leveraging LLMs can significantly boost the quality of the generated answers.\n2. Increasing the budget for the BM25 heuristic yields better results \u2014 the GPT-4 evaluator prefers answers from the high-budget simulations for 67% of all questions (vs. low-budget simulations). This result serves to verify that the simulated marketplace functions as expected. \n\nWe have updated the manuscript accordingly (Appendix C).\n\n### Trust and Security in the Information Bazaar\n\nIn our design, we operate under the assumption that sellers trust the marketplace but not necessarily the buyers. This is because the marketplace is controlled by software that implements checks to ensure legal actions by the buyer agents. For instance, the software guarantees that the buyer stays within budget and cannot leak information. This means that the buyer agent can try to buy information outside its budgetary constraints, but the software will not permit that behavior. Therefore, the need to trust buyers is eliminated as the marketplace software provides data security, facing the same set of vulnerabilities as other online businesses. This risk can be reduced through standard cybersecurity practices such as regular security audits, threat modeling, implementation of security protocols, and the addition of compliance layers.\n\nCrucially, the buyer agents can decide whether to buy information after they have received it. They will never commit to buying information before having seen all of it. This approach provides a mechanism for vendors to safely increase the amount of inspection they allow, trusting only the marketplace. While we did not investigate all possible inspection mechanisms, we demonstrated the benefit of allowing more inspection in our study. Specifically, we showed the advantage of allowing content inspection versus metadata-only inspection. This eliminates the need for sellers to strategically withhold or present information, which is one of the key benefits of our approach. We hope that future work builds on the information bazaar concept to evaluate the efficacy of these alternative vendor strategies.\n\n### LLM Rationality,  Debate Prompting, and Economic Decision-making\n\nWe agree that all the LLMs we evaluated display a degree of irrational behavior, and one contribution of this paper is to highlight these. We developed this debate prompting methodology to ameliorate some of those behaviors. To our knowledge this style of method was first published in a blogpost titled **[The Socratic Method for Self-Discovery in Large Language Models](https://princeton-nlp.github.io/SocraticAI/)** on May 5, 2023 by Runzhe Yang and Karthik Narasimhan \u2014 **we cite this in our work** (Section 3.4, paragraph on \u201cDebate Prompting\u201d). In contrast to their contribution, our method underscores the importance of adaptable character shaping within the debate, providing the opportunity to balance the debate dynamics by offering tactical hints to the respective characters.\n\nThe key conceptual idea in this work is that of a buyer agent that is guaranteed to forget (by the marketplace) and can therefore be safely granted access to all information. Such buyer agents can be implemented in different ways, we focus on an LLM-based proof of concept because they are currently by far the most powerful agents for operating on textual data (besides humans, but erasing their memory would be ethically problematic). We completely agree that LLMs fail to act rationally in many cases, but they are rapidly becoming more powerful and there is a growing body of literature on LLMs as economic agents (see e.g. [Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?](https://arxiv.org/abs/2301.07543)). Any advancements in LLMs will directly translate to improved performance of our approach. \n\n**In closing,** thank you again for your valuable feedback on our work. If you have further thoughts or questions on this subject, please feel invited to engage with us."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7945/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700225133526,
                "cdate": 1700225133526,
                "tmdate": 1700225133526,
                "mdate": 1700225133526,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mq3HbSmmqY",
                "forum": "6werMQy1uz",
                "replyto": "QsVgTMsM1A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7945/Reviewer_STDL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7945/Reviewer_STDL"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the detailed explanations, especially the additional experiments using BM25. My judgement on the strengths and weakness of this paper remains, so I would keep my score as it is. Again I appreciate the initiative of this paper, and here is my key takeaway from this paper: while LLMs may be reasonably capable of evaluating the value of information, they are not ready yet to fully take charge of the information acquisition task as a rational agent. I take this as an opportunity for future work, if we resort to certain algorithmic approaches for some part of this task, we might be able to design an AI agent of higher performance and reliability."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7945/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700457655118,
                "cdate": 1700457655118,
                "tmdate": 1700457655118,
                "mdate": 1700457655118,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ugGapcBAGX",
            "forum": "6werMQy1uz",
            "replyto": "6werMQy1uz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7945/Reviewer_UxN6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7945/Reviewer_UxN6"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose text-based digital information market environment is proposed. In such an environment, buyer agents try to obtain the necessary information by transactions with vendor agents without overspending the budgets. Vendor agents need to sell the information for market credits. As the evaluation and access process is implemented by LLMs, the information is not directed accessed by the buyers."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Abundant experiments about whether LLM can be used to evaluate information and make economic decisions. It also examines the performance of different LLMs in different aspects.\n2. Give detailed introductions about how LLM can become a useful agent in Information Bazaar, including the prompts, interaction frameworks, and dataset analysis.\n3. An open-source simulator has been established, which is helpful for future work."
                },
                "weaknesses": {
                    "value": "1. The idea of protecting the information lies in the belief in LLM. However, LLM may face data leakage risks. The authors need to clarify whether it is secure for LLMs to access the information, even if only metadata is accessed.\n2. This paper primarily focuses on explaining how to transform LLM into an agent capable of performing rational actions in an information bazaar, but it lacks detailed explanations regarding using LLM. In other words, replacing LLM with any intelligent agent possessing information evaluation capabilities and trading intelligence would still be able to effectively address the problem of determining the value of information."
                },
                "questions": {
                    "value": "see weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7945/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7945/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7945/Reviewer_UxN6"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7945/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698932758773,
            "cdate": 1698932758773,
            "tmdate": 1699636975951,
            "mdate": 1699636975951,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FvPws6kMym",
                "forum": "6werMQy1uz",
                "replyto": "ugGapcBAGX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7945/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7945/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer UxN6"
                    },
                    "comment": {
                        "value": "We appreciate your review and the constructive feedback. Your positive comments about our experimental results, presentation, and our open source contribution are highly valued. We will address your concerns in the order they were presented.\n\n### Security in the Information Bazaar\n\nThank you for asking this question. To clarify, we do not rely on the LLM to avoid data leakage. Data security is provided by classical software running the marketplace and faces the same set of vulnerabilities as other online businesses. The buyer agent only finds and buys information. The marketplace software guarantees that the buyer stays within budget and cannot leak information. Here\u2019s how this works:\n\n1. **The buyer agent is entirely controlled by the marketplace**. The software that runs the marketplace implements checks that constrain the buyer agent to acting \u201clegally\u201d. It is this static code that ensures that only purchased information can leave the marketplace. This means, for example, that the buyer agent can try to buy information outside its budgetary constraints, but the software will not permit that behavior.\n2. **Cybersecurity Measures**: The cybersecurity risk can be reduced through standard practices, such as regular security audits, threat modeling, implementation of security protocols, and the addition of compliance layers. \n\n### What makes a good buyer agent?\n\nWe appreciate your insightful question. Our framework necessitates buyer agents to meet two primary conditions:\n\n1. They must possess the capacity to accurately estimate the value of the information for the buyer. \n2. They must have the capability for their memory to be audited and manipulated in a hard-coded manner. \n\nThe key ideas we present indeed apply to any such agent. LLMs are the most promising implementation of such an agent due to their unprecedented ability to operate on textual data. We added an experiment with a simpler, keyword-based agent to highlight this point.\n\nDoes this address your concerns, or are there other points where more discussion would be helpful?"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7945/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700225038865,
                "cdate": 1700225038865,
                "tmdate": 1700225038865,
                "mdate": 1700225038865,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wQJFeYhgy4",
            "forum": "6werMQy1uz",
            "replyto": "6werMQy1uz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7945/Reviewer_ovK6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7945/Reviewer_ovK6"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces an interesting automated market run by LLMs that avoids the information asymmetry characteristic of information markets.  The market is run entirely by agents implemented as LLMs that both evaluate text offerings then forget what they've read. This avoids the need for the human agent--the principals-- to view content offered in the market to be able to evaluate it,  creating a  problem for the vendor who would prefer to not reveal the content prior to sale. By use of automated agents for both buyer and vendor, a selection is made without human intervention, so not revealing any content used for evaluation. \n\nThe paper works out a full simulation of multiple agents together with a pricing scheme to demonstrate the feasibility of LLMs performing these tasks. Various LLM implementations are used --"
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The intricacy and just pure inventiveness of the marketplace proposed is impressive. To create system with LLMs playing multiple competing roles is novel. SImilarly the insight that such automation can address a longstanding question in information economics. One can imagine that this work could inspire a flock of similar LLM-driven markets to resolve similar inefficiencies in actual markets. \n\nThe simulation presented shows favorable qualities of better performance with more capable LLMs, rational price behavior in both micro- and macroeconomic scenarios, and improved performance as information content improves."
                },
                "weaknesses": {
                    "value": "There is a  fundamental evaluation question, concerning is definition and creation of a evaluation baseline. The paper takes as a premise that an LLM-based method is by nature superior to a conventional automated method. Granted, evaluating LLM performance is an area open to many approaches, and no conventional method exists such as cross validation serves for supervised learning.  Specifically in this paper, one could create a surrogate for non-LLM buyer and vendor agents (the vendor could be a trivial version that just presents metadata), to serve as a point of comparison for the LLM models presented. This would be the analog of the statistician's null hypothesis. For example, if just metadata were used - e.g. the $\\script{F}(M(I))$ by an algorithm based on conventional similarity measures of relevance, how would it perform? Hence the research question posed, \"Does this marketplace enable buyers to more reliably identify and value information?\" begs the question, \"more reliably than what?\"\n\nIn the Section \"Evaluating the Evaluator\" a comparison is made between GPT4's result and a human label, showing reasonable human-level performance. This is interpreted to mean that the method has a subjective component.  This does not answer the fundamental evaluation question. \n\nIncidentally Figure 6 is missing the caption \"Figure 6\"  Figure 6a could be more succinctly presented since the\noff-diagonal elements are simply 1 minus the other. The choice of visualization method is different than for 6b - one is a comparative percentage, the other a correlation, which is confusing."
                },
                "questions": {
                    "value": "One could argue that judging a paper on a task that it does not propose to do is to force a requirement on the paper outside of the scope of work.  One conceivably could always come up with such arguments - \"what about X or Y -- why were they not included in the work?\" and hence such criticisms might appear in general unfair.    The argument as to the weakness described could be considered as such.  However this is a stronger argument, that claims about a contribution must be substantiated against a conventional norm.   I am open to reconsideration of this point should the current contribution based purely on novelty be considered adequate."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7945/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698967644619,
            "cdate": 1698967644619,
            "tmdate": 1699636975824,
            "mdate": 1699636975824,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SNkw6r3blY",
                "forum": "6werMQy1uz",
                "replyto": "wQJFeYhgy4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7945/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7945/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ovK6"
                    },
                    "comment": {
                        "value": "Thank you for your constructive review. We are glad to hear your feedback that the \u201cintricacy and just pure inventiveness of the marketplace proposed is impressive\u201d, and that \u201cthis work could inspire a flock of similar LLM-driven markets to resolve similar inefficiencies in actual markets.\u201d In what follows, we address your concerns in the order in which they were presented.\n\n### Evaluation and Baselines\n\nThank you for raising this point. We share your view that evaluating LLMs is still fundamentally an open question, and that comparing with a standard non-LLM baseline will strengthen this work. In response to your query, we have conducted additional experiments. \n\n**New Baseline and Experiment with non-LLM Buyer and Vendor Agents.** TL;DR, we added a new experiment with a conventional baseline (BM25) and found that 95% of the time it was outperformed by LLama-2-70B. More specifically, we replace the LLM in the buyer-agent with the widely used keyword matching algorithm (BM25), and also replace the vendor agent\u2019s LLM embeddings with BM25. The buyer agents\u2019 policy is natural \u2014 it ranks informational goods by their relevance to the question (via BM25), and purchases all goods until the budget is spent. \n\nWe run this simulation with a lower budget (25 credits) and with a higher budget (100 credits). Our findings are two fold: \n\n1. For 95% of the questions, the Llama-2-70b buyer agent\u2019s answers are preferred to the BM25 agent\u2019s answers by the GPT-4 evaluator. This verifies that LLMs can significantly boost the quality of the generated answers.\n2. For 67% of the questions, the BM25 heuristic with a high budget is preferred to the BM25 heuristic with a lower budget by the GPT-4 evaluator. This result serves to verify that the simulated marketplace functions as expected. \n\nWe have updated the manuscript accordingly (Appendix C).\n\n**Metadata-only Vendors.** Regarding your point that \"the vendor could be a trivial version that just presents metadata\", we would direct your attention to the experiments presented in Table 1 and Figure 5 (right), which compare against a baseline (\"Without inspection\") where the buyer agents can only review the metadata instead of the full content. There, we see that the ability to review the full content (\"With inspection\") provides a clear advantage. Your broader point is well-taken that a large family of vendor strategies may be explored. \n\n### Figure 6\n\nThank you for pointing this out; we will fix this in our next revision.\n\n**In closing**, we thank you for the effort invested in reviewing our work. If you have further questions or clarifications, we would be happy to discuss."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7945/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700225011228,
                "cdate": 1700225011228,
                "tmdate": 1700225011228,
                "mdate": 1700225011228,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zzRvVnle9A",
            "forum": "6werMQy1uz",
            "replyto": "6werMQy1uz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7945/Reviewer_mENG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7945/Reviewer_mENG"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies how the use of agents based on large language models (LLMs) could potentially affect information markets. To this end, the paper introduces a suitable environment simulating an information market, and it experimentally evaluates various LLM-based agents within it."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "I believe that the challenges addressed in the paper are relevant for better understanding how large language models behave in application scenarios in which strategic aspects are concerned. The paper makes a very good job at presenting the studied setting and derived results."
                },
                "weaknesses": {
                    "value": "The first concern that I have is about the exposition of the results in the paper. While the obtained results are very-well explained at least intuitively, I think that the paper misses some formalism that is needed to really fully understand the presented results. In the end, the actual framework that has been developed to model agents' strategic interactions is never introduced in the paper. Perhaps this is not so important from an experimental perspective, but it could be of great value for those that are more interested in the theoretical implications that the obtained results have.\n\nThe second concern that I have is more from a deployment perspective. I found interesting the idea of equipping agents with the ability of forgetting information if this is not acquired by them. However, I have some doubts on how this behavior can be enforced in practice."
                },
                "questions": {
                    "value": "See the second concern in the Weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7945/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699433151257,
            "cdate": 1699433151257,
            "tmdate": 1699636975716,
            "mdate": 1699636975716,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lHzgSIxPeU",
                "forum": "6werMQy1uz",
                "replyto": "zzRvVnle9A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7945/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7945/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer mENG"
                    },
                    "comment": {
                        "value": "Thank you for reviewing our work. We are pleased to know that you found that our paper does a \u201cvery good job at presenting the studied setting and the derived results\u201d. We will now address your concerns. \n\n### Theoretical Results\n\nWe chose to not fully formalize our model because the key idea of agents whose memory can be erased is applicable to a wide range of models and economic assumptions. Nevertheless, we\u2019d be happy to explore if introducing some high-level formalism early on would help with clarity of exposition. Was the model you had in mind something along the lines of the one in Appendix A, titled \u201cFormal Result on the Impact of Inspection on Expected Utility\u201d. In this section, we demonstrate that under the assumption of \u201cMonotonicity in Information\u201d, the expected utility of the buyer agent increases if inspection is permitted. \n\n### Practical Deployment\n\nThank you for raising this point, which we rephrase as: \u201cHow can we practically ensure that the agents discard the information that they are required to forget?\u201d Our solution involves two strategies:\n\n1. **The buyer agent is entirely controlled by the marketplace**. The software that runs the marketplace implements checks that constrain the buyer agent to acting \u201clegally\u201d. It is this static code that ensures that only purchased information can leave the marketplace. This means, for example, that the buyer agent can try to buy information outside its budgetary constraints, but the software will not permit that behavior.\n2. **Cybersecurity Measures**: On top of this, a practical deployment needs to address cybersecurity risks. These can be reduced through standard practices, such as regular security audits, threat modeling, implementation of security protocols, and the addition of compliance layers. \n\nWe will include this clarification in our manuscript.\n\n**In conclusion,** we thank you again for your review. If you have further questions about either aspect, please feel free to engage with us."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7945/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700224876121,
                "cdate": 1700224876121,
                "tmdate": 1700224876121,
                "mdate": 1700224876121,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]