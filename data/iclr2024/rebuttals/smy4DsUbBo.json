[
    {
        "title": "Energy-conserving equivariant GNN for elasticity of lattice architected metamaterials"
    },
    {
        "review": {
            "id": "fcZI13hgnd",
            "forum": "smy4DsUbBo",
            "replyto": "smy4DsUbBo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6408/Reviewer_uV3y"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6408/Reviewer_uV3y"
            ],
            "content": {
                "summary": {
                    "value": "## Summary\n\nThe paper presents an extension to the [MACE](https://proceedings.neurips.cc/paper_files/paper/2022/file/4a36c3c51af11ed9f34615b81edb5bbc-Paper-Conference.pdf) model by adding a matrix power layer to ensure the positive semidefinite (PSD) nature of the output tensor. Although the idea of maintaining PSD properties might be of value, the paper's contributions are incremental at best. Most notably, the claim about \"high-order rotational equivariance\" is not an original contribution but belongs to the original MACE model. The paper severely suffers from a lack of organization and clarity in writing. Hence, I recommend a rejection of this submission.\n\n## Detailed Comments\n\n### 1. Lack of Definitions and Citations\n\na) The term \"edge shifts\" is used without a definition or reference.\nb) The suffix 'lb' used in the context of training methods is not defined.\nc) Clebsch\u2013Gordan coefficients are mentioned without proper citation.\nd) On page 17, there are numbers in parentheses next to \"Young's modulus,\" \"shear modulus,\" and \"Poisson's ratio,\" without any explanation.\n\n### 2. Unclear Illustrations and Descriptions\n\na) The paper claims that energy conservation equates to a PSD tensor, but this is tucked away in a footnote. This claim needs to be explained in the main text.\nb) The choice of the optimal 've' method, which is squaring matrix A, is not mentioned until late in the results section. This should be mentioned in the methodology section.\nc) Only absolute errors are presented without giving the context of ground truth magnitudes or relative errors. It's unclear for the readers to know if this method is accurate or not at all.\nd) It's unclear if Figure 1b is a plot for ground truth or predictions.\n\n### Flaws in Finite Element Method (FEM) Introduction\n\na) The paper mentions that FEM has \"~10^9 elements\" but does not state the computation time for such a scale. Furthermore, GNNs cannot handle such scales on a single GPU, making the comparison unfair. Instead, try to report a wall time comparison between your method and FEM for the same dataset.\nb) The statement that FEM ensures force equilibrium is incorrect; it is the underlying PDE that ensures this.\nc) Similarly, FEM itself does not ensure PSD properties; this is ensured by the constitutive model.\nd) The paper incorrectly claims that FEM is rotationally equivariant. Special treatments are needed to achieve rotational equivariance in FEM.\n\n## Conclusion\n\nThe paper presents an incremental extension to the MACE model with a focus on preserving the PSD properties of the output tensor. However, the paper lacks clarity in writing and organization, and its contributions are limited. As a result, I recommend a borderline reject for this submission.\n\nThe authors can also consider a workshop or journal submission that focuses on this area.\n\n##\nAfter rebuttal, I think the writing quality and the motivation has been more clear. Hence, decided to improve to 6."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "See above"
                },
                "weaknesses": {
                    "value": "See above"
                },
                "questions": {
                    "value": "See above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6408/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6408/Reviewer_uV3y",
                        "ICLR.cc/2024/Conference/Submission6408/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6408/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698364481516,
            "cdate": 1698364481516,
            "tmdate": 1700504764083,
            "mdate": 1700504764083,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gu8xi5NgRW",
                "forum": "smy4DsUbBo",
                "replyto": "fcZI13hgnd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6408/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6408/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer uV3y"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their helpful comments. \nIt is clear that the reviewer strives to ensure the quality of the submission. \nWe made our best effort to address the reviewer's comments in order to improve the quality of the paper.\n\nIn response to the reviewer's comments:\n\n\n1.  The reviewer points out a lack of organization and clarity in writing.\nWe have improved the organization of the paper.\nSeveral sections (MACE details, training details) were moved to the Appendix, and Methods section was expanded to include the details of the PSD layer and Mandel representation.\n\n2.  With regards to reviewer's comment \"1. Lack of Definitions and Citations''. Term edge shifts is defined in section A.5 in the Appendix. Suffix 'lb' is defined in the text (paragraph **Energy conservation learning**). It is mentioned in text that Clebsch-Gordan coefficients  enforce the equivariance of the layer. A formal introduction of Clebsch-Gordan coefficients is beyond the scope of this paper -- we now point the reader to the MACE paper for more detail.\nThe numbers by \"Young's modulus\" etc are now expanded in words.\n\n3.  With regards to reviewer's comment \"2. Unclear Illustrations and Descriptions''. The claim that energy conservation equates to PSD tensor is now explained in main text, as is the equivalence between the positive-definite fourth-order tensor and positive-definite stiffness matrix in Mandel notation.\nThe Methods section now mentions the various methods for ensuring positive semi-definiteness.\nIt is not quite true that only absolute errors are presented without the context of ground truth magnitudes or relative errors. We also report error $L_{{dir,rel}}$ which is directional error normalized by the square root of the tensor norm.\nWe edited the caption of Figure 1 to clarify that the plotted surface corresponds to ground truth.\n\n4.  With regards to reviewer's comment \"Flaws in Finite Element Method (FEM) Introduction''. We have included section **Speedup using machine learning methods** which compares runtime of ML methods that we used and FE.\nThe ML methods are 3 orders of magnitude faster than FE baseline.\nThe reviewer criticises our statements that (i) FE enforces force equilibrium, and (ii) FE gives PSD output.\nWe agree with the reviewer that it is the underlying PDE and constitutive law, respectively, that enforce those principles.\nHowever, in this context, the *FE solution* for a lattice does indeed satisfy these principles.\nMoreover, no special treatments are required for equivariance.\n\n\nWe thank the reviewer for the helpful comments. We made relevant changes to the manuscript which improve its quality.\nWe believe that the contributions of this paper are significant on two levels:\n(i) it is not trivial to enforce positive semi-definiteness of a 4-th order tensor while maintaining equivariance (Reviewer azcZ pointed out a need for formal mathematical proofs, which we now include in the manuscript.) \n(ii) The paper is submitted in the area of *applications to physical sciences*, and another key contribution is that we are making the dataset publicly available. There has been a lack of datasets and corresponding method development for higher-order tensors, which we are hoping to address by this work."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6408/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322502788,
                "cdate": 1700322502788,
                "tmdate": 1700322502788,
                "mdate": 1700322502788,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "F2ltygx9Bw",
                "forum": "smy4DsUbBo",
                "replyto": "gu8xi5NgRW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6408/Reviewer_uV3y"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6408/Reviewer_uV3y"
                ],
                "content": {
                    "title": {
                        "value": "Reply"
                    },
                    "comment": {
                        "value": "I thank the authors for replying, here is more follow-up\n\n1. My concern mentioned in the summary that \"the novelty is limited\" is not addressed. I noticed you replied to Reviewer TDG7\nthough on this. I think that is a valid point.\n\n2. Your reply 2. mentions that many of the definitions are in the appendix. This is not a good way of expressing, please at least mention their full definition when they 1st appear. You can move further details and proofs in the appendix though for being concise.\n\n3. Your reply 3. equivariance also relies on the constitutive model. Non-linear models without the special treatment on the rotation can cause trouble on this point. However, I admit in your context, this may not be an issue. It's better to be more precise.\n\nBased on your reply to other reviewers, I am improving my score to 6. Please refine a bit more according to the 2,3 items above."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6408/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700504704898,
                "cdate": 1700504704898,
                "tmdate": 1700504704898,
                "mdate": 1700504704898,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7a7P2dOxd8",
            "forum": "smy4DsUbBo",
            "replyto": "smy4DsUbBo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6408/Reviewer_TDG7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6408/Reviewer_TDG7"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a specially design graph neural network that well tackles the physical constraints in lattice architected metamaterials. To be specific, the model guarantees by design SE(3)-equivariance and energy conservation. The latter is fulfilled by the proposed positive semi-definite layer that overcomes the limits of previously proposed approaches using Cholesky factorization and eigenvalue decomposition. The model is examined on a dataset ``limp'' showcasing that MACE is superior when equipped with the proposed PSD layer.\n\nUpdate: contribution raised from fair to good, overall score raised from 3 to 5 due to additional experiments on material design."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The motivation of the paper is clear: designing a GNN that fulfills the inductive biases for lattice architected metamaterials.\n\n2. The proposed approach is clean and easy to follow."
                },
                "weaknesses": {
                    "value": "1. The novelty is somewhat limited in the sense that the proposed model is a direct utilization of MACE, equipped with the proposed layer that satisfies PSD.\n\n2. The dataset is a bit limited and the experiments lack of comparison with other methods. If there are no significant deep learning based (or even GNN-based) methods to compare, it would also help a lot if any FE-based method could be involved. The readers may be curious about how the proposed model can achieve better accuracy/efficiency tradeoff compared with traditional solvers.\n\n3. The implication of the practical usage of the method is limited. Since this paper is developed purely based on practical considerations, it would be better if the paper could show how this model can help in other related/similar tasks or downstream tasks that could potentially benefit from this method., other than just predict the stiffness tensor."
                },
                "questions": {
                    "value": "1. How does the method perform compared with other solvers, deep learning-based or even not?\n\n2. Are there other tasks/datasets that can benefit from the development of such GNN-based method that is specifically designed to regress on the stiffness?\n\n3. Even if the paper discusses the limitations of previous Cholesky/eigenvalue decomposition-based methods that permit PSD constraint, it would help a lot if this point is also verified by experimental results/ablation studies."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6408/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6408/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6408/Reviewer_TDG7"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6408/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698615204014,
            "cdate": 1698615204014,
            "tmdate": 1700618322710,
            "mdate": 1700618322710,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6X4SWX9D5X",
                "forum": "smy4DsUbBo",
                "replyto": "7a7P2dOxd8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6408/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6408/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer TDG7"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for taking the time to review the paper and providing relevant comments that will help us improve the quality of the submission.\n\nWe are addressing all reviewer's comments:\n\n\n1.  The reviewer states that\n\n> The novelty is limited in the sense that the proposed model is a direct utilization of MACE, equipped with the proposed layer that satisfies PSD.\n\nWe recognize that the reviewer is worried about the lack of ML-specific novelty of this work.\nWe would like to address these concerns on two levels:\n(i) it is not trivial to enforce positive semi-definiteness of a 4-th order tensor while maintaining equivariance (Reviewer azcZ pointed out a need for formal mathematical proofs, which we now include in the manuscript.) Therefore, we believe that this constitutes significant contribution to the community.\n(ii) The paper is submitted in the area of *applications to physical sciences*, and another key contribution is that we are making the dataset publicly available. There has been a lack of datasets and corresponding method development for higher-order tensors, which we are hoping to address by this work.\n\n2.  It is true that the dataset lacks comparisons with other methods -- that is because there is presently a lack of methods which focus on lattices and 4-th order tensors.\nThe two previously presented GNN methods for lattices are based on CGC and NNConv, which are the models against which we benchmark our MACE-based model.\nMoreover, we have included runtime comparisons for the three model families, and for FE baseline.\nWe show that the ML models achieve a speedup of 3 orders of magnitude.\n\n3.  We thank the reviewer for pointing out other tasks that could benefit from this methods other than just the prediction of the stiffness tensor.\nThe presented methods is applicable to any 4-th order tensor. Examples include diffusion tensor in MRI,  piezo-optical tensor and the elasto-optical tensor.\nWe have incorporated this statement in the Abstract and Conclusion.\n\n4.  We do not provide benchmarks with Cholesky/eigenvalue based methods because the Choleksy method fails on the basic requirement of equivariance, and the eigenvalue-based method is unstable during training due to the underlying instability of gradients of eigenvector computation."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6408/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322316076,
                "cdate": 1700322316076,
                "tmdate": 1700322316076,
                "mdate": 1700322316076,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JsoKbMT4L3",
                "forum": "smy4DsUbBo",
                "replyto": "6X4SWX9D5X",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6408/Reviewer_TDG7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6408/Reviewer_TDG7"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thank the authors for the response.\n\nI am still concerned on the novelty of the paper, especially considering potential limited audience at a venue like ICLR--I think the paper would benefit much more if the method or the target problem would have implications to benefit a wider range of tasks, or at least demonstrate any downstream applications besides simply measuring the prediction error of the stiffness tensor, e.g., how the method would help in structural design/optimization.\n\nSince it is a first work that brings the task to ML venue, I have to place a little bit higher standard on the scope of the empirical evaluation. I think a more comprehensive benchmark protocol will help more in advancing ML for material science community."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6408/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700534618862,
                "cdate": 1700534618862,
                "tmdate": 1700534618862,
                "mdate": 1700534618862,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gZEKNzgvYG",
                "forum": "smy4DsUbBo",
                "replyto": "ApfOxmPUco",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6408/Reviewer_TDG7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6408/Reviewer_TDG7"
                ],
                "content": {
                    "title": {
                        "value": "Further response"
                    },
                    "comment": {
                        "value": "I appreciate the additional experiment by the authors on material design. I thank the authors for the efforts. I believe the paper benefits a lot from such interesting illustrations and is able to attract broader audience and inspires more future works.\n\nFor now I am raising the score to 5 but is open to further increasing the score in reviewer discussions barring any other concerns raised during the process."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6408/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700618192557,
                "cdate": 1700618192557,
                "tmdate": 1700618192557,
                "mdate": 1700618192557,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "GnQvdg7ax7",
            "forum": "smy4DsUbBo",
            "replyto": "smy4DsUbBo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6408/Reviewer_kbo4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6408/Reviewer_kbo4"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces higher-order energy-conserving SE(3) equivariant GNNs which build upon the MACE architecture. These GNNs are applied to lattices, i.e. architected metamaterials. The new features of the model are conservation of energy and SE(3) equivariant predictions of the a 4th order stiffness tensor.  For the stiffness tensor positive-definiteness is ensured. Experiments compare against existing deep learning models of Crystal Graph Convolution (CGC) and NNConv."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- This paper introduces a novel and very interesting application of SE(3) equivariant GNNs.\n- Positive semi-definiteness of stiffness tensor is a interesting new tool for physics-based machine learning.\n- The paper contains all important information to follow (general physics background, no material-design expert).\n- The evaluation scheme is quite solid and the different training methods are sound."
                },
                "weaknesses": {
                    "value": "- It seems that most of the important information which is novel to the deep learning community is put into the appendix. For example, definitions of stress and strain tensors, or their relation to the stiffness tensor. Even more importantly, only in the appendix one can read why the stiffness tensor can be represented as a matrix, and how the positive definiteness of a matrix can be ensured. \n- On the other hand, background and related work are a bit repetitive\n- Code / or pseudocode would be pretty helpful to understand output layers and how the stiffness tensor is ensembled.\n- There are no runtime comparisons in the paper, especially since e3nn based models are known to be slow this would be interesting to know.\n- Related to runtime comparisons, comparisons to FE methods are needed to get a better understanding of the presented performances. I understand that FE models are used as ground truth and that this might be tricky to obtain, but for example one could estimate runtime comparisons (especially since it is stated the FE methods are very slow) and report performance differences for nodal perturbations to get a perspective for the reported loss values? The latter should give a feeling to what nodal perturbations the presented losses are comparable. \n- As far as I can see there is no OOD experiments although this is claimed to be one of the main reasons why such models built on physical principles are built."
                },
                "questions": {
                    "value": "- When exactly is the positive semi-definite layer applied? after the readout?\n- In Figure 2 validation loss of CGC+tr seems to be still dropping sharply, is it possible that training was stopped too early?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6408/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6408/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6408/Reviewer_kbo4"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6408/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698746387824,
            "cdate": 1698746387824,
            "tmdate": 1700584039279,
            "mdate": 1700584039279,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bLZp1DrUEB",
                "forum": "smy4DsUbBo",
                "replyto": "GnQvdg7ax7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6408/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6408/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer kbo4"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the helpful comments.\nWe strive to improve the quality of our submission and we addressed all of the reviewer's comments.\n\nSpecifically, we have made the following revisions in response to the reviewer's comments\n\n\n1.  The reviewer states that\n\n> most of the information which is novel to the deep learning community is put into the appendix.  \n> [...] the background and related work are a bit repetitive\n\nWe expand on the solid mechanics section in the background, noting that for energy conservarion, the stiffness tensor must be positive semi-definite. We moved the details of MACE model which might feel repetitive into the appendix.\n\n2.  The reviewer states that\n\n> Code / or pseudocode would be pretty helpful to understand output layers and how the stiffness tensor is assembled.  \n> [...] When exactly is the positive semi-definite layer applied? After the readout?\n\nIn the Methods section, we included a schematic of the model, so it is clear where the PSD layer is applied.\nWe expanded the Methods section to include more details about the dataset and the positive semi-definite (PSD) layer.\nWe explain how the fourth-order tensor is represented by $6\\times6$ matrix and how it can be made positive definite.\nIn addition, we have written a mathematical proof that our PSD layer in Mandel notation is equivariant. This is now in the Appendix.\n\n3.  The reviewer points out that\n\n> There are no runtime comparisons in the paper  \n> [...] comparisons to FE methods are needed [...]\n\nWe provide inference time comparisons for the three families of ML models and FE baseline.\nWhile the e3nn-based model is slower than the ML counterparts, all ML models are approximately 3 orders of magnitude faster than FE.\n\n4.  With regards to OOD experiments, we now explain in the Methods section (subset Dataset) the big separation of our training and test data, so testing is done on OOD data.\n\n5.  While it appears in Figure 2 (now Fig 3) that validation loss for CGC+tr continues to drop sharply, this is exaggerated by the log-scale nature of the x-axis.\nAll models were trained to convergence."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6408/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322169268,
                "cdate": 1700322169268,
                "tmdate": 1700322169268,
                "mdate": 1700322169268,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dAf5RfkVz1",
                "forum": "smy4DsUbBo",
                "replyto": "bLZp1DrUEB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6408/Reviewer_kbo4"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6408/Reviewer_kbo4"
                ],
                "content": {
                    "title": {
                        "value": "Post-rebuttal"
                    },
                    "comment": {
                        "value": "Thanks to the authors for restructuring the paper, many things have become clearer to me. I do thing that this work is an important contribution to the community, I have thus raised my score."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6408/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700584092794,
                "cdate": 1700584092794,
                "tmdate": 1700584092794,
                "mdate": 1700584092794,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ANQUYzXtvl",
            "forum": "smy4DsUbBo",
            "replyto": "smy4DsUbBo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6408/Reviewer_azcZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6408/Reviewer_azcZ"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an application of equivariant GNNs for predicting the stiffness tensor of architected lattice metamaterials. To ensure the validity of physical significance, a layer is proposed to preserve the positive semi-definiteness of the predicted stiffness."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThere is less work focused on studying higher-order tensors beyond first-order tensors, such as coordinates, velocity, and force. Research on a 4th-order tensor represents a new situation for application.\n2.\tThis paper try to design a new module to ensure the validity of physical significance, which is inspiring. \n3.\tThe figures are pretty."
                },
                "weaknesses": {
                    "value": "1.\tThis work chooses to predict a 4-th ordered tensor \u2013 \u201cstiffness tensor\u201d, whose symmetry has been maintain well with existing models like TFN, PAINN. This paper does not propose theoretical innovations in maintaining equivariance, so this methodology and the emphasis on \u201cfourth-order\u201d in abstract are not directly related (the Positive Semi-Definite Layer is based on physical meaning, regardless of whether it is a fourth-order tensor).\n2.\tSince the whole backbone is built with existing MACE layer, the main novelty is to propose the  \u201cPositive Semi-Definite Layer\u201d(let us call it \u201cPSD-layer\u201d). About this, here are some questions:\n     - a) To maintain the equivariance of the total model, we must ensure each layer in such a model is equivariant. But for the PSD-layer, the PSD matrix $A$ is based on $M$, which is created by arrange $n(n+1)/2$ entries of the output of an equivariant model.\n        - **i**. Is it an equivariant operator to arrange $n(n+1)/2$ entries to get $M$?  This requires a formal mathematical proof.\n        - **ii**. Is it an equivalent operator of the function $\\rho$ to turn $M$ into $A$? In the end of Section A.2.2, \u201cIf the overall model had been equivariant with respect to vectors in $U$, it will remain equivariant after eigenvalues are made positive\u201d is not trivail, it may also require a formal mathematical proof.\n         - **iii**.\tFor now, we assume that the previous question (function $\\rho$ is equivariant) has a good proof. It is necessary to discuss whether this design will reduce the representational capacity of the entire neural network. Assume that this neural network is a bijection (we consider an equivalence class divided based on different perspectives as an input. But the function $\\rho$ may not a bijection, e.g. $(\\pm \\Lambda) ^2$ will get a same result. The Wigner-D based network build a faith representation of the group, but the induction of function $rho$ will lead to an unfaith representation, it requires more analysis. For example,  an analysis for the increased stiffness-based errors of CGC+ve, NNConv+ve, and MACE+ve in Table 1 may be a manifestation of the decline in the ability of network representation.\n    - b)\tLet assume the PSD-layer is equivariant, there are some questions about the experiments:\n        - **i**.\tIn Section 3 (Related Work) and Section 5(Conclusion), Finite element (FE) modelling is mentioned, but the experiment could not find the data comparison (e.g. time cost or accuracy) between your model and FE.\n        - **ii**.\tMore powerful baselines should be discussed, especially the geometric GNNs like TFN[1], NequIP [2], SCN[3], GMN[4], SE(3)-Transformer [5]. \n3.\tHere are some possible typos and recommended symbol modifications:\n    - a)\tAlmost all the inline formulas in the article lack punctuation at the end.\n    - b)\tIn Section 2.1, the rotation of the stiffness tensor $R_{ia}R_{jb}C_{abcd}R_{kc}R_{ld}$ may be better to generalize to $n$-th order tensors with the format of changing bases of a tensor($ R_{ia}R_{jb} R_{kc}R_{ld} C_{abcd}$).\n    - c)\tIn Eq. (2),  the Wigner-D matrix generally written in the form $D_{m\u2019,m}^{(l)}(R)$.\n    - d)\tIn Section 4, the third line in the paragraph \u201cPositive Semi-Definite Layer\u201d, \u201cin line wih\u201d, may be \u201cin line with\u201d.\n\nReference:\n\n- [1] Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds. \n- [2] E(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials\n- [3] Spherical Channels for Modeling Atomic Interactions\n- [4] Equivariant Graph Mechanics Networks with Constraints\n- [5] SE(3)-Transformers: 3D Roto-Translation Equivariant Attention Networks"
                },
                "questions": {
                    "value": "Please refer to the weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6408/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698814147633,
            "cdate": 1698814147633,
            "tmdate": 1699636712607,
            "mdate": 1699636712607,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gH6fSMaSpL",
                "forum": "smy4DsUbBo",
                "replyto": "ANQUYzXtvl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6408/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6408/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer azcZ"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for the detailed comments.\nIt is clear that the reviewer wants to ensure the quality of the submission; thus, we have made significant changes to address all of the reviewer's comments.\n\n### Comment 1\nThe reviewer states that \n\n>    the existing models (like TFN and PAINN) have been able to fit a 4-th order tensor and that this paper does not propose theoretical innovations in maintaining equivariance.\n\n\nWhile it is true that models like TFN and PAINN can fit 4-th-order tensors, there is a lack of such examples in the machine learning community. \nFor instance, the PAINN paper shows an example of fitting rank-2 polarizability tensor.[1,p5] \nVery few, if any, examples of rank-4 tensors have been reported in the machine learning community.\nWe believe that it is one of the contributions of this paper (in the area of *applications to physical sciences*) to make available a real-world dataset of rank-4 tensors, as this could fuel further developments in the community. \n\nSecondly, Positive Semi-Definite (PSD) layer brings about new challenges related to equivariance.\nMaintaining equivariance of the 4-th order tensor is more challenging than for the rank-2 tensor.\nA new theoretical contribution in maintaining equivariance, consistent with positive-definiteness of a 4-th order tensor, is needed and is presented here. \n\n### Comment 2\nThe reviewer raises valid questions. Based on these, we have made the following revisions to the manuscript.\n\n\n1.  We included in the Appendix section **Proof of equivariance of PSD layer in Mandel notation**\nin which we mathematically prove that our PSD layer is equivariant.\n1.  The reviewer voices concerns that function $\\rho$ might lead to a reduced representational capacity of the model.\nWhile we are unable to run further experiments at this short timescale, we will make effort to address reviewer's points in due course.\nEmpirically and from the point of view of using this model in practice, the performance hit due to the possible reduction in representational capacity is minor as seen in Table 1.\n1.  We have included section **Speedup using machine learning methods** in the results section\nwhere we compare inference speed of the three families of models and FE.\nWe show that the ML models bring a speedup of 3 orders of magnitude.\nSince FE results are the ground truth data for ML training, it is not meaningful to compare the accuracy of FE with the accuracy of ML models.\n1.  The reasoning behind our decision to discuss models based on CGC, NNConv, and MACE is as follows.\nThe only GNN models, to our best knowledge, that have been used for lattices are CGC and NNConv. [2,3]\nTherefore we decided to benchmark our model against the previous baseline used in the literature.\nThe reason why we chose MACE as the basis for our model (as opposed to TFN, NequIP etc) is that\nit has been reported by the computational chemistry community as the best equivariant model for molecules.\nAs a side note, in paragraph **Correlation order** on p.9 we note that MACE with $\\nu=1$ is equivalent to TFN.\n\n\n### Comment 3\nThe reviewer makes valuable suggestions and we have revised the manuscript based on their comments.\n\nReference:   \n[1] Equivariant message passing for the prediction of tensorial properties and molecular spectra   \n[2] Using Graph Neural Networks to Approximate Mechanical Response on 3D Lattice Structures   \n[3] Graph-based metamaterials: Deep learning of structure-property relations"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6408/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700321907750,
                "cdate": 1700321907750,
                "tmdate": 1700321907750,
                "mdate": 1700321907750,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XGE8lU81Hr",
                "forum": "smy4DsUbBo",
                "replyto": "gH6fSMaSpL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6408/Reviewer_azcZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6408/Reviewer_azcZ"
                ],
                "content": {
                    "title": {
                        "value": "Received with thanks."
                    },
                    "comment": {
                        "value": "Dear author, \n    I've read your responses. Some concerns, such as comparison with FE and Proof of equivariance of PSD have been addressed. However, I still have the concerns about the  theoretical innovations, mathematical proof of $\\phi$ and comparisons with other geometric GNNs. For now, I will maintain my negative opinions and finalize my score after the reviewers' discussion."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6408/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700545011060,
                "cdate": 1700545011060,
                "tmdate": 1700545011060,
                "mdate": 1700545011060,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]