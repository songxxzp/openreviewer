[
    {
        "title": "MAP's not dead yet: Uncovering true language model modes by conditioning away degeneracy"
    },
    {
        "review": {
            "id": "0PXnk0xrlF",
            "forum": "vXf8KYTJmm",
            "replyto": "vXf8KYTJmm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8969/Reviewer_vYmk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8969/Reviewer_vYmk"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes ACBS, a modified version of beam search that produces output from the LM by conditioning on external signals, e.g. length. The authors argue that the unexpected behavior of the model is caused by the low-entropy noise sample and derive their proposed method. The experiments are conducted on two tasks (machine translation and story generation) with model scales up to 7B."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The motivation for this work is interesting.\n* The authors provide extensive qualitative examples."
                },
                "weaknesses": {
                    "value": "* **Poor Presentation**: The presentation of this work is poorly written. Please proofread your manuscript before submission. Some examples are \n  * Section 1: distribution which the mode representsEikema & Aziz (2020) --- the citation should be included in parenthesis and there should be a white space.\n  * Section 1: training data data --> training data\n  * Footnote 1: the regurgitating the input --> the regurgitating of the input\n  * Section 2.1: distributions arbitrarily closely --> distributions arbitrarily close\n  * Section 3: translation model Tiedemann & Thottingal (2020) --> translation model (Tiedemann & Thottingal, 2020)\n  * Section 3: ROC stories dataset Mostafazadeh et al. (2016) --> ROC stories dataset (Mostafazadeh et al., 2016)\n  * Section 3: LLaMA model Touvron et al. (2023) --> LLaMA model (Touvron et al., 2023)\n* **Poor Theoretical Analysis**: The theoretical motivations presented in Section 2.1, 2.2, 2.3 are hard to follow. For instance, the authors write \"For the SVO translation example\", what is SVO? And there should be a proper citation. The mathematical derivations in those sections are not detailed enough, which clearly undermines the quality of this work.\n* **Lack of Details in Experiments**: There are necessary details are missing, including how the outputs are obtained from the LM which are then used to train the classifier; number of epochs; number of training samples.\n* **Limited Evaluations**: The evaluations are only considered up to 200 tokens which is too short under current literature, e.g. ChatGPT API has 4k length. I strongly suggest the authors to extend their evaluations up to at least 2k length.\n* **No human evaluation**: When comparing two decoding methods like in Section 5.2.1, simply using likelihood is not enough. Human evaluations are necessary to include to provide more evidence of the proposed approach."
                },
                "questions": {
                    "value": "N/A"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8969/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698521273959,
            "cdate": 1698521273959,
            "tmdate": 1699637129610,
            "mdate": 1699637129610,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tiV3w24WJR",
                "forum": "vXf8KYTJmm",
                "replyto": "0PXnk0xrlF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8969/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8969/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your review"
                    },
                    "comment": {
                        "value": "Thank you for your time in reviewing and considering our topic interesting. We address your concerns below and we also have updated the draft to make the presentation cleaner with additional results to support our findings.\n\n### Poor presentation\nThank you for the detailed feedback here, we have addressed the problems in the updated draft.\n\n### Theoretical analysis\nWe motivated our problem and analysis via several examples related to various considerations for natural language processing in Section 2. SVO is a common abbreviation used by linguists and NLP researchers to characterize a language that typically arranges information in a \u201csubject verb object\u201d order in the sentences. We have reworded the writing to make it clear we were referring to the preceding example in the text.\n\nRegarding the mathematical derivations not being enough, our goal in Section 2 is simply to show that the bad mode problem can arise in the absence of model error. This does not require an involved calculation, as it\u2019s clear that a large set of valid outputs can easily be dominated by a small set of noise sequences, even with a tiny mixing rate. There is value in presenting this to the community, as it is an underappreciated point. Most prior work on the topic makes the inference that \u201cbad mode\u201d implies \u201cmodel error\u201d, which has led to a dearth of research on approximate-MAP methods.\n\n### Human Evaluation\nWe have expanded our evaluation to include several other informative metrics for our experiments.\nIn section 5.2.1, we primarily focused on likelihood because we wanted to emphasize that constrained beam search is not an appropriate method for performing length-constrained MAP. We found that ACBS finds sequences which are higher likelihood, and the large number of randomly sampled examples we present do show the trend of ACBS finding more grammatical translations. However, we appreciate your concern that his is not sufficiently convincing, so we have added BLEURT/BLEU scores in the updated draft (Table 3b). ACBS outperforms constrained beam search significantly on the BLEURT metric which captures fluency and well-formedness unlike BLEU (which only considers n-gram precision with a heuristic brevity penalty). We also provide perplexity measurements of the translations under Llama2-7B and find that ACBS results in higher quality sequences under this metric as well (Table 3c).\n\nWe also provide further evidence that ACBS leads to improved outputs from LLaMA-7B, a model which was not trained for instruction following. Specifically, we perform a blinded pairwise comparison between the outputs under standard beam search and those found by ACBS, using both GPT-4 and one of the authors. In a camera-ready version we will expand the human evaluation.\n\n### Context length limits for evaluation\nWe agree that experiments using more computational resources would be necessary to establish ACBS as a state-of-the-art decoding method. However, we actually view the ACBS experiments as supporting the preceding sections, rather than the other way around. Prior work has suggested that we should abandon MAP-like methods in favor of sampling-based ones, due beam search\u2019s failure to produce good outputs in tasks less constrained than machine translation, and its failure in even MT at large beam sizes. (For example, see Holtzman et al. (2020), Stahlberg and Byrne (2019), and Eikema and Aziz (2020)).\n\nIn this work, we use ACBS as a preliminary indication that the choice to drop MAP was premature, as we suggest in the title of the paper. Our ideal outcome from this paper wouldn\u2019t be that everyone stops using nucleus sampling and switches to ACBS tomorrow. Instead, we hope to spur future work on improved MAP-like methods.\n\n### Lack of details in experiments\nThe space constraints made it difficult for us to include extensive details for a lot of aspects of the paper\u2019s contents. In the original draft, we included extensive details in the appendix as well to complement the claims, experiments, and arguments in the main body. \nHowever, we would like to point out that we attempted to provide sufficient details in the main body of the original draft- sections 5.2, 5.3, 3, and 3.1. Additionally, we provided more extensive details about our experiment setup in the Appendix sections G and D, as well as giving pointers to them in the Reproducibility section. \n\nTo the specific question about training examples for the LLaMA-7B classifier, 14,000 training examples were produced using vanilla beam search on inputs from the databricks-dolly-15k dataset.The number of training examples was stated in the body of the text, but we have added it to Appendix G along with the other details to make it easier to find.\n\nThank you once again for your detailed feedback, we believe it has helped us produce a much better draft, especially through the addition of more evaluations of our system outputs."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8969/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700605843026,
                "cdate": 1700605843026,
                "tmdate": 1700605843026,
                "mdate": 1700605843026,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9vb47WfiWq",
            "forum": "vXf8KYTJmm",
            "replyto": "vXf8KYTJmm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8969/Reviewer_3nJt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8969/Reviewer_3nJt"
            ],
            "content": {
                "summary": {
                    "value": "This paper shows that degenerate modal outputs are not necessarily an intrinsic property of language models themselves, but rather are likely a result of contamination in the training data. For improving the quality of text decoded from language models, the paper introduce an algorithm called ACBS (attribute-conditional beam search), which adds an additional constraint on the output to avoid the degenerate behavior. The experiment shows that ACBS are better than ordinary beam search and especially contirbutes to ameliorate empty-string degenerate behavior."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This paper provides a very detailed explanation to the model architecture, algorithms, and experimental data in the appendix, which is very useful for helping readers to understand the paper\u2019s work. \n2. Derivation and motivation are clear. Point out the phenomena and causes of degeneracy problem at the beginning and then solve it later.\n3. This paper is logical and flowing. The location and analysis of degeneracy problem are given progressively.\n4. The analysis of the low-entropy distractor is concise and easy to understand with examples.\n5. The experimental setup follows intuition, and argumentation process is basically based on experiments."
                },
                "weaknesses": {
                    "value": "1. Missing experimental data in 5.3. The detailed experiment result about the comparison between ACBS and regular beam search should be compared in a table instead of directly stating the data in the paragraph. Otherwise, your results won't be convincing.\n2. In 3.2.1, figure 1a and figure 1b just represents the increase of empty sequence with source length, lack of the curve that shows the decrease of empty output with source length to better support the conclusion.  \n3. Lack of explaination about the difference between empty mode and empty output.\n4. The paper only gives two examples to illustrate that low-entropy distractor outputs and empty outputs have a high log prob in section 2 but does not provide enough mathematical reasoning, so the argument that the degenerate modal behavior is related to the entropy of the set of valid outputs is not strong enough.\n5. In section 3, the x-axis and y-axis markings in Figure 1a are not clear and Figure 1a does not offer enough support for the observed phenomenon that the probability of the empty sequence declines as the source length increases. The experiments in section 3 do not indicate the impact of contamination of the training data, which is emphasized in the abstract and conclusion."
                },
                "questions": {
                    "value": "1. At the end of Section 3, how can we conclude that the degenerate modal behavior is related to the entropy of the set of valid outputs?\n2. Exact search experiments are meaningful, but the result that exact search performs good is not relevant to Subsequent Chapters. Maybe their relevance should be emphasized by experiments in terms of computational cost.\n3. The experiment to prove that ACBS not only benefit from removing empty outputs should be detailed."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8969/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8969/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8969/Reviewer_3nJt"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8969/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698538658929,
            "cdate": 1698538658929,
            "tmdate": 1699637129487,
            "mdate": 1699637129487,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xhljoCuoSX",
                "forum": "vXf8KYTJmm",
                "replyto": "9vb47WfiWq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8969/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8969/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your review"
                    },
                    "comment": {
                        "value": "Thank you for your time in reviewing this paper and for your kind words about the structure of the paper and argumentation. Below, we address some of the concerns you raised:\n\n### Presentation and analysis of results\nThanks for pointing out that the empirical comparison between regular beam search and ACBS doesn\u2019t appear to be detailed from our in-text description in the original draft. In our updated draft, we report the results in Table 5, and additionally. \n\nPlease see our overall response to the reviewers for a description of the other newly added evaluations.\n\n### Elaboration on figures 1a) and 1b) and other terms used in the paper\nWe have re-added a figure which was cut to make this explicit. Figure 2 in the appendix now shows that the probability of the empty output declines with source length. Despite this, the rate at which the mode is empty increases, which is not surprising in light of our analysis in Section 2.\n\nThe term \u201cempty output\u201d refers to the output of any decoding method being empty, while an \u201cempty mode\u201d describes the case where the empty sequence is the single most likely output.\n\n### Connection between our results and low-entropy distractors\nThe entropy of a distribution is just the average of the negative log likelihood of a sample, so what we do in Section 2.1 is compare how two distributions with different entropies react to a small amount of noise. We did not have space to get into this, but in practice what one needs is high-entropy PLUS the distribution of valid outputs is not too \u201cnon-uniform\u201d. Since we don\u2019t have analytic access to the population distribution for realistic datasets, we aren\u2019t trying to show that the bad mode problem only arises from noise in the data. Instead, we just want to give enough argumentation to show that the inference \u201cbad model mode -> the model has mis-estimated the mode of the distribution\u201d is not true. It is important that this point becomes internalized by the community of NLG researchers, as it strongly affects how we interpret prior findings such as Stahlberg and Byrne (2019).\n\nAdditionally, we now also refer to Ott et al. (2018) for another example of a low entropy distractor. In their work, adding a small fraction of training examples where the reference translation is a copy of the source sentence leads to an outsized impact on search outputs. This is just what our analysis predicts, but they do make the theoretical argument for why this _must_ happen in certain cases, depending on the noise rate and entropy/likelihood of the valid outputs.\n\n### Question 1\n> At the end of Section 3, how can we conclude that the degenerate modal behavior is related to the entropy of the set of valid outputs?\nWe cannot conclusively conclude that, but entropy is roughly equivalent to there being a larger set of valid answers. As we note, the degenerate mode behavior occurs more frequently for more open-ended prompts and longer source sentences for translation (see Figure 1a), but which we argue is suggestive, but not conclusive that the entropy plays a large role.\n\n### Question 2\n> Exact search experiments are meaningful, but the result that exact search performs good is not relevant to Subsequent Chapters. Maybe their relevance should be emphasized by experiments in terms of computational cost.\nWe open Section 5 by stating \u201c DFS-related approaches are too expensive to be practical in NLG applications, especially so for the conditioning variables that force high amounts of backtracking.\u201d Does this help with the connection between sections? If not, we can emphasize this further in the writing.\n\n### Question 3\n> The experiment to prove that ACBS not only benefit from removing empty outputs should be detailed.\n\nThe experiment to prove that ACBS not only benefit from removing empty outputs should be detailed\nWe in fact controlled for this by making our baseline stronger in empirical comparison! By \u201crestrict our attention\u201d in paragraph 2 of Section 4, we meant that we dropped any examples from our analysis for which beam search (baseline) produces an empty output. This gives the beam search baseline a large advantage, since it isn\u2019t penalized for this failure mode, but ACBS still finds an improved output much more often. As we mentioned above, we have additional results about the quality of generated outputs evaluated by GPT-4 and humans to further support our claims.\n\n\n\nThank you for the helpful comments and questions, we believe they have helped us significantly improve our manuscript."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8969/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700606127124,
                "cdate": 1700606127124,
                "tmdate": 1700606127124,
                "mdate": 1700606127124,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "09TuTXttR0",
            "forum": "vXf8KYTJmm",
            "replyto": "vXf8KYTJmm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8969/Reviewer_mRtz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8969/Reviewer_mRtz"
            ],
            "content": {
                "summary": {
                    "value": "This paper argues that one source of so-called text degeneration is contamination of the training data with low-entropy noise, such as empty or nearly empty completions, or partial or total repetitions of the prompt. It substantiates this claim by performing exact MAP decoding, including on LLaMA. It offers a decoding solution, which is to do exact or beam search decoding with constraints on \"attributes\" like length."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "Overall, I really like this paper and favor acceptance.\n\nThe experiments with exact search provide convincing evidence of the claim about low-entropy strings. These experiments are also valuable because they reveal a new kind of degeneracy (copying the prompt) and they are the first to perform exact decoding on a large language model.\n\nThe observation that sampling has the opposite \"Achilles' heel\" is valuable, although not really the focus of this paper.\n\nThe attribute-constrained beam search algorithm is new. It's a nice idea that has essentially the same running time as standard beam search, and seems to work well. It's interesting that the example length-conditioned translations are good summaries of translations."
                },
                "weaknesses": {
                    "value": "The explanation of degeneracy in terms of low-entropy strings is not new, and the authors may not be aware of the following two papers:\nOtt, https://arxiv.org/abs/1803.00047\nHoltzman, https://arxiv.org/abs/2104.08315\n\nAs an alternative to your decoding method, you could use an adaptive beam, using a wider beam for earlier timesteps that gets narrower for later timesteps. Then at timestep $a$, you would get higher-quality outputs with length $a$. I am not sure what schedule you would use for the beam size, but perhaps work by Brian Roark for adaptive beams in CKY parsing is relevant.\n\nThe evaluation of the attribute constrained beam search method for LLaMA consists of recording what percent of sentences get a higher reward according to the same reward model used in training, and giving a general subjective impression of sample outputs. I think this is a fairly weak evaluation, and it would be a lot better to elicit quality judgements from other people.\n\nStyle / minor points:\n\nThere is too much important information in the appendix, especially Algorithm 1, with many references from the text to the appendix.\n\nEveryone has their own writing style, but I feel that there are too many exclamation points for an academic paper. There are even two sentences in a row with exclamation points on page 4, but this is probably just an editing error."
                },
                "questions": {
                    "value": "table 2: how can truncated beam search be better than itself?\n\ntable 3: why do the TBS translations seem shorter?\n\n5.3.1 In the example, the source sentence in the prompt is \"I love machine learning,\" but the output translates the source sentence \"My eyes are clear.\" Is that really what happened?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8969/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698772323003,
            "cdate": 1698772323003,
            "tmdate": 1699637129343,
            "mdate": 1699637129343,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0fCmSF6mwU",
                "forum": "vXf8KYTJmm",
                "replyto": "09TuTXttR0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8969/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8969/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your review"
                    },
                    "comment": {
                        "value": "Thank you for your time in reviewing this paper and recognizing the positive aspects of our work! In our updated draft, we provide additional results based on more in depth evaluation and human judgements to further support our claims. Below we respond to your concerns and questions:\n\n### Additional related work\nWe have added brief discussion of both papers you referenced in our updated draft. Ott et al.\u2019s work aligns precisely with the behavior we would expect, although they don\u2019t make the generalization to low-entropy noise in general. \n\n### Alternative to decoding method\nThe suggestion of an adaptive beam size is an interesting one, and should certainly be investigated. Note that if the empty sequence or any other short distractor is the problem, the beam size must start small. On the other hand, for a problem such as repetition of the prompt, a different heuristic may be necessary. These methods (and others such as length-normalization) generally need to be tailored quite closely to the exact degeneracy being combatted.\n\n### Evaluation with reward model\nWe agree with your concern about evaluation based on our reward model. In our updated draft, we report additional metrics that support our claims. In Table 5, we additionally report the results of blinded pairwise comparisons made by GPT-4 and one of the authors. (In a camera-ready version we will add additional human annotators). See also our overall response for other evaluations we have added.\n\n### Style\nWe agree that it is not ideal to put so much content in the Appendix, but we were not able to accommodate it in the main text. We have also cleaned up the writing style in several places per your remarks.\n\n### Table 2 question\nWe realize that the presentation of these results might be confusing. The way to read this is that B=5 and length ratio 0.8, ACBS wins 56.9 % of the time and TBS wins 35.5. % (remaining 7.6% are ties), and for B=20 and length ratio 0.8, ACBS wins 57.8 % of the time and TBS wins 29.1 % (remaining 13.1% are ties). We have  made this clearer in the updated draft.\n\n### Table 3 question\nThe apparent discrepancy in length is due to the tokenizer splitting \u201cIt\u2019s\u201d into 3 tokens. For example:\n\n['\u2581Andr', 'ada', '\u2581said', ':', '\u2581\"', 'It', '\u2019', 's', '\u2581not']\n['\u2581Andr', 'ada', '\u2581said', ':', '\u2581\u201c', 'It', '\u2581does', '\u2581not', '.']\n(Both 9 tokens, excluding EOS)\n\n### \"I love ML\" question\nOur original example used the sentence \u201cI love machine learning\u201d in the prompt, but we switched it to \u201cMy eyes are clear\u201d once we decided to submit to ICLR.\n\nThank you once again for your feedback and questions. The additional references in particular have helped quite a bit."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8969/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700606312699,
                "cdate": 1700606312699,
                "tmdate": 1700606312699,
                "mdate": 1700606312699,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0NqLnFcFy6",
            "forum": "vXf8KYTJmm",
            "replyto": "vXf8KYTJmm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8969/Reviewer_YHYo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8969/Reviewer_YHYo"
            ],
            "content": {
                "summary": {
                    "value": "The authors provide analysis of why text generation models often suffer degenerated distribution mode. They attribute the problem to the contamination in the training data sampled from natural language distribution. They further find that the bad mode problem is alleviated when conditioned on a certain target length. To this end, the authors propose an attribute-conditional beam search algorithm which exhibits superiority compared with truncating methods when target length is given."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The authors provide a detailed analysis of bad mode problem.\n2. The authors propose an attribute-conditional beam search algorithm which exhibits superiority compared with truncating methods when target length is given. \n3. The authors conduct experiments on various NLP tasks."
                },
                "weaknesses": {
                    "value": "1. **Analysis less than convincing in supporting the \"*bad mode problem*\"**.  \nIn Section 2, the authors claim that introducing noise into the data distribution can lead to model degeneration, even when the model is perfectly trained to fit the original data distribution. The authors provide examples to illustrate this concept. However, I found some of these analyses less than convincing. In Section 2.1, the authors argue that \"*If one in a billion sequences is replaced with a bad output, MAP on a perfectly trained model should give us one of the bad outputs*\". However, this argument relies on the assumption that \"*there might be 2^100 possible abstracts for a given scientific paper*\". It seems such an assumption never holds true in the case of a real dataset. In contrast, there is only one reference for a source in the typical setting.\n\n2. **Unclear logic between Section 2 & 3.**  \nIn Section 3.2, the authors provide experimental results that \"*the occurrence of empty sequences increases with source length*\". The authors attribute the empty mode problem to that \"*the entropy of valid outputs increases with input length, but the probability of the empty output does not decline enough*\". I am confused that this may contradict the analysis in Section 2 that attributes the bad mode to \"*low-entropy distractors*\".\n\n3. **Experiments are not serious**.  \n**a.** In Section 3.2.1 & Section 4, the authors conduct qualitative analysis only based on case study, lacking rigorous analysis and discussion.  \n**b.** In Section 5.2.1, the authors compare their proposed attribute-conditional beam search with truncated beam search when a target length is provided. The comparison is based solely on the log-likelihood of the search results, without considering the evaluation of generated quality, such as BLEU scores. This evaluation seems insufficient, especially considering the background that a language model's mode can lead to degenerated results. Furthermore, there's no comparison between the proposed attribute-conditional beam search and standard beam search (without length truncating, evaluated with both likelihood and BLEU), which appears to be weird and not convincing.\n4. **Concerns on the motivation and novelty.**  \n**a.** The authors proposed a length-conditioned beam search algorithm. However, this seems not very helpful to solving the bad mode problem in LLM, as a pre-determined length may be imprecise and lack the flexibility.  \n**b.** The novelty of proposed attribute-conditional beam search is limited. Those attribute-conditional sampling methods is well-studied, and the authors only adapt it to the beam search.\n5. **The paper has too many typos**.  \n**a.** Please check the format (should use ICLR 2024)  \n**b.** Confused paragraph numbering (Section 3.1 & 3.1.1)  \n**c.** wrong citing format"
                },
                "questions": {
                    "value": "Please see the weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8969/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8969/Reviewer_YHYo",
                        "ICLR.cc/2024/Conference/Submission8969/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8969/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698822688895,
            "cdate": 1698822688895,
            "tmdate": 1700739741129,
            "mdate": 1700739741129,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UmnZxvnu5T",
                "forum": "vXf8KYTJmm",
                "replyto": "0NqLnFcFy6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8969/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8969/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your review"
                    },
                    "comment": {
                        "value": "Thank you for taking the time to review our paper, providing helpful feedback, and recognizing the detail in which we address the issue of modal sequences in LMs. We have tried to **eliminate the typos** in our newly posted draft and addressed some of your concerns as well.\n\n### Motivation and novelty\n(See the overall response to reviewers for an explicit list of novel contributions).\n\nWe see ACBS as an individual supporting piece of evidence to the overall story, rather than the main novel contribution of the paper. Namely it suggests that our insights and empirical results can be used to drive the design of future MAP-like decoding algorithms. Currently, the decoding algorithms in common use are either sampling based (top-k sampling, top-p sampling, locally typical, FUDGE), or try to maximize some score (Reward-augmented beam search, Monte-Carlo tree search, or the recent methods suggested by Deng and Raffel, 2023, and Mudgal et al., 2023). Here, we point towards another possible class of algorithms: those which     search for sequences of maximal likelihood under a constraint.\n\nThe community has largely stopped trying to improve on this class of algorithms, due to what we argue are misconceptions about the reason for degenerate modal sequences. As we argued in Section 2, MAP-like methods have certain desirable properties in terms of controlling noise. We hope that the results we share here will urge the community into further research on this class of algorithms.\n\n### Concerns about the evaluation of search outputs\n\nIn Section 5.2.1, we primarily focused on likelihood because we wanted to emphasize that constrained beam search is not an appropriate method for performing length-constrained MAP finding since our approach can find higher likelihood sequences under the unspecified length-conditional distribution. While it is true that mode of the MT model might be of bad quality, in the sections prior to ACBS, we show that *conditional* modes ameliorate the bad mode problem. Hence, we only reported likelihood scores in our first draft. \n\nTo further increase the confidence in this finding, we have added quantitative evaluations throughout our experiments. Please see our summary response for a description of the newly added evaluations.\n\n### Comments on the example of bad mode problem\nRegarding there only being one reference output in NLG datasets, we are not referring to dataset themselves, but the *population distribution*. We view a dataset as a sample from some population distribution, in line with the common formalism of machine learning. Even in a task like sentence-level machine translation, there are a large number of valid outputs for any given input. So while we only observe one reference, our hope is that our models will learn the population conditional distribution of outputs given inputs. Even for a one word \u201csentence\u201d, the translations: \u201cYes\u201d, \u201cThat\u2019s right\u201d, \u201cOkay\u201d, \u201cSure\u201d, \u201cIndeed\u201d and so on may be possible. Which one is exactly correct may depend on things such as the translator\u2019s style, and context which exists outside the sentence level. This set of valid translations explodes in size once we move to full sentences, and is astronomical if one considers a paragraph or full document. In order to reach the 2^100 number for writing scientific abstracts, it just needs to be the case that one makes at least 100 choices with at least 2 options during the process.\n\nOur key point here is that it is necessary that modeling these distributions well also makes the mode of the model more vulnerable to noise.\n\n### Logic between Section 2 and 3\nThe empty sequence is such a low-entropy distractor (more generally you could consider the set of truncated translations of 0-2 tokens to be the set of distractors).\nThe number of valid translations for a 30 token input will be enormous, so despite the fact that the probability of the low-entropy set declines (See the newly added Figure 2), the entropy of the good outputs increases too fast. Entropy increasing is the same thing as the average log-likelihood decreasing, so this could equivalently be stated as: The likelihood of a typical good translation decreases with length faster than the likelihood of the distractors decreases with length.\n\nThank you once again for taking the time to give us detailed feedback on our work."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8969/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700605589708,
                "cdate": 1700605589708,
                "tmdate": 1700605589708,
                "mdate": 1700605589708,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YQUhuP3k8F",
                "forum": "vXf8KYTJmm",
                "replyto": "UmnZxvnu5T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8969/Reviewer_YHYo"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8969/Reviewer_YHYo"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your reply. \n\n\n\n\nAccording to your comment, you view a dataset as a sample from some population distribution. However, the discussion of the bad mode problem in Section 2 is framed within the context of limited data. I find there is a potential contradiction. In my opinion, with an unlimited amount of data (e.g. the real-world distribution), even if there are some noises, I think the distribution would not experience the bad mode problem. I am willing to have more discussion, however your reply is submitted a little late. In any case, I have decided to raise my score to 5."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8969/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700741476760,
                "cdate": 1700741476760,
                "tmdate": 1700741476760,
                "mdate": 1700741476760,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]