[
    {
        "title": "Out-of-Distribution Detection & Applications With Ablated Learned Temperature Energy"
    },
    {
        "review": {
            "id": "esyA55vL4W",
            "forum": "wFPfYccHJ1",
            "replyto": "wFPfYccHJ1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission319/Reviewer_yXfA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission319/Reviewer_yXfA"
            ],
            "content": {
                "summary": {
                    "value": "This paper contributes a new OOD detection algorithm based on energy score. It first equips the energy score with a trainable temperature. It then analyze the effect of forefront temperature and exponential divisor temperature in energy score by pointing out that the exponential divisor temperature is desired while forefront temperature is not. The trainable term is thus only for the exponential divisor temperature."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. The empirical performance of the work is good, especially in the segmentation task. \n2. The discussion of the forefront temperature and exponential divisor temperature is reasonable. \n3. It seems this method is able to perform well without a knowing the OOD samples for training/fine-tuning."
                },
                "weaknesses": {
                    "value": "The work in general seems to be incremental.\n1. This work trains an objective similar to generalized ODIN and uses an energy score with trained temperature for OOD detection. A theoretical analysis between ODIN seems to be missing. For example previous energy score pointed out it was better than the maximum confidence score because of the contradiction of maximum logit and energy score. Even if it has, the contribution will still be limited. \n2. Sec 5 only addresses the empirical understanding rather than theoretical."
                },
                "questions": {
                    "value": "1. (For weakness 1) Why using energy score with trainable temperature for energy-score is better than the OOD score in generalized ODIN? Maybe following this idea? What determines the performance in energy score is mainly the logsumexp of the logits, rather than temperature. Thus, its analysis was mainly in the denominator of the softmax function and temperature does not play a major role there. Given this fact/approximation, I feel like the function $\\hat f_{y_i}(x_i; \\theta)$ (just below equ(1)) could be analyzed similarly. Taking the log of $\\hat f_{y_i}(x_i; \\theta)$, we will have two terms, one of which will be the AbeT score. \n2. Given the similarity between Generalized ODIN and energy score, it seems the really interesting result to me is it seems it does not need OOD samples during training.  (2.1) Can you confirm this? (2.2) If so, can you explain why the trained temperature only could change the OOD performance theoretically? If this explanation is convincing, it may be more important than the empirical perspectives of the methods."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission319/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission319/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission319/Reviewer_yXfA"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission319/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698042035783,
            "cdate": 1698042035783,
            "tmdate": 1699637379362,
            "mdate": 1699637379362,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "T9omzIinkU",
                "forum": "wFPfYccHJ1",
                "replyto": "esyA55vL4W",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission319/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission319/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the comments! In general it sounds like you would like to see a more clear and/or rigorous theoretical interpretation as to why Abet works and potentially compared to ODIN. Is the explanation in section 3 not sufficient in providing intuition? If so, the authors would be happy to formalize this intuition into a theorem."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission319/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700504068372,
                "cdate": 1700504068372,
                "tmdate": 1700504068372,
                "mdate": 1700504068372,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0F8QtzSEsC",
            "forum": "wFPfYccHJ1",
            "replyto": "wFPfYccHJ1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission319/Reviewer_Jfeb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission319/Reviewer_Jfeb"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes the Ablated Learned Temperature Energy (or \"AbeT\" for short) for out-of-distribution detection. AbeT comprises two components: a learned temperature and an ablated energy score. Abet significantly boosts OOD detection performance, and shows efficacy in identifying OOD samples in object detection and semantic segmentation."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The method is simple and the performance is promising. \n2. The visualization on object detection and semantic segmentation is interesting."
                },
                "weaknesses": {
                    "value": "1. The idea of learned temperature has been fully studied in previous works like GODIN (Liu et al., 2020). This paper seems to be an incremental work.\n2. In figure 1, as the Learned Temperature contradicts with energy score, how about using the negative temperature to boost the energy, rather than simply ablating the temperature?\n3. The experimental results should be further discussed. For example, in Table 1, as vanilla AbeT achieves 40% of FPR95 in ImageNet-1k, why a simple combination with ASH leads to such a surprising 3.7% of FPR95?"
                },
                "questions": {
                    "value": "Please check the weakness section above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission319/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698722944291,
            "cdate": 1698722944291,
            "tmdate": 1699637379252,
            "mdate": 1699637379252,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "D0S86Nhy7J",
                "forum": "wFPfYccHJ1",
                "replyto": "0F8QtzSEsC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission319/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission319/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## Weakness 1\n* Reviewer comment: The idea of learned temperature has been fully studied in previous works like GODIN (Liu et al., 2020). This paper seems to be an incremental work.\n* Response: It is true that the idea of a learned temperature has been studied in GODIN. However, this is the first work where it is combined with an energy score. We additionally contribute the dropping of the forefront temperature constant. And we adapt our score the semantic segmentation and object detection settings.\n\n## Weakness 2 \n* Reviewer comment: In figure 1, as the Learned Temperature contradicts with energy score, how about using the negative temperature to boost the energy, rather than simply ablating the temperature?\n* Response: we attempted using various inversion techniques on the temperature, but found that performing the ablation performs approximately the same as all of our tested inversion techniques. This is because our AbeT score already is inversely proportional to the learned temperature, as a result of the exponential divisor term.\n\n## Weakness 3\n* Reviewer comment: The experimental results should be further discussed. For example, in Table 1, as vanilla AbeT achieves 40% of FPR95 in ImageNet-1k, why a simple combination with ASH leads to such a surprising 3.7% of FPR95?\n* Response: In the original ASH paper [1], ASH-S 95.12 is already at AUROC using ImageNet-1k as their ID dataset. As can be seen in Table 1 of our manuscript, we found a similar result in combining Energy and ASH, with a slight improvement to 96.59 AUROC. Given that AbeT is a significant improvement upon Energy (as can be seen by our performance metrics), we find that this jump from 96.59 of Energy + ASH to 99.00 AUROC of AbeT + ASH to be in alignment with other experiments and literature. \n\n[1] Djurisic, Andrija, et al. \"Extremely simple activation shaping for out-of-distribution detection.\" arXiv preprint arXiv:2209.09858 (2022)."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission319/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700157104135,
                "cdate": 1700157104135,
                "tmdate": 1700504053288,
                "mdate": 1700504053288,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5b0G6US8PR",
            "forum": "wFPfYccHJ1",
            "replyto": "wFPfYccHJ1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission319/Reviewer_NVtq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission319/Reviewer_NVtq"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses the critical task of identifying Out-of-Distribution (OOD) inputs in deep neural networks. The authors introduce \"AbeT\" (Ablated Learned Temperature Energy), a method that combines existing techniques without complex training stages or additional hyper-parameters. Specifically, the proposed method combines the use of learned temperature parameters and energy scores for OOD detection. Crucially, it proposes a simple adjustment to the way energy score is computed with temperature parameters, leading to empirically demonstrated gains. AbeT significantly reduces false positives in classification, surpassing state-of-the-art methods. It also offers insights into how it learns to distinguish ID and OOD samples. Moreover, AbeT demonstrates improved performance in object detection and semantic segmentation tasks, making it a valuable tool for model robustness in critical domains."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Empirical Results: The paper supports its claims with empirical results, demonstrating the practical benefits and effectiveness of AbeT across multiple datasets and tasks.\n\n- Insightful Model Behavior Analysis: The paper provides valuable insights into how the model learns to distinguish between In-Distribution (ID) and OOD samples, contributing to a better understanding of model behavior.\n\n- General Applicability: The method's versatility is showcased by its successful application in object detection and semantic segmentation tasks, highlighting its potential for various computer vision applications.\n\n- Simplicity and Efficiency: Unlike some methods that require complex training stages, hyperparameters, or test-time backward passes, AbeT offers simplicity and efficiency in OOD detection, making it more practical for real-world applications."
                },
                "weaknesses": {
                    "value": "- Lack of novelty: While being able to achieve good performance empirically, the proposed method is a simple adaptation of two existing methods. \n\n- Lack of theoretical justifications: While empirically proven, the proposed decision on dropping Forefront Temperature Constant, a crucial part of the proposed method, lacks theoretical justifications. \n\n- Formatting: the paper is not in the ICLR conference formatting."
                },
                "questions": {
                    "value": "- Based on my understanding of table 1, no ablation study was done to compare the effect of dropping Forefront Temperature Constant. How does the performance of Energy + learned temperature compare to the proposed AbeT?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission319/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698810395400,
            "cdate": 1698810395400,
            "tmdate": 1699637379158,
            "mdate": 1699637379158,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Zt651nyfY9",
                "forum": "wFPfYccHJ1",
                "replyto": "5b0G6US8PR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission319/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission319/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## Weakness 1\n* Reviewer comment: While being able to achieve good performance empirically, the proposed method is a simple adaptation of two existing methods.\t\n* Response: We do acknowledge that our method is simple. However, we view simplicity in the presence of efficacy as far superior to complexity in the presence of efficacy.\n\n## Weakness 2\n* Reviewer comment: Lack of theoretical justifications: While empirically proven, the proposed decision on dropping Forefront Temperature Constant, a crucial part of the proposed method, lacks theoretical justifications.\n* Response: we ask of the reviewer if the explanation in section 3 is not sufficient in providing intuition. If so, the authors would be happy to formalize this intuition into a theorem.\n\n## Weakness 3: \n* Reviewer comment: Formatting: the paper is not in the ICLR conference formatting.\n* Response:If accepted, we will change the formatting to be according to the ICLR template.\n\n## Question 1\n* Reviewer comment: Based on my understanding of table 1, no ablation study was done to compare the effect of dropping Forefront Temperature Constant. How does the performance of Energy + learned temperature compare to the proposed AbeT?\n* Response: please see Appendix Table 10 for results of energy + learned temperature with and without ablation, as requested"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission319/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700157069267,
                "cdate": 1700157069267,
                "tmdate": 1700503966960,
                "mdate": 1700503966960,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "t3zkwLLCfK",
            "forum": "wFPfYccHJ1",
            "replyto": "wFPfYccHJ1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission319/Reviewer_HZpi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission319/Reviewer_HZpi"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents an ablated learned temperature energy for OOD detection. The paper is built on two existing works in OOD detection, which rely on a learned temperature and an energy score. The paper argues that the existing work does not consider any OOD examples while estimating the temperature; hence, it proposes to learn based on an input. The method is evaluated on multiple OOD datasets considering CIFAR-10, CIFAR-100, and Imagenet-1k as domain data sets. Experimental results show the method surpasses the existing methods."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "OOD detection is an important research problem and can be of interest to a large audience.\n\nThe paper compares the performance with several existing methods on multiple benchmarks."
                },
                "weaknesses": {
                    "value": "Combining existing methods does not make the contribution less significant. However, I am not convinced that making the hyper-parameter learnable is a solid contribution. It is also unclear how the parameters of temperature are optimized and what the learning behaviour looks like.\n\nThe paper proposes to make the temperature of the existing method learnable, which is a decent contribution; however,  given the number of high-quality submissions that we receive in the ICLR, it can be challenging to find a spot in the main conference. \n\nThe paper lacks insight into how the learnable temperature varies with different inputs.\n\nSometimes, the paper is difficult to follow. \n\nThe paper does not use the correct template of ICLR, although this does not have any role in my final rating."
                },
                "questions": {
                    "value": "Please see the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission319/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698957861847,
            "cdate": 1698957861847,
            "tmdate": 1699637379043,
            "mdate": 1699637379043,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "od6yxSHXgS",
                "forum": "wFPfYccHJ1",
                "replyto": "t3zkwLLCfK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission319/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission319/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## Weakness 1\n* Reviewer comment: Combining existing methods does not make the contribution less significant. However, I am not convinced that making the hyper-parameter learnable is a solid contribution. It is also unclear how the parameters of temperature are optimized and what the learning behaviour looks like.\n* Response: Please see Section 2.3.1 on how the parameters of the temperature are optimized\n\n\n## Weakness 3\n* Reviewer comment: The paper lacks insight into how the learnable temperature varies with different inputs.\n* Response: please see our explanation at the bottom of Page 4, pasted here for convenience: \u201cWe note that the learned temperature is trained to be higher on inputs on which the classifier is uncertain - such as OOD and misclassified ID inputs - in order to deflate the softmax confidence on those inputs (i.e. increase softmax uncertainty); and the learned temperature is trained to be lower on inputs on which the classifier is certain - such as correctly classified ID inputs - in order to inflate the softmax confidence on those inputs (i.e. increase softmax certainty).\u201d \n\n## Weakness 4\n* Reviewer comment: Sometimes, the paper is difficult to follow.\n* Response: we welcome any specific suggestions as to sections that the reviewer found difficult to follow\n\n## Weakness 5\n* Reviewer comment: The paper does not use the correct template of ICLR, although this does not have any role in my final rating.\n* Response:  If accepted, we will change the formatting to be according to the ICLR template."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission319/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700157009416,
                "cdate": 1700157009416,
                "tmdate": 1700503891504,
                "mdate": 1700503891504,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]