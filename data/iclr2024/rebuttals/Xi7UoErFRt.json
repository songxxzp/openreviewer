[
    {
        "title": "FedGP: Buffer-based Gradient Projection for Continual Federated Learning"
    },
    {
        "review": {
            "id": "om8OeYrbSK",
            "forum": "Xi7UoErFRt",
            "replyto": "Xi7UoErFRt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5562/Reviewer_sEUN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5562/Reviewer_sEUN"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a approach called FedGP for addressing the challenge of catastrophic forgetting in Continual Federated Learning, where decentralized clients learn from continuous data streams. FedGP aims to preserve knowledge across clients by leveraging local buffer samples and aggregated buffer gradients. This method enhances the performance of existing continual learning and CFL techniques and demonstrates performance improvements on standard benchmarks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The experiment part is comprehensive and solid. The authors compare the proposed method with various baselines on a number of tasks. The experiment details and results are well presented and explained. The authors also report the storage, communication, computation overhead of the proposed methods, which is great importance to show the efficiency of the proposed method."
                },
                "weaknesses": {
                    "value": "1. The novelty of the proposed method is questionable. The key steps of the proposed FedGP algorithm, including using buffers and performing gradient projection, can all be found in previous works [1]. The only major difference, as far as I can tell, is to extend the centralized setup in [1] to a decentralized/federated setup.\n2. The algorithm design of FedGP is mostly heuristic and not well motivated. For example,  the authors do not rigorously explain why the gradient projection operation and the buffer updating algorithm will solve the catastrophic forgetting problem and  fit into the FL setting. A theoretical analysis and more ablations on algorithm design will help to show the effectiveness of FedGP.\n3. I am skeptical about whether the use of a buffer can solve the problem of catastrophic forgetting. Since the buffer size is limited, one is unable to store the entire past information in it, and has to discard stale information. According to Algorithm 4, when the buffer is full the algorithm randomly selects an old entry in the buffer and replace it with a new data point. How can this avoid discarding useful information, e.g., the data point stored in previous rounds? \n\n[1] Arslan Chaudhry, Marc\u2019Aurelio Ranzato, Marcus Rohrbach, and Mohamed Elhoseiny. Efficient lifelong learning with A-GEM."
                },
                "questions": {
                    "value": "See the weaknesses part"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5562/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5562/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5562/Reviewer_sEUN"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5562/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698113126281,
            "cdate": 1698113126281,
            "tmdate": 1699636572134,
            "mdate": 1699636572134,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "E4INzbtZ1Y",
                "forum": "Xi7UoErFRt",
                "replyto": "om8OeYrbSK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5562/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5562/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the Reviewer for the detailed review and constructive suggestions. We appreciate your acknowledgement that the experiment part is comprehensive, solid and well-written. Our responses are detailed below.\n\n**`Q1: The novelty of the proposed method is questionable. The key steps of the proposed FedGP algorithm, including using buffers and performing gradient projection, can all be found in previous works [1]. The only major difference, as far as I can tell, is to extend the centralized setup in [1] to a decentralized/federated setup.`**\n\nWe consider our main contribution lies in the development and presentation of a ***simple yet highly effective*** algorithmic solution for continual federated learning. We have devoted considerable effort to an **extensive empirical validation** of our approach. Especially, to support our claim, we added new extensive experimental results in the revised manuscript. The detailed explanations can be found in a related question [R1-Q1] by Reviewer MNXy.\n\n[1] Efficient lifelong learning with A-GEM.\n\n\n\n**`Q2: The algorithm design of FedGP is mostly heuristic and not well motivated. For example, the authors do not rigorously explain why the gradient projection operation and the buffer updating algorithm will solve the catastrophic forgetting problem and fit into the FL setting. A theoretical analysis and more ablations on algorithm design will help to show the effectiveness of FedGP.`**\n\n\nThanks for the sharp question. To address the reviewer's concern, below we added extensive experimental results for ablations on our algorithm design, which is decomposed into (1) gradient manipulation algorithm, and (2) buffer updating algorithm.\n\nFirst, we considered different ways of manipulating the gradient $g$, given the reference gradient $g_{\\text{ref}}$. In the below table, we compared **four different methods of updating $g$**:\n- ``Average``: define $g \\leftarrow (g+g_{\\text{ref}})/2$.\n- ``Rotate`` : rotate $g$ towards $g_{\\text{ref}}$ while keeping the magnitude.\n- ``Project``: project $g$ to the space that is orthogonal to $g_{\\text{ref}}$.\n- ``Project & Scale``: apply ``Project`` and then scale up the vector such that the magnitude is identical to the original $g$\n\nRecall that our FedGP applies ``Project`` method only when the angle between $g$ and $g_\\text{ref}$ is larger than 90 degree, i.e., when the reference gradient $g_\\text{ref}$ (measured for the previous tasks) and the gradient $g$ (measured for the current task) conflicts to each other. Our intuition for such choice is, it is better to manipulate $g$ if the direction favorable for current task is conflicting with the direction  favorable for previous tasks. To support that this choice is meaningful, we compared **two ways of deciding when we manipulate the gradients**, denoted below:\n\n- ``(>90)``: update the gradient $g$ only when the angle($g,g_\\text{ref}$)>90\n- ``(Always)``: update the gradient $g$ always\n\n\nWe compared the performances of above choices in Table [R3-2a], for S-CIFAR100 dataset. One can confirm that our FedGP (denoted by ``Project (>90)`` in the table) far outperforms all other combinations, **showing that our design (doing projection for conflicting case only) is the right choice**. If we check each component (``Project`` and ``(>90)``) independently, one can check that choosing ``Project`` outperforms ``Average``, ``Rotate`` and ``Project & Scale`` in most cases, and choosing  ``(>90)`` outperforms ``Always`` in all cases.\n\n\n#### [Table R3-2a. Effect of different gradient manipulation method on the accuracy (%) of FedGP, tested on S-CIFAR100]\n|Method|Class-IL|Task-IL|\n|-|-|-|\n|FL|8.76\u00b10.1|47.74\u00b11.2|\n|Average (Always)|7.26\u00b11.95|35.96\u00b13.23|\n|Average (>90)|7.79\u00b10.65|36.57\u00b11.55|\n|Rotate (Always)|7.59\u00b10.89|36.15\u00b12.83|\n|Rotate (>90)|8.41\u00b10.78|38.97\u00b11.83|\n|Project \\& Scale (Always)|8.77\u00b10.09|32.96\u00b11.10|\n|Project \\& Scale (>90)|12.30\u00b10.65|73.61\u00b10.75|\n|Project (Always)|8.90\u00b10.08|34.00\u00b11.98|\n|Project (>90), **ours**|**17.08**\u00b11.8|**74.71**\u00b10.9|\n\n\nWe also tested whether doing the projection is helpful in all cases when $\\text{angle}(g, g_\\text{ref}) > 90$. We considered applying the projection for $p\\%$ of the cases having $\\text{angle}(g, g_\\text{ref}) > 90$, for $p=10, 50, 80$ and $100$. Note that $p=100\\%$  case reduces to our FedGP. \n\nTable R3-2b shows the effect of **projection rate** $p\\%$ on the accuracy, tested on S-CIFAR100 dataset. In both class-IL and task-IL settings, increasing $p$ always improves the accuracy of the FedGP method. This supports that our way of projection is suitable for the continual federated learning setup.\n\n\n#### [Table R3-2b. Effect of projection rate $p\\%$ on the accuracy (%) of FedGP, tested on S-CIFAR100]\n|Method|Class-IL|Task-IL|\n|-|-|-|\n|FL, $p=0\\%$|8.76\u00b10.1|47.74\u00b11.2|\n|FedGP, $p=10\\%$|8.82\u00b10.07|54.90\u00b11.61|\n|FedGP, $p=50\\%$|8.91\u00b10.07|67.89\u00b10.67|\n|FedGP, $p=80\\%$ |10.36\u00b10.42|72.73\u00b10.74|\n|FedGP, $p=100\\%$ (Ours)|**17.08**\u00b11.8|**74.71**\u00b10.9|"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700387312366,
                "cdate": 1700387312366,
                "tmdate": 1700387312366,
                "mdate": 1700387312366,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "d2IgTRlFIy",
                "forum": "Xi7UoErFRt",
                "replyto": "om8OeYrbSK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5562/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5562/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "In Table R3-2c, we compared three different **buffer updating algorithms**:\n- ``Random Sampling``: randomly replaces a data point in the buffer with incoming new data\n- ``Sliding Window Sampling``: replaces the earliest data point in the buffer when new data arrives\n- ``Reservoir Sampling`` (Ours): given $N$ (the number of observed samples up to now) and $B$ (the buffer size), we do the following\n    - when $N \\le B$, we put the current sample in the buffer\n    - when $N > B$, with probability $B/N < 1$, we replace a random sample in the buffer with the current sample\n\nNote that when the number of incoming data is $N$, those $N$ samples have the same probability of getting into the buffer, for the ``Reservoir Sampling`` method used in our paper. Thus, when ``Reservoir Sampling`` is used, the **buffer contains approximately equal number of samples for each task** (when each task has the same number of samples), throughout the continual learning process. This is the underlying intuition why we choose such buffer updating algorithm. To support this claim, we report the performance of different sampling methods in Table R3-2c. Here, one can confirm that our sampling method is outperforming other sampling methods.\n\n\n#### [Table R3-2c. Effect of different buffer updating algorithms on the accuracy (%) of FedGP, tested on CIFAR100]    \n|Method|Class-IL|Task-IL|\n|-|-|-|\n|FL|8.76\u00b10.1|47.74\u00b11.2|\n|Sliding Window Sampling|8.82\u00b10.15|46.16\u00b12.38|\n|Random Sampling|9.72\u00b10.10|54.82\u00b11.58|\n|Reservoir Sampling **(Ours)**|**17.08**\u00b11.8|**74.71**\u00b10.9|\n\n\n\n\n\nThe below figure compares the sample distribution across different tasks, for different buffer updating algorithms (uniform-random sampling, reservoir sampling and sliding window sampling). This clearly shows the difference of buffer updating algorithms, which guided to the different performances reported in Table R3-2c. \n\nhttps://docs.google.com/document/d/e/2PACX-1vRzMZ8Ha3DaG79IhAR6lLEFj7UYjQt-W3pJkBvgkPHLtSIv5KkCE7DcAUIBf7VuxnUVM3l78oduC54N/pub\n\nAll in all, the reservoir sampling method used in FedGP allows us to have **balanced sample distribution across different tasks**, thus allowing us to mitigate the catastrophic forgetting and to improve the accuracy in the continual federated learning setting.\n\nIn the revised manuscript, we will include our new results as well as the discussion we made during the rebuttal. \n \n\n\n\n\n**`Q3: I am skeptical about whether the use of a buffer can solve the problem of catastrophic forgetting. Since the buffer size is limited, one is unable to store the entire past information in it, and has to discard stale information. According to Algorithm 4, when the buffer is full the algorithm randomly selects an old entry in the buffer and replace it with a new data point. How can this avoid discarding useful information, e.g., the data point stored in previous rounds?`**\n\nThanks for the great question. The reviewer is correct that a finite buffer can**not** maintain the entire history of data regardless of buffer update algorithm. Instead, our goal is to continuously maintain the buffer so that it represents all the tasks that have been seen in the past. Under the ***Reservoir Sampling***, it is easy to prove that after seeing $N$ samples for any $N$, the samples stored in the buffer are $B$ samples chosen uniformly at random. Before proving this property, let us recall the ***definition of Reservoir Sampling***: for a given $N$ (the number of observed samples up to now) and $B$ (the buffer size), \n- when $N \\le B$, we put the current sample in the buffer\n- when $N > B$, with probability $B/N < 1$, we replace a random sample in the buffer with the current sample\n\n\nWe now prove that for reservoir sampling, the probability of a sample contained in the buffer is $\\frac{B}{N}$. We prove this by induction; suppose this statement holds when $N-1$ samples are observed, and we show that this holds when one more sample is observed. Note that the probability of a sample contained in the buffer can be computed as $\\frac{B}{N-1} * (1-\\frac{B}{N}*\\frac{1}{B})=\\frac{B}{N}$, where\n\n- $\\frac{B}{N-1}$ is the probability of the sample initially contained in the buffer;\n- $(1-\\frac{B}{N}*\\frac{1}{B})$ is the probability of a sample not being kicked out of the buffer; \n- $\\frac{B}{N}*\\frac{1}{B}$ is the probability of a sample being kicked out of the buffer\n\nWe will include these details in the revised manuscript."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700387434861,
                "cdate": 1700387434861,
                "tmdate": 1700387434861,
                "mdate": 1700387434861,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "00BSpZE4Yx",
                "forum": "Xi7UoErFRt",
                "replyto": "om8OeYrbSK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5562/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5562/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "From the above mathematical results, we can confirm that the reservoir sampling allows the buffer to contain samples from previous tasks. However, as the reviewer mentioned, given a limited buffer size, the number of samples the buffer can maintain for old tasks is bounded above. In Fig. R3-3, we reported the effect of buffer size on the accuracy of the trained model for old tasks. At the end of each task, we measured the accuracy of the trained model with respect to the test data for task 1. We tested on S-CIFAR100 dataset, and considered task incremental learning (task-IL) setup. \n\nOne can observe that when the buffer size $B$ is small, the accuracy drops as the model is trained on new tasks. On the other hand, when $B \\ge 100$, the task-IL accuracy for task 1 is maintained throughout the process. Note that training with our default setting $B=200$ does not hurt the accuracy for task 1 throughout the continual learning process.\n\n\n#### [Figure R3-3. Accuracy (%) for Task 1, under the Task-IL setting on S-CIFAR100. We tested on FedGP with different buffer sizes.]\n\nhttps://docs.google.com/document/d/e/2PACX-1vQfbETzt5SUSDrgcCAypbjrxTia1uBgTjNZ4_KnY6tYZ7pcpRo20SA-FiDctxgQNKUwTgP_RZSRxgdZ/pub"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700387469753,
                "cdate": 1700387469753,
                "tmdate": 1700387469753,
                "mdate": 1700387469753,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "A9oRhcUKPr",
            "forum": "Xi7UoErFRt",
            "replyto": "Xi7UoErFRt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5562/Reviewer_Nmd1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5562/Reviewer_Nmd1"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces FedGP, a buffer-based gradient projection method designed for continual federated learning. FedGP effectively tackles the challenge of catastrophic forgetting while amplifying the performance of the continual learning and continual federated learning techniques. Extensive experiments conducted on multiple benchmarks demonstrate the effectiveness of the proposed FedGP method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This paper introduces a buffer-based gradient projection method to address the catastrophic forgetting in continual federated learning.\n2. This work is straightforward and easily understandable, making it reader-friendly for potential readers.\n3. Extensive experimental results demonstrated the effectiveness of the proposed FedGP method."
                },
                "weaknesses": {
                    "value": "The paper focus on an interesting continual federated learning problem and has several issues that can be improved: The proposed FedGP method suffer from more communication costs than comparison methods. Moreover, additional gradients need to be uploaded to the server which increases the risk of the local data leakage."
                },
                "questions": {
                    "value": "(1) The gradient projection that conflict with the previous task update direction would aggravate forgetting, while directly drop it would impair the current task learning. The proposed method can be addressed the forgetting to some extent while ignoring its impact on the current task.\n\n(2) In Table 3, the two times communication get an inferior performance than the equalized communication with FedGP in P-MNIST, can you give an explanation?\n\n(3) The adopted comparison methods seem to be outdated, it is better to adopted the SOTA methods to further validate the effectiveness of the proposed FedGP method.\n\n(4) The literature[1] also addressed the forgetting by using gradient projection, which has a strong connection with the proposed method. It is better to taken as a comparison method.\n\n(5) Please see the weakness above.\n\n[1] Gradient Projection Memory for Continual Learning, In ICLR 2021"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5562/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698776380262,
            "cdate": 1698776380262,
            "tmdate": 1699636572034,
            "mdate": 1699636572034,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VYl6JomzQB",
                "forum": "Xi7UoErFRt",
                "replyto": "A9oRhcUKPr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5562/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5562/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank Reviewer Nmd1 for the detailed review and very helpful suggestions. We thank the Reviewer for appreciating the proposed projection method, extensive experimental results, and our efforts in making a well-written paper. Our responses are detailed below.\n\n**`Q1: The gradient projection that conflict with the previous task update direction would aggravate forgetting, while directly drop it would impair the current task learning. The proposed method can be addressed the forgetting to some extent while ignoring its impact on the current task.`**\n\n\nWe thank the Reviewer for pointing this out. To address your concern, below we provided additional experimental results on the performance measured for the **current** task. The below plot shows the Class-IL accuracy of FedGP (with buffer size 200) and FL for S-CIFAR100, where the total number of tasks is set to 10. During the continual learning process, we measured the accuracy of each model for the **current** task. One can confirm that using FedGP does not hurt the current task accuracy, compared with FL. Note that this shows that FedGP does not impair the performance of the current task, while also alleviating the forgetting in upcoming rounds.\n\n\nWe will include this result and discussion in the revised manuscript.\n\n\n\n\n#### [Figure R2-1. Class-IL Accuracy (%) of current task for FL and FedGP on the S-CIFAR100]\n\nhttps://docs.google.com/document/d/e/2PACX-1vSqmIgnlzdcX2Pvvjw3acXsM1tINU-Jj385cYadSk1jUI9RDm6jr7hZQ3mtomf3Mxo6nDYBq4ZR9Lre/pub\n\n\n\n**`Q2: In Table 3, the two times communication get an inferior performance than the equalized communication with FedGP in P-MNIST, can you give an explanation?`**\n\nWe thank the Reviewer for carefully reading our work. \nAfter reading our result again, we noticed that the performances of two methods (``2x communication`` stragety and ``equalized communication`` strategy) in P-MNIST are quite close to each other, and they are within the errors.\n\n\nDuring the rebuttal period, we ran additional experiments; instead of the initial 5 runs (which we reported in the submitted manuscript), we did 20 runs per method, each with a unique random seed, the result of which is given below. \n\n\n#### [Table R2-2. Effect of communication on accuracy (%) performance averaged across 20 runs, for P-MNIST]\n|Method|Domain-IL|\n|-|-|\n|FL|27.49\u00b11.98|\n|FL w/ FedGP (2\u00d7 comm overhead) |**35.91**\u00b13.98|\n|FL w/ FedGP (equalized comm overhead) |34.96\u00b13.16|\n\n\nAs in Table R2-2, ``2x communication`` strategy has a slightly better performance than ``equalized communication`` strategy, when evaluated across 20 runs. Note that this result is consistent with our finding for other datasets (R-MNIST, S-CIFAR10 and S-CIFAR100) we reported in Table 3 of the submitted manuscript. \n\nBased on this observation, we will revise the result for P-MNIST in the updated manuscript."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700386208942,
                "cdate": 1700386208942,
                "tmdate": 1700386208942,
                "mdate": 1700386208942,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IZ97lamh1Z",
                "forum": "Xi7UoErFRt",
                "replyto": "A9oRhcUKPr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5562/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5562/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**`Q3: The adopted comparison methods seem to be outdated, it is better to adopted the SOTA methods to further validate the effectiveness of the proposed FedGP method.`**\n\nAs per the reviewer's suggestion, we compared our method with SOTA paper [1] proposing Federated Orthogonal Training (FOT) algorithm for continual federated learning. \n\nIn FOT, at the end of each task, each local client transmits the activation vectors information (computed for local data points) of each local model to the server. Then, the server computes the subspace $S$ spanned by the aggregated activations. This subspace is used during the global model update process; the gradient $g$ is updated in the direction that is orthogonal to the subspace $S$. Note that FOT has several advantages compared with existing baselines; the privacy leakage is mitigated, the communication cost is reduced, and the solution has theoretical guarantees. We very much appreciate their work.\n\nWhile both FOT and our FedGP project the gradients $g$ on the subspace $S$ specified by previous tasks, they have two main differences. First, the subspace $S$ is defined in a different manner: FOT relies on the representations of local model activations to define $S$. FedGP, on the other hand, relies on the gradient of model computed on its local buffer data. Second, FOT projects the gradient computed at the server side, while FedGP projects the gradient computed at each local client. \n\nThe below table compares the accuracy of FL, FOT and FedGP (with buffer size 200) for P-MNIST and S-CIFAR100 under the task incremental learning scenario, consistent with the paper's benchmarks. Assuming that the local buffer is available, FedGP outperforms FOT. \n\nWe will include this in the revised manuscript.\n\n#### [Table R2-3.  Comparative accuracy (%) performance analysis of FL, FOT, and FL+FedGP]\n\n| Methods  | P-MNIST (Domain-IL) | S-CIFAR100 (Task-IL) |\n|----------|---------------------|----------------------|\n| FL       | 25.92\u00b12.1           | 47.74\u00b11.2            |\n| FOT      | 23.77\u00b11.1           | 50.57\u00b11.5            |\n| FL+FedGP | **34.23**\u00b12.7           | **74.71**\u00b10.9            |\n\n[1] \"Federated Orthogonal Training: Mitigating Global Catastrophic Forgetting in Continual Federated Learning\"\n\n**`Q4: The literature[1] also addressed the forgetting by using gradient projection, which has a strong connection with the proposed method. It is better to taken as a comparison method.`**\n\nWe thank the Reviewer for bringing this work [1] to our attention. As the reviewer mentioned, both our method (FedGP) and the gradient projection memory (GPM) method suggested in [1] consider gradient projection for mitigating the forgetting issue. \n\nHowever, FedGP (ours) and GPM (proposed in [1]) have two clear differences.\n\nFirst, the reference vector used for the projection is different. In our FedGP, the reference vector is the gradient $g_{\\text{ref}}$ of the global model computed by the buffer data stored at clients. In contrast, in [1], the network representation (activations) approximated by top singular vectors are used as the reference vector, which is measured when each task ends. \n\nSecond, GPM requires task boundaries, while FedGP does not. Thus, FedGP can be applied in more realistic scenarios where the task boundaries are not given.\n\nTable R2-4 compares the performance of FedGP and GPM (applied in federated learning) for various datasets. We compared the two methods assuming that task boundaries are given. Note that our method does not use this information, while GPM does. Still, we observe that our FedGP outperforms GPM. The potential reasons could be (1) FedGP utilizes buffer gradients which could provide more information than the top singular vectors derived from the activations in GPM. (2) FedGP updates its reference gradients more often, like after every communication round, while GPM only updates after finishing a task.\n\n[1] \u201cGradient projection memory for continual learning.\u201d \n\n#### [Table R2-4. Comparative accuracy (%) performance analysis of FL, FL+GPM, and FL+FedGP across various datasets]\n| Methods       | R-MNIST (Domain-IL) | S-CIFAR10 (Class-IL) | S-CIFAR10 (Task-IL) |\n|---------------|---------------------|----------------------|---------------------|\n| FL            | 68.02\u00b13.1           | 17.44\u00b11.3            | 70.58\u00b14.0           |\n| FL+GPM  | 74.42\u00b16.4           | 17.59\u00b10.4            | 74.50\u00b13.6           |\n| FL+FedGP      | **79.46**\u00b14.1           | **18.02**\u00b10.6           | **80.83**\u00b12.0           |\n\n|          | P-MNIST (Domain-IL) | S-CIFAR100 (Class-IL) | S-CIFAR100 (Task-IL) |\n| -------- | ------------------- | --------------------- | -------------------- |\n| FL       | 25.92\u00b12.1           | 8.76\u00b10.1              | 47.74\u00b11.2            |\n| FL+GPM   | 31.92\u00b13.4           | 8.18\u00b10.1              | 54.48\u00b11.4            |\n| FL+FedGP | **34.23**\u00b12.7                        | **17.08**\u00b11.8             |**74.71**\u00b10.9\n\nWe will include this in the revised manuscript."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700386720089,
                "cdate": 1700386720089,
                "tmdate": 1700386720089,
                "mdate": 1700386720089,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WiST3EBISK",
                "forum": "Xi7UoErFRt",
                "replyto": "A9oRhcUKPr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5562/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5562/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**`Q5: The paper focus on an interesting continual federated learning problem and has several issues that can be improved: The proposed FedGP method suffer from more communication costs than comparison methods. Moreover, additional gradients need to be uploaded to the server which increases the risk of the local data leakage.`**\n\nWe thank the reviewer for pointing out the possible limitations of our method. Regarding the communication cost, it is true that vanilla FedGP has 2x communication cost compared with baselines. However, we consider a variant of FedGP which updates the model and buffer gradient less frequently (i.e., reduce the communication rounds for each task by half or more), which has reduced communication than the vanilla FedGP.\n\n\nDuring the rebuttal period, we ran extensive new experiments which explore the accuracy of FedGP methods for different communication frequencies. Table R2-5 below reports the performance for different datasets, when the communication overhead is set to 2x, 1x, 0.5x and 0.2x. Values in brackets indicate differences from the FL baseline.\n\nFirst, in most cases (except S-CIFAR10 Class-IL setup), FedGP with equalized (1x) communication overhead is outperforming FL. In addition, for most of tested datasets including R-MNIST, P-MNIST and S-CIFAR100, FedGP outperforms FL with at most 0.5x communication overhead. This means that FedGP enjoys a **higher performance with less communication**, in the standard benchmark datasets for continual federated learning.\n\nIn the revised manuscript, we will include Table R2-5 our discussions written above. \n\n\n\n#### [Table R2-5. Effect of communication on the accuracy (%) performance, with values in brackets indicating differences from the FL baseline]\n\nHere's the updated table with the differences compared to the first row (FL) included:\n\n| Method                                   | R-MNIST                  | P-MNIST                 | S-CIFAR10 Class-IL       | S-CIFAR10 Task-IL       | S-CIFAR100 Class-IL     | S-CIFAR100 Task-IL     |\n| ---------------------------------------- | ------------------------ | ----------------------- | ------------------------ | ----------------------- | ----------------------- | ---------------------- |\n| FL                                       | 68.02\u00b13.1                | 27.49\u00b11.98              | 17.44\u00b11.3                | 70.58\u00b14.0               | 8.76\u00b10.1                | 47.74\u00b11.2              |\n| FL w/ FedGP (2x comm overhead)           | **79.46**\u00b14.1 (\u219111.44)   | **35.91**\u00b13.98 (\u21918.42)  | **18.02**\u00b10.6 (\u21910.58)   | **80.83**\u00b12.0 (\u219110.25)  | **17.08**\u00b11.8 (\u21918.32)   | **74.71**\u00b10.9 (\u219126.97) |\n| FL w/ FedGP (equalized comm overhead)    | 75.63\u00b13.9 (\u21917.61)        | 34.96\u00b13.16 (\u21917.47)      | 16.65\u00b11.0 (\u21930.79)       | 78.79\u00b12.8 (\u21918.21)       | 13.62\u00b10.6 (\u21914.86)       | 73.96\u00b10.4 (\u219126.22)     |\n| FL w/ FedGP (0.5x comm overhead)         | 76.05\u00b14.05 (\u21918.03)       | 29.75\u00b14.63 (\u21912.26)      | 14.30\u00b11.34 (\u21933.14)      | 66.90\u00b13.61 (\u21933.68)      | 13.09\u00b10.49 (\u21914.33)      | 69.96\u00b10.56 (\u219122.22)    |\n| FL w/ FedGP (0.2x comm overhead)         | 70.59\u00b14.70 (\u21912.57)       | 15.51\u00b12.71 (\u219311.98)     | 13.37\u00b12.64 (\u21934.07)      | 59.75\u00b16.36 (\u219310.83)     | 13.59\u00b10.87 (\u21914.83)      | 59.31\u00b11.59 (\u219111.57)    |\n\n\nRegarding the data leakage issue, we are running experiments measuring the privacy leakage of FedGP and other baselines. We will report the result as soon as we get it."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700386775388,
                "cdate": 1700386775388,
                "tmdate": 1700386775388,
                "mdate": 1700386775388,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "OOjJ5XnxrM",
            "forum": "Xi7UoErFRt",
            "replyto": "Xi7UoErFRt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5562/Reviewer_MNXy"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5562/Reviewer_MNXy"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents FedGP, an approach that addresses the challenges of continual federated learning (CFL) by integrating techniques from both continual learning (CL) and federated learning (FL). At its core, FedGP conducts server aggregation of local buffer gradient to obtain a global buffer gradient. Then use the global buffer gradient to guide the local continual learning by gradient projection. Furthermore, in the federated context, FedGP preserves the knowledge across multiple tasks in a  non-iid and heterogeneous client data distribution. Through this integration, FedGP improves the performance of current CFL approaches."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is easy to read and follow, and the extensive experiments show the resulting improvement spanning many datasets and baseline methods. The proposed methods also work with a large number of clients and partial client aggregation in FL."
                },
                "weaknesses": {
                    "value": "1. While I'm familiar with FL and CL, I'm not a deep expert in CFL. Observing FedGP, it seems to be a federated take on A-GEM, where g_ref is replaced by a federated aggregation of local buffer gradients. Although FedGP shows promising results when combined with other methods, I'm still pondering its overall novelty and contribution.\n\n2. In the experimental section, Table 1 presents the performance of all baseline methods. It's noticeable that, in the without FedGP column, even though CFL methods are designed for continual learning challenges, some, especially FL+iCaRL/L2P, performed better than CFL methods. Can the authors clarify the reasons behind these results?"
                },
                "questions": {
                    "value": "See weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5562/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5562/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5562/Reviewer_MNXy"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5562/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698834609581,
            "cdate": 1698834609581,
            "tmdate": 1699636571940,
            "mdate": 1699636571940,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5XBCiOox6w",
                "forum": "Xi7UoErFRt",
                "replyto": "OOjJ5XnxrM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5562/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5562/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank Reviewer MNXy for the detailed review. We are happy to see the acknowledgement of the paper's clarity and thorough experiments. Please find our answers to comments and questions as follows.\n\n**`Q1: Observing FedGP, it seems to be a federated take on A-GEM, where g_ref is replaced by a federated aggregation of local buffer gradients. Although FedGP shows promising results when combined with other methods, I'm still pondering its overall novelty and contribution.`**\n\n\n\nThanks for your comments. \n\nWe consider our main contribution lies in the development and presentation of a ***simple yet highly effective*** algorithmic solution for continual federated learning. Our FedGP is a simple variant combining existing methods, but it highly outperforms baselines in various scenarios. To show this, we have devoted considerable effort to an **extensive empirical validation** of our approach, including \n* image classification\n* language processing\n* object detection data from the CARLA simulator\n\nThis empirical justification is a critical part of our contribution, demonstrating the general applicability of our algorithm. \n\nTo further strengthen our claim, we **added extensive new results during the rebuttal period**. To be specific, we conducted experiments exploring the effect of \n* gradient manipulation (projection, rotation, averaging) methods -- result is in R3-Q2\n* buffer data sampling methods (reservior, random, sliding-window)-- result is in R3-Q2\n* buffer size -- result is in R3-Q3\n* communication frequency -- result is in R2-Q5\n* the reference gradient used for projection (by comparing with related baselines [1], [2]) -- result is in R2-Q3 & R2-Q4\n\n\n[1] Saha, Gobinda, Isha Garg, and Kaushik Roy. \"Gradient projection memory for continual learning.\" arXiv preprint arXiv:2103.09762 (2021).\n[2] Bakman, Yavuz Faruk, et al. \"Federated Orthogonal Training: Mitigating Global Catastrophic Forgetting in Continual Federated Learning.\" arXiv preprint arXiv:2309.01289 (2023).\n\n\n\n\n\n**`Q2: In the experimental section, Table 1 presents the performance of all baseline methods. It's noticeable that, in the without FedGP column, even though CFL methods are designed for continual learning challenges, some, especially FL+iCaRL/L2P, performed better than CFL methods. Can the authors clarify the reasons behind these results?`**\n\n\nWe thank the reviewer for the sharp question. \nFirst, it is worth nothing that **FL+CL methods could still outperform some CFL methods under certain conditons**, and the similar findings have been made in the previous work too. For example, according to a recent work [1], FL+CL methods (FL+EWC and FL+ER) outperforms CFL methods (GLFC and FedCIL) for S-CIFAR100 dataset. \n\nSecond, we note that FL+L2P's high performance is due to a different reason -- **it utilizes a pretranied Vision Transformer (ViT), which helps mitigate the catastrophic forgetting**. This is why we wrote the numbers in gray with a caveat in the caption, but we will further clarify this in the revision.\n\n\n\n\nThird, regarding a CFL method called CFeD [2], it is important to note that its performance is heavily dependent on the choice of surrogate data (we used CIFAR for our experiments), and **no direct comparison with state-of-the-art FL+CL methods (e.g., iCaRL) has been reported** in [2].\n\n\n\nIn the revised manuscript, we will include this discussion.\n\n[1] Y. F. Bakman et al., \"Federated Orthogonal Training: Mitigating Global Catastrophic Forgetting in Continual Federated Learning\", arXiv 2023\n[2] Ma, Yuhang, et al. \"Continual federated learning based on knowledge distillation.\" Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence. Vol. 3. 2022."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5562/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700385585878,
                "cdate": 1700385585878,
                "tmdate": 1700385585878,
                "mdate": 1700385585878,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]