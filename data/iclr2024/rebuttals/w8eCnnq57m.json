[
    {
        "title": "LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition"
    },
    {
        "review": {
            "id": "ZRcRwEWGGe",
            "forum": "w8eCnnq57m",
            "replyto": "w8eCnnq57m",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission97/Reviewer_8M9N"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission97/Reviewer_8M9N"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces LoRAHub, a method designed to enhance performance on unseen tasks by re-utilizing trained LoRA (Low Rank Approximation) parameters across different tasks. LoRAHub operates by weighting each of these parameters, learned through a minimal set of examples on unseen tasks, thereby outperforming zero-shot baselines while achieving comparable results to in-context learning."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper presents a novel approach to leveraging previously learned LoRA parameters to improve performance on unseen tasks.\n\n2. It demonstrates competitive performance compared to in-context learning while outperforming zero-shot baselines, showcasing the potential of the method.\n\n3. It would be beneficial if the authors could release the fine-tuned LoRA weight to the community."
                },
                "weaknesses": {
                    "value": "1. The choice of using FLAN-T5-Large as the base model is questionable as a model pre-trained on unsupervised text might have been more relevant for fine-tuning / LoRA fine-tuning on upstream tasks from the FLAN collection.\n\n2. The paper lacks clarity in explaining the rationale behind maintaining the same rank for the composed LoRA module and could benefit from exploring higher rank matrices when composing.\n\n3. The selection of 20 LoRAs for unseen tasks seems arbitrary and might limit the method\u2019s performance. An iterative procedure or justification for this selection would have been beneficial.\n\n4. The absence of certain baselines, such as the average performance for BBH's top 5 upstream tasks, leaves gaps in the evaluation.\n\n5. The baseline corresponding to the retrieval of a trained LoRAs, when given a handful of examples from unseen tasks, is missing. For example, see https://arxiv.org/abs/2302.03202"
                },
                "questions": {
                    "value": "1. Can you elaborate on the interpretation of negative coefficients for the LoRA weights?\n\n2. Why was the decision made to maintain the same rank for the composed LoRA module? Have higher rank matrices been explored and if so, what were the findings?\n\n3. Is the selection of 20 LoRAs for unseen tasks fixed or is there an iterative procedure to this selection? How does this choice impact the method\u2019s performance on unseen tasks?\n\n4. I believe the strength of the method lies in cases where there are a handful of examples from unseen tasks. If it's otherwise, that it is beneficial to use a larger number of examples, it would make sense to compare against methods like IA3 [https://arxiv.org/abs/2205.05638], which fine-tunes efficiently on few-shot examples from unseen tasks.\n\n5. Why was FLAN-T5-Large chosen as the base model over a model pre-trained on unsupervised text? Wouldn't it be strange to fine-tune on FLAN tasks using LoRA on an already FLAN multitask-trained backbone model?\n\n6. How does the absolute value of LoRA weight not exceeding 1.5 relate to the method's performance in section 4.2, and is there a particular significance to this threshold?\n\n7. It would be beneficial to include parameter efficient fine-tuning and traditional fine-tuning performance in Table 1, especially with the setup of a limited number of examples.\n\n8. Is In-Context Learning (ICL) performed on the same base Language Model (LLM), or is it conducted using larger decoder only LLMs? What are the implications of this choice on the comparison of results?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission97/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission97/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission97/Reviewer_8M9N"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission97/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698687649180,
            "cdate": 1698687649180,
            "tmdate": 1699635934739,
            "mdate": 1699635934739,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qmwHG3Y39S",
                "forum": "w8eCnnq57m",
                "replyto": "ZRcRwEWGGe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors [1/5]"
                    },
                    "comment": {
                        "value": "Thank you for acknowledging our efforts and providing constructive feedback! We are glad to respond to all your concerns below.\n\n## Weakness 1 / Question 5: The Choice of FLAN-T5\n---\n\nThanks for your feedback. We would like to clarify that the selection of FLAN-T5-large as our main base model was a strategic choice based on several considerations and explain them in detail below.\n\nFirstly, the choice of FLAN-T5 as our base model is grounded in the pursuit of language models with exceptional few-shot capabilities, making it a robust baseline for our study. FLAN-T5 not only excels in both zero-shot and few-shot scenarios but also boasts strong problem-solving capabilities, positioning it as a formidable candidate for our consideration.\n\nSecondly, the choice of FLAN-T5 as our primary base model is crucial to ensuring a fair comparison with zero-shot learning. By utilizing LoRA modules trained on the FLAN collection, our intention is to insulate our method's performance from the influence of additional datasets. Given that the FLAN collection is already seen during FLAN-T5's training, we can reasonably assert that the true efficacy lies in the composition of LoRA modules rather than the introduction of extra datasets. Selecting an unsupervised model, such as T5, as the base would present an unfair advantage for our method, as it would indirectly leverage datasets not encountered during T5's pre-training.\n\nLastly, we genuinely appreciate and understand your concern. To address it comprehensively, we have also provided an analysis of the performance of our method with T5 as the base model in both Section 5 (`Can LoraHub work well on non-instruction-tuning models`) and Appendix B. These sections explicitly showcase the efficacy of our method when applied to models trained exclusively on unsupervised text, underscoring the generality of our approach.\n\n## Weakness 2 / Question 2: LoRA Rank Exploration\n---\n\nThanks for your question! In fact, we have investigated the impact of different ranks in Section 5 (`Will the rank of LoRA modules impact the performance of LoraHub learning`) and Appendix B. Our analysis indicates that, for FLAN-T5, the choice of rank has minimal impact. However, for T5, it still exerts some influence. Empirical findings reveal that, in comparison to rank values of $4$ or $64$, a rank value of $16$ consistently demonstrates superior performance across different runs, both in terms of average and best performance.\n\n| Task | Rank 4$_{avg}$ | Rank 4$_{best}$ | Rank 16$_{avg}$ | Rank 16$_{best}$ | Rank 64$_{avg}$ | Rank 64$_{best}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| Average Performance Per Task | 16.1 | 24.2 | 20.8 | 30.7 | 14.8 | 21.4 |\n\nWe hope that this exploration addresses your concerns and brings satisfaction. We anticipate that future research endeavors will contribute to a deeper understanding of the factors influencing these effects.\n\n## Weakness 3 / Question 3: LoRA Module Selection\n---\n\nThank you for pointing this out! In our initial experiment, the selection of the $20$ LoRA module candidates is conducted randomly, serving as the primary source of randomness in our method.\n\nAcknowledging the need for improvement in the aspect, we explored a straightforward approach ($\\rm LoraHub_{filter}$) in the selection of LoRA module candidates. Specifically, we first identified $20$ LoRA module candidates with the lowest loss on the few-shot examples, with the goal of minimizing introduced variance and fostering a more consistent performance. The experimental results demonstrate that this approach contributes to a slight improvement in the average performance. These results have been included in Appendix D for further reference. We hope the updated experiment addresses your concerns.\n\n| $\\rm Task$                                   | $\\rm LoraHub_{avg}$ | $\\rm LoraHub_{filter}$ |\n|-------------------------------------------|-------------|----------------|\n| Boolean Expressions                       | 55.5        | 60.0           |\n| Causal Judgement                          | 54.3        | 52.9           |\n| Date Understanding                        | 32.9        | 33.3           |\n| Disambiguation                            | 45.2        | 62.7           |\n| Dyck Languages                            | 1.0         | 0.0            |\n| ... | | |\n| Tracking Shuffled Objects (three objects) | 29.0        | 32.7           |\n| Web of Lies                               | 53.0        | 46.0           |\n| Word Sorting                              | 1.1         | 1.3            |\n| **Avg Performance Per Task**                  |**34.7**       | **35.4**          |"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700127588082,
                "cdate": 1700127588082,
                "tmdate": 1700136324877,
                "mdate": 1700136324877,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vD4APyfdZm",
                "forum": "w8eCnnq57m",
                "replyto": "ZRcRwEWGGe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors [2/5]"
                    },
                    "comment": {
                        "value": "## Weakness 4: Absence of Baselines\n---\n\nThank you for your valuable suggestion. We acknowledge the importance of incorporating such a baseline, and as a response, we have included new experimental results in our study. Concretely, we evaluate the performance on BBH tasks of the top 5 generally useful LoRA modules presented in Table 2 (More details of these LoRA modules can be found in the paper). The additional experimental results are outlined below.\n\n| Task                                      | WIQA: Last | RACE: Right | WIQA: First | AdversaraialQA: BiDAF  | WebQuestions: Answer |\n|-------------------------------------------|------------|-------------|------------|-------|-------|\n| Boolean Expressions                       | 52.7       | 58.0        | 52.7       | 54.7  | 53.3  |\n| Causal Judgement                          | 55.2       | 63.2        | 55.2       | 57.5  | 57.5  |\n| Date Understanding                        | 17.3       | 19.3        | 17.3       | 16.7  | 15.3  |\n| Disambiguation                            | 0.0        | 0.0         | 0.0        | 0.0   | 0.0   |\n| Dyck Languages                            | 0.7        | 0.7         | 0.7        | 1.3   | 1.3   |\n| Formal Fallacies                          | 51.3       | 51.3        | 51.3       | 51.3  | 51.3  |\n| Geometric Shapes                          | 8.0        | 13.3        | 8.0        | 6.7   | 7.3   |\n| Hyperbaton                                | 16.7       | 44.0        | 16.7       | 1.3   | 6.0   |\n| Logical Deduction (five objects)          | 23.3       | 28.0        | 23.3       | 19.3  | 20.7  |\n| Logical Deduction (seven objects)         | 22.0       | 26.0        | 22.0       | 10.7  | 12.0  |\n| Logical Deduction (three objects)         | 0.7        | 9.3         | 0.7        | 0.0   | 0.0   |\n| Movie Recommendation                      | 63.3       | 62.7        | 63.3       | 56.7  | 63.3  |\n| Multistep Arithmetic                      | 0.7        | 0.7         | 0.7        | 0.7   | 0.7   |\n| Navigate                                  | 47.3       | 50.0        | 47.3       | 47.3  | 47.3  |\n| Object Counting                           | 34.7       | 34.0        | 34.7       | 35.3  | 35.3  |\n| Penguins in a Table                       | 45.7       | 41.3        | 45.7       | 39.1  | 43.5  |\n| Reasoning about Colored Objects           | 40.0       | 37.3        | 40.0       | 31.3  | 30.7  |\n| Ruin Names                                | 22.0       | 21.3        | 22.0       | 17.3  | 22.7  |\n| Salient Translation Error Detection       | 36.7       | 34.7        | 36.7       | 32.7  | 37.3  |\n| Snarks                                    | 52.6       | 55.1        | 52.6       | 47.4  | 52.6  |\n| Sports Understanding                      | 56.0       | 58.7        | 56.0       | 55.3  | 55.3  |\n| Temporal Sequences                        | 16.7       | 17.3        | 16.7       | 12.7  | 17.3  |\n| Tracking Shuffled Objects (five objects)  | 12.0       | 12.0        | 12.0       | 10.7  | 12.0  |\n| Tracking Shuffled Objects (seven objects) | 6.7        | 6.7         | 6.7        | 6.7   | 6.7   |\n| Tracking Shuffled Objects (three objects) | 20.7       | 30.7        | 20.7       | 10.7  | 25.3  |\n| Web of Lies                               | 54.7       | 54.0        | 54.7       | 54.0  | 54.0  |\n| Word Sorting                              | 1.3        | 1.3         | 1.3        | 1.3   | 1.3   |\n| **Avg Performance per Task**              | **28.1**    | **30.8**     | **28.1**    | **25.1** | **27.0** |\n| **$\\Delta$ FLAN-T5-large**                    | **1.1**     | **3.8**      | **1.1**     | **-1.9** | **0.0**  |\n\nNotably, the findings indicate that, in most cases, these top LoRA modules perform similarly as the original FLAN-T5-large. And there is only one module \"RACE: Right\" stands out as significantly surpassing FLAN-T5-large. However, it's important to highlight that this individual performance doesn't reach the level achieved by LoraHub. These results reinforce the conclusion that module compositions can indeed enhance the overall performance. We appreciate your insightful suggestion, as it has enabled us to more effectively demonstrate the efficacy and necessity of our approach. Your perspective is invaluable to our work."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700128178881,
                "cdate": 1700128178881,
                "tmdate": 1700128664862,
                "mdate": 1700128664862,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hHg9mbKfuE",
                "forum": "w8eCnnq57m",
                "replyto": "ZRcRwEWGGe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors [3/5]"
                    },
                    "comment": {
                        "value": "## Weakness 5: The LoRA Retrieval Baseline\n---\n\nThank you for pointing out the absence of a baseline corresponding to the retrieval of trained LoRAs given a handful of examples from unseen tasks. We sincerely appreciate your sharing of the related work (https://arxiv.org/abs/2302.03202), and we acknowledge its interesting and novel methods.\n\nIn response to your feedback, we have included a discussion of this work in Section 5 (\"Does composing LoRA modules extend beyond the single module\u2019s benefits?\") in the revised paper. And we conducted an experiment involving the LoRA retrieval method as our baseline. Notably, in order to ensure a fair comparison, we designed a LoRA retrieval mechanism based on the loss derived from few-shot examples. Specifically, we ranked all LoRA module candidates based on their loss on the few-shot examples and evaluated the best candidate on the test set of the unseen task. The performance comparison is as below.\n\n| $\\rm Task$                                    | $\\rm LoRA  Retrieval$ | $\\rm LoraHub_{avg}$ | $\\rm LoraHub_{best}$ |\n|-----------------------------------------|-------------|-----------------|------------------|\n| Boolean Expressions                     | 53.3 | 55.5            | 60.7             |\n| Causal Judgement                        | 63.2  | 54.3            | 63.2             |\n| Date Understanding                      | 20.7 | 32.9            | 45.3             |\n| Disambiguation                       | 0           | 45.2            | 68               |\n| Dyck Languages                          | 0.7 | 1.0               | 2.7              |\n|Formal Fallacies                        | 51.3 | 52.8            | 59.3             |\n| Geometric Shapes                        | 9.3 | 7.4             | 18.7             |\n| Hyperbaton                              | 57.3 | 62.8            | 72.7             |\n| Logical Deduction (five objects)          | 26          | 36.1            | 40               |\n| Logical Deduction (seven objects)         | 36.8 | 36.8            | 46               |\n| Logical Deduction (three objects)         | 10.0          | 45.7            | 52.7             |\n| Movie Recommendation                    | 63.3 | 55.3            | 62               |\n| Multistep Arithmetic Two                | 1.3 | 0.4             | 1.3              |\n| Navigate                                | 49.3 | 47.1            | 51.3             |\n| Object Counting                         | 37.3 | 33.7            | 36.7             |\n| Penguins in a Table                  | 41.3 | 35.9            | 47.8             |\n| Reasoning about Colored Objects         | 40          | 40              | 44.7             |\n| ruin_names                              | 21.3 | 24.4            | 28.7             |\n| Salient Translation Error Detection     | 46          | 36              | 42.7             |\n| Snarks                                  | 50          | 56.9            | 61.5             |\n| Sports Understanding                    | 54.7 | 56.7            | 62.7             |\n| Temporal Sequences                      | 17.3 | 18.2            | 21.3             |\n| Tracking Shuffled Objects (five objects)  | 12.0          | 12.3            | 16.7             |\n| Tracking Shuffled Objects (seven objects) | 6.7 | 7.7             | 15.3             |\n| Tracking Shuffled Objects (three objects) | 30.7 | 29.2            | 31.3             |\n| Web of Lies                             | 55.3 | 50.1            | 57.3             |\n| Word Sorting                            | 0.7 | 1.1             | 1.3              |\n|  **Average Performance**                                       | **31.7** | **34.7**        | **41.2**         |\n\nAs depicted in the table above, the performance of LoRA retrieval is notably impressive, positioning it as a strong baseline. However, in comparison to LoraHub, the performance of LoRA retrieval is relatively less favorable. This underscores the imperative and effectiveness of LoRA module composition.\n\nWe extend our sincere gratitude to the reviewer for providing insightful perspectives that have significantly enriched the comprehensiveness of our evaluation.\n\n## Question 1: The Negative Coefficients\n---\n\nWe apologize if our paper's description did not accurately convey our approach. In the equation: $\\hat{m} = (w_1A_1+w_2A_2)(w_1B_1+w_2B_2)$, when the weight parameter ($w$) assumes a negative value, the operation remains consistent\u2014subtracting the corresponding parameters of LoRA at the specified positions. No additional adjustments are made for negative coefficients. We hope this clarification provides a clearer understanding of the process."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700128406349,
                "cdate": 1700128406349,
                "tmdate": 1700136256598,
                "mdate": 1700136256598,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GhQxzUrzHB",
                "forum": "w8eCnnq57m",
                "replyto": "ZRcRwEWGGe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors [4/5]"
                    },
                    "comment": {
                        "value": "## Question 4: The IA3 Baseline\n---\n\nThank you for your valuable suggestion. We have incorporated your feedback by updating Table 1 to provide a more focused comparison between our method and IA3, a representative efficient few-shot fine-tuning method. The experimental results are as below.\n\n| $\\rm Task$                                      |  $\\rm Zero$    | $\\rm ICL_{avg}$ | $\\rm IA3_{avg}$ | $\\rm LoraHub_{avg}$ |\n|-------------------------------------------|-----------|-------------|-------------|-----------------|\n| Boolean Expressions                       | 54.0      | 59.6        | 56.2        | 55.5            |\n| Causal Judgement                          | 57.5      | 59.4        | 60.2        | 54.3            |\n| Date Understanding                        | 15.3      | 20.4        | 20.0        | 32.9            |\n| Disambiguation                            | 0.0       | 69.1        | 0.0         | 45.2            |\n| Dyck Languages                            | 1.3       | 0.9         | 4.2         | 1.0             |\n| Formal Fallacies                          | 51.3      | 55.3        | 51.5        | 52.8            |\n| Geometric Shapes                          | 6.7       | 19.6        | 14.7        | 7.4             |\n| Hyperbaton                                | 6.7       | 71.8        | 49.3        | 62.8            |\n| Logical Deduction\u00a7 (five objects)         | 21.3      | 39.1        | 32.7        | 36.1            |\n| Logical Deduction\u00a7 (seven objects)        | 12.7      | 40.7        | 33.8        | 36.8            |\n| Logical Deduction\u00a7 (three objects)        | 0.0       | 51.6        | 8.5         | 45.7            |\n| Movie Recommendation                      | 62.7      | 55.8        | 61.8        | 55.3            |\n| Multistep Arithmetic                      | 0.7       | 0.7         | 0.7         | 0.4             |\n| Navigate                                  | 47.3      | 45.3        | 46.2        | 47.1            |\n| Object Counting                           | 34.7      | 32.4        | 35.1        | 33.7            |\n| Penguins in a Table                       | 43.5      | 41.3        | 45.0        | 35.9            |\n| Reasoning about Colored Objects           | 32.0      | 40.2        | 40.7        | 40.0            |\n| Ruin Names                                | 23.3      | 19.3        | 24.4        | 24.4            |\n| Salient Translation Error Detection       | 37.3      | 47.3        | 37.1        | 36.0            |\n| Snarks                                    | 50.0      | 54.2        | 53.9        | 56.9            |\n| Sports Understanding                      | 56.0      | 54.7        | 55.1        | 56.7            |\n| Temporal Sequences                        | 16.7      | 25.1        | 18.2        | 18.2            |\n| Tracking Shuffled Objects (five objects)  | 12.0      | 12.0        | 12.0        | 12.3            |\n| Tracking Shuffled Objects (seven objects) | 6.7       | 6.7         | 6.7         | 7.7             |\n| Tracking Shuffled Objects (three objects) | 24.7      | 31.1        | 30.7        | 29.2            |\n| Web of Lies                               | 54.0      | 53.8        | 54.2        | 50.1            |\n| Word Sorting                              | 1.3       | 0.5         | 1.3         | 1.1             |\n| **Avg Performance Per Task**              | **27.0**  | **37.3**    | **31.6**    | **34.7**        |\n| **Avg Tokens Per Example**                | **111.6** | **597.8**   | **111.6**   | **111.6**       |\n| **Gradient-based Training**               | **No**    | **No**      | **Yes**     | **No**          |\n\n\nThe experimental results indicate that our method exhibits competitive, and even superior, average performance compared to IA3. We appreciate your insightful suggestion, which has led to a more targeted evaluation of our approach in comparison to IA3.\n\n## Question 6: The Weight Threshold\n---\n\nThank you for question! In fact, the final LORA parameters will all be within 1. The choice of 1.5 is more to adapt to the implementation of parameter-free optimization methods, providing a good initial step size. This parameter plays a role similar to the learning rate in the deep learning process. Choosing other parameters may increase the number of steps required for convergence (used to adjust the step size)."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700128528117,
                "cdate": 1700128528117,
                "tmdate": 1700129029180,
                "mdate": 1700129029180,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Q53NxIhPTS",
                "forum": "w8eCnnq57m",
                "replyto": "ZRcRwEWGGe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors [5/5]"
                    },
                    "comment": {
                        "value": "## Question 7: Including LoRA and Fine-tuning Results in Table 1\n---\n\nThank you for your constructive feedback regarding Table 1. We have thoroughly reviewed your suggestions, as well as those from other reviewers, and made the necessary adjustments to improve the comprehensiveness of our experimental results. In response to your suggestion, we have conducted additional experiments on LoRA tuning (LoRA), full fine-tuning (FFT), and report their average (avg) and best (best) performance across three different runs. Below is a summary of the results obtained from these experiments:\n\n| $\\rm Task$                                      | $\\rm ICL_{best}$ | $\\rm IA3_{best}$ | $\\rm LoRA_{best}$ | $\\rm FFT_{best}$ | $\\rm LoraHub_{best}$ | $\\rm ICL_{avg}$ | $\\rm IA3_{avg}$ | $\\rm LoRA_{avg}$ | $\\rm FFT_{avg}$ | $\\rm LoraHub_{avg}$ |\n|-------------------------------------------|--------------|--------------|---------------|--------------|------------------|-------------|-------------|--------------|-------------|-----------------|\n| Boolean Expressions                       | 62.7         | 58.0         | 60.7          | 65.3         | 60.7             | 59.6        | 56.2        | 56.0         | 62.2        | 55.5            |\n| Causal Judgement                          | 59.8         | 62.1         | 57.5          | 60.9         | 63.2             | 59.4        | 60.2        | 55.6         | 57.5        | 54.3            |\n| Date Understanding                        | 21.3         | 20.7         | 40.7          | 67.3         | 45.3             | 20.4        | 20.0        | 35.8         | 59.3        | 32.9            |\n| Disambiguation                            | 69.3         | 0.0          | 68.7          | 70.7         | 68.0             | 69.1        | 0.0         | 68.0         | 68.2        | 45.2            |\n| Dyck Languages                            | 2.0          | 4.7          | 25.3          | 33.3         | 2.7              | 0.9         | 4.2         | 22.2         | 19.5        | 1.0             |\n| Formal Fallacies                          | 59.3         | 52.0         | 56.7          | 56.0         | 59.3             | 55.3        | 51.5        | 53.6         | 54.0        | 52.8            |\n| Geometric Shapes                          | 20.0         | 15.3         | 28.7          | 39.3         | 18.7             | 19.6        | 14.7        | 24.0         | 31.1        | 7.4             |\n| Hyperbaton                                | 72.7         | 49.3         | 57.3          | 82.0         | 72.7             | 71.8        | 49.3        | 55.3         | 77.3        | 62.8            |\n| ... |  | | | | | | | | \n| Tracking Shuffled Objects (seven objects) | 6.7          | 6.7          | 12.0          | 10.0         | 15.3             | 6.7         | 6.7         | 10.0         | 9.8         | 7.7             |\n| Tracking Shuffled Objects (three objects) | 31.3         | 30.7         | 32.0          | 36.0         | 31.3             | 31.1        | 30.7        | 30.9         | 32.0        | 29.2            |\n| Web of Lies                               | 54.0         | 54.7         | 55.3          | 54.0         | 57.3             | 53.8        | 54.2        | 52.7         | 48.2        | 50.1            |\n| Word Sorting                              | 0.7          | 1.3          | 5.3           | 6.0          | 1.3              | 0.5         | 1.3         | 4.9          | 4.9         | 1.1             |\n| **Average Performance Per Task**            | **38.4**     | **32.1**     | **40.9**      | **46.2**     | **41.2**         | **37.3**        | **31.6**        | **37.7**         | **42.1**        | **34.7**            |\n| **Avg Tokens Per Example**       |      **597.8**  | **111.6**  | **111.6**   | **111.6**  | **111.6**      |      **597.8**  | **111.6**  | **111.6**   | **111.6**  | **111.6**      |\n| **Gradient-based Training**             |     **No**     | **Yes**    | **Yes**     | **Yes**    | **No**     |      **No**     | **Yes**    | **Yes**     | **Yes**    | **No**     |\n\n\n## Question 8: In-Context Learning Comparison\n---\n\nThanks for your question! The in-context learning (ICL) results are derived from Flan-T5-large to ensure a fair and consistent comparison. Given that Flan-T5-large has been exposed to the same dataset utilized in training LoRA candidates, this setup establishes a fair basis for assessing the performance of both ICL and LoraHub on the BBH task. To reflect this decision clearly, we have revised the descriptions in the caption of Table 1 accordingly."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700128630706,
                "cdate": 1700128630706,
                "tmdate": 1700128693524,
                "mdate": 1700128693524,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hJ9ka14bW6",
                "forum": "w8eCnnq57m",
                "replyto": "ZRcRwEWGGe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Reviewer_8M9N"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Reviewer_8M9N"
                ],
                "content": {
                    "comment": {
                        "value": "If we select T5 LM as the backbone, I agree that the baseline might not be very strong. However, we could incorporate retrieval baselines. This could involve selecting a dataset from the FLAN collection that performs best across various held-out datasets and choosing the most effective dataset from the collection for each held-out dataset for a more effective comparison. I believe this approach is appropriate because, in a general LoRAhub setting, it wouldn't be reasonable to assume a multitask backbone. The strategy would then involve adding LoRA to all held-in datasets, and for held-out datasets, learning the weights using a few examples from each held-out dataset. I understand obtaining results for this setting in a short time frame might be challenging. However, could you provide your thoughts on whether this represents the future direction of LoraHub?\n\nThank you for running experiments with different ranks. It helps justify the choice of rank=16.\n\nIt's encouraging to see that the LoRAhub filter offers a slight improvement over the original method. Thank you for conducting these experiments.\n\nThank you also for experimenting with choosing the best dataset for all held-out datasets. The results show that RACE: Right outperforms the Flan-T5 Large multitask model by 3.8 points, indicating the drawbacks of multitasking a model. Training LoRA for each dataset and learning to weigh them for held-out datasets seems to be a more beneficial approach.\n\nRegarding the retrieval baseline, I\u2019d like to point out that the original retrieval method involves creating an expert library with keys as encoded examples using a sentence encoder, and values as LoRA weights. For held-out datasets, it operates by taking the inner product of keys, which are encoded representations of a few examples, and retrieves a LoRA weight by majority. Could you please modify the baseline accordingly? \n\nThank you for clarifying the aspects of negative coefficients, the ICL baseline, and weight thresholds. Are there any experiments where not including a weight threshold negatively impacts the method?\n\nFinally, regarding the PEFT baselines, I just want to confirm: did you train IA3 and LoRA by initializing them randomly and then training only with the 5-10 few-shot examples from the held-out dataset?\n\n\nI noticed that the average performance on BBH using FLAN-T5-large in Table 1 is higher than the FLAN-T5-xl results in Table 6. I am under the impression that larger models usually perform better. Could you please double-check these results?"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700419846134,
                "cdate": 1700419846134,
                "tmdate": 1700419972861,
                "mdate": 1700419972861,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Xalm4uoggH",
                "forum": "w8eCnnq57m",
                "replyto": "ZRcRwEWGGe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 8M9N [1/2]"
                    },
                    "comment": {
                        "value": "We sincerely appreciate your acknowledgment of the significance of our recent experiment and are grateful for your encouraging remarks. Your thoughtful and constructive feedback is highly valued, serving as a guiding force to improve the quality and direction of our work. We genuinely thank you for dedicating your time and expertise to provide insightful comments that will undoubtedly contribute to refining our research. In response to your inquiries, we have provided detailed responses below.\n\n> If we select T5 LM as the backbone, I agree that the baseline might not be very strong. However, we could incorporate retrieval baselines. This could involve selecting a dataset from the FLAN collection that performs best across various held-out datasets and choosing the most effective dataset from the collection for each held-out dataset for a more effective comparison. I believe this approach is appropriate because, in a general LoRAhub setting, it wouldn't be reasonable to assume a multitask backbone. The strategy would then involve adding LoRA to all held-in datasets, and for held-out datasets, learning the weights using a few examples from each held-out dataset. I understand obtaining results for this setting in a short time frame might be challenging. However, could you provide your thoughts on whether this represents the future direction of LoraHub?\n\nThank you for your insightful suggestions regarding the improvement of our experimental setup. We highly value your recommendation to incorporate a retrieval baseline from the FLAN collection, as it aligns more closely with practical applications and establishes a reasonable baseline for comparative analysis. Constructing LoraHub on base language models, as you proposed, is a promising approach that not only boosts its generality but also reduces the risk of potential overfitting of language models to specific tasks.\n\nAlthough time constraints limit our capacity to conduct experiments on both the retrieval baseline and construct LoraHub using other base language models beyond T5-large, we fully recognize that exploring these avenues is essential for enhancing the overall value of our paper. **Therefore, we are committed to incorporating experiments featuring Llama 2 as the base model for LoraHub in the final version of our paper**. The addition will enable us to compare its effectiveness with the current FLAN-T5, providing valuable insights for the entire research community. Thank you again for your thoughtful input.\n\n> Regarding the retrieval baseline, I\u2019d like to point out that the original retrieval method involves creating an expert library with keys as encoded examples using a sentence encoder, and values as LoRA weights. For held-out datasets, it operates by taking the inner product of keys, which are encoded representations of a few examples, and retrieves a LoRA weight by majority. Could you please modify the baseline accordingly?\n\nThank you for your thoughtful feedback and corrections. Following your suggestions, we conducted experiments utilizing the `sentence-transformers/all-MiniLM-L6-v2` as the sentence encoder for similarity measurement to retrieve LoRA module candidates. Unfortunately, the results fell short of expectations, with an average performance across all tasks in BBH reaching 28.3. This slightly surpassed the zero-shot setting but lagged behind the loss-based LoRA retrieval baseline.\n\nIn analyzing the reasons for these unexpected results, we find it is usually challenging to identify relevant LoRA experts based on the prompt similarity, especially in cases where there are no explicit upstream tasks closely related to the evaluation tasks. Notably, we also encountered some positive outcomes, where tasks like `Movie Recommendation` successfully identified relevant LoRA experts (e.g., `Duorc ParaphraseRC: Movie Director`).\n\nNevertheless, it is crucial to acknowledge that the limited time may have impacted the implementation of our baseline, and we recognize the potential for incompleteness in its current state. We are committed to conducting a thorough review and addressing any shortcomings in the final version. Additionally, we are exploring alternative retrieval systems to better align with the concepts presented in the referenced paper. Please let us know if you have any concern!"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700476108645,
                "cdate": 1700476108645,
                "tmdate": 1700486875174,
                "mdate": 1700486875174,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FtMvNNLoV9",
                "forum": "w8eCnnq57m",
                "replyto": "ZRcRwEWGGe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 8M9N [2/2]"
                    },
                    "comment": {
                        "value": "> Thank you for clarifying the aspects of negative coefficients, the ICL baseline, and weight thresholds. Are there any experiments where not including a weight threshold negatively impacts the method?\n\nThanks for your question! In response, we conducted an ablation study by removing the threshold. Our observations revealed that this adjustment had minimal impact on the majority of tasks, underscoring the robustness of the gradient-free optimization algorithm in most scenarios. The algorithm efficiently identified reasonable ranges without specific upper and lower bounds. \n\nHowever, three tasks, namely `Date Understanding`, `Disambiguation` and `Hyperbaton`, exhibited notable effects. The resulting performance decline led to an average decrease of `1.2%` compared to with threshold. This highlights the significance of establishing a reasonable threshold to mitigate extreme scenarios. A summary of the experimental results is outlined below, with additional details provided in Appendix H.\n\n| $\\rm Task$                                | $\\rm {LoraHub_{avg}}\\ w/\\ Threshold$   |  $\\rm {LoraHub_{avg}}\\ w/o\\ Threshold$  |\n|-------------------------------------------|---------------------|----------------------|\n| Boolean Expressions                       | 55.5                | 54.0                 |\n| Causal Judgement                          | 54.3                | 54.8                 |\n| Date Understanding                        | 32.9                | 17.7                 |\n| Disambiguation                            | 45.2                | 40.6                 |\n| ... | ... | ... |\n| Temporal Sequences                        | 18.2                | 16.7                 |\n| Tracking Shuffled Objects (five objects)  | 12.3                | 12.3                 |\n| Tracking Shuffled Objects (seven objects) | 7.7                 | 8.5                  |\n| Tracking Shuffled Objects (three objects) | 29.2                | 29.8                 |\n| Web of Lies                               | 50.1                | 50.3                 |\n| Word Sorting                              | 1.1                 | 1.3                  |\n| **Average Performance**                   | **34.7**            | **33.5**                 |\n\n> Finally, regarding the PEFT baselines, I just want to confirm: did you train IA3 and LoRA by initializing them randomly and then training only with the 5-10 few-shot examples from the held-out dataset?\n\nYes, we trained IA3 and LoRA by initializing them randomly and using only 5 examples, aligning with the same examples employed in LoraHub and In-Context Learning.\n\n> I noticed that the average performance on BBH using FLAN-T5-large in Table 1 is higher than the FLAN-T5-xl results in Table 6. I am under the impression that larger models usually perform better. Could you please double-check these results?\n\nThank you for bringing attention to the discrepancy between FLAN-T5-large and FLAN-T5-xl results. We have carefully re-evaluated the numbers, and we can confirm that the reported results for FLAN-T5-xl are accurate. However, we deeply appreciate your concerns and thus conduct a thorough investigation in the results. Based on our observations, FLAN-T5-xl exhibits less robust output formatting (at least on BBH), particularly in zero-shot tasks like `logical_deduction` and `tracking_shuffled_objects`. This impacts the exact match metrics, resulting in lower zero-shot performance. For instance, in cases where the expected output should be `(b)`, FLAN-T5-xl outputs `b. large rectangular Turkish knife`, despite being prompted to output only the option itself. We are committed to addressing this issue by implementing more robust post-processing techniques in the final version. Your careful observation has prompted us to enhance the reliability and accuracy of our experimental evaluations.\n\nFinally, we hope you will take into consideration an increase in your scores based on the aforementioned improvements. As we work on revising the paper to address your concerns, please feel free to let us know if there's any clarification or additional information we can provide."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700476447904,
                "cdate": 1700476447904,
                "tmdate": 1700476585461,
                "mdate": 1700476585461,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gTbGTCSwd6",
                "forum": "w8eCnnq57m",
                "replyto": "FtMvNNLoV9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Reviewer_8M9N"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Reviewer_8M9N"
                ],
                "content": {
                    "comment": {
                        "value": "I genuinely appreciate the authors' efforts in experimenting with the suggested baselines and believe that the framework established by this paper will benefit the community. However, while the proposed method offers better inference benefits compared to ICL, it does not show any performance advantages over ICL and even underperforms compared to LoRA tuning. The latter has a similar inference speed to the proposed method, with perhaps a slight overhead in training, but this is only a one-time requirement. Therefore, I am keeping my score. I wish the authors the best of luck in continuing to develop in this direction."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700579886858,
                "cdate": 1700579886858,
                "tmdate": 1700579886858,
                "mdate": 1700579886858,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "bdHzkKHaM0",
            "forum": "w8eCnnq57m",
            "replyto": "w8eCnnq57m",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission97/Reviewer_ZnG8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission97/Reviewer_ZnG8"
            ],
            "content": {
                "summary": {
                    "value": "The paper tackles the task of employing `LoRA` (parameter-efficient low rank adapters) for few-shot learning of unseen tasks:: When only few samples are available for a new task, then training a new `LoRA` module on it may not work well. Instead, the paper considers the setting where several `LoRA` modules are available, pretrained on a set of upstream tasks $T_i$. Then, given a set of few samples for a new task, the proposed `LoRAHub` aims to learn the ideal \"meta-weights\" $w_i$ such that the agglomerated `LoRA` module $\\sum_i w_i LoRA_{T_i }$ yields the best performance for the new few-shot task (Note that this required that all upstream `LoRA` modules have the same rank).\n\nTo optimize the weights $w$, `LoraHub` employs a gradient-free method based on combinatorial optimization, `Shiwa`, and uses it to minimize the loss on the given few-shot samples, with an additional regularization term on the weights $w$.\n\nThe proposed method is then evaluated using a `Flan-T5` backbone on the `Big-Bench Hard` benchmark. The upstream tasks are the 200 tasks originally used to instruct `Flan-T5`; however, in practice, a random subset of 20 tasks is used in each run, such that we only have 20 weights $w_i$ to tune in each run. Overall, `LoraHub` performs almost on-par with in-context learning method, with the advantage that it requires shorter input prompts hence fewer tokens to process (essentially identical to zero-shot learning)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- **Interesting idea and motivation**: I find the core idea of the paper very interesting with potential applications to fields such as multi-task learning or continual learning. While there are similar concurrent idea mixing mixture-of-experts with LoRA, I found the results of the paper and focus on few-shot multi-task novel and insightful.\n\n- **Clear writing**: Overall the paper is clearly written, easy to read and understand. \n\n- **Detailled experimental analysis**: I found the experimental analysis (Section 5 in the paper) quite interesting and raises interesting properties as well as limitations of the proposed method."
                },
                "weaknesses": {
                    "value": "- **Computational cost of optimization**: Unlike In-Context Learning, `LoraHub` does not need to process additional tokens hence a reduced inference cost. However, it also adds the cost to optimize the combination weights $w$ on the input few-shot samples, in particular when many upstream tasks are available. It would be interesting to discuss the trade-off between these two costs, e.g. say we have some few-shot samples but only want to solve the associated task once, it might be more practical to use in-context learning rather than the optimization pipeline of `LoraHub` ?\n\n- **Optimization of $w$ for many tasks and robustness of `LoRAHub`:** It's not clear to me how the optimization methods scale to a higher number of upstream LoRA modules either in terms of cost (see previous point) or performance: In **Figure 4**, we see that increasing the number of LoRA module does not always improve performance but strongly affects the variance of the outputs. This suggests that the optimization procedure is either noisy and/or does not converge well. As a consequence, it means that the number of candidate upstream LoRA modules, $N$, must be carefully selected (and the optimal $N$ even seems to be task dependent from **Figure 4**) which introduces an additional hyperparameter. This can be an important limitation for real-life applications."
                },
                "questions": {
                    "value": "- On the topic of **optimizing $w$ for many tasks**, I am wondering if authors have considered alternative techniques which might be more robust to optimization noise (beyond the prefiltering strategy mentioned in Section 7): e.g. a hierarchical approach (optimize $w$ for multiple random subsets of 20 LoRA candidates, then learn $w'$ for these agglomerated modules) or a curriculum like approach (gradually drop some of the candidates when optimizing $w$ if they are consistently given very low weights) ?\n\n- **Question/Suggestion on Table 1**:  it is not clear to me whether Table 1 reports results averaged on 5 random seeds for *all methods* or only for `LoraHub` and whether the different random seeds impact the choice of query few-shot samples, or only optimization(e.g. initialization, and library of Lora modules). Maybe a more complete evaluation metric would be to report (avg) and (best) for all methods (or even some form of significance test) to understand how robust the other methods are to the random seed. \n\n- **Figure 3 and variance**: I think **Figure 3** would be much more convincing with error bars or some notion of variance. This figure's aim is to illustrate that \"LoRA with few samples does not work as well as LoraHub's few-shot learning\" , however the results are only available for 3 tasks, for which the assumption only holds until 20 few-shot samples;therefore it's not clear how the insight generalizes to more few-shot settings."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission97/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698767503462,
            "cdate": 1698767503462,
            "tmdate": 1699635934639,
            "mdate": 1699635934639,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "eaa7dbW1UK",
                "forum": "w8eCnnq57m",
                "replyto": "bdHzkKHaM0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors [1/3]"
                    },
                    "comment": {
                        "value": "We sincerely appreciate the reviewer's examination of our paper and the insightful, detailed comments provided. The constructive feedback has been invaluable in refining our work, and we have incorporated them into our revisions.\n\n## Weakness 1: Computational Cost of Optimization\n---\n\nThank you for your insightful comment regarding the trade-off between the costs of in-context learning and LoraHub. We truly appreciate your observation, and we have addressed this trade-off in our discussion below.\n\nLoraHub addresses the challenge of reducing inference costs by eliminating the need for processing additional tokens, resulting in a noticeable reduction in overall inference expenses. However, it indeed introduces an inherent cost during the Adapt stage, necessitating extra inference steps. This introduces a trade-off between choosing the in-context learning approach and LoraHub, with the decision typically hinging on the nature of the situation.\n\nFor one-time ad-hoc tasks, the in-context learning approach should be more pragmatic due to LoraHub's additional inference step costs. In such scenarios, where immediate, single-use solutions are preferred, the simplicity and efficiency of in-context learning might outweigh the benefits of potential savings offered by LoraHub. Conversely, for recurring or similar tasks, LoraHub emerges as a compelling option. Despite the initial fixed cost associated with the Adapt stage, LoraHub's ability to efficiently handle repetitive tasks, often occurring thousands of times, while simultaneously reducing overall expenses, establishes it as a practical and viable option in such scenarios.\n\nIn summary, our intention is not to replace in-context learning with LoraHub, but to present LoraHub as a complementary strategy with performance-efficiency trade-offs. We appreciate your valuable feedback, and in response, we have revised the paper to thoroughly discuss these trade-offs in Section 4.3. Thank you again for bringing this to our attention.\n\n## Weakness 2 / Question 1\uff1aOptimizing for Many Tasks and the Robustness of Optimization\n---\n\nWe are grateful for the thoughtful feedback provided by the reviewer, especially regarding alternative methods to address variance in the optimization process. We highly appreciate the suggestions for exploring a hierarchical or curriculum-like strategy to enhance robustness beyond the prefiltering approach.\n\nWhile these suggestions are intriguing, we would like to clarify that, based on our in-depth analysis, the primary source of variance in our current method is not related to gradient-free optimization algorithms but rather associated with the LoRA candidate modules. In other words, once the candidates are determined, random seeds have minimal impact on the final performance. Hence, we posit that the observed instability primarily arises from the inherent challenge of balancing the `quantity` and `quality` of the LoRA module candidates. This hypothesis receives partial support from our analysis in Section 5, where attempts to increase the number of LoRA modules led to a noticeable rise in model performance volatility.\n\nIn response to this observation, we explored a straightforward approach in the selection of LoRA module candidates. Specifically, we first identified $20$ LoRA module candidates with the lowest loss on the few-shot examples, with the goal of minimizing introduced variance and fostering a more consistent performance. This strategic selection process, named as $\\rm LoraHub_{filter}$, has notably contributed to a slight enhancement in average performance compared to  $\\rm LoraHub_{avg}$. Below we show a brief summary of the results, and the detailed results can be found in Appendix D.\n\n| $\\rm Task$                                   | $\\rm LoraHub_{avg}$ | $\\rm LoraHub_{filter}$ |\n|-------------------------------------------|-------------|----------------|\n| Boolean Expressions                       | 55.5        | 60.0           |\n| Causal Judgement                          | 54.3        | 52.9           |\n| Date Understanding                        | 32.9        | 33.3           |\n| Disambiguation                            | 45.2        | 62.7           |\n| Dyck Languages                            | 1.0         | 0.0            |\n| ... | | |\n| Tracking Shuffled Objects (three objects) | 29.0        | 32.7           |\n| Web of Lies                               | 53.0        | 46.0           |\n| Word Sorting                              | 1.1         | 1.3            |\n| **Avg Performance Per Task**                  |**34.7**       | **35.4**          |\n\n\nHowever, the method has also introduced additional reasoning overhead, as the losses of all LoRA module candidates need to be calculated. We have also discussed the variance in Appendix G. We appreciate your insights and remain open to further discussion on refining our methodology. We intend to explore additional strategies in future investigations."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700126516964,
                "cdate": 1700126516964,
                "tmdate": 1700128002657,
                "mdate": 1700128002657,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZQ5GPggyYw",
                "forum": "w8eCnnq57m",
                "replyto": "bdHzkKHaM0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors [2/3]"
                    },
                    "comment": {
                        "value": "## Question 2\uff1aSuggestion on Table 1\n---\n\nThank you for your constructive feedback regarding Table 1. We have thoroughly reviewed your suggestions, as well as those from other reviewers, and made the necessary adjustments to improve the comprehensiveness of our experimental results. In response to your suggestion, we have conducted additional experiments by randomly sampling three sets of five examples each and applied various few-shot methods to assess their robustness. We follow your suggestion to report both the average (avg) and best (best) performance across multiple runs. Below is a summary of the results obtained from these experiments:\n\n| $\\rm Task$                                      | $\\rm ICL_{best}$ | $\\rm IA3_{best}$ | $\\rm LoRA_{best}$ | $\\rm FFT_{best}$ | $\\rm LoraHub_{best}$ | $\\rm ICL_{avg}$ | $\\rm IA3_{avg}$ | $\\rm LoRA_{avg}$ | $\\rm FFT_{avg}$ | $\\rm LoraHub_{avg}$ |\n|-------------------------------------------|--------------|--------------|---------------|--------------|------------------|-------------|-------------|--------------|-------------|-----------------|\n| Boolean Expressions                       | 62.7         | 58.0         | 60.7          | 65.3         | 60.7             | 59.6        | 56.2        | 56.0         | 62.2        | 55.5            |\n| Causal Judgement                          | 59.8         | 62.1         | 57.5          | 60.9         | 63.2             | 59.4        | 60.2        | 55.6         | 57.5        | 54.3            |\n| Date Understanding                        | 21.3         | 20.7         | 40.7          | 67.3         | 45.3             | 20.4        | 20.0        | 35.8         | 59.3        | 32.9            |\n| Disambiguation                            | 69.3         | 0.0          | 68.7          | 70.7         | 68.0             | 69.1        | 0.0         | 68.0         | 68.2        | 45.2            |\n| Dyck Languages                            | 2.0          | 4.7          | 25.3          | 33.3         | 2.7              | 0.9         | 4.2         | 22.2         | 19.5        | 1.0             |\n| Formal Fallacies                          | 59.3         | 52.0         | 56.7          | 56.0         | 59.3             | 55.3        | 51.5        | 53.6         | 54.0        | 52.8            |\n| Geometric Shapes                          | 20.0         | 15.3         | 28.7          | 39.3         | 18.7             | 19.6        | 14.7        | 24.0         | 31.1        | 7.4             |\n| Hyperbaton                                | 72.7         | 49.3         | 57.3          | 82.0         | 72.7             | 71.8        | 49.3        | 55.3         | 77.3        | 62.8            |\n| ... |  | | | | | | | | \n| Tracking Shuffled Objects (seven objects) | 6.7          | 6.7          | 12.0          | 10.0         | 15.3             | 6.7         | 6.7         | 10.0         | 9.8         | 7.7             |\n| Tracking Shuffled Objects (three objects) | 31.3         | 30.7         | 32.0          | 36.0         | 31.3             | 31.1        | 30.7        | 30.9         | 32.0        | 29.2            |\n| Web of Lies                               | 54.0         | 54.7         | 55.3          | 54.0         | 57.3             | 53.8        | 54.2        | 52.7         | 48.2        | 50.1            |\n| Word Sorting                              | 0.7          | 1.3          | 5.3           | 6.0          | 1.3              | 0.5         | 1.3         | 4.9          | 4.9         | 1.1             |\n| **Average Performance Per Task**            | **38.4**     | **32.1**     | **40.9**      | **46.2**     | **41.2**         | **37.3**        | **31.6**        | **37.7**         | **42.1**        | **34.7**            |\n| **Avg Tokens Per Example**       |      **597.8**  | **111.6**  | **111.6**   | **111.6**  | **111.6**      |      **597.8**  | **111.6**  | **111.6**   | **111.6**  | **111.6**      |\n| **Gradient-based Training**             |     **No**     | **Yes**    | **Yes**     | **Yes**    | **No**     |      **No**     | **Yes**    | **Yes**     | **Yes**    | **No**     |\n\nAs depicted in the above table, it is evident that uncertainties exist in all methods when confronted with changes in few-shot examples. On average, LoraHub demonstrates a reasonable performance-efficiency trade-off, showcasing solid performance with a notable reduction in tokens. We have further updated Table 1 and introduced Table 3 (Appendix A) to incorporate these results. These tables present both the average performance and the best performance across different runs for each method. We hope these additional results contribute to a more comprehensive understanding of the methods' performance, effectively addressing your concerns."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700127094053,
                "cdate": 1700127094053,
                "tmdate": 1700128042898,
                "mdate": 1700128042898,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vnxl2BeSwi",
                "forum": "w8eCnnq57m",
                "replyto": "bdHzkKHaM0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors [3/3]"
                    },
                    "comment": {
                        "value": "## Question 3: Figure 3 and Variance\n---\n\nIn response to your insightful feedback, we have dedicated efforts to conduct a thorough analysis of various methods, including LoRA tuning (LoRA), full fine-tuning (FFT), and IA3 fine-tuning (IA3) as suggested by Reviewer 8M9N. Surprisingly, upon averaging the performance of LoRA tuning, our conclusions differ from the observations presented in Figure 3. Essentially, our new experimental results, as presented in Table 1 in response to Question 2, suggest that the previously highlighted instability of LoRA tuning, especially in scenarios with extremely limited examples, may have been overstated. As it stands, the overall performance of LoRA tuning appears to be great.\n\nIn light of these findings, we have taken the step of removing statements about the instability of LoRA tuning in Section 2, Section 4.2 and Section 5. Additionally, we have temporarily removed Figure 3 from the paper to prevent the dissemination of potentially inaccurate conclusions. In the final version, we are committed to enhancing the comprehensiveness of our presentation by expanding Figure 3 to encompass all tasks in BBH with varying numbers of examples. This extension aims to provide a more nuanced and thorough representation of our research findings. Your feedback has been invaluable in refining the precision and accuracy of our paper."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700127159855,
                "cdate": 1700127159855,
                "tmdate": 1700128057372,
                "mdate": 1700128057372,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1SJTs7Wfja",
                "forum": "w8eCnnq57m",
                "replyto": "bdHzkKHaM0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Any New Comments are Welcomed"
                    },
                    "comment": {
                        "value": "Dear Reviewer ZnG8,\n\nWe sincerely appreciate your thorough review and the valuable suggestions and comments you provided for our paper. We have carefully considered each point and have addressed them in detail in our rebuttal.\n\nAs the Author-Review Discussion period is drawing to a close with only two days remaining, we would like to ensure that all your concerns have been adequately addressed. If there are any questions or unresolved issues, we are eager to provide further clarification or make necessary revisions.\n\nBest regards,\n\nThe Authors"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700476991306,
                "cdate": 1700476991306,
                "tmdate": 1700477265456,
                "mdate": 1700477265456,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YhKyzvtYr2",
                "forum": "w8eCnnq57m",
                "replyto": "1SJTs7Wfja",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Reviewer_ZnG8"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Reviewer_ZnG8"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your response"
                    },
                    "comment": {
                        "value": "Dear authors,\nthank you for your rebuttal and addressing my questions! \nThanks for extending the results of Table 1 and making a stronger comparison to the baselines. And it's also very encouraging to see that introducing a selection criterion for the candidate LoRA modules can further boost the performance of $\\text{LoRAHub}_{\\text{filter}}$"
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700579843113,
                "cdate": 1700579843113,
                "tmdate": 1700579843113,
                "mdate": 1700579843113,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "WMWqjIwSXA",
            "forum": "w8eCnnq57m",
            "replyto": "w8eCnnq57m",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission97/Reviewer_pXQC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission97/Reviewer_pXQC"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a method to improve the generalizability of LLMs to new tasks. The proposed method can be summarized as below:\n1. Train several models on a set of downstream tasks (one model for each task). This is done in a parameter-efficient way using the LORA method. This results in a set of LORA models. \n2. Randomly choose a subset of the LORA models.\n3. Learn a set of weights to combine these LORA models using a few (for eg, 5) samples from a new task not seen in step 1. The weights are learnt using gradient-free optimization. \n4. Use the learnt weights to generate a combination of the LORA models and combine it with the base LLMs for inference. \n\nThe result is a method that can be used to improve generalizability when the number of samples available for a new task is very low."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper presents an interesting way to fine-tune LLMs on tasks where the number of training examples might be very low. \n- The proposed method uses gradient-free optimization to minimize resource requirements, since the number of parameters being learnt is very low.\n-The method outperforms zero-shot deployment of the base LLM."
                },
                "weaknesses": {
                    "value": "The main weakness of the paper is its performance compared to in-context learning (ICL), as highlighted in Table. 1. The authors acknowledge this in the paper but justify by saying that their method uses fewer tokens in their fine-tuning process compared to in-context learning. However, I feel that ICL is a very straight-forward and easy way to improve generalizability and that the problem that the authors are addressing is a minor one. Further, the performance of the proposed method also weakens the paper. From a practitioner's perspective I feel that the proposed method will be less appealing to just using ICL."
                },
                "questions": {
                    "value": "- Can the authors provide more insight into the impact of the reduced number of tokens required in the proposed method? What does that mean to a practitioner in the end? Especially considering the fact that the proposed method first needs the training of several LORA modules, the burden on a practitioner may actually be higher."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission97/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission97/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission97/Reviewer_pXQC"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission97/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699049999736,
            "cdate": 1699049999736,
            "tmdate": 1700576449210,
            "mdate": 1700576449210,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "sCeSHdYPNo",
                "forum": "w8eCnnq57m",
                "replyto": "WMWqjIwSXA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors [1/2]"
                    },
                    "comment": {
                        "value": "We deeply appreciate your thoughtful comments on our paper. Your insightful questions have proven invaluable, helping us refine and articulate the positioning and motivation of our work. To provide a clear overview, we outline three key reasons highlighting the significance of our paper below.\n\n## Reason 1. Inference Efficiency\n---\n\nWhile we acknowledge the effectiveness of in-context learning (ICL) for generalization, we wish to emphasize that our proposed LoraHub is not intended to replace ICL but rather to offer a complementary strategy with performance-efficiency trade-offs. An essential benefit of LoraHub, highlighted in our paper, is its focus on improving inference efficiency by utilizing fewer prompt tokens per example. As illustrated in Table 1, LoraHub demonstrates a significant advantage with a reduced token requirement per example \u2014 `111.6` tokens compared to the `597.8` tokens needed for ICL.\n\nThe efficiency of inference is paramount for real-world deployments, particularly when dealing with lots of inference examples. With fewer tokens per example during inference, our method significantly reduces computational overhead and enables faster responses. The commitment to optimizing inference efficiency aligns seamlessly with a broader research trend, as evidenced by several recent studies actively exploring approaches to reduce the number of input tokens [1,2,3,4,5,6]. For example, as stated in [1], in-context learning can be inefficient because it makes the input prompt much longer, consuming valuable space in the context window and leading to larger computational costs.\n\n[1]. Wangchunshu Zhou, Yuchen Eleanor Jiang, Ryan Cotterell, Mrinmaya Sachan, Efficient Prompting via Dynamic In-Context Learning. ArXiv abs/2305.11170 (2023) \n\n[2]. Tao Ge, Jing Hu, Lei Wang, Xun Wang, Si-Qing Chen, Furu Wei, In-context Autoencoder for Context Compression in a Large Language Model. ArXiv abs/2307.06945 (2023)\n\n[3]. Alexis Chevalier, Alexander Wettig, Anirudh Ajith, Danqi Chen, Adapting Language Models to Compress Contexts. ArXiv abs/2305.14788 (2023)\n\n[4]. Huiqiang Jiang, Qianhui Wu, Xufang Luo, Dongsheng Li, Chin-Yew Lin, Yuqing Yang, Lili Qiu, LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression. ArXiv abs/2310.06839 (2023)\n\n[5]. Yucheng Li, Bo Dong, Chenghua Lin, Frank Guerin, Compressing Context to Enhance Inference Efficiency of Large Language Models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing\n\n[6]. Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang, Lili Qiu, LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700125993563,
                "cdate": 1700125993563,
                "tmdate": 1700127967414,
                "mdate": 1700127967414,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "c5vPpaaYQI",
                "forum": "w8eCnnq57m",
                "replyto": "WMWqjIwSXA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors [2/2]"
                    },
                    "comment": {
                        "value": "## Reason 2. The Potential of LoraHub\n---\n\nWhile acknowledging that our current approach currently lags behind ICL in terms of average performance,  we posit that the inferior performance is primarily an artifact of our implementation rather than an inherent limitation of LoraHub. We believe that the observed gap can be narrowed through the development of better module composition algorithms. This conviction finds support in the new experimental results (below) on the challenging Big-Bench Hard benchmark.\n\nThe new experimental results directly address the suggestion from Reviewer `ZnG8`, which prompted us to report the best performance of ICL. In response, we conducted a meticulous examination, collecting three distinct sets of few-shot examples, ensuring a comprehensive evaluation that covers both **average** (Table 1) and **best** (Table 3) performances across all tasks for various methods. The **best** performance of both ICL and LoraHub are as below.\n\n| Task                                      | ICL$_{best}$ | LoraHub$_{best}$ |\n|-------------------------------------------|----------|----------|\n| Boolean Expressions                       | 62.7     | 60.7     |\n| Causal Judgement                          | 59.8     | 63.2     |\n| Date Understanding                        | 21.3     | 45.3     |\n| Disambiguation                            | 69.3     | 68.0     |\n| Dyck Languages                            | 2.0      | 2.7      |\n| Formal Fallacies                          | 59.3     | 59.3     |\n| Geometric Shapes                          | 20.0     | 18.7     |\n| Hyperbaton                                | 72.7     | 72.7     |\n| Logical Deduction (five objects)          | 39.3     | 40.0     |\n| Logical Deduction (seven objects)         | 42.0     | 46.0     |\n| Logical Deduction (three objects)         | 52.7     | 52.7     |\n| ... | | |\n| Tracking Shuffled Objects (five objects)  | 12.0     | 16.7     |\n| Tracking Shuffled Objects (seven objects) | 6.7      | 15.3     |\n| Tracking Shuffled Objects (three objects) | 31.3     | 31.3     |\n| Web of Lies                               | 54.0     | 57.3     |\n| Word Sorting                              | 0.7      | 1.3      |\n| **Avg Performance Per Task**     | **38.4**     | **41.2**     |\n| **Avg Tokens Per Example**          | **597.8**  |  **111.6** |\n\nNotably, our findings indicate that LoraHub's best performance surpasses that of ICL on 18 tasks, highlighting its promising potential for future development. This underscores the untapped capabilities of LoraHub, emphasizing its capacity to excel in challenging tasks.\n\n\n## Reason 3. New Insights\n---\n\nMore broadly, we believe our work opens an interesting research direction in composing LoRA modules for unseen task generalization. While our current prototype still requires few-shot examples, we are excited by the possibility of automating the module composition process without any example. There is great potential in finding the right assemblies of specialized modules to attain broad capabilities.\n\nOur vision is to democratize artificial intelligence. Specifically, we aim to establish a LoRA platform where users can seamlessly share and access well-trained LoRA modules for application in new tasks. LoRA providers can freely share or sell their modules on the platform without compromising data privacy. Users can leverage powerful LoRA modules contributed by others, utilizing algorithms for automated distribution, with the process requiring only CPU capability. The training of LoRA modules in our experiments serves as a simulation of LoRA providers within the platform.\n\n## Summary\n---\n\nThank you again for the constructive feedback. We hope the above clarification alleviates your concerns and provides more insights into our method. We have revised our paper to more clearly position the trade-offs and potential of our approach compared to ICL. Please let us know if you have any other suggestions for improving our messaging and the impact of this work."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700126058018,
                "cdate": 1700126058018,
                "tmdate": 1700127864683,
                "mdate": 1700127864683,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qfAyNeWidl",
                "forum": "w8eCnnq57m",
                "replyto": "WMWqjIwSXA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Any New Comments Would be Greatly Appreciated"
                    },
                    "comment": {
                        "value": "Dear Reviewer pXQC,\n\nWe appreciate the time and effort you dedicated to reviewing our paper. Your feedback is invaluable to us, and we genuinely thank you for your insightful comments.\n\nWe want to assure you that we took your feedback seriously and made a concerted effort to address the highlighted issues to the best of our ability. We conducted additional experiments, and refined our arguments to enhance the overall quality of the paper. We are open to any further suggestions or specific points you feel require additional attention.\n\nThank you once again for your time and consideration. We look forward to the opportunity to discuss any remaining concerns.\n\nBest Regards,\n\nThe Authors"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700477477878,
                "cdate": 1700477477878,
                "tmdate": 1700477676709,
                "mdate": 1700477676709,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yjANzVMCQR",
                "forum": "w8eCnnq57m",
                "replyto": "qfAyNeWidl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission97/Reviewer_pXQC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission97/Reviewer_pXQC"
                ],
                "content": {
                    "title": {
                        "value": "Update after reading author rebuttal"
                    },
                    "comment": {
                        "value": "I thank the authors for the detailed response. I appreciate the clarification regarding why the reduced number of input tokens is an important contribution and I acknowledge the same. \n\nI have raised my score from 3 to 5."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission97/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700577148965,
                "cdate": 1700577148965,
                "tmdate": 1700577148965,
                "mdate": 1700577148965,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]