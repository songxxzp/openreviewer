[
    {
        "title": "Querying Easily Flip-flopped Samples for Deep Active Learning"
    },
    {
        "review": {
            "id": "H0Lq4NPE5w",
            "forum": "THUBTfSAS2",
            "replyto": "THUBTfSAS2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7173/Reviewer_L6Gr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7173/Reviewer_L6Gr"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new active learning technique based on novel selection strategy of unlabeled examples. Its main contributions are the following:\n\n\u2014\u00a0A new measure of closeness to the decision boundary the authors call the 'least disagree metric' (LDM). This is a metric inspired by the disagree metric of [1],  to play a role akin to \"margin-score\" or \"entropy\" in the standard active-learning algorithms like \"margin\" etc. As the authors mention, conceptually, a sample with a small LDM indicates that its prediction can be easily flip-flopped even by a small perturbation in the predictor. \n\n\u2014\u00a0An estimator of LDM that is provably asymptotically consistent under mild assumptions, and a simple Bayesian-perspective-inspired algorithm to empirically evaluate such an estimator. (LDM is intractable to compute in most cases so the authors propose.)\n\n\u2014\u00a0An LDM-based active learning algorithm (LDM-S) that, besides using LDM as the \"scoring function\" for selecting unlabeled examples\",  it also makes sure that there's \"diversity\" in the selected batch of unlabeled examples to be labeled. In particular, diversity is ensured via a modification of the k-means++ seeding algorithm and  without introducing additional hyperparameters. Finally, The authors compare their algorithm with several SOTA active learning techniques and show that it typically performs better.\n\n[1]  Theory of Disagreement-Based Active Learning. Foundations and Trends\u00ae in Machine Learning, 7(2-3):131\u2013309, 2014, Steve Hanneke."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "\u2014\u00a0Well-written paper\n\n\u2014\u00a0Novel, principled approach to active-learning.\n\n\u2014\u00a0A method of incorporating diversity in the sample selection without adding hyperparameters.\n\n\u2014\u00a0Extensive experimental evaluation."
                },
                "weaknesses": {
                    "value": "\u2014\u00a0The proposed approach provides somewhat mild benefits compared to already existing approaches (although it is consistently the best or the second best approach in each scenario, and the best according to metrics that consider the average performance among all datasets.)\n\n\u2014The datasets considered in this paper are somewhat small-scale, and so it's not clear to me whether the proposed approach is suitable for large-scale applications. For example, in Table 2 where the authors present the running time per dataset, Imagenet \u2014 which is the largest dataset considered in this paper, is missing."
                },
                "questions": {
                    "value": "Could the authors provide the mean running time of each algorithm considered for the Imagenet dataset?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7173/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698637350352,
            "cdate": 1698637350352,
            "tmdate": 1699636850940,
            "mdate": 1699636850940,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "atMsLNroUJ",
                "forum": "THUBTfSAS2",
                "replyto": "H0Lq4NPE5w",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7173/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7173/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for an overall positive outlook of our paper as well as insightful questions. Let us clarify the points raised in the review:\n\n\n> The proposed approach provides somewhat mild benefits compared to already existing approaches (although it is consistently the best or the second best approach in each scenario, and the best according to metrics that consider the average performance among all datasets.)\n\nWe first emphasize that, as shown by our extensive experiments, our algorithm consistently outperforms or is at least at par with, prior state-of-the-art algorithms over various scenarios (varying datasets, networks, etc). This characteristic is very important as it shows how strong and safe our algorithm is, i.e., how robust our algorithm is to the scenario considered.\n\nWe also note that our algorithm *appears* to provide mild benefits compared to existing approaches because it is compared with the best-performing algorithm for each dataset. Our algorithm provides significantly improved performance when comparing each algorithm across all datasets, which is arguably a fairer comparison. For example, our algorithm significantly outperforms OML#6, OML#44135, CIFAR10, SVHN, TinyImageNet, and FOOD101 compared to BADGE on all datasets. In particular, there is a large performance difference of about 2% between the two algorithms on OML#6 and OML#44135. \n\n\n> The datasets considered in this paper are somewhat small-scale, and so it's not clear to me whether the proposed approach is suitable for large-scale applications. For example, in Table 2 where the authors present the running time per dataset, Imagenet \u2014 which is the largest dataset considered in this paper, is missing.\n\n> Could the authors provide the mean running time of each algorithm considered for the Imagenet dataset?\n\nFor ImageNet, we have used different hardware (CPU/GPU) for each algorithm due to time and resource constraints, so a fair comparison between the algorithms is impossible. Still, to answer your pointed-out weakness, one step of acquisition time (min) is reported.\nThe results are as follows.\n\n| Algorithm  | time (min) |\n| -------- | ------- |\n|Training |\t4,572.1, |\n|LDM-S |\t\t     62.8, |\n|Entropy |\t       5.5, |\n|Margin | \t       3.6, |\n|Coreset | \t     96.6, |\n|ProbCov | \t     17.0, |\n|ENS | \t\t     18.1, |\n|BADGE | \t1,389.9.|\n\nIf we only compare the acquisition time of a single step, our algorithm seems to take longer than Entropy or Margin. Still, the difference is insignificant if we consider the training time of the model, which was three days. In the case of BADGE, the runtime is proportional to the square of the number of features and classes, so the runtime increases significantly on ImageNet compared to other datasets, which is in contrast to our algorithm, which is comparable to other algorithms. ENS has a short acquisition time, but this is because only the time for calculating the variation ratio is measured. If the whole training time of ensemble networks is considered, the runtime is about 15 days."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7173/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700411440346,
                "cdate": 1700411440346,
                "tmdate": 1700411440346,
                "mdate": 1700411440346,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Gh8WpPJDQq",
                "forum": "THUBTfSAS2",
                "replyto": "atMsLNroUJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7173/Reviewer_L6Gr"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7173/Reviewer_L6Gr"
                ],
                "content": {
                    "title": {
                        "value": "Reply"
                    },
                    "comment": {
                        "value": "Thank you for the additional experiments and explanations! I will keep my the score as is \u2014\u00a0but I am still an advocate of the paper being accepted."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7173/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700421051254,
                "cdate": 1700421051254,
                "tmdate": 1700421051254,
                "mdate": 1700421051254,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ausjfpscSL",
                "forum": "THUBTfSAS2",
                "replyto": "H0Lq4NPE5w",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7173/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7173/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the review"
                    },
                    "comment": {
                        "value": "Thank you for your constructive feedback that helped us further improve our paper and for a positive outlook. We are grateful to the reviewer for advocating our paper, and we will ensure that all the feedback and comments are incorporated into our final manuscript."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7173/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700461136614,
                "cdate": 1700461136614,
                "tmdate": 1700475518474,
                "mdate": 1700475518474,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zYR9Dbs8AQ",
            "forum": "THUBTfSAS2",
            "replyto": "THUBTfSAS2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7173/Reviewer_ixMJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7173/Reviewer_ixMJ"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes to use LDM estimator as heuristics to query samples for active learning. The estimator is proven to be asymptotically consistent under mild assumptions. Two approaches based on LDM, i.e., naive approach and LDM-S, have been considered for batch active learning."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "(1) The paper maintains a high-quality presentation. The measure, proof of asymptotical consistency, and algorithms are clearly presented.\n(2) Extensive experiments on 3 openml datasets and 6 benchmark image datasets."
                },
                "weaknesses": {
                    "value": "(1) Many baseline models are not considered in the paper's experiment, e.g., SAAL, Cluster-Margin, Similar, and [4]. \n\n(2) Computational cost analysis is lacking, including LDM estimation cost and LDM-S. What is the relationship to batch size, ensemble size, M, etc? The computational cost seems to be comparable to BADGE which has squared complexity to batch size. \n\n(3) The authors provide no analysis of the relatedness of LDM to active learner performance in the paper setting.\n\n(4) Careful discussion of limitations is lacking in the paper. There are many deep active learning algorithms coming out each year, each with its own pros and cons. A careful discussion of advantages and limitations will be very helpful to the community. One possible drawback is the need to use ensembles which takes more cost compared to methods that only use one model like BADGE and CoreSet.\n\n(5) The seeding strategy seems detached from the novel estimator. Many strategies, e.g., [1], [2], and [4], have been published to extend to batches. It is better to compare these strategies based on LDM and show if the performance improvement is consistent.\n\nreferences:\n\n[1] Kim, Yoon-Yeong, Youngjae Cho, JoonHo Jang, Byeonghu Na, Yeongmin Kim, Kyungwoo Song, Wanmo Kang, and Il-chul Moon. \"SAAL: Sharpness-Aware Active Learning.\" (2023).\n\n[2] Citovsky, Gui, Giulia DeSalvo, Claudio Gentile, Lazaros Karydas, Anand Rajagopalan, Afshin Rostamizadeh, and Sanjiv Kumar. \"Batch active learning at scale.\" Advances in Neural Information Processing Systems 34 (2021): 11933-11944.\n\n[3] Kothawade, Suraj, Nathan Beck, Krishnateja Killamsetty, and Rishabh Iyer. \"Similar: Submodular information measures based active learning in realistic scenarios.\" Advances in Neural Information Processing Systems 34 (2021): 18685-18697.\n\n[4] Kirsch, Andreas, Sebastian Farquhar, Parmida Atighehchian, Andrew Jesson, Fr\u00e9d\u00e9ric Branchaud-Charron, and Yarin Gal. \"Stochastic Batch Acquisition: A Simple Baseline for Deep Active Learning.\" Transactions on Machine Learning Research (2023)."
                },
                "questions": {
                    "value": "(1) Could the authors provide numerical or illustrative examples to show that LDM-based algorithm can be more effective in deep active learning? The authors provided the asymptotical analysis of the estimator but no analysis is provided for the relatedness of LDM to the final performance. In this case, it is better to provide some illustrative examples to show the effectiveness of LDM-based algorithms. \n\n(2) I am very interested to see the performance of active learning models with MC-dropout. MC-dropout is more efficient compared ensemble method.\n\n(3) Could the authors explain why they do not use more advanced posterior sampling method like [1] and [2]\n\nreferences:\n\n[1] Zhang, Ruqi, Chunyuan Li, Jianyi Zhang, Changyou Chen, and Andrew Gordon Wilson. \"Cyclical stochastic gradient MCMC for Bayesian deep learning.\" arXiv preprint arXiv:1902.03932 (2019).\n\n[2] Chen, Tianqi, Emily Fox, and Carlos Guestrin. \"Stochastic gradient hamiltonian monte carlo.\" In International conference on machine learning, pp. 1683-1691. PMLR, 2014."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7173/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7173/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7173/Reviewer_ixMJ"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7173/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698705133510,
            "cdate": 1698705133510,
            "tmdate": 1700612068867,
            "mdate": 1700612068867,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ml1BgCbxyg",
                "forum": "THUBTfSAS2",
                "replyto": "zYR9Dbs8AQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7173/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7173/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for providing several constructive comments. Let us clarify the points raised in the review:\n\n> Many baseline models are not considered in the paper's experiment, e.g., SAAL, Cluster-Margin, Similar, and [4].\n\nWe focused on uncertainty and diversity-baed baselines, which have been receiving lots of attention in recent years and which are much more related (and thus comparable) to our work. We emphasize that we have already considered quite a lot of standard baseline models to the best of our knowledge at the time of submission.\n\nWe thank the reviewer for pointing out additional baselines compared to which we could further show the effectiveness of our approach. Out of the suggested algorithms, we have added BatchBALD (Figure 13) and Cluster-Margin (Figure 14) results in Appendix F.3, showing that, indeed, our LDM-S outperforms both algorithms. We will add the results for the other suggested algorithms in the final draft (we are currently implementing those algorithms).\n\n\n> Computational cost analysis is lacking, including LDM estimation cost and LDM-S. What is the relationship to batch size, ensemble size, M, etc? The computational cost seems to be comparable to BADGE which has squared complexity to batch size.\n\nFirst, we would like to emphasize that in our paper, \u201censemble size\u201d is the number of sampled hypotheses in the LDM estimation. In our paper, we do not perform the usual ensembling where multiple models must be trained with new initializations; instead, we replace this with sampling near a single trained model.\n\nWe have already included the computational cost analysis for LDM evaluation in Figure 10 of Appendix F.1; this cost is directly related to the number of Monte-Carlo samples $M$ and the number of sampled hypotheses $N$. The runtime for LDM evaluation is almost linearly proportional to the stop condition $s$ and is linearly proportional to $M$ and $N$.\n\nLet us now clarify the dependency of the computational cost on the batch size. Our LDM-S has two stages: evaluating the LDM of each sample for the entire pool dataset (which only requires a single pass at the beginning) via Algorithm 1 and selecting samples for querying. The first stage is not affected by the batch size, but the runtime for the second stage increases linearly with the batch size since it requires selecting a batch size of samples. BADGE uses a similar seeding method; thus, its runtime increases linearly with the batch size. We would also like to clarify that BADGE has squared complexity to the number of features and classes, not the batch size.\n\n\n> The authors provide no analysis of the relatedness of LDM to active learner performance in the paper setting.\n\n> Could the authors provide numerical or illustrative examples to show that LDM-based algorithm can be more effective in deep active learning? The authors provided the asymptotical analysis of the estimator but no analysis is provided for the relatedness of LDM to the final performance. In this case, it is better to provide some illustrative examples to show the effectiveness of LDM-based algorithms.\n\nTo show the effectiveness of LDM, in Appendix F.1, we provide an ablation study by replacing LDM with other uncertainty measures, such as Entropy, Margin\u2026etc, combined with our seeding algorithm. There, it is clear that out of all the considered uncertainty measures, LDM is the most effective in the context of active learning. Please also refer to Fig. 2 in the main text for illustrative examples of the effectiveness of LDM."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7173/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700411837847,
                "cdate": 1700411837847,
                "tmdate": 1700411837847,
                "mdate": 1700411837847,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TGmCX0wlDH",
                "forum": "THUBTfSAS2",
                "replyto": "zYR9Dbs8AQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7173/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7173/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> Careful discussion of limitations is lacking in the paper. There are many deep active learning algorithms coming out each year, each with its own pros and cons. A careful discussion of advantages and limitations will be very helpful to the community. One possible drawback is the need to use ensembles which takes more cost compared to methods that only use one model like BADGE and CoreSet.\n\nAgain, we would like to emphasize that in our paper, \u201censemble size\u201d is the number of sampled hypotheses in the LDM estimation. In our paper, we do not perform the usual ensembling where multiple models must be trained with multiple (random) initializations; instead, we replace this with sampling near a single trained model.\n\nThus, the drawback regarding the cost, as suggested by the reviewer, is not accurate, as we only train one model as well, similar to BADGE and CoreSet; this is clear when we compare the runtime of the algorithms in Table 2 in the main text.\n\nStill, we agree with the reviewer that a careful discussion of the limitations of our framework is indeed lacking in our paper, and we would like to thank the reviewer for pointing this out. We have included another paragraph in the Conclusion section that discusses the potential limitations of our work. One limitation that is also an important future direction is to obtain a rigorous sample complexity guarantee for our LDM-S algorithm in the context of active learning; we have included this in our revised Conclusion section.\n\n\n> The seeding strategy seems detached from the novel estimator. Many strategies, e.g., [1], [2], and [4], have been published to extend to batches. It is better to compare these strategies based on LDM and show if the performance improvement is consistent.\n\nThank you for pointing out these recent works. First, [1] uses k-means++ seeding to introduce diversity to the acquisition, similar to our approach, along with a novel acquisition function; replacing that with LDM is precisely our current algorithm.\n\nAt first glance, Cluster Margin [2] is a viable option for LDM to be incorporated into, with LDM replacing margin score. However, this introduces an additional hyperparameter, margin batch size $k_m$, and the number of clusters $r$ among others, which requires an intricate tuning. This goes against our goal of keeping our proposed algorithm simple and intuitive. Also, during the preliminary phase of our research, we tried a similar approach in which we first sampled samples with high LDM (more uncertain) and then performed k-means clustering. Here, we observed that the tuning of the additional parameters relied heavily on the particular problem instance, and the overall performance was sensitive to such hyperparameters.\n\n[4], which is a very recent work, proposes several alternate batch acquisition strategies, such as score-based and rank-based strategies. Indeed, it would be interesting to see how our LDM-based approach would combine with the alternate strategies, and we will definitely look into this in our future work. We would like to emphasize that our main novelty lies in proposing LDM, a new uncertainty measure, which provides very good performance in the active learning context.\n\n\n> I am very interested to see the performance of active learning models with MC-dropout. MC-dropout is more efficient compared ensemble method.\n\nAgain, we would like to emphasize that in our paper, \u201censemble size\u201d is the number of sampled hypotheses in the LDM estimation. In our paper, we do not perform the usual ensembling where multiple models must be trained; rather, we replace this with sampling near a single trained model.\n\nIn Table 2, we compare our approach to the MC-dropout-based approach (DBAL [9]) has about the same runtime as ours, yet the number of hypotheses for MC-dropout is 100 while our approach uses much more (for instance, for MNIST + SCNN, with stop condition $s = 10$, our approach uses roughly $10^4$ hypotheses). It should also be noted that with similar time, our approach consistently outperforms, or is at least at par with, DBAL over all tasks. In this respect, although somewhat similar, MC-dropout requires a bit more computation time than ours, as it requires going through all the neuron connections in the given network for dropout for each forward pass, in contrast to ours, which only involves sampling. In other words, given the same computation cost, our approach could yield more hypotheses than MC dropout; of course, the precise comparison would be different depending on the network."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7173/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700411858054,
                "cdate": 1700411858054,
                "tmdate": 1700538424578,
                "mdate": 1700538424578,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "basT7Kt7ej",
                "forum": "THUBTfSAS2",
                "replyto": "g4BMy2nlNC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7173/Reviewer_ixMJ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7173/Reviewer_ixMJ"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the detailed response"
                    },
                    "comment": {
                        "value": "I have read the response. Some of the questions are resolved. Some concerns including weakness 5 and question 1 remain. The score is raised accordingly."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7173/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700612003748,
                "cdate": 1700612003748,
                "tmdate": 1700612003748,
                "mdate": 1700612003748,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9ie8vBV7QI",
            "forum": "THUBTfSAS2",
            "replyto": "THUBTfSAS2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7173/Reviewer_o58y"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7173/Reviewer_o58y"
            ],
            "content": {
                "summary": {
                    "value": "Framed in the field of active learning, this paper presents LDM (least disagree metric), a novel concept to quantify the distance between an instance and the decision boundary of a classifier. Along with the theoretical definition of LDM, the authors provide an asimptotically consistent estimator of LDM as well as a practical algorithm to calculate it. Based on this notion of LDM, they define a new acquisition procedure in active learning, by favoring low values of LDMs and enforcing diversity. Empirical evaluation shows that the proposed approach is competitive or superior against other state-of-the-art active learning methods in various datasets and with different architectures."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The quality of the exposition is high in general. The concepts and ideas are presented by combining an specific and accurate definition along with an intuition on their meaning. It is easy to follow the flow of the paper, and sections are well organized in a natural manner. \n\n* The experimental evaluation is a comprehensive one, including a wide range of baselines, datasets and architectures. Results are analyzed in a rigorous way, including statistical tests and popular active learning metrics such as the performance profile (Dolan-More plots). \n\n* The proposed metric LDM is clearly explained, and intuition is provided on how it reflects the distance to the decision boundary. It is well motivated and theoretically sounded. The example provided after Definition 1 is clarifying and helps understanding LDM definition.\n\n* LDM estimator, denoted as $L_{N,M}$, has a theoretical underpinning. Under some assumptions, $L_{N,M}$ is shown to converge in probability to the true value L when M scales logarithmically with respect to N.\n\n* 2D binary classification case is thoroughly investigated. Proposition 1 and Proposition 2 in the appendix theoretically confirm the intuition behind the choices made in this work.\n\n* Additional interesting experiments are included in the appendix. In particular: \n    * An effort to study the hyperparameters effect (number of MC samples, batch size, LDM stop condition and \u03c3 interval) is made.\n    * To favour diversity, the LDM estimator is corrected using a popular weighting strategy\nin active learning. The importance of this correction is addressed in the ablation study."
                },
                "weaknesses": {
                    "value": "* I think there exists an important gap between the theoretical description of LDM (its definition in Section 2.1 and its estimator in Section 2.2) and how it is empirically evaluated (Section 2.3). In Section 2.3, the \"motivation\" paragraph includes several sentences to justify the procedure that the authors are going to follow to empirically evaluate LDM, but these sentences are just somewhat \"generic\"/\"loose\", and there is no guarantee that hypothesis in Section 2.2 are satisfied. Taking this into account, I wonder whether Section 2.2 is a core component of the contribution, or could be moved to the appendix, leaving room in the main text for other information that may be more central to the contribution (e.g. a more detailed description of the experiments or further empirical evaluations, which are currently in the appendix). \n\n* Even if Section 2.2 is moved to the appendix, I think that assumptions 1, 2 and 3 should be further motivated. The reader who is unfamiliar with mathematical concepts could get lost: what is a Polish space, and why is it necessary? Why is it necessary that \u03c1 is Lipschitz? How restrictive is assumption 3? There are no references to other works where these assumptions are made. If they are common, these references should be provided. If not, authors should motivate and discuss them.\n\n* I also wonder whether the idea of \"sampling close to the decision boundary\" is the best way to go in active learning. Samples close to the decision boundary may not be informative if all the uncertainty that they present is of _aleatoric_ nature (inherent to the data, i.e. it cannot be reduced by further sampling training data). I think that more subtle distinctions on the types of uncertainty to be considered in active learning should be analyzed. My intuition is that this might be related to the finding that using LDM alone did not work properly, and a (somewhat ad-hoc) procedure to encourage diversity had to be introduced. \n\n* I think that more empirical evaluations should be moved to the main text (specially if theoretical details are moved to appendix, as suggested in the first point above). Right now, the experimental setting is not clearly described in the main text (it is deferred to Appendix C), and several ablation studies that could be interesting are \"lost\" in the appendix. \n\n* In some occasions, the statements made by the authors may lead to confusion. For example, in section 2.3, it is said that \u201c...in Appendix B.2, we show that $E_w[\u03c1_M(h, g)]$ is monotone increasing in $\u03c3^2$.\u201d. One could think that this is shown in general. However, the proof only applies to the 2D binary classification case.\n\n* Related to the first point above, some aspects of theory are disconnected from the implementation:\n    * To implement $L_{N,M}$ the authors propose to sample near the learned hypothesis using standard parameter perturbation techniques. As authors state, this sampling scheme would need to satisfy Assumption 3. However, it is not explained why this specific form\nof sampling assures that the hypothesis spaces $\\mathcal{H}_n$ satisfy Assumption 3.\n    * In the 2D binary classification experiment, the performance of LDM-S, entropy, and random based sampling procedures are investigated. As authors state, true LDM is measurable in the 2D binary classification scenario. Thus, a study could be carried out on the error made when approximating L using $L_{N,M}$. Verification of bounds and rates of\nconvergence could be carried out."
                },
                "questions": {
                    "value": "Other questions/comments: \n\n* The effect of each hyperparameter is studied independently. Nothing is said about how they\naffect each other. Does the choice of one hyperparameter (number of MC samples, batch size, LDM stop condition\nand \u03c3 interval) affect each other?\n\n* Which metric/score is used to quantify performance in section 4.2? Accuracy is mentioned in\nthe appendix, but it is not entirely clear to me.\n\n* x should be present in the input in algorithm 1, right?\n\n* Perhaps, Assumption 3 is over-complicated: $\\sup_{\\epsilon\\in(0,1)} \\lim_N \u03b1(N, \\epsilon)= 0$ amounts to saying\nthat $\\lim_N \u03b1(N, \\epsilon)$ exists and is 0 when $\\epsilon\\in (0, 1)$.\n\n* I think $f$ in Theorem 1 should be $\\alpha$?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7173/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7173/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7173/Reviewer_o58y"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7173/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698773452047,
            "cdate": 1698773452047,
            "tmdate": 1700588642226,
            "mdate": 1700588642226,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0TFGiDRXdZ",
                "forum": "THUBTfSAS2",
                "replyto": "9ie8vBV7QI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7173/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7173/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for providing several insightful and constructive comments and pointing out several typos we have missed. Let us clarify the points raised in the review:\n\n\n> I think there exists an important gap between the theoretical description of LDM (its definition in Section 2.1 and its estimator in Section 2.2) and how it is empirically evaluated (Section 2.3). In Section 2.3, the \"motivation\" paragraph includes several sentences to justify the procedure that the authors are going to follow to empirically evaluate LDM, but these sentences are just somewhat \"generic\"/\"loose\", and there is no guarantee that hypothesis in Section 2.2 are satisfied. Taking this into account, I wonder whether Section 2.2 is a core component of the contribution, or could be moved to the appendix, leaving room in the main text for other information that may be more central to the contribution (e.g. a more detailed description of the experiments or further empirical evaluations, which are currently in the appendix).\n\n>Related to the first point above, some aspects of theory are disconnected from the implementation:\n> - To implement $L_{N, M}$ the authors propose to sample near the learned hypothesis using standard parameter perturbation techniques. As authors state, this sampling scheme would need to satisfy Assumption 3. However, it is not explained why this specific form of sampling assures that the hypothesis spaces $\\mathcal{H}_n$ satisfy Assumption 3.\n> - In the 2D binary classification experiment, the performance of LDM-S, entropy, and random based sampling procedures are investigated. As authors state, true LDM is measurable in the 2D binary classification scenario. Thus, a study could be carried out on the error made when approximating L using $L_{N, M}$. Verification of bounds and rates of convergence could be carried out.\n\n\nFirst, we would like to thank the reviewer for providing very insightful and constructive comments and questions that would help us improve our paper significantly. Indeed, as the reviewer has correctly stated, in the original draft, we did not theoretically justify our Algorithm 1 for evaluating LDM, thus seemingly creating a gap between Section 2.2 and 2.3.\n\nHowever, we would like to emphasize that the current Algorithm 1 is *inspired* by our theoretical guarantees, and thus, we believe that Section 2.2 is a core contribution of our work. While proving the asymptotic consistency of the LDM estimator, we realized that Assumption 3 (coverage assumption) was required. Naturally, we thought that by sampling a sufficiently large, finite collection of $N$ hypotheses $\\mathcal{H}_N$ with a distribution whose support spans the entire space, e.g., Gaussian distribution over $\\mathbb{R}^d$ and is centered around $g$, we could \u201ccover\u201d the hypothesis that yields the true LDM with high probability, as $N \\rightarrow \\infty$. Conversely, if such a true hypothesis cannot be covered, we cannot hope to obtain a consistent estimator of LDM.\n\nWe agree with the reviewer that this still does not give a solid reason why the proposed sampling scheme should satisfy Assumption 3. But, we would like to remark that, as briefly mentioned in Section 2.3, directly verifying Assumption 3 for a very general scenario (e.g., deep neural network + multiclass classification + complex data distribution) is often impossible, as it is challenging to compute the true LDM nor identify the hypothesis that (approximately) attains the true LDM. On a slightly different note, we have shown in Appendix F.1 that for realistic deep AL scenarios, our algorithm shows a solid trend of convergence in the estimated LDM, which suggests that Assumption 3 is being satisfied.\n\nWe have also empirically shown that for the toy binary classification with linear classifiers in which the true LDM and the optimal hypothesis attaining the optimal LDM are known (see Section 2.1), the empirical LDM output from our algorithm converges to the true LDM. As the reviewer has suggested, we could prove that Assumption 3 can be attained in the same setting. We have included this in Appendix B.3. This shows that Assumption 3 is not unrealistic and is not an assumption for the considered toy example. Again, we thank the reviewer for this helpful suggestion.\n\nLastly, we agree with the reviewer that some of the experiments in the appendix should be moved to the main text. We have done so in the revised manuscript; see the general response for the changes that we have made."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7173/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700412059433,
                "cdate": 1700412059433,
                "tmdate": 1700412059433,
                "mdate": 1700412059433,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZHNiFimD6U",
                "forum": "THUBTfSAS2",
                "replyto": "9ie8vBV7QI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7173/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7173/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> The effect of each hyperparameter is studied independently. Nothing is said about how they affect each other. Does the choice of one hyperparameter (number of MC samples, batch size, LDM stop condition and \u03c3 interval) affect each other?\n\nThank you for asking this question. The number of MC samples, $M$, affects runtime and the estimation quality of the LDM, but it has little effect on other hyperparameters or performance, i.e., $M$ is independent of other hyperparameters. Batch size is also irrelevant as it is given by the task rather than being tuned individually in the algorithm by the learner.\n\nThe stop condition, $s$, and the $\\sigma$ interval can indirectly affect each other. If the $\\sigma$ interval is narrow, the estimation quality of LDM would be high with smaller $s$, although the number of intervals to be considered would also have to increase. If the $\\sigma$ interval is wide, then to retain the estimation quality, $s$ also needs to be increased, but the number of intervals wouldn\u2019t be as high as before. In our setting, we set the $\\sigma$ interval sufficiently narrow for using a small $s$ to reduce runtime, which we have verified empirically to be the case when we grid-searched for the correct hyperparameters.\n\n\n\n> Which metric/score is used to quantify performance in section 4.2? Accuracy is mentioned in the appendix, but it is not entirely clear to me.\n\nIn Section 4.3 (Main Experiments), we use two performance metrics. We use test accuracy (%) for Table 1 and AUC for the Dolan-More curve (Fig. 3). We have included the exact expressions for the metrics for Fig. 3 in Appendix E. We have clarified this further in our revised manuscript.\n\n\n> x should be present in the input in algorithm 1, right?\n\nThank you for pointing this out. Yes, it should be part of the input. We have fixed this in our revised manuscript.\n\n\n> Perhaps, Assumption 3 is over-complicated: $\\sup_{\\epsilon \\in (0, 1)} \\lim_{N} \\alpha(N, \\epsilon) = 0$ amounts to saying that $\\lim_{N} \\alpha(N, \\epsilon)$ exists and is 0 when $\\epsilon \\in (0, 1)$.\n\nThat is true. We wanted to state that $\\lim_N \\alpha(N, \\varepsilon) = 0$ for any $\\epsilon \\in (0, 1)$ in a compact way. But we are happy to rephrase the assumption to be in a simpler term, as the reviewer has suggested.\n\n\n> I think $f$ in Theorem 1 should be $\\alpha$?\n\nIndeed, $f$ should be $\\alpha$. Thank you for pointing out this typo. We have fixed it."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7173/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700412162718,
                "cdate": 1700412162718,
                "tmdate": 1700412178227,
                "mdate": 1700412178227,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TgbNYNjnC6",
                "forum": "THUBTfSAS2",
                "replyto": "9ie8vBV7QI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7173/Reviewer_o58y"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7173/Reviewer_o58y"
                ],
                "content": {
                    "title": {
                        "value": "Reply"
                    },
                    "comment": {
                        "value": "Thanks to the authors for their detailed response, which has addressed a good amount of my concerns. Thus, I am raising my score to 8."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7173/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700588737101,
                "cdate": 1700588737101,
                "tmdate": 1700588737101,
                "mdate": 1700588737101,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qME13xB8Tx",
            "forum": "THUBTfSAS2",
            "replyto": "THUBTfSAS2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7173/Reviewer_2mvn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7173/Reviewer_2mvn"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents LDM-S, an active learning method based on selecting samples close to the decision boundary. The paper starts by formulating a Least Disagree Metric (LDM) function, and then proceeds to implement it in a Monte Carlo fashion. Necessary assumptions and theorems are proven as needed. Over 5 repeats, the method is compared with other active learning methods and a t-test is used to check significance."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* At least in some parts of the paper, the flow is very good, and theorems and conclusions naturally lead to the next part.\n* The evidence for diversity in LDM-based active learning, as discussed in Appendix E.3, is extraordinary. Through an intuitive first example and then a real-world example (MNIST), the motivation is very clear. If possible, this should definitely be in the main paper to give readers better intuitions.\n* Ablation studies are presented whenever necessary to justify choices made, for example, for modifying the k-means++ seeding algorithm."
                },
                "weaknesses": {
                    "value": "* Minor typo: Page 1, last paragraph: flips-flopped --> flip-flopped\n* Section 2.2 is rather rushed in its presentation, and details are not expanded on. For example, it is unclear why $\\mathcal{H}$ needs to be a Polish space (i.e., why second countability is necessary, for instance). In Theorem 1, $f$ is undefined. In Assumption 3, it seems that the phrase, \"that is monotone decreasing in the first argument\" refers to $\\alpha$, but that is not fully clear.\n* Similarly, some other details are presented with no clear rationale. For example, in (6), why is p(x) squared?\n* In Figure 2a, LDM sometimes samples on or very close to the decision boundary. Please change the color of the LDM crosses so they are more apparent."
                },
                "questions": {
                    "value": "* Why does $\\mathcal{H}$ need to be a Polish space as opposed to a more general metric space?\n* In Algorithm 2, when you compute $L_x$ via Algorithm 1, could you clarify the parameters passed? My understanding is that you pass it a hypothesis parameterized by $v$, number of samples $m$, and a \"small\" $s$ (as said in Sec. 2.3), but I'm unclear what $\\{ \\sigma^2_k \\}$ you pass."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "10: strong accept, should be highlighted at the conference"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7173/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7173/Reviewer_2mvn",
                        "ICLR.cc/2024/Conference/Submission7173/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7173/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698796909839,
            "cdate": 1698796909839,
            "tmdate": 1700459986432,
            "mdate": 1700459986432,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Rm6NZdZEE2",
                "forum": "THUBTfSAS2",
                "replyto": "qME13xB8Tx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7173/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7173/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for highlighting the strengths of our paper and providing several constructive comments. Let us clarify the points raised in the review:\n\n\n> Minor typo: Page 1, last paragraph: flips-flopped --> flip-flopped\n\nThank you for pointing out this typo. We have fixed this in our revised manuscript.\n\n\n> Section 2.2 is rather rushed in its presentation, and details are not expanded on. For example, it is unclear why $\\mathcal{H}$  needs to be a Polish space (i.e., why second countability is necessary, for instance). In Theorem 1, $f$  is undefined. In Assumption 3, it seems that the phrase, \"that is monotone decreasing in the first argument\" refers to $\\alpha$ but that is not fully clear.\n\n> Why does $\\mathcal{H}$ need to be a Polish space as opposed to a more general metric space?\n\nWe thank the reviewer for pointing this out. We have revised Section 2.2 to be more well-motivated and have expanded on the missing details.\n\nThank you for pointing out the typos. Indeed, $f$ should be $\\alpha$, and with a closer look, we realized that the \u201cmonotone \u2026\u201d part of the assumption isn\u2019t required. We have removed that part, and we would like to thank the reviewer for helping us discover this.\n\nThe reason for assuming that $\\mathcal{H}$ is a Polish space is to avoid any complications that may arise from the space being not countable, especially as we consider a probability measure over $\\mathcal{H}$; see Chapter 1.1 of [1], where it states that the usual measurability and other related properties may not hold for non-separable spaces (e.g., Skorohod space). The Euclidean space, which comes up naturally by parametrizing $\\mathcal{H}$ (e.g., neural networks), is Polish.\n\n\n[1] Aad W. van der Vaart and Jon A. Wellner. \u201cWeak Convergence and Empirical Processes: With Applications to Statistics,\u201d Springer. 1996.\n\n> Similarly, some other details are presented with no clear rationale. For example, in (6), why is p(x) squared?\n\nOur paper incorporates diversity by using the $k$-means++ seeding algorithm, which has been proposed in an influential prior work [1] for initializing the centers of clustering. Their seeding algorithm uses squared $p(x)$, i.e., squared distance, to minimize the potential function defined as $\\phi = \\sum_{x \\in \\mathcal{X}} \\min_{c \\in C} \\Vert x - c \\Vert^2$. Note that we only modified the distance measure from L2 to cosine distance between the features of the data points. In Appendix F.2, we have provided further ablation studies showing that the cosine distance outperforms L2 distance in active learning.\n\nPlease let us know of any other confusing details; we will be happy to elaborate.\n\n\n[1] David Arthur and Sergei Vassilvitskii. K-Means++: The advantages of Careful Seeding. In Proceedings of the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA \u201907, 2007.\n\n> In Figure 2a, LDM sometimes samples on or very close to the decision boundary. Please change the color of the LDM crosses so they are more apparent.\n\nThank you for your suggestion. We have revised the figure accordingly.\n\n\n> In Algorithm 2, when you compute $L_x$ via Algorithm 1, could you clarify the parameters passed? My understanding is that you pass it a hypothesis parameterized by $v$, number of samples $m$, and a \"small\" $s$ (as said in Sec. 2.3), but I'm unclear what $\\sigma_k^2$ you pass.\n\nAs described in Section 4.2, we set $s=10$, $M$ to be the same size as the pool size, and $\\sigma_k = 10^{0.1k - 5}$ for $k \\in {1, 2, \\cdot, 51\\}$. Figure 7 of Appendix C.2 shows the relationship between the disagree metric and $\\sigma$. The $\\sigma$ controls the $\\rho$. To properly approximate LDM, we need to sample hypotheses with a wide range of $\\rho$, and thus we need a wide range of $\\sigma$. To efficiently cover a wide range of $\\sigma$, we consider equal spacing in the log scale, where the spacing was chosen via a grid search."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7173/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700411183820,
                "cdate": 1700411183820,
                "tmdate": 1700460789303,
                "mdate": 1700460789303,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "leouhZPmtj",
                "forum": "THUBTfSAS2",
                "replyto": "Rm6NZdZEE2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7173/Reviewer_2mvn"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7173/Reviewer_2mvn"
                ],
                "content": {
                    "comment": {
                        "value": "The authors thoroughly addressed my concerns, and have updated their manuscript also taking other reviewers' comments into account. The new version is a significant improvement, with much more clear motivations and better references, and also moves the old Appendix E.3 to the main text. \n\nBased on the revised manuscript along with the authors' responses to all the reviewers, I would champion for strong acceptance, and have changed my score to 10/4. On top of the great presentation, the paper will be of interest to relevant communities in the ICLR audience."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7173/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700460175216,
                "cdate": 1700460175216,
                "tmdate": 1700460175216,
                "mdate": 1700460175216,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]