[
    {
        "title": "DISPEL: Domain Generalization via Domain-Specific Liberating"
    },
    {
        "review": {
            "id": "OQyblZwZxV",
            "forum": "05gc31KWpz",
            "replyto": "05gc31KWpz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission409/Reviewer_Mwon"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission409/Reviewer_Mwon"
            ],
            "content": {
                "summary": {
                    "value": "The paper discusses the challenge of domain generalization in machine learning, where a model needs to perform well on new, unseen domains after training on limited source domains. The authors propose a post-processing solution, called \"Domain-specific Features Liberating (DISPEL),\" that filters out indistinguishable domain-specific features using fine-grained masking in the embedding space. The authors demonstrate the performance of DISPEL on five benchmarks and provide a theoretical framework for the generalization performance of the proposed method."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The authors propose a simple method in order to improve the performance of the pre-trained model on unseen test domains. The method demonstrates stable improvement by few percent across almost all benchmarks. The method doesn't require labels from source domains."
                },
                "weaknesses": {
                    "value": "The main weakness of the paper is the theoretical justification of the method. Unfortunately, Theorem 1 has nothing to do with the generalization error on unseen domains and the original definition of the generalization error in the first place. Proper definitions could be for example found in the works of Ben-David (e.g. \"A theory of learning from different domains\")."
                },
                "questions": {
                    "value": "- The logic of splitting methods in group 1 and group 2 is not very clear to me. These methods could be run using labels only in source domains as discussed in DomainBed paper. Could the authors please clarify that?\n- It is quite interesting that pretrained masked generator doesn't suffer from generalization issues when applied to new unseen domains. Do the authors have an intuition why this could be the case?\n- It is an interesting property, that the method doesn't require labels from source domains. However, it is a bit difficult for me to imagine a situation when you would still have access to the full source inputs, but not to labels (given that you did have access to labels in order to pre-train the network in the first place). The authors stress it several times throughout the paper that this is an important property of the proposed approach, so it would be good if they could clarify this point.\n- What is the numerical difference of the proposed method compared to global masking? Could the authors please provide the table with the ablation study?\n- It looks like the authors inexplicitly assume that the embedding dimensions are disentangled with respect to domain-specific and domain-sharing features. For me it is not obvious why this would be a general case. Could the authors comment on that?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission409/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698592534008,
            "cdate": 1698592534008,
            "tmdate": 1699635967808,
            "mdate": 1699635967808,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "fzx5UNuRrd",
            "forum": "05gc31KWpz",
            "replyto": "05gc31KWpz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission409/Reviewer_u3X2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission409/Reviewer_u3X2"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a model for domain generalization without domain labels, DISPEL, which is a post-processing feature-masking approach that can filter out domain-specific features in the embedding space. \nThe authors derive a generalization error bound (but is not like a conventional generalization bound in the sense of statistical learning theory, which often includes sample-size dependence) to guarantee the generalization performance.\nDISPEL achieves SOTA performance in some cases."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed method is simple but effective. The proposed method achieves state-of-the-art performance in some cases, even without leveraging domain labels and any data augmentation method.\n\n- The experiments are nicely designed. Error bars are given. The experimental results are mostly significant.\n\n- Source code is available, which is critically important in domain generalization, where reproducibility is a crucial problem.\n\n- The paper is easy to follow."
                },
                "weaknesses": {
                    "value": "- (Critical) The underlying mechanism, i.e., why DISPEL works well in domain generalization, is not completely clear (see Questions). I would like to know more about why DISPEL works well in unseen target domains.\n\n- The main idea of decomposing features into domain-invariant and domain-specific features has been explored and is not novel."
                },
                "questions": {
                    "value": "- [Question (major)] The idea of the proposed masking looks similar to other methods that attempt to obtain domain-invariant features (in fact, some call domain-sharing feature as domain-invariant feature in the literature). The question is: What is the novelty of the proposed method compared to the previous methods that aim to obtain domain-invariant features? Please show an evidence that DISPEL is not a \"yet another model\" in domain generalization.\n\n- [Question (major)] Why is the temperature-dependent Gumbel softmax (and the associated sampling of random variables) used? Why are they necessary? There are many other choices, e.g., a simple softmax, etc.\n\n- [Question (major)] Is there any ablation study about Section 3.2?\n\n- [Question (major)] EMG is designed to remove domain-specific features, but the masks thus obtained does not know the target domain data anyway, which means they may overfit to source domain data. Therefore, I guess the performance improvement in experiment comes from the randomness introduced in the Gumbel softmax. So I have a question: Is the mask generation process in the inference phase deterministic? If no, please show the variance due to the randomness. If yes, how did you fix the randomness?\n\n- [Question (major)] In Section 3.4:\n> DISPEL framework minimizes the value of second terms in Eq. 1 by making z^T-sp_k approaches z^T-sp_k with a generated mask.\n\nCould you elaborate on this statement? What do you mean by \"second terms in Eq. 1\"? How does DISPED framework minimizes what?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission409/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission409/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission409/Reviewer_u3X2"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission409/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698722541441,
            "cdate": 1698722541441,
            "tmdate": 1699635967723,
            "mdate": 1699635967723,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "aWxeog6ldZ",
            "forum": "05gc31KWpz",
            "replyto": "05gc31KWpz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission409/Reviewer_StPi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission409/Reviewer_StPi"
            ],
            "content": {
                "summary": {
                    "value": "This work tries to develop a domain generalization method that needs no data-augmentation technique or domain label information. It is a post-processing fine-grained masking approach that learns to filter out domain-specific features for each sample separately in the embedding space. The authors provide theoretical and experimental analysis to verify their method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The method proposes a kind of sample-level domain-specific feature identification which is supposed to be more flexible than existing global-level method considering the complex domain information in real application."
                },
                "weaknesses": {
                    "value": "There are many publications also try to solve DG from the view of separating the representation into domain specific and domain invariant parts, which is not mentioned in this work. The analysis about the mask learning is not sufficient to support their idea."
                },
                "questions": {
                    "value": "1.\tThe authors claim that \u201cdata manipulation methods require highly engineered efforts and can introduce too much prediction-irrelevant knowledge label noise\u201d, please provide more explanation about the \" prediction-irrelevant knowledge label noise \", and how it influence the generalization performance.\n\n2.\tSome important closely related work are not mentioned in this paper, for example, to divide the representation into domain-specific and domain invariant, some work use the disentangling technique, and some work use causal inference. And what about the performance compared to these methods?\n3.\tequation (1), what are i and j for? It looks like they are not related to the right side of the equation? What\u2019s the effect of different /tao on the generated masks? And how to set \\tao to avoid the trivial outcome?\n\n4.\tHow does equation(3) make sure that the masked part of the embedding is domain-specific? Since when the masked part of the embedding learns something redundancy or constant, equation(3) can still be minimized  \n\n5.\twhat does the final masks look like, is there any obvious patten in the generated masks which is highly related to domain information? If so, there will be a pattern highly domain related in the embeddings after the mask operation, which is contradictory to the goal of domain invariant.\n\n6.\tDoes the author use any traditional data-augmentation techniques, (e.g. random crop, random flip,\u2026) in the ERM pre finetuning period?\n\n7.\tthere is no analysis on the effect of the sparseness of the mask. How to choose a proper parameter to control it given a specific dataset?\n8.\twhat about the performance when compared to some SOTA method, e.g. SWAD?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission409/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698760633369,
            "cdate": 1698760633369,
            "tmdate": 1699635967637,
            "mdate": 1699635967637,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "4EXEEgcmHS",
            "forum": "05gc31KWpz",
            "replyto": "05gc31KWpz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission409/Reviewer_zEDH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission409/Reviewer_zEDH"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a feature learning based method for domain generalization under assumptions that there exists two types of features: i) domain-shared and ii) domain-specific features, and a good out-of-distribution performance can be achieved by filtering out the domain-specific features. One way to do so is to apply a global masking on the top of the features to retain only the domain-shared features. It is empirically shown that the global masking slightly improves the domain generalization performance, but the result is still sub-optimal.\n\nTo better optimize the impact from the masking, a method for domain generalization namely DomaIn-SPEcific Liberating (DISPEL) is proposed, which introduces a learnable mask called Embedding Mask Generator (EMG) that automatically constructs a distinct filter for each input data. DISPEL finds an optimal EMG that minimizes the cross entropy between the normal and feature-masked prediction while keeping the foundational model frozen.\n\nThe performance evaluation on various benchmarks empirically demonstrates the effectiveness of DISPEL, producing state-of-the-art performance. The theoretical analysis provides a guarantee that DISPEL improves the domain generalization performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "$\\textbf{Performance and practicality}$: DISPEL consistently produces superior domain generalization performance over existing methods on 5 benchmarks, with a relatively simple implementation, i.e., applying trainable masking in the embedding space. Furthermore, it does not require domain label information and can be used additively with any deep learning based finetuning method as demonstrated in Table 4.\n\n$\\textbf{Novelty}$: To my knowledge, this is the first attempt in employing dynamic, instance-specific feature masking in the context of domain generalization."
                },
                "weaknesses": {
                    "value": "$\\textbf{Performance Stability}$: As stated in Sec 4.3.1, DISPEL possesses stable generalizing efficacy (Observation 2). If the \u201cstability\u201d here means that there is no significant performance degradation from across a wide range of benchmarks, I\u2019m not sure if the empirical evaluation is convincing enough to support the claim. I would argue that, for examples, Mixup and MIRO are \u201cstable\u201d enough. \n\nFurthermore, the early premise about the needs of DISPEL as a more stable solution over the global masking (since it\u2019s stated that its effectiveness varies for different compositions of training domains \u2013 hence it\u2019s less stable) is not backed with empirical evidence.\n\nI would like to hear more from the authors regarding this concern.\n\n$\\textbf{Comparison with recent work}$: A few recent work by, such as [Ding et al. NeurIPS 2022] and [Bui et al. NeurIPS 2021] that also improve domain generalization by devaluing domain-specific features are not discussed. I encourage that the empirical comparison with those methods using the same benchmarks should be included.\n\n[Ding et al. NeurIPS 2022] Domain Generalization by Learning and Removing Domain-specific Features\n\n[Bui et al. NeurIPS 2021] Exploiting Domain-Specific Features to Enhance Domain Generalization\n\nSome minor issues from my side are as follows:\n-\tPutting the indices explicitly at the corresponding terms in equation (3) would be helpful.\n-\tSubsection 4.3.1: DoainNet \uf0e0 DomainNet\n-\tTheorem 1: I think the notations (i.e., superscript parts) for denoting domain-specific and domain-sharing features are interchanged?"
                },
                "questions": {
                    "value": "Is it necessary to use the base model as large as ResNet50 for the mask generator? Would much smaller models work?\n\nHow are the convergence behaviour and time complexity of the EGM training? \n\nWhy are DA-ERM and MIRO excluded from the evaluation comparison in Table 2?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission409/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699252571702,
            "cdate": 1699252571702,
            "tmdate": 1699635967572,
            "mdate": 1699635967572,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]