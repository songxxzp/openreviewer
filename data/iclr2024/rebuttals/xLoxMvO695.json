[
    {
        "title": "Decomposing the Enigma: Subgoal-based Demonstration Learning for Formal Theorem Proving"
    },
    {
        "review": {
            "id": "FJgKBnFAiV",
            "forum": "xLoxMvO695",
            "replyto": "xLoxMvO695",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3920/Reviewer_kVAV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3920/Reviewer_kVAV"
            ],
            "content": {
                "summary": {
                    "value": "This work aims at using LLMs to assist formal proof generation. Previous attempts decompose the generation process into two phases, where the LLMs first generate an informal proof given the statement and then build a formal proof given the informal proof. The authors argue that LLM-generated informal proofs are prone to be invalid while human-written ones could be incompatible with the formal proof. To bridge the gap, the authors propose to replace the informal proof with a sequence of subgoal proofs, where each step of the subgoals can be verified. The subgoal proofs are iteratively generated with LLMs and existing automated theorem prover as the verifier.\n\nThe authors also claim that the order and selection of demonstrations are vital to the performance of LLM-based generations. To automate this selection process, the authors utilize a diffusion model to generate conditional demonstration organizations.\n\nEmpirically, the proposed method can outperform previous baselines in the MiniF2F dataset or match the performance while significantly reducing the number of LLM calls."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is well-written and easy to follow.\n- The idea of using subgoal-based proofs to bridge the gap between formal proofs and LLMs is well-motivated.\n- There is a clear empirical improvement over previous baselines."
                },
                "weaknesses": {
                    "value": "- For the diffusion model-based reorganization, it would be nice to show the correlation between the generated optimal demonstration organization and the input statement. I am curious if the diffusion model would collapse into generating a generic organization that works decently well with most statements. On roughly the same note, it would also be nice to show some examples where the order of the demonstrations greatly affects the performances. Another interesting baseline to compare would be to search the optimal organization for each tested statement.\n- It seems that previous LLM-based algorithms do not utilize formal proof generation tools such as Sledgehammer. I am wondering if it's possible to add a comparison of the number of usages of such tools (or their resource consumptions), aligning with the LLM calls comparison."
                },
                "questions": {
                    "value": "I don't have any questions for the authors."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3920/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3920/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3920/Reviewer_kVAV"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3920/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698811001458,
            "cdate": 1698811001458,
            "tmdate": 1699636352179,
            "mdate": 1699636352179,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JczVUf0rAL",
                "forum": "xLoxMvO695",
                "replyto": "FJgKBnFAiV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3920/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3920/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer kVAV"
                    },
                    "comment": {
                        "value": "We sincerely appreciate your time and constructive suggestions, particularly your recognition of our work, which has been greatly encouraging. We hope our responses adequately address all of your concerns.\n\n**Question 1: Whether the diffusion model generates a generic organization effective for most statements.**\n\nWe deeply appreciate your insightful advice regarding the diffusion model's performance. Our empirical finding strongly suggests that there isn't a \u201cone-size-fits-all\u201d optimal demonstration organization. Specifically, even the most adaptable organization we identified could successfully prove only *3* distinct statements. Furthermore, we only observed *4* instances of such adaptable organizations on the miniF2F-test. This highlights the tailored nature of each organization to its corresponding statement. The limited scope of even the most adaptable organization indicates the challenge in identifying the optimal demonstration organization for each unique statement. This complexity further emphasizes the effectiveness of our model in efficiently searching for and determining the most suitable demonstration organization for individual statements. These discussions are now included in Appendix D of the updated manuscript.\n\n**Question 2: Examples about how demonstration order affects performance.**\n\nWe are sincerely grateful for your valuable suggestion and have taken steps to address it. We have added several illustrative examples in Figures 16-18 in Appendix E. These cases specifically highlight how the order of demonstrations can significantly impact the final performance.\n\n**Question 3: Comparing with a baseline that searches for optimal organization for each tested statement.**\n\nThank you for your constructive suggestion. We conducted additional experiments using 200 randomized organization sampling attempts for each statement in the miniF2F-valid and miniF2F-test to search for the optimal organization. The results are as follows:\n\n| Method                       | Valid  | Test  |\n|------------------------------|--------|-------|\n| Ours                         | 48.0%  | 45.5% |\n| Optimal Organization Search  | 48.4%  | 44.3% |\n\nAs noted in [1], the benefit of conducting extensive organization searches tends to diminish beyond 100 attempts. This finding highlights the inherent challenges presented by this dataset and indicates the effectiveness of our diffusion model in efficiently optimizing the search process, thereby conserving costs in using LLMs. These results have been incorporated into Appendix C.7 in the updated version of our manuscript.\n\n**Question 4: Comparing resource consumption of Sledgehammer in LLM-based algorithms.**\n\nThank you for your valuable feedback! We have further analyzed the average number of Sledgehammer calls and their execution times, comparing our method with the DSP algorithm[1]. This analysis was conducted on a machine equipped with 64 CPU cores.\nIt is important to note that DSP also uses Sledgehammer. We have clarified this point more explicitly in the updated version. The results are as follows, displaying the average number of Sledgehammer calls and their corresponding durations (in seconds) for each solved statement:\n\n| **Method** | **Calls (valid)** | **Calls (test)** | **Duration (valid)** | **Duration (test)** |\n|------------|-------------------|------------------|----------------------|---------------------|\n| DSP        | 2.33              | 2.39             | 3.29                 | 2.98                |\n| Ours       | 2.88              | 3.22             | 4.16                 | 4.94                |\n\n\nThese results show that our method has a slight increase in both the frequency of Sledgehammer calls and their execution times compared to DSP. Specifically, this increase is primarily observed in statements that our method can solve but DSP cannot. For these statements, the number of Sledgehammer calls on the miniF2F-valid and miniF2F-test are 3.21 and 5.38, respectively. This suggests that the need for Sledgehammer becomes more important as the problem complexity increases. These results have been incorporated into Appendix C.8 in the updated version of our manuscript.\n\nThese results indicate that optimizing the use of Sledgehammer could potentially enhance the effectiveness of existing LLM-based methods. However, it is important to note that such an optimization strategy falls beyond the scope of our current paper. Nonetheless, your suggestion has sparked interest in this as a valuable direction for future research.\n\n**Reference**:\n\n[1] Jiang A Q, Welleck S, Zhou J P, et al. Draft, sketch, and prove: Guiding formal theorem provers with informal proofs. ICLR 2023."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3920/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700385419755,
                "cdate": 1700385419755,
                "tmdate": 1700385419755,
                "mdate": 1700385419755,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "t4PfllJaMj",
                "forum": "xLoxMvO695",
                "replyto": "JczVUf0rAL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3920/Reviewer_kVAV"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3920/Reviewer_kVAV"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response. I believe my concerns have been addressed."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3920/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700513444620,
                "cdate": 1700513444620,
                "tmdate": 1700513444620,
                "mdate": 1700513444620,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "t4DX7BNn4c",
            "forum": "xLoxMvO695",
            "replyto": "xLoxMvO695",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3920/Reviewer_Wmqb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3920/Reviewer_Wmqb"
            ],
            "content": {
                "summary": {
                    "value": "This paper looks at using LLMs to provide formal proofs from an initial human-provided proof sketch, where the formal proofs are verifiable by an external automated theorem prover. The proposed method consists of two parts. First, the authors propose generating subgoal based proofs from human-provided proof sketches. This is inspired by the subgoal generation literature in reinforcement learning--specifically, that a good sequence of subgoals should preserve the property that each subgoal is reachable from the start state, and that the goal state is reachable from the subgoal. Second, the authors propose using diffusion models to select and order the demonstrations provided to the LLMs, for generating the formal theorem sketches."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Using LLMs for theorem proving is an interesting problem. The proposed method follows prior work in breaking down the problem into two in-context  learning problems: first, providing a subgoal proof, and second, providing a formal proof based on the subgoal proof. The paper proposes novel methods to order in-context learning examples for the in-context learning problems. \n- Well written and clear. \n- Experiments are described clearly and sufficient baselines are used. Experiments show ~7% improvement of proposed method over baselines."
                },
                "weaknesses": {
                    "value": "Experiments: \n- No std deviations or measurement of uncertainty in Tbl 1 &2. \n- The improvement brought by using the diffusion models is very minor (about 1% in the Table 2). This is potentially not statistically significant. However, in Figure 2a, there seems to be a clear  advantage of using diffusion models + subgoals over using subgoals alone (about 2-5 additional problems solved for each # of LLM calls). These two results seem slightly contradictory. In any case, the result of Table 2 shows that the main innovation of the method seems to be the subgoal generation itself, which I feel the authors should state clearly. \n\nExperimental setup is not fully justified. \n- Why are words like \"sorry\" and \"oops\" used to determine that the proof is not valid? The provided justification is that these words indicate that the proof has been prematurely terminated, but I'm not quite sure I understand this justification."
                },
                "questions": {
                    "value": "How does the quality of the human provided proof sketch influence the performance of the proposed method?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3920/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3920/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3920/Reviewer_Wmqb"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3920/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698813290773,
            "cdate": 1698813290773,
            "tmdate": 1699636352092,
            "mdate": 1699636352092,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ioe7svoBk8",
                "forum": "xLoxMvO695",
                "replyto": "t4DX7BNn4c",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3920/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3920/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Wmqb"
                    },
                    "comment": {
                        "value": "Thank you for dedicating your time and providing constructive suggestions. We hope our responses can thoroughly address your concerns.\n\n**Question 1: Lack of standard deviation and uncertainty measures.**\n\nThank you for your valuable suggestions! We have included additional results with mean and standard deviation values to quantify the uncertainty associated with our method. Specifically, for the variants employing diffusion models (\u201dOurs\u201d and \u201c-subgoal\u201d), we trained three separate diffusion models as detailed in Section 3.4. For the variants without diffusion models (\u201d-subgoal & diffusion\u201d and \u201c-diffusion\u201d), we repeated the experiment three times. The results are as follows and we have also updated these values in Table 2 of our manuscript:\n\n| Method               | Valid             | Test              |\n|----------------------|-------------------|-------------------|\n| Ours                 | 48.0% (*\u00b10.4*)    | 45.5% (*\u00b10.6*)    |\n| -subgoal & diffusion | 41.4% (*\u00b10.9*)    | 38.7% (*\u00b11.2*)    |\n| -subgoal             | 44.3% (*\u00b10.7*)    | 40.6% (*\u00b10.6*)    |\n| -diffusion           | 46.9% (*\u00b11.3*)    | 44.1% (*\u00b10.9*)    |\n\nThese results demonstrate that the methods incorporating diffusion models exhibit relatively more stable performance.\n\nFor baseline methods in Table 1, we used reported results from their original papers to ensure a fair comparison, hence standard deviations for these are not included in our analysis.\n\n**Question 2: Inconsistency in diffusion model's efficacy.**\n\nWe greatly appreciate your perceptive remarks regarding the diffusion model's performance in our study. As detailed in Section 4.3, we found that the benefit of the diffusion model tends to decrease when the number of Large Language Model (LLM) calls reaches 100. This pattern is attributed to the model being trained on data points where optimal demonstration organization is achievable through a reasonable number of randomized organization sampling attempts. Consequently, it is adept at generalizing to *unseen* data points of similar complexity, thereby effectively reducing the number of LLM calls required for these *unseen* scenarios. This capability notably results in the more pronounced gap between \u201csubgoal+diff\u201d and \u201csubgoal\u201d observed in Figure 2a, particularly evident when the LLM calls are reduced to 20.\n\nOn the other hand, the model's efficiency in organizing demonstrations may not be as marked for data points demanding a significantly higher count of randomized sampling attempts for optimal organization. This factor contributes to the relatively limited effect of the diffusion model shown in Table 2 (It is important to highlight that the results presented in Table 1 & 2 were obtained with 100 LLM calls, aligning with the standard experimental setups prevalent in the field [1]).\n\n**Question 3: Clarification on the use of \"sorry\" and \"oops\" to determine invalid proofs.**\n\nIn the Isabelle proof assistant, \"sorry\" can be interpreted as \"we presume the current proposition is true (without proving it)\", and \"oops\" means that \"we give up showing the current proposition\". For example, both `lemma \"1=(2::int)\" sorry` and `lemma \"1=(2::int)\" oops` are valid Isabelle code: the first assumes the integers 1 and 2 are equal (and this is treated as a lemma that can then be used in other proofs); in the second case, we abandon the attempt to show 1=2. We, of course, will not accept either as a valid proof of the equation 1 = 2. Therefore, any proof that includes the terms \"oops\" or \"sorry\" will be deemed invalid.\n\n**Question 4: Impact of human-provided proof sketch quality on method performance.**\n\nThank you for this valuable advice in making the evaluation of our method more solid. We additionally used gpt-3.5-turbo-0613 to generate informal proofs for problems in the miniF2F-valid. We applied the algorithms detailed in Section 2.1 to construct subgoal-based proofs. A total of 61 problems were then selected as demonstration samples for our experiments, in accordance with the setup described in Section 3.4. The results obtained are as follows:\n\n| Method                        | Valid            | Test             |\n|-------------------------------|------------------|------------------|\n| Ours                          | 48.0% (\u00b10.4)     | 45.5% (\u00b10.6)     |\n| Ours (GPT-3.5 Informal Proofs)| 47.7% (\u00b10.5)     | 45.0% (\u00b10.7)     |\n\nThese results suggest that our method demonstrates robustness against variations in the quality of informal proof sketches. These additional results have been detailed in Appendix C.6 of the updated version of our manuscript.\n\n**Reference**:\n\n[1] Jiang A Q, Welleck S, Zhou J P, et al. Draft, sketch, and prove: Guiding formal theorem provers with informal proofs. ICLR 2023."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3920/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700385334528,
                "cdate": 1700385334528,
                "tmdate": 1700385334528,
                "mdate": 1700385334528,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UXTeBMcsGD",
                "forum": "xLoxMvO695",
                "replyto": "t4DX7BNn4c",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3920/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3920/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Further comments and discussions will be appreciated!"
                    },
                    "comment": {
                        "value": "Dear Reviewer Wmqb,\n\nThank you for your time and effort in reviewing our manuscript. We greatly appreciate your insightful comments, which have been invaluable in enhancing the quality of our work.\n\nIn response:\n\n1. We have enriched our manuscript with additional experimental results to better quantify uncertainty and evaluate the impact of human-provided proof sketch quality.\n\n1. Additionally, we have provided detailed explanations regarding the inconsistency in the diffusion model's efficacy and the use of terms such as \"sorry\" and \"oops\" in determining invalid proofs.\n\nWe hope our answers have addressed your concerns. If you have any further questions, we are happy to address them. We would really appreciate it if you are willing to reconsider your score.\n\nThanks very much!\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3920/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646387330,
                "cdate": 1700646387330,
                "tmdate": 1700646519881,
                "mdate": 1700646519881,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "xXBm9qPqFA",
            "forum": "xLoxMvO695",
            "replyto": "xLoxMvO695",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3920/Reviewer_xitB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3920/Reviewer_xitB"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a method of improving the performance of LLM-based guidance to the formal prover Isabell for the Isabell problems in MiniF2F.  The reported results are an improvement on previous results for this dataset.  The primary method involves the constructions of in-context examples to serve as a prompt to an LLM in finding a proof of a desired theorem x.  The prompt consists of a set of \"demonstrations\" each of which is a kind of \"lemma\" consisting of the statement proved by the lemma and the sequence of steps (subgoals) in the proof of the lemma. The method of constructing the demonstrations in the prompt appropriate for a specific goal x is quite complex involving a heuristic solution to a Hamiltonian graph problem."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper described an considerable effort in improving the performance of LLM-based support for formal verification.  The ideas are nontrivial and provide experimental results that may be of value to future efforts in this area."
                },
                "weaknesses": {
                    "value": "The writing is unclear.  For example does the term \"demonstration-based proof\" in the subgoal refinement section correspond to graph nodes (demonstrations) in section 2.2?  Reviewers cannot be expected to read appendices and the technical meaning of terms needs to be clear from the body of the paper.\n\nA serious ambiguity is whether the \"manually written\" seed demonstration-based proofs are biased to the test set.  If so, this would constitute training on the test set.  The process of manual annotation needs to be discussed.  A related issue is source of the training data for the \"diffusion model\" (it is not really a diffusion model as the latent variables are not in R^d and no Gaussian distributions are involved).\nIn the section on evaluation they say\n\n   Given the absence of a training split in the miniF2F\n   dataset, we leverage optimal organizations that yield successful proofs from the miniF2F-valid set\n   to train the diffusion model.\n\nI find this very unclear.  Why is training on the validation set ok?\n\nIt seems to me that the complexity of the system allows for an over-fitting of the system design to the test data. I worry that the results would not generalize to a test set that was unavailable to the authors before testing."
                },
                "questions": {
                    "value": "Questions are asked in the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3920/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3920/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3920/Reviewer_xitB"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3920/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699732239525,
            "cdate": 1699732239525,
            "tmdate": 1699732239525,
            "mdate": 1699732239525,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "G3qFVqktxk",
                "forum": "xLoxMvO695",
                "replyto": "xXBm9qPqFA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3920/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3920/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer xitB (Part 1/2 )"
                    },
                    "comment": {
                        "value": "Thank you for your insightful feedback and for recognizing the effort and novelty of our work. We appreciate the opportunity to clarify the points you have raised and address your concerns.\n\n**Question 1: Unclear definition of \u201cdemonstration-based proof\u201d in the subgoal refinement section and its relation to graph nodes in section 2.2.**\n\nWe appreciate your query and apologize for any confusion. We would like to gently clarify that the correct term we intended to use is \u201csubgoal-based proof\u201d, as opposed to \u201cdemonstration-based proof\u201d.\n\nThe term \u201csubgoal-based proof\u201d is used to describe the in-context examples that are generated during the subgoal refinement process, as detailed in Section 2.1. Each of these examples includes a mathematical statement, a proof based on subgoals, and a corresponding formal sketch, as introduced in the opening paragraph of Section 2. Additionally, we would like to clarify that these subgoal-based proofs indeed serve as the graph nodes, as highlighted in the first paragraph of Section 2.2. We are grateful for the opportunity to clarify and hope this clarification better illustrates the connection between the concepts.\n\n**Question 2: Potential bias in the manually written seed demonstration-based proofs.**\n\nWe understand the criticality of this concern. To mitigate such biases, we sourced the manually written seeds from DSP\u2019s informal proofs [1], which are entirely independent of the test set. The selection was based solely on the success of constructing a subgoal proof, not on any similarity or relevance to the test set. It also makes our results comparable with the DSP paper.\n\n**Question 3: Training data for the diffusion model.**\n\nIn our study, we focus on enhancing the efficacy of Large Language Models (LLMs) in formal theorem proving. A key aspect of our experiment is the use of the miniF2F dataset, a benchmark where almost no formal proofs are provided (in neither miniF2F-valid nor miniF2F-test) and the goal is to supplement those statements with formal proofs. This makes it suitable for evaluating LLMs as no formal proof of the valid/test questions can be found online.\nNeither the previous work [1][2] nor this work has formal proofs to train on.\nTo make our approach performance-wise comparable to prior work like DSP [1], which effectively used the miniF2F-valid to guide LLMs in proof generation for miniF2F-test problems, we retained the same set-up. Concretely, we use the statements from the validation set to obtain better prompts (i.e., demonstrations) that generate better informal proofs (i.e., subgoal-based proofs) to guide formal theorem proving. As detailed in Section 3.4, we further divided the miniF2F-valid into non-overlapping training and validation subsets. This division allowed us to conduct hyperparameter tuning and implement early stopping mechanisms in the validation subset. This should ensure a fair and reliable evaluation of our model performance in the miniF2F test set.\n\n**Question 4: Clarification of the definition of \u201cdiffusion Model\u201d used in the study.**\n\nWe greatly appreciate your observation regarding the nature of the diffusion model employed in our framework. It is important to clarify that our model is indeed a discrete diffusion model incorporating Bernoulli noise. This approach is in accordance with the methodologies described in [4].\n\n**Question 5: The potential lack of generalizability to an unseen test set.**\n\nWe appreciate the chance to highlight that our approach has shown promising results with in-domain *unseen* test data (\u201din-domain\u201d means that all problems come from high-school level practices or competitions). As we elaborated in our response to **Question 3**, the miniF2F-test was kept completely *unseen* during the hyperparameter tuning process, ensuring an unbiased evaluation of our model.\n\nWe acknowledge that our current diffusion model may face challenges in transferring to out-of-domain data, such as undergraduate-level problems. Our methodology has the potential for wider application as more diverse datasets, such as ProofNet [3] (currently available in Lean with an Isabelle version in progress), become available. The current scope of our research has successfully demonstrated that with a judicious use of annotated data, our learned diffusion model can achieve competitive results with only 1/5 LLMs calls on the *unseen* miniF2F-test, indicating the potential of our approach to adapt to more diverse training set and generalize to out-of-domain test sets in future work. We are grateful for the opportunity to clarify this aspect of our study and thank you for bringing this important topic to our attention. We look forward to contributing further to this exciting field of research.\n\nWe sincerely appreciate the opportunity to address the concerns raised and to further clarify the contributions of our work. Should there be any need for additional clarifications, we are more than willing to provide them."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3920/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700385050457,
                "cdate": 1700385050457,
                "tmdate": 1700385050457,
                "mdate": 1700385050457,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "odeQmgyUME",
                "forum": "xLoxMvO695",
                "replyto": "xXBm9qPqFA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3920/Reviewer_xitB"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3920/Reviewer_xitB"
                ],
                "content": {
                    "title": {
                        "value": "Clarifications"
                    },
                    "comment": {
                        "value": "Rather than try to extract clarity from the paper, which I am fining very difficult, I'll just ask.\n\nI'm still having trouble understanding your basic data structures. Your (informal) presentation seems ambiguous (as informal statements tend to be, which is the subject of your paper!).  I'm trying to \"auto-formalize\" your paper.\n\nYou seem to be saying that a subgoal-based proof is a pair <conclusion, {premise1,...,premiseK}> where the conclusion follows logically from the premises.  Is that correct?  Has each proof been formally verified? If so wouldn't it be much clearer to say this explicitly? What language are these statements written in.  What syntactic category of Isabell expressions are we talking about?"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3920/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700415436296,
                "cdate": 1700415436296,
                "tmdate": 1700415538154,
                "mdate": 1700415538154,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Fnw5aAtFyR",
                "forum": "xLoxMvO695",
                "replyto": "xXBm9qPqFA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3920/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3920/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Further comments and discussions will be appreciated!"
                    },
                    "comment": {
                        "value": "Dear Reviewer xitB,\n\nThank you for your constructive feedback on our manuscript. Your insights have been invaluable in guiding our revisions. In response, we have included detailed clarifications regarding the data structure and the syntactic category of Isabelle expressions. We hope our answers have addressed your concerns. If you have any further questions, we are happy to address them. We would really appreciate it if you are willing to reconsider your score.\n\nThanks very much!\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3920/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646259451,
                "cdate": 1700646259451,
                "tmdate": 1700646506042,
                "mdate": 1700646506042,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]