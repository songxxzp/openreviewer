[
    {
        "title": "Diffusion Models for Imperceptible and Transferable Adversarial Attack"
    },
    {
        "review": {
            "id": "H59pW3IQfT",
            "forum": "IZbLMHbOQg",
            "replyto": "IZbLMHbOQg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2148/Reviewer_eRtP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2148/Reviewer_eRtP"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a novel imperceptible and transferable attack by leveraging both the generative and discriminative power of diffusion models. Different from the existing unrestricted attacks (i.e., manipulation in pixel space), this paper crafts perturbations in the latent space of diffusion models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The structure of the paper is well organized and most of the descriptions are very clear.\n- The performance of the proposed method are powerful, which significantly boosts the transferability and with a good FID.\n- The design of the unrestricted attack is intersting, and the resulting adversarial examples looks natural."
                },
                "weaknesses": {
                    "value": "- The comparison of papers may not be so fair. This proposed method additionally relies on stabe diffsion to enhance the transferability, while other methods can only rely on the substitute models."
                },
                "questions": {
                    "value": "- Is the method in this paper time-consuming? Could you provide the time cost, e.g., DiffAttack vs. (NCF, PerC-AL and S$^2$I-FGSM)"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2148/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2148/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2148/Reviewer_eRtP"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2148/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697898449065,
            "cdate": 1697898449065,
            "tmdate": 1699636147749,
            "mdate": 1699636147749,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vGS7pHs3xM",
                "forum": "IZbLMHbOQg",
                "replyto": "H59pW3IQfT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2148/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2148/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer eRtP"
                    },
                    "comment": {
                        "value": "Thank you sincerely for taking the time to review our work. We extend our heartfelt gratitude for your positive evaluation of our research, which not only encourages us but also instills confidence in our efforts.\n\n---\n\n>**W1:** The comparison of papers may not be so fair. This proposed method additionally relies on stabe diffsion to enhance the transferability, while other methods can only rely on the substitute models.\n\nThank you for your insightful concern. We appreciate your consideration of potential fairness issues in comparing our method, given its reliance on stable diffusion to enhance transferability.\n\nTo comprehensively address this concern, our manuscript included a thorough analysis and extensive experiments in Appendix K. This analysis was explicitly referenced in the last sentence of Sec. 3.3, where we mentioned, \"\u2026 DiffAttack exhibits an implicit ensemble characteristic \u2026 we give a detailed analysis in Appendix K\".\n\nWithin Appendix K, we not only demonstrate the fairness of the comparison but also compare our method with other attack approaches that incorporate an additional CLIP classifier. This supplementary analysis aims to further support and validate the effectiveness of our approach.\n\nFurthermore, our superior performance over GAN-based attacks that leverage additional GAN generators, as presented in Appendix J, contributes additional evidence supporting the effectiveness of our approach.\n\nWe trust that these points effectively address your concerns. Thank you.\n\n---\n\n>**Q1:** Is the method in this paper time-consuming? Could you provide the time cost, e.g., DiffAttack vs. (NCF, PerC-AL and SI-FGSM)\n\nThank you for your insightful advice. We would like to acknowledge that this matter was indeed discussed in the final paragraph of Sec. 5, and a detailed comparison of computational and time costs, along with corresponding analysis, can be found in Appendix M. We hope this information suffices for your inquiry.\n\nWe hope that these responses effectively address your questions. Thank you for your continued support."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2148/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700242155900,
                "cdate": 1700242155900,
                "tmdate": 1700242155900,
                "mdate": 1700242155900,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "DiiXHqMmfZ",
            "forum": "IZbLMHbOQg",
            "replyto": "IZbLMHbOQg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2148/Reviewer_9mVi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2148/Reviewer_9mVi"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a transferable adversarial attack using a diffusion model for stealthiness. They specifically optimized three loss to deceive the classifier while maintaining stealthiness."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1) Evaluation results look promising.\n\n2) The writing is clear."
                },
                "weaknesses": {
                    "value": "1) transfer loss: It is confusing that eq.4 optimizes the objective of variance, which is not differentiable. According to the description, it optimizes the objective of evenly distributed cross-attention maps. It disturbs the attention recognition of the diffusion process, but it is unclear how the corruption can be transferred to other pure classifiers without diffusion. Briefly, the loss can help attack diffusion, but how can it help transferability?\n\n2) structure loss: if the purpose is to maintain structure property over diffusion steps, why not directly impose constraints on edges detected by discontinuity detection algorithms or PCA analysis and so on?\n\n3) Evaluation: Lack of ablation study of coefficient in eq. 6 for understanding the interplay of the designed losses.\n\n4) Overall, I feel the loss design (main contribution of the paper) is not fully explained. Basically, it is not convincing why adversarial examples generated by diffusion have better transferability. It is not clear why the designed loss is important, and ablation is missing."
                },
                "questions": {
                    "value": "Please refer to weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2148/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697940061768,
            "cdate": 1697940061768,
            "tmdate": 1699636147662,
            "mdate": 1699636147662,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ND3qBE6hEx",
                "forum": "IZbLMHbOQg",
                "replyto": "DiiXHqMmfZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2148/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2148/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 9mVi [1/2]"
                    },
                    "comment": {
                        "value": "Thank you sincerely for taking the time to review our paper. We appreciate the questions you've raised, as they provide us with the opportunity to offer further clarification regarding the motivation behind our network design. Below, we present our responses to your queries, aiming to provide a clearer understanding of the rationale behind our loss design.\n\n---\n\n>**W1:** transfer loss: It is confusing that eq.4 optimizes the objective of variance, which is not differentiable. According to the description, it optimizes the objective of evenly distributed cross-attention maps. It disturbs the attention recognition of the diffusion process, but it is unclear how the corruption can be transferred to other pure classifiers without diffusion. Briefly, the loss can help attack diffusion, but how can it help transferability?\n\nThank you for your insightful questions. **Our transfer loss enhances DiffAttack by imbuing it with an ensemble attack-like characteristic.** To offer a clearer understanding, we've organized our response into several key sections:\n\n**About the Differentiability of the Variance:**\n\nWe need to clarify that the variance operation is indeed differentiable. The calculation of variance, denoted as $\\sigma^2$, is expressed as follows:\n\n$$\\sigma^2=\\frac{1}{n}\\sum_{i=1}^{n}\\left(x_i-\\mu\\right)^2$$\n\nAs both squaring and summation are differentiable operations, the variance calculation, being a composition of differentiable functions, is itself differentiable.\n\n**About the Benefit to Transferability of This Loss:**\n\nTo address concerns about the benefit of our loss design to transferability, two key findings must be acknowledged first:\n\n**Finding 1:** An ensemble-based attack, where adversarial examples are generated on multiple models, enhances transferability compared to a single-model attack. This principle is well-established in prior works such as [1] and [2].\n\n**Finding 2:** The diffusion model, originally designed for image synthesis, implicitly possesses recognition capabilities when pretrained on extensive data like Stable Diffusion. This is highlighted in Para. 2, Sec. 3.3, and validated by [3] and [4].\n\nBuilding on these findings, our design motivation is to leverage the diffusion model as an implicit surrogate recognition model. Alongside the explicit surrogate recognition model, we craft adversarial examples, making our DiffAttack operate akin to an ensemble attack. Drawing on Finding 1, this ensemble characteristic contributes to improved transferability. We elaborate on this concept in the final sentence of Sec. 3.3, and in Appendix K, we provide a detailed discussion of our method\u2019s ensemble characteristic. The ablation study results in Table 3 affirm the effectiveness of this loss design on transferability, as evidenced by the following excerpt:\n\n|Transfer Loss|Average Accuracy among Black-Box Models|\n|:---:|:---:|\n|w/o|66.5|\n|w/|**65.4**|\n\n**Others:**\n\nAddressing the reviewer's mention of \u201chow the corruption can be transferred to other pure classifiers without diffusion\u201d, we suspect there might be some ambiguity regarding the transferable attack task. In a transferable attack, the attacker crafts adversarial examples on a known recognition model (usually named the surrogate model, distinct from the target model being attacked). These crafted adversarial examples are then expected to deceive other unknown recognition models.\n\nIn our method, both the explicit classifier and the implicit diffusion model serve as the surrogate model. We craft adversarial examples based on them and can directly utilize the crafted examples to attack other pure classifiers. There is no requirement for these other classifiers to incorporate diffusion.\n\nWe hope these clarifications provide a comprehensive understanding of our design. Thanks.\n\n[1] Liu, Yanpei, et al. \"Delving into Transferable Adversarial Examples and Black-box Attacks.\" International Conference on Learning Representations. 2016.\n\n[2] Dong, Yinpeng, et al. \"Boosting adversarial attacks with momentum.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.\n\n[3] Xu, Jiarui, et al. \"Open-vocabulary panoptic segmentation with text-to-image diffusion models.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n\n[4] Clark, Kevin, and Priyank Jaini. \"Text-to-Image Diffusion Models are Zero-Shot Classifiers.\" ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models. 2023."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2148/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700241101536,
                "cdate": 1700241101536,
                "tmdate": 1700241101536,
                "mdate": 1700241101536,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Vd3FgUqjnF",
                "forum": "IZbLMHbOQg",
                "replyto": "DiiXHqMmfZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2148/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2148/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Seeking Your Feedback on Our Paper's Rebuttal"
                    },
                    "comment": {
                        "value": "Dear Reviewer 9mVi,\n\nWe sincerely appreciate your time and dedication to reviewing our paper. Recognizing the demands of this busy period, we are reaching out to kindly request your feedback on our rebuttal, as the discussion phase nears its conclusion.\n\nIf you have any additional comments or suggestions regarding our paper, we would be more than happy to engage in further discussion with you.\n\nLooking forward to your response.\n\nWith deepest gratitude,\n\nThe Authors"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2148/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700679839595,
                "cdate": 1700679839595,
                "tmdate": 1700679839595,
                "mdate": 1700679839595,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rvLIPc0NLe",
            "forum": "IZbLMHbOQg",
            "replyto": "IZbLMHbOQg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2148/Reviewer_WbRq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2148/Reviewer_WbRq"
            ],
            "content": {
                "summary": {
                    "value": "This work studies transferable and imperceptible adversarial attacks using diffusion models. Instead of crafting adversarial perturbations in the pixel space, the authors proposed to use the latent space of diffusion models. Cross-attention and self-attention were also utilized in the attack. Experiments with several baselines showed that the attack can achieve high attack success rates and imperceptibility."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The crating of adversarial perturbations in the latent space of diffusion models is quite intuitive and the paper is easy to follow.\n- The experimental results in Table 1 showed that the method can generally achieve good performance wrt a set of baselines."
                },
                "weaknesses": {
                    "value": "- The method seems to have adopted the diffusion model to craft adversarial perturbations in a relatively straightforward way since crafting adversarial attacks in the latent space of generative models has existed before (the diffusion model is a new representative of generative models). Thus it hinders the technical novelty of this work.\n- In Table 2, the results show that the method performed worse in attacking NIP-r3 and RS, and it performed worse than PI-FGSM to attack Adv-Inc-v3.\n- In Table 4, the authors used FID to measure imperceptibility which is not a visual quality metric, while LPIPS should be more accurate and these results should be presented in the main paper rather than in Appendix.\n\n**Post rebuttal**\n\nI thank the authors for preparing the rebuttal. I have carefully checked the rebuttal and comments from other reviewers, I still feel the technical contributions and the presentation can be further improved. Therefore, I would like to maintain my rating."
                },
                "questions": {
                    "value": "See Weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA."
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2148/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2148/Reviewer_WbRq",
                        "ICLR.cc/2024/Conference/Submission2148/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2148/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698807431048,
            "cdate": 1698807431048,
            "tmdate": 1700659880500,
            "mdate": 1700659880500,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Snul0Iswxw",
                "forum": "IZbLMHbOQg",
                "replyto": "rvLIPc0NLe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2148/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2148/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer WbRq [1/2]"
                    },
                    "comment": {
                        "value": "Thank you for taking the time to review our work and for providing valuable feedback. We are grateful for your acknowledgment of the clarity of our paper and the performance of our method. In response to the highlighted weaknesses, we provide the following clarifications. We trust that these responses will enhance the understanding of the value of our work and address your concerns effectively.\n\n---\n\n>**W1:** The method seems to have adopted the diffusion model to craft adversarial perturbations in a relatively straightforward way since crafting adversarial attacks in the latent space of generative models has existed before (the diffusion model is a new representative of generative models). Thus it hinders the technical novelty of this work.\n\nThank you for your insightful feedback. We value this opportunity to address your concerns and **would like to underscore the uniqueness, novelty, and significance of our method to the research community**. Our response is organized into key subparts for clarity:\n\n**Uniqueness of Our Method:**\n\nAs depicted in Fig. 2, our approach involves projecting input images into the latent space of diffusion models and perturbing the latent codes to craft adversarial examples. The novel concept of achieving transferable, visually imperceptible adversarial examples by directly manipulating latent space variables of a generative model distinguishes our work. We have pioneered this new paradigm for adversarial attacks, striking a balance between visual imperceptibility and transferability.\n\nThe works most closely related to ours are [1,2], which optimize a pre-trained GAN generator\u2019s latent code to craft physical adversarial patches. These crafted patches exhibit significantly different patterns from their background. In contrast, our method crafts imperceptible adversarial examples that do not alter the appearance of the original input image.\n\n[1] Hu, Yu-Chih-Tuan, et al. \"Naturalistic physical adversarial patch for object detectors.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.\n\n[2] Hu, Zhanhao, et al. \"Adversarial texture for fooling person detectors in the physical world.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022.\n\n**Technical Novelty of Our Method:**\n\nWithin our methodology (Sec. 3), our approach consists of three integral components: Basic Framework (Sec. 3.2), \"Deceive\u201d Diffusion Model (Sec. 3.3), and Preserve Content Structure (Sec. 3.4). These segments incorporate the design of three distinct loss functions, $L_{attack}$, $L_{transfer}$, and $L_{structure}$.\n\nRegarding the reviewer's comment on the existence of crafting attacks in the latent space of generative models, the focus appears to center solely on the Basic Framework (corresponding to $L_{attack}$). However, our innovation extends beyond this component. Our $L_{transfer}$ and $L_{structure}$ designs, highlighted in the \"Deceive\u201d Diffusion Model and Preserve Content Structure sections, enable the creation of transferable and imperceptible adversarial examples within the diffusion model\u2019s latent space. These designs leverage the inherent attention maps of the diffusion model, presenting a distinct approach. The evidence from our ablation experiments and visualizations (Table 3, 4, and Figure 5) underscores the significance of these designs.\n\nWe kindly request the reviewer to consider the entirety of our method, encompassing all three designs, while reassessing the novelty of our work, as these innovative components collectively contribute to the advancement in this domain.\n\n**Significance to Community of Our Method:**\n\nGoing beyond the specific designs of our method, we emphasize the paramount contribution of our work \u2014 the demonstration of diffusion models as a promising foundation for crafting adversarial examples. This pivotal aspect is highlighted as the first contribution in the Introduction's contribution list. Our diffusion-based approach showcases promising outcomes across diverse datasets (Appendix I), various model structures (Sec. 4.2.1 & Appendix H), and demonstrates resilience to defense models (Sec. 4.2.2). Additionally, our method also exhibits superior performance when compared to ensemble attacks (Appendix G & K) and GAN-based methods (Appendix J).\n\nThese results collectively underscore the diffusion model as a robust platform for crafting adversarial examples. Beyond empirical validation, our work offers a comprehensive exploration of potential future directions for diffusion-based methods in the discussion section (Sec. 5). We believe that this exploration not only enhances the understanding of diffusion-based models' potential within the community but also provides valuable guidance for future research endeavors.\n\nIn light of these clarifications, we believe our work stands as a very valuable contribution to the field and hope you find it equally compelling after these explanations. Many thanks."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2148/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700240237645,
                "cdate": 1700240237645,
                "tmdate": 1700240237645,
                "mdate": 1700240237645,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nugKTSFshU",
                "forum": "IZbLMHbOQg",
                "replyto": "rvLIPc0NLe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2148/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2148/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Sincere Request for Reconsideration [Final]"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for your response to our rebuttal. **We appreciate the time and consideration you've dedicated to evaluating our submission**.\n\nWe want to express our genuine frustration with the current evaluation outcome. It's disheartening to feel that our efforts in the previous rebuttal might not have been fully acknowledged, although we understand this can be a common occurrence in conference reviews. Nonetheless, **rather than resigning to disappointment, we'd like to make a final effort to appeal for a Rating Increase**.\n\nAllow us to present some additional insights for your consideration and that of potential readers, articulated in bullet points for clarity:\n\n- Our work stands as the **pioneering venture that introduces diffusion models into the realm of adversarial attacks**, garnering relatively **good attention within the field**.\n- We have **an array of experiments within the manuscript to bolster its comprehensiveness**. This ICLR submission showcases **numerous experiments and comparisons**, with **our method achieving the best results in various situations**.\n\nWe're perplexed by the notion that our work lacks novelty. Being **the first** to delve into **diffusion-based attacks**, proposing **effective designs** of utilizing diffusion models, conducting **extensive experiments and comparisons** yielding **promising results**, and **delving deeply into the future research direction** of diffusion-based attacks\u2014**Don't these elements establish the novelty and value of our work?**\n\nOn the other hand, **the word \"feel\"** in the reviewer's reply to our rebuttal is, to be honest, **subjective and ambiguous**. **We genuinely hope that the reviewer can carefully reassess our contribution**.\n\n**While we understand that perspectives on novelty can vary, we are eager for another opportunity to advocate for our work.** We earnestly wish for this work to be shared at the conference, allowing more individuals to recognize the potential of diffusion-based attacks.\n\nThank you for your time and consideration.\n\nBest regards and wishes for a good day,\n\nAuthors of Submission 2148"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2148/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700676125005,
                "cdate": 1700676125005,
                "tmdate": 1700676125005,
                "mdate": 1700676125005,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]