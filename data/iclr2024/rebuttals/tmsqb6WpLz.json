[
    {
        "title": "Dissecting learning and forgetting in language model finetuning"
    },
    {
        "review": {
            "id": "6MAbHbYsrO",
            "forum": "tmsqb6WpLz",
            "replyto": "tmsqb6WpLz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9346/Reviewer_o2MC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9346/Reviewer_o2MC"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the effects of finetuning on an LM. The authors disentangle the effects of the finetuning along three \u201cdimensions\u201d: topic, style, and factual knowledge. To achieve that, they leverage ChatGPT to generate a series of texts that are only different in one of those facets. Provided such texts, one can estimate log-likelihood ratio of different styles (for instance), by calculating differences of cross-entropies of the model on the texts.\nThe generated texts were verified by human judgements. \n\nThe experimental study is performed using two corpora (BioMed and C4) and three LMs (GPT-2 XL, LLaMa 2 - 7B & 13B). \n\nThe paper reports the following findings: (a) topic and style changing rapidly,(b) topic and style biases are independent, (c) topic and style require minimal capacity to be learned, in contrast to knowledge, (d) mixing in unbiased data only reduces the biases to a certain degree."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* I find the topic of the investigation quite novel. I believe that the approach taken is original and innovative, in particular building a corpus that allows disentangling style/topic/factual knowledge. I also like the way LoRa was used to measure the capacity required for learning different facets.\n* The authors are sharing the data and code.\n* The reported experiments have provided some applicable insights, e.g. wrt the data mixing."
                },
                "weaknesses": {
                    "value": "* Using synthetic data, generated by ChatGPT, might introduce some hidden biases. It is not given that the same findings could be found if we had natural data.\n* It is not clear if the same approach can be generalized to any other characteristics?\n\nTypos:\n* \u201cby just changing the order of decomposition in 1\u201d -> \u201c...in Eq. 1\u201d"
                },
                "questions": {
                    "value": "* I wonder if there are other factorizations which can be studied in the same setup, apart from style/topic/knowldge?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9346/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698486488509,
            "cdate": 1698486488509,
            "tmdate": 1699637176101,
            "mdate": 1699637176101,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dMnfDFbNIw",
                "forum": "tmsqb6WpLz",
                "replyto": "6MAbHbYsrO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9346/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9346/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the reviewer"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for the insightful comments and suggestions. We have revised the paper incorporating many of the suggestions. Please let us explain our responses to the reviewer's comments below:\n\n\n**Hidden biases of synthetic data**\n\nWe agree with the reviewer that text generated with ChatGPT can have hidden biases, and we mentioned some forms of possible bias in the limitations of the paper. It would make the results of our paper more robust if we had natural data, but unfortunately the data we require for controlled-variable analysis (e.g., two document having the same content but different styles) is unlikely to be available in natural corpora. The advantage of using synthetic data is precise control on the components on text, so that we can have good precision in locating the variables we want to study which increases the reliability of our results.\n\n**Generalization to other characteristics of text**\n\nThe decomposition of text into generating factors is not unique, as long as the decomposition of $p(x)$ into conditional probabilities corresponds to a valid model of text-generation process. For example, we could decompose text into a semantic part and a syntactic part, suggested by one of the reviewers. Such a decomposition would corresponds to a model of text generation where the semantic information is first determined, then the syntax of the document is determined based on the semantic information. \n\nOne would find more ways to decompose text for studying its various characteristics from linguistic theories. For example, stylistics separates the style of text into linguistic features such as vocabulary, syntax, and figurative language. Narratology separates the narrative of text into components like plot, characters, and narrative perspective. For specific types of text, we can define more components to analysis than general text. \n\nAs long as the separation of one characteristic from the rest of the text is clear enough and meaningful, we could apply our dissection analysis method to analyze how the characteristic is learned in finetuning. More precisely, \"separation\" means that the chosen factor has a degree of freedom that is independent of other factors, so that modifying it while keeping other factors still result in valid and coherent text. For example, the plot in a narrative text can be changed while keeping the characters and narrative perspective the same.\n\n\n**Typo in the paper**\n\nWe thank the reviewer for pointing out the typo and we have corrected it in the revised paper.\n\n**Generalization to other factorizations**\n\nWe answered this question in combination with the previous question and provided our response above.\n\n\n**Other paper updates**\n\nWe also kindly ask the reviewer to refer to the \"comments to all reviewers\" section at the top of this page for a list of newly added contents in the revised paper. We included theoretical support of our methods, new domain corpora and more knowledge evaluation tasks to generalize our findings. We hope that the revised paper is getting even more clear and complete with the help of the reviewers."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9346/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700410354834,
                "cdate": 1700410354834,
                "tmdate": 1700410354834,
                "mdate": 1700410354834,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KX6fDquf1N",
            "forum": "tmsqb6WpLz",
            "replyto": "tmsqb6WpLz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9346/Reviewer_QBAp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9346/Reviewer_QBAp"
            ],
            "content": {
                "summary": {
                    "value": "The paper investigates the impact of finetuning language models on domain-specific texts and how it affects their general performance. The authors show that finetuning alters the model's preferences for topics and styles significantly, learning these features quickly and with minimal capacity. Factual knowledge, however, is acquired more slowly and requires greater capacity. The study's insights into language model learning dynamics could guide future enhancements in domain adaptation and help address the challenge of model forgetting during continuous learning.\n\nIn this study, the authors fine-tuned three models in increasing scales (GPT2-XL, LLaMa2 7B, and 13B) on PubMed abstracts with different scales of datasets up to 1M abstracts."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Investigating the changes language models undergo after finetuning continues to be a highly relevant and evolving area of study, despite prior coverage in academic literature.\n\n2. The research offers key empirical insights into the differential impact of finetuning on language models, revealing a more pronounced effect on style and topic preferences compared to factual knowledge. These findings enhance our understanding of language model training dynamics and are instrumental in formulating more effective training methodologies.\n\n3. The researchers conducted extensive experiments on three language models of considerable size, particularly from an academic perspective."
                },
                "weaknesses": {
                    "value": "* The assertion that each prediction by a language model can be broken down into components of writing style, topic, and factual knowledge requires further justification or explanation. The paper should present a stronger argument or provide additional evidence to substantiate this claim.\n\n* The primary message or conclusion of the paper is ambiguous. The authors need to clarify the central thesis to ensure that readers can grasp the main contribution of the work. what is the takeaway from this research? \n\n* While the prose is generally lucid, the paper's structure, particularly the introduction, could use refinement to enhance its readability and impact.\n\nFor improved clarity and presentation, the following suggestions are offered:\n1. The introduction would benefit from concrete examples illustrating the key domains of style, topic, and factual knowledge to help contextualize the subsequent findings.\n2. Details regarding the fine-tuning process are scant. Clarification of which specific models are assessed and the precise nature of the fine-tuning would provide a more robust understanding of the study's scope.\n3. The transition from discussing fine-tuning effects to probing methods in the third paragraph of the introduction is somewhat abrupt. A smoother segue that connects these topics would aid reader comprehension.\n4. In the fourth paragraph, where style and topic biases are introduced, it would be helpful to include examples or elaborate on what these biases entail to furnish readers with a clearer picture of these concepts."
                },
                "questions": {
                    "value": "* The basis of the method assumes that p(x)=p(topic,style,factual), but is there a justification to that decomposition? what about arithmetic? how does it fall to this decomposition?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9346/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9346/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9346/Reviewer_QBAp"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9346/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698580562967,
            "cdate": 1698580562967,
            "tmdate": 1699637175990,
            "mdate": 1699637175990,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Co3Z0LNf1m",
                "forum": "tmsqb6WpLz",
                "replyto": "KX6fDquf1N",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9346/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9346/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the reviewer"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for the insightful comments and suggestions. We have revised the paper incorporating many of the suggestions. Please let us explain our responses to the reviewer's comments below:\n\n\n**Decomposition of text-generating factors**\n\nWe could find theories from linguistics and literary analysis that endorse the approach of decomposition of text into content and style. Separating the content (what is being said) and form (how it is being said) has been a traditional approach in literary theories (Eagleton, 2011). Content analysis deals with themes and the narrative while form (style) analysis studies the use of literary devices like metaphors and the organization of the text.\n\nSome linguistics theories further support decomposing the content into an overall topic and specific, detatiled information. For example, topic-focus articulation (Sgall et al., 1986) distinguishes between the \"topic\" of a sentence (what the sentence is about, or its theme) and the \"focus\" (new or important information in the sentence). Theme-rheme analysis (Halliday, 1994) divides a sentence into \"theme\" (the departure point of the clause, what it's about) and \"rheme\" (the rest of the clause, what is being said about the theme). It can also be extended to larger text structures, where the overall theme of the text is distinguished from specific, detailed information.\n\nIn machine learning and NLP, there are many work that study the three aspects separately. For example, topic modeling (Hofmann, 1999; Blei et al., 2003) studies the topic distribution of text in a corpus, style transfer studies manipulation of the style of text (Shen et al., 2017; Fu et al., 2018) (and also how to separate style from content (Fu et al., 2018)), and information extraction (Brin, 1998; Banko et al., 2007) studies the identification of factual information from text. Also, in document modeling, several work uses a hierachical structure to separately model the overall theme and specific information (Lin et al., 2015;\nLi et al., 2015; Nawrot et al., 2022), in a similar spirit as we did in this work.\n\nThe citation and discussion on the above mentioned work can be found in the Related Work section of the revised paper. We hope that we provided sufficient evidence from past work for justification of the decomposition used in our approach.\n\n**A summary of contributions with better focus**\n\nWe have rewritten the summary of contributions in the introduction section to better highlight the main contributions of the paper. The main contributions of our paper are the following two observations:\n\n* Domain finetuning leads to a significant change in the topic and style priors of the language model, biasing them towards the training data. Effect caused by such bias dominates the learning and forgetting observed in finetuning.\n\n* Topic and style biases are learned like simple features, while factual knowledge are learned like complex features in finetuning. We present the significant differences between their learning dynamics in multiple aspects.\n\nThe details of each observation are succinctly summarized under the two bullet points at the end of the introduction section. We hope that the revised introduction can help readers better grasp the main contributions of the paper."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9346/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700409917091,
                "cdate": 1700409917091,
                "tmdate": 1700409917091,
                "mdate": 1700409917091,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "IeQh1AMom9",
            "forum": "tmsqb6WpLz",
            "replyto": "tmsqb6WpLz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9346/Reviewer_xGn4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9346/Reviewer_xGn4"
            ],
            "content": {
                "summary": {
                    "value": "This paper dissects the effect of fine-tuning on learning and forgetting of language style, topic, and factual knowledge. The authors use instruction-following LLMs to automatically construct corpus with controlled factors above. The authors performed extensive analysis across different LM types and summarized several empirical findings, among which they show topic and style priors are easy to learn but factual knowledge is not."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The method how the analysis is performed is novel. Creating training and evaluation corpora with controlled differences (topics, style, factual knowledge) by prompting instruction following LLMs is interesting and inspiring.  \n- The analysis is extensive and is performed under various configurations (like the choice of LM, size of the training corpora)\n- The outcomes of analysis are interesting and relevant to future research that study lifelong learning of LMs."
                },
                "weaknesses": {
                    "value": "- Although other configurations are very extensive, the choice of training and evaluation corpora and exclusively original or variants of PubMed and C4. \n- The three text-generating factors (styles, topics, facts) may not always be clearly separable of extensive enough in every corpora. The authors discussed this limitation in their limitation section.\n- Clarity issue: I feel the plots very hard to read because the captions are too generic and not self-contained. I suggest to briefly summarize the findings or implications in the captions.\n- Clarity issue: some legends in plots such as Figure 4 are not explained in text (e.g. readers may be confused about \"C4 -factuals\" before they associate them with \"C4-counterfactual\" in Table 1)\n- Though the authors pointed out the hardness of learning factual knowledge without learning style and topic bias, the authors' attempts failed to improve such performance at the end of Sec. 3. I suggest to provide some future directions about how the analysis will be beneficial the challenge of learning factual knowledge above.\n- The authors focused on evaluation of LM loss throughout the paper. I think this is fine for style and topics, but factual knowledge, evaluating LM loss is not clean enough because only a few tokens in a sentence are related to facts. The authors could create cloze-style  or question answering evaluation sets that focus exclusively on generation of factual knowledge."
                },
                "questions": {
                    "value": "- There is a \"side note\" in page 7: \"When capacity is limited, the topic ratio and factual ratio simultaneously reduce on Pubmed in Figure 6.\" I did not see topic ratio reduces in Figure 6. Is this information supposed to be told by Figure 6?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9346/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698657942204,
            "cdate": 1698657942204,
            "tmdate": 1699637175869,
            "mdate": 1699637175869,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "IWBOZuHnlk",
                "forum": "tmsqb6WpLz",
                "replyto": "IeQh1AMom9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9346/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9346/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the reviewer"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for the insightful comments and suggestions. We have revised the paper incorporating many of the suggestions. Please let us explain our responses to the reviewer's comments below:\n\n**Corpora for evaluation**\n\nWe included two new domains, the legal domain and the customer review domain, in our analysis to verify the generalization of our finding. For the legal domain, we use the \"Court Listener Opinions\" subset from the Pile of Law corpus. For the customer review domain, we use the \"automotive\" subset from the Amazon reviews dataset. We use the same procedure as in our main study to finetune LLaMa 2 7B model, generate derived datasets, and probe the model accordingly.\n\nWe show (in Figure 9-10 of the revised paper) that similar to the biomedical domain, for the legal and the customer review domain, likelihood of the dominant topic and style in the corresponding training corpus also increases significantly during finetuning. For all the domains, the factual/counterfactual likelihood ratio changes at a significantly slower rate than the topic and style likelihood ratios, showing that the effect of topic and style adaptation on langauge modeling modeling are much more significant than the effect of knowledge learning. This shows that our main findings are likely general phenomena in domain finetuning.\n\nThe above results and discussions are included in the Appendix D of the revised paper.\n\n**Separability of text-generating factors**\n\nWe agree that the text-generating factors may not always be clearly separable in every corpora, and this poses a limitation on the scope where the dissection analysis can be directly applied. However, we believe that the general idea of decomposition of text into simple features (such as topic, style) and complex features (such as factual knowledge) is still useful in understanding the learning dynamics in domain finetuning even in cases where the decomposition cannot be explicitly performed. \n\n**Improving factual knowledge learning**\n\nWhile the current study mainly aim to uncover the learning dynamics in domain finetuning, we believe that by identifying bias learning as a potential hindrances in knowledge learning and showing the properties of bias learning, we also pointed out potential directions to improve knowledge learning. We can use the discovered differences between bias learning and knowledge learning to design methods that encourage knowledge learning. For example, based on the observation that bias learning mostly happens on the first few tokens of the sequence, we could mask out the loss on the first few tokens in the finetuning objective to considerably reduce bias learning. Based on the different capacity requirement of bias and knowledge learning, in principle we could use a small low-rank adapter to learn the bias, and subtract its weights from the full finetuned model to remove the bias while keeping the learned knowledge.\n\nWe add a part of discussion on potential directions to improve knowledge learning in the conclusion section of the revised paper."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9346/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700408817727,
                "cdate": 1700408817727,
                "tmdate": 1700408817727,
                "mdate": 1700408817727,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "tAmKnN5JGR",
            "forum": "tmsqb6WpLz",
            "replyto": "tmsqb6WpLz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9346/Reviewer_DT5M"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9346/Reviewer_DT5M"
            ],
            "content": {
                "summary": {
                    "value": "- This paper presents a detailed analysis of the effects of fine-tuning of large language models on domain-specific downstream tasks/datasets.\n- In doing so, authors break down the probability distribution of a text into its fundamental factors i.e., topic, style and factual knowledge, and study the effects of fine-tuning on the probability distribution over these three factors.\n- It has been shown that in the early cycles of fine-tuning, the language model easily captures the topic and style information of the underlying text data thus introducing learning bias, which ultimately leads to an increase in the forgetting of the previous knowledge. However, the model is able to capture the factual knowledge in the later cycles of fine-tuning and also requires significant model capacity as compared to the model capacity required for capturing topic and style information.\n- Extensive experimental evaluation asserts the claims made by authors and opens a new research direction in continual learning research."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Quality\n\t- The motivation is well-founded and the claims are sound.\n\t- Experimental analysis is very detailed and explanatory.\n- Clarity\n\t- Paper is clearly presented and easy to follow."
                },
                "weaknesses": {
                    "value": "- Quality\n\t- As the topic of a document can be determined by the factual knowledge it contains then it might be redundant to keep the topic as a relevant factor in the text generation process and only style and factual knowledge might suffice which then could directly align with the syntax and semantics of the underlying text respectively.\n- Significance\n\t- This paper presents a detailed technical analysis of the fine-tuning process of a language model on domain-specific downstream tasks/datasets. However, the outcomes of the study conform with the expected outcomes of fine-tuning a model on domain-specific data and hence this paper misses to provide any significant gainful insight into the fine-tuning process due to the following reasons:\n\t\t- In the PubMed dataset, as academic style is present across all abstracts with different factual knowledge, it is expected that the model will readily adapt to the academic style first before capturing the diverse type of factual knowledge.\n\t\t- Just like in topic modeling, the topic of a document is a broad sentiment and can be easily determined using a set of keywords. So, it will be easy for the model to detect/understand the topic of a document before reading the whole document and capturing the factual knowledge inside it. Therefore, it is expected for the model to easily understand the topic and style factors before capturing the factual knowledge inside it.\n\t- I am keen to hear the response of the authors on this and hope that they can change my point of view."
                },
                "questions": {
                    "value": "- The C4 dataset could possibly contain the documents written in the \"academic\" style although in a different domain. Similarly, the C4 dataset could also contain documents related to the biomedical domain although having different factual information. So, it is possible that the model is adapting fast to the academic style and biomedical domain topic because it has already seen them in the pretraining data, but the diverse factual information in the PubMed dataset is new for the model, and that is why model is possibly taking time to capture that knowledge. Have authors taken this into consideration in their analysis of the finetuning process?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9346/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698752847344,
            "cdate": 1698752847344,
            "tmdate": 1699637175765,
            "mdate": 1699637175765,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8vFbANmxjt",
                "forum": "tmsqb6WpLz",
                "replyto": "tAmKnN5JGR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9346/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9346/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the reviewer"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for the insightful comments and suggestions. We have revised the paper incorporating many of the suggestions. Please let us explain our responses to the reviewer's comments below:\n\n**The necessity of separating the topic factor**\n\n *Separating the topic factor reflects a natural generation process of text, and allows us to study the many properties of topic bias.*\n\nWe agree that the topic of a document can be determined by the factual knowledge it contains. However, considering the natural generation process of text (i.e., how a paragraph is written), it is often the case that the overall topic is determined first, then the factual information to include in the paragraph is selected. Our decomposition of $p(x)$ into $p(topic) p(factual|topic)$ reflects such a natural generation process, where $p(topic)$ models how likely a topic is chosen in the first step, and $p(factual|topic)$ models how likely certain factual information is included once the topic is chosen. As the reviewer pointed out, the alternative decomposiiton of $p(x)$ into $p(factual) p(topic|factual)$ will not make sense becuase $p(topic|factual)$ is deterministic.\n\nThere are linguistics theories that support the decomposition of text into an overall topic and specific, detatiled information. For example, topic-focus articulation (Sgall et al., 1986) distinguishes between the \"topic\" of a sentence (what the sentence is about, or its theme) and the \"focus\" (new or important information in the sentence). Theme-rheme analysis (Halliday, 1994) divides a sentence into \"theme\" (the departure point of the clause, what it's about) and  \"rheme\" (the rest of the clause, what is being said about the theme). In machine learning and NLP, there are also prior work that endorse a hierachical decomposition of paragraphs which fascilitate analysis of text at different levels of semantic granularity (Lin et al., 2015; Li et al., 2015; Nawrot et al., 2022). We have included a new subsection in the Related Work section of the revised paper to discuss the above mentioned work, for a better justification of the text decomposition method used in our approach. (The citation and discussion on the above mentioned work can be found in the Related Work section of the revised paper.)\n\nSeparating the topic factor from factual knowledge also allows us to study the many differences of the learning dynamics between topic bias and factual knowledge, which constitudes one of the two main contributions of our paper. We show that the topic biases and factual knowledge are learned very differently, which also evidences that to a certain extent the language model internally models topics separately from factual knowledge. It might have been harder to gain these insights if the topic factor is not separated from factual knowledge in the analysis. We have also revised the introduction section to better highlight the main contributions of the paper."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9346/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700408328484,
                "cdate": 1700408328484,
                "tmdate": 1700408328484,
                "mdate": 1700408328484,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GNUZ2ZX6Hm",
                "forum": "tmsqb6WpLz",
                "replyto": "tAmKnN5JGR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9346/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9346/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Significance of our findings**\n\n*Our findings starts from a simple intuition, but leads to an unexpected result, detailed understanding of different components in domain finetuning, and wide implications for future work.*\n\nWe agree with the reviewer that topic and style are very simple features of text. We pointed out that given existing study on spectral bias and shortcut learning, it is expected that topic and style are learned faster than factual knowledge. This is the starting point of our study.\n\nWith a dissection analysis, we found that the topic and style biases not only learns *fast*, but the *degree* of adaptation of topic and style priors is very significant, much larger than the degree of adaptation to factual knowledge. We think this high degree of biasing towards certain topic and style is not quite expected, as one could reasonably speculate that because topic and style are so salient and easily determinable, the model can easily recognize them during inference and does not need to adopt a strongly biased prior.\n\nWe showed that the implication of bias learning is that it affect how we interpret loss/perplexity changes in finetuning. Large reduce in perplexity does not necessarily mean significant learning of new domain knowledge as we would often assume. Large increase in perplexity on general corpus also does not equal to catastrophic forgetting of factual knowledge. We also need to take care of the bias in finetuned models in applications, as they could potentially be too heavily biased towards certain topic and style in generation which may negatively impact application in real-world scenarios.\n\nAs our second main contribution of the paper, we showed that *there are many more different properties between bias learning and knowledge learning besides the learning order*. We showed that the two types of learning have different capacity requirements, different sensitivity to learning rate and data composition, and affect modeling probabilities at different token positions. Also the topic and style biases are learned independently of each other.\n These results are not found in previous literature and we believe they are not obvious derivatives from the nature of domain finetuning.\n\nWe also point out (in the revised version of the paper) how these new insights into the fine-tuning process can be useful and its implications for future directions. We can use the discovered differences between bias learning and knowledge learning to design methods that encourage knowledge learning and reduce forgetting. For example, based on the observation that bias learning mostly happens on the first few tokens of the sequence, we could mask out the loss on the first few tokens in the finetuning objective to considerably reduce bias learning. Based on the different capacity requirement of bias and knowledge learning, in principle we could use a small low-rank adapter to learn the bias, and subtract its weights from the full finetuned model to remove the bias while keeping the knowledge. We believe that more understanding of the detailed learning dynamics in domain finetuning under a systematic analysis is very much needed as a basis to explore more finetuning techniques beyond the conventional causal language modeling recipe."
                    },
                    "title": {
                        "value": "(continued)"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9346/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700408424635,
                "cdate": 1700408424635,
                "tmdate": 1700408487248,
                "mdate": 1700408487248,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]