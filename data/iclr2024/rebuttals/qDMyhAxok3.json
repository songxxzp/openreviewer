[
    {
        "title": "MorphGrower: A Synchronized Layer-by-layer Growing Approach for Plausible and Diverse Neuronal Morphology Generation"
    },
    {
        "review": {
            "id": "jL3h8X1EYP",
            "forum": "qDMyhAxok3",
            "replyto": "qDMyhAxok3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5669/Reviewer_NzbM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5669/Reviewer_NzbM"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a generative model for neuronal morphologies (in skeleton form), implemented as a conditional VAE with an LSTM encoder/decoder. Neurons are grown using an autoregressive sampling procedure inspired by natural growth processes. The proposed model is shown to consistently perform better than MorphVAE (the only other deep learning-based alternative) under multiple metrics and for different tissue samples."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The idea to generate branches progressively is interesting and makes intuitive sense.\n- Terminology is clearly defined and illustrated in Sec. 2. \n- The authors promise to release the source code of their method.\n- Evaluations show consistently improved results in comparison to MorphVAE.\n- In addition to morphological metrics, a classifier-based approach is used to verify plausibility and BND to evaluate diversity of the generated morphologies."
                },
                "weaknesses": {
                    "value": "- Ablations of MAE and local/global conditioning are relegated to an appendix and restricted to a single dataset. Please consider including and discussing them in the main text. Perhaps some of the formulas for the LSTMs could be moved to the appendices to make space for this."
                },
                "questions": {
                    "value": "- The importance of neuronal morphology for diseases such as Alzheimer's feels out of place in the abstract. The statement itself is true of course, but it's unclear how having a computational model of such morphologies would make studying these diseases any easier. I suggest replacing it with some other potential applications.\n- In the global condition, are the non-branch coordinates completely discarded or still used somehow?\n- In section 3.3 describing the sampling procedure a \"reference morphology T\" is described. Does that mean that the sampled neurons will always have the exact same tree structure as T?\n- Have you performed any studies on the impact of the embedding size? (both for your model and MorphVAE). This hyperparameter does not appear to be explored much in the text.\n- Does Fig. 4 suggest overfitting? How is it possible that the generated neurons remain so close to the original morphology?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5669/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698778377543,
            "cdate": 1698778377543,
            "tmdate": 1699636591105,
            "mdate": 1699636591105,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CQXJI1faGo",
                "forum": "qDMyhAxok3",
                "replyto": "jL3h8X1EYP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer NzbM (1/2)"
                    },
                    "comment": {
                        "value": "Thank you for your feedback. Here are our responses to your questions.\n\n> **Response to the mentioned weaknesss.**\n\n- Firstly, we would like to humbly point out to the reviewer that we did not restrict the ablation study to a single dataset. Instead, in the appendix of the submitted manuscript, we provided ablation study results on four different datasets (Tables 11, 12, 13, and 14 in the previous version). We believe it might have been due to the formatting and separation of the four tables that led you to notice the ablation study results for only one dataset, giving the impression that we conducted experiments on only one dataset. In the latest revised version, we have consolidated the ablation study results on multiple datasets into a single table (Table 11 in the new version).\n\n- Furthermore, we appreciate your suggestion regarding the importance of ablation studies and the necessity to present them in the main text. We are aware of the significance of this aspect, which is why in the previous version submitted, in the first paragraph of Sec. 4 (the experimental section), we informed readers that we had conducted an ablation study and explicitly directed them to a specific section in the appendix for further details. However, including the results of the ablation study in the main text would require a significant amount of space, and given the limitation of a maximum of 9 pages for the main text, we opted to place the results of the ablation study in the appendix.\n\n\n> **Necessity of the importance of neuronal morphology for diseases.**\n\n- Systematic, large-scale and high-throughput acquisition of neuronal morphology can help us to understanding brain anatomy at fine scales, and has received worldwide attentions[1-3]. Such digital morphologies make a lot of downstream computational neuroscience applications possible, e.g. neuron simulation [4], classification [5], network analysis[6], studying the connection to computational models in deep learning [7], etc. Additionally, alterations in dendrite morphology influence not only dendritic function and signal transmission but also affect electrophysiological properties and neural network behavior. Abnormal dendritic morphology has been linked to brain disorders, including mental retardation [8], schizophrenia [9], autism [10], and stress-related disorders [11-13]. However, the current process of annotating morphological data requires a significant amount of manpower, which comes with high costs. This is exactly why we are developing methods for synthesizing neuronal morphologies.\n\n- Despite the aforementioned, we are very willing to accept your suggestion to omit this section of the discussion and allocate this space to other content.\n\n> **Reference:**\n\n[1] Winnubst, J. et al. Reconstruction of 1,000 Projection Neurons Reveals New Cell Types and Organization of Long-Range Connectivity in the Mouse Brain. Cell 179, 268-281.e13 (2019).\n\n[2] Peng, H. et al. Morphological diversity of single neurons in molecularly defined cell types. Nature 598, 174\u2013181 (2021).\n\n[3] Gao, L. et al. Single-neuron projectome of mouse prefrontal cortex. Nat Neurosci 25, 515\u2013529 (2022).\n\n[4] Markram, H. et al. Reconstruction and Simulation of Neocortical Microcircuitry. Cell 163, 456\u2013492 (2015).\n\n[5] Gouwens, N. W. et al. Classification of electrophysiological and morphological neuron types in the mouse visual cortex. Nat Neurosci 22, 1182\u20131195 (2019).\n\n[6] Gao, L. et al. Single-neuron analysis of dendrites and axons reveals the network organization in mouse prefrontal cortex. Nat Neurosci 1\u201316 (2023).\n\n[7] Beniaguev, D., Segev, I. & London, M. Single cortical neurons as deep artificial neural networks. Neuron 109, 2727-2739.e3 (2021).\n\n[8] Kaufmann, Walter E., and Hugo W. Moser. \"Dendritic anomalies in disorders associated with mental retardation.\" Cerebral cortex 10.10 (2000): 981-991.\n\n[9] Glausier, Jill R., and David A. Lewis. \"Dendritic spine pathology in schizophrenia.\" Neuroscience 251 (2013): 90-107.\n\n[10] Phillips, Mary, and Lucas Pozzo-Miller. \"Dendritic spine dysgenesis in autism related disorders.\" Neuroscience letters 601 (2015): 30-40.\n\n[11] Shansky, Rebecca M., and John H. Morrison. \"Stress-induced dendritic remodeling in the medial prefrontal cortex: effects of circuit, hormones and rest.\" Brain research 1293 (2009): 108-113.\n\n[12] Dioli, Chrysoula, et al. \"Chronic stress triggers divergent dendritic alterations in immature neurons of the adult hippocampus, depending on their ultimate terminal fields.\" Translational Psychiatry 9.1 (2019): 143.\n\n[13] Sandini, Corrado, et al. \"Pituitary dysmaturation affects psychopathology and neurodevelopment in 22q11. 2 Deletion Syndrome.\" Psychoneuroendocrinology 113 (2020): 104540."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5669/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700229381312,
                "cdate": 1700229381312,
                "tmdate": 1700229381312,
                "mdate": 1700229381312,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TgxXUJ3YEU",
                "forum": "qDMyhAxok3",
                "replyto": "jL3h8X1EYP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer NzbM (2/2)"
                    },
                    "comment": {
                        "value": "> **Question about the global condition.**\n\n- We extracted the global condition from all previously generated layers, as detailed in Section 3.2 of the paper. Specifically, we treated each branch generated in the earlier layers as a node. We used an LSTM to encode the branches, obtaining representations that served as the initial features for each node. The input to the LSTM consists of the coordinate information of all points constituting a branch in the spatial domain. In other words, we utilized the coordinate information of all points contained in the branches generated in the earlier layers to derive the global condition.\n\n\n> **Question about the given reference morphology.**\n\n\n- The generated neuron indeed has the exact same tree structure as the real morphology used as a reference.\n\n- This question is closely related to the next question after the following one. Here, we provide a comprehensive further explanation:\n\n   - From the original MorphVAE paper, it is evident that MorphVAE also requires a real sample as a reference when generating a new sample:\n        - The formulation of the neuronal morphology generation task in the original MorphVAE paper at Sec 2.4 is as follows: $$\\hat{M}\\_T=g_\\phi\\left(f_\\theta\\left(M_T\\right)\\right),$$\n          where $M_T$ is a set of 3D-walks that make up the morphology, which MorphVAE uses to represent a morphology. $f_\\theta$ and $g_\\phi$ represent the encoder and decoder, respectively. $\\hat{M}_T$ represents the final generated 3D-walks.\n        - If there was no need for a reference during generation, there would not be a test dataset. However, the original MorphVAE paper clearly defines train-valid-test dataset splits.\n    \n   - In our paper, we adopt the same experimental setting as MorphVAE. This setting is somewhat similar to \"augmentation\", and we have justified the validity of such a setting in the introduction of our paper (refer to the the fourth paragraph in Section 1 for both the old and revised versions).\n  \n- Now, returning to the question itself, our method adopts a layer-by-layer generation strategy and generates branches in pairs within each layer. This approach allows us to strictly adhere to the same tree structure as the reference. In contrast, when MorphVAE clusters the generated 3D-walks, it can create forks with more than two subsequent branches (see the Appendix C.1 for both the old and revised versions of the paper). This contradicts the basic rules of neuronal growth and the fundamental requirements of neuronal morphology data, which somewhat goes against the purpose of the augmentation task. Therefore, MorphVAE lacks internal consistency.\n\n\n\n> **Sensitivity to the embedding size.**\n\n- We have provided the results of how the performance of our method, MorphGrower, and baseline MorphVAE is affected by changes in the embedding size. However, due to time constraints, we have only presented experimental results on the VPM dataset. The corresponding results and analysis have been added to Appendix J.5 in the revised manuscript.\n\n\n> **Question about over-fitting.**\n\n- Referring to our response in the question before the previous one, since we, like the baseline MorphVAE, generate new neurons in an augmentation-like manner, it is reasonable for the generated morphology to closely resemble the given reference morphology, and this does not indicate over-fitting."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5669/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700229470273,
                "cdate": 1700229470273,
                "tmdate": 1700229743063,
                "mdate": 1700229743063,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "9fOKheVntp",
                "forum": "qDMyhAxok3",
                "replyto": "TgxXUJ3YEU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5669/Reviewer_NzbM"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewer_NzbM"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for all the responses and clarifications -- these are very helpful!\n\nI think the paper would benefit a lot from being very upfront about the importance of the template morphology (i.e. what you explained in your responses above). You already mention this in Sec. 1, but it's easy to miss when one does not know what one is looking for. It also does not explicitly say what is the nature of the \"augmentation\" -- i.e. that the topology stays exactly the same, but the detailed positions of the nodes might change.\n\nWhile this is very similar to the MorphVAE baseline to which you compare, in my opinion this is a fairly severe limitation of the overall approach as it very strongly constrains the diversity of shapes that might be generated (which then also limits any potential downstream applications; for instance, it's still unclear to me how this could be used for studying diseases). A \"growing approach for morphology generation\" evokes images of a neuron extending its branches from the soma to establish its final shape. As is, I think many readers might miss the fact that in the growing process a preexisting neuron morphology is being followed closely, making the final result more of a perturbation, rather that de-novo growth."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5669/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700624164469,
                "cdate": 1700624164469,
                "tmdate": 1700624164469,
                "mdate": 1700624164469,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "2VnSHpzjq7",
            "forum": "qDMyhAxok3",
            "replyto": "qDMyhAxok3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5669/Reviewer_7LXV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5669/Reviewer_7LXV"
            ],
            "content": {
                "summary": {
                    "value": "- S1. MorphVAE encoded sequences of arbitrary number of consecutive vertices along a branch with an LSTM to learn a fixed length representation. It also used an LSTM to generate a new branch conditioned on that representation. \n\n - S2. As I understand, the proposed neuron generation method is:\n\n    1. initialize `active_vertices` with soma vertex\n    2. at each step, generate two branches, conditioned on already generated graph\n    3. generated branches are allowed to be null.\n    4. replace `active_vertices` with tips of non-null generated branches\n    5. repeat 2 $\\rightarrow$ 4 until `active_vertices` is empty\n\n - S3. Conditioning on the already generated graph requires a fixed length representation of a graph. Authors propose to do this in 2 ways:\n\n    1. _global context_ aggregates fixed length branch-level representations at different branch orders $\\dagger$\n\n    2. _local context_ uses a discount scheme to weigh contribution at different branch orders. \n\n - S4. MorphVAE combine \"walks\" (sampled branches) with a heuristic procedure to construct a neuron tree. \n\n - S5. This manuscript uses a similar scheme to generate branches, but proposes a recursive procedure to generate the neuron tree. \n\n - S6. Authors provide a comparison of trees generated by either method based on 4 datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Manuscript builds on ideas in MorphVAE and proposes a meaningful extension.\n - The auto-regressive scheme of generating morphologies is interesting, and perhaps a good direction to think about the problem of generative models for neurons."
                },
                "weaknesses": {
                    "value": "- W1. The writing and notation would benefit from being more concise and self-contained. For example, various metrics are only referred to by their acronyms in the main text. Separating the biological motivation/justification in a single paragraph instead of describing it after each method step would also help towards this end. Some symbols aren't introduced at all. \n\n - W2. The proposed method seems to be so over-fit to training data, that the morphologies hardly differ from the given sample (e.g. examples in Fig 4a-c., and also Fig. 23-26)? Is this not a major problem?\n\n - W3. Building on W2., consider a _model_ that simply jitters branch points of the reference morphology by a small amount. Based on evaluations presented in the manuscript, this procedure would\n    - obtain near-perfect match on the metrics in Table on p.7.\n    - match distributions in Fig. 3\n    - be hardest to distinguish for classifiers (Sec. 4.3)\n    - have higher BlastNeuron distances with simple heuristics (e.g. deletion of small fraction of terminal branches)\n\n    From the manuscript and the metrics chosen to justify the generated morphologies, it is unclear to me why one should prefer the proposed method over this simple procedure to generate morphologies. \n\n - W4. The language is often not careful; some strong biological claims are made that are not well substantiated. Examples:\n\n    > Since the neuronal morphology is static, the generation order of the branch pairs in each layer does not matter.\n\n    > Remark. A typical neuron is comprised of a soma, dendrites, and an axon. Dendrites perform a random walk from the soma, while the elongation and bifurcation of axons exhibit specificity."
                },
                "questions": {
                    "value": "- Q1. If the intention is to also use such models to study morphology as it relates to neuronal development, the following view should probably be reconsidered?\n    > Since the neuronal morphology is static, the generation order of the branch pairs in each layer does not matter.\n\n - Q2. It looks like a typo (should be 3 instead of 3k), but just to make sure please clarify:\n    > Most nodes on the tree have no more than 3k k-hop neighbors, thereby limiting the receptive field of nodes.\n\n - Q3. I assume $k$ here refers to the depth of the tree?\n    > For a branch $b_i$, its corresponding node feature at the k-th iteration $\\hat{h}(k)$ is calculated by\n\n - Q4. $\\textbf{r}_{b_i}$ is not defined in the section on global context."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5669/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698810361997,
            "cdate": 1698810361997,
            "tmdate": 1699636590988,
            "mdate": 1699636590988,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KqoUjEFOKJ",
                "forum": "qDMyhAxok3",
                "replyto": "2VnSHpzjq7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5669/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 7LXV (1/3)"
                    },
                    "comment": {
                        "value": "Thank the reviewer for the time and the valuable comments. We hope that the following responses will help to address your concerns.\n\n\n\n> **Response to Q1.**\n- Assuming that we have generated up to the $i$-th layer, using all previously created layers as a condition. In the $i$-th layer, each pair of branches possesses two conditions: global and local. The global condition ensures consistency within the layer, while the local condition varies among different pairs, only depending on their respective ancestor branches. This approach guarantees that the generation order of branch pairs within the same layer does not have any impact, enabling synchronous generation.\n\n- Regarding the sentence you mentioned, we intended to convey that our focus in neuronal morphology generation is on generating a static morphology, as the original data consists solely of such static morphologies, lacking data on the dynamic growth process. We drew inspiration from the influence of previous branches on subsequent branch generation during neuronal growth, rather than attempting to directly simulate the growth process itself or what you referred to as neuronal development. If the intention were to simulate the growth process, the sentence you pointed out would indeed be incorrect.\n\n- To avoid any ambiguity caused by this sentence, we have removed it and added the detailed explanation mentioned above in the revised version.\n\n\n> **Response to Q2.**\n\n- It's not a typo. The definition of \"$k$-hop\" we use here follows the definition from a paper accepted at NeurIPS 2022 [1]. Specifically, \"$k$-hop neighbors of a node $v$\" refers to all the neighbors that have a distance from node $v$ less than or equal to $k$,\" not exactly at a distance of $k$ from node $v$.\" If it was understood as the latter, then your statement of \"$3$\" is correct. To eliminate any ambiguity, we have added footnotes in the revised version to explain this.\n\n\n> **Response to Q3.**\n\n- The reviewer's conjecture is correct. In the context of the sentence mentioned by the reviewer, \"$k$\" indeed refers to the depth within the tree structure.\n\n- When we revisited the original text and reviewed the sentence in question, we noticed a minor issue with Eq. 3 below this section. We have made the necessary corrections and clarified the meaning of \"$k$\" in the revised version to enhance the reader's experience. Thank you for your assistance.\n\n\n> **Response to Q4.**\n\n- In Eq. 2 and the text immediately above it, we defined that for a general branch $b$, we can obtain its corresponding representation $\\mathbf{r}\\_{b}$ using an LSTM. The reviewer's concern regarding $\\mathbf{r}\\_{b\\_{i}}$ in Eq. 3 is simply a specialization for a more specific branch $b\\_{i}$. Here, we added an additional subscript because we needed to distinguish between a branch and its neighboring branches.\n\n> **Reference:**\n\n[1] Feng, Jiarui, et al. \"How powerful are k-hop message passing graph neural networks.\" Advances in Neural Information Processing Systems 35 (2022): 4776-4790."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5669/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700228858448,
                "cdate": 1700228858448,
                "tmdate": 1700229077252,
                "mdate": 1700229077252,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3ndaOn2Nmo",
                "forum": "qDMyhAxok3",
                "replyto": "2VnSHpzjq7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 7LXV (2/3)"
                    },
                    "comment": {
                        "value": "> **Response to W1.**\n\n- We sincerely appreciate the reviewer's advice on the writing of our paper.\n    - In our previous manuscript submission, while we did not provide the specific definitions of metrics in the main text, we promptly directed readers to refer to the appendix for detailed metric definitions and explicitly indicated where in the appendix they could find this information. As shown in the specific metric definitions in the appendix, explaining these metrics in detail would require a considerable amount of space. Given that the main text needed to be limited to 9 pages, dedicating a substantial portion of it solely to introducing metric definitions would not have been appropriate. Furthermore, even though readers might not be familiar with the exact definitions of these metrics, we provided guidance on how to evaluate the performance of the results. For example, in the caption of Table 1, we explicitly mentioned, \"A closer alignment with Reference indicates better performance.\"\n\n    - The section in our paper regarding the biological motivation/justification for local and global conditions immediately follows our introduction of extracting local and global conditions from previously generated layers. We believe that this arrangement provides a coherent and concise presentation. If we did not provide the biological motivation/justification at this point, readers might wonder why we decided to split the conditions into two categories and what the significance of each condition is. You mentioned that it would be best to place this content \"after each method step\". If you are referring to \"method\" as Sec 3.1, we believe our approach already meets this requirement. If you are referring to \"method\" as Sec 3.2, we believe that placing this content there would be less effective, as it would diminish the clarity of the motivation behind the two conditions mentioned Sec 3.1. Additionally, Sec 3.2 focuses on the practical instantiation of the method.\n\n    - Regarding your questions about the meaning of certain notations, we have already provided explanations for some of the notations in response to your previous questions regarding Q3 & Q4. Since our paper contains a considerable amount of notation, we have summarized the notations in the main text in Appendix K (for both the old and new versions of the paper). In the revised version, we have made some additional clarifications. If you have any further questions about other notations, please feel free to let us know, and we will promptly provide explanations.\n\n\n\n> **Response to W2.**\n\n- This is not a case of over-fitting. Please refer to our explanation below:\n   - From the original MorphVAE paper, it is evident that MorphVAE also requires a real sample as a reference when generating a new sample:\n        - The formulation of the neuronal morphology generation task in the original MorphVAE paper at Sec 2.4 is as follows: $$\\hat{M}\\_T=g_\\phi\\left(f_\\theta\\left(M_T\\right)\\right),$$\n          where $M_T$ is a set of 3D-walks that make up the morphology, which MorphVAE uses to represent a morphology. $f_\\theta$ and $g_\\phi$ represent the encoder and decoder, respectively. $\\hat{M}_T$ represents the final generated 3D-walks.\n        - If there was no need for a reference during generation, there would not be a test dataset. However, the original MorphVAE paper clearly defines train-valid-test dataset splits.\n    \n   - In our paper, we adopt the same experimental setting as MorphVAE. This setting is somewhat similar to \"augmentation\", and we have justified the validity of such a setting in the introduction of our paper (refer to the the fourth paragraph in Section 1 for both the old and revised versions).\n\n    - Since we, like the baseline MorphVAE, generate new neurons in an augmentation-like manner, it is justified that the generated morphology closely resembles the provided reference morphology, and this does not suggest over-fitting."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5669/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700229113926,
                "cdate": 1700229113926,
                "tmdate": 1700229689265,
                "mdate": 1700229689265,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QOsNEiEqqJ",
                "forum": "qDMyhAxok3",
                "replyto": "2VnSHpzjq7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 7LXV (3/3)"
                    },
                    "comment": {
                        "value": "> **Response to W3.**\n\n\n\n- Your approach may indeed achieve better performance on some metrics compared to our MorphGrower and baseline MorphVAE. However, we do not recommend generating more morphologies in this way unless a very reasonable perturbation method can be designed. The specific reasons are as follows:\n\n    - If you simply perturb branch points, it may result in abrupt changes in the branch, which should be avoided as much as possible. If such abrupt changes occur at the end of a branch, it may also affect the starting segment of subsequent branches.\n    - Perturbation design should also take into account the influence of predecessor branches on subsequent branches, i.e., how the perturbation of subsequent branches is conditioned on the perturbation of predecessor branches. It is also essential to consider that the perturbed branches should still follow the organizing principle of self-avoidance. As detailed in the revised paper's Appendix N.1, our global condition extraction module indeed has the ability to capture complex patterns in neuronal morphologies, thereby influencing subsequent branches. In contrast, the perturbation method, without careful design, cannot achieve this.\n    - Additionally, the strategy of removing some branches that you mentioned should also be approached with caution. This can affect the asymmetry of the tree structure, which is a factor to be considered in the process of neuron growth. Simply deleting some branches may lead to morphology with an unreasonable tree asymmetry metric.\n    - Furthermore, such a perturbation algorithm is sure to involve hyperparameter selection, and it would require reselecting suitable hyperparameters for different datasets. For instance, parameters controlling the degree of perturbation would need to be adjusted. The choice of these hyperparameters may heavily rely on expert experience. In contrast, our method is purely data-driven and can generalize more rapidly across various datasets.\n\n> **Response to W4.**\n\n- We have already provided an explanation for the first sentence mentioned by the reviewer in our response to Q1.\n\n- As for the second sentence, we acknowledge that there is an issue with its accuracy. Our intention here was to convey a relative concept, where dendrites' growth is slightly more random compared to soma, while axons exhibit more specificity. This sentence is not crucial to the main points, so we have chosen to remove it in the revised version."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5669/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700229163649,
                "cdate": 1700229163649,
                "tmdate": 1700229163649,
                "mdate": 1700229163649,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iPOUYr1m7H",
                "forum": "qDMyhAxok3",
                "replyto": "2VnSHpzjq7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5669/Reviewer_7LXV"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewer_7LXV"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the clarifications by the authors, and have gone through the revised manuscript.\n\nI agree with the authors that the main contribution is in generating perturbed versions of a given morphology (and not in generating de novo morphologies from the overall distribution of morphologies in a dataset). The proposed method is only used to produce and evaluate perturbed trees that are identical in terms of number and connectivity of branches. \n\nThe method can also extract a global representation of a morphology; however there is no direct validation of the global representations obtained in this way. This could be an straightforward and interesting experiment in a future version of the paper, using labels e.g. the M1-EXC and M1-INH datasets.\n\nMy central opposition to the paper stems from a persisting lack of clarity about why such morphology perturbations are needed / useful (independent of MorphVAE). The authors agree that a simple baseline augmentation strategy (see W3 and related response) can beat the proposed method on evaluations considered here. The manuscript lacks an evaluation to demonstrate the advantage of this method over such simple, reasonable augmentation strategies.\n\nI have retained my original score for these reasons."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5669/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700605181383,
                "cdate": 1700605181383,
                "tmdate": 1700605196717,
                "mdate": 1700605196717,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "gr5v94PK5w",
            "forum": "qDMyhAxok3",
            "replyto": "qDMyhAxok3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5669/Reviewer_s2ri"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5669/Reviewer_s2ri"
            ],
            "content": {
                "summary": {
                    "value": "The authors present MorphGrower, a model for neuron morphology generation based on reference morphologies as inputs. Their method features conceptual advances over the previous state of the art in the field, MorphVAE. A comprehensive evaluation suggests that these advances yield considerable benefit across a range of quantitative measures of performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "MorphGrower constitutes a significant advance in learning-based neuronal shape generation compared to the pioneering MorphVAE. In particular, MorphVAE generates neurons by sampling soma-to-tip branches and agglomerating a set of such branches via threshold-based node merging. This can yield topologically infeasible morphologies; Furthermore, agglomeration by averaging node positions has a smoothing effect which is detrimental to the yielded shape variability.\nTo counter these deficiencies, MorphGrower generates shapes recursively, \"layer by layer\", where \"layer\" refers to branch distance from the soma (where a \"branch\" spans from bifurcation or soma to bifurcation or tip). By recursion, an encoding of the local path to a current branching point as well as an encoding of the full previous layer is fed as condition to a branch pair encoder and -decoder."
                },
                "weaknesses": {
                    "value": "MorphVAE provides an embedding for whole neuronal morphologies (via pooling of walk embeddings), which can be leveraged for shape clustering and cell type classification. This feature is not straightforwardly contained in MorphGrower as the respective encoder operates recursively on neuron branches. While MorphGrower is clearly pitched as focusing on neuronal shape generation, an explicit discussion of the aforementioned distinction in scope from MorphVAE would still be helpful for the reader. \n\nWhile the provided evaluation of neuronal shape generation is comprehensive and shows clear benefits of MorphGrower over MorphVAE, it would still be beneficial to also report the shape characteristics statistics employed in MorphVAE (cf. their Fig. 5). Furthermore, it appears that MorphVAE has been re-trained by the authors with hyper parameters different from the original model, which are then however applied to (partly) the same date -- would it be possible to directly use the resp. models trained by the MorphVAE authors, or at least their exact hyperparameters?\n\nFurther details:\n\nFor the branch pair decoder, it would be helpful if you could discuss respective permutation equivariance -- do you include both orders of each branch pair during training to train towards equivariance? or is the architecture inherently permutation equivariant? (if so this is not straightforwardly obvious)\n\nIn your comparative evaluation vs MorphVAE, it would be beneficial if you could provide a more comprehensive discussion of hypotheses regarding the sources of the observed differences. E.g., MorphVAE caps walk lengths, which clearly entails an underestimate of some of the measures you evaluate, yet this source of underperformance is not discussed."
                },
                "questions": {
                    "value": "Would it be possible to directly use the models (or at least hyper parameters) employed by the MorphVAE authors, at least for your comparative evaluation on data also used in the MorphVAE work?\n\nCould you extend your evaluation of morphological statistics to the measures evaluated in the MorphVAE work?\n\nFurthermore, please explicitly discuss the distinct scope of MorphGrower vs MorphVAE."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5669/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698850291396,
            "cdate": 1698850291396,
            "tmdate": 1699636590873,
            "mdate": 1699636590873,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3VPww2fUmV",
                "forum": "qDMyhAxok3",
                "replyto": "gr5v94PK5w",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer s2ri (1/2)"
                    },
                    "comment": {
                        "value": "Thank you for your insightful comments. Below, we address your concerns with our responses.\n\n> **Using MorphVAE's authors' provided pre-trained model or hyperparameters on the dataset shared by us and MorphVAE.**\n\n- We could not directly utilize the models or hyperparameters provided by the MorphVAE authors for the following specific reasons:\n\n    - The baseline MorphVAE did not provide a pretrained model in their open-source GitHub repository. Therefore, we had to train MorphVAE ourselves.\n    - The authors of MorphVAE provided datasets, but these datasets were in a processed format that could be directly fed into the MorphVAE model, which was not suitable for our model. Consequently, we sought out the original datasets for these three datasets and discovered that, for example, in the case of the RGC dataset, the original dataset contained more samples than the RGC samples used by MorphVAE. Mismatched sample counts implied inconsistent data splits, making it inappropriate for us to directly adopt the hyperparameter choices from the MorphVAE original paper. We had to perform a new search for hyperparameters.\n    - During our grid search for training MorphVAE's hyperparameters, we included the training hyperparameter settings provided by the MorphVAE original paper. Additionally, we strictly followed MorphVAE's resampling distance parameter for data preprocessing, which was the same for all three datasets used by both us and MorphVAE (we mentioned it in Appendix H.1 in both the old and new versions of the paper).\n\n> **Evaluating the effectiveness of MorphGrower using metrics adopted in MorphVAE.**\n\n\n- Based on the feedback from the reviewer, it is evident that the reviewer conducted a thorough and responsible review, including a review of the original paper on baseline MorphVAE. We deeply appreciate this aspect of their review.\n\n- Both baseline MorphVAE and our MorphGrower require a real sample as input, referred to as a \"reference\" in the paper, to generate new samples that closely resemble the input. MorphVAE employs a 3D-walk as the fundamental generation unit, followed by clustering to obtain the final morphology. This approach can result in discrepancies between the tree structure of the generated morphology and the reference, and may even lead to the creation of invalid branching points (with more than two successor nodes).\n\n- In contrast, we utilize a layer-by-layer generation strategy and generate branches in pairs within each layer. This approach ensures that the tree structure of the final morphology we generate strictly aligns with the reference.\n\n- You mentioned that the original MorphVAE paper's Figure 5(b) includes six metrics. Among these, four metrics\u2014max branch order, tree asymmetry, width, and depth\u2014are employed to assess the similarity of the generated morphology's tree structure to the provided reference. Therefore, these four metrics are guaranteed to be identical to the reference and are thus superior to baseline MorphVAE. Consequently, we believed that presenting the results for these metrics was not essential. The remaining two metrics, mean soma exit angle and mean branch angle, are angle-related, and in our previous manuscript submission, we have introduced two better-defined angle metrics and presented their results."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5669/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700228468316,
                "cdate": 1700228468316,
                "tmdate": 1700228468316,
                "mdate": 1700228468316,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GMMYxytsf3",
                "forum": "qDMyhAxok3",
                "replyto": "gr5v94PK5w",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer s2ri (2/2)"
                    },
                    "comment": {
                        "value": "> **The distinct scope of MorphGrower vs MorphVAE.**\n\n\n- MorphVAE primarily addresses two main issues:\n\n    - It introduces method for augmenting neuronal morphology data using 3D walks as the fundamental generation unit.\n\n    - It proposes a method for extracting an overall representation of neuronal morphology data: a pooling operation is applied to the latent embeddings corresponding to all walks. This overall representation can be applied to downstream tasks such as neuron classification.\n\n   In MorphVAE, the generation module and the downstream classifier are trained simultaneously. However, it's worth noting that MorphVAE's primary focus and contribution lie in augmenting neuronal morphology data. The extraction of overall features of neuronal morphology, as described in the second point, can be considered an additional byproduct. Additionally, MorphVAE uses a relatively large step size for resampling neuron data, resulting in the loss of a substantial amount of fine-grained information and the possibility of introducing multiple branching points in the augmented data. This does not align with the reasonable requirements of neuronal morphology topology, further indicating that MorphVAE may not be a particularly suitable model for augmenting neuronal morphology data.\n\n- MorphGrower focuses on augmenting neuronal morphology data at a finer granularity: We employ a layer-by-layer generation strategy and generate branches in pairs within each layer. We do not aim to learn an overall representation of neuronal morphology for downstream tasks. However, it is worth noting that we have found that the global condition module proposed by MorphGrower also has the ability to capture complex patterns in the data, as detailed in revised paper's Appendix N.1. Additionally, we use a more reasonable data preprocessing approach by using a smaller step size for normalizing neuron samples. These measures ensure that our augmentation pipeline results in neuron data with more detail and guarantees the topological validity of generated samples.\n\n- We appreciate the reviewer's suggestion, and we have provided a discussion of the differences between the two approaches in revised paper's Appendix L.\n\n\n> **Question about the both orders of each branch pair during training.**\n\n- During training, we do not fix the order of the two branches in each branch pair; their order is randomized in each epoch. Therefore, during training, we include both possible orders of the two branches within the same branch pair, enabling the model to train towards permutation equivariance.\n\n\n> **More comprehensive discussion of hypotheses regarding the sources of the observed differences.**\n\n- The reviewer's suggestions are greatly appreciated. In response, we have added more discussion on hypotheses regarding the sources of the observed differences in the revised manuscript, which has been resubmitted."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5669/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700228513687,
                "cdate": 1700228513687,
                "tmdate": 1700228513687,
                "mdate": 1700228513687,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YsWE0cQyEA",
                "forum": "qDMyhAxok3",
                "replyto": "3VPww2fUmV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5669/Reviewer_s2ri"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewer_s2ri"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your comprehensive response. It clarifies that the best effort was made to reproduce MorphVAE's hyper parameters and model. Did you perform a sanity check of your reproduction of the MorphVAE model by means of their evaluation metrics to see if these are (approximately) reproduced as well? Or would this not be meaningful due to the flaws in the data splits you encountered?\\\nYour response also clarifies that four of the six MorphVAE evaluation metrics do not make sense for MorphGrower as the latter guarantees identical topology. Could you please still elaborate on the \"better-defined angle metrics\" you mention? How do they improve upon the respective MorphVAE metrics? \nMany thanks!"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5669/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700593732799,
                "cdate": 1700593732799,
                "tmdate": 1700593732799,
                "mdate": 1700593732799,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "391jAy3OW3",
                "forum": "qDMyhAxok3",
                "replyto": "GMMYxytsf3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5669/Reviewer_s2ri"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewer_s2ri"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate that you've included an explicit discussion of MorphVAE's vs MorphGrower's scope, as well as an extended discussion of hypotheses regarding the observed differences, in the revised manuscript. Last but not least, my permutation equivariance question is fully clarified."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5669/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700593920095,
                "cdate": 1700593920095,
                "tmdate": 1700593920095,
                "mdate": 1700593920095,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "o877G0Z0Xz",
                "forum": "qDMyhAxok3",
                "replyto": "391jAy3OW3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5669/Reviewer_s2ri"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5669/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5669/Reviewer_s2ri"
                ],
                "content": {
                    "comment": {
                        "value": "I agree with the other Reviewers that it would be great to show the benefits of the neuronal morphology augmentation provided by MorphGrower in downstream (learning) tasks. However, the authors convincingly show that their augmentations are more realistic than the previous state of the art, which suggests good potential for use in downstream tasks. Thus hence I stick to my original score."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5669/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700651317367,
                "cdate": 1700651317367,
                "tmdate": 1700651317367,
                "mdate": 1700651317367,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]