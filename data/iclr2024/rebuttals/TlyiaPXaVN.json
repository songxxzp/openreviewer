[
    {
        "title": "Generative Adversarial Equilibrium Solvers"
    },
    {
        "review": {
            "id": "MA8W896ldk",
            "forum": "TlyiaPXaVN",
            "replyto": "TlyiaPXaVN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8725/Reviewer_pH5J"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8725/Reviewer_pH5J"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors present a novel neural network-based method for approximating the generalized Nash equilibrium (GNE) within pseudo-games derived from a specific distribution. These pseudo-games consist of players operating within compact and convex action spaces, where the choices made by each player can influence the feasible action space of others.\n\nTo facilitate the training of the GNE neural network solver, the authors introduce exploitability as the loss function.  Exploitability quantifies the total utility gains that all players would achieve by deviating to their own best responses. However, calculating exploitability poses a challenge due to the potentially infinite action space. To tackle this issue, an adversarial network is employed to approximate each player's best response.\n\nThe authors also establish a theoretical framework by providing a generalization bound for this neural solver. Furthermore, in practical experiments, they apply this approach to identify Nash equilibria in normal-form games, compute competitive equilibria in Arrow-Debreu economic models, and determine GNE in an environmental economic model involving the Kyoto mechanism."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The versatility of this method is evident because it can be applied to a wide range of games, thanks to the inherent generality of pseudo-games.\n- The methodology looks strong. The use of two neural networks (a generator and a discriminator) and adversarial training is intriguing to me.\n- The concept of employing a neural network as a function approximator to compute GNE is innovative. I believe it has the potential to expedite equilibrium computation in practice."
                },
                "weaknesses": {
                    "value": "- The title in the PDF is still the template title.\n- The paper concentrates on finding a single equilibrium, yet many games have multiple equilibria. Incorporating a discussion on equilibrium selection would enhance the work.\n- The overall presentation of this paper would benefit from further refinement. The figures within the paper are small and appear blurry due to the absence of vector graphics formats such as .pdf or .svg. Upgrading the figures to vector graphics would improve their clarity and overall visual impact."
                },
                "questions": {
                    "value": "- How does the performance of GAES degrade with approximate discriminators in practice? Is there a way to quantify the required discriminator accuracy?\n- Could you apply GAES to find other solution concepts like correlated equilibria? How would the formulation need to change?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8725/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8725/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8725/Reviewer_pH5J"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8725/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698138879135,
            "cdate": 1698138879135,
            "tmdate": 1699637094209,
            "mdate": 1699637094209,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KgdkwMmzzr",
                "forum": "TlyiaPXaVN",
                "replyto": "MA8W896ldk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8725/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8725/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review!\n\n**Regarding the weaknesses you mention.**\n\n- A clash in macro definitions seems to have caused the title to be missing from the paper, this will be fixed for the camera-ready version.\n- We will make sure to include a discussion on equilibrium selection, but we note that a strength of our method is that it does not require practitioners to have to select an equilibrium selection criteria which might be hard to decide.\n- We will make sure to include graphics which are clearer.\n\n**Regarding your questions.**\n\n- **On the effectiveness in approximating the best response.** As we show in additional experiments in Appendix G.1., the accuracy of the discriminator directly impacts the accuracy of the generator, however these two architectures can be tuned independently. We find it interesting to see that 3 of the 5 games can be solved accurately, even when the discriminator is not optimized. This seems to suggest that the accuracy needed for the discriminator depends on the equilibrium structure induced by the payoff structure of the pseudo-game, a direction which future work can explore. \n\n- **On generalizing GAES for correlated equilibria.** Yes, GAES can be directly extended to compute correlated equilibria, and in fact to any equilibrium notion which can be expressed as a $\\Phi$-equilibrium [1] where $\\Phi$ is a set of action deviations. To do so, one can replace the cumulative regret with the $\\Phi$-cumulative regret, i.e., the sum of unilateral improvements by deviations within a set $\\Phi$-action deviations. In this more general setting, the discriminator would then simply output action deviations within $\\Phi$.\n\n**References**\n\n[1] Greenwald, Amy, and Amir Jafari. \"A general class of no-regret learning algorithms and game-theoretic equilibria.\" Learning Theory and Kernel Machines: 16th Annual Conference on Learning Theory and 7th Kernel Workshop, COLT/Kernel 2003, Washington, DC, USA, August 24-27, 2003. Proceedings. Berlin, Heidelberg: Springer Berlin Heidelberg, 2003."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8725/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700119240189,
                "cdate": 1700119240189,
                "tmdate": 1700119240189,
                "mdate": 1700119240189,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ny6hvgIJzk",
                "forum": "TlyiaPXaVN",
                "replyto": "KgdkwMmzzr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8725/Reviewer_pH5J"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8725/Reviewer_pH5J"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response. I have some further questions. \n\n* **About the effectiveness in approximating the best response.** \n\nI have observed from Figure 5 and Figure 6 that the performance of GAES degrades significantly in Bertrand Oligopoly and Traveller\u2019s Dilemma when the discriminator is not precise enough. However, you only applied a one-layer neural network with a softmax activation function as the neural discriminator. So, how does a more complicated architecture, such as a multi-layer neural network discriminator, perform in the five normal-form games?\n\nFurthermore, could you provide some insight into how sensitive the performance of GAES would be with respect to the precision of the discriminator?\n\n\n* **About your general comments.** \n> We provide an affirmative answer to the open question posed by Marris et al. [1] and Duan et al. [2] ...\n\nI did not see the title of Duan et al. [2] in your general comments. \nIt seems to be an AAMAS paper, however, I still not find it in the references of your paper.\nThe references that seem most similar are Duan et al. [2021a] and Duan et al. [2021b]. \nHowever, I noticed that these two references are both duplicated and contain inaccuracies, such as differences in author order and conference details compared to what you listed in the general comments. \nIt would be good if you could check the references in your paper."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8725/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700448695320,
                "cdate": 1700448695320,
                "tmdate": 1700448695320,
                "mdate": 1700448695320,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Q8kibZhsyH",
                "forum": "TlyiaPXaVN",
                "replyto": "ynlVWRfepm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8725/Reviewer_pH5J"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8725/Reviewer_pH5J"
                ],
                "content": {
                    "comment": {
                        "value": "> For discrete action (pseudo-)games where the best-response is always discrete the accuracy of the discriminator (i.e., the discriminator outputting a pure action rather than a mixed action) seems to matter a lot as our experiments show.\n\nI believe that for such discrete action pseudo-games, we still need the discriminator to output mixed actions to better approximate the best response. This is because the discrete best response is discontinuous and could change differently with a slight modification of the payoffs.\n\n>  (pseudo-)games which do not have this property the performance of the trained generator seems highly robust to the accuracy of the discriminator.\n\nIt is counterintuitive that the generator is more robust with respect to the discriminator in pseudo-games than in normal-form games. As far as I know, pseudo-games are generalized versions of normal-form games; thus, they are more difficult to solve. Do you mean that when the best response is smooth, the generator would be robust to the discriminator?\n\n\n> [2] Zhijian Duan, Wenhan Huang, Dinghuai Zhang, Yali Du, Jun Wang, Yaodong Yang, Xiaotie Deng. International Conference on Autonomous Agents and Multi-Agent Systems 2023\n\nI still haven't seen the title of this reference, and I also cannot find it in the references of your paper.\nAre you referring to the paper `Duan, Zhijian, et al. \"Is Nash Equilibrium Approximator Learnable?.\" Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems. 2023.` ?"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8725/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700534029831,
                "cdate": 1700534029831,
                "tmdate": 1700534029831,
                "mdate": 1700534029831,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2baFijJJ1U",
                "forum": "TlyiaPXaVN",
                "replyto": "MA8W896ldk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8725/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8725/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you so much for your quick answer!\n\n> I believe that for such discrete action pseudo-games, we still need the discriminator to output mixed actions to better approximate the best response. This is because the discrete best response is discontinuous and could change differently with a slight modification of the payoffs.\n\nPrior work seems to corroborate to our point. Namely, Duan et al. [1] show that expected exploitability in normal-form games (i.e., when the discriminator in our setting outputs the exact best-response) can be effectively minimized. This is because while the best-response might be discontinuous (assuming it is unique) in the candidate equilibrium, the exploitability itself is still continuous in the candidate equilibrium.\n\n> It is counterintuitive that the generator is more robust with respect to the discriminator in pseudo-games than in normal-form games. As far as I know, pseudo-games are generalized versions of normal-form games; thus, they are more difficult to solve. Do you mean that when the best response is smooth, the generator would be robust to the discriminator?\n\nOur statement was only regarding regarding pseudo-games with **discrete** action spaces which also includes normal-form games. The intuition for our answer is that if a mixed action best-response always exists, then it is more likely that the players' best-responses change smoothly as a function of the other players' actions. Once again, these claims are empirical anecdotes and not theoretical claims, since in general, without strong concavity and Lipschitz-smoothness of payoffs it is not possible to guarantee a connection between the best-response of each player and their opponents' actions (e.g., Lipschitz-continuity of the best-responses w.r.t. the opponents' actions). Beyond this, we prefer to refrain ourselves from speculating a theory.\n\n\n> I still haven't seen the title of this reference, and I also cannot find it in the references of your paper. Are you referring to the paper Duan, Zhijian, et al. \"Is Nash Equilibrium Approximator Learnable?.\" Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems. 2023. ?\n\nThank you for noticing this! You can find the correct ACM citation in [1]. The version of the paper cited in our paper is [2]. We consulted [2] while writing our paper, however, the contents align with the most recent version [1]. \n\n[1] Zhijian Duan, Wenhan Huang, Dinghuai Zhang, Yali Du, Jun Wang, Yaodong Yang, and Xiaotie Deng. 2023. Is Nash Equilibrium Approximator Learnable? In Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems (AAMAS '23). International Foundation for Autonomous Agents and Multiagent Systems, Richland, SC, 233\u2013241.\n\n[2] Zhijian Duan, Dinghuai Zhang, Wenhan Huang, Yali Du, Jun Wang, Yaodong Yang, and Xiaotie\nDeng. Towards the pac learnability of nash equilibrium, 2021b. URL https://arxiv.org/abs/2108.07472."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8725/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700535485446,
                "cdate": 1700535485446,
                "tmdate": 1700535536579,
                "mdate": 1700535536579,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rCNKi8T07D",
            "forum": "TlyiaPXaVN",
            "replyto": "TlyiaPXaVN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8725/Reviewer_Wcqa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8725/Reviewer_Wcqa"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces generative adversarial equilibrium solvers (GAES), a GAN that learns to map pseudo-games to their generalized Nash equilibria from a sample of problem instances. In particular, they provide a formulation that makes the problem amenable to standard stochastic first-order methods. They use GAES to compute in a scalable way competitive equilibria in exchange economies and an environmental economic model of the Kyoto mechanism, outperforming earlier methods."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Pseudo-games are very general game-theoretic models with a number of applications, most notably Arrow-Debreu competitive economies. Yet, there is a lack of scalable techniques for computing generalized Nash equilibria in such settings. This paper makes a concrete contribution in that direction by providing a method with promising performance across a number of benchmarks. The proposed method is natural and the experimental results are overall convincing and quite thorough. Indeed, the paper appears to attain state of the art performance in a number of important applications, and could have significant impact in this area."
                },
                "weaknesses": {
                    "value": "There are some soundness issues that the authors have to address. First, there appears to be a significant gap between the theoretical analysis and the experimental settings. Specifically, it is not clear how a stationary point in the sense of Theorem 4.1 translates to a GNE. If stationary points are not necessarily GNE, the narrative of the paper has to be restructured. In particular, it is often claimed that the method maps pseudo-games to GNE, and it is not clear whether that claim is theoretically sound. Of course, computing GNE is intractable, but it is alluded (for example in the abstract) that under a distribution over problem instances the problem could be easier. Theorem 4.1 also makes a strong concavity assumption which appears to be violated in all settings of interest. It should be the case that a \"small\" regularizer can always be incorporated without affecting the equilibria by much, but I think this should be discussed in more detail. \n\nI am also confused about Footnote 4. It is claimed that the method obtains the state of the art $O(1/\\epsilon^3)$ complexity, a major improvement over $O(1/\\epsilon^6)$, which the authors claim was the previous state of the art. The authors have to explain more precisely the class of problems this applies to; there are many variants of the PL condition studied in the literature. In particular, the following papers seem to obtain a much better dependency: \"Faster single-loop algorithms for minimax optimization without strong concavity,\" \"faster stochastic algoritms for minimax optimization under Polyak-Lojasiewicz Conditions\" and \"Doubly smoothed GDA for constrained nonconvex-nonconcave minimax optimization.\"\n\nBesides the issues above, the algorithmic approach is very close to the paper \"Exploitability minimization in games and beyond,\" which limits to some extent the algorithmic contribution of the present paper. The authors have to highlight the comparisons in more detail."
                },
                "questions": {
                    "value": "Some minor comments for the authors:\n\n1. The title of the submission document is the default one.\n2. The references have to be polished. There are many papers that are published many years ago and only the arXiv version is cited. There is also an issue with consistency: sometimes URLs are included, sometimes they are not. Please fix those issues.\n3. There are underfull equations in Observation 1 and immediately below.\n4. I don't understand how the paper of Daskalakis et al. (2009) is relevant in the context of Footnote 4 about min-max optimization.\n5. The appendix has many overfull equations that need to be formatted properly."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8725/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8725/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8725/Reviewer_Wcqa"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8725/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698594577092,
            "cdate": 1698594577092,
            "tmdate": 1699637094075,
            "mdate": 1699637094075,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "K5rBPP0yii",
                "forum": "TlyiaPXaVN",
                "replyto": "rCNKi8T07D",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8725/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8725/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review!\n\n**Regarding the weaknesses you mention.**\n\n**On stationary points of the exploitability.** Stationary points of exploitability do not always coincide with GNE, however, our convergence result to stationary points of the expected exploitability is still in line with known theoretical results, since the computation of GNE under Assumption 1 is PPAD-complete [1] and converging to a GNE would imply polynomial-time computation for problems in PPAD. That said, stationary points of the exploitability correspond to $\\varepsilon$-GNE, where $\\varepsilon$ is equal to the exploitability at the stationary point, and as at a stationary point the exploitability cannot be decreased via first-order information, this Theorem 4.1 suggests that our approach is sound to learn equilibrium mappings via first-order methods, the most prevalent training methods in deep learning. \n\n\n**On the strong concavity assumption.** Our theorems directly generalize to payoff functions that only satisfy concavity. This extension follows from the discussion at lines 235-239 and is obtained by regularizing the exploitability. Note that this regularization does not modify the optimal solutions of the optimization problem. However, while running our experiments for exchange economies we have tried adding this regularization to the cumulative regret, but we observed that this regularized cumulative regret performed worse than the original cumulative regret most likely due to the fact that although regularization makes the cumulative regret strongly concave, it also increases the non-convexity of the exploitability. As such, we have decided to present the experiments without regularization. We will make sure to include a more extensive discussion to our paper on this issue.\n\n**On the differences between our paper and Goktas and Greenwald\u2019s \u201cExploitability Minimization in Games and Beyond\u201d.**\nWhile Goktas and Greenwald observe that the exploitability minimization problem for *only one* pseudo-game can be expressed as a min-max optimization, it is not obviously true that one can minimize the expected exploitability via a min-max optimization problem. The novelty in our method lies in noticing that we can compute the expected exploitability after computing the expected cumulative regret, by optimizing over the space of best-response functions from pseudo-games to actions, rather than the space of actions individually for every pseudo-game. \n\n**On convergence complexity.** Thank you for pointing out these papers to us, especially \"Doubly smoothed GDA for constrained nonconvex-nonconcave minimax optimization.\" which seems to going to appear at NeurIPS seems very relevant and we were not aware of them. At a high-level, in all three papers, ignoring acceleration-type methods\u2013-which are rarely used in the training of neural networks in practice due to their complexity\u2014the best convergence complexity achieved is $O(\\varepsilon^{-4})$ (see for instance [2]), while our algorithm\u2014which makes use of no acceleration techniques\u2014achieves a complexity of $O(\\varepsilon^{-3})$. As a result, in the light of these more recent (and some unpublished) results, our algorithm still achieves a faster convergence rate than single-loop algorithms with no-acceleration.\n\n\n**Regarding your questions.**\n\n1) A clash in macro definitions seems to have caused the title to be missing from the paper, this will be fixed for the camera-ready version.\n2) We chose to cite the Arxiv versions of the paper to allude to the most recent version of the papers. That said, to address your concern we will cite the published versions of the papers when the Arxiv versions we have consulted match the published versions.\n3) We will fix these equation formatting issues for the camera-ready.\n4) Thank you for pointing this citation out. It seems that we accidentally cited the wrong paper from Daskalakis et al., while we sought to cite [2].\n5) Once again, we will fix these equation formatting issues for the camera-ready.\n\n**References**\n\n[1] Yang, Junchi, et al. \"Faster single-loop algorithms for minimax optimization without strong concavity.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2022.\n \n[2] Daskalakis, Constantinos, Dylan J. Foster, and Noah Golowich. \"Independent policy gradient methods for competitive reinforcement learning.\" Advances in neural information processing systems 33 (2020): 5527-5540."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8725/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700118934262,
                "cdate": 1700118934262,
                "tmdate": 1700118967070,
                "mdate": 1700118967070,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qzhfgmWNlz",
                "forum": "TlyiaPXaVN",
                "replyto": "K5rBPP0yii",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8725/Reviewer_Wcqa"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8725/Reviewer_Wcqa"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the Response"
                    },
                    "comment": {
                        "value": "I thank the authors for their response. Regarding the first point, computing GNE is of course intractable in general, but your abstract gives the misleading idea that your setting is more benign; namely, you are saying that \"Although the computation of GNE and CE is intractable in the worst-case, i.e., PPAD-hard, in practice, many applications only require solutions with high accuracy in expectation over a distribution of problem instances.\" That is, in the setting where one is given a distribution over games, the PPAD-hardness results do not necessarily kick in. Now you are claiming in the abstract \"We introduce Generative Adversarial Equilibrium Solvers (GAES): a family of generative adversarial neural networks that can learn GNE and CE from only a sample of problem instances.\" If I understand correctly this is wrong: you only compute stationary points. If the focus of the paper is on computing GNE, then the method is not theoretically sound. At the very least the authors have to revise the presentation of the paper to account for this discrepancy. On a similar note, I am not sure whether it is fair to compare your algorithm with other methods that are theoretically guaranteed to converge to competitive equilibria.\n\nRegarding the iteration complexity, there is also a paper appearing at this year's NeurIPS, namely \"A Single-Loop Accelerated Extra-Gradient Difference Algorithm with Improved Complexity Bounds for Constrained Minimax Optimization,\" which seems to subsume the complexity bounds of this paper. This is of course concurrent work, so it does not have any bearing on the evaluation of this paper, but it would be good to mention that in the revised version."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8725/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700419254319,
                "cdate": 1700419254319,
                "tmdate": 1700419254319,
                "mdate": 1700419254319,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2wkKLncgWJ",
                "forum": "TlyiaPXaVN",
                "replyto": "rCNKi8T07D",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8725/Reviewer_Wcqa"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8725/Reviewer_Wcqa"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the Response"
                    },
                    "comment": {
                        "value": "I thank the authors for their time and their response. I have no further questions at the moment."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8725/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700530743715,
                "cdate": 1700530743715,
                "tmdate": 1700530753620,
                "mdate": 1700530753620,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vXMaWKwBpf",
            "forum": "TlyiaPXaVN",
            "replyto": "TlyiaPXaVN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8725/Reviewer_Db1F"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8725/Reviewer_Db1F"
            ],
            "content": {
                "summary": {
                    "value": "This paper study the generalized Nash equilibrium of pseudo games where a player\u2019s action not only affects his utility, but also other players\u2019 action sets. The authors use GAN and employ exploitability as the loss function. The solver is applied to compute the GNE of Arrow-Debreu competitive economies and the Kyoto mechanism."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Introduce a novel method to compute GNE by GAN.\n2. Provide theoretical guarantee on convergence and generalization bounds.\n3. The performance is better according to the experiments.\n4. The literature review in the appendix summarizes the current methods to solve GNE and the application of pseudo games."
                },
                "weaknesses": {
                    "value": "1. Assume strong concavity in assumption 1, however, the utility function is not strong convex in Arrow-Debreu competitive economy.\n2. Do not provide guarantee for the performance on the training set.\n3. Use different network architecture in two experiments which means GAES is not a general solver for GNE."
                },
                "questions": {
                    "value": "1. In which paper was the name \"pseudo game\" and \"GNE\" made? It seems that the cited paper by Arrow Debreu mentioned the game first, but did not name it.\n2. Do you measure the difference between the results and the optimal action in the feasible set? Notice that the results \u201cis on average better than at least 99% of the action profiles\u201d in the experiments.\n3. Is there any guarantee when the utility function only satisfy convexity?\n4. What is the title of this paper?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8725/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698823424249,
            "cdate": 1698823424249,
            "tmdate": 1699637093859,
            "mdate": 1699637093859,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MnrfgtryXh",
                "forum": "TlyiaPXaVN",
                "replyto": "vXMaWKwBpf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8725/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8725/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review!\n\n**Regarding the weaknesses you mention.**\n1) Our theorems directly generalize to the concave game settings and as such apply to Arrow-Debreu markets as well; see part 3) of the below answer to your questions and the discussion in lines 235-240 for more information.\n2) Our results provide computational complexity guarantees on the training dataset (Theorem 4.1), whose average exploitability achieved on the training set generalizes to the test set with a sample complexity result (Theorem 4.2). Even though Theorem 4.1 does not provide a bound on the value of the average exploitability of the training set, it tells us that average exploitability on the training set, cannot be minimized via first-order deviations, hence suggesting the correctness of the algorithm we use. We note that lack of a full characterization of the average exploitability on the training set is a common occurrence in the literature for learning equilibrium mappings (see for instance [4] and [5]).  \n3) Just like any neural network, GAES also faces an architecture search problem, and for it to solve the task at hand a search over optimal architectures has to be done. However, this does not affect the generality of GAES. To give a theoretical explanation, according to our sample complexity bounds, the accuracy of GAES depends on the choice of the generator and discriminator hypothesis classes which appear as a \"bias\" term corresponding to the difference in performance between the optimal generator and discriminator in the class of all possible functions and the optimal ones in the hypothesis class. That is, the choice of a hypothesis class will affect the bias term in performance. As the selection of a neural network architecture effectively determines the hypothesis space we chose, if the architecture of the network is not well-chosen, then the bias of GAES will go up, hence degrading accuracy. This, however, does not take away the fact that with an appropriate neural network architecture GAES is guaranteed to be ``general\u2019\u2019 as the bias term will go down to 0.\n\n\n**Regarding your questions.**\n1) Pseudo-games were introduced by Kenneth Arrow and Gerard Debreu in 1954 [1] under the name of Abstract Economies, who studied GNE under the name of \u201cequilibrium points\u201d. More recently, Francisco Facchinei and Christian Kanzow\u2019s works has re-popularized Arrow and Debreu\u2019s model under the name of pseudo-games, calling equilibrium points GNE [2]. To the best of our knowledge the first use of the term GNE is due to Harker [3].\n\n2) The distance between the candidate equilibrium actions outputted by GAES and any GNE is measured in payoff space in terms of the exploitability.  As such the phrasing \u201cis on average better than at least 99% of the action profiles\u201d means that the GAES achieves an exploitability lower than 99% of all other action profiles in the feasible action space.\n\n3) Yes, our theoretical guarantees apply more broadly to any concave game\u2014that is we can drop the strong concavity condition. As mentioned in lines 235-240, our theorems generalize to the concave game settings by replacing the exploitability with the regularized exploitability, however for consistency and simplicity we chose to present our results under these stronger assumptions, since in experiments non-regularized exploitability performed better.\n\n4) The paper is called \u201cGenerative Adversarial Equilibrium Solvers\u201d, a clash in macro definitions seems to have caused the title to be missing from the paper.\n\n**References**\n\n[1] Arrow, Kenneth J., and Gerard Debreu. \"Existence of an equilibrium for a competitive economy.\" Econometrica: Journal of the Econometric Society (1954): 265-290.\n\n[2] Facchinei, Francisco, and Christian Kanzow. \"Generalized Nash equilibrium problems.\" Annals of Operations Research 175.1 (2010): 177-211.\n\n[3] Harker, P. T. (1991). Generalized Nash games and quasi-variational inequalities. European Journal of Operational Research, 54, 81\u201394.\n\n[4] Marris, Luke, et al. \"Turbocharging Solution Concepts: Solving NEs, CEs and CCEs with Neural Equilibrium Solvers.\" Advances in Neural Information Processing Systems.\n\n[5] Zhijian Duan, Wenhan Huang, Dinghuai Zhang, Yali Du, Jun Wang, Yaodong Yang, Xiaotie Deng. International Conference on Autonomous Agents and Multi-Agent Systems 2023"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8725/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700118583518,
                "cdate": 1700118583518,
                "tmdate": 1700118583518,
                "mdate": 1700118583518,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HnlfsWwm0C",
                "forum": "TlyiaPXaVN",
                "replyto": "MnrfgtryXh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8725/Reviewer_Db1F"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8725/Reviewer_Db1F"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your response. I have several addtional comments.\n\n> Our theorems directly generalize to the concave game settings and as such apply to Arrow-Debreu markets as well; see part 3) of the below answer to your questions and the discussion in lines 235-240 for more information.\n\nI checked with the cited paper Von Heusinger & Kanzow, 2009. It seems not a trivial result that under the regularized utility function, the GNE is still the same, letting alone the non-uniqueness issue of GNE. It would be better provide a detailed explanation. \n\n> Do not provide guarantee for the performance on the training set.\n\nTheorem 4.1 is about the convergence, but there is no result about how far is the stationary point to GNE, which is the \"performance\" I mean.\n\n> Just like any neural network, GAES also faces an architecture search problem, and for it to solve the task at hand a search over optimal architectures has to be done. \n\nThis is not what a \"solver\" should be like. Anyway, it does not matter much.\n\n> The distance between the candidate equilibrium actions outputted by GAES and any GNE is measured in payoff space in terms of the exploitability. As such the phrasing \u201cis on average better than at least 99% of the action profiles\u201d means that the GAES achieves an exploitability lower than 99% of all other action profiles in the feasible action space.\n\n\"better than at least 99% of the action profiles\" is really strange. Literally, the rest 1% action profile may be much better than what the approach learned."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8725/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700443269333,
                "cdate": 1700443269333,
                "tmdate": 1700443269333,
                "mdate": 1700443269333,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0lcNa2lVfL",
            "forum": "TlyiaPXaVN",
            "replyto": "TlyiaPXaVN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8725/Reviewer_ni1H"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8725/Reviewer_ni1H"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes a novel algorithm, General Adversarial Equilibrium Solvers, for training general GNE solvers.\n\nThe goal of equilibrium solvers is, given a strategic game between multiple players, to find a (generalized) Nash equilibrium of the game. \n\nWhile there has been a few previous work that proposes algorithms to train equilibrium solvers, they all suffers from three technical challenges:\n- the gradient of the exploitability requires solving a concave maximization problem\n- the exploitability of pseudo-games is in general not Lipschitz-continuous\n- the gradients cannot be bounded in general\n\nThe authors formulates equilibrium solver training as training a generative adversarial networks, where the generator takes a pseudo-game representation, and outputs a tuple of actions (one per player), and the discriminator takes both the pseudo-game, and the output of the generator, and outputs a best-response for each player.\n\nThe goal of discriminator is to output a best-response actions that produces the exploitability, and the goal of generator is to output actions that minimizes the exploitability, i.e., GNE."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "# Presentation\n- The paper is well-organized and easy-to-follow: Sec.1 motivates the readers by illustrating the possible applications of GNE solvers, including network communication, cloud computing, and economic models (e.g., Arrow-Debreu exchange economy, Kyoto joint implementation mechanism)\n\n# Novelty, Technical Contribution\n- The formulation of GAES establishes a novel, efficient, simple, and scalable algorithm to train generic GNE solvers.\n    - To the best of my knowledge, most of the previous work relied on supervised learning, and suffered from a few technical challenges in terms of computational tractability and stability. \n    - GAES beautifully solves these problems, and provides a simple yet powerful framework for training GNE solvers.\n- The formulation is strongly backed up by theoretical guarantees; convergence of the networks towards a stationary point of exploitability, and sample complexity. \n- The experiments are conducted on non-trivial games, namely Arrow-Debreu exchange economies and Kyoto joint implementation mechanism \u2014 which are non-monotone or non-jointly convex. Strong empirical results on these games verifies the efficiency of GAES."
                },
                "weaknesses": {
                    "value": "# Weaknesses\n- I don\u2019t see any special weakness in this paper. The authors establish a simple yet powerful framework for training GNE solvers, and backs up their algorithm both with strong theoretical guarantees and empirical results."
                },
                "questions": {
                    "value": "- Would it be possible to scale GAES to modern games that consists of multiple neural networks (e.g., GANs, multi-agent RL problems, etc.)? If not, what would be the main technical challenges to do so?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "10: strong accept, should be highlighted at the conference"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8725/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8725/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8725/Reviewer_ni1H"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8725/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699642710811,
            "cdate": 1699642710811,
            "tmdate": 1699642710811,
            "mdate": 1699642710811,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "050D8fCCaY",
                "forum": "TlyiaPXaVN",
                "replyto": "0lcNa2lVfL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8725/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8725/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you so much for your encouraging and thorough review! It means a lot for us!\n\nRegarding your question. GAES extends directly to games $\\mathcal{G} \\in \\Gamma$ in which players are $n \\in \\mathbb{N}$ \u201cneural players\u201d with each player $i \\in \\mathbb{N}$ \u201cchoosing\u201d an action (i.e., network weights) from an action space (i.e., a subset of $\\mathbb{R}^d$ where $d$ is the number of parameters) which maximizes some desired payoff function $u_i^{\\mathcal{G}}$. In such settings, GAES can be seen a meta-learning method, where any game $\\mathcal{G} \\in \\Gamma$ is described as parameters of the problem.\n\nFor instance, for generative adversarial neural networks for image classification, we have two neural players consisting of a generator and a discriminator for whom the payoff functions are respectively given as the expected negated cross-entropy and expected cross-entropy over a data set of images. As such, each game is characterized by the data set of images, and GAES can be trained over *distributions* of image datasets, so as to output optimal network weights for the generator and discriminator for a given image dataset."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8725/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700117873078,
                "cdate": 1700117873078,
                "tmdate": 1700117873078,
                "mdate": 1700117873078,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]