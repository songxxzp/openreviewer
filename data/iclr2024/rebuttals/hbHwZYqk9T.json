[
    {
        "title": "FedP3: Federated Personalized and Privacy-friendly Network Pruning under Model Heterogeneity"
    },
    {
        "review": {
            "id": "pdzBR0T87N",
            "forum": "hbHwZYqk9T",
            "replyto": "hbHwZYqk9T",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission100/Reviewer_45Hg"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission100/Reviewer_45Hg"
            ],
            "content": {
                "summary": {
                    "value": "Federated learning has gained attention for its capability to train global models while maintaining local data privacy. This paper delves into the challenge of client-side model heterogeneity, exacerbated by differences in clients' memory, processing, and network capabilities (system heterogeneity). The proposed FedP3 framework can well address these challenges."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- Adaptable Design: FedP3 caters to model diversity by allowing personalization based on each client's specific capacities, including computational, memory, and communication constraints.\n- Novel Dual-Pruning Strategy: FedP3 integrates a dual-pruning approach. This encompasses both global pruning (server to client) and local pruning executed by individual clients.\n- Strong Privacy Commitment: FedP3 prioritizes user privacy. The design ensures that full client data is kept confidential as only the selected layers are transmitted from the client to the server post-local training."
                },
                "weaknesses": {
                    "value": "- Absence of Theoretical Insights: This work seems lacks a strong theoretical foundation or interpretation.\n- More Ablations: The current model does not explore all potential ablations, for instance, different data aggregation techniques."
                },
                "questions": {
                    "value": "Please refer to the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission100/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698543645749,
            "cdate": 1698543645749,
            "tmdate": 1699635935091,
            "mdate": 1699635935091,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tAhThzWaNJ",
                "forum": "hbHwZYqk9T",
                "replyto": "pdzBR0T87N",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 45Hg"
                    },
                    "comment": {
                        "value": "Thank you so much for your valuable feedback! We sincerely hope our response below can address your concerns. \n\n---\n**W1**: Absence of Theoretical Insights: This work seems lacks a strong theoretical foundation or interpretation.\n\n**A1**: We are currently working on the theoretical analysis and will provide a response before the conclusion of this author-reviewer period.\n\n---\n**W2**: More Ablations: The current model does not explore all potential ablations, for instance, different data aggregation techniques.\n\n**A2**: We acknowledge this point and have included the results and analysis of various FL aggregation strategies in Section 4.3.3 of our revised paper."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission100/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700245999895,
                "cdate": 1700245999895,
                "tmdate": 1700245999895,
                "mdate": 1700245999895,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "z5oW3eCGnG",
            "forum": "hbHwZYqk9T",
            "replyto": "hbHwZYqk9T",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission100/Reviewer_8d9P"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission100/Reviewer_8d9P"
            ],
            "content": {
                "summary": {
                    "value": "The authors present a \"privacy-preserving\" pruning mechanism that is tailored for heterogeneous clients/devices. In this approach, only a part of the model is transmitted to the server, saving resources and enhancing privacy."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is well written, presented and easy to understand. \n- Tackling device heterogeneity on federated learning is an important problem\n- Model pruning and submode research is an important step towards addressing device heterogeneity and our ability to train larger models with federated learning"
                },
                "weaknesses": {
                    "value": "The main weaknesses of this paper are:\n- The authors claim that this method is \"privacy-preserving\" and designed to maximise privacy overall. At the same time, there is no evaluation at all wrt to privacy (either analytical or through some empirical attacks). Furthermore, the privacy aspect is not discussed, practically assuming that fewer layers sent -> more privacy. While there might be some correlation there, I would expect these claims to be backed up with some thorough evaluation/analysis. \n\n- Similarly, the authors claim that resources are saved (energy, memory, cpu)  and larger models can be trained. But there is no evaluation wrt to any such savings. There are no numerical results wrt to any energy savings, the memory consumption savings, understanding how wide can the heterogeneity can we have wrt to device capabilities. Finally, It would be great to have a thorough study on the convergence speed. \n\n- Finally, given that there are a number of sub-model FL training methods proposed (the authors cite a few), it would be great if the evaluation could be expanded to compare with the state of the art."
                },
                "questions": {
                    "value": "Please see my comments above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission100/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission100/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission100/Reviewer_8d9P"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission100/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698749601078,
            "cdate": 1698749601078,
            "tmdate": 1699635935005,
            "mdate": 1699635935005,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bf6PIIwOZT",
                "forum": "hbHwZYqk9T",
                "replyto": "z5oW3eCGnG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 8d9P (Part 1)"
                    },
                    "comment": {
                        "value": "Thank you for your insightful feedback. We hope our response below can adequately address your concerns.\n\n---\n**W1**: The authors claim that this method is \"privacy-preserving\" and designed to maximise privacy overall. At the same time, there is no evaluation at all wrt to privacy (either analytical or through some empirical attacks). Furthermore, the privacy aspect is not discussed, practically assuming that fewer layers sent $\\rightarrow$ more privacy. While there might be some correlation there, I would expect these claims to be backed up with some thorough evaluation/analysis.\n \n**A1**: Our \"privacy-friendly\" method enhances privacy by not sharing the complete network architecture from the client to the server. This strategy effectively hides critical architecture details, reinforcing our privacy stance, which we support analytically. The training process is designed to extract features using only a subset of layers, rather than relying on the entire network that memorizes local data. By transmitting only a limited selection of layers in each iteration, our approach becomes more privacy-friendly.\n\nIt is important to note that the concept of gradient pruning as a means of preserving privacy was initially popularized by the foundational work of Zhu et al. in \"Deep leakage from gradients\" (NeurIPS, 2019). Subsequently, studies such as \"Privacy-preserving learning via deep net pruning\" by Huang et al. (arXiv:2003.01876, 2020) have further explored the effectiveness of DNN pruning in maintaining privacy. Our framework presents a broad scope for meaningful exploration and lays the groundwork for future research. However, the quantitative assessment of privacy in FL remains a complex and open issue. Exploring the privacy dimensions of our framework is an exciting and valuable direction for forthcoming studies.\n\n---\n**W2-1**: Similarly, the authors claim that resources are saved (energy, memory, cpu) and larger models can be trained. But there is no evaluation wrt to any such savings. There are no numerical results wrt to any energy savings, the memory consumption savings, understanding how wide can the heterogeneity can we have wrt to device capabilities.\n\n**A2-1**: We specify that clients in our study have a fixed number of layers, not equal parameters from fully-trained layers, mirroring a heterogeneous environment with diverse memory and communication capacities. For example, in CIFAR10, the first convolutional layer contains 4,864 parameters, contrasting sharply with the 1,638,400 parameters in the first fully-connected layer. As demonstrated in Appendix B.4 (Figure 6), clients training FC2+FFC layers, in comparison to those training Conv1+FFC layers, face communication costs that are over 10,815 times higher. Additionally, they encounter 24.91\\% and 57.93\\% increases in the sizes of deployed models at global pruning ratios of 0.7 and 0.5, respectively. Section 4.3.3 delves into the assignment of varying layer numbers to clients, analyzing different weighting strategies and detailing our experimental approach.\n\nOur primary experiments with CNNs (2 Conv and 4 FC layers) on CIFAR-10/100 and Fashion-MNIST demonstrate network size reduction. In OPU2, where the last FC layer and two randomly chosen layers (2Conv+2FC) are trained without global or local pruning, we find a 40\\% reduction in parameter communication compared to the full FedAvg model. OPU3, with 20\\% less parameter communication, matches FedAvg's performance. Dual pruning significantly decreases both the deployed (global pruning) and locally trained (local pruning) model sizes. Figure 4 highlights our method's efficiency for larger models in collaborative training, with a detailed quantitative analysis in Figure 6. The revised paper's Section 4.2 also presents an in-depth analysis of ResNet18. \n\n---\n**W2-2**: Finally, It would be great to have a thorough study on the convergence speed.\n\n**A2-2**: We are currently working on the theoretical analysis and will provide a response before the conclusion of this author-reviewer period."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission100/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700246487432,
                "cdate": 1700246487432,
                "tmdate": 1700246487432,
                "mdate": 1700246487432,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XcLNVM45ex",
                "forum": "hbHwZYqk9T",
                "replyto": "z5oW3eCGnG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 8d9P (Part 2)"
                    },
                    "comment": {
                        "value": "**W3**: Finally, given that there are a number of sub-model FL training methods proposed (the authors cite a few), it would be great if the evaluation could be expanded to compare with the state of the art.\n\n**A3**: Our framework is not only versatile but also well-suited for integrating existing dual-pruning methods. As an illustration, Table 2 in our paper showcases the effective incorporation of the Ordered Dropout method from FjORD (NeurIPS21) into our system. We have enriched the revised version of our paper with an extended related work section, offering a comprehensive comparison with a wide array of relevant studies, as detailed in Appendix A.\n\nFurthermore, our analysis extends beyond mere comparisons with the standard FedAvg algorithm. We have undertaken a thorough comparative study with the cutting-edge algorithm FedCR. The details of this comparison, highlighting the efficacy and advancements of our framework in relation to state-of-the-art methods, are meticulously presented in Figure 2 of Section 4.2. This set of comparisons underscores the robustness and innovation of our framework in the context of FL."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission100/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700246558377,
                "cdate": 1700246558377,
                "tmdate": 1700246558377,
                "mdate": 1700246558377,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ygaR5pSMTt",
                "forum": "hbHwZYqk9T",
                "replyto": "z5oW3eCGnG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Gentle Reminder for Response"
                    },
                    "comment": {
                        "value": "Thank you once again for your valuable comments. As the discussion stage is nearing its conclusion, we kindly request your feedback on whether our responses adequately address your concerns. We have included a new set of theoretical analyses pertaining to privacy, convergence, and communication complexity in our general response to all reviewers, titled \u201cNew Theoretical Analyses of FedP3 and LDP-FedP3\u201c. More details are also provided in the revised paper. We would greatly appreciate any further feedback you may have."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission100/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700612999582,
                "cdate": 1700612999582,
                "tmdate": 1700621764422,
                "mdate": 1700621764422,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Ko44TTxBow",
            "forum": "hbHwZYqk9T",
            "replyto": "hbHwZYqk9T",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission100/Reviewer_Kwpv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission100/Reviewer_Kwpv"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on addressing the model heterogeneity problem in federated learning. Concretely, it proposes an adaptable federated framework that leverages the personalized pruning technique in a privacy-preserving way. Experiments show that FedP3 can deal with data and model heterogeneity and adapt to various pruning strategies."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. An interesting network pruning-based pipeline is proposed. In this pipeline, the size of training parameters can be personalized for each client.\n\n2. Various local pruning and global aggregation strategies are developed, which present high flexibility of the proposed framework. \n\n3. Limitations of this paper including theoretical analysis and LLMs aspects are well discussed."
                },
                "weaknesses": {
                    "value": "1. The relation between privacy-friendly property and network pruning is implicit. It is better to provide a detailed illustration of the reason why existing pruning-based FL methods have privacy concerns. This can help readers to better understand the motivation of the privacy-preserving part. \n\n2. The authors have emphasized the possibility of utilizing the proposed method in LLMs-based scenarios but there is a lack of related experiments supporting that point. Only shallow neural networks and ResNet are considered in the experimental part.\n\n3. To show the improved communication efficiency as mentioned in the 5th paragraph of the Introduction, it is better to provide some quantitive results on the number of communicated parameters. \n\n4. The presentation of the paper should be further enhanced and some parts should be reorganized. For example, the training goal and variable notation should be given in the Preliminary or Methodology section rather than the Introduction section. \n\n5. Lack of empirical comparison with existing FL methods that also address model heterogeneity problem. \n\n6. To solve the model heterogeneity problem, some existing work needs to be discussed, e.g. Knowledge Distillation-based FL [1],  Prototype-based FL [2], and NAS-based FL.\n\n[1] Ensemble Distillation for Robust Model Fusion in Federated Learning, NeurIPS 2020\n\n[2] FedProto: Federated Prototype Learning across Heterogeneous Clients, AAAI 2022\n\n[3] FedNAS: Federated Deep Learning via Neural Architecture Search, arXiv 2020"
                },
                "questions": {
                    "value": "1. Please refer to weakness.\n\n2. How to conduct federated training of LLMs based on the proposed method?\n\n3: In the algorithm, predefined pruning mechanisms are assigned for each client. Is this a common operation in FL under model heterogeneity issues? Are there any previous works conducting similar operations?\n\n4: There are multiple pruning and averaging strategies that can be adopted in the proposed FedP3. For a specific case, how to select the most appropriate strategy? \n\n5. In practice, what if we set several types of models to tackle various heterogeneous devices? Can you set a baseline algorithm to test it?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission100/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699448727287,
            "cdate": 1699448727287,
            "tmdate": 1699635934931,
            "mdate": 1699635934931,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "IQLE7T03dd",
                "forum": "hbHwZYqk9T",
                "replyto": "Ko44TTxBow",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Kwpv (Part 1)"
                    },
                    "comment": {
                        "value": "Thanks for your valuable comments. We hope our response below can adequately address your concerns.\n\n---\n**W1**: The relation between privacy-friendly property and network pruning is implicit. It is better to provide a detailed illustration of the reason why existing pruning-based FL methods have privacy concerns. This can help readers to better understand the motivation of the privacy-preserving part.\n\n**A1**:  Firstly, it is important to note that the concept of gradient pruning as a means of preserving privacy was initially popularized by the foundational work of Zhu et al. in \"Deep leakage from gradients\" (NeurIPS, 2019). Subsequently, studies such as \"Privacy-preserving learning via deep net pruning\" by Huang et al. (arXiv:2003.01876, 2020) have further explored the effectiveness of DNN pruning in maintaining privacy.\n\nIn our setting, we ensure that our training process focuses on extracting partial features without relying on all layers to memorize local training data. This is achieved by transmitting only a limited subset of layers from the client to the server in each iteration. Under this approach, sending fewer layers\u2014effectively implementing more pruning from clients to the server\u2014enhances the privacy-friendliness of our framework.\n\n---\n**W2**: The authors have emphasized the possibility of utilizing the proposed method in LLMs-based scenarios but there is a lack of related experiments supporting that point. Only shallow neural networks and ResNet are considered in the experimental part.\n\n**A2**: We appreciate the interest in applying our framework to scenarios involving LLMs, and we plan to address this in future work. The main objective of this paper is to validate the effectiveness of our novel framework and to ascertain whether existing best practices in FL that are orthogonal to our approach can be successfully integrated.\n\n---\n**W3**: To show the improved communication efficiency as mentioned in the 5th paragraph of the Introduction, it is better to provide some quantitive results on the number of communicated parameters.\n  \n**A3**: In our approach, where we randomly select a subset of layers across all clients, we focus on the average communication cost. Our experiments on CIFAR10/100 and FashionMNIST demonstrate significant communication cost savings: 20\\% for OPU3, 40\\% for OPU2, and 60\\% for LowerB. In the case of ResNet18 experiments, the communication reduction is 6.25\\% for both -B2(part) and -B3(part), and 12.5\\% for -B2-B3(full). We have expanded Section 4.2 to include a more comprehensive analysis. Additionally, Figure 6 illustrates the distribution of communicated parameters across different layers. We observed notable heterogeneity in our model settings. For instance, the relative saving ratio between two clients can exceed 10815 times. Detailed information on this can be found in Appendix B.5.\n\n---\n**W4**: The presentation of the paper should be further enhanced and some parts should be reorganized. For example, the training goal and variable notation should be given in the Preliminary or Methodology section rather than the Introduction section.\n\n**A4**: In the Introduction, we introduced two optimization objectives: eq (1) illustrates the standard finite-sum, while eq (2) represents our optimization goal in a high-level sense. Our intention is for the comparison of these two objectives to offer intuitive insights to readers. Starting with the standard FL objective and continuing through the related work section, we aim to furnish essential background information for readers less familiar with FL. Meanwhile, our formal and detailed methodologies are comprehensively outlined in Section 3 - Approach. We've provided a revised version and we remain receptive to suggestions for improving the organization of this content based on further discussions."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission100/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700245323649,
                "cdate": 1700245323649,
                "tmdate": 1700245323649,
                "mdate": 1700245323649,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tKiM1f2od2",
                "forum": "hbHwZYqk9T",
                "replyto": "Ko44TTxBow",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Kwpv (Part 2)"
                    },
                    "comment": {
                        "value": "**W5**: Lack of empirical comparison with existing FL methods that also address model heterogeneity problem.\n\n**A5**: Firstly, it's important to clarify that our main objective is not necessarily to surpass existing methods addressing model heterogeneity. Instead, our focus is on assessing the viability of our novel framework, which integrates personalized and privacy-friendly network pruning in FL. We are encouraged by extensive experiments that validate the effectiveness of our approach; while there may be some compromise in final testing accuracy, our method notably reduces communication costs and supports flexible dual-pruning, enhancing privacy.\n\nSecondly, the concept of dual-pruning, encompassing both global and local pruning, inherently introduces model heterogeneity. Consequently, we view any pruning method as a potential solution for addressing model heterogeneity. In this respect, our framework is orthogonal to existing approaches, allowing for the safe integration of different pruning methods. The details are provided in Sec 4.3. \n\nLastly, we are also keen on exploring performance enhancements beyond the standard FedAvg. Our ablation studies include the state-of-the-art FL method FedCR (ICML23), with detailed experiments and analyses provided in Figure 2 in the revised version. These studies reveal that our framework remains efficient, achieving promising performance and significantly reducing the number of required parameters.\n\n---\n**W6**: To solve the model heterogeneity problem, some existing work needs to be discussed, e.g. Knowledge Distillation-based FL [1], Prototype-based FL [2], and NAS-based FL[3].\n\n**A6**: We are grateful to the reviewer for suggesting relevant literature. We have incorporated a comparison of these works in Appendix A, titled \"Extended Related Work.\"\n\n---\n**Q2**: How to conduct federated training of LLMs based on the proposed method?\n\n**A7**: We have not yet performed experimental verifications on federated LLMs, a field that remains in its early stages and likely warrants dedicated projects. Currently, we must clarify that the application of our method to federated training of LLMs is theoretical. A crucial initial step would involve developing a reliable FedAvg-like method specifically for LLMs. Given that our method, FedP3 as detailed in Algorithm 1, is not limited by the architecture of the global model, it offers the potential for integration into federated LLM frameworks. This integration would aim at enabling personalized and privacy-aware pruning, albeit with necessary adaptive adjustments.\n\n---\n**Q3**: In the algorithm, predefined pruning mechanisms are assigned for each client. Is this a common operation in FL under model heterogeneity issues? Are there any previous works conducting similar operations?\n\n**A8**: In addressing the question, our focus is twofold: layer-wise assignment for each client and dual-pruning. In our unique scenario, where clients train only a subset of layers, we lack direct references from existing literature. We chose a simple approach where each client trains a fixed set of layers, although our model could, in theory, permit variable layer selection. However, this adjustment may not substantially benefit our contributions. As for dual-pruning, we follow the conventional design of both global and local pruning, maintaining a consistent pruning mechanism without mixing various strategies, in line with standard practices outlined in Section 2.1.\n\n---\n**Q4**: There are multiple pruning and averaging strategies that can be adopted in the proposed FedP3. For a specific case, how to select the most appropriate strategy?\n\n**A9**: In Figure 5, our analysis demonstrates that weighted averaging consistently outperforms simple averaging, albeit marginally. Table 2 further illustrates that Order Dropout local pruning consistently falls short in Top-1 accuracy when compared to Uniform strategies. This is likely because Uniform pruning encompasses all weights, thereby providing a more comprehensive global perspective. The versatility and adaptability of our framework with different pruning and averaging techniques open up a wide array of opportunities for more targeted experimentation across various datasets and contexts. A key, consistent observation with our FedP3 method is its ability to achieve comparable performance while significantly reducing communication costs and friendly to privacy."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission100/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700245667410,
                "cdate": 1700245667410,
                "tmdate": 1700245667410,
                "mdate": 1700245667410,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pqrTdx40ti",
                "forum": "hbHwZYqk9T",
                "replyto": "Ko44TTxBow",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q5**: In practice, what if we set several types of models to tackle various heterogeneous devices? Can you set a baseline algorithm to test it?\n\n**A10**: We appreciate the reviewer's interest in training different types of local models. To the best of our knowledge, two possible approaches are knowledge distillation and building model prototypes. However, knowledge distillation operates on loss or other agency, often requiring additional shared data or constraints. Building model prototypes doesn't align with our objective, which is to train a *single* large global model.\n\nWhen different models with varying semantic meanings of weights are aggregated, as in combining ResNet18 and ResNet50, it presents numerous unresolved challenges. For example, the distinct semantics of each layer in these models render standard mean aggregation impractical. Developing suitable aggregation strategies for such diverse models is complex and could lead to many interesting research projects. While potential new strategies might be adapted to our general framework with some modifications, there is currently a lack of literature on aggregating outputs from local clients with different model types.\n\nIn the context of dual-pruning, our FedP3 framework can accommodate various local models. We also acknowledge the importance of mimicking heterogeneous device environments, including varying memory and bandwidth constraints among devices, an approach we have adopted in our research."
                    },
                    "title": {
                        "value": "Response to Reviewer Kwpv (Part 3)"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission100/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700245764399,
                "cdate": 1700245764399,
                "tmdate": 1700245785094,
                "mdate": 1700245785094,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "XK073o9trN",
            "forum": "hbHwZYqk9T",
            "replyto": "hbHwZYqk9T",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission100/Reviewer_CVkW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission100/Reviewer_CVkW"
            ],
            "content": {
                "summary": {
                    "value": "The paper focus on the problem of federated learning with model heterogeneity among clients and designs an algorithm that (1) allows each client only to perform training on a small subnetwork and (2) incorporates model pruning between server and clients to meet the different memory and communication constraints of individual clients. For subnetwork selection, the paper allows each client to train a randomly selected subset of layers of the global model. For model pruning, the paper explores two approaches: uniform pruning and uniform-ordered dropout. Finally, for aggregation of clients' updates, the paper explores simple averaging, weighted averaging (with the weight proportional to the number of layers each client trains), and attention averaging."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The problem of designing FL algorithms under model heterogeneity is well-motivated from practice. \n- The paper introduces the new ingredient of subnetwork pruning between the server and the clients and investigates the effect of pruning strategies and pruning ratio on the performance of FL.\n- The authors performed necessary ablation studies for the proposed algorithm, such as different subnetwork selections, data heterogeneity levels, sizes of total networks, and aggregation methods."
                },
                "weaknesses": {
                    "value": "- There is a discrepancy between the experiment setting and the motivation problem setting in the introduction. \n  - The experiment setting does not reflect the heterogeneity of memory and communication constraints between clients, even though this is a major motivation mentioned in the introduction. Specifically, in all experiments, different clients train subnetworks roughly the same size. \n  - The subnetwork is not significantly smaller than the global model. For the ResNet-18 experiments, the subnetwork of each client appears to be at least around half the scale of the global model. This differs from the interesting scenario mentioned in the introduction, where each subnetwork is significantly smaller than the global model.\n- Lack of baselines for interpreting the significance of the proposed algorithm. One baseline that is not mentioned is an approach that performs model pruning on the global model first and then performs standard FL on the pruned smaller model. This is for understanding the necessity of personalized model pruning among clients.\n- Algorithm descriptions sometimes need more clarity; see question 3 for more details."
                },
                "questions": {
                    "value": "1. Could the authors comment on whether the algorithm would perform well if the subnetworks trained by individual clients are significantly smaller than the global model? Table 2 shows that the algorithm performs poorly when each client only trains one layer.\n2. Could the authors comment on an alternative approach of global model pruning + standard FL on the pruned model?\n3. Several parts of the algorithm could be clarified more.\n   - Figure 1 shows that each client still needs to store a large proportion of the unpruned global model. Is that correct?\n   - In Algorithm 1, the pruned weights $P_i(W_t^l)$ are not used anywhere later.\n   - In eq (2), the objective function $h$ does not appear to be defined for the problem considered in this paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission100/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699635934855,
            "cdate": 1699635934855,
            "tmdate": 1699637371324,
            "mdate": 1699637371324,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lyEJdlaIpX",
                "forum": "hbHwZYqk9T",
                "replyto": "XK073o9trN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer CVkW (Part 1)"
                    },
                    "comment": {
                        "value": "Thank you for taking the time to review our paper and for your thoughtful comments. Following your suggestions, we have added new results and analysis to the revised version of the paper. We hope that this updated version adequately addresses your concerns.\n\n---\n**W1**: There is a discrepancy between the experiment setting and the motivation problem setting in the introduction. **a)** The experiment setting does not reflect the heterogeneity of memory and communication constraints between clients, even though this is a major motivation mentioned in the introduction. Specifically, in all experiments, different clients train subnetworks roughly the same size. **b)** The subnetwork is not significantly smaller than the global model. For the ResNet-18 experiments, the subnetwork of each client appears to be at least around half the scale of the global model. This differs from the interesting scenario mentioned in the introduction, where each subnetwork is significantly smaller than the global model.\n\n**A1** Thanks for the insightful questions.\n\n**a**: We specify that clients in our study have a fixed number of layers, not equal parameters from fully-trained layers, mirroring a heterogeneous environment with diverse memory and communication capacities. For example, in CIFAR10, the first convolutional layer contains 4,864 parameters, contrasting sharply with the 1,638,400 parameters in the first fully-connected layer. As demonstrated in Appendix B.4 (Figure 6), clients training FC2+FFC layers, in comparison to those training Conv1+FFC layers, face communication costs that are over 10,815 times higher. Additionally, they encounter 24.91\\% and 57.93\\% increases in the sizes of deployed models at global pruning ratios of 0.7 and 0.5, respectively.\n\n**b**: Our primary experiments with CNNs (2 Conv and 4 FC layers) on CIFAR-10/100 and Fashion-MNIST demonstrate network size reduction. In OPU2, where the last FC layer and two randomly chosen layers (2Conv+2FC) are trained without global or local pruning, we have a 40\\% reduction in parameter communication compared to the full FedAvg model.\nOPU3, with 20\\% less parameter communication, matches FedAvg's performance. Dual pruning significantly decreases both the deployed (global pruning) and locally trained (local pruning) model sizes. Figure 4 highlights our method's efficiency for larger models in collaborative training, with a detailed quantitative analysis in Figure 6. The revised paper's Section 4.2 presents an in-depth analysis of ResNet18. \n\n---\n**W2**: Lack of baselines for interpreting the significance of the proposed algorithm. One baseline that is not mentioned is an approach that performs model pruning on the global model first and then performs standard FL on the pruned smaller model. This is for understanding the necessity of personalized model pruning among clients. **Q2**: Could the authors comment on an alternative approach of global model pruning + standard FL on the pruned model?\n\n**A2**: We actually denote this baseline as to the \"Full\" method depicted in Table 1 and the \"Fixed\" method in Table 2. We have updated their captions to clarify this. By default, we set the global pruning ratio to 0.9, which entails transferring approximately 10\\% fewer parameters from the server to the client. Both \"Full\" and \"Fixed\" represent the implementation of standard FedAvg during local training and subsequent model aggregation. Further details are available in Sections 4.3.1 and 4.3.2 of our revised paper."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission100/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700230999076,
                "cdate": 1700230999076,
                "tmdate": 1700230999076,
                "mdate": 1700230999076,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UuVXFoAqAn",
                "forum": "hbHwZYqk9T",
                "replyto": "XK073o9trN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer CVkW (Part 2)"
                    },
                    "comment": {
                        "value": "**W3**: Algorithm descriptions sometimes need more clarity; see question 3 for more details. **Q3**: Several parts of the algorithm could be clarified more. **a)** Figure 1 shows that each client still needs to store a large proportion of the unpruned global model. Is that correct? **b)** In Algorithm 1, the pruned weights are not used anywhere later. **c)** In eq (2), the objective function does not appear to be defined for the problem considered in this paper.\n\n**A3**: Thanks for your valuable questions. Our response is as follows:\n\n**a**: We would like to clarify that this assertion is not correct. Our focus is on retaining mainly the *pruned* global model layers and training a smaller portion of the *unpruned* fully-trained layers. We substantiate this with quantitative analysis in the right panel of Figure 4 and throughout Figure 6.\n\n**b**: Correct. Our primary aim is to showcase the feasibility of training large models with reduced communication costs in a privacy-friendly manner. Consequently, our method does not utilize pruned weights for each client.\n\n**c**: Equation (2) outlines our process in a general form. We have not specified the function $h$ here, as it can refer to various aggregation strategies. More details are provided in Algorithm 3 and Section 4.3.3.\n\n---\n**Q1**: Could the authors comment on whether the algorithm would perform well if the subnetworks trained by individual clients are significantly smaller than the global model? Table 2 shows that the algorithm performs poorly when each client only trains one layer.\n\n**A4**: We acknowledge some potential misunderstandings. average communication cost reduction of 20\\% for OPU3, 40\\% for OPU2, and 60\\% for LowerB. We provide a detailed analysis in our revised paper. We treat LowerB as the lower bound benchmark for providing analytical insights. OPU3, notably, delivers performance on par with FedAvg, yet requires only 80\\% of the parameter communication. Specifically, LowerB exhibits an average 8.53\\% drop in performance but benefits from 60\\% lower communication costs. The size of the locally deployed and trained model parameters is quantitatively analyzed in the right part of Figure 4 and throughout Figure 6. These figures demonstrate that our method achieves significantly smaller deployed model sizes, effectively balancing accuracy trade-offs, particularly when the global model is large."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission100/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700231138741,
                "cdate": 1700231138741,
                "tmdate": 1700231138741,
                "mdate": 1700231138741,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VNTxuDj582",
                "forum": "hbHwZYqk9T",
                "replyto": "XK073o9trN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission100/Reviewer_CVkW"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission100/Reviewer_CVkW"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the authors' response. My main concerns are addressed.\n\nHowever, the communication cost gain is still not perfectly clear to me. As other reviewers pointed out, the convergence speed needs to be clarified. Although the clients only train a smaller part of the model, the total communication cost may still be considerable if convergence is slower under the pruning than without pruning. I will keep my score as is for now and will update it based on the authors' upcoming discussion on this issue."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission100/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700556866453,
                "cdate": 1700556866453,
                "tmdate": 1700557028175,
                "mdate": 1700557028175,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1HL1LmHBLH",
            "forum": "hbHwZYqk9T",
            "replyto": "hbHwZYqk9T",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission100/Reviewer_mPei"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission100/Reviewer_mPei"
            ],
            "content": {
                "summary": {
                    "value": "The appeal of Federated learning lies in its privacy-aware model training using data held locally on clients. However, the issue of varied client capacities, termed system heterogeneity, complicates its implementation. This paper proposes the FedP3 framework, emphasizing federated, personalized, and privacy-friendly network pruning, to cater to such diverse client scenarios."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1.\tThe proposed system comprehensively considers a holistic management of heterogeneity, i.e., it effectively manages both data and model disparities. It supports data distribution among clients, class-wise or Dirichlet non-iid. Moreover, it accommodates variance in the models between the server-client and among individual clients.\n2.\tThe proposed methods are inspiring for real-world scenarios, including dual pruning that supports both global pruning (from server to client) and local pruning by individual clients; few-layer communication from the clients to the server after local training. \n3.\tExperiments validate that the proposed FedP3 is both effective and adaptable. It paves the way for personalized and privacy-conscious pruning in a heterogeneous federated setting."
                },
                "weaknesses": {
                    "value": "1.\tFew-layer communication can also significantly reduce communication costs and save bandwidth, a detailed numerical analysis would help.\n2.\tThe results on various FL aggregation strategies shall be considered for completeness.\n3.\tHyperparameter tuning part is not so crystal. More explanation is needed on how to choose and tune the hyperparameter (maybe via grid-search?) to deliver the best possible results for each model.\n4.\tBroader Literature Review is expected. While this work focuses primarily on the discussion and analysis of the most relevant and typical works, this approach might overlook other pertinent past research that holds tangential relevance to their study."
                },
                "questions": {
                    "value": "1. How much the few-layer communication can save communication costs and bandwidth?\n2. How the other FL aggregation strategies work in combination with FedP3?\n3. How to choose and tune the hyperparameter?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission100/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission100/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission100/Reviewer_mPei"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission100/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699666009073,
            "cdate": 1699666009073,
            "tmdate": 1699666009073,
            "mdate": 1699666009073,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9OZDpA3Pqe",
                "forum": "hbHwZYqk9T",
                "replyto": "1HL1LmHBLH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer mPei"
                    },
                    "comment": {
                        "value": "Thank you so much for the positive feedback and valuable comments. We hope the following new analysis and clarifications can address your concerns. \n\n---\n**W1**: Few-layer communication can also significantly reduce communication costs and save bandwidth, a detailed numerical analysis would help. **Q1**: How much the few-layer communication can save communication costs and bandwidth?\n\n**A1**: In the paragraph \"Layer Overlapping Analysis\" of Section 4.2 of our revised paper, we assess the impact of few-layer communication on reducing costs. Our findings indicate significant savings: 20\\% for OPU3, 40\\% for OPU2, and 60\\% for LowerB on average. Particularly, OPU3 achieves comparable results to FedAvg with only 80\\% of the parameters communicated. This method is also applicable to ResNet18 and EMNIST-L datasets. As detailed in Appendix B.4 (Figure 6), clients training FC2+FFC layers, in comparison to those training Conv1+FFC layers, face communication costs that are over 10,815 times higher. Additionally, they encounter 24.91\\% and 57.93\\% increases in the sizes of deployed models at global pruning ratios of 0.7 and 0.5, respectively.\n\n---\n**W2**:The results on various FL aggregation strategies shall be considered for completeness. **Q2**: How the other FL aggregation strategies work in combination with FedP3?\n\n**A2**: Acknowledging this, we've added a detailed examination of various FL aggregation strategies in Section 4.3.3 of our revised paper. We show a slight improvement using weighted averaging based on the relative number of layers on each client.\n\n---\n**W3**: Hyperparameter tuning part is not so crystal. More explanation is needed on how to choose and tune the hyperparameter (maybe via grid-search?) to deliver the best possible results for each model. **Q3**: How to choose and tune the hyperparameter?\n\n**A3**: We optimized key hyper-parameters, including the local training learning rate and the personalized factor of FedCR, through grid search, while maintaining other parameters at default settings for fair comparison. Comprehensive details of the training procedure can be found in Appendix B.3.\n\n---\n**W4**: Broader Literature Review is expected. While this work focuses primarily on the discussion and analysis of the most relevant and typical works, this approach might overlook other pertinent past research that holds tangential relevance to their study.\n\n**A4**: In the Related Work section of our paper, we initially compared our study to the most pertinent existing research within our knowledge. Responding to feedback, we have expanded this section to encompass and contrast additional studies, particularly those highlighted by reviewers, along with other relevant papers. Further details are provided in Appendix A."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission100/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700229602711,
                "cdate": 1700229602711,
                "tmdate": 1700229602711,
                "mdate": 1700229602711,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ykL2P9lgVL",
            "forum": "hbHwZYqk9T",
            "replyto": "hbHwZYqk9T",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission100/Reviewer_2HRe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission100/Reviewer_2HRe"
            ],
            "content": {
                "summary": {
                    "value": "This paper highlights the growing interest in federated learning (FL) for its privacy-preserving capabilities. It particularly addresses the challenge of client-side model heterogeneity in FL, driven by variations in client resources. Termed \"system heterogeneity,\" this scenario necessitates customizing a unique model for each client. The paper introduces FedP3, a Federated Personalized and Privacy-friendly Network Pruning Framework, designed to address model heterogeneity effectively. FedP3 can adapt established techniques to specific instances, offering a practical solution."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "==*== Strengths\n+ This work offers an effective and adaptable FL framework FedP3 tailored for model heterogeneity scenarios.\n+ The proposed personalized network pruning technique is applicable to diverse scenarios."
                },
                "weaknesses": {
                    "value": "==*== Weaknesses\n- The outcomes of the experiment need to be made more convincing. \n- Limited in-depth comparison with state-of-the-art solutions.\n- Privacy analysis and convergence analysis need to be included.\n- Empirical verification of the claimed contributions is necessary."
                },
                "questions": {
                    "value": "Comments:\n\n-\tPrivacy analysis and convergence analysis need to be included. Indeed, separating model parameters from the network parameter architecture is intuitively beneficial to FL privacy protection, but whether existing gradient reconstruction attacks or other privacy attacks will challenge this personalization technology has not been fully explored. Therefore, it would be better if the authors could analyze the privacy performance empirically or theoretically.\n\n-\tFurthermore, the convergence analysis of the proposed method has not given any explanation. For model heterogeneous scenarios, reviewers expect to see rigorous analysis and discussion of the convergence and stability of this method.\n\n-\tThis paper claims that the proposed personalized pruning technique can well alleviate the system heterogeneity and model heterogeneity problems, but the reviewer has not seen any discussion and numerical results on the system heterogeneity scenario.\n\n-\tLimited in-depth comparison with state-of-the-art solutions. In fact, personalized pruning technique is not the first time to be applied to FL to solve efficiency and heterogeneity problems. The following literature needs to be included in the baseline solutions and explain the differences and connections between this paper and them.\n\n[1] Zhou X, Jia Q, Xie R. NestFL: efficient federated learning through progressive model pruning in heterogeneous edge computing[C]//Proceedings of the 28th Annual International Conference on Mobile Computing And Networking. 2022: 817-819.\n\n[2] Li A, Sun J, Li P, et al. Hermes: an efficient federated learning framework for heterogeneous mobile clients[C]//Proceedings of the 27th Annual International Conference on Mobile Computing and Networking. 2021: 420-437.\n\n[3] Pase F, Isik B, Gunduz D, et al. Efficient federated random subnetwork training[C]//Workshop on Federated Learning: Recent Advances and New Challenges (in Conjunction with NeurIPS 2022). 2022."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission100/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission100/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission100/Reviewer_2HRe"
                    ]
                }
            },
            "number": 6,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission100/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699776804952,
            "cdate": 1699776804952,
            "tmdate": 1700630215244,
            "mdate": 1700630215244,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VcHfTkI2dm",
                "forum": "hbHwZYqk9T",
                "replyto": "ykL2P9lgVL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 2HRe (Part 1)"
                    },
                    "comment": {
                        "value": "We thank you for the valuable review and for sharing relevant references. We hope that our following discussion will address your raised weaknesses and comments.\n\n---\n**W1**: The outcomes of the experiment need to be made more convincing.\n\n**A1**: In response, we have implemented several modifications to enhance the clarity and illustrative quality of our experiments. Details are attached in the general response to all reviewers. Please also find our revised paper with more evidence. \n\nWe trust that these enhancements will make our experiments and analyses more transparent and insightful. We are readily available to address any specific queries regarding the experimental components.\n\n---\n**W2**: Limited in-depth comparison with state-of-the-art solutions.\n\n**A2**: We wish to clarify that the primary objective of our paper is not to surpass existing FL algorithms on popular datasets. Instead, our focus is on introducing a general pruning framework that not only allows for personalization but also operates within a privacy-friendly setting. This claim is substantiated by comprehensive experiments conducted throughout the paper.\n\nGiven the general nature of our framework, we are also interested in investigating its applicability to cutting-edge personalized FL methodologies. To this end, we have conducted a comparative analysis with the state-of-the-art FedCR (ICML23). The details of our experimental setup, results, and analysis are thoroughly documented in the right part of Figure 2. Our findings are encouraging, indicating that even when applied to FedCR, our framework maintains comparable performance while significantly reducing the volume of parameters communicated.\n\n---\n**W3-1**: Privacy analysis ... need to be included. **Q1**: Privacy analysis needs to be included ... whether existing gradient reconstruction attacks or other privacy attacks will challenge this personalization technology has not been fully explored. Therefore, it would be better if the authors could analyze the privacy performance empirically or theoretically.\n\n**A3**: Our \"privacy-friendly\" method enhances privacy by not sharing the complete network architecture from the client to the server. This strategy effectively hides critical architecture details, reinforcing our privacy stance, which we support analytically. The training process is designed to extract features using only a subset of layers, rather than relying on the entire network that memorizes local data. By transmitting only a limited selection of layers in each iteration, our approach becomes more privacy-friendly.\n \nIt is important to note that the concept of gradient pruning as a means of preserving privacy was initially popularized by the foundational work of Zhu et al. in \"Deep leakage from gradients\" (NeurIPS, 2019). Subsequently, studies such as \"Privacy-preserving learning via deep net pruning\" by Huang et al. (arXiv:2003.01876, 2020) have further explored the effectiveness of DNN pruning in maintaining privacy. \n\nOur framework presents a broad scope for meaningful exploration and lays the groundwork for future research. However, the quantitative assessment of privacy in FL remains a complex and open issue. Exploring the privacy dimensions of our framework is an exciting and valuable direction for forthcoming studies.\n\n---\n**W3-2**: ... convergence analysis need to be included. **Q2**: Furthermore, the convergence analysis of the proposed method has not given any explanation. For model heterogeneous scenarios, reviewers expect to see rigorous analysis and discussion of the convergence and stability of this method.\n\n**A4**: We are currently working on the theoretical analysis and will provide a response before the conclusion of this author-reviewer period."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission100/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700247065024,
                "cdate": 1700247065024,
                "tmdate": 1700247065024,
                "mdate": 1700247065024,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pEJjnb31OV",
                "forum": "hbHwZYqk9T",
                "replyto": "ykL2P9lgVL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 2HRe (Part 2)"
                    },
                    "comment": {
                        "value": "**W4**: Empirical verification of the claimed contributions is necessary.\n\n**A4**: We would like to emphasize all our claimed contributions are clearly stated with enough evidence. Here is the response for all our contributions:\n\n- **Contribution 1: general framework.** \"A versatile design that caters to model heterogeneity, enabling tailored personalization based on clients\u2019 local capacities (computational, memory and communication constraints).\"\n    - Our general framework, FedP3, detailed in Algorithm 1, uses $L_i$, $P_i$, and $Q_i$ as personalization factors for client $i$, aligning with each client's computational capacity and bandwidth. This framework is central to this paper and the feasibility has been verified through all our experiments.\n    \n- **Contribution 2: dual-pruning approach.** \"A dual-pruning approach that supports both global pruning (from server to client) and local pruning by individual clients.\"\n    - We provide empirical evidence of this methodology throughout Sections 4.3.1 and 4.3.2.\n    \n- **Contribution 3: Privacy-friendly design.** \" A commitment to privacy, ensuring that complete client information is never disclosed to the server as only a few layers are communicated from the clients to the server after local training.\"\n    - Our approach ensures privacy-friendliness by not sending the full network architecture from client to server. The quantitative efficiency of this method is demonstrated throughout our experimental section.\n  \n- **Contribution 4: handling data and model heterogeneity.** \"Comprehensive handling of both data and model heterogeneity. We allow data distributed among clients to be class-wise or Dirichlet non-iid. Meanwhile, we allow the server-client models and client-wise models to be different.\n      - Our experiments, detailed in Section 4, focus on non-iid data, including class-wise or Dirichlet cases. After dual-pruning, the local models naturally exhibit heterogeneity, a key focus in our paper. \n\nWe also revised the contribution part in the introduction for better clarity. \n\n\n---\n**Q3**: This paper claims that the proposed personalized pruning technique can well alleviate the system heterogeneity and model heterogeneity problems, but the reviewer has not seen any discussion and numerical results on the system heterogeneity scenario.\n\n**A5**: There seems to be a misunderstanding regarding systems heterogeneity, which, as defined in reference [a] below, pertains to the varying storage, computational, and communication capabilities of each device. Our paper directly addresses this issue throughout. The number of personalized layers $L_i$, alongside the global pruning mechanism $P_i$ and the local pruning mechanism $Q_i$ presented in Algorithm 1, are specifically designed to cater to system heterogeneity. Intuitively, different clients may need to train a vastly different number of parameters. \n\nFor example, in CIFAR10, the first convolutional layer contains 4,864 parameters, contrasting sharply with the 1,638,400 parameters in the first fully-connected layer. As demonstrated in Appendix B.4 (Figure 6), clients training FC2+FFC layers, in comparison to those training Conv1+FFC layers, face communication costs that are over 10,815 times higher. Additionally, they encounter 24.91\\% and 57.93\\% increases in the sizes of deployed models at global pruning ratios of 0.7 and 0.5, respectively. Section 4.3.3 delves into the assignment of varying layer numbers to clients, analyzing different weighting strategies and detailing our experimental approach.\n\nOur primary experiments with CNNs (2 Conv and 4 FC layers) on CIFAR-10/100 and Fashion-MNIST demonstrate network size reduction. In OPU2, where the last FC layer and two randomly chosen layers (2Conv+2FC) are trained without global or local pruning, we find a 40\\% reduction in parameter communication compared to the full FedAvg model. OPU3, with 20\\% less parameter communication, matches FedAvg's performance. Dual pruning significantly decreases both the deployed (global pruning) and locally trained (local pruning) model sizes. Figure 4 highlights our method's efficiency for larger models in collaborative training, with a detailed quantitative analysis in Figure 6. The revised paper's Section 4.2 also presents an in-depth analysis of ResNet18. \n\n[a] Li, Tian, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. \"Federated learning: Challenges, methods, and future directions.\" IEEE signal processing magazine 37, no. 3 (2020): 50-60."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission100/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700247618428,
                "cdate": 1700247618428,
                "tmdate": 1700247618428,
                "mdate": 1700247618428,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JYhCGiRX3k",
                "forum": "hbHwZYqk9T",
                "replyto": "ykL2P9lgVL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission100/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 2HRe (Part 3)"
                    },
                    "comment": {
                        "value": "**Q4**: Limited in-depth comparison with state-of-the-art solutions. In fact, personalized pruning technique is not the first time to be applied to FL to solve efficiency and heterogeneity problems. The following literature needs to be included in the baseline solutions and explain the differences and connections between this paper and them.\n\n**A4**: Firstly, it's important to clarify that our main objective is not necessarily to surpass existing methods addressing model heterogeneity. Instead, our focus is on assessing the viability of our novel framework, which integrates personalized and privacy-friendly network pruning in FL. We are encouraged by extensive experiments that validate the effectiveness of our approach; while there may be some compromise in final testing accuracy, our method notably reduces communication costs and supports flexible dual-pruning, enhancing privacy.\n\nSecondly, the concept of dual-pruning, encompassing both global and local pruning, inherently introduces model heterogeneity. Consequently, we view any pruning method as a potential solution for addressing model heterogeneity. In this respect, our framework is orthogonal to existing approaches, allowing for the safe integration of different pruning methods. The details are provided in Sec 4.3. \n\nLastly, we are also keen on exploring performance enhancements beyond the standard FedAvg. Our ablation studies include the state-of-the-art FL method FedCR (ICML23), with detailed experiments and analyses provided in Figure 2 in the revised version. These studies reveal that our framework remains efficient, achieving commendable performance while significantly reducing the number of required parameters."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission100/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700247705310,
                "cdate": 1700247705310,
                "tmdate": 1700247705310,
                "mdate": 1700247705310,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NFI6p1f0aI",
                "forum": "hbHwZYqk9T",
                "replyto": "JYhCGiRX3k",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission100/Reviewer_2HRe"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission100/Reviewer_2HRe"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "Thanks to the authors for their detailed responses. The authors have addressed most of my concerns. However, the following issues still require further clarification:\n\n- I look forward to seeing the authors provide more formal privacy analysis before the end of the rebuttal.\n- The authors may have some misunderstandings about system heterogeneity. As far as I understand, the authors at least need to verify the proposed algorithm under different devices, different network states, and different communication environments.\n\nSince the authors have addressed most of my concerns, I will increase my score appropriately."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission100/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700414080176,
                "cdate": 1700414080176,
                "tmdate": 1700414080176,
                "mdate": 1700414080176,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1m9JWuSe3P",
                "forum": "hbHwZYqk9T",
                "replyto": "ykL2P9lgVL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission100/Reviewer_2HRe"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission100/Reviewer_2HRe"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "Thanks to the authors for their responses. It's nice to see the authors provide details of the analysis in response to my concerns, and I will revise my score appropriately."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission100/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700630124047,
                "cdate": 1700630124047,
                "tmdate": 1700630193352,
                "mdate": 1700630193352,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]