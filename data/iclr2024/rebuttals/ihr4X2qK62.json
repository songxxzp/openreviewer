[
    {
        "title": "Choosing Public Datasets for Private Machine Learning via Gradient Subspace Distance"
    },
    {
        "review": {
            "id": "MRngXU3V4z",
            "forum": "ihr4X2qK62",
            "replyto": "ihr4X2qK62",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission428/Reviewer_VtTm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission428/Reviewer_VtTm"
            ],
            "content": {
                "summary": {
                    "value": "Considering training a network privately via differential privacy, this work adopts a two-phase pre-training followed by a low-dimensional adaptation as the training pipeline to achieve better performance. Specially, both the second phase pre-training and low-dimensional adaptation are executed suing a public dataset selected from plenty of candidates via the proposed gradient subspace distance measure. The authors have conducted experiments on various architectures and datasets demonstrate the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "i) A high-quality basis would be crucial for the performance of low-dimensionally projected DP-SGD. This work manages to achieve this goal by identifying the most suitable public dataset from a group of candidate for computing the basis.\n\nii) The paper provides analysis to justify why choosing a basis with a smaller gradient subspace distance is beneficial in the context of low-dimensionally projected optimization."
                },
                "weaknesses": {
                    "value": "i) Computing the basis using private dataset compromises privacy, as the basis is directly depending on the private data. Although the authors argue that this can be considered as tuning hyperparameters, such an argument is unconvincing. In particular, this work does not conserve privacy for basic hyperparameter-tuning such as learning rate. Compared to related works or baselines, the proposed method definitely loses more privacy .\n\nii) The authors claim to focus on smaller public datasets due to computational resource limitations. For instance, instead of pre-training a network in CIFAR100, a batch of CIFAR100 data is selected for the projected DP-SGD. However, this argument seems weak. In my experience, projected DP-SGD is resource -intensive due to the basis calculation and gradient matrix storage. I suspect that conducting PEFT on the entire CIFAR100 dataset followed by vanilla PEFT DP-SGD could be faster and yield better results. This raises questions about the motivation and necessity of devising such a multi-stage training pipeline. The authors could conduct some additional experiments and provide details on running time, memory usage and configurations to justify the merits of their framework.\n\niii) The best utility gains reported in the experiments are primarily achieved when the private dataset is used as the public dataset. This result is trivial and does not demonstrate the necessity of employing GSD. Additionally, only a limited number of candidates are reported in each experiment, making it is unclear whether the GSD order is aligned well with the actual utility gain.\n\niv) Most of the utility gains are marginal. I also note the reported results are poor given that the networks are pre-trained. Specifically, the best results of CIFAR10 and FMNIST are worse than or only comparable to some basic baselines, e.g. [1].  Although the original paper of this baseline does not report the results of $\\epsilon=2$, the authors can run its code to verify this.\n\n[1] Tramer & Boneh, DIFFERENTIALLY PRIVATE LEARNING NEEDS BETTER FEATURES (OR MUCH MORE DATA), 2021."
                },
                "questions": {
                    "value": "In addition to my questions in the weaknesses section, I have the following questions:\n\ni) Is it consistently the case that CIFAR100 is a better public dataset for CIFAR10 than CIFAR10 itself, regardless of variations in batch size and the data points selected for basis calculation?\n\nii) Based on the experimental results, it seems that visually similar datasets usually make the best choices. Could Frechlet inception distance, which is widely used in generative models, serve as a replacement for GSD?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission428/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission428/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission428/Reviewer_VtTm"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission428/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698147890971,
            "cdate": 1698147890971,
            "tmdate": 1699635969557,
            "mdate": 1699635969557,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fypqNtUm3G",
                "forum": "ihr4X2qK62",
                "replyto": "MRngXU3V4z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your constructive feedback"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the constructive feedback. We are encouraged that the reviewer also agrees on the importance of such a scientific question: identifying a high-quality basis for private machine learning, and also agrees that our work manages to give a useful solution. Here, we explain in detail how we address your comments."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700085686586,
                "cdate": 1700085686586,
                "tmdate": 1700085686586,
                "mdate": 1700085686586,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8wf6kIPoYK",
                "forum": "ihr4X2qK62",
                "replyto": "MRngXU3V4z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Address weakness i"
                    },
                    "comment": {
                        "value": "We agree that, _in theory,_ the computation of GSD does cause privacy leakage.  However, our empirical evaluation using membership inference attacks reveals that an overestimated adversary has a success rate similar to _random guessing_ in practice. Based on realistic assumptions, the additional information an adversary can obtain from GSD is limited to \"CIFAR-100 is the chosen public dataset for CIFAR-10.\" This information is difficult to construct a meaningful attack. Therefore, we further assume a powerful yet unrealistic adversary: we assume that the adversary knows: 1) the model used by GSD and all the related computations such as gradients, hidden layer activation, 2)  90% of the private data examples used by GSD, and all the rest private examples in the private dataset. The adversary tries to use membership inference attacks to tell if a particular image $x_i$ is used by GSD (i.e., see if $x_i$ is in the rest 10%). We apply one of the most well-studied and well-cited white-box membership inference attacks and the experiments show that: even under this overly estimated and powerful adversary, the attack success rate is as good as random guesses (see Appendix D.1 for more details).\n\nAdditionally, we nevertheless discuss DP methods for GSD computation in Appendix C. We hope that this work will serve as a starting point and inspire future research to effectively solve this scientific question with differential privacy."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700085786018,
                "cdate": 1700085786018,
                "tmdate": 1700085993493,
                "mdate": 1700085993493,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QuIOZ3hCrj",
                "forum": "ihr4X2qK62",
                "replyto": "MRngXU3V4z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Address weakness ii"
                    },
                    "comment": {
                        "value": "The reviewer has raised concerns about the claims we made in the paper regarding computational resource limitations. We address these concerns with the following points:\n\n* Indeed we focus on the scenario where practitioners only have a small amount of public datasets. Due to 1) this is consistent with previous literature setting [1][2] 2) this setting is applicable in certain key settings. For example, consider a clinical environment. Due to privacy and safety concerns, it may be inappropriate to use large, uncurated Internet datasets as public data (e.g., such a dataset may be infected by a data poisoning attack). Instead, the practitioner may have a small set of trusted public datasets. In our experiments, we set the number of public data examples to 2000 or 300, depending on the size of the private dataset. \n* Under this smaller public datasets setting, projected DP-SGD is not resource-intensive. It is indeed less time-efficient than \u201cpublic pre-training, DP fine-tuning\u201d, but all the experiments in this paper can be done on a single NVIDIA A100 GPU with 40GB VRAM. More importantly, as indicated in previous studies on public-data-assisted private ML, projected DP-SGD does improve accuracy. This is why this work is based on them and efficiently addresses the problem of selecting the best public dataset.\n* When discussing computation resource limitations, we refer to large-scale pre-training on datasets like ImageNet, JFT-300, or even foundation models. These computational resource requirements are not on the same scale as the projected DP-SGD. Most practitioners can neither afford the computation resources for such pre-training, nor afford the time, effort and money to collect and create such a dataset. That\u2019s why most practitioners will turn to off-the-shelf pre-trained models, and this advocates the necessity of devising such a \u201cmulti-stage training pipeline\u201d. In addition, irrelevant pre-training datasets do not improve accuracy [3][4], highlighting the need for GSD to identify the best public datasets .\n* Additionally, if the reviewer agrees with the setting together with the reasoning we give, \u201cPEFT on the entire CIFAR100 dataset followed by vanilla PEFT DP-SGD\u201d would be inappropriate because we cannot assume that we have enough public examples available. \n* To make this more clear, the \u201cmulti-stage training pipeline\u201d is designed as an alternative to \u201cPEFT, vanilla PEFT DP-SGD\u201d, based on the reasoning we give aforementioned. Projected DP-SGD is one of the pre-conditioning methods. We also evaluated other pre-conditioning methods other than projected DP-SGD (see Appendix D.3) and GSD also works. That said, GSD works for all kinds of public-data-assist private ML methods, based on our experiments.\n\n[1] Da Yu, Huishuai Zhang, Wei Chen, and Tie-Yan Liu. Do not let privacy overbill utility: Gradient embedding perturbation for private learning. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021. URL https://openreview.net/forum?id=7aogOj_VYO0.\n\n[2] Yingxue Zhou, Steven Wu, and Arindam Banerjee. Bypassing the ambient dimension: Private sgd with gradient subspace identification. In International Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=7dpmlkBuJFC.\n\n[3] Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., Krueger, G., & Sutskever, I. (2021). Learning transferable visual models from natural language supervision. In arXiv [cs.CV]. http://arxiv.org/abs/2103.00020\n\n[4] Da Yu, Sivakanth Gopi, Janardhan Kulkarni, Zinan Lin, Saurabh Naik, Tomasz Lukasz Religa, Jian Yin, and Huishuai Zhang. Selective pre-training for private fine-tuning, 2023."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700085925319,
                "cdate": 1700085925319,
                "tmdate": 1700085983164,
                "mdate": 1700085983164,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ijZnxansug",
                "forum": "ihr4X2qK62",
                "replyto": "MRngXU3V4z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission428/Reviewer_VtTm"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission428/Reviewer_VtTm"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Reviewer"
                    },
                    "comment": {
                        "value": "Thank the authors for answering my questions and providing further information.\n\n> Response to weakness i\n\nThis response doesn't alleviate my concern. Many (membership inference attacks) MIAs have been evaluated under scenarios of limited data and/or overfitted networks. Their performance on realistically trained networks is not perfect. Theoretically, this work proposes a method that releases more privacy. I'm not convinced that the failure of MIAs to prove non-hazardous privacy leakage is sufficient, since MIAs are not robust themselves. Additionally, the choice of a public dataset can sometimes directly release key information, such as when selecting a \"tumor dataset\" to assist in the private training. \n\n> Response to weakness ii\n\nThe author should clarify that this work focuses on the cases where large scale public datasets are not available, and remove the previous claim that the focus is on smaller public datasets due to computational resource limitations.\n\n> Response to weakness iii\n\nIt is interesting to note that CIFAR100 is more effective than CIFAR10 for computing the gradient subspace of CIFAR10, but there is only a single example. In contrast, in the most settings, the private datasets are their own best public counterparts. Nevertheless, I agree that a metric predicting the utility gain of incorporating a public dataset is useful. But I believe the current experiments are very limited and do not adequately evaluate the robustness of the proposed metric.\n\n> Response to weakness iv\n\nThe reference I provided describes a network with a handcrafted feature extractor and does not use any public data. A comparison would prove whether it is worthwhile to sacrifice some privacy (due to public data selecting) in exchange for significantly better utility.\n\nSince my concerns largely remain, I would like to maintain the score by far."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700515477372,
                "cdate": 1700515477372,
                "tmdate": 1700515678002,
                "mdate": 1700515678002,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KqXPEWWMjc",
            "forum": "ihr4X2qK62",
            "replyto": "ihr4X2qK62",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission428/Reviewer_heJ7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission428/Reviewer_heJ7"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces the Gradient Subspace Distance (GSD), a metric to quantify the difference between two data sets: First, finding the gradient subspace of two data sets and then computing the distance between two subspaces.\nThe GSD was used in selecting public datasets in both pre-conditioning and transfer learning settings in this paper, and some experiments were done to support this."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The combination of public data and private is something interesting in differential privacy, and this paper follows that flow.\n2 The. introduces the Gradient Subspace Distance (GSD) is something new in the measure of similarity of data sets.\n3. The quality of presentation this paper is Good."
                },
                "weaknesses": {
                    "value": "1. GSD-based public data set selection may leak sensitive information."
                },
                "questions": {
                    "value": "1. What is running time (time complexity) of Algorithm 1 Gradient Subspace Distance (GSD) ?\n2. It is unclear why Gradient Subspace Distance is a good measure of the similarity of data sets in nature.\n3. In Lemma 4.1 what is the relationship between singular values and gradient subspace distance, which one is larger?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission428/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698801939279,
            "cdate": 1698801939279,
            "tmdate": 1699635969422,
            "mdate": 1699635969422,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Dhn4Ycfpcq",
                "forum": "ihr4X2qK62",
                "replyto": "KqXPEWWMjc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your constructive feedback"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the constructive suggestions on improving the quality of this paper. Leveraging public data in private machine learning is an important direction to improve utility and we are encouraged that the reviewer also agrees that GSD is something new under this context.\n\nBelow we give detailed responses to your concerns and questions."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700084866562,
                "cdate": 1700084866562,
                "tmdate": 1700084866562,
                "mdate": 1700084866562,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fBiIvtr1pT",
                "forum": "ihr4X2qK62",
                "replyto": "KqXPEWWMjc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer question1"
                    },
                    "comment": {
                        "value": "One thing worth noticing about GSD is: it doesn\u2019t update or iterate over the model, meaning the gradient subspace distance is given only by one pass through the model. _For a simple theoretical analysis_, we assume that the model used for GSD is a linear model with one hidden layer of size $n$, the number of examples are $m$, the input dimension is $d$, the output is of size $c$, and the lower dimension is $k$. Then the time complexity of GSD is $O(2mdn + 2mnc + 2m(dn+nc)\\log(k) + 2(m+dn+nc)k^2)$ as we only need to get top-$k$ basis. Empirically, in our experiments, GSD computation takes only a _negligible_ amount of time. For example, giving a gradient subspace distance number in Table 1, like 0.15, will only take ~12s with one NVIDIA A100 (40GB) GPU (here #parameters is $O(10^4)$). For fine-tuning LoRA on ViT (#params becomes $O(10^5)$), the time cost is ~41s."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700085291603,
                "cdate": 1700085291603,
                "tmdate": 1700241484065,
                "mdate": 1700241484065,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "dtF5RyiLhO",
            "forum": "ihr4X2qK62",
            "replyto": "ihr4X2qK62",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission428/Reviewer_xFXu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission428/Reviewer_xFXu"
            ],
            "content": {
                "summary": {
                    "value": "The paper considers finding good representative subspaces for the gradients of loss functions when training ML models using sensitive data. In particular, these gradient subspaces are obtained by evaluating the gradients using public data. The background for this: DP-SGD introduces lot of noise and degrades the model performance as the parameter dimension grows. To this end, certain projection method have been introduced (e.g., Yu et al., 2021) where an orthogonal projector is used such that the DP-noise is added only in the projected space, reducing the total expected 2-norm of the injected DP-noise from $O(\\sqrt{d})$ to $O(\\sqrt{k})$, where $d$ is the parameter space dimension and $k$ the dimension of the projection subspace. Then, the problem is, how to obtain a good basis for the projector. Doing this privately is challenging, and a natural choice is to use public data for this. Then the question is, which public data set to use, so that the basis would well represent the subspace where the sensitive gradients live. This paper proposes a certain metric, \"Projection Metric\", to evaluate the goodness of the projector obtained with the public data. This metric is studied both theoretically and experimentally. Another related contribution is to consider \"second phase pre-training\", where a public data pre-trained large model is fine-tuned with another public data by having a small number of trainable parameters, and then the \"Projection Metric\" can be used to select best possible public dataset for this second phase pre-training, in case we use some projection method in the final fine-tuning with the sensitive data."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Very well written paper, everything is explained clearly and comprehensively.\n\n- Nice contributions with introducing the projection metric and studying its properties and also with the second-phase pre-training (as the authors point our, it has not been considered before).\n\n- Extensive and clearly explained experiments."
                },
                "weaknesses": {
                    "value": "- The biggest questions in my mind after reading the paper are related to the computational efficiency of the method. I think these questions are related to these projection methods in general, but of course are directly related to using this projection metric also. I don't really see it discussed anywhere, in the appendix either. Suppose I use that second phase pre-training such that I DP fine-tune LoRa parameters using some public dataset. There would be some $O(10^4)$ parameters, let's say there are 40k of them. And the public dataset size would be, let's say $O(10^5)$. Wouldn't computing the $V_{public}$ using SVD be quite expensive in this case? Or should I somehow limit the number of trainable parameters, the public dataset size, or use stochastic approximations to obtain $V_{public}$, or some other approximative numerical methods? As far as I see, one should update $V_{public}$ quite frequently? How frequently? I am just trying to think of a practical scenario, and what would one need to take into account when using these projection methods and this projection metric. E.g., when I compare public datasets, which one to use for construction the projector, should I just take some random subsets of them as candidates and would that be sufficient?\n\n-  Overall, I think the presented ideas are intuitive and I believe useful but on theoretical level the contribution is not big, the value is on the experimental side. All in all this is a nice contribution and I appreciate also the \"second phase fine-tuning\" part of the paper and the careful experiments. I think this paper would fit well to this venue."
                },
                "questions": {
                    "value": "- I have mostly questions related to the computational efficiency (see above). In the experiments of this paper, how big was the computational burden of choosing and using the projectors? I mean if you compare, e.g., to DP-SGD?\n\nComment: I think the form of the \"projection metric\" with those cosine principal angles as given in Definition 2 is quite intuitive, but I think the form where it is written with the Frobenius norm (used e.g. in the proof of Lemma 4.1) makes it even clearer, perhaps you could consider moving that to the main text? Just to quickly mention it.\n\nMinor comments:\n\n- Dot missing after Eq. 4\n- There are some dots left to the tables all over, e.g. on page 8 and in the appendix.\n- Page 20, paragraph \"Experiment Setting\", third line: bracket missing\n- Page 21, before D.3 title: dot in the middle of the page"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission428/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698827016118,
            "cdate": 1698827016118,
            "tmdate": 1699635969338,
            "mdate": 1699635969338,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "m6Cil73gAl",
                "forum": "ihr4X2qK62",
                "replyto": "dtF5RyiLhO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the insightful and encouraging feedback"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer's insightful and encouraging feedback on the utility of public datasets in private machine learning. We are encouraged by the reviewer's interest in our idea and the acknowledgment of the paper's contribution, as well as its fit with ICLR. The summary given by the reviewer is thorough and concise, and we are lucky to have a reviewer who understands our work well.\n\nBelow, we respond to your specific concerns."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700084541339,
                "cdate": 1700084541339,
                "tmdate": 1700084541339,
                "mdate": 1700084541339,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wXnKVHxCFN",
                "forum": "ihr4X2qK62",
                "replyto": "dtF5RyiLhO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Address weaknesses"
                    },
                    "comment": {
                        "value": "The reviewer raised concerns about the computational efficiency of our method, which is an important aspect for all projection-based preconditioning methods. The short answer is, computational efficiency is not a problem for our methods. We give the following reasons:\n* We assume that the practitioner has a relatively small number of public data examples, which is consistent with projection-based pre-conditioning methods literatures[1][2]. This setting is especially applicable in certain key settings, such as a clinical environment where privacy and safety concerns make it inappropriate to use large, uncurated Internet datasets as public data due to the risk of data poisoning attacks. Instead, the practitioner may have a small set of trusted public datasets. In our experiments, we set the number of public data examples to 2000 or 300, depending on the size of the private dataset. \n* Another advantage of GSD is, GSD doesn\u2019t update or iterate over the model, meaning the gradient subspace distance is given only by one-pass through the model. In Section 4.2, we empirically validate that the order of GSD is preserved over training, thus only two computation (one for $V_{pub}$ and one for $V_{priv}$) is needed to give the gradient subspace distance. With this advantage, combined with small number of public examples assumption, GSD computation only takes negligible time. For example, giving a gradient subspace distance number in Table 1, like 0.15, will only take ~12s with one NVIDIA A100 (40GB) GPU (here #parameters is $O(10^4)$). For fine-tuning LoRA (#params becomes $O(10^5)$), the time cost is ~41s.\n* For those projection-based methods, like GEP, yes, these methods will cost an extra computational burden. As pointed out by the reviewer, computing the basis can be quite expensive, and for GEP, $V_{pub}$ needs to be updated per iteration. However, extra computational burden makes GSD valuable as we can identify the best one from a list of public datasets in advance and thus, saving the time to run GEP over all the public datasets.\n* Practical scenario: as mentioned earlier, GSD is applicable in certain key settings, like clinical environments. To improve accuracy using private ML methods with public data assistance, practitioners can follow these steps: 1) Use GSD to rank the utility of available public datasets, and select the best one; 2) Use the same public examples in step 1, run algorithms like GEP to enhance accuracy.\n\n[1] Da Yu, Huishuai Zhang, Wei Chen, and Tie-Yan Liu. Do not let privacy overbill utility: Gradient embedding perturbation for private learning. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021. URL https://openreview.net/forum?id=7aogOj_VYO0.\n\n[2] Yingxue Zhou, Steven Wu, and Arindam Banerjee. Bypassing the ambient dimension: Private sgd with gradient subspace identification. In International Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=7dpmlkBuJFC."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700084791584,
                "cdate": 1700084791584,
                "tmdate": 1700085148958,
                "mdate": 1700085148958,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xLGzURPc3p",
                "forum": "ihr4X2qK62",
                "replyto": "dtF5RyiLhO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "content": {
                    "title": {
                        "value": "About comments"
                    },
                    "comment": {
                        "value": "We thank the reviewer for pointing out Forbenius norm is more intuitive from an audience\u2019s perspective. We also thank the reviewer for pointing out the minor mistakes made in this paper. We will correct these in the final camera-ready paper (if possible)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700084826809,
                "cdate": 1700084826809,
                "tmdate": 1700085163773,
                "mdate": 1700085163773,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XDHUytDKEQ",
                "forum": "ihr4X2qK62",
                "replyto": "dtF5RyiLhO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission428/Reviewer_xFXu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission428/Reviewer_xFXu"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the replies. I would still have few questions about this:\n\nHow big part of the subspace distance compute cost consists of computing the bases $V_{pub}$ and $V_{priv}$? I.e. if it takes 41s for LoRA, how many seconds of it is just computing $V_{pub}$ and $V_{priv}$? If number of public data samples is 2000, I would imagine it is quite expensive to compute just $V_{pub}$ using SVD. \n\nAnd a related question (concerns again these projection methods in general): How big part of the overall compute cost does forming $V_{pub}$ constitute in a common scenario? How does its cost compare to computing the clipped gradients?"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700204096602,
                "cdate": 1700204096602,
                "tmdate": 1700204214036,
                "mdate": 1700204214036,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "APnMKMCNPj",
                "forum": "ihr4X2qK62",
                "replyto": "85wV4AFcIg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission428/Reviewer_xFXu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission428/Reviewer_xFXu"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the reply! I didn't realize one can use also the randomized SVD for the task of computing $V_{pub}$, indeed it seems to become approximately the same order as the gradients computation. And that also seems to be the case with the projection method analysis / [BWZK22] gradient computation cost analysis. I believe that this analysis gives the correct idea. Thank you for the discussion."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688211375,
                "cdate": 1700688211375,
                "tmdate": 1700688211375,
                "mdate": 1700688211375,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ccq3J4NZyN",
            "forum": "ihr4X2qK62",
            "replyto": "ihr4X2qK62",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission428/Reviewer_Ukt9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission428/Reviewer_Ukt9"
            ],
            "content": {
                "summary": {
                    "value": "This paper extends on the recent line of work that gradients during private optimization lie in a low-dimensional subspace and hence we can reduce the curse of dimensionality by leveraging this fact. Unfortunately, since estimating the subspace privately also incurs an error that scales with the dimension, these works estimate the subspace using \"publicly\" available dataset and use it as a proxy to project the gradient computation on private data to the low-dimensional subspace. This paper provides a metric that measures the distance between private and public subspace."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The definition of the metric."
                },
                "weaknesses": {
                    "value": "The metric studied in the paper is studied a lot in low-rank approximation and non-private subspace estimation problems. In fact, the entire theory of Davis-Kahn revolves around such a metric. So, I really do not get the main contribution of the paper.\n\nThe bound on the reconstruction error is weird. On the right hand side you are measuring the error in terms of spectral norm while the bound is wrt the Frobenius norm. It is never desirable, starting the matrix approximation theory studied from early 20th century. \n\nThe proof idea in the paper has been used in several places and is not new at all. I would suggest the authors to do a proper survey of the literature in matrix analysis. Frank McSherry's thesis might be a good starting point to see the relevant literature from the CS perspective. If the authors want, I can suggest some literature from matrix perturbation theory and operator theory where these concepts are also widely studied. Stewart-Sun's book can be a good starting point."
                },
                "questions": {
                    "value": "No question. I believe I understand the paper well."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission428/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698881996533,
            "cdate": 1698881996533,
            "tmdate": 1699635969273,
            "mdate": 1699635969273,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8XF0Fsgfzn",
                "forum": "ihr4X2qK62",
                "replyto": "ccq3J4NZyN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission428/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the feedback"
                    },
                    "comment": {
                        "value": "We nevertheless appreciate the feedback from the reviewer, but we disagree with their understanding of the paper's main contribution. _The main contribution of this paper is not about the matrix approximation theory or the proof idea_. In fact, we don\u2019t even acknowledge it as a contribution of this paper. \n\nThe main contribution of this paper is proposing a crucial scientific question and providing a solution to it. All other reviewers, even the reviewer who recommended rejection can identify this contribution and agree with this assessment.\n\nWe struggle to construct a rebuttal as the reviewer's feedback does not seem constructive or insightful. Nevertheless, we are open to suggestions about _matrix perturbation theory and operator theory_, and we are willing to explore how these early 20th-century studies can help enhance the quality of this paper."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700084482184,
                "cdate": 1700084482184,
                "tmdate": 1700085110857,
                "mdate": 1700085110857,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "l5Ui2HmHe3",
                "forum": "ihr4X2qK62",
                "replyto": "8XF0Fsgfzn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission428/Reviewer_Ukt9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission428/Reviewer_Ukt9"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response"
                    },
                    "comment": {
                        "value": "Thanks for clarifying that your main contribution is not with respect to anything on matrix perturbation theory; however, the idea of using cosine similarity to measure the closeness of two subspaces is not new. It is a crucial scientific question that has been raised a long time ago. So, I am still unsure how this is anyhow a \"new\" question. \n\nUsing Davis-Kahn type results is pretty common in understanding low-rank structure. As I mentioned earlier, there is a rich literature on it in various disciplines of applied mathematics. AFAIK, even in privacy, results like \"Beyond worst case for singular value computation\" and its follow-up work by Hardt-Price, and \"Analyze Gauss\" and its follow-up based on Dyson Brownian motion also use such similarity to study how close the span of the space is.  \n\nFinally, I still do not understand how measuring bounding the spectral norm of error with Frobenius norm of related object is anyhow meaningful. If you want to prove a bound, you would like to impose similar metric. Spectral norm approximation is traditionally harder (even from the streaming literature) because you are trying to bound the error with respect to $\\sigma_{k+1}$ instead of $\\sum_{j \\geq k} \\sigma_{j}$. That is why results like Kapralov-Talwar and Achliptas-McSherry (in privacy) is beautiful and the space required for such an approximation even without privacy is linear in dimension. When you use spectral norm as a metric on one side and Frobenius norm on the other side, you end up comparing apples with oranges."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700103705240,
                "cdate": 1700103705240,
                "tmdate": 1700103705240,
                "mdate": 1700103705240,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]