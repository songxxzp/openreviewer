[
    {
        "title": "NPEFF: Non-Negative Per-Example Fisher Factorization"
    },
    {
        "review": {
            "id": "1U9E43RKwT",
            "forum": "gywQnORzJX",
            "replyto": "gywQnORzJX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4277/Reviewer_Brpd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4277/Reviewer_Brpd"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an interpretability method which allows to obtain representations of concepts. These representations are found by non-negative per-example fisher factorization, which can be done for any end-to-end differentiable model. This method is analogous to non-negative matrix factorization matrices in one of its instantiations and hence decomposes the per-example fisher information matrix into a set of non-negative coefficients and concept vectors, referred to as pseudo-Fishers.\nIn their experiments, the authors demonstrate the ability of their method to verify what concepts lead to the model's processing. They also show some initial experiments demonstrating how to selectively fix incorrect predictions."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The authors propose a novel, low-rank decomposition for the per-example fisher.\n- The method is applicable to any end-to-end differentiable model.\n- The authors did a thorough analysis of the hyperparameters introduced by their method."
                },
                "weaknesses": {
                    "value": "- While the advantages of the method are well explained, it would be good to add a separate limitations section for transparency. Could you elaborate in your comments on what you see as the biggest limitations.\n- I have found the toy model difficult to understand. I think it would be good to provide an intuitive explanation in the main text on the programmatic search."
                },
                "questions": {
                    "value": "- Could your example about fixing flawed heuristics have applications to the unlearning literature?\n- As pointed out by Kunstner et al. 2019, the fisher information matrix is an overloaded object which may or may not refer to the empirical fisher. Since you switch from the true fisher to an approximation which Kunstner et al. 2019, please check section 3.2 of their paper that you followed the correct terminology\n\n\nTypos / Small errors\n- Please review your references, e.g. the lottery ticket hypothesis paper appeared in ICLR 2018.\n- The equation equation 5 provides ...\n\n\nReferences:\nKunstner, Frederik, Philipp Hennig, and Lukas Balles. \"Limitations of the empirical fisher approximation for natural gradient descent.\" Advances in neural information processing systems 32 (2019)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4277/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4277/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4277/Reviewer_Brpd"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4277/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697543222445,
            "cdate": 1697543222445,
            "tmdate": 1699636396128,
            "mdate": 1699636396128,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xmuuys11TL",
                "forum": "gywQnORzJX",
                "replyto": "1U9E43RKwT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4277/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4277/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review.\n\n> Would you elaborate in your comments on what you see as the biggest limitations.\n\nWe've added a limitations/future work paragraph to the end of the conclusion. The two main limitations\nwe see in our current implementation of NPEFF are supporting models with a large output space (e.g.\nhaving many classes or text generation) and allowing for control over component tunings.\n\nFor the former, we can sample from the output distribution to create an approximation of the PEFs.\nThis would require things like determining the number of samples needed per example. Alternatively if\ncanonical input/output pairs are provided, we can use something like the empirical Fisher (as per Kunstner et al. 2019)\ninstead.\n\nAlthough the unsupervised nature of component recovery using NPEFF can be considered one of its advantages, it\ncan also be a limitation when trying to use NPEFF in some applications. For example, being able to create a\ncomponent tuned for a particular user-defined concept would be useful when using something like our\nperturbation procedure to make user-guided changes to a model. One potential method for this is to create a component whose\ncoefficients would be forced to be non-zero for a selected set of examples and zero for all others.\n\n\n> I have found the toy model difficult to understand.\n\nThere was general confusion amongst the reviewers about this. We have updated Section 3.2 to more clearly describe\nwhat the \"concepts\" were (values of Boolean intermediate variables in the RASP program) and the tunings of the\nrecovered components.\n\n> Could your example about fixing flawed heuristics have applications to the unlearning literature?\n\nPossibly. One limitation of NPEFF, however, is the inability to directly create a component tuned for a\nhuman-defined concept. This could make it challenging to obtain a component tuned for something that you\nwant to unlearn. As was done in the flawed heuristics experiments, the components set expansion procedure\ncould help in creating components tuned to user-defined concepts/information, but there would be no guarantees\nin actually recovering such a component. However, it is possible that modifications could be made to the\nNPEFF decomposition to procedure to better support this. For example, one could create a component whose\ncoefficients would be forced to be non-zero for a selected set of examples and zero for all others.\n\n> The fisher information matrix is an overloaded object which may or may not refer to the empirical fisher.\n\nFor PEFs (per-example Fishers), there is no expectation over the model inputs $x$, so there is no conceptual difference\nbetween a \"statistics Fisher\" and \"statistics empirical Fisher\". As for the role of\nthe expectation over classes \"y\", we make no use of any label provided with the example and perform\nan expectation over the set of classes."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4277/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700272046669,
                "cdate": 1700272046669,
                "tmdate": 1700272046669,
                "mdate": 1700272046669,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Q0boGL0L1J",
            "forum": "gywQnORzJX",
            "replyto": "gywQnORzJX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4277/Reviewer_RGwC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4277/Reviewer_RGwC"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a new method for interpreting neural networks called NPEFF. The method applies to classification models and relies on first constructing the Fisher matrix for each example. This matrix can be sparsified by magnitude clipping and also by omitting classes with low probability. Given the Fisher matrices for many examples, the \u201ccomponents\u201d are extracted by approximately factorizing the Fisher matrix in a fashion close to non-negative matrix factorization. The authors also shows how the extracted matrices can be used to relate changes in model parameters to changes in the outputs. Experimentally the authors considers two settings: image classification with Resnets and NLP tasks with a finetuned BERT model. In Figure 1 and 2 the authors visualize some found components, in figure 3 they also show that the model is sensitive in the directions uncovered by NPEFF. Additionally, a comparison with toy data with known ground truth components is done, some ablation experiments are included and a comparison to a previous interpretability strategy is conducted."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Intrepretability is important, especially for LLMs. \n\nThe paper is well written."
                },
                "weaknesses": {
                    "value": "Interpretability has been studied for a long time, so the novelty is rather low.\n\nThe results are only presented for small Bert/Resnet models. It would be better with results for LLMs. \n\nIt is hard to know if the proposed method works well. Interpretability is very subjective, and a few examples (which could be cherry picked) are not very convincing. The authors only compare against a single baseline."
                },
                "questions": {
                    "value": "Could you compare against more baselines? \n\nCould you do some kind of human evaluation? E.g. give a sample of 10 people two interpretability models and ask which one they prefer.\n\nCould you give results on LLMs?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4277/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697580060420,
            "cdate": 1697580060420,
            "tmdate": 1699636395210,
            "mdate": 1699636395210,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "zXPA0t9qeE",
                "forum": "gywQnORzJX",
                "replyto": "Q0boGL0L1J",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4277/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4277/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review.\n\n> Interpretability has been studied for a long time, so the novelty is rather low.\n> ...\n> Could you compare against more baselines?\n\nWhile interpretability has been studied for a long time, we argue that it is a broad enough field\nthat there still exists room for significant novelty. In particular, unsupervised concept discovery\nmethods like NPEFF are highly novel. We were only able to find two existing unsupervised concept discovery\nmethods: Ghorbani et al. (2019) and Yeh et al. (2020). These both operate by mapping activations to concepts.\nFor models without a fixed dimension activation space, these methods need some way to get fixed-dimensional (set of) activations\nfor example. Neither previous work experimented on Transformers, but you could use token-level activations at a particular layer.\nSince these are not example-level activations, they can leave out important information that is spread out across multiple sequence\npositions. In constrast, NPEFF provides a full example-level decomposition of the model's processing.\n\nIn our baselines, we compared NPEFF to Ghorbani et al. (2019) by using activations that come right before the classification\nhead. Although this allowed us to get an example level decomposition for the baseline, the activations in the transformer body\ncannot be analyzed this way. Yeh et al. (2020) experimented with performing a sequence/image-position level decomposition of\nactivations. However, they only experimented with convolutional models. Some of their methods rely on the properties of the\nreceptive fields of intermediate activations in convolutional models, so their method would be harder to adapt to transformers.\n\n> Interpretability is very subjective, and a few examples (which could be cherry picked) are not very convincing.\n\nSuccinctly evaluating interpretability methods is tricky due to the generally subjective nature of interpretability.\nWe've added to the supplemental material a pdf (mnli_to_snli.pdf) of all of the component top examples for the NLI experiment from Section 3.1.1. While not ideal, these can be used to verify that most components have an interpretable tuning and that the examples included in the paper were not cherry-picked.\n\n\n> Could you do some kind of human evaluation? E.g. give a sample of 10 people two interpretability models and ask which one they prefer.\n\nWhile human evaluation might be useful for verifying that components have interpretable tunings, we think that using it to compare\nNPEFF to another interpretability model would have many pitfalls. The goal of an unsupervised concept discovery method like NPEFF is to uncover components that accurately reflect the processing done by a model. An interpretability method that produces\noverly simple components might win out in a human evaluation over a model that more accurately reflects the processing done\nby the model. Such comparisons could be of value if the goal of an interpetability method was to get the model to \"show\nits work\" to an end user, but that was not a goal of NPEFF.\n\n> Could you give results on LLMs?\n\nOur current method of computing PEFs uses an expectation over the set of possible model outputs. For\nclassification models with few classes, we compute this expectation exactly, and we ignore classes\nassigned low probabilities for classification models with many classes. For autoregressive language models, however,\nwe would need to approximate the PEF by doing something like taking several samples from the model's output.\nIf model inputs are paired with ground-truth outputs, then we could use something like empirical Fisher instead of the\ntrue Fisher. We leave exploration of this to future work.\n\nIn terms of applying NPEFF to large models in general (e.g. xlm-roberta-xl and xlm-roberta-xxl), NPEFF doesn't have\nany methodological issues. We can include experiments at that scale, but we do not have the time to run them during\nthe rebuttal period.\n\nOperating on sparse representations of PEF matrices allows NPEFF to better scale to large models.\nIt is also possible to run NPEFF on PEFs computed using only a subset of the model variables. For example, one might\nrun NPEFF using only the parameters from a single transformer layer. While we do not explore that in this work,\nwe have explored this a bit and found the components to have interpretable tunings."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4277/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700272016457,
                "cdate": 1700272016457,
                "tmdate": 1700272016457,
                "mdate": 1700272016457,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Oajkctkpr8",
                "forum": "gywQnORzJX",
                "replyto": "zXPA0t9qeE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4277/Reviewer_RGwC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4277/Reviewer_RGwC"
                ],
                "content": {
                    "title": {
                        "value": "reply"
                    },
                    "comment": {
                        "value": "I thank the authors for their reply. My concerns remain and I will retain my score.\n\nI agree that there are pitifalls regarding using humans for evaluation, but maybe it would be possible to recruit a small cohort of DNN researchers to evaluate the interpretability? More quantative evaluation on the interpretability would be good."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4277/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700682619958,
                "cdate": 1700682619958,
                "tmdate": 1700682619958,
                "mdate": 1700682619958,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "21RNesX0KN",
            "forum": "gywQnORzJX",
            "replyto": "gywQnORzJX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4277/Reviewer_2rEq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4277/Reviewer_2rEq"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose NPEFF for unsupervisedly discovering the components being used in a learnt model. NPEFF decomposes each example' Fisher information matrix as a non-negative sum of components, so as to discover a set of r components within the network and a coefficient $W_{ij}$ describing the influence of the j-th component on the i-th example's prediction. NPEFF components are examined for two language and one vision dataset, both by viewing the sets of examples strongly associated with each component and by observing the effects of perturbing on components. Lastly, an experiment is performed to discover whether modifying components associated with incorrect predictions will improve predictive performance, resulting in an accuracy gain of 0.5%."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- An unsupervised method for concept discovery that works on general NN would be a useful and significant contribution. While there is some related work as detailed in Section 4, much is focused on vision or does not automatically group features together into sets of discrete concepts (for instance, visualizing CNN convolutions creates human-interpretable patterns as to what the convolutions are picking up, but does not group these patterns together itself)\n- The resulting components indeed match to desired, human-recognizable concepts in both the language and vision domains\n- Quantitative and qualitative evaluations of the method are both very comprehensive"
                },
                "weaknesses": {
                    "value": "- The experiment on fixing flawed heuristics achieves only a slight improvement of 0.5% accuracy, by improving predictions for 4/48 components associated with incorrect heuristics\n- Unclear how the perturbations experiment in Section 3.1.2 demonstrates that NPEFF's discovered parameter space directions are important as stated at the end of the section. Would be nice to see more potential application of NPEFF with strong results\n- Minor typo: definition of $a_j(x)$ in section 2.1 should have $y_j$, not $y_i$"
                },
                "questions": {
                    "value": "- In section 2.2's preprocessing section, you state that raw PEFs gave components tuned to outlier examples. Could NPEFF with raw PEFs be useful for some form of OOD detection or prediction confidence measure?\n- Could you give more information on how Section 3.1.2 perturbation experiment demonstrates the claims at the end of this section?\n- Figure 3: it seems interesting how in QQP and NLI, the PEF norm ratios take a wider range of values than the KL ones, while in ImageNet the opposite is true. Is this meaningful in any way?\n- Could you give more details on what constitutes a \"concept\" and what components resulted in Section 3.2? For instance, did each component tend to focus on one particular concept and components were quite diverse from each other (as likely desirable), or do many components tend to identify with many different concepts so that components are relatively similar to each other?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4277/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4277/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4277/Reviewer_2rEq"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4277/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698293595622,
            "cdate": 1698293595622,
            "tmdate": 1699636395126,
            "mdate": 1699636395126,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FV5zH2ynIN",
                "forum": "gywQnORzJX",
                "replyto": "21RNesX0KN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4277/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4277/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review.\n\n> The experiment on fixing flawed heuristics achieves only a slight improvement of 0.5% accuracy,\n\nWe agree that 0.5% is a small boost, but a small boost is to be expected when correcting a single incorrect heuristic\nthat is used only on a relatively small subset of examples. The change was significantly bigger when we look at\nmodel's predictions for the component top examples. The four components that provided a boost of 0.5% or greater to\nthe total accuracy had accuracies of 27%, 24%, 58%, and 41% on their top 128 examples using the base model. Their\nrespective perturbed models reached accuracies of 88%, 72%, 95%, and 77%, respectively, on the same examples.\n\nWe also note that these improvements are for correcting\na single heuristic at a time. We found that perturbating multiple components at once could boost total accuracy\nfurther, but we did not explore this beyond some preliminary experiments.\n\n> Could NPEFF with raw PEFs be useful for some form of OOD detection or prediction confidence measure?\n\nPotentially. A simple alternative would be just looking at the norm of a PEF for something like OOD detection.\nNPEFF could provide an advantage over this by having components match up with specific reasons why examples\nare OOD or hard to make good predictions on. For example, such a component from a digit identification task\ncould be tuned to ambiguous 4/9 and 5/6 digits.\nKnowing that an example had a high coefficient for such a component could be useful for providing a reason why\none might not want to place much confidence on the model's prediction for a particular example. We haven't done much\nexploration with NPEFF on raw PEFs, but it is a potential future research detection.\n\n> Could you give more information on how Section 3.1.2 perturbation experiment demonstrates the claims at the end of this section?\n\nWe've added some text in the last paragraph of that section to help explain this. The goal of the perturbation\nexperiments was to show that the direction in parameter space associated to a component (its pseudo-Fisher) is of particular importance\nto the model's processing of the component's top examples. The perturbation experiment tests this by constructing\na perturbation derived from a components pseudo-Fisher and seeing how much the predictions for each example change\nas measured by their KL-divergences from their original predictions. Taking the ratio of the average KL-divergence for a component's top\nexamples to the average KL-divergence for the data set as a whole measures how much more/less the predictions of the top\nexamples changed compared to the rest of the examples. However, the model's predictions for some examples are simply more\nsensivitive to perturbations in general, which is measured by the norm of their PEFs. Hence, if component top examples tended\nto have PEFs with larger norms than average, then looking at the KL-divergence ratios alone would be misleading.\nWe therefore also looked at the ratios of the average PEF norm for the component's top examples to average PEF norm for the\nrest of the examples. As the KL-ratios tended to be significantly higher than the PER-norm ratios, the component-derived\nperturbations affected the component's top examples more than can be explained by their general sensitivity to perturbations.\n\n\n> Figure 3: it seems interesting how in QQP and NLI, the PEF norm ratios take a wider range of values than the KL ones, while in ImageNet the opposite is true. Is this meaningful in any way?\n\nWe think this might be due to the difference in the number of classes between the tasks. The text tasks have 2 or 3 classes, and the\nmodel can use some heuristics very confidently to make predictions. This leads to these component top examples having very small\nPEF norms. In contrast, ImageNet is a fine-grained image classification task with a 1000 classes. Most strategies used by the\nmodel wouldn't be able to confidently make predictions for a single class, so component top examples will tend to have norms\nmore in line with average examples. This leads to PEF norm ratios taking on a far larger range for QQP and NLI compared to ImageNet."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4277/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700271959014,
                "cdate": 1700271959014,
                "tmdate": 1700271959014,
                "mdate": 1700271959014,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LRP0HOoF8l",
                "forum": "gywQnORzJX",
                "replyto": "deUxrvAwji",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4277/Reviewer_2rEq"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4277/Reviewer_2rEq"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the very detailed response! I will maintain my rating, because I think that NPEFF is promising but the paper could also be improved by expanding the empirical results and potentially investigating possible further uses like OOD detection. However, I am still leaning towards accept."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4277/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700605114771,
                "cdate": 1700605114771,
                "tmdate": 1700605114771,
                "mdate": 1700605114771,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Yn7CSUVYPw",
            "forum": "gywQnORzJX",
            "replyto": "gywQnORzJX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4277/Reviewer_19bz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4277/Reviewer_19bz"
            ],
            "content": {
                "summary": {
                    "value": "The current paper focuses on developing an approach to decomposing a fisher information matrix into interpretable components to understand the behavior of a pretrained model. I found the claims and the methodology itself interesting, albeit reminiscent of prior works on importance/saliency estimation of model parameters in network pruning (Molchanov et al., 2017)---the authors already cite some of these papers."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "I found the proposed methodology itself interesting, though arguably difficult to implement or work with. The available code can help address this."
                },
                "weaknesses": {
                    "value": "My biggest apprehension at the moment is that the paper's writeup is extremely unclear at times. While the first half of the papers reads fine and I'm able to follow, the motivation for the experiments, their setup, and the very results themselves are quite unclear to me. For example, the authors claim all \"directions\" unveiled by their method encodes some \"concept\" used by Tracr for manually performing the tasks discussed therein. It is entirely unclear though what a \"concept\" means---is it mere addition, a Tracr primitive, a composition of primitives, etc.? Such lack of clarity generally left me confused throughout the paper, such that I was not certain what the implication of any of the experiments was. This made it hard for me to judge the paper.\n\nPracticality: While the authors conduct experiments on a BERT model, the proposed method requires at least linear in number of parameters memory. I'm uncertain of the scalability of this approach, therefore. Of course several methods suffer from this problem, but it will be worth discussing this in the paper.\n\n**Post rebuttals comment:** I appreciate the authors' comments. Having gone through the updated paper, other reviewers' comments, and the rebuttals to them, I do think the paper has improved. I still found the writing unclear at times (e.g., while I get what \"tunings\" are, I don't understand why the term is suddenly informally defined and then casually used thereafter, making the paper confusing to me at points). I'm increasing my score to 5 however, given the updates and responses."
                },
                "questions": {
                    "value": "See weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4277/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4277/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4277/Reviewer_19bz"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4277/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699063761136,
            "cdate": 1699063761136,
            "tmdate": 1700931088445,
            "mdate": 1700931088445,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "D2VMAfcfOT",
                "forum": "gywQnORzJX",
                "replyto": "Yn7CSUVYPw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4277/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4277/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We have updated Section 3.2 on the toy TRACR/RASP experiment to more clearly describe what the \"concepts\" were and the tunings of the\nrecovered components. Essentially, concepts corresponded to values of Boolean intermediate variables in the RASP program.\nSince the RASP program was human-written and readable, these meanings of these concepts can be ascertained by looking\nat the associated variable in the RASP code.\nWe found the set of components tunings to be fairly diverse. We also found that many components were tuned to the logical \"and\"\nof multiple concepts, which can be thought of as more fine-grained concepts.\n\nSince real-world models do have an associated RASP program, the rest of the paper uses the term \"concept\" to refer\nmore generally as something the model uses to inform its predictions. This can include concrete features (e.g. mention of food)\nor more abstract properties of the example (e.g. having word in the hypothesis that is in direct contradiction to a word\nin the premise). We'd frequently see components tuned to a combination of these types of concepts (e.g. the premise and hypothesis assigning different colors to an article of clothing).\n\n> the proposed method requires at least linear in number of parameters memory.\n\nAs discussed in the \"sparsity\" paragraph of Section 2.1, we make use of a thresholding operation to create a sparse representation\nof each PEF. The number of non-zero values used in this representation is a user-defined hyperparameter, so the amount\nof memory used to store each PEF ends up being significantly smaller than the number of model parameters. For a 110M\nparameter BERT-base, we found even using 16k non-zero values per PEF to perform well. The number of non-zero values\nneeded will likely increase with model size but would still remain significantly smaller than the number of parameters.\nFurthermore, it is also possible to run NPEFF on PEFs computed using only a subset of the model variables. For example, one might\nrun NPEFF using only the parameters from a single transformer layer. We found this to be effective in preliminary experiments but left it out of the paper due to space considerations."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4277/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700271916111,
                "cdate": 1700271916111,
                "tmdate": 1700271916111,
                "mdate": 1700271916111,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]