[
    {
        "title": "Reflected Schr\\\"odinger Bridge for Constrained Generative Modeling"
    },
    {
        "review": {
            "id": "ilb3NsQ83e",
            "forum": "PyERBFX0wJ",
            "replyto": "PyERBFX0wJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3755/Reviewer_vVua"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3755/Reviewer_vVua"
            ],
            "content": {
                "summary": {
                    "value": "The authors combine reflected SDEs [1] with the diffusion schrodinger bridge methodology [2] and IPF training scheme. This enables regularized OT on constrained domains. The authors show good empirical performance.\n\n[1] Lou and Ermon Reflected Diffusion Models, 2023 \\\n[2] Bortoli et al Diffusion Schrodinger Bridge 2023"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- In general equations and methods appear correct\n- This provides a neural entropic OT approach to constrained domains, which is novel as far as I am aware (other diffusion and or simple mapping approaches are not capable of this)\n- Generation performance is good for image datasets"
                },
                "weaknesses": {
                    "value": "- This is a straight forward connection between reflected SDEs [1] and schrodinger bridge IPF [2,3], without a clear reason or motivation\n- Benefits of the method, in particular reduced number of diffusion steps or the benefit of entropic OT on constrained spaces are not really explored, it has not been made clear how this method is beneficial\n\n- Likelihood based training of IPF appears incorrect. The first terms in algorithm 1 involve expected $\\log y_T$ and $\\log y_0$ starting from points from the alternate marginal distribution $x_0$ and $x_T$ respectively. My understanding form [3] is that these are the result of simulating the diffusion backwards and hence depend on the parameters of the networks. These log terms do not coincide with the log densities of the target measures unless the IPF procedure has converged, hence these one cannot simply ignore them and use this as a loss without taking gradients through the diffusion simulation. I would argue this is not likelihood training and [3]'s argument is incorrect unless there's the assumption that the method has already converged, in which case there is no need for further iterations?\n\nIt has been shown by the same authors of [3] that this coincides with regular IPF of [2] and does not require this (incorrect) likelihood derivation. \n\nMinor:\n\n- Section 1: Shi et al 2023 does not use IPF but IMF.\n- Vargas et al 2021 does non perform SB on high dimensional examples as claimed, maximum dimension is 4..\n- There are many other constrained domain diffusion methods e.g Fishman et al Diffusion Models for Constrained Domains 2023\n- The authors mention other related work such as Riemannian SGM Bortoli et al 2022, it should be noted that even more relevant to this work is SB and hence OT has been performed on manifolds in Thornton et al Riemannian Diffusion Schrodinger Bridge, 2022\n\n[1] Lou and Ermon Reflected Diffusion Models, 2023 \\\n[2] Bortoli et al Diffusion Schrodinger Bridge 2023 \\\n[3] Chen et al Likelihood Training of Schr\u00f6dinger Bridge using Forward-Backward SDEs Theory, 2022\n[4] Liu et al , Deep Generalized Schr\u00f6dinger Bridge, 2023\n\n**Edit: correcting typos**"
                },
                "questions": {
                    "value": "What are the applications and significance of OT on constrained domains?\n\nDoes the proposed method use fewer diffusion steps to obtain similar results to non SB constrained methods?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3755/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3755/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3755/Reviewer_vVua"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3755/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698741049258,
            "cdate": 1698741049258,
            "tmdate": 1699704684228,
            "mdate": 1699704684228,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "J4Xu9y0fa8",
                "forum": "PyERBFX0wJ",
                "replyto": "ilb3NsQ83e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3755/Reviewer_vVua"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3755/Reviewer_vVua"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Francisco, \n\nThank you for your interest in this review. I am taken aback by this comment. I hope this is not intentional, but I find your tone and wording quite condescending, and highly unprofessional.\n\nI stand by this remark, regardless of how very minor it is. \n\nIf you take the time to read the sentence again - \"pushed the frontier of IPFs to high-dimensional generative models\" - I do not think this characterises your paper. I do not consider dimension 4 or even 5 to be high dimension. I am not sure anyone would. So in my opinion your work has not \"pushed the frontier of IPFs to high-dimensional generative models\" as stated in the text, especially when other work at the same time extended IPF to dimensions > 1,000.\n\nI also do not think you showed that your approach can be used for generative modeling. \n\nI agree one could take the regression loss, then adjust the training procedure to be substantially more scalable with a host of training techniques, neural networks, time batching etc. from the diffusion model literature. However to the best of my knowledge this is not done in your work. To cite your work specifically for this would demerit/diminish other contributions from 2021 that actually scale IPF to a dimension in the thousands and not 4 or 5.\n\nI appreciate the contributions of your paper. Indeed it works well for low dimension and non linear reference diffusions. However this minor remark is unrelated to other contributions and does not diminish other contributions. I believe your work should be cited but certainly not for scaling IPF for high dimensional generative modeling."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700169060002,
                "cdate": 1700169060002,
                "tmdate": 1700170765961,
                "mdate": 1700170765961,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "eQoVrqLkMR",
                "forum": "PyERBFX0wJ",
                "replyto": "ilb3NsQ83e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3755/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3755/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Connections, losses, and experiments"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer for the insightful suggestions.\n\n**Straightforward connections between reflected SDEs and Schrodinger bridge (SB)**\n\nWhile the SB algorithms (Valentin'21, Chen'22) have made significant strides in the study of dynamic optimal transport and generative modeling, our understanding of constrained generative modeling with non-linear transport and theoretical optimal transport guarantees remains incomplete, especially in light of real-world data often exhibiting bounded support. To address this challenge, we derive reflected forward-backward stochastic differential equations (reflected FB-SDEs) with Neumann and Robin boundary conditions, yielding a specific loss function for constrained generative modeling on arbitrary smooth domains. Furthermore, we establish connections between reflected FB-SDEs and Entropic Optimal Transport (EOT) on bounded domains. Notably, **our work opens avenues for analyzing the linear convergence of dynamic couplings on bounded domains, offering valuable insights into high-dimensional generative models.**\n\n**Log terms do not coincide with log densities unless the IPF procedure has converged and Why Chen'22's alternative training has no $E[\\log \\overleftarrow y_T]$ and $E[\\log \\overrightarrow y_0]$, while ours does.**\n\nAlthough the likelihood in Proposition 1 is theoretically correct, we recognize the challenges in estimating $E[\\log \\overleftarrow y_T]$ and $E[\\log \\overrightarrow y_0]$ in Alg.1, particularly at non-differentiable terminal time points $t=0$ and $T$. A more pragmatic alternative involves omitting these terms following Chen'22, albeit at the cost of a slight increase in the variational gap. We have made the corresponding revision in Alg.1. We express our gratitude to reviewer vVua again for capturing the important details and improving the algorithmic demonstration.\n\n**Empirical justification of Fewer NFEs**\n\n\nWe have included section D.5 in the appendix to study how optimal transport helps reduce NFEs in a simulation example. We note that optimizing the forward network plays a crucial role in training the backward network, especially when contrasted with the baseline where the forward network weights are set to 0. The well-optimized forward network leads to an improved sample quality even in cases where NFE is set to 10 and 12. We also wish to produce more examples in the final version.\n\n\n\n**Comments on the References**\n\nWe value your insightful suggestions regarding the references. In response, we have reintroduced the bridge matching method in the introduction section and incorporated the more pertinent reference [1] into our related works.\n\n[1] Riemannian Diffusion Schr\u00f6dinger Bridge. \n\nWe sincerely hope we have addressed your concerns and kindly request the reviewer to generously reconsider the work."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700328247132,
                "cdate": 1700328247132,
                "tmdate": 1700328342616,
                "mdate": 1700328342616,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Rsipqg1MMA",
            "forum": "PyERBFX0wJ",
            "replyto": "PyERBFX0wJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3755/Reviewer_bpMp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3755/Reviewer_bpMp"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors propose to extend the Schrodinger Bridge methodology to state space which are defined by constraints. They follow closely the methodology based on Forward Backward Stochastic Differential Equations (FBSDEs) introduced in [1]. The main contribution of the paper is to extend this set up to the case where the FBSDEs are replaced with a reflected FBSDE. This is in accordance with the recent works of [2,3] who study reflected versions of diffusion models. Another contribution of the paper is to study the convergence of Iterative Proportional Fitting (IPF) approaches. In that setting, the authors follow [4]. The authors also illustrate the efficiency of their method with \n\n[1] Chen et al. (2021) -- Likelihood Training of Schr\u00f6dinger Bridge using Forward-Backward SDEs Theory\n\n[2] Lou and Ermon (2023) -- Reflected Diffusion Models\n\n[3] Fishman et al. (2023) -- Diffusion Models for Constrained Domains\n\n[4] Chen et al. (2023) -- Provably Convergent Schr\u00f6dinger Bridge with Applications to Probabilistic Time Series Imputation"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The extension of the Schrodinger Bridge framework to the reflected setting is new to my knowledge. \n\n* The convergence guarantees presented in the paper are also interesting (although see my comments in the \"Weaknesses\" section for some concerns I have regarding their novelty and soundness).\n\n* I appreciate the fact that the authors produce extensive experiments and compare themselves to [1]. \n\n[1] Lou and Ermon (2023) -- Reflected Diffusion Models"
                },
                "weaknesses": {
                    "value": "* My main concern is with the motivation of the paper. While it is certainly possible (as shown by the authors) to extend the Schrodinger Bridge framework to the reflected setting it is not clear why one would like to do this. I think that a contribution to a top tier venue such as ICLR requires more motivation (either theoretical, methodological or experimental), note that I am not talking about the novelty here (there is no doubt that the presented work is novel). It seems that the authors want to put forward that Schrodinger Bridge has the ability to reduce the length of the integration time in generative modeling (a reason first put forward in the work of [1]) \"Notably, the forward process (1a) requires a long time T to approach the prior distribution, which inevitably leads to a slow inference\". However there already exist many works focused on improving the speed of diffusion models (distillation, better samplers, etc.) which have proven to be more efficient than Schrodinger bridges. \n\n* The authors claim that Proposition 1 is a valid ELBO, however this result is only true at equilibrium. It is no longer true when the vector fields are parametric functions. \n\n* I am not very convinced by the significance of the empirical results. As I emphasized earlier, I appreciate the fact that the authors provide an extensive image investigation, however the results are not very convincing. The quality seems to be worse than [2]. If the authors claim that the reflected SB method improves the speed of the generation then it would have been useful to compare NFE.\n\n* It is not clear at all for me what are the differences between the theoretical section and the work of [3]. The work of [3] is cited but not comparison or discussion is provided. \n\n* The assumption A4 is very strong. It is claimed that it is similar to the one of [4] but this is not true. In fact, the assumption of [4] only holds for one iteration of the IPF. The stability of the approximation across IPF iterations is not clear at all and should be discussed. \n\nMinor comments:\n\n* In the introduction [5] should be cited when citing [6] as the works are concurrent.\n\n* In (3) missing index $t$ in $x_t$ \n\n* When deriving the reflected FBSDE framework I would have appreciated more emphasis on the introduced quantities.\n\n* Could the authors be more precise on the algorithmic differences between the introduced algorithm and the one of [7]?\n\n* It would be very interesting to understand if the current setting can accomodate for an understanding of the dynamic thresholding procedure used in [8]\n\n[1] De Bortoli et al. (2021) -- Diffusion Schr\u00f6dinger Bridge with Applications to Score-Based Generative Modeling\n\n[2] Lou and Ermon (2023) -- Reflected Diffusion Models\n\n[3] Chen et al. (2023) -- Provably Convergent Schr\u00f6dinger Bridge with Applications to Probabilistic Time Series Imputation\n\n[4] De Bortoli (2022) -- Convergence of diffusion models under the manifold hypothesis \n\n[5] Peluchetti (2023) -- Diffusion Bridge Mixture Transports, Schr\u00f6dinger Bridge Problems and Generative Modeling\n\n[6] Shi et al. (2023) -- Diffusion Schr\u00f6dinger Bridge Matching\n\n[7] Chen et al. (2021) -- Likelihood Training of Schr\u00f6dinger Bridge using Forward-Backward SDEs Theory\n\n[8] Saharia et al. (2022) -- Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding"
                },
                "questions": {
                    "value": "Please answer to the main comments in the \"Weaknesses\" section. The authors should focus on the motivation of their method. As of now, it is not clear what are the key contributions of the paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3755/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698749933074,
            "cdate": 1698749933074,
            "tmdate": 1699636331805,
            "mdate": 1699636331805,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PooTwDubNY",
                "forum": "PyERBFX0wJ",
                "replyto": "Rsipqg1MMA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3755/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3755/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Motivation, ELBO, and Assumptions A4."
                    },
                    "comment": {
                        "value": "We appreciate the reviewer for the valuable comments.\n\n**Major Novelty and Motivation of the paper**\n\nOur major novelty comes from the constrained generation on **arbitrary smooth** bounded domains with **theoretical support**. To achieve this goal, we developed the reflected Schrodinger bridge algorithm (rSB), which provides the first work of generative models that extends to arbitrary smooth geometries with optimal transport guarantees. Theoretically, we establish the elegant connections between rSB and the linear convergence of optimal transport on bounded domains. This not only enhances our understanding of the algorithm but also lays the foundation for exploring the theoretical properties of dynamic Schr\u00f6dinger bridges\u2014a domain that remains less explored. This novel linkage contributes significantly to the field, providing a deeper comprehension of the algorithm and paving the way for the study of dynamic Schr\u00f6dinger bridges.\n\n**Proposition 1 is not a valid ELBO when vector fields are parametric functions**\n\nWe respectfully **disagree** with this argument. Firstly, we did not claim that Proposition 1 constitutes an Evidence Lower Bound (ELBO), as it is not parameterized by $\\overrightarrow z_t^{\\theta}$ and $\\overleftarrow z_t^{\\omega}$; rather, it serves as the precise likelihood /loss function. Secondly, the statement that the parametrized loss bears resemblance to the ELBO is initially posited in Theorems 1 and 2 in [1], and this statement holds true in our context as well.\n\n[1] Song, Maximum Likelihood Training of Score-Based Diffusion Models. 2021\n\n**Difference between the theoretical section and the work of [3]**\n\nWe want to emphasize that the convergence of optimal transport in **general domains and bounded domains are fundamentally different**. For instance, [1] delved into linear convergence on bounded domains, whereas [2] investigated sublinear convergence in general domains.\n\nConcerning the convergence of optimal transport with practically approximated marginals, [3] explored the **primal** Iterative Proportional Fitting (IPF) in a **general** space with a **sublinear** rate. In contrast, our work examines the convergence of the **dual** IPF in a **bounded** space with a **linear** rate. It is noteworthy that our study on the reflected Schr\u00f6dinger bridge also reveals the linear convergence of optimal transport on bounded domains, offering a more practical and **tangible impact and guiding the hyperparameter tuning of $\\varepsilon$**.\n\n[1] Guillaume Carlier (2022). On the Linear Convergence of the Multi-Marginal Sinkhorn Algorithm. \n\n[2] Ghosal and Nutz (2022) On the Convergence Rate of Sinkhorn\u2019s Algorithm.\n\n[3] Chen (2023) Provably Convergent Schrodinger Bridge with Applications to Probabilistic Time Series Imputation.\n\n\n**Assumption A4 is very strong**\n\nWe respectfully **disagree** with this argument. A4 is a mild assumption, akin to A3 in [1], quantifying the distance between distributions. However, these assumptions serve distinct purposes. [1] establishes convergence in score matching under the manifold hypothesis with A3 quantifying marginal distribution error. Our theory focuses on demonstrating the stability of Iterative Proportional Fitting (IPF) for Schr\u00f6dinger bridge regarding marginal distributions, with A4 modeling perturbations in the marginals.\n\n\nAs shown in Figure 3, standard IPF iterates require exact alternating projections such that $\\mu_{2k+1}=\\mu_{\\star}$ and $\\nu_{2k}=\\nu_{\\star}$ (see Eq.(6.5) in page 55 of [2]) in **every iteration instead of only the first iteration**. Computing the exact projections and obtaining the exact marginal $\\mu_{\\star}$ (or $\\nu_{\\star}$) at $2k+1$ (or $2k$) iterations for any $k=1,2,3, 4$ can be expensive in practice. To tackle this issue, we relax the requirement to approximated projections and marginals in Eq(14) such that $\\mu_{2k+1}=\\mu_{\\star, k+1}$ and $\\nu_{2k}=\\nu_{\\star, k}$, where the scale of perturbations is quantified by A4.\n\nConsistent observations were made in [3], which employed a geometric approach rather than a probabilistic one. Additionally, our approach allows for more flexible perturbations across different IPF iterations.\n\n**We consider our Assumption A4, which quantifies the perturbation, to be standard. Any identification of major errors in our proof would be greatly appreciated.**\n\n[1] De Bortoli (2022) -- Convergence of diffusion models under the manifold hypothesis.\n\n[2] Marcel Nutz (2022). Introduction to Entropic Optimal Transport. \n\n[3] Deligiannidis (2021), etc. Quantitative Uniform Stability of the Iterative Proportional Fitting Procedure. 2108.08129v2"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700328998255,
                "cdate": 1700328998255,
                "tmdate": 1700329285613,
                "mdate": 1700329285613,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IirxWsjyP9",
                "forum": "PyERBFX0wJ",
                "replyto": "Rsipqg1MMA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3755/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3755/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Fewer NFEs, ours v.s. Chen22, and others"
                    },
                    "comment": {
                        "value": "**Empirical justification of Fewer NFEs**\n\nExperimentally, we acknowledge that the class of Schrodinger bridge algorithms is expensive and may not provide compelling large-scale empirical results compared to techniques such as distillation. We have included section D.5 in the appendix to study the reduced NFEs in a simulated example, which shows that a well-optimized forward network significantly contributes to training the backward network compared to the baseline with the forward network weights being 0, which leads to an improved sample quality even in cases where NFE is set to 10 and 12. We wish to produce more examples in the final version.\n\n**Difference between our algorithm and the algorithm in Chen22**\n\nOur algorithm represents a natural yet crucial extension of Chen's algorithm for constrained generation on smooth domains (Chen22). The primary distinction lies in the incorporation of local time in the simulations and the Neumann and Robin boundary conditions in the derivation of reflected FB-SDEs. Additionally, we emphasize that working with bounded domains offers a **more favorable linear convergence rate** for guiding the hyperparameter tuning of $\\varepsilon$ in practice. Such a property **does not hold** for general domains in Chen22.\n\n\nMinor\n\n**missing one literature on bridge matching**\n\nThank you for bringing attention to the noteworthy work on bridge matching studies. We have incorporated this relevant contribution into the revised version.\n\n**If the algorithm accommodates dynamic thresholding**\n\nYes. Similar to the study of Corollary A.11 in [1], dynamic thresholding approximates the projection operator on hypercubes given a fine enough discretization and inner pointing drifts.\n\n[1] Lou (2023) Reflected Diffusion Models.\n\nWe sincerely hope we have addressed your detailed concerns and kindly request the reviewer to generously re-evaluate the work."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700329166605,
                "cdate": 1700329166605,
                "tmdate": 1700352294127,
                "mdate": 1700352294127,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "3PIDxneBoI",
            "forum": "PyERBFX0wJ",
            "replyto": "PyERBFX0wJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3755/Reviewer_qZiS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3755/Reviewer_qZiS"
            ],
            "content": {
                "summary": {
                    "value": "This paper generalizes shrodinger bridge models to constrained domains. The construction uses reflected brownian motion to construct the diffusion processes and an IPF procedure to fit the machine learning component. Compared with the previous work on score based reflected diffusion models, this method has the added benefit of being more generalizable across geometries and base distributions."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The proposed framework is technically sound and helps overcome fundamental issues with working with the more complex geometry of the base space.\n*  The technical constructions are constructed very cleanly with a full explication of the strengths and limitations of the underlying model.\n* The technical analysis showcase theoretical speedups for convergence, which can be important on more complicated geometric base spaces."
                },
                "weaknesses": {
                    "value": "* I wouldn't say that [1] doesn't necessarily propose approaches to deal with general geometries. In particular, they propose a diffeomorphic mapping scheme that should help generalization to other spaces although there are of course analytic blowups at edges/corners.\n* There could be more experimental results. In particular, the current results mostly show that the method works and can scale to high dimensions. Importantly, a more involved example (e.g. high dimensional simplex) would be needed to show that the method retains its niceties, as compared with [1].\n\n[1] Reflected Diffusion Models Lou and Ermon"
                },
                "questions": {
                    "value": "N/A"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3755/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698789509059,
            "cdate": 1698789509059,
            "tmdate": 1699636331719,
            "mdate": 1699636331719,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "l0Hzzrd8Mc",
                "forum": "PyERBFX0wJ",
                "replyto": "3PIDxneBoI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3755/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3755/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Refined description of reflected diffusion and more experiments."
                    },
                    "comment": {
                        "value": "We appreciate the reviewer for the insightful suggestions.\n\n**Reflected diffusion model may also tackle general domains.**\n\nWe have refined our description of reflected diffusion models in the abstract and conclusion sections. For example, instead of saying \"reflected diffusion models lack the flexibility to adapt to diverse domains\", we wrote \"reflected diffusion models may not easily adapt to diverse domains without the derivation of proper diffeomorphic mappings\" to emphasize the flexible constrained generation ability when diffeomorphic mappings are available.\n\n**More experimental results, including a high dimensional simplex result.**\n\nWe have included section D.4 to study the generation in the simplex domain, which obtained a similar promising performance compared with Lou'23; we also observe that a well-optimized forward network helps in reducing the number of function evaluations in a simulation example and results in a better sample quality in section D.5 \n\n\nWe sincerely hope we have addressed your concerns and kindly request the reviewer to re-evaluate the work."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700326782158,
                "cdate": 1700326782158,
                "tmdate": 1700326782158,
                "mdate": 1700326782158,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]