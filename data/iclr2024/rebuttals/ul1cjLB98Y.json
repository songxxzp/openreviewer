[
    {
        "title": "A Theory of Unimodal Bias in Multimodal Learning"
    },
    {
        "review": {
            "id": "H8bGTW3JQs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7698/Reviewer_T6g2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7698/Reviewer_T6g2"
            ],
            "forum": "ul1cjLB98Y",
            "replyto": "ul1cjLB98Y",
            "content": {
                "summary": {
                    "value": "This work initiates a theoretical study on the unimodal bias in multimodal learning, by analyzing the training dynamics. In particular, for linear networks, factors including a deeper fusion layer, stronger correlations between modalities and disparities in input-output correlations are identified as the causes of the unimodal bias."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The problem of building up a theoretical understanding of multimodal learning is urgent and significant.\n\nAnalyzing the training dynamic is an interesting and promising avenue for understanding unimodal bias. Such direction is intuitive due to relevant works on the implicit bias of neural networks, particularly on the training dynamics after zero training loss."
                },
                "weaknesses": {
                    "value": "**Unfocused writing:** the writing of this work is unfocused. From the title and the contents, I presume this work is theoretical paper. However, there is no formal presentation of the theoretical results (propositions/lemmas/theorems). It greatly obstructs a smooth understanding of the results for readers. After I read the main-text, I still can't tell which part is prioritized. There should be rigorous summaries of the theoretical results. Even a heuristic-level summary can be useful.\n\n**Restricted results:** the dynamic analysis only concerns linear networks, which is not popular in practice. Tools from the study of implicit bias of neural networks (for example, [1]) might be useful to deal with nonlinear networks.\n\n[1] What Happens after SGD Reaches Zero Loss? \u2013 A Mathematical Framework, Li et al 2021"
                },
                "questions": {
                    "value": "Though the contents might be interesting, the current writing style is certainly non-standard and disadvantageous to readability. In my opinion, the work needs a thorough rewriting for a clear summary and presentation of the theoretical results.\n\nStill, I'm curious the reason of the current writing. There seems to be plenty rigorous mathematical arguments in the appendix. Is there any difficulty preventing you from summarizing them as theorems?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7698/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697142708005,
            "cdate": 1697142708005,
            "tmdate": 1699636937610,
            "mdate": 1699636937610,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "G15YGUghY7",
                "forum": "ul1cjLB98Y",
                "replyto": "H8bGTW3JQs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7698/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7698/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer T6g2"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the questions and suggestions and would like to respond below.\n\n- Restricted results\n\n  We agree that our analytical analysis is on the learning dynamics of linear networks. Nonetheless, we empirically find that our results, derived for linear networks, carry over to two-layer early/late fusion ReLU networks when the target task is linear. The results of two-layer ReLU networks (plotted as crosses in Fig. 3b and 3c) closely follow the theoretical predictions and results of their linear counterparts.\n\n  Furthermore, we believe understanding behaviors of multimodal deep linear networks is a prerequisite to tackling multimodal nonlinear networks. Studying linear networks has restrictions in the network architecture, while studying nonlinear networks has its restrictions as well --- the amount of amenable questions in nonlinear networks are much fewer. Focusing on linear networks grants us opportunities to derive results that would be highly intractable in nonlinear networks. Thus our novelty lies in that we derive the time ratio of when two modalities get learned in terms of dataset statistics, network configuration, and initialization. This was never done analytically for any multimodal networks and is still intractable for nonlinear networks to the best of our knowledge.\n\n- Unfocused writing\n\n  Regarding our writing, we intended to strike a balance between formality and accessibility to serve the primal goal of letting as many readers understand our content as possible. We note that the other three reviewers explicitly mentioned our manuscript is well-written and clear as a strength. Propositions/lemmas/theorems is one of the mainstream writing styles for theory but not the only style. For instance, the following top conference/journal papers [1,2,3,4] did not write propositions/lemmas/theorems but did a great job in delivering theoretical contents. We have used style conventions common in the statistical physics of machine learning community.\n\n  Regarding our priorities, we would like to restate them here. We studied the duration of the unimodal phase, misattribution during the unimodal phase, and superficial modality preference in this paper. Among the three topics, the duration of the unimodal phase is prioritized. Our main theoretical result is the time ratio in Eq. (11-12), from which we learn a deeper fusion layer, a larger input-output correlation ratio, and stronger correlations between input modalities prolong the unimodal phase in the joint training of deep multimodal linear networks with small initialization. Should you find specific sections unclear or incoherent, please let us know. We will try our best to improve the clarity.\n\n  [1] Atanasov, et al. \"Neural Networks as Kernel Learners: The Silent Alignment Effect.\" ICLR. 2022.\n\n  [2] Canatar, et al. \"Spectral bias and task-model alignment explain generalization in kernel regression and infinitely wide neural networks.\" Nature communications. 2021.\n\n  [3] Gerace, et al. \"Generalisation error in learning with random features and the hidden manifold model.\" ICML. 2020.\n\n  [4] Saxe, et al. \"Exact solutions to the nonlinear dynamics of learning in deep linear neural networks.\" ICLR. 2014"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7698/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700270627369,
                "cdate": 1700270627369,
                "tmdate": 1700270874287,
                "mdate": 1700270874287,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pvjsuuhlma",
                "forum": "ul1cjLB98Y",
                "replyto": "G15YGUghY7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7698/Reviewer_T6g2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7698/Reviewer_T6g2"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the reply. I agree with you that writing theorems is not the only writing style. However, it's the mainstream style for theory, which means it's the most acceptable style for readers in the ICLR community. \n\nSince the criteria of accepting a paper also concerns how it fits the interests of the community, it's important to make most readers read smoothly. It's likely the current style is standard for statistical physics of machine learning, but I'm not familiar with statistical physics just as most of the ICLR community. The current writing makes it hard for me to judge the results, and I sincerely suggest the authors to consider changing the writing style, if you are submitting to mainstream ML conferences."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7698/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700660909959,
                "cdate": 1700660909959,
                "tmdate": 1700660909959,
                "mdate": 1700660909959,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Tijv65cDFd",
            "forum": "ul1cjLB98Y",
            "replyto": "ul1cjLB98Y",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7698/Reviewer_H94d"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7698/Reviewer_H94d"
            ],
            "content": {
                "summary": {
                    "value": "This paper theoretically study the unimodal bias in deep multimodal linear networks. They also derived the duration of the unimodal phase in terms of network configuration, and dataset statistics. The theoretical findings are supported by numerical simulations."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is clear and well-written \n2. The results for early fusion and intermediate fusion are novel\n3.  This paper explicitly characterizes an analytical relationship between unimodal bias, network configuration, and dataset statistics under simplified linear settings, and the implication from theory, fast-to-learn modality, is interesting.\n4.  The results are validated by numerical simulations."
                },
                "weaknesses": {
                    "value": "1. The author claims \"there is a scarce theoretical understanding of how unimodal bias arises and how it is affected by the network configuration, dataset statistics, and initialization\". However,  the work [1] mentioned in this paper already theoretically explored the rise of unimodal bias in a more realistic neural network setting, and their results somewhat reveal the relationship between the inferior performance of late-fusion networks with initialization and modality correlations. \n\n2. Moreover, there is another work [2] that has provided some analysis about insufficient learning of uni-modal features and proposed some methods to overcome the limitations of late-fusion networks.  In their study, they also discuss the effect of easy-to-learn features.\n\nTherefore, the novelty and contribution of this paper compared to the previous analysis is not clear to me, considering they studied more complex and realistic settings.\n\n[1] Modality Competition: What Makes Joint Training of Multi-modal Network Fail in Deep Learning? (Provably),  Huang et al, ICML 2022\n\n[2] On Uni-Modal Feature Learning in Supervised Multi-Modal Learning, Du et al, ICML 2023"
                },
                "questions": {
                    "value": "See weakness.\n\n1. For the data generation process,  it appears that only the correlation matrices are required. Are there specific assumptions made regarding $y$ that need to be clarified?\n2. The author claims \"we develop a theory of unimodal bias with deep multimodal linear networks.\" However, the frequent use of the approximation symbol ($\\approx$) in the appendix when deriving mean results raises questions about the rigor and precision of the theoretical justifications provided."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7698/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7698/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7698/Reviewer_H94d"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7698/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698445077680,
            "cdate": 1698445077680,
            "tmdate": 1699636937491,
            "mdate": 1699636937491,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8lU7GOb22J",
                "forum": "ul1cjLB98Y",
                "replyto": "Tijv65cDFd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7698/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7698/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer H94d"
                    },
                    "comment": {
                        "value": "## Comparison with Two Prior Works\n\nWe thank the reviewer for highlighting the two related papers and would like to provide a more detailed comparison between our work and theirs.\n\n- Huang et al studied two-layer late fusion network with smooth ReLU activation. We compare the differences between their and our problem setup in the table below. We make a stronger assumption on the activation function. However, in return, we are able to study deep networks with all three common fusion schemes trained with standard gradient descent, all of which were not covered in Huang et al.\n\n  Actually, a main motivation of our work came from the Limitations section in Huang et al, where they point out in their Limitations section that their analysis focused on two-layer late fusion networks and immediate future directions are to study **other fusion frameworks** and **deep neural networks**.\n\n  |                     | Huang et al                                                  | Ours                                     |\n  | ------------------- | ------------------------------------------------------------ | ---------------------------------------- |\n  | Network Depth       | Two-layer                                                    | **Deep**                                 |\n  | Activation function | **Smoothed ReLU**                                            | Linear                                   |\n  | Fusion scheme       | Late fusion                                                  | **Late, intermediate, and early fusion** |\n  | Training            | Fixing the second layer, gradient descent on only the first layer | **Standard gradient descent**            |\n\n  In terms of analytical results, Huang et al proved the occurrence of modality competition. We provide new insights into the process of this competition by studying the learning dynamics. We also derive an analytical expression to describe the influence of dataset statistics and network configurations on unimodal bias, for which Huang et al and other prior literature did not have theory-grounded answers.\n\n- Du et al proposed a solution to mitigate unimodal bias and validated its effectiveness with experiments, which are indeed not covered by our work due to a different scope. On the theory side, Du et al did not analytically study concrete multimodal neural networks. Instead, Du et al developed their theoretical argument by assuming that a multimodal task involves unimodal/paired features and their model learns features in descending order of predicting probability. Specifically, Du et al assumed that powerful features are learned first by citing 2 relevant papers in their footnote 5 on page 5. However, Du et al did not specify how to identify powerful features in a given dataset or why multimodal networks learn powerful features first. Since our work does not assume the dataset comes from a particular data generation process and we study concrete deep multimodal networks with various fusion scheme, we provide novel theory-grounded results that aim to complement the contributions from Du et al.\n\n  Thanks in particular for bringing up this recent paper, we have now added it to our references.\n\nIn summary, we believe our paper is not subsumed by the related work, and vice versa. We developed different analytical tools and unraveled different aspects of unimodal bias, which advance our understanding of unimodal bias altogether as a community.\n\n## Response to Questions\n\nWe also appreciate and would like to respond to the two questions raised.\n\n- Thank you for this note. We have added in our main text that we assume the input covariance $\\boldsymbol \\Sigma$ has full rank but make no further assumption on the correlation matrices. \n\n  Since the gradient descent dynamics of multimodal linear networks given in Eq. (3-4) only involve the correlation matrices $\\boldsymbol \\Sigma$ and $\\boldsymbol \\Sigma_{yx}$, knowing $\\boldsymbol \\Sigma$ and $\\boldsymbol \\Sigma_{yx}$ suffices to determine the learning trajectories. We have also added an Implementation Details section at the end of Appendix.\n\n- We acknowledge our frequent usage of $\\approx$ in the Appendix. To control approximations more explicitly, we are re-working through our derivations to include error correction terms and will post these updates as soon as we are done.\n\n  All our approximation signs are precisely equality when the initialization scale is taken to the limit of $0$. The approximations are also justified by our simulation results, which align well with theoretical predictions."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7698/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700270181244,
                "cdate": 1700270181244,
                "tmdate": 1700270181244,
                "mdate": 1700270181244,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lu6NXJilHC",
                "forum": "ul1cjLB98Y",
                "replyto": "8lU7GOb22J",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7698/Reviewer_H94d"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7698/Reviewer_H94d"
                ],
                "content": {
                    "title": {
                        "value": "Response to Rebuttal"
                    },
                    "comment": {
                        "value": "Thanks for the response.  Although the author compared the paper with existing analyses from various aspects, I still found the settings too simplistic and limited to the linear regime. Considering the weaknesses other reviewers pointed out, I have decided to keep my original score."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7698/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700691947381,
                "cdate": 1700691947381,
                "tmdate": 1700691947381,
                "mdate": 1700691947381,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qch0oBSkCj",
            "forum": "ul1cjLB98Y",
            "replyto": "ul1cjLB98Y",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7698/Reviewer_8NBJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7698/Reviewer_8NBJ"
            ],
            "content": {
                "summary": {
                    "value": "The paper focuses on a theoretical understanding of unimodal bia and  examines the effect of network architecture, dataset characteristics, and initialization factors. It reveals that while early fusion networks do not exhibit unimodal bias, this bias is noticeable in networks with intermediate and late fusion. Additionally, the paper quantifies the duration of the unimodal phase in these settings. To support these findings, the paper presents experimental data using numerical simulations conducted on two-layer ReLU networks and deep linear networks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper tackles an important problem of unimodal bias by investigating the unimodal bias theoretically and understanding the impact of various components such as network configuration, dataset statistics and initialization, which would be of interest to the community.\n- The paper was clear and well-written.\n- The supporting experimental evidence provides interesting insights into intermediate and late fusion for multimodal learning."
                },
                "weaknesses": {
                    "value": "- The paper presents an interesting study of unimodal bias in intermediate and late fusion contexts, yet the evidence supporting the absence of unimodal bias in early fusion remains unconvincing. The reliance on the Frobenius norm of weights as a metric for understanding unimodal bias seems reasonable, but the experiments regarding early fusion are limited to simplistic scenarios. These toy settings are insufficient to assert the absence of unimodal bias in early fusion.\n- All experiments are conducted with linearly separable data. The inclusion of experiments with XOR data, where early fusion fails to perform effectively, further casts doubt on the claims for early fusion. Considering that the main focus of the paper was to investigate the interplay between unimodal bias, network configuration, and dataset statistics, the scope and depth of the study become critical. When this research is contrasted with prior studies that have identified unimodal bias across a diverse range of datasets, the robustness of the current findings for complex, real-world scenarios appears uncertain.\n\n- Minor suggestions\n   - In equation 2, did you intend to use W^{tot} alongside y?.\n   - The latter part of the caption for figure 2, particularly the description following parts a-c, is somewhat confusing and could benefit from a more straightforward explanation."
                },
                "questions": {
                    "value": "Apart from the review, I have some additional questions:\n- Can the authors provide more details with respect to Fig 3e) \n- \u201cTwo-layer early fusion ReLU networks do not learn XOR features and can even fail to learn this task\u201d \u2013 can the authors comment and provide more reasoning about this observation wirth respect to the XoR experiment?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7698/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698785059106,
            "cdate": 1698785059106,
            "tmdate": 1699636937346,
            "mdate": 1699636937346,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YzoLfl9r3K",
                "forum": "ul1cjLB98Y",
                "replyto": "qch0oBSkCj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7698/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7698/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 8NBJ (part 1)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the questions and suggestions and would like to respond below.\n\n- Absence of unimodal bias in early fusion\n\n  We would like to clarify that we only claim that unimodal bias is absent in early fusion linear networks. And we strongly agree that we cannot claim the same for other nonlinear early fusion networks. For early fusion linear networks, we studied linearly separable data without losing generality since linear networks can only learn the linear component even if the dataset contains a nonlinear task. In addition to the one example in Fig 2, we also numerically computed the time ratio for four-layer early fusion linear networks in Fig 5b-d (purple circles), which are all close to 1.\n\n  It is also important to note that the learning curves for different modalities are not exactly the same in early fusion. By absence, we intend to mean that we see no conspicuous unimodal phase during training. Since early fusion linear networks learn both modalities during one transitional period, the time lag is bounded by the duration of the transitional period, which approaches zero when the initialization scale is taken to the limit of $0$. In comparison, the time lag is much longer in late fusion linear networks since two modalities are learned during two separated transitional periods with a unimodal phase in between. We can revise the wording \"absent\" if it is the word that particularly misleads readers.\n\n- Uncertain robustness for real-world scenarios\n\n  Our results provide a fundamental understanding of unimodal bias in deep linear networks, and in this specific setting, earlier fusion does shorten the unimodal phase. However, this analysis is only one part of a more complete picture: in nonlinear settings, several pre-fusion layers may be necessary to implement nonlinear transformations. This is why we include experiments on XOR, in order to show the additional factors that enter in nonlinear settings. We hope our work provides practitioners with some theoretical intuitions and theorists with a prerequisite to study unimodal bias in more complex scenarios.\n\n  We note that all theoretical approaches at present study simplified settings to obtain greater tractability, and this work is one step toward a more complete treatment. Our intuition and qualitative conclusions can still apply to complex scenarios. For instance, the idea that a shallower fusion layer enables modalities to cooperate more reciprocally and alleviates unimodal bias still holds in complex multimodal networks. This is because it remains true that the gradient descent updates for each layer share more common terms when the fusion layer is shallower.\n\n  We have also found our results consistent with empirical findings while containing more details for our specific setup. To give examples, multimodal networks were found to utilize different modalities at different speeds during training in [1,2], which is consistent with our time ratio results. [3] found that balancing the dataset mitigates unimodal bias, which is consistent with our conclusion that smaller disparities in input-output correlations reduce unimodal bias. \n\n  [1] Wu, et al. \"Characterizing and overcoming the greedy nature of learning in multi-modal deep neural networks.\" ICML. 2022.\n\n  [2] Wang, et al. \"What makes training multi-modal classification networks hard?.\" CVPR. 2020.\n\n  [3] Goyal, et al. \"Making the v in vqa matter: Elevating the role of image understanding in visual question answering.\" CVPR. 2017.\n\n- More comments on the XOR experiment\n\n  We thank the reviewer for their interest in our XOR experiment. We have added videos in the supplementary material and extended the Appendix H.2 on the XOR experiment. The videos show the time evolution of features corresponding to Fig 11.\n  \n  Late fusion ReLU networks learn the XOR and linear task better because the XOR branch of the network forms the XOR features in the two-dimensional space without being interfered by the linear branch. The features in the XOR branch preserve its independence from the linear branch as how the weights are independently initialized. However, early fusion ReLU networks favor particular feature directions in the three-dimensional space that correlate the most with the target output. The favorable feature directions tilt more towards the direction of the linear modality and are more prone to let the network be stuck in local minimum when the variance in the linear modality is larger."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7698/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700271215652,
                "cdate": 1700271215652,
                "tmdate": 1700423970475,
                "mdate": 1700423970475,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "eVDo21k784",
                "forum": "ul1cjLB98Y",
                "replyto": "qch0oBSkCj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7698/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7698/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 8NBJ (part 2: minor clarifications)"
                    },
                    "comment": {
                        "value": "## Minor clarifications\n\n- Notation in Eq 2\n\n  We checked that we do intend to write down $\\boldsymbol W^{\\text{tot}}{\\boldsymbol x}$. We re-write Eq 2 with more details below:\n  $$\n  \\hat y (\\boldsymbol x; \\boldsymbol W) = \\prod _{j=L_f+1}^L \\boldsymbol W^j \\left( \\prod _{i=1}^{L_f} \\boldsymbol W^i_A \\boldsymbol x_A + \\prod _{i=1}^{L_f} \\boldsymbol W^i_B \\boldsymbol x_B \\right) \n  \\equiv \\boldsymbol W^{\\text{tot}}_A \\boldsymbol x_A + \\boldsymbol W^{\\text{tot}}_B \\boldsymbol x_B \n  \\equiv \\boldsymbol W^{\\text{tot}} \\boldsymbol x  ,\n  $$\n  where\n  $$\n  \\boldsymbol W^{\\text{tot}}_A \\equiv  \\prod _{j=L_f+1}^L \\boldsymbol W^j \\prod _{i=1}^{L_f} \\boldsymbol W^i_A ,\n  $$\n\n  $$\n  \\boldsymbol W^{\\text{tot}}_B \\equiv \\prod _{j=L_f+1}^L \\boldsymbol W^j \\prod _{i=1}^{L_f} \\boldsymbol W^i_B  ,\n  $$\n\n  $$\n  \\boldsymbol W^{\\text{tot}} \\equiv \\left[ \\boldsymbol W^{\\text{tot}}_A, \\boldsymbol W^{\\text{tot}}_B \\right] .\n  $$\n\n- Caption of Fig 2\n\n  We apologize for inducing confusion and have changed the order of the caption for Fig 2. In Fig 2b and 2d, we plot the loss and total weight trajectories with respect to time (i.e., epoch) for a 2D simple case. The loss trajectory is the training mean square error loss. The total weights are $\\boldsymbol W^{\\text{tot}}_A, \\boldsymbol W^{\\text{tot}}_B$ as defined in Eq 2 and clarified above. Since we are assuming scalars $x_A, x_B$ in Fig 2, $\\boldsymbol W^{\\text{tot}}_A, \\boldsymbol W^{\\text{tot}}_B$ are also scalars and thus can be directly plotted.\n\n  Please let us know if this is still unclear or we got the question wrong.\n\n- Caption of Fig 3e\n\n  We realize it can be confusing that we plotted the time ratio twice in Fig 3b and 3e and want to re-try explaining.\n\n  Lines in Fig 3b and the entire Fig 3e are plotted with theoretical predictions. Specifically, the theoretical prediction here is a 2D corollary to the general time ratio in late fusion linear networks given in Eq 8. By plugging the standard 2D covariance matrix $\\boldsymbol\\Sigma = \\left[ \\sigma_A^2 , \\rho \\sigma_A \\sigma_B ; \\rho \\sigma_B \\sigma_A , \\sigma_B^2 \\right]$ and target output $y = x_A + x_B$ into the Eq 8, we obtain the time ratio in the special case of 2D inputs:\n  $$\n  \\frac{t_B}{t_A} = 1 + \\frac{\\frac{\\sigma_A^2}{\\sigma_B^2}-1}{1-\\rho^2} .\n  $$\n  We plot Fig 3b to show that our theoretical predictions align closely with simulations. We plot Fig 3e to show how the theoretical predictions vary with continuous values of correlation $\\rho$ and variance ratio $\\sigma_A/\\sigma_B$. We are open to the removal Fig 3e if most readers find it redundant.\n\n  The rationale for assuming 2D inputs in Fig 3 is that metrics for variances inside a modality and correlations across modalities are well-defined in 2x2 covariance matrices, which allows us to systematically sweep the variance and correlation parameters. Furthermore, we have found that covariance matrices with higher dimensions do not give rise to any qualitatively different behavior as long as the input dimension is not larger than the number of training samples."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7698/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700272973406,
                "cdate": 1700272973406,
                "tmdate": 1700693313526,
                "mdate": 1700693313526,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zfKunw2hsp",
            "forum": "ul1cjLB98Y",
            "replyto": "ul1cjLB98Y",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7698/Reviewer_W8DV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7698/Reviewer_W8DV"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies how deep linear networks with multiple pathways learn from data to produce a scalar output  when starting from small weights. The paper studies how the learning dynamics depend on layer in the network architechture when the modalities is fused in an additive manner, and find that with early fusion both modalities are learned (approx) simultaenously, whereas with late fusion the modality more correlated with the output is learned earlier in training."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well-written, the figures are clear, and the mathematical results appear to be sound. I did not carefully check the derivation of the time ratios for learning from the different modalities in the Appendix."
                },
                "weaknesses": {
                    "value": "The motivating phenomonom (unimodal bias) that one modality dominates at convergence is not addressed in the deep linear multimodal settings, as the manuscript studies the transient dynamics for when these modalities get learned (which the authors directly acknowledge in the intro). While the motivating phenomenon is well motivated, developing an improved understanding of the transient dynamics was not well-motivated. It would be helpful if the manuscript could comment/discuss how the analysis of the transient in the deep linear network setting could inform the phenomemon of unimodal bias at convergence in practice. I also feel that the paper title could better reflect the contents of the paper.\n\nDo the results extend to the multitask case where output y is a vector?"
                },
                "questions": {
                    "value": "The authors considered architectures of equivalent depth between pathways. How do the result change if these depths differ? \n\nHow do the weights evolve in the pre and post fusion layers?\n\nWhen the paper says: \"In essence, an early fusion point allows the weaker modality to benefit from the stronger modality's learning in the post-fusion layers:\" Are there settings where this can be harmful as well, or would the larger scale of the weights always help learning?\n\nMinor: \n\nWhat matrix norm is being used throughout the paper? It should be clarified (For example in Eq 7, Eq 9 etc). Apologies if I missed it.\nDo the results apply to more complicated covariance matrices? It seems like diagonal input covarainces were studied, and 2x2 matrices.\n\nDefine the product notation used for a product over weight matrices (for example in Eq 2)\n\nIt was unclear the experimental details used. For example, were there a finite amount of inputs used, or were inputs drawn according to the covariance structure every batch (In Fig 2,3; for example). The paper mentioned full-batch SGD but the details were not provided (and could not find in appendix.)\n\nIn sect. 3.2.3 unclear why it is ideal for modality learned first to lead to larger decrease in loss.\n\nWording \" a smaller initialization scale exacerbates the impediment to learning modality A compared to modality\nB, yielding a larger time ratio\" is unclear.\n\nIt was a bit strange to add in new results in the discussion section.\n\nWhy do the results require a small initialization?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7698/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7698/Reviewer_W8DV",
                        "ICLR.cc/2024/Conference/Submission7698/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7698/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698870110255,
            "cdate": 1698870110255,
            "tmdate": 1700689453328,
            "mdate": 1700689453328,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "WGYqA1Z4Q3",
                "forum": "ul1cjLB98Y",
                "replyto": "zfKunw2hsp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7698/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7698/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer W8DV (part 1)"
                    },
                    "comment": {
                        "value": "We appreciate your reviewing our manuscript in great depth and detail. We have taken your constructive suggestions and updated our manuscript. Additionally, we respond to the questions and highlight our edits below.\n\n- Motivation of studying transient unimodal bias\n\n  Thank you for the important comment, we believe we in fact do study a situation that is relevant to the non-transient setting, and have added experiments to demonstrate why. In particular, we note that in practical settings, networks can overfit such that their training error differs from test error. As shown in new experiments in the revision Fig 9d, an overparameterized late fusion linear network learns the faster-to-learn modality first and overfits this modality during the unimodal phase when the training loss plateaus but the generalization error increases. In this case, there is a dilemma between overfitting one modality and underfitting the other. Under optimal early stopping on the generalization error, training terminates right after the first modality is learned, and the network has not learned the second modality, yielding a model with a strong and **permanent** unimodal bias. If training terminates after both modalities are learned, the network has overfitted the first modality, which can yield a generalization error higher than that in early stopping. Thus overfitting is a mechanism that can convert the transient unimodal phase to a generalization deficit and permanent unimodal bias.\n\n  An additional note is that even in underparameterized networks, the transient unimodal phase will lead to a bias at convergence when input modalities have collinearity. In the collinear input case, late and intermediate fusion networks learn to fit the output with only the faster-to-learn modality and never learn the rest. Such multimodal networks are unable to make predictions in the absence of certain modalities, which is a common task in multimodal learning.\n\n- Paper title could better reflect the contents of the paper.\n\n  We regret that our title failed to reflect the contents well. We are open to changing the title should the system allow it.\n\n- Extension to vector output case.\n\n  In a multimodal multitask setup, late and intermediate fusion linear networks learn every task from every modality with a unique timescale. This can result in multiple phases in the vector output case, where the networks exhibit qualitatively similar behaviors. For instance, there will be at most 4 transitional periods when there are 2 input modalities and the output is 2-dimensional; see [image](https://postimg.cc/G4Hq1Dmr).\n\n  We will discuss the vector output case in the final revision.\n\n- Different depth between pathways.\n\n  Thank you for the useful suggestion, we have derived the time ratio for unequal depths and added it to the Appendix. The time ratio is given in Eq 57-58.\n\n  The new factor taken into consideration is that deeper linear networks learn faster compared to shallower linear networks with the same initialization per layer. The reason is that small initialization accumulates through multiplication in deep linear networks, making the gradient update around initialization very small. The qualitative conclusions derived for networks with equal depth between pathways still hold for unequal depth cases. Additionally, a larger difference in the pre-fusion layer depth can prolong the unimodal phase."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7698/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700269462539,
                "cdate": 1700269462539,
                "tmdate": 1700412624650,
                "mdate": 1700412624650,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8DQqvXnkTQ",
                "forum": "ul1cjLB98Y",
                "replyto": "zfKunw2hsp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7698/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7698/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer W8DV (part 2)"
                    },
                    "comment": {
                        "value": "- How do the weights evolve in the pre and post fusion layers?\n\n  We added a section on Feature Evolution in Appendix E and uploaded videos in supplementary material to elaborate on this.\n\n  The weights in linear networks stay rank-one and aligned as described in Eq 39. The first-layer weights in linear networks are the features and have different structures depending on the task. Intermediate layers stay aligned with their consecutive layers and only evolve in scale. Our added Appendix section discusses the specifics of the first-layer weight evolution in early, intermediate, and late fusion linear networks.\n\n  As for the norm of layers, the conservation law given in Eq 36 hold true during training. Assume modality A is learned first. In intermediate fusion networks, the norm of post-fusion layers and pre-fusion layers of modality A grow to $|| \\boldsymbol \\Sigma_{yx_A} \\boldsymbol \\Sigma_A ||^{\\frac1L}$ during the first transitional period. After a unimodal phase, the norm of pre-fusion layers of modality B grows to $u_B^\\infty$ while norm of post-fusion layers adjusts to $u^\\infty$ and norm of pre-fusion layers of modality A adjusts to $u_A^\\infty$ where\n  $$\n  u_A^\\infty = w_A^{\\frac1L} \\left[ 1+ \\left(\\frac{w_B}{w_A}\\right)^{\\frac2{L_f}} \\right]^{-\\frac{L-L_f}{2L}}\n  $$\n\n  $$\n  u_B^\\infty = w_B^{\\frac1L} \\left[ 1+ \\left(\\frac{w_A}{w_B}\\right)^{\\frac2{L_f}} \\right]^{-\\frac{L-L_f}{2L}} \n  $$\n\n  \n  $$\n  u^\\infty = \\left( w_A^{\\frac2{L_f}} + w_B^{\\frac2{L_f}} \\right)^{\\frac{L_f}{2L}}\n  $$\n  We use $w_A, w_B$ to denote the norm of the converged total weights for modality A,B, which are the two blocks in the converged total weights $\\boldsymbol \\Sigma_{yx} \\boldsymbol \\Sigma$.\n\n- When the paper says: \"In essence, an early fusion point allows the weaker modality to benefit from the stronger modality's learning in the post-fusion layers:\" Are there settings where this can be harmful as well, or would the larger scale of the weights always help learning?\n\n  We did not mean to imply that the larger scale of weights always helps learning, only that it speeds up learning in the feature learning regime. We note that this may or may not aid generalization depending on the specifics of the task. The unimodal phase arises because different modalities are learned at different speeds. The weaker modality benefits from the stronger modality's learning in the post-fusion layers because the difference in speeds is brought closer, shortening the unimodal phase. However, the larger scale of weights alone cannot lead to conclusions on the length of the unimodal phase. We will clarify these points in the revision.\n\n- Do the results apply to more complicated covariance matrices?\n\n  Yes! Our results apply to arbitrary covariance matrices. We made no assumptions on the input covariances for our derivations. In the figures, our simulations are done with 2x2 covariance matrices, but they are not always diagonal. We varied the correlation coefficient $\\rho$ in Fig 3 and Fig 5b. The covariance matrix is not diagonal for any $\\rho \\neq 0$. It is an important part of our results that a stronger correlation between input modalities prolongs the unimodal phase.\n\n  The reason for using 2x2 covariance is that metrics for variances inside a modality and correlations across modalities are very clear in 2x2 covariance matrices, which allows us to systematically sweep the variance and correlation parameters in Fig 3 and 5. Furthermore, we have found that covariance matrices with higher dimensions do not give rise to any qualitatively different behavior as long as the input dimension is not larger than the number of training samples."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7698/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700269768765,
                "cdate": 1700269768765,
                "tmdate": 1700269957404,
                "mdate": 1700269957404,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "01LfhW2PMt",
                "forum": "ul1cjLB98Y",
                "replyto": "zfKunw2hsp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7698/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7698/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer W8DV (part 3: minor clarifications)"
                    },
                    "comment": {
                        "value": "## Minor Clarifications\n\n- Norm notation\n\n  We added a footnote in our manuscript clarifying that we use $|| \\cdot ||$ to denote the L2 norm of a vector or the Frobenius norm of a matrix.\n\n- Product notation\n\n  We added a definition to clarify that we abuse the product notation to represent the ordered product of matrices with the largest index on the left and smallest on the right. For example, $\\prod_{i=1}^L \\boldsymbol W^i = \\boldsymbol W^L \\boldsymbol W^{L-1} \\cdots \\boldsymbol W^1$.\n\n- Experimental details\n\n  We added an Implementation Details section at the end of Appendix. The amount of samples for all experiments is 4096. We randomly draw 4096 input data points from a normal distribution with zero mean and a certain covariance matrix. The dataset is fixed for a single run of training a network. We use the regular gradient descent on full batch (batchsize=4096) with learning rate 0.04.\n\n- Why it is ideal for modality learned first to lead to larger decrease in loss?\n\n  We apologize for the inappropriate wording of \"ideal\" and have deleted this sentence from the manuscript.\n\n  The comparison we intend to make is between the two cases: (i) the network learns modality A first, goes through a unimodal phase, and learns modality B; (ii) the network learns modality B first, goes through a unimodal phase, and learns modality A. Assume learning modality A yields a larger decrease in loss. Then we consider case (i) to be better than (ii), since one would have a better model if training is terminated during the unimodal phase. However, we acknowledge that both cases are not ideal in the sense that the unimodal phase exists.\n\n- Unclear wording: \"a smaller initialization scale exacerbates the impediment to learning modality A compared to modality B, yielding a larger time ratio.\"\n\n  We have re-phrased this sentence and adopted a more direct wording: \"Even amongst cases that all fall into the rich feature learning regime, the initialization scale has an effect on the time ratio, with a larger time ratio for a larger initialization scale.\"\n\n- Why do the results require a small initialization?\n\n  From the technical side, our derivations utilized the conservation law $\\boldsymbol W_1 \\boldsymbol W_1^\\top = \\boldsymbol W_2^\\top \\boldsymbol W_2$ between layers, which is true for small initialization but often untrue for large initialization. We will clarify in the final revision.\n\n  From the motivation side, the neural tangent kernel community extensively has studied that neural networks with large initialization are in the lazy learning regime and networks with small initialization are in the rich feature learning regime; see [1,2]. In many settings where representation learning is important, neural networks generalize better when trained in the rich rather than lazy regime. Practical neural network systems often learn structured representations. We thus study networks with small initialization to understand this rich feature learning behavior.\n\n  [1] Woodworth, et al. \"Kernel and rich regimes in overparametrized models.\" COLT. 2020.\n\n  [2] Chizat et al. \"On lazy training in differentiable programming.\" NeurIPS. 2019."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7698/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700269907396,
                "cdate": 1700269907396,
                "tmdate": 1700269907396,
                "mdate": 1700269907396,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iUYTaITPyD",
                "forum": "ul1cjLB98Y",
                "replyto": "01LfhW2PMt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7698/Reviewer_W8DV"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7698/Reviewer_W8DV"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their detailed reply and updated revision. The authors have addressed my questions and I believe have improved their manuscript. I have updated my score to an accept from a borderline accept to reflect this.\n\nAs a minor clarification, regarding, *\"The new factor taken into consideration is that deeper linear networks learn faster compared to shallower linear networks with the same initialization per layer. The reason is that small initialization accumulates through multiplication in deep linear networks, making the gradient update around initialization very small\"*, why would deeper linear networks learn faster with a small initialization?"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7698/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700689432477,
                "cdate": 1700689432477,
                "tmdate": 1700689432477,
                "mdate": 1700689432477,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Ynk2FPq8N2",
                "forum": "ul1cjLB98Y",
                "replyto": "zfKunw2hsp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7698/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7698/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks and a minor clarification"
                    },
                    "comment": {
                        "value": "Thank you very much for reviewing our rebuttal and updating the acore!\n\nAnd thanks again for a sharp catch in our response! The quoted sentence was indeed a slip-up. What we intend to write is *\"deeper linear networks learn slower compared to shallower linear networks with the same initialization per layer\"*. As indicated by Eq 44, the time when the first modality gets learned scale with $u_0^{2-L}$. Since the initialization scale $u_0$ is usually smaller than 1, the time increases with larger depth $L$. Hence, with $u_0$ held fixed, a deeper linear network experiences a longer plateau before its first transitional period. This has been studied by prior literature on regular linear networks. Figure E1(a) in [1] and Figure S1 in [2] both illustrate this point.\n\n[1] Atanasov, et al. \"Neural Networks as Kernel Learners: The Silent Alignment Effect.\" ICLR. 2022.\n\n[2] Saxe, et al. \"A mathematical theory of semantic development in deep neural networks.\" PNAS. 2019."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7698/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700695584531,
                "cdate": 1700695584531,
                "tmdate": 1700695644567,
                "mdate": 1700695644567,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]