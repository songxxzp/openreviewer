[
    {
        "title": "Be Aware of the Neighborhood Effect: Modeling Selection Bias under Interference for Recommendation"
    },
    {
        "review": {
            "id": "sKWDmdxYL3",
            "forum": "52fz5sUAy2",
            "replyto": "52fz5sUAy2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8755/Reviewer_1Wkk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8755/Reviewer_1Wkk"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors introduce a new debias problem under the causal inference framework for handling selection bias in recommendation systems in the presence of the neighboring effect: when the potential outcome for one user-item pair does vary with the treatments assigned to other user-item pairs. The potential outcome, treatment and a new ideal loss are defined so as to include both the selection bias AND the neighborhood interference effect. Follow two new estimators to estimate the newly designed ideal loss: neighborhood inverse propensity score (N-IPS) and neighborhood doubly robust (N-DR)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is well written and quite enjoyable to read. \n\nThe newly proposed ideal loss and estimators are well theoretically investigated:\n\n-The difference between the two losses with and without neighborhood effect (Theorem 2) is studied. \n\n-The new ideal loss is shown as identifiable (Theorem 1). \n\n-The first proposed estimator tackles the case when $\\bold{g}_{u,i}$, the treatment representation vector, is a continuous probability density via a smoothing symmetric kernel function (ex: Epanechnikov or Gaussian kernels). The N-DR estimator is derived similarly.  -Bias and variance of both estimators are computed with tail and generalization error bounds provided (Theorem 5). \n\nThen, it is shown how to estimate the propensity score for the joint effect of the treatment and the treatment representation vector for the neighboring effect.  \n\nThe approach is accompanied first with experiments on semi-synthetic data (based on MovieLens 100K) to: \n1) assess whether the proposed estimators provide a more accurate estimation for the ideal loss compared to the state-of-the-art methods when neighboring interference is observed.  \n2) measure the influence of the neighborhood effect strength on the estimation accuracy.\nOn the semi-synthetic dataset, for all interference strengths, N versions of DR or MRDR are giving better accuracy (lower relative error) than DR and MRDR but also are less harmed by the interference strength for 6 different methods of predicting the ratings.  \n\nReal-world experimentation is done on Coat, Yahoo! R3 and KuaiRec for which MSE, AUC and NDCG are evaluated N-* are usually in the 3 best results."
                },
                "weaknesses": {
                    "value": "I would develop some explanations for the experimental part even in the appendix. Cf. questions. \n\nMinor, typos:\n\n-p.2: \u201cIn addition, we introduces\u201d\n\n-p.3: \u201c... both \u2026 leads\u201d\n\n-p.9: \u201cFor the methods require propensity\u201d, \u201cthe three choice\u201d, \u201cGuassian\u201d, \u201con the a prior\u201d\n\n-p.10: \u201cEarly literature focus\u201d\n\nAlso, when Figure 1 is first introduced in Introduction section, we don\u2019t yet have the preliminaries content and all elements are not fully defined such as $\\bold{g}_{u,i}$ which can make it difficult to understand at first sight."
                },
                "questions": {
                    "value": "Q1: In practice, how do you specify the probability density function of $\\bold{g}$?\n\nQ2: In practice, what is the best choice between Epanechnikov and Gaussian kernels? Experiments seem to have been done only with the Gaussian kernel.\n\nQ3: Can you please detail again for the semi-synthetic experiments how do you define the set of $\\mathcal{N)_{u,i}$ as the set of historical user and item interactions for the neighbors of (u,i) who do have an influence on user u? \n\nQ4: How does $p_{u,i} = p \\alpha^{max(0,4-r_{u, i})}$ account for the neighboring effect too?\n\nQ5: c is chosen to be the median of all g_u,i according to p. 7 but g_u,i is also defined depending on c. Can you please explain?\n\nQ6: Does KuaiRec specify the MAR and MAR watching ratio records? If not, how to measure the neighboring effect?\n\nQ7: How p is defined in $p_{u,i} = p \\alpha^{max(0,4-r_{u, i})}$ is explained in p. 28. Can you please elaborate: \u201cwe adjust p to ensure the total observed sample is 5% of the entire matrix\u201d?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8755/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697998841392,
            "cdate": 1697998841392,
            "tmdate": 1699637098745,
            "mdate": 1699637098745,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hagAr5MCiA",
                "forum": "52fz5sUAy2",
                "replyto": "sKWDmdxYL3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8755/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8755/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Please kindly find our concise and clear rebuttal below for addressing your current concerns [Q1-Q4]"
                    },
                    "comment": {
                        "value": "We sincerely appreciate the reviewer\u2019s great efforts and insightful comments to improve our manuscript. In below, we address these concerns point by point and try our best to update the manuscript accordingly.\n\n> **[Q1] In practice, how do you specify the probability density function of $\\boldsymbol{g}$.**\n\n**Response:** We thank the reviewer for the comment. In our experiments, we choose the one with the better debiasing performance among **a uniform distribution or a Dirichlet distribution** for $\\boldsymbol{g}. In practice, some other distributions can also be chosen.\n\n> **[Q2] In practice, what is the best choice between Epanechnikov and Gaussian kernels? Experiments seem to have been done only with the Gaussian kernel.**\n\n**Response:** We thank the reviewer for the question. Yes, in our original manuscript, the experiments are only done with Gaussian kernel. For exploring and comparing the Epanechnikov and Gaussian kernels, we add the experiments that our methods adopting Epanechnikov kernel on all three dataset (Page 8, Table 2) in our revised manuscript. The results are shown below, the best two results are bolded in IPS based, DR-JL based and MRDR-JL based methods, respectively.\n\n|Dataset| |Coat| || |Yahoo! R3| || |KuaiRec| |\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n|Method|MSE $\\downarrow$|AUC $\\uparrow$|NDCG@5 $\\uparrow$||MSE  $\\downarrow$|AUC $\\uparrow$|NDCG@5 $\\uparrow$||MSE  $\\downarrow$|AUC $\\uparrow$|NDCG@5 $\\uparrow$| \n|N-IPS [LR, Gaussian]|0.212|0.742|**0.678**||0.226|0.693|**0.664**||0.092|**0.796**|**0.585**|\n|N-IPS [LR, Epanechnikov]|0.224|**0.746**|0.645||0.242|**0.703**|**0.673**||0.094|**0.794**|**0.582**| \n|N-IPS [NB, Gaussian]|**0.206**|0.744|**0.648**||**0.196**|**0.693**|0.658||**0.049**|0.785|0.579|\n|N-IPS [NB, Epanechnikov]|**0.210**|**0.753**|0.646||**0.197**|0.685|0.653||**0.047**|0.755|0.562|\n||\n|N-DR-JL [LR, Gaussian]|0.231|0.731|**0.651**||0.247|**0.698**|**0.664**||0.113|0.779|0.537|\n|N-DR-JL [LR, Epanechnikov]|0.235|0.741|**0.655**||0.251|**0.693**|**0.663**||0.108|**0.784**|0.552|\n|N-DR-JL [NB, Gaussian]|**0.204**|**0.748**|0.650||**0.198**|0.691|0.653||**0.049**|0.778|**0.574**|\n|N-DR-JL [NB, Epanechnikov]|**0.209**|**0.744**|0.648||**0.191**|0.681|0.637||**0.046**|**0.786**|**0.570**|\n||\n|N-MRDR-JL [LR, Gaussian]|0.217|0.728|**0.662**||0.252|**0.697**|**0.666**||0.107|0.785|0.539|\n|N-MRDR-JL [LR, Epanechnikov]|0.233|0.734|**0.656**||0.253|**0.695**|**0.666**||0.097|0.791|0.560|\n|N-MRDR-JL [NB, Gaussian]|**0.208**|**0.742**|0.651||**0.206**|0.694|0.663||**0.045**|**0.793**|**0.583**|\n|N-MRDR-JL [NB, Epanechnikov]|**0.207**|**0.756**|0.635||**0.194**|0.690|0.644||**0.044**|**0.802**|**0.587**|\n||\n\nAdopting either the Gaussian kernel or the Epanechnikov kernel in our methods is able to stably outperform the baseline methods in all metrics and these two kernels yield similar performance of our methods.\n\n> **[Q3] Can you please detail again for the semi-synthetic experiments how do you define the set of $\\mathcal{N}_{u,i}$ as the set of historical user and item interactions for the neighbors of (u,i) who do have an influence on user u?**\n\n**Response:** We thank the reviewer for pointing out this issue. In the semi-synthetic experiment, **we suppose that all the $o_{u, i'}$ which $i' \\neq i$ affects $r_{u, i}$.** The intuition behind is that users who have seen better movies than the current movie are more likely to have a low rating towards the current movie than the average rating. It is intuitive and is verified in the case study (Appendix I) in our revised manuscript. **Meanwhile, we suppose that all the $o_{u', i}$ which $u' \\neq u$ affects $r_{u, i}$** because users may subjectively believe that movies that have been watched more times are of better quality. So we suppose $\\mathcal{N}_{u, i}$ is {$({u'}, i')\\neq (u, i) \\mid  u'=u~ \\text{or}~ i'=i$} in the semi-synthetic experiment.\n\n> **[Q4] How does $p_{u, i}=p \\alpha^{\\max \\left(0, 4-r_{u, i}\\right)}$ account for the neighboring effect too?**\n\n**Response:** We thank the reviewer for the question. In fact, $p_{u, i}=p \\alpha^{\\max \\left(0, 4-r_{u, i}\\right)}$ only taking MNAR effect into account. Neighborhood effect is considered by splitting $r_{u, i}$ into $r_{u, i}(1, g)$, introducing $\\pi_{g}$ and setting the ideal loss to $\\tilde{\\mathcal{L}}_\\mathrm{ideal}(\\hat{\\mathbf{R}})$."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700738511023,
                "cdate": 1700738511023,
                "tmdate": 1700738541189,
                "mdate": 1700738541189,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LO0M03nyJ6",
                "forum": "52fz5sUAy2",
                "replyto": "sKWDmdxYL3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8755/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8755/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Please kindly find our concise and clear rebuttal below for addressing your current concerns [Q5-Q7, W1]"
                    },
                    "comment": {
                        "value": "> **[Q5] c is chosen to be the median of all g_u,i according to p. 7 but g_u,i is also defined depending on c.**\n\n**Response:** We thank the reviewer for pointing out this issue and we apologize for the **typo** here. Actually, $c$ is chosen to be the median of all\n$ \\sum_{ (u',i') \\in N_{(u,i)} } o_{u',i'} $. We have fixed this typo in our revised manuscript.\n\n> **[Q6] Does KuaiRec specify the MAR and MAR watching ratio records? If not, how to measure the neighboring effect?**\n\n**Response:** We thank the reviewer for the useful question. We manually split the MNAR and MAR set in KuaiRec dataset. Because KuaiRec is a fully exposed dataset, we uniformly sample 5% watching ratio records for each user to generate the MAR set. Meanwhile, we adopt the same technic as semi-synthetic experiments to manually set a propensity for each user-item pair to sample the MNAR set.\n\n> **[Q7] Can you please elaborate: \u201cwe adjust p to ensure the total observed sample is 5% of the entire matrix\u201d?**\n\n**Response:** We thank the reviewer for the detailed question. As reviewer mentioned, the definition of $p_{u, i}$ is $p_{u, i} = \\textcolor{red}{p} \\alpha^{\\max \\left(0, 4-r_{u, i}\\right)} \\cdot m_{u, i}$, where $\\textcolor{red}{p}$ is a pre-specified constant. The expected observation number of user-item pair is $\\sum_{(u,i) \\in \\mathcal{D}} p_{u, i}$. Following the previous studies [1-2], we adjust $\\textcolor{red}{p}$ to ensure $\\sum_{(u,i) \\in \\mathcal{D}} p_{u, i} = 0.05 * |\\mathcal{D}|$ for different mask number $ m_{u, i}$.\n\n> **[W1] Some typos and unclear Figure 1.**\n\n**Response:** We thank the reviewer for pointing out some typos and unclear figure in our original manuscript. In our revised manuscript, we fixed those typos and add a notation table in Figure 1 to improve the readability.\n\n***\n**We hope the above discussion will fully address your concerns about our work.** We really appreciate your insightful and constructive comments to further help us improve the quality of our manuscript. Thank you!\n***\n\n**Reference**\n\n[1] Tobias Schnabel et al. Recommendations as Treatments: Debiasing Learning and Evaluation. ICML 16.\n\n[2] Xiaojie Wang et al. Doubly Robust Joint Learning for Recommendation on Data Missing Not at Random. ICML 19."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700738655215,
                "cdate": 1700738655215,
                "tmdate": 1700739450336,
                "mdate": 1700739450336,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1aKlXuYeDj",
            "forum": "52fz5sUAy2",
            "replyto": "52fz5sUAy2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8755/Reviewer_TJ54"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8755/Reviewer_TJ54"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses the combined impact of selection bias and neighborhood effects in recommender systems.\\\nIt introduces a novel approach to represent neighborhood effects as interference, alongside a treatment representation.\\\nThe paper establishes a theoretical connection with existing methods, showing that their approach achieves unbiased learning in the presence of both selection bias and neighborhood effects.\\\nExperimental validation is conducted on semi-synthetic and real-world datasets to demonstrate the effectiveness of the proposed methods."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is comprehensive and provides a theoretical analysis.\n- the paper provides a robust theoretical foundation for its proposed methods. It derives unbiased estimators for the ideal loss, establishes a connection to prior methods that do not account for neighborhood effects, and includes analyses of tail bounds and generalization error bounds for the proposed estimators.\n\n2. The experiment is thorough.\n- the paper substantiates its claims with empirical results from experiments conducted on both semi-synthetic and real-world datasets. These experiments demonstrate that the proposed estimators outperform previous methods when neighborhood effects are present, underscoring the practical utility and effectiveness of the proposed approach."
                },
                "weaknesses": {
                    "value": "1. Motivation is weak\n- why do we need to eliminate the neighborhood effect?\n- for example, existing recommenders can consider the neighborhood effect in the training phase and make recommendations with the neighborhood effect (e.g., similar users have similar embedding and thus get similar recommendations).\n- Therefore, the neighborhood effect can be a rich information source for model training.\n\n2. Assumptions are not realistic.\n- why $r_{u,i}$ is affected by $o_{u,i}$? In my opinion, $o_{u,i}$ is just a treatment to observe $r_{u,i}$, and does not affect the 'value' of  $r_{u,i}$. (i.e., the value of $r$ is affected only by $x$ and observed only when $o=1$).\n- If $r_{u,i}$ is affected by $o_{u,i}$, i think the assumption 3 is not hold.\n- In the paper, g is a scalar (a continuous variable), not a representation vector.\n\n3. Minor concerns\n- In the real-world experiment, the authors use 5% MAR test ratings for the propensity estimation. This process is unrealistic.\n- In the semi-synthetic experiment, the definition of neighborhood effect is the number of neighbor pairs with $o >= c$. what does it mean? Since $o \\in {0,1}$, i cannot understand the c is chosen to be the median of all $g$."
                },
                "questions": {
                    "value": "Please refer to the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed.",
                        "Yes, Responsible research practice (e.g., human subjects, data release)"
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8755/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8755/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8755/Reviewer_TJ54"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8755/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698155491354,
            "cdate": 1698155491354,
            "tmdate": 1699637098607,
            "mdate": 1699637098607,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "t9W8fQRPfa",
                "forum": "52fz5sUAy2",
                "replyto": "1aKlXuYeDj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8755/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8755/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Please kindly find our concise and clear rebuttal below for addressing your current concern [W1]"
                    },
                    "comment": {
                        "value": "We sincerely appreciate the reviewer\u2019s great efforts and insightful comments to improve our manuscript. In below, we address these concerns point by point and try our best to update the manuscript accordingly.\n\n**1. Motivation**\n> **Why do we need to eliminate the neighborhood effect?** For example, existing recommenders can consider the neighborhood effect in the training phase and make recommendations with the neighborhood effect (e.g., similar users have similar embedding and thus get similar recommendations). Therefore, the neighborhood effect can be a rich information source for model training.\n\n**Response:** The reviewer has raised an important point. We hope the following clarification addresses your concerns about the motivation.\n\n-\tWe agree with the reviewer that modern recommender systems consider the neighborhood effect in the training phase and make recommendations with the neighborhood effect. \n-\tNonetheless, we know that **users tend to behave similarly to the others in a group, even if doing so goes against their own judgment**, making the feedback in the observed data not reflect the true preferences of the users [1].\n-\tWe also notice another related work [2] referenced by **Reviewer qJ35,** in which the authors discuss the presence of interference in debiasing user feedback for the learning-to-rank (LTR) task.\n\nMoreover, **we also add a real-world example using the KuaiRec dataset demonstrating the necessity of eliminating the neighborhood effect for debiased recommendation** in Appendix I, for a clearer comprehension of the motivation in this paper.\n\n-\tFor the same item interacted with different users, we use the user social network information to compute and compare the feedback similarity of friends and non-friends. The results are shown in Figure 3(a). **Compared with the non-friend user pairs, it is clear that there is a higher similarity in the ratings of friends for the same item.**\n\n-\tFor a given user with different items, we use timestamps to first select the $K$ most recent items this user has interacted with, then compute the average video viewing time among all users on the fully exposed dataset. **As shown in Table 3 and Figure 3(b), we found that the lower the average viewing time of the items the user recently interacted with, the better the user's feedback on the current item will be, and vice versa.** Such a feedback mechanism is reasonable: when users have previously observed more low-quality videos, they will provide better feedback on the current items."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700739265140,
                "cdate": 1700739265140,
                "tmdate": 1700739265140,
                "mdate": 1700739265140,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BXZXyGux0F",
                "forum": "52fz5sUAy2",
                "replyto": "1aKlXuYeDj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8755/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8755/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Please kindly find our concise and clear rebuttal below for addressing your current concerns [W2-W3]"
                    },
                    "comment": {
                        "value": "**2. Assumptions**\n> **[W2.1] why $r_{u, i}$ is affected by $o_{u, i}$ ? In my opinion, $o_{u, i}$ is just a treatment to observe $r_{u, i}$ and does not affect the 'value' of $r_{u, i}$. (i.e., the value of $r$ is affected only by $x$ and observed only when $o=1$).**\n\n**Response:** In fact, $o_{u, i}$ is **not** just a treatment to observe $r_{u, i}$ and **does** affect the 'value' of $r_{u, i}$. **We further clarify the definition of $o_{u, i}$ in Section 2 and add a notation table in Figure 1 to make the presentation clearer.**\n\n-\tSpecifically, $x_{u,i}$, $o_{u,i}$, and $r_{u,i}$ are the feature, treatment (e.g., exposure), and feedback (e.g., conversion)} of the user-item pair $(u,i)$. **These broad concepts can have different meanings in different recommendation scenarios.**\n-\tFor instance, one may consider $o_{u,i}$ equals 1 or 0 represents whether the item $i$ is exposed to user $u$ or not, and $r_{u,i}$ is the conversion indicator. **Thus it is plausible that the exposure of the item affects the conversion.**\n\n> **[W2.2] If $r_{u, i}$ is affected by $o_{u, i}$, I think the assumption 3 is not hold.**\n\n**Response:** We would like to distinguish here between **the observed feedback $r_{u, i}$** and **the potential feedback $r_{u, i}(1)$**.\n\n-\tWe **agree** with the reviewer that $r_{u, i}$ is affected by $o_{u, i}$, e.g., the exposure of the item affects the conversion.\n\n-\tNonetheless, what assumption 3 states is that the potential feedback $r_{u, i}(1)$ is independent with the exposure indicator $o_{u, i}$. \n\n-\tSince the definition of $r_{u, i}(1)$ is the potential feedback that would be observed if item $i$ had been exposed to user $u$  (i.e., $o_{u,i}$ had been set to 1). Thus it is plausible that $r_{u, i}(1)$ is independent with $o_{u, i}$.\n\n> **[W2.3] In the paper, $g$ is a scalar (a continuous variable), not a representation vector.**\n\n**Response:** We thank the reviewer for pointing out this issue.\n\n-\tOn a **theoretical** level, our approach allows $g$ to be a vector. Noting that **there is a significant difference in the statistical theory when $g$ is a vector and a scalar, we discuss in detail the new proofs and the theorems in main text for multi-dimensional $g$ in Appendix G.**\n\n-\tOn a **experimental** level, **as the reviewer captured, we only considered the cases when $g$ is a scalar (a continuous variable), but such implementation has already achieved significant performance improvement**. In the future, we will conduct more experiments to explore the use of multi-dimensional $g$ to implement the proposed methods.\n\n**3. Minor concerns**\n- In the real-world experiment, the authors use 5\\% MAR test ratings for the propensity estimation. This process is unrealistic.\n\n**Response:** Indeed, in our original manuscript, **we implement the proposed methods using both Logistic Regression (LR) and Naive Bayes (NB) for estimating the propensities. LR does not require any MAR test ratings for the propensity estimation**, whereas NB requires 5\\% MAR test ratings for the propensity estimation. **We carefully revised the statement about propensity estimation in Section 6, as well as highlighting the results of the experiments using LR and NB in Table 2.**\n\n> **[W3.2] In the semi-synthetic experiment, the definition of neighborhood effect is the number of neighbor pairs with $o \\geq c$. what does it mean? Since $o \\in $ {$0$, $1$}, I cannot understand the $c$ is chosen to be the median of all $\\boldsymbol{g}$.**\n\n**Response:** We thank the reviewer for the careful reading and apologize for the **typo** here. Actually, $c$ is chosen to be the median of all $ \\sum_{ (u',i') \\in N_{(u,i)} } o_{u',i'} $. **We have fixed this typo in our revised manuscript.**\n\n***\n\nFinally, we would like to kindly remind the reviewer that he/she **might have mistakenly flagged \"Flag For Ethics Review\"** due to checking both \"No ethics review needed\" and \"Yes, Responsible research practice (e.g., human subjects, data release)\".\n\n**We hope the above discussion will fully address your concerns about our work.** We really appreciate your insightful and constructive comments to further help us improve the quality of our manuscript. Thank you!\n\n***\n\n**References**\n\n[1] Yu Zheng et al. Disentangling User Interest and Conformity for Recommendation with Causal Embedding, WWW 2021.\n\n[2] Mouxiang Chen et al. Adapting Interactional Observation Embedding for Counterfactual Learning to Rank. SIGIR 2021."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700739380131,
                "cdate": 1700739380131,
                "tmdate": 1700739545488,
                "mdate": 1700739545488,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "88zLKT4Rwl",
            "forum": "52fz5sUAy2",
            "replyto": "52fz5sUAy2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8755/Reviewer_g9eU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8755/Reviewer_g9eU"
            ],
            "content": {
                "summary": {
                    "value": "Selection bias in recommender systems arises from the filtering process and user interactions, with most studies focusing on addressing it for unbiased prediction models. However, these studies often overlook the neighborhood effect, which is the variation in potential outcomes due to treatments assigned to other user-item pairs. This paper formulates the neighborhood effect as an interference problem and proposes a novel ideal loss to deal with selection bias in the presence of this effect. Two new estimators are developed, which are shown to achieve unbiased learning when both selection bias and neighborhood effects are present, unlike existing methods. Extensive experiments confirm the effectiveness of these proposed methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The studied topic is practical and interesting.\n2. The experiments are very detailed for reproducing."
                },
                "weaknesses": {
                    "value": "1. Too many assumptions made the manuscript hard to follow."
                },
                "questions": {
                    "value": "n/a"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8755/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698632946206,
            "cdate": 1698632946206,
            "tmdate": 1699637098476,
            "mdate": 1699637098476,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hmfTCEINlP",
                "forum": "52fz5sUAy2",
                "replyto": "88zLKT4Rwl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8755/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8755/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely appreciate the reviewer\u2019s great efforts and insightful comments to improve our manuscript. In below, we try our best to address these concern and update the manuscript accordingly.\n\n> **[W1] Too many assumptions made the manuscript hard to follow.**\n\n**Response:** We thank for the reviewer for raising such concern. We would like to kindly remind the reviewer that all causal conclusions are based on a set of assumptions [1,2]. In this paper, we have adhered to common assumptions widely employed in causal inference. \n\n**It's important to highlight that the primary assumption underpinning our approach is Assumption 1 (neighborhood treatment representation). The remaining assumptions we utilize are standard in causal inference and kernel-smoothing estimation.** To elaborate:\n- Assumptions 2-3 are common assumptions (also called backdoor adjustment criterion in structural causal model, or unconfoundedness assumption in potential outcome framework) in causal inference to ensure the identifiability of the ideal loss (eq. (2)). \n- Assumption 4 aligns with the standard assumption in kernel-smoothing estimation [3, 4, 5]. \n- Assumption 5 merely assumes the boundedness of propensities and imputed errors, which is a trivial assumption. \n\n***\n**We hope the above discussion will fully address your concerns about our work.** We really appreciate your insightful and constructive comments to further help us improve the quality of our manuscript. Thank you!\n***\n\n**Reference**\n\n[1] Miguel A. Hern\u00e1n et al. Causal Inference: What If. 2020.\n\n[2] Guido W. Imbens et al. Causal Inference For Statistics Social and Biomedical Science. 2015.\n\n[3] Jianqing Fan et al. Local Polynomial Modelling and Its Applications. 1996.\n\n[4] Qi Li et al. Nonparametric econometrics. 2007.\n\n[5] Wolfgang H\u00e4rdle et al. Nonparametric and Semiparametric Models. 2004."
                    },
                    "title": {
                        "value": "Please kindly find our concise and clear rebuttal below for addressing your current concern [W1]"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737970155,
                "cdate": 1700737970155,
                "tmdate": 1700738172490,
                "mdate": 1700738172490,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5xjxAhBKQM",
            "forum": "52fz5sUAy2",
            "replyto": "52fz5sUAy2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8755/Reviewer_qJ35"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8755/Reviewer_qJ35"
            ],
            "content": {
                "summary": {
                    "value": "This research investigates the influence of other user-item interactions on their ratings in Recommender Systems (RS). While prior studies concentrated on reducing selection bias, neglecting the neighborhood effect can lead to distorted estimates and subpar predictive model performance. This study introduces a treatment representation to capture the neighborhood effect and suggests a new loss function and estimators to tackle both selection bias and neighborhood effects, resulting in unbiased learning compared to current approaches. The effectiveness of these methods is demonstrated through theoretical assurances and comprehensive experiments."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The introduction of the neighborhood effect in mitigating bias in Recommender Systems (RS) is innovative. The research addresses a significant issue, and its rationale is evident.\n\n- The paper is well-structured and the method is substantiated by robust theoretical foundations."
                },
                "weaknesses": {
                    "value": "- The breach of SUTVA and the presence of interference in debiasing user feedback were previously discussed in [1], where they also examined the interactions between propensity and implicit feedbacks on other items. I would like to see a discussion on it in this manuscript.\n\n- A case study or a real-world example demonstrating the neighborhood effect would be valuable for a clearer comprehension of the underlying motivation.\n\n- To enhance the clarity, it is advisable for the authors to furnish pseudocodes delineating the procedural steps of the proposed estimator and the propensity estimation process.\n\n[1] Mouxiang Chen, Chenghao Liu, Jianling Sun, and Steven C.H. Hoi. 2021. Adapting Interactional Observation Embedding for Counterfactual Learning to Rank. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '21). Association for Computing Machinery, New York, NY, USA, 285\u2013294. https://doi.org/10.1145/3404835.3462901"
                },
                "questions": {
                    "value": "Please see the Weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8755/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8755/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8755/Reviewer_qJ35"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8755/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698730621308,
            "cdate": 1698730621308,
            "tmdate": 1699637098370,
            "mdate": 1699637098370,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Qo86yuobjW",
                "forum": "52fz5sUAy2",
                "replyto": "5xjxAhBKQM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8755/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8755/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Please kindly find our concise and clear rebuttal below for addressing your current concerns [W1-W3]"
                    },
                    "comment": {
                        "value": "We sincerely appreciate the reviewer\u2019s great efforts and insightful comments to improve our manuscript. In below, we address these concerns point by point and try our best to update the manuscript accordingly.\n\n> **[W1] The breach of SUTVA and the presence of interference in debiasing user feedback were previously discussed in [1], where they also examined the interactions between propensity and implicit feedback on other items. I would like to see a discussion on it in this manuscript.**\n\n**Response:** We thank the reviewer for bringing up the relevant literature [1], and **we have added a detailed discussion in the Related Work Section regarding the relation and difference between our paper and [1]**, and **have added a clear citation to [1] as a key motivation of our paper** in the Introduction Section.\n\n-\tDespite **both our paper and [1] exploring the influence induced by \"other user-item interactions\"**, it appears to be the sole similarity between the two studies.\n-\tFirstly, for the **problem settings**, [1] focuses on the task of learning to rank (LTR), addressing position bias using implicit feedback data. In contrast, our paper focuses on eliminating selection bias in the rating prediction task using explicit feedback data.\n-\tSecondly, for the **basic ideas**, [1] considers \"other user-item interactions\" as \"confounders\" (refer to the third paragraph in the Introduction Section). In contrast, our paper regards \"other user-item interactions\" as a new \"treatment\" from the perspective of interference in causal inference.  \n-\tThirdly, for the **proposed methods**, [1] uses embedding as a proxy confounder to capture the influence of \"other user-item interactions\". In contrast, our paper formally formulates the influence of \"other user-item interactions\" as an interference problem in causal inference, and introduces a treatment representation to capture the influence. On this basis, we propose a novel ideal loss that can be used to deal with selection bias in the presence of interference. We also provide comprehensive **theoretical guarantees**.\n\n> **[W2] A case study or a real-world example demonstrating the neighborhood effect would be valuable for a clearer comprehension of the underlying motivation.**\n\n**Response:** Thank you for the kind advice. As suggested by the reviewer, we add a real-world example using the KuaiRec dataset demonstrating the presence of the neighborhood effect in Appendix I, for a clearer comprehension of the motivation in this paper.\n\n-\tFor the same item interacted with different users, we use the user social network information to compute and compare the feedback similarity of friends and non-friends. The results are shown in Figure 3(a). **Compared with the non-friend user pairs, it is clear that there is a higher similarity in the ratings of friends for the same item.**\n\n-\tFor a given user with different items, we use timestamps to first select the $K$ most recent items this user has interacted with, then compute the average video viewing time among all users on the fully exposed dataset. **As shown in Table 3 and Figure 3(b), we found that the lower the average viewing time of the items the user recently interacted with, the better the user's feedback on the current item will be, and vice versa.** Such a feedback mechanism is reasonable: when users have previously observed more low-quality videos, they will provide better feedback on the current items.\n\n> **[W3] To enhance the clarity, it is advisable for the authors to furnish pseudocodes delineating the procedural steps of the proposed estimator and the propensity estimation process.**\n\n**Response:** We thank the reviewer for pointing out this issue. As suggested by the reviewer, **we add pseudocodes delineating the propensity estimation process in Alg. 1, as well as the procedural steps of the proposed N-IPS, N-DR, and N-MRDR in Alg. 2-4, respectively.** Please kindly refer to Appendix H for the added 4 algorithmic details using pseudocodes.\n\n***\n**We hope the above discussion will fully address your concerns about our work.** We really appreciate your insightful and constructive comments to further help us improve the quality of our manuscript. Thank you!\n***\n\n**Reference**\n\n[1] Mouxiang Chen et al. Adapting Interactional Observation Embedding for Counterfactual Learning to Rank. SIGIR 2021."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700738188737,
                "cdate": 1700738188737,
                "tmdate": 1700738279842,
                "mdate": 1700738279842,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "y4WcYqkLgA",
                "forum": "52fz5sUAy2",
                "replyto": "Qo86yuobjW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8755/Reviewer_qJ35"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8755/Reviewer_qJ35"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your responses"
                    },
                    "comment": {
                        "value": "Dear authors,\n\nThanks for the responses. The responses address the most of my concerns. I decide to maintain my score."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700739972282,
                "cdate": 1700739972282,
                "tmdate": 1700739972282,
                "mdate": 1700739972282,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]