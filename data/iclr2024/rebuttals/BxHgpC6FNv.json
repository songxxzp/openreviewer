[
    {
        "title": "Benign Overfitting and Grokking in ReLU Networks for XOR Cluster Data"
    },
    {
        "review": {
            "id": "Q5gdGK9bau",
            "forum": "BxHgpC6FNv",
            "replyto": "BxHgpC6FNv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6036/Reviewer_AQUA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6036/Reviewer_AQUA"
            ],
            "content": {
                "summary": {
                    "value": "This paper theoretically combines the phenomena of benign overfitting and Grokking by training a two-layer ReLU neural network using gradient descent on XOR cluster data. The authors demonstrate that after the first step of gradient descent, the network achieves 100% training accuracy, perfectly fitting the noisy labels in the training data, but exhibits nearly random performance on the test data. However, after some time in training, the Grokking phenomenon occurs, and the network achieves near-optimal test accuracy while still adapting to the random labels in the training data, demonstrating benign overfitting."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper is the first to study the combination of benign overfitting and the Grokking phenomenon in neural networks."
                },
                "weaknesses": {
                    "value": "My main concern about this paper lies in its assumptions. Combining assumptions A1 and A2, we can obtain $p\\geq C^4 n^{5.02}$. This is an extremely high-dimensional setting."
                },
                "questions": {
                    "value": "1: Do the authors have any ideas for improvements in the high-dimensional setting?\n\n2: What behavior does the test error exhibit when the training time is between 1 and $n^{0.01}$?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6036/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6036/Reviewer_AQUA",
                        "ICLR.cc/2024/Conference/Submission6036/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6036/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698760998785,
            "cdate": 1698760998785,
            "tmdate": 1700693461756,
            "mdate": 1700693461756,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "RVdcRpBCUC",
                "forum": "BxHgpC6FNv",
                "replyto": "Q5gdGK9bau",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6036/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6036/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer AQUA"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their review and address their comments and questions below. We hope that the reviewer will consider raising their score in light of our response.\n\n**1: My main concern about this paper lies in its assumptions\u2026 Do the authors have any ideas for improvements in the high-dimensional setting?**\n\nNote that all existing benign overfitting results require input dimension much larger than the number of samples ($p>\\mathrm{poly}(n)$), e.g. [[Bartlett et al. (2019)](https://www.pnas.org/doi/10.1073/pnas.1907378117), [Frei et al. (2022)](https://arxiv.org/abs/2202.05928), [Cao et al. (2022)](https://arxiv.org/abs/2202.06526), [Frei et al. (2023)](https://jmlr.org/beta/papers/v24/22-1132.html), [Xu & Gu (2023)](https://proceedings.mlr.press/v206/xu23k.html), [Kou et al. (2023)](https://arxiv.org/abs/2303.04145)]. Compared with these papers, our non-linearly separable setting is significantly harder. One major technical challenge is to give concentration bounds for summation of dependent random variables (see Equations (A.17)-(A.22) and Lemma A.17 in Section A.6). There are few techniques that can analyze the concentration of such summation, which is necessary for our trajectory analysis. We note that such difficulty is due to the non-linearly separable nature of our data distribution, which was not present in previous papers on linearly separable data.\n\nFurthermore, we are not sure what the reviewer means regarding potential ideas for \u201cimprovements in the high-dimensional setting.\u201d We do not have a complete understanding of whether grokking or benign overfitting happen in lower-dimensional settings, and we believe a full characterization of whether these two phenomena occur as a function of the dimension, number of samples, step-size, initialization variance, and signal-to-noise ratio (determined by $\\|\\mu_i\\|$) is an extremely challenging problem. Indeed, prior work by [Frei et al. (2023)](https://jmlr.org/beta/papers/v24/22-1132.html) (Figure 2, page 15) showed that in the high-SNR, low-dimensional setting for two-layer ReLU nets trained on the XOR cluster distribution we consider, overfitting is not benign and grokking does not occur.\n\nWe believe it is significant that we have established a proof of both benign overfitting and grokking in ReLU networks for nonlinear data, and that our work helps elucidate how high-dimensionality and low-SNR can play a crucial role in both of these phenomena. We believe these contributions are of substantial interest to the ICLR community. We hope the reviewer will consider raising their score.\n\n**2: What behavior does the test error exhibit when the training time is between 1 and $n^{0.01}$?**\n\nRegarding the test error behavior between time $1$ and time $n^{0.01}$: for technical reasons, we cannot prove a generalization bound for the behavior between times 1 and $n^{0.01}$. That said, we are able to prove that the expectation of the margin keeps increasing with step $t$, which intuitively should help generalization. Empirically, Figure 1 shows that the test accuracy increases gradually from near-random to near-perfect."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6036/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700330485748,
                "cdate": 1700330485748,
                "tmdate": 1700330485748,
                "mdate": 1700330485748,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VSPZYNgUl4",
                "forum": "BxHgpC6FNv",
                "replyto": "RVdcRpBCUC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6036/Reviewer_AQUA"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6036/Reviewer_AQUA"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Authors,\n\nThank you for the response.\n\nI apologize for the ambiguity in my question. The original intent of Question 1 was to inquire whether the high-dimensional condition in this paper, $p\\geq n^5$, could be improved to something similar to the conditions in the previous papers, such as $p\\geq n^2 \\log n$ in [1].\n\nThank you,\n\nReviewer AQUA\n\nReference:\n\n[1] Spencer Frei, et al. Benign Overfitting without Linearity: Neural Network Classifiers Trained by Gradient Descent for Noisy Linear Data. COLT 2022."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6036/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700518638906,
                "cdate": 1700518638906,
                "tmdate": 1700518638906,
                "mdate": 1700518638906,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "t1NOuoLZTX",
                "forum": "BxHgpC6FNv",
                "replyto": "79zvIn49Wx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6036/Reviewer_AQUA"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6036/Reviewer_AQUA"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Authors,\n\nThank you for the response.\n\nI still have a doubt about linearly separable. Can the author explain why you think the setting [1] is linearly separable? Thank you!\n\nReviewer AQUA\n\nReference:\n\n[1] Spencer Frei, et al. Benign Overfitting without Linearity: Neural Network Classifiers Trained by Gradient Descent for Noisy Linear Data. COLT 2022."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6036/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700656055218,
                "cdate": 1700656055218,
                "tmdate": 1700656055218,
                "mdate": 1700656055218,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6lAqVIrauS",
                "forum": "BxHgpC6FNv",
                "replyto": "HT3jCPCFJO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6036/Reviewer_AQUA"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6036/Reviewer_AQUA"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Authors,\n\nThank you for the response. I will increase the score. And I recommended the author add some relevant remarks to the paper.\n\nReviewer AQUA"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6036/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700693393589,
                "cdate": 1700693393589,
                "tmdate": 1700693393589,
                "mdate": 1700693393589,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "2KLOTeJSAm",
            "forum": "BxHgpC6FNv",
            "replyto": "BxHgpC6FNv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6036/Reviewer_mTpn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6036/Reviewer_mTpn"
            ],
            "content": {
                "summary": {
                    "value": "This paper delves into the exploration of benign overfitting and \"grokking\" in two-layer ReLU neural networks when trained on XOR cluster data with noisy labels. The authors demonstrate that networks can perfectly fit noisy training data (benign overfitting) and, after a period, transition from harmful overfitting to a stage where they generalize near-optimally (\"grokking\"). Through rigorous theoretical analysis and proofs, the study reveals that these surprising phenomena are evident in the networks' training trajectories, providing a nuanced understanding of overfitting and generalization in neural network models.\n\nThe paper's contributions lie in providing the first theoretical insights into benign overfitting in non-linearly separable data distributions, unraveling the feature learning dynamics under gradient descent. These findings illuminate the pathways through which neural networks navigate the complexities of noisy data, offering a fresh perspective on their capacity to generalize despite apparent overfitting."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The paper offers a new theoretical examination of benign overfitting and \"grokking\" in two-layer ReLU neural networks. It focuses on XOR cluster data with noisy labels, giving a detailed exploration and proofs related to these phenomena. The authors use existing concepts and new theories to better explain the behavior of neural networks with noisy training data.\n\n* The paper is structured and clear, effectively communicating the authors\u2019 work and results. It has a logical organization that makes it easy for readers to follow the ideas and analyses. The presentation of definitions, explanations, and proofs is mostly straightforward, helping readers understand the complex concepts and findings.\n\n* The paper is important because it helps understand overfitting and generalization in neural networks better. It explains the concepts of benign overfitting and \"grokking\" in one framework."
                },
                "weaknesses": {
                    "value": "* The assumption made in A1 seems to contradict common understanding. Generally, increasing the number of samples, even with limited noisy labels, tends to enhance the generalization capability of neural networks. However, in Assumption A1, having a larger number of training samples seems to adversely affect the model, as indicated by its presence on the right-hand side of the inequality. This aspect might require further clarification or justification within the context of the study.\n\n* The mechanism of overfitting, once the neural network learns the directions of $u_1$ and $u_2$. is not explicitly clear. The paper mentions that post the initial gradient step, positive neurons learn $u_1$ while negative neurons learn $u_2$. However, the explanation seems lacking in how the network overfits to samples with noisy (flipped) labels in this condition. A more detailed discussion or clarification on this would be beneficial.\n\n* The role of Lemma 4.6 in the paper is unclear. A clearer explanation of how it relates to other parts of the paper and how it contributes to the overall arguments and conclusions is needed for better understanding. \n\n* The paper seems to lack a comparative discussion with some relevant works, specifically references [1,2].\n\n\n[1] Meng, Xuran, Difan Zou, and Yuan Cao. \"Benign Overfitting in Two-Layer ReLU Convolutional Neural Networks for XOR Data.\" arXiv preprint arXiv:2310.01975 (2023).\n\n[2] Glasgow, Margalit. \"SGD Finds then Tunes Features in Two-Layer Neural Networks with near-Optimal Sample Complexity: A Case Study in the XOR problem.\" arXiv preprint arXiv:2309.15111 (2023)."
                },
                "questions": {
                    "value": "* Could you provide more insights or justification regarding Assumption A1? Specifically, could you clarify why an increase in the number of training samples seems to negatively influence the model, contrary to the common understanding that more samples generally improve a model's generalization capability?\n\n* Could you elaborate on the mechanism of overfitting after the neural network learns the directions of $u_1$ and $u_2$.\n\n* Could you clarify the role and significance of Lemma 4.6 in the context of the paper's objectives and findings?\n\n* Could you make a comparsion your results and techniques with [1] and [2]?\n\n* Have you considered variations in the network architecture, such as not fixing the second layer, and if so, how do these variations influence the results?\n\n* In the model settings used in the paper, there doesn\u2019t appear to be an upper bound on the network width. If an extremely wide network setting were used, would the findings align with the \"lazy training\" regime? Could you discuss how the results might be influenced by varying the width of the network to such extremes?\n\nI would increase my score if the authors could clarify my concerns demonstrated in the above questions.\n\n--------------------------------------\nI increase my score to 6 after rebuttal."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6036/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6036/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6036/Reviewer_mTpn"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6036/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698844042568,
            "cdate": 1698844042568,
            "tmdate": 1700622106618,
            "mdate": 1700622106618,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "cj2Veub6aC",
                "forum": "BxHgpC6FNv",
                "replyto": "2KLOTeJSAm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6036/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6036/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer mTpn (part I)"
                    },
                    "comment": {
                        "value": "We thank the reviewer the detailed review and for appreciating the contributions of our paper. It is encouraging to see that the reviewer thinks our paper is \u201cimportant\u201d and \u201cstructured and clear\u201d and offers \u201ca new theoretical examination of benign overfitting and grokking.\u201d\n\nWe are happy to address the reviewer\u2019s questions below, and hope that the reviewer will consider raising the score in light of our response.\n\n**Could you provide more insights or justification regarding Assumption A1? Specifically, could you clarify why an increase in the number of training samples seems to negatively influence the model, contrary to the common understanding that more samples generally improve a model's generalization capability?**\n\nWe appreciate the question regarding the potential negative impact of increasing the number of samples on the model's performance, and agree that it is a bit counterintuitive. We wish to mention that an assumption on the upper bound of $n$ was needed in all previous benign overfitting results (since they all require high-dimensional data), e.g. [[Bartlett et al. (2019)](https://www.pnas.org/doi/10.1073/pnas.1907378117), [Frei et al. (2022)](https://arxiv.org/abs/2202.05928), [Cao et al. (2022)](https://arxiv.org/abs/2202.06526), [Frei et al. (2023)](https://jmlr.org/beta/papers/v24/22-1132.html), [Xu & Gu (2023)](https://proceedings.mlr.press/v206/xu23k.html), [Kou et al. (2023)](https://arxiv.org/abs/2303.04145)]. Also note that in practical settings it is possible that increasing the sample size could hurt generalization (see e.g. \u201cdeep double descent\u201d [[Nakkiran et al. (2019)](https://arxiv.org/abs/1912.02292)]). \n\nEmpirically, such an upper bound for sample size is indeed necessary. We have added an experiment for large sample size $n$ (see Figure 5 in Appendix A.8), which empirically shows that increasing $n$ could harm generalization, so it is not just a limitation of the analysis. \n\nAdditionally, we also refer the reviewer to Figure 2 in [Frei et al. (2023)](https://jmlr.org/beta/papers/v24/22-1132.html) (page 15), where they showed empirically that an upper bound for the number of samples is required (see the discussion section there). \n\n**Could you elaborate on the mechanism of overfitting after the neural network learns the directions of u1 and u2?**\n\nA high-level intuition of this mechanism is: the training data points can be easily memorized by the neural network due to the near-orthogonality property ($\\| x_i \\|^2 \\gg |\\langle x_i, x_j \\rangle|, \\forall j \\neq i$) and the high-dimensionality ($p\\gg n$). The network has the capacity to learn the correct directions $\\mu_1$ and $\\mu_2$ and to memorize all the training data points.\n\nIn our paper, we prove that once the model memorizes a data point, it will never forget it. Specifically, for $a_j y_i > 0$, if at step $s$, the neuron $w_j$ positively correlates with the data point $x_i$, i.e. $\\langle w_j^{(s)}, x_i\\rangle > 0$, then it will stay that way afterward since $\\langle w_j^{(t+1)} \u2013 w_j^{(t)}, x_i \\rangle > 0, \\forall t \\ge s$. We refer the reviewer to (F1)-(F2) in Corollary A.5, which are the key properties used to prove the overfitting result. We note that previous benign overfitting results [[Cao et al. (2022)](https://arxiv.org/abs/2202.06526), [Xu & Gu (2023)](https://proceedings.mlr.press/v206/xu23k.html)] also utilized analogous properties to prove the overfitting result.\n\nWe think a more interesting question is how features can continue to be learned after the network has already achieved a perfect fit to data - this question seems to be the crux of why grokking has received so much attention. What we show is that even though the network has fitted the data, the small signal in the data continues to be picked up by gradient descent.  In high dimensions, the noise components are close to completely orthogonal, so over time the small increments in the signal learned by each step of gradient descent grow more than the fixed level of noise coming from the nearly-orthogonal noise variables.\n\n**Could you clarify the role and significance of Lemma 4.6 in the context of the paper's objectives and findings?**\n\nThe role of this technical lemma is solely to explain the approximation in Equation (4.3). We will make this point clear in the updated version of the paper.\n\nTo provide some further explanation, recall that (4.3) is the key equation which shows that the network\u2019s decision boundary at step 1 is approximately linear and thus it fails to generalize. The key step in (4.3) (with the \u201ca.s.\u201d) follows from Lemma 4.6. In the formal proof of the non-generalization result, we use concentration properties that have a similar form to Lemma 4.6 (see Lemma A.12 in Section A.5.2, which is used to prove Theorem 4.8)."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6036/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700330235893,
                "cdate": 1700330235893,
                "tmdate": 1700330296146,
                "mdate": 1700330296146,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qFnaPxmqLk",
                "forum": "BxHgpC6FNv",
                "replyto": "Dp9qjLfzvx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6036/Reviewer_mTpn"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6036/Reviewer_mTpn"
                ],
                "content": {
                    "comment": {
                        "value": "I extend my gratitude to the authors for their comprehensive response. Consequently, I am inclined to revise my rating upwards."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6036/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700622047830,
                "cdate": 1700622047830,
                "tmdate": 1700622047830,
                "mdate": 1700622047830,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9itkvJ0ZkG",
            "forum": "BxHgpC6FNv",
            "replyto": "BxHgpC6FNv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6036/Reviewer_6CDP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6036/Reviewer_6CDP"
            ],
            "content": {
                "summary": {
                    "value": "This paper analyzes two-layer ReLU network trained by gradient descent on XOR cluster data with a high-dimensional input space, and rigorously proves grokking and benign overfitting occurs.\n\nSpecifically, with one sufficiently large gradient step, the network is almost a linear classifier and achieves perfect overfitting to the training data, which contains label-flipping noise. If training is continued, the model almost perfectly predicts the clean label, while keeping perfect overfit to the training data."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "### Notable results on benign overfitting of neural networks beyond linearly separable data\n\nAs far as I understand, proving benign overfitting for neural network involves several difficulties due to its nonlinearity, and especially I agree that showing the superiority of neural network to linear methods by learning nonlinear target function has been largely open in this context. I think XOR cluster data is a good starting point to this problem and this paper proves benign overfitting under moderate assumptions.\n\n### Providing useful theoretical understandings on grokking\n\nAs well as benign overfitting result, this paper also proves that after one large (compared to the initialization scale) gradient step, the neural network approximately behaves as the linear model and perfectly overfit to the training data. The phenomena that the early stage of training only produces the linear model but there is a transition to the nonlinear neural network with richer features is particularly interesting, providing one of the first rigorous theoretical demonstrations of grokking.\n\n### The paper is well written and clearly explaining its theoretical key points.\n\nThe proof sketch section is well-written and provides a sufficient understanding of the overall theoretical contributions. It is expected that the techniques presented in this paper will also be valuable in demonstrating the potential for more enriching feature learning in the future."
                },
                "weaknesses": {
                    "value": "### Justification of the small initialization\n\nIn my understanding, it is crucial to take a small initialization scale compared to the step size $\\alpha$ to obtain the perfect overfitting at the first gradient step. I think this is acceptable as theory, but it should be better to justify such a small initialization. I also want to know what happens if the initialization scale is much larger than used in Figure 3.\n\n### Large signal-to-noise ratio\n\nCompared to [Ji & Telgarsky (2019)](https://arxiv.org/abs/1909.12292); [Wei et al. (2019)](https://arxiv.org/abs/1810.05369); [Barak et al. (2022)](https://arxiv.org/abs/2207.08799); [Telgarsky (2023)](https://openreview.net/forum?id=swEskiem99); [Suzuki et al. (2023)](https://openreview.net/forum?id=tj86aGVNb3&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DNeurIPS.cc%2F2023%2FConference%2FAuthors%23your-submissions), where $x$ is a $d$-dimensional (essentially) rotationally invariant input and $y=\\rm{sgn}(x_1x_2)$, this paper considers large signal $\\|\\mu\\|$ as an input."
                },
                "questions": {
                    "value": "- Is it possible to see an additional experiment when the initialization scale is not so small?\n\n- When $\\|\\mu\\|$ gets small, is this grokking phenomena still observed?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6036/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6036/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6036/Reviewer_6CDP"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6036/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699123549783,
            "cdate": 1699123549783,
            "tmdate": 1699636648861,
            "mdate": 1699636648861,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "OJzixadmTi",
                "forum": "BxHgpC6FNv",
                "replyto": "9itkvJ0ZkG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6036/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6036/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the detailed review and for appreciating the contributions of our paper. It is encouraging to see that the reviewer thinks our paper is well-written and regards our paper as providing \u201cnotable results on benign overfitting\u201d and \u201cuseful theoretical understanding on grokking.\u201d\n\nWe are happy to address the reviewer\u2019s questions below.\n\n \n\n**Justification of the small initialization:**\n\nThe small initialization is indeed crucial as it makes the analysis of the training dynamics easier. Such an assumption has been made in a number of related theory papers, such as [[Frei et al. (2022)](https://arxiv.org/abs/2202.05928), [Frei et al. (2023)](https://jmlr.org/beta/papers/v24/22-1132.html), [Xu & Gu (2023)](https://proceedings.mlr.press/v206/xu23k.html)].\n\nWe share the reviewer\u2019s desire for understanding what happens under a larger initialization scale and have done some experiments in this regime. Specifically, in our paper, Figure 1 (right) gives the train and test accuracy under large initialization (relative to step size). The large initialization version of Figure 3 is given in Figure 4 in Appendix A.7. We observe similar benign overfitting and grokking behaviors for large initialization, though the overfitting and generalization require more steps than the case of small initialization.\n\nWe have also run additional experiments with a fixed learning rate and varying initialization scales; see Figure 6 in Appendix A.8. We again observe similar qualitative phenomena.\n\n \n\n**Large signal-to-noise (SNR) ratio:**\n\nWe agree that our SNR is larger than that in the papers that the reviewer mentioned. However, those papers consider a different problem and are not directly comparable to our work. In particular, the XOR problem they studied is the discrete (p, 2) parity task, while we study the Gaussian noise XOR problem. Instead of a large SNR, those papers all require a large sample size $n$:  [Ji & Telgarsky (2019)](https://arxiv.org/abs/1909.12292), [Wei et al. (2019)](https://arxiv.org/abs/1810.05369), [Barak et al. (2022)](https://arxiv.org/abs/2207.08799), and [Telgarsky (2023)](https://openreview.net/forum?id=swEskiem99) all need $n = \\Omega(p^2)$, and [Suzuki et al. (2023)](https://openreview.net/forum?id=tj86aGVNb3&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DNeurIPS.cc%2F2023%2FConference%2FAuthors%23your-submissions) need $n = \\Omega(p)$. On the other hand, we study the high-dimensional regime $n \\ll p$, which is in line with all existing benign overfitting results (e.g. [[Bartlett et al. (2019)](https://www.pnas.org/doi/10.1073/pnas.1907378117), [Frei et al. (2022)](https://arxiv.org/abs/2202.05928), [Cao et al. (2022)](https://arxiv.org/abs/2202.06526), [Frei et al. (2023)](https://jmlr.org/beta/papers/v24/22-1132.html), [Xu & Gu (2023)](https://proceedings.mlr.press/v206/xu23k.html), [Kou et al. (2023)](https://arxiv.org/abs/2303.04145)]) and intuitively explains why a relatively large SNR is needed.\n\nWe also note that there is a concurrent work studying (p, 2) parity [[Glasgow (2023)](https://arxiv.org/abs/2309.15111)] which discusses the difference between the (p, 2) parity problem and the Gaussian noise XOR problem in their Conclusion and Discussion section and why their results cannot be extended to Gaussian noise XOR.\n\n** **"
                    },
                    "title": {
                        "value": "Author Response to Reviewer 6CDP"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6036/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700329318675,
                "cdate": 1700329318675,
                "tmdate": 1700329360863,
                "mdate": 1700329360863,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wzqSEpWiPH",
                "forum": "BxHgpC6FNv",
                "replyto": "9itkvJ0ZkG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6036/Reviewer_6CDP"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6036/Reviewer_6CDP"
                ],
                "content": {
                    "comment": {
                        "value": "Dear authors, \n\nI appreciate authors' efforts on the extensive clarification.\n\nBest,"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6036/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687100612,
                "cdate": 1700687100612,
                "tmdate": 1700687124707,
                "mdate": 1700687124707,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]