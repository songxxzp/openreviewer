[
    {
        "title": "Enhancing Compositional Generalization via Compositional Feature Alignment"
    },
    {
        "review": {
            "id": "1TWOxXuQXA",
            "forum": "Aemqy6Hjdj",
            "replyto": "Aemqy6Hjdj",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6129/Reviewer_ZjmZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6129/Reviewer_ZjmZ"
            ],
            "content": {
                "summary": {
                    "value": "The paper deals with the challenge of compositional generalization, which in detail is the generalization to unseen domain-class combinations. To this end, the paper proposes CG-Bench, a suite of CG benchmarks derived from existing real-world image datasets. Furthermore, Compositional Feature Alignment (CFA), a two-stage finetuning technique is proposed. Evaluation is performed on CG-Bench using CLIP and DINOv2 vision foundation models fine-tuned using the proposed CFA approach."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "\u00b7         The paper is well written and easy to understand, e.g., Figure 2 is very useful for understanding the definition of Compositional Feature Structure.\n\n\u00b7         The proposed method is novel and interesting, and it seems to work well in the case of datasets such as Color-CIFAR. The results in Figure 4 show that the learned features are disengaged across classes and domains.\n\n\u00b7         The proposed CG-Bench compositional generalization benchmark is also novel and well-curated."
                },
                "weaknesses": {
                    "value": "\u00b7         Theorem 1 holds only at the global minimum of the objective function (4). However, in practice when the features Z are from large neural networks such as CLIP the global minimum is unlikely to be obtained. In that case, features would likely not conform to the compositional feature structure defined in Definition 1. Therefore, it is unclear if Theorem 1 has any practical significance.\n\n\u00b7         While the features seem to be disentangled in the case of the simple Color-CIFAR dataset as shown in Figure 2, it is not clear if the same effect can be observed in the case of more complex datasets such as DomainNet.\n\n\u00b7         Stability of the model during training is not discussed in detail. This is important because of the complex two-stage training process. The paper should include experiments where the number of training steps in the first and second stage are varied and analyze the effect on the performance of the final model.\n\n\u00b7         From the results in Table 1, the performance gain over the reweight strategy is minimal (<1%) for all datasets. The biggest performance gain comes from the use of WiSE-FT (Wortsman et al., 2022). Also, compared to the reweight strategy, the proposed approach uses 2-staged training. Therefore, it is not clear whether the increase in training complexity is justified by the small performance gain.\n\n\u00b7         In Table 1, the reweight baseline with WiSE when using the DINOv2 model seems to be missing. Comparing reweighting and the proposed CFA method the gain in performance without WiSE seems to be <0.3%, especially in the case of OfficeHome and DomainNet.\n\n\u00b7         Can the proposed approach take advantage of unlabeled data? This is important because prior work such as CLIP or DINOv2 does not need explicit domain/class labels, unlike the proposed CFA approach."
                },
                "questions": {
                    "value": "\u00b7         For models trained using CFA, do we observe the disentanglement similar to Color-CIFAR in Figure 2 in case of larger datasets such as DomainNet?\n\n\u00b7         Additional details of the reason for the small performance gain of the proposed CFA approach over the reweight baseline in Table 1 would be helpful."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6129/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698729425196,
            "cdate": 1698729425196,
            "tmdate": 1699636663784,
            "mdate": 1699636663784,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1DtYAGYN8i",
                "forum": "Aemqy6Hjdj",
                "replyto": "1TWOxXuQXA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6129/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6129/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer ZjmZ [Part 1]"
                    },
                    "comment": {
                        "value": "## 1. Feature Alignment in Large Neural Nets (e.g., CLIP)\n\nTo address your concern regarding whether large neural networks can conform to the compositional feature structure (as defined in Definition 1) using our CFA algorithm, we conducted feature visualization for a CLIP model in both its pretrained and CFA-trained versions. The comparative visualization is presented in **Figure 7 in Appendix D of our revised manuscript**, which you can review at [_this link_](https://openreview.net/pdf?id=Aemqy6Hjdj). From this figure, it is evident that the features fine-tuned with CFA align well with a compositional feature structure, unlike the original CLIP features. We believe this visualization further justifies the ability of our proposed CFA objective to align features of large neural networks with the desired structure.\n\n## 2. Feature Disengtanglement on Real-World Dataset\n\nWe believe the feature visualization for the DomainNet dataset, as mentioned above, also addresses the reviewer's concern: the CFA-finetuned CLIP model exhibits a feature structure with disentanglement similar to what is seen in the Color MNIST visualization in the paper.\n\n## 3. Training Complexity\nTo address your concerns regarding the training stability of CFA's two stages, we conducted experiments with different training lengths for each stage. The results are provided in item 3 of our **[General Response](https://openreview.net/forum?id=Aemqy6Hjdj&noteId=ddKHrBob2l)** above ([link](https://openreview.net/forum?id=Aemqy6Hjdj&noteId=ddKHrBob2l)). The table shows that Stage-1 training is quite stable, as it involves only optimization over linear models. Additionally, the training cost of Stage-1 (linear probing) is almost negligible compared to Stage-2 (backbone finetuning). Stage-1 requires only a single forward pass over training samples for feature gathering (features are stored in CPU memory), and then the linear probing can be optimized fastly on CPU. The training cost for Stage-2 is slightly less than standard full finetuning, as the last layer remains frozen during Stage-2 of CFA. Overall, we conclude that the implementation complexity and additional training costs of CFA are mild, making it a practical method for addressing compositional generalization problems in real-world applications."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6129/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700383218107,
                "cdate": 1700383218107,
                "tmdate": 1700383722300,
                "mdate": 1700383722300,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JbkbrsQG3S",
                "forum": "Aemqy6Hjdj",
                "replyto": "1TWOxXuQXA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6129/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6129/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer ZjmZ [Part 2]"
                    },
                    "comment": {
                        "value": "## 4. Performance Gain\nRegarding the performance gain of CFA over reweighting, a strong baseline method, we acknowledge that the improvement is not significant. However, our main contribution lies in designing a principled algorithm for compositional generalization, a novel challenge in OOD generalization. As our theoretical analysis and feature visualization in Figures 4 and 7 demonstrate (on Color MNIST and DomainNet, respectively), our method aligns features with a compositional structure suitable for compositional generalization. In OOD generalization research, it's typical for specialized algorithms to only modestly outperform baselines like ERM, as evidenced by extensive benchmarking in studies like DomainBed [1] and WILDS [2]. Thus, we consider CFA's performance gain to be meaningful and convincing. Additionally, the mild implementation complexity and training costs (discussed in the last item) make CFA a viable method for enhancing compositional generalization.\n\n\nMoreover, we want to emphasize that real-world datasets used in our paper have lots of labeling issues (for both class and domain labels), which may prevent CFA from obtaining greater performance gain. Notably, CFA employs both class and domain labels for training, leading to an increased susceptibility to label noise, particularly from domain labels. Below, we illustrate two types of labeling noise encountered:\n\n+ **(i) Mislabeling**: We observe that the DomainNet dataset contains many mislabeled images. Many images in the \u201cClipart\u201d domain are actually real photos of a single object on a white background, which should be categorized into the \u201cProduct\u201d domain. On the other hand, numerous class labels are also mislabeled: images in the \u201cbush (plant)\u201d class contain pictures of President George Bush of the USA; the \u201ccooler\u201d class includes electric fan images, which are incorrectly categorized; the \u201csquare (shape)\u201d class contains table, which should be placed into the \u201ctable\u201d class instead. Note: We only manually examined a very tiny subset of the DomainNet dataset, which comprises 0.6 million images, and have already found many mislabeled images. Therefore, overall, we believe the mislabeling ratio is not negligible.\n\n+ **(ii) Ambiguous Labels**: We observe that certain domains contain a large number of images that are visually similar to those in another domain. For example, in both [Office-Home](https://www.hemanthdv.org/officeHomeDataset.html) and [DomainNet](https://ai.bu.edu/M3SDA), the images in the \u201cProduct\u201d domain are real photos of objects, making them almost indistinguishable from their counterparts in the \u201cReal\u201d domain. The distinguishing feature of the \u201cProduct\u201d domain is that its images all have a white background; however, some images in the \u201cReal\u201d domain also share this characteristic. Additionally, in DomainNet, the \u201cInfograph\u201d domain contains many images stylistically similar to those in \u201cClipart\u201d or \u201cReal\u201d; some images in the \u201cPainting\u201d domain are sketches, despite the presence of a separate \u201cSketch\u201d domain. This ambiguity issue extends to class labels as well. In DomainNet, the classes \u201ccup,\u201d \u201ccoffee cup,\u201d and \u201cmug\u201d lack clear stylistic distinctions.\n\nIn addition to these issues, other aspects of these datasets may affect learning. For instance, the iWildCam dataset includes a class labeled \u201cempty,\u201d signifying the absence of animals, which comprises a significant portion of the dataset.\n\n## 5. Reweighting Not Work with WiSE-FT for DINOv2 Backbone\nWe did not include the results of Reweighting+WiSE-FT for DINOv2 in Table 1, as we had observed its ineffectiveness before the submission of this paper. We re-run the experiments for Reweighting for DINOv2 on DomainNet over 3 random seeds and provide the mean accuracy results in the table below. \n\nIt is evident that WiSE-FT significantly decreases the performance of Reweighting in terms of both ID and OOD accuracy. The primary reason is that, unlike CLIP that includes a text encoder capable of providing a zero-shot linear classifier on top of its image encoder, DINOv2 is solely an encoder without an initial classifier (the last linear layer). Therefore, when applying WiSE-FT to Fine-tuning and Reweighting methods on DINOv2, the initial parameters of the last linear layer are set to zeros and then interpolated with the final finetuned last linear layer. However, this interpolated image encoder may not align well with the interpolated last layer, leading to a decrease in both ID and OOD performance.\n\n| Method       | ID Acc   | ID Acc (WiSE) | OOD Acc | OOD Acc (WiSE) |\n|--------------|------|-----------|-----|------------|\n| Reweight-E   | 81.8 | 40.7      | 5.1 | 3.6        |\n| Reweight-YxE | 81.5 | 41.2      | 5.3 | 3.1        |\n\nWe will run Reweighting+WiSE-FT experiments for DINOv2 on more datasets, and provide results in the appendix of the next revision."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6129/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700383475702,
                "cdate": 1700383475702,
                "tmdate": 1700690803362,
                "mdate": 1700690803362,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "SwULJKdsvk",
            "forum": "Aemqy6Hjdj",
            "replyto": "Aemqy6Hjdj",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6129/Reviewer_d1KC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6129/Reviewer_d1KC"
            ],
            "content": {
                "summary": {
                    "value": "This paper tackles the challenge of data distribution shifts in machine learning applications. In particular, it emphasizes the multi-domain, multi-class setup where obtaining training data for every domain-class combination becomes impractical, and they try to examine the compositional generalization (CG) for learning models. The authors propose a simple solution in the form of CG and introduce \"CG-Bench,\" a suite of CG benchmarks derived from real-world image datasets. They tested CLIP and DINOv2, and show the effectiveness of both the proposed benchmark and method.\n\n---\n# Post rebuttal\n\nI appreciate the provided two solutions (lessen the need for a fully domain-labeled dataset). I encourage the author to incorporate all the discussion into their revision."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "I personally believe the studied topic of compositional generalization is crucial in real-world machine learning applications, especially in scenarios with multi-domain, multi-class setups. The introduction of \"CG-Bench\" is commendable, providing the research community with a dedicated suite of benchmarks for evaluating CG performance.\n\nThe proposed two-stage process is clear and logically structured, with a rationale that suggests a theoretical underpinning for the method. I personally pretty like Figure 4 which provided a great comparisons between vanilla CLIP features and the features obtained by this paper."
                },
                "weaknesses": {
                    "value": "It is hard to obtain the class and domain labels. Therefore, the studies in this paper are hard to scale-up to real world system. \n\nBased on Table 1, it seems the proposed method would usually cause negative effects to ID Acc."
                },
                "questions": {
                    "value": "Besides, I feel the caption of Figure 2 could be improved to help reader understand the goal of the proposed method.\n\nPlease also address the concerns raised above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6129/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6129/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6129/Reviewer_d1KC"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6129/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698731965469,
            "cdate": 1698731965469,
            "tmdate": 1700890316467,
            "mdate": 1700890316467,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Mii3rpZXvR",
                "forum": "Aemqy6Hjdj",
                "replyto": "SwULJKdsvk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6129/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6129/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer d1KC"
                    },
                    "comment": {
                        "value": "## 1. Label Availability\n\nCLIP is trained in a weakly supervised manner, and its classification performance can often be enhanced through supervised finetuning, such as on ImageNet. In our compositional generalization benchmark (CG-Bench), we observed that the zero-shot prediction accuracy of CLIP was unsatisfactory, indicating the need for further finetuning with class labels. Similarly, the DINOv2 model, a bare image encoder, has to be supervised finetuned to obtain classification capabilities. Overall, class labels are necessary for achieving effective results in CG-Bench.\nWe recognize that the additional requirement of domain labels may not always be feasible in real-world applications. To address this, we propose two solutions to lessen the need for a fully domain-labeled dataset:\n\n+ Use partially available domain labels, e.g., only 10% training samples have domain labels\n\n+ Use zero-shot predicted domain labels by CLIP when no domain labels are provided.\n\nThe experimental results are detailed in the item-2 of our [General Response](https://openreview.net/forum?id=Aemqy6Hjdj&noteId=ZWViPLA35z) above (please review at this [link]((https://openreview.net/forum?id=Aemqy6Hjdj&noteId=ZWViPLA35z))). The results show that our CFA method maintains most of its OOD performance advantages even with limited domain label availability, such as with only 10% of labels. In situations where no domain labels are available, employing CFA with zero-shot predicted domain labels by CLIP still shows improvement compared to the standard finetuning method. Overall, these results indicate that CFA's dependency on domain labels is quite mild.\n\n## 2. ID-OOD Performance Trade-off\n\nIn the literature of OOD generalization and domain generalization, it is widely observed that methods aiming to improve OOD performance usually suffer from some mild in-distribution (ID) performance degradation [1,2]. Additionally, from the theoretical perspective of invariant feature learning [3,4], enhancing OOD performance often requires the omission of domain-specific features, which naturally leads to a decrease in ID accuracy. \n\nIn the empirical results of Table 1 of our manuscript, when comparing the two rows of CFA vs. Fine-tuning in a pairwise manner, one can observe that for the CLIP model, the ID (in-distribution) performance of Fine-tuning is always slightly better than that of CFA. However, for DINOv2, the ID performance of CFA consistently outperforms Fine-tuning across all four datasets. Overall, the difference in ID performance between CFA and other methods is quite small for both models across all datasets. We believe these findings justify that CFA maintains competitive ID performance while improving OOD performance in compositional generalization benchmarks.\n\n\n\n# References\n\n[1] Gulrajani et al. In Search of Lost Domain Generalization. ICLR 2021\n\n[2] Koh et al. Wilds: A benchmark of in-the-wild distribution shifts. ICML 2021\n\n[3] Arjovsky et al. Invariant Risk Minimization. 2019\n\n[4] Rosenfeld et al. The Risks of Invariant Risk Minimization. ICLR 2021"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6129/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700382892728,
                "cdate": 1700382892728,
                "tmdate": 1700382892728,
                "mdate": 1700382892728,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "dXXgp0LrVH",
            "forum": "Aemqy6Hjdj",
            "replyto": "Aemqy6Hjdj",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6129/Reviewer_H15m"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6129/Reviewer_H15m"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the challenge of compositional generalization in machine learning and focuses on generalization to unseen domain-class combinations. The author present a real-world benchmark named CG-Bench and propose the compositional feature alignment method to improve the CG performance of pretrained models. Extensive experiments demonstate the effectiveness of the method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "S1: This paper solve a new setting or problem: can the model generalize to unseen domain-class combinations?\n\nS2: The overall writing is clear, including problem introduction and theoretical and experimental verification of experimental methods.\n\nS3: Some visualization experiments are shown to help the understanding of the review or reader."
                },
                "weaknesses": {
                    "value": "W1: The setting of compositional generalization (CG) means that the pre-trained model is tested on the unseen domain-class combinations and the setting of domain generalization means that the pre-trained model is tested on the unseen domain samples? if yes, what is the difference between CG and some papers in open-set tasks to solve domain generalization problems?\n\nW2: To solve the CG problem, the authors propose a method to align the class information in different domain. I'm more curious about why the two-stage training method can achieve this goal? If possible, I would tend to see experiments on each stage of visualization.\n\nW3: I am more concerned about different training stages and ablation experiments related to orthogonal loss."
                },
                "questions": {
                    "value": "see weaknesses\n\nIf the authors solve my concers, I tend to imporve my socre."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6129/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6129/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6129/Reviewer_H15m"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6129/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698837018261,
            "cdate": 1698837018261,
            "tmdate": 1700667613091,
            "mdate": 1700667613091,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1ccYR3x0H9",
                "forum": "Aemqy6Hjdj",
                "replyto": "dXXgp0LrVH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6129/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6129/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer H15m [Part 1]"
                    },
                    "comment": {
                        "value": "## 1. Problem Setting\n\nCompositional generalization (CG) explicitly assumes that all domains and classes are seen during training, with only certain combinations of them being unseen, which are used for OOD evaluation. As a comparison, in Open-Set Domain Generalization (OS-GD) [1,2], test samples are from a new domain, and unseen classes in the training phase can appear during the test phase. Notably, OS-DG typically requires models to assign the \u201cunknown\u201d class label to test samples from classes unseen in the training set, which essentially constitutes an auxiliary task of out-of-distribution (OOD) detection. \n\nNote: while OS-DG does not explicitly state requirements on test domains, it generally poses certain implicit assumptions about the test domains. For example, the OS-DG problem setup as described in [1] implicitly places distributional assumptions on domains, implying that the test domain is related to the training domains in a specific manner (so that data augmentation techniques, such as feature-level MixUp applied to training domains, can partially encompass test domains).\n\nBelow, we use two tables to illustrate the differences between CG and OS-DG, where \"\u2713\" marks a domain-class combination seen during training.\n+ Compositional Generalization (CG)\n\n    In the CG table, combinations marked with \u201c\u2713\u201d are present in the training set, while those labeled \u201cTest\u201d are not. The CG challenge is to determine if models trained on \u201c\u2713\u201d combinations can accurately generalize to \u201cTest\u201d combinations.\n\n    |           | Class 1 | Class 2 | Class 3 |\n    |-----------|---------|---------|---------|\n    | **Domain 1** | \u2713       | Test    | Test    |\n    | **Domain 2** | Test    | \u2713       | Test    |\n    | **Domain 3** | \u2713       | Test    | \u2713       |\n\n+ Open-Set Domain Generalization (OS-DG)\n\n    In the OS-DG table, the symbols \u201c\u2713\u201d and \u201cTest\u201d have the same implications as in the CG table. Additionally, \u201cX\u201d denotes a domain-class combination that is unavailable during training and is also not evaluated. The class \u201cUnknown\u201d encompasses all classes not present during training, with models expected to predict the \u201cUnknown\u201d class for these.\n    |                  | Train Class 1 | Train Class 2 | Train Class 3 | Class \u201cUnknown\u201d |\n    |------------------|---------------|---------------|---------------|-----------------|\n    | **Train Domain 1** | \u2713             | X             | X             | X               |\n    | **Train Domain 2** | X             | \u2713             | X             | X               |\n    | **Train Domain 3** | \u2713             | X             | \u2713             | X               |\n    | **Test Domain**    | Test          | Test          | Test          | Test            |\n\nIn summary, while CG and OS-DG problems are similar, they aim for different outcomes in OOD generalization. CG seeks to generalize to unseen domain-class combinations composed of domains and classes seen during training. OS-DG can be viewed as domain generalization (DG) with an additional task of OOD detection."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6129/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700382303799,
                "cdate": 1700382303799,
                "tmdate": 1700382303799,
                "mdate": 1700382303799,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ggeqIu2UVA",
                "forum": "Aemqy6Hjdj",
                "replyto": "dXXgp0LrVH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6129/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6129/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer H15m [Part 2]"
                    },
                    "comment": {
                        "value": "## 2. Explanation of Two Stages of CFA and Feature Visualization on Real-World Dataset\nStage-1 of CFA involves linear probing, which trains two orthogonal linear classifiers ($\\mathbf{Y}$ and $\\mathbf{E}$) for class and domain predictions on features $\\mathbf{Z}$ of the pre-trained backbone. The backbone remains frozen in Stage-1, and the primary objective of this stage is to establish a compositional feature structure via the two trained orthogonal classifiers, $\\mathbf{Z}$ and $\\mathbf{E}$. \n\nIn Stage 2, CFA freezes the trained classifiers $\\mathbf{Y}$ & $\\mathbf{E}$, and only fine-tunes the backbone (image encoder) \u2013 this process modifies the features $\\mathbf{Z}$. Drawing from research on neural collapse [3,4,5], it is understood that supervised learning with cross-entropy loss causes the features of samples from class-$i$ to collapse towards the $i$-th column vector of $\\mathbf{Y}$, denoted as $y_i$ (for a visual illustration of neural collapse, refer to Fig. 1 in this [ICLR 2022 paper](https://openreview.net/forum?id=w1UbdvWH_R3)). In our context of two orthogonal linear classifiers, our theoretical analysis indicates that for each training sample associated with class-$i$ and domain-$j$, its feature will collapse towards the composition $y_i + e_j$. Given the orthogonality constraint of classifiers $\\mathbf{Y}$ and $\\mathbf{E}$, the resulting collapsed features will adhere to the compositional feature structure defined in Definition 1.\n\nAs per your request, we visualized features using both the pretrained CLIP ViT model and the one fine-tuned with CFA on the DomainNet dataset. Due to limitations in 3D visualization, we selected 2 out of 6 domains and 3 out of 345 classes for representation. As figures cannot be inserted in OpenReview posts, the visualization is provided in Fig. 7 of Appendix D in the revised manuscript. Please refer to [this PDF](https://openreview.net/pdf?id=Aemqy6Hjdj) for review. This visualization clearly demonstrates that CFA can align features with the intended compositional feature structure. We are confident that this visualization effectively addresses your concern regarding the feature alignment of CFA with real data.\n\n## 3. Ablation Study on Orthogonal Loss\nWe fixed other hyper-parameters as presented in the manuscript, only changing the orthogonal loss coefficient in Stage-1 of CFA. For each set of hyper-parameters, we repeated the experiment with three seeds. It is clear that with the coefficient set to 100, the out-of-distribution (OOD) performance peaks, leading to our choice of this value in our manuscript. From the table, we observe that a large orthogonal loss coefficient (e.g., >=100) is necessary to encourage orthogonality between heads. (The orthogonal loss coefficient of 100 was used in our paper.)\n\n| **Orthogonal Loss Coef.** | **ID**        | **ID (WiSE)**  | **OOD**       | **OOD (WiSE)** |\n|-----------------|---------------|----------------|---------------|----------------|\n| 1               | 93.2          | 92.8           | 46.4          | 46.6           |\n| 10              | **94.0**      | **93.6**       | 50.8          | 53.3           |\n| 100 (Chosen)    | **94.0**      | 93.1           | **54.3**      | **56.9**       |\n| 1000            | 93.8          | 92.8           | 53.9          | 55.2           |\n\n\nIn addition to studying the orthogonal loss coefficient, we also conducted experiments on the training steps of the two stages of CFA. These results, detailed in item-3 (_\"Two-Stage Training Stability\"_) of our [General Response](https://openreview.net/forum?id=Aemqy6Hjdj&noteId=ddKHrBob2l) above _([link](https://openreview.net/forum?id=Aemqy6Hjdj&noteId=ddKHrBob2l))_, demonstrate that the final performance is relatively stable to the training steps numbers in each stage of CFA.\n\n# References\n\n[1] Shu et al. Open Domain Generalization with Domain-Augmented Meta-Learning. CVPR 2021\n\n[2] Zhu et al. CrossMatch: Cross-Classifier Consistency Regularization for Open-Set Single Domain Generalization. ICLR 2022\n\n[3] Papyan et al. Prevalence of neural collapse during the terminal phase of deep learning training. PNAS. 2020\n\n[4] Zhu et al. A Geometric Analysis of Neural Collapse with Unconstrained Features. NeurIPS 2021\n\n[5] Kothapalli et al. Neural Collapse: A Review on Modelling Principles and Generalization. TMLR. 2023"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6129/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700382642731,
                "cdate": 1700382642731,
                "tmdate": 1700383845466,
                "mdate": 1700383845466,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zSYA1fqVqE",
                "forum": "Aemqy6Hjdj",
                "replyto": "dXXgp0LrVH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6129/Reviewer_H15m"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6129/Reviewer_H15m"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your responses"
                    },
                    "comment": {
                        "value": "I have understood the difference between compositional generalization (CG) and open-set domain generalization (OS-DG) in the problem setting from the two tables. However, from the first table, the problem setting of CG is somewhat similar to the compositional zero-shot learning (CZSL) [1]. It is recommended that the author can provide comparative explanations in related work.\n\nAfter carefully reading the author's responses, I feel that my concerns have been resolved and I raised the score to 6.\n\n[1] Hao et al. Learning Attention as Disentangler for Compositional Zero-shot Learning. CVPR2023."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6129/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700666820380,
                "cdate": 1700666820380,
                "tmdate": 1700667587571,
                "mdate": 1700667587571,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]