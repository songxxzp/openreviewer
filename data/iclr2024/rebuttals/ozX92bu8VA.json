[
    {
        "title": "The Truth Is In There: Improving Reasoning with Layer-Selective Rank Reduction"
    },
    {
        "review": {
            "id": "aiMmZHkCtG",
            "forum": "ozX92bu8VA",
            "replyto": "ozX92bu8VA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4114/Reviewer_Zz8q"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4114/Reviewer_Zz8q"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a layer-selective rank-reduction method called LASER. The authors demonstrate that the performance in open-ended question answering is improved when rank-reduction is applied to the specific weight matrix. Moreover, they confirm consistent performance enhancements in tasks on non-text domains such as policy learning and image classification. Additionally, through analysis, it has been observed that high-order components contain factually incorrect knowledge which degrades question answering performance."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The authors conduct extensive experiments with respect to layer number, parameter type, and rate reduction to identify setups that lead to performance improvement.\n- The authors provide interesting observations such as a correlation between rank reduction and question answering accuracy.\n- The authors demonstrate that the proposed method can also be applied to various domains such as image classification."
                },
                "weaknesses": {
                    "value": "- Analysis on other text domain tasks such as reading comprehension could provide further insights."
                },
                "questions": {
                    "value": "- In Figure 3(c), what is the number of originally correct and answer-corrected datapoints?\n- It appears that there is a significant improvement in overall performance with GPT-J compared to LLama2 or Roberta. What could be the underlying cause of the result?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4114/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4114/Reviewer_Zz8q",
                        "ICLR.cc/2024/Conference/Submission4114/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4114/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698477473202,
            "cdate": 1698477473202,
            "tmdate": 1700641320576,
            "mdate": 1700641320576,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0wc5GLU3x7",
                "forum": "ozX92bu8VA",
                "replyto": "aiMmZHkCtG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4114/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4114/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Clarifications and results on 3 datasets, including the task of reading comprehension."
                    },
                    "comment": {
                        "value": "We thank you for your feedback.\n\n>Analysis on other text domain tasks such as reading comprehension could provide further insights.\n\n**Results on New Datasets:** We have added analysis on Epistemic Reasoning (logic and reading comprehension), TruthfulQA (factuality), and QA Wiki Data (world knowledge). The Epistemic Reasoning dataset is provided by Big Bench and was developed specifically to measure reading comprehension and reasoning. Please see Table 4 in the Appendix and the general response. All edits are written in red. \n\nAs with other datasets, we find that LASER offers notable boosts in performance across model architectures. We believe that **improvements across 8 datasets and multiple LLMs and tasks provide strong evidence for using LASER.**\n\n>In Figure 3(c), what is the number of originally correct and answer-corrected data points?\n\n**Clarification:** We apologize for not defining these terms clearly. \u201cOriginally correct\u201d describes samples that are correctly classified even without any intervention.  \u201cAnswer-corrected\u201d refers to questions that the model gets correct only after intervening with LASER (i.e., they were not correctly classified before executing LASER). We have edited the text to clarify this in the new version of the paper. \n\n>It appears that there is a significant improvement in overall performance with GPT-J compared to LLama2 or Roberta. What could be the underlying cause of the result?\n\n**Possible Causes:** Thank you for the question and observation. Although the improvements in GPT-J are more pronounced than in LLAMA2 or Roberta,  there are some domains where improvements in LLAMA2 (FEVER) and Roberta (Bias in bios) are more significant than in GPT-J as well. We consider a thorough analysis of this to be outside the scope of this work, but there are several possible causes that we believe merit investigation, including the capacity of the model, the amount of training data, and the particulars of the optimization procedure. We have added this as an important direction for future research in the current draft."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700543369129,
                "cdate": 1700543369129,
                "tmdate": 1700543369129,
                "mdate": 1700543369129,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Evxig7d5cH",
                "forum": "ozX92bu8VA",
                "replyto": "0wc5GLU3x7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4114/Reviewer_Zz8q"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4114/Reviewer_Zz8q"
                ],
                "content": {
                    "comment": {
                        "value": "I have read the comment including additional results, and raised my score."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700641415449,
                "cdate": 1700641415449,
                "tmdate": 1700641415449,
                "mdate": 1700641415449,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "iy4UYPTHMj",
            "forum": "ozX92bu8VA",
            "replyto": "ozX92bu8VA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4114/Reviewer_4cdi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4114/Reviewer_4cdi"
            ],
            "content": {
                "summary": {
                    "value": "This work discussed a traditional idea, i.e. the low-rank approximation using SVD, for language model compression. Its major observation is that using a low-rank approximation on the MLP layer of transformers can even improve the downstream performance.\nThis observation is verified across different tasks and different transformer models."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "-The use of low-rank approximation should be an effective and general way to allow the models to obtain more robust generalization abilities, while being more computationally efficient in the inference.\n-The authors tried very hard to demonstrate the major observation by showing the results across different transformer models, which are actually not even for language modeling tasks."
                },
                "weaknesses": {
                    "value": "Albeit the strengths above, I would like to say the major weakness of this work is that it draws its conclusion not very rigorously:\n-Current LLMs are often evaluated from multiple aspects including their reasoning abilities such as commonsense reasoning, world knowledge, reading comprehension etc, as well as their language generation abilities such as multilingual ability etc. And each aspect contains well-known benchmark datasets for the evaluation, such as MNLU, AGIEval and BBH. However, this work uses none of them. Therefore, I am not convinced that this robust performance can be achieved across all the above-mentioned aspects.\n-The authors do not provide the final search results of rank reduction, i.e. the layers selected for compressing and the reduced rank, in the final performance in Table1, 2 & 3. It is very important to provide these results to show that the selected model is indeed in a reduced rank."
                },
                "questions": {
                    "value": "I find that the dimension of GPTJ is 4096, which should be $d$ in your notation. So in Fig2, what is the rank of Reduction 99.5%/99.75% and others with .5%? (4096*0.0025=10.24, not an integer?)\n\nThe used CounterFact is very similar to the table-to-text generation task (but for a qa task), which is not a frequently used dataset to test even the QA and factual/world-knowledge reasoning performance of LLM. Any reason for choosing the dataset?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4114/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698661546043,
            "cdate": 1698661546043,
            "tmdate": 1699636376172,
            "mdate": 1699636376172,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hnL7aNhZPc",
                "forum": "ozX92bu8VA",
                "replyto": "iy4UYPTHMj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4114/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4114/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Additional Results and Important Clarifications."
                    },
                    "comment": {
                        "value": "Thank you for your review. \n\n>This work discussed a traditional idea, i.e., the low-rank approximation using SVD, for language model compression. \n \n**Clarification:** We want to emphasize that the focus of the paper is not to compress models but to demonstrate instead that selective rank-reduction interventions can offer a significant boost in terms of predictive performance. \n\nWe also emphasize that most past works (Lv et al., 2023; Hajimolahoseini et al., 2021; Yu et al., 2017) that do a low-rank approximation of neural networks or transformers perform low-rank approximation on every weight matrix and/or every layer of the model. In contrast, LASER is layer-selective, meaning we intervene in selective weight types (e.g., MLP input matrix ($U_{in}$)) and selective layer numbers. In fact, doing low-rank approximation unilaterally across layer numbers and layer types often leads to a significant reduction in performance. We believe this subtle difference with past work is an important finding.\n\nTo our knowledge, papers that use a low-rank approximation of matrices for model compression at best only obtain roughly accuracy-preserving models. We instead demonstrate that selective reduction of this sort can offer significant performance improvements. \n\n>Current LLMs are often evaluated from multiple aspects including their reasoning abilities such as commonsense reasoning, world knowledge, reading comprehension, etc...such as MNLU, AGIEval, and BBH...this work uses none of them...\n\n**Additional Experiments on 3 new datasets:** We evaluate LASER on 5 benchmarks and 3 LLMs, which gives 15 different setups in total. The sizable improvements given by LASER across these setups demonstrate a clear and robust result. \nHowever, we agree that evaluating LASER on more setups will bolster our arguments. In light of this, we have added results on additional new datasets, including Epistemic Reasoning (from Big Bench Hard) and QA Wikidata (from Big Bench) alongside the Truthful QA benchmark. Of these, the big bench hard was specifically suggested in the review. We were unable to locate the MNLU dataset.\n\nThese new results are in the general response and in Table 4, Appendix C of the paper. All relevant edits are written in red. These results show similar notable improvements as in our main paper. For example, we notice a 14% point increase in test accuracy on QA Wikidata with GPTJ and an 18.6% point increase in test accuracy on Epistemic reasoning with Llama2. We also notice that, similar to Table 1 in our main paper, some setups have more modest gains of 0.5-2%. Understanding which datasets have more improvements and why is an interesting avenue for future work.\n\nWe will release our code and provide results on more datasets in the future, but we believe that **positive results across 8 datasets and multiple LLMs and tasks establish the general usefulness of LASER and that these results cannot be a coincidence.**\n\n>The authors do not provide the final search results of rank reduction...It is very important to provide these results to show that the selected model is indeed in a reduced rank\n\n**Final Search Results:** Thank you for pointing this out. We have added the final search results of the reduced ranks in Table 5 and Table 6 of the updated paper.  As noted in the paper, the largest gains typically occur when intervening in higher layers of the LLM. For reference, Llama2 has 32 layers, GPTJ has 28 layers, and Roberta has 12 layers.\n\n>I find that the dimension of GPTJ is 4096, which should be in your notation. So in Fig2, what is the rank of Reduction 99.5%/99.75% and others with .5%? (4096*0.0025=10.24, not an integer?)\n\n**Rounding Clarification:** As mentioned in Section 4, last line of paragraph 1: \u201cWe replace it with a rank \u230a\u03c1 \u00b7 d\u230b-approximation.\u201d  Here, \u201c\u230b\u201d represents the floor of the number, i.e., the number is rounded down to the nearest integer value.\n \n>The used CounterFact is very similar to the table-to-text generation task (but for a QA task), which is not a frequently used dataset to test even the QA and factual/world-knowledge reasoning performance of LLM. Any reason for choosing the dataset?\n\n**Justification for using Counterfact:** The CounterFact dataset (introduced by Meng et al. 2022 ) is derived from the PARAREL dataset (Elzar 2021) and WikiData. This dataset is well-cited and commonly used for research on LLM understanding, and this was the main reason why we picked it. Including this dataset afforded the measurement of robustness to paraphrases with and without LASER (See Section 5.1 para 3). This study deepened our understanding of LASER\u2019s robustness to paraphrases. Additionally, we provide results on 7 other datasets, including 3 new datasets that we added in this rebuttal. Specifically, we have also included the effect of LASER on WikiData QA, a similar benchmark from Big Bench."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700542854971,
                "cdate": 1700542854971,
                "tmdate": 1700543444891,
                "mdate": 1700543444891,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TY1MJFrkdS",
                "forum": "ozX92bu8VA",
                "replyto": "hnL7aNhZPc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4114/Reviewer_4cdi"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4114/Reviewer_4cdi"
                ],
                "content": {
                    "comment": {
                        "value": "Again, I appreciate the authors trying very hard to demonstrate their observations by adding more results to their responses. However, as Reviewer F88a says, this paper presents a surprising result, I still want to hold back my score. The reason is that the authors try to say that this low-rank approximation and the resulting improvement could generalize well to a wide range of transformation models. However, the backbone models here are very limited. GPTJ and Roberta may not be the most suitable base models to validate currently. Also, if we want to demonstrate even a very simple modification to work well on current LLMs (say Llama alone), we need to evaluate extensive benchmark dataset collections, as I mentioned (MMLU, BBH, AGIEval and many others), and each of them includes multiple datasets (say BBH has 27 datasets). So, there is still a long way to go before reaching the conclusion that this work draws here. And I will be very pleased if someday the authors can convince the community to incorporate this idea as a standard module for Transformer."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700647193457,
                "cdate": 1700647193457,
                "tmdate": 1700647193457,
                "mdate": 1700647193457,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Iwb6NFvMnW",
            "forum": "ozX92bu8VA",
            "replyto": "ozX92bu8VA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4114/Reviewer_F88a"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4114/Reviewer_F88a"
            ],
            "content": {
                "summary": {
                    "value": "LLMs are usually considered \u201cthe larger the better\u201d, but this paper presents a surprising result: it is often possible to improve the performance of LLMs by simply removing higher-order components of their constituent weight matrices in the MLP layers. This paper presents this rank reduction method, LASER, that removes the components in the {Q,K,V,O} matrices that have smaller singular values (i.e., those higher-order components).\n\nThis paper finds that the effects of reduction is not uniform across layers. The performance degradation can be found by reducing early layers, while significant performance benefits are available, often by pruning the later layers. This effect is the most obvious in the MLP output, and is also observable in the k, q, v matrices.\n\nThis paper further dives into studying what types of facts are recovered by rank reduction, and finds that the facts recovered on rank reduction are most likely those infrequently present in the data. \n\nWhy are the higher-ordered components noisy? And what are the higher-ordered components computing? This paper approximates the final weight matrix using its higher-ordered components, and analyze how the model\u2019s behavior changes on the datapoints that GPT-J\u2019s lower-order components lead to incorrect outputs. They find that the model predicts incorrect entities of the same semantic type as the correct answer. As more lower-ordered components are included, the output changes to predicting common word tokens.\n\nWith additional experiments (on text domains including QA and non-text-domains including learning policies, images), this paper studies the generalizability of the findings."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- This paper is well-written and easy to read.\n- The experiments are designed thoughtfully, and nicely supports the hypothesis.\n- The findings are important for both the understanding and the developments of better models in the future."
                },
                "weaknesses": {
                    "value": "I do not see obvious weaknesses in this paper. There is a typo: Table 3 needs a horizontal line at the bottom."
                },
                "questions": {
                    "value": "Seems like the MLP layers are the key components in storing the noise vs storing the \u201cuseful inductive biases\u201d. I wonder if some structural choices (e.g., different position embedding methods, different activation functions, number of heads, etc.) can affect Transformer\u2019s low-rank vs high-rank component behavior as well."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "10: strong accept, should be highlighted at the conference"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4114/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698700023538,
            "cdate": 1698700023538,
            "tmdate": 1699636376035,
            "mdate": 1699636376035,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "48XJfG2aBx",
                "forum": "ozX92bu8VA",
                "replyto": "Iwb6NFvMnW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4114/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4114/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you. Added additional discussion and results."
                    },
                    "comment": {
                        "value": "We thank you for your encouraging remarks. \n\nWe have added the missing horizontal line in Table 3 and thank you for pointing it out. \n\n_We have also added results on more datasets, which also show notable gains due to LASER and further support our main argument (see Table 4 in Appendix F and in the general response)._ We have also added experimental details in the Appendix. All edits are indicated by red text.\n\n\n>Seems like the MLP layers are the key components in storing the noise vs storing the \u201cuseful inductive biases\u201d. I wonder if some structural choices (e.g., different position embedding methods, different activation functions, number of heads, etc.) can affect Transformer\u2019s low-rank vs high-rank component behavior as well. \n\nExamining how structural choices in model design affect the low-rank and high-rank components of the MLP layers is an intriguing question that could advance our understanding of this phenomenon and of transformer models in general. While we consider a thorough investigation of this question to be outside the scope of this work, and it will require training models with different structural choices from scratch, we have included a discussion of this in our paper to contextualize our results in light of this discussion (please see Appendix F)."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700541066088,
                "cdate": 1700541066088,
                "tmdate": 1700541066088,
                "mdate": 1700541066088,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8dyERy5i1a",
                "forum": "ozX92bu8VA",
                "replyto": "48XJfG2aBx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4114/Reviewer_F88a"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4114/Reviewer_F88a"
                ],
                "content": {
                    "title": {
                        "value": "Reviewer reply"
                    },
                    "comment": {
                        "value": "Thanks for the response. I'm happy to keep my original score."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700630108554,
                "cdate": 1700630108554,
                "tmdate": 1700630108554,
                "mdate": 1700630108554,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]