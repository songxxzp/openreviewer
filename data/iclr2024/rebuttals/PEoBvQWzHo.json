[
    {
        "title": "Dirichlet-based Uncertainty Quantification for Personalized Federated Learning with Improved Posterior Networks"
    },
    {
        "review": {
            "id": "hR629YTBri",
            "forum": "PEoBvQWzHo",
            "replyto": "PEoBvQWzHo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5281/Reviewer_p9yL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5281/Reviewer_p9yL"
            ],
            "content": {
                "summary": {
                    "value": "Within the realm of personalized federated learning, personalized models may exhibit suboptimal performance when confronted with data from disparate domains. This paper aims to devise a criterion rooted in uncertainty assessment, serving as a means to decide whether to employ a global model or a local model. This approach is envisioned to enhance performance on both in-distribution and out-of-distribution data."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The writing is of high quality.\nThe algorithm is underpinned by a solid theoretical foundation. They introduce a stop gradient operation subsequent to the analysis of the problems associated with off-the-shelf loss functions."
                },
                "weaknesses": {
                    "value": "1. Novelty is limited\n\nSeems that most of the framework is directly taken from previous works, and this paper just combines and applies these in the federated learning setting as an application. For example, the Dirichlet-based model formulation is the same as [1] and [2], and the criteria are based on [3] and [4]. The only modification seems to be the stop-gradient operation based on the analysis on page 6~7.\n\n2. Cannot scale to more complex datasets like CIFAR-10\n\nFrom Table 2, it seems that there is a significant drop in the in-distribution data. An improvement from $10+%$ to $20+%$ cannot mitigate the performance drop from $70+%$ to $50+$. This challenges the model ability in this Dirichlet-based framework, especially for even more complex datasets like CIFAR-100 and Tiny-ImageNet.\n\n3. Additional computation\n\nThe authors mention that they have to use a density model to decide if they should use a global or local model. This extra step adds more work for the computer. Even if they use a simple model, the reason why the model doesn't perform well on hard datasets might be that this density model is not very strong. But making this special model stronger would require more computation.\n\n[1] Bertrand Charpentier, Daniel Z\u00fcgner, and Stephan G\u00fcnnemann. Posterior network: Uncertainty estimation without ood samples via density-based pseudo-counts. Advances in Neural Information Processing Systems, 33:1356\u20131367, 2020.\n\n[2] Bertrand Charpentier, Chenxiang Zhang, and Stephan G\u00fcnnemann. Training, architecture, and prior for deterministic uncertainty methods. In ICLR 2023 Workshop on Pitfalls of limited data and computation for Trustworthy ML, 2023.\n\n[3] Andrey Malinin and Mark Gales. Predictive uncertainty estimation via prior networks. Advances in neural information processing systems, 31, 2018.\n\n[4] Alex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer vision? Advances in neural information processing systems, 30, 2017."
                },
                "questions": {
                    "value": "Are there any explanations on why you can use entropy and average entropy as the criteria for Epistemic uncertainty and Aleatoric uncertainty respectively in Section 3.2?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5281/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698584662048,
            "cdate": 1698584662048,
            "tmdate": 1699636528049,
            "mdate": 1699636528049,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8iHNqjTo5Z",
                "forum": "PEoBvQWzHo",
                "replyto": "hR629YTBri",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5281/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5281/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their thorough review and feedback. We address their questions below.\n\n**1. Novelty is limited. Most of the framework is directly taken from previous works. Dirichlet-based model formulation is the same as [1] and [2], and the criteria are based on [3] and [4]. The only modification seems to be the stop-gradient operation based on the analysis on page 6~7.**\n\nWe kindly disagree with this assessment. Our main innovation is suggesting a new approach to switching between local and global models based on uncertainty quantification.  We believe that this methodological novelty is the main contribution of our paper. Everything else is already an implementation of a general idea, and we agree that we mostly use techniques that were known previously. However, the problem with the loss function identified by us was not known before despite this loss function has been used in a series of high impact papers. Thus, we think that it is another non-trivial contribution of our paper. \n\n\n**2. Cannot scale to more complex datasets like CIFAR-10.  Significant drop in the in-distribution data in Table 2\u2026 An improvement from 10+ to 20+ cannot mitigate the performance drop from 70+ to 50+. This challenges the model ability in this Dirichlet-based framework, especially for even more complex datasets like CIFAR-100 and Tiny-ImageNet.**\n\n\nWe want to emphasize that it is not the problem of the particular method. All the datasets dropped in quality on this dataset for a given specific data heterogeneity. Please note that our method still improved upon the others.\n\n\n**3. Additional computation. Learning a density model adds more work for the computer. Even for a simple model, the reason why the model doesn't perform well on hard datasets might be that this density model is not very strong. But making this special model stronger would require more computation.**\n\n\nWe agree with this point. Learning an additional density model is indeed of extra cost and may be considered as the limitation of the model. \nHowever, we should emphasize that not only the density model is important, but also the feature extractor itself. If the resulting features are good, then we don\u2019t need to train a stronger density model given the intuition that representations are well clustered.\nAlso, sometimes simple density models work pretty well [1, 2].\n\nAdditionally, adding a density model is not just for the sake of improving the performance. It allows us to receive good uncertainty estimates and distinguish between different types of it. So the extra price is justified.\n\n\n[1] Bertrand Charpentier, Oliver Borchert, Daniel Z\u00fcgner, Simon Geisler, and Stephan G\u00fcnnemann. Natural posterior network: Deep bayesian predictive uncertainty for exponential family distributions. In International Conference on Learning Representations, 2022.\n\n[2] Vazhentsev, Artem, et al. \"Efficient Out-of-Domain Detection for Sequence to Sequence Models.\" Findings of the Association for Computational Linguistics: ACL 2023. 2023.\n\n\n**Q1: Are there any explanations on why you can use entropy and average entropy as the criteria for Epistemic uncertainty and Aleatoric uncertainty respectively in Section 3.2?**\n\n\nThe idea of using the entropy of the predicted Dirichlet distribution is rooted in the paper of [1, 2]. There is a connection between the sampling from the posterior of weights and the simplex, parameterized by Dirichlet. Specifically, Bayesian Model Averaging involves sampling from the posterior over weights, resulting in the posterior predictive distribution. This sampling from the posterior is an implicit sampling from the simplex, and we can parameterize the distribution over this simplex directly. The spread over the simplex is an indicator of the disagreement between models and thus can be used as an estimate of epistemic uncertainty. This spread can be measured, for example, as the entropy of the predictive Dirichlet.\nAbout aleatoric uncertainty - we follow ideas from [3]. Since aleatoric uncertainty is well-defined only for in-distribution samples, then every sample of the weights from posterior over weights should result in some ambiguous distribution over the simplex. That is why we find entropy first (which will be big for ambiguous samples), and then average it over all possible samples. Thus we result in the expected entropy as in equation (4). \n\n\n[1] Malinin, A., & Gales, M. (2018). Predictive uncertainty estimation via prior networks. Advances in neural information processing systems, 31.\n\n[2] Malinin, A., & Gales, M. (2019). Reverse kl-divergence training of prior networks: Improved uncertainty and adversarial robustness. Advances in Neural Information Processing Systems, 32.\n\n[3] Kendall, A., & Gal, Y. (2017). What uncertainties do we need in bayesian deep learning for computer vision?. Advances in neural information processing systems, 30."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5281/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700138515776,
                "cdate": 1700138515776,
                "tmdate": 1700138515776,
                "mdate": 1700138515776,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZQZOGsqaht",
                "forum": "PEoBvQWzHo",
                "replyto": "hR629YTBri",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5281/Reviewer_p9yL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5281/Reviewer_p9yL"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks the authors for the rebuttal. Regarding the experimental results, I acknowledge that FedPN outperforms the baselines in smaller datasets, but I observe a more pronounced trade-off between InD and OOD performance in FedPN on CIFAR-10. Specifically, the improvement in OOD performance from 0 to 28% doesn't seem to fully compensate for the decline from 80% to 60% in comparison to the baselines. This raises my curiosity about FedPN's effectiveness on more complex datasets like CIFAR-100 and Tiny-ImageNet.\n\nIn terms of novelty, while I recognize some new analysis in your work, I find it to be somewhat incremental.\n\nAs such, I am inclined to maintain my original score."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5281/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700649916947,
                "cdate": 1700649916947,
                "tmdate": 1700649949697,
                "mdate": 1700649949697,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "SoCxvMZ9Qe",
            "forum": "PEoBvQWzHo",
            "replyto": "PEoBvQWzHo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5281/Reviewer_g6z9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5281/Reviewer_g6z9"
            ],
            "content": {
                "summary": {
                    "value": "The paper sets out to introduce uncertainty quantification to Federated Learning. This can be particularly useful in deciding whether to use a local or global (federated) model for each user and sample. To this end, the paper uses a deep Bayesian algorithm, NatPN, with a slight modification to the loss function. Experiments show that the proposed framework can reduce the error on the OOD data while (often) not degrading on the InD data compared to existing baselines in Federated Learning."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Judging by the Introduction, the research question is relevant to Federated Learning, and the contributions are original.\n- The conceptual scheme in 2.1 makes sense. The paper clearly explains the different kinds of uncertainties and their importance in the context of Federated Learning.\n- Design choices such as Dirichlet-based models, pseudo-count representation of $\\alpha$, and entropy-based uncertainty estimates, seem sensible.\n- The core experimental setup, i.e., dividing the data into InD and OOD, is sound."
                },
                "weaknesses": {
                    "value": "- The methodological novelty is limited to applying existing approaches to a new problem.\n- The authors are right to note that the choice of the uncertainty threshold is the most subjective part of the approach. Ablations (where the threshold is varied) are required to inspect how important this choice is. This also leads me to a concern about the conceptual scheme described in 2.1: a misestimated threshold may result in abstaining from predictions in a large portion of the data. Perhaps, the global model should not abstain at all?\n- I am not sure about best practices in image classification these days, but the datasets seem simple.\n- One issue I have with Table 2 is that the Mix score depends on the mixing proportions. I think it would be more illustrative to divide this table into InD and OOD tables and highlight with bold the best models in the respective tables.\n- Ablations are required to complement the fix proposed in 3.3. Otherwise, I remain unconvinced that the described issue \u201ccould be a potential issue in federated learning\u201d or even exists.\n\nMinor issues\n- Some parts were unclear from the submission and I had to read cited sources to understand them. After eq. 2, properties of p(g(x)) are listed, but it isn\u2019t explained why f(g(x)) is required (as far as I understood, this term is a class prior, but then I do not exactly understand why it is required along with $\\alpha_{prior}$). Eq. 5 is hard to parse as cross-entropy, consider using $CE$ like Charpentier et al. (2020)."
                },
                "questions": {
                    "value": "- Can there be scenarios where the scheme in 2.1 should be reversed? I.e., where the global model may have higher epistemic uncertainty.\n- Could the general approach be extended to other Federated tasks such as Regression or RL?\n- From the bounds of $\\psi(x)$ before eq. 7, wouldn\u2019t it make more sense to approximate it as $log(x) - 1/x$? Would it change the conclusions about issues with the loss function?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5281/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698671704520,
            "cdate": 1698671704520,
            "tmdate": 1699636527921,
            "mdate": 1699636527921,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fJUX6cZC4R",
                "forum": "PEoBvQWzHo",
                "replyto": "SoCxvMZ9Qe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5281/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5281/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their thorough review and feedback. We address their questions below.\n\n**1. The methodological novelty is limited to applying existing approaches to a new problem.**\n\n\nWe kindly disagree with this assessment. We are not considering any new problem but rather suggest a new approach to switching between local and global models based on uncertainty quantification.  We believe that this methodological novelty is the main contribution of our paper. Everything else is already an implementation of a general idea, and we agree that we mostly use techniques that were known previously. However, the problem with the loss function identified by us was not known before despite this loss function has been used in a series of high impact papers. Thus, we think that it is another non-trivial contribution of our paper. \n\n\n**2. Ablation for the threshold selection.**\n\nThis is an interesting and important point, and we are currently working on the corresponding experiment. As soon as it is ready, we will add it to the text.\n\n- This also leads me to a concern about the conceptual scheme described in 2.1: a misestimated threshold may result in abstaining from predictions in a large portion of the data. Perhaps, the global model should not abstain at all?\n\nThis is true, that misestimated threshold may lead to the abstaining for a large portion of the data. However, the models (local and global) have different thresholds. One can set the threshold for the global moel high enough so that it rarely abstains. However, the applications that imply the possibility of abstention of any predcition (for example, when it possible to refer to human expert) may benefit from the abstention of the global model.\n\n\n**3. I am not sure about best practices in image classification these days, but the datasets seem simple.**\n\nThank you for your comment. We wish to emphasize that the datasets we employed are standard in the federated learning (FL) community and widely recognized as adequate for evaluating federated algorithms. Seminal works in FL, such as FedProx [1], SCAFFOLD [2], and FedOpt [3], have also utilized these datasets. We believe our evaluation effectively demonstrates the viability of our proposed approach.\n\nWe acknowledge the reviewer's concerns regarding the complexity of the datasets. We will endeavor to include additional evaluations on a more complex dataset by the end of the discussion period or in the camera-ready version of our paper. However, we anticipate that the results will align with those already presented in our manuscript.\n\n[1] Li, T., Sahu, A. K., Zaheer, M., Sanjabi, M., Talwalkar, A., & Smith, V. (2020). Federated optimization in heterogeneous networks. Proceedings of Machine learning and systems, 2, 429-450.\n\n[2] Karimireddy, S. P., Kale, S., Mohri, M., Reddi, S., Stich, S., & Suresh, A. T. (2020, November). Scaffold: Stochastic controlled averaging for federated learning. In International conference on machine learning (pp. 5132-5143). PMLR.\n\n[3] Reddi, S., Charles, Z., Zaheer, M., Garrett, Z., Rush, K., Kone\u010dn\u00fd, J., ... & McMahan, H. B. (2020). Adaptive federated optimization. ICLR 2021\n\n\n\n**4. One issue I have with Table 2 is that the Mix score depends on the mixing proportions. I think it would be more illustrative to divide this table into InD and OOD tables and highlight with bold the best models in the respective tables.**\n\nThank you for the suggestion! We have split the table into several ones and added them to the supplementary part of the paper.\n\n\n**5. Ablations are required to complement the fix proposed in 3.3. Otherwise, I remain unconvinced that the described issue \u201ccould be a potential issue in federated learning\u201d or even exists.**\n\nWe apologize for being imprecise by saying that this led to issues in federated learning. In fact, the issue is general, and it holds not only for the federated scenario but also for the centralized one. Thank you for pointing it out!\nThe demonstration of the issue is already in Figure 2. However, to make it even more apparent, we will add the same plot for the loss function with the proposed fix.\nEven further, we slightly change the locations of the point clouds. The reason for that is the untrained flow by default initializes higher density in the origin. So we move the noisy blob to the point of (0, 1) and add new results."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5281/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700137983362,
                "cdate": 1700137983362,
                "tmdate": 1700137983362,
                "mdate": 1700137983362,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uJoGIEG3OH",
                "forum": "PEoBvQWzHo",
                "replyto": "f864sBOeP5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5281/Reviewer_g6z9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5281/Reviewer_g6z9"
                ],
                "content": {
                    "title": {
                        "value": "Response to rebuttal"
                    },
                    "comment": {
                        "value": "Thank you for the detailed response! It helps my understanding.\n\n1. Yes, I think we mean the same thing. I didn't mean that the problem itself is new, but rather that applying this approach to this problem is new.\n\n2. Let me know how it goes!\n\n3. Could you please also provide references to some newer publications in FL? Other reviewers also seem to have problems with datasets.\n\n5 and Q3. Ok, the issue is demonstrated to be real for the loss function. Still, this contribution seems too independent at the moment. If we removed this part from the text and used the old loss function, would the experimental results in section 5 change? Would the performance drop? An ablation is required to investigate.\n\nQ1 and Q2. Thank you for the clarifications, consider adding those to the text."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5281/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700142775981,
                "cdate": 1700142775981,
                "tmdate": 1700142775981,
                "mdate": 1700142775981,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jEYcA0gbhB",
                "forum": "PEoBvQWzHo",
                "replyto": "SoCxvMZ9Qe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5281/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5281/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for your valuable feedback!\n\nFollowing your suggestions, we have conducted additional experiments, focusing on threshold selection ablation (detailed in Section B.4) and evaluating the effectiveness of the Stopgrad technique (described in Section B.5). We kindly invite you to review these additions, along with our general response to all reviewers.\nIn relation to your query about recent publications, see for example these:\n1) Yu, S., Hong, J., Wang, H., Wang, Z., & Zhou, J. (2022, September). Turning the curse of heterogeneity in federated learning into a blessing for out-of-distribution detection. In The Eleventh International Conference on Learning Representations\n\n2) Kumar, S., Lakshminarayanan, A., Chang, K., Guretno, F., Mien, I. H., Kalpathy-Cramer, J., ... & Singh, P. (2022, September). Towards more efficient data valuation in healthcare federated learning using ensembling. In International Workshop on Distributed, Collaborative, and Federated Learning (pp. 119-129). Cham: Springer Nature Switzerland.\n\n3) Li, B., Shi, Y., Kong, Q., Du, Q., & Lu, R. (2023). Incentive-Based Federated Learning for Digital Twin Driven Industrial Mobile Crowdsensing. IEEE Internet of Things Journal.\n\n4) Zhai, R., Chen, X., Pei, L., & Ma, Z. (2023). A Federated Learning Framework against Data Poisoning Attacks on the Basis of the Genetic Algorithm. Electronics, 12(3), 560."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5281/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700736568905,
                "cdate": 1700736568905,
                "tmdate": 1700739109806,
                "mdate": 1700739109806,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "t2dGdYujdi",
            "forum": "PEoBvQWzHo",
            "replyto": "PEoBvQWzHo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5281/Reviewer_LHCT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5281/Reviewer_LHCT"
            ],
            "content": {
                "summary": {
                    "value": "Authors propose to use Dirichlet models for uncertainty quantification for personalized federated learning setup."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "(1) First time using Dirichlet methods to assess uncertainty quantification in PFL to deal with OOD and mix of In & OOD.\n\n(2) I liked the idea of showing Mix and OOD data in experiments. Especially the Table 2. I have more comments in Weaknesses though."
                },
                "weaknesses": {
                    "value": "(1) Authors claim to use Dirichlet methods for uncertainty quantification but do not compare with existing Bayesian federated methods such as FedPA[1], FedEP[2] , and FedPop[3], which are also assumed to perform efficient Bayesian inference for (P)FL.\n\n\n(2) Comparison is unfair for multiple reasons : 1)  Other models do not use a switching model. Technically speaking, other personalized FL models can benefit from \"switching\" too, but not exactly with the same way as this paper does. Also, the proposed method is the only method geared toward uncertainty quantification.  Bayesian FL methods and/or the methods mentioned above should be included as those methods are  (in)directly uncertainty quantification methods too. The paper claims that Dirichlet is an efficient method compared to MCMC and VI, but what about in terms of performance in federated settings? \n\n(3) 20 clients is practically low, and having an equal number of data points is not a practical assumption. I think 100 clients and using more difficult datasets such as CIFAR100 and Stackoverflow would be needed.  Also, an ablation study over the number of clients would be needed, too.\n\n(4) The claim \"In this paper, we proposed a personalized federated learning framework that leverages both a globally trained federated model and personalized local models to make final predictions.\" is misleading as there are previous papers utilizing both global and local models for prediction [4] \n\n(5) The transition from Section 3 to federated settings is poorly developed. Section 3 has too much text in it it is not clear what are the problems/complications of using Dirichlet methods in federated settings. Authors should condense Section 3 and move some parts to the Appendix as it is hard to understand what is the problem for federated learning.\n\n\n[1] Al-Shedivat, Maruan, et al. \"Federated learning via posterior averaging: A new perspective and practical algorithms.\" ICLR'21 arXiv:2010.05273 (2020).\n[2] Guo, Han, et al. \"Federated Learning as Variational Inference: A Scalable Expectation Propagation Approach.\" ICLR '23arXiv:2302.04228 (2023).\n[3] Kotelevskii, Nikita, et al. \"Fedpop: A bayesian approach for personalised federated learning.\" Advances in Neural Information Processing Systems 35 (2022): 8687-8701.\n[4] Hanzely, Filip, and Peter Richt\u00e1rik. \"Federated learning of a mixture of global and local models.\" arXiv preprint arXiv:2002.05516 (2020)."
                },
                "questions": {
                    "value": "(1) Why is there no comparison with previous Bayesian FL methods such as such as FedPA[1], FedEP[2], and FedPop[3] ?\n\n(2) Federated loss was unclear to me. Are you using the loss in Eqn. (8)?\n\n\n\n[1] Al-Shedivat, Maruan, et al. \"Federated learning via posterior averaging: A new perspective and practical algorithms.\" ICLR'21 arXiv:2010.05273 (2020).\n[2] Guo, Han, et al. \"Federated Learning as Variational Inference: A Scalable Expectation Propagation Approach.\" ICLR '23arXiv:2302.04228 (2023).\n[3] Kotelevskii, Nikita, et al. \"Fedpop: A bayesian approach for personalised federated learning.\" Advances in Neural Information Processing Systems 35 (2022): 8687-8701."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5281/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698792571068,
            "cdate": 1698792571068,
            "tmdate": 1699636527801,
            "mdate": 1699636527801,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qa7roHDcV2",
                "forum": "PEoBvQWzHo",
                "replyto": "t2dGdYujdi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5281/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5281/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their thorough review and feedback. We address their questions below.\n\n1. **Comparison with Bayesian Baselines FedPA[1], FedEP[2], and FedPop[3]:**\n\nIn the FedPA paper, the authors adopt a Bayesian approach to derive a global posterior from locally distributed data. This focus leads to an optimization process that results in the global model, lacking personalization. The adaptation of our switching procedure to their model is not straightforward. Similarly, the FedEP paper also focuses on the global posterior without offering personalized models, making it unclear how to compare our local/global models with their method.\n\nAs for the FedPop paper, while it adopts a Bayesian view and has personalization, they don\u2019t have a notion of a global model. They indeed have a shared backbone (feature extractor) and many local personalized models. However, no proper global model. Moreover, they do not provide a method for separately evaluating epistemic and aleatoric uncertainties.\n\nWe wish to highlight that our paper's *main contribution is the introduction of the switching framework.* This framework is general, allowing for various implementations, whether they are based on Variational Inference (VI) or Markov Chain Monte Carlo (MCMC) methods. We chose to illustrate this framework with a Dirichlet-based model because of its relative ease of training, straightforward implementation, and intuitive way of measuring epistemic uncertainty.\n\n\n**2. Comparison is unfair for multiple reasons:**\n\n- Other models do not use a switching model\n\nWe appreciate the observation regarding the lack of switching strategies in other methods. Indeed, our approach is unique in this aspect. Implementing a similar switching strategy in other models is not a straightforward task. \n\nThis complexity arises from the complications involved in identifying a suitable metric for switching that aligns with the specific characteristics and objectives of each model. Our method was specially designed with a switching strategy that is integrated into its core framework, making the replication of this feature in other models non-trivial. This feature not only demonstrates the innovation of our approach but also underscores the challenges in adapting such strategies to different models. Moreover, not all the models used in the list of baselines we compared with are personalized. Hence, it is questionable what are those models between which we should switch.\n\n- The proposed method is the only method geared toward UQ. Bayesian FL methods and/or the methods mentioned above should be included as those methods are (in)directly uncertainty quantification methods too.\n\nUncertainty quantification is an essential part of our approach that gives the full UQ capabilities for the resulting system of models. However, our main innovation is not in UQ itself but rather in its application to switching between local and global models. That is why our experiments are focused on classical performance metrics such as accuracy, and not on the evaluation of predictive uncertainty. Even if we have an estimate of uncertainty for some model, it is not clear how we should proceed with them for switching as some of the mentioned models do not have a global model at all. For example, in FedPop there is no global model, but only local ones (which are compositions of the global parameters and local ones sampled from some population prior).\n\n- The paper claims that Dirichlet is an efficient method compared to MCMC and VI, but what about in terms of performance in federated settings?\n\nIndeed, our approach utilizing the Dirichlet method can be seen as a lightweight form of VI, offering greater computational efficiency compared to standard VI techniques and MCMC. The latter, particularly, requires significant time both to converge to the target posterior and to obtain uncorrelated samples.\nOur paper's primary contribution is the introduction of a novel switching framework. We specifically chose the Dirichlet-based model within this framework for its computational lightness and its advantages in practical scenarios. While it's true that employing MCMC with many computational resources might yield superior results, our aim is not to demonstrate state-of-the-art performance. Rather, we focus on presenting a new concept in model selection that was previously unexplored, along with validating its effectiveness through practical application."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5281/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700136940521,
                "cdate": 1700136940521,
                "tmdate": 1700136940521,
                "mdate": 1700136940521,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YGvnZI5s2Y",
                "forum": "PEoBvQWzHo",
                "replyto": "AufcJ0XkTe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5281/Reviewer_LHCT"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5281/Reviewer_LHCT"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "Thanks to the authors for the rebuttal. I understand that the contribution is switching model, but the main problem is the evaluation of and ablation over \"switching model.\"\n\nI am inclined to maintain my original score."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5281/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700735285235,
                "cdate": 1700735285235,
                "tmdate": 1700735285235,
                "mdate": 1700735285235,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]