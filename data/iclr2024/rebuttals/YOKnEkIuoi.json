[
    {
        "title": "Conditional Variational Diffusion Models"
    },
    {
        "review": {
            "id": "diXwQDxQP9",
            "forum": "YOKnEkIuoi",
            "replyto": "YOKnEkIuoi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5967/Reviewer_gCsZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5967/Reviewer_gCsZ"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents an extension of variational diffusion models to the conditional setting. In particular, the paper makes the following novel contributions:\n1. An element-wise learned variance schedule is used.\n2. The learned variance schedule is factorized wrt. time and the conditioning variable.\n3. The continuous time shedule is formulated in a different way than in Kingma et al. and new loss terms enforcing constraints is introduced.\nThe method is demonstrated on two image processing problems."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Developing variational diffusion models and making them practically useful is an important and timely problem.\n\nThe proposed methods appear sound and reasonable, and seem to work well in practice.\n\nThe paper includes supplementary material where ample technical details are given, allowing the reader to follow each step of the derivations.\n\nThe paper presents several novel contributions beyond the existing literature."
                },
                "weaknesses": {
                    "value": "In the abstract, learning the variance schedule is stated as a main contribution, however it is not clear from the abstract in which way the proposed method differs from existing methods that learn the variance schedule.\n\nIn general, it is not clearly stated what the contributions are beyond previous work, particularly Kingma et al. 2023. It would be a strong improvement to have a clear list of technical contributions in the beginning of the paper, allowing the reader to have an overview from the beginning.\n\nBefore eq. 1 it is mentioned that a continuous time diffusion is used, however, the manuscripts proceeds with discrete time steps. Since in the end, the continuous time formulation is used, I wonder if the presentation could be more direct, building on the continuous time formulation in Kingma et al. 2023?\n\nThe technical novelty of the paper is fairly limited, but while the novel contributions might be minor, it could still be practically important. However, it is not absolutely clear from the paper, to what extent these contributions are important for performance. An ablation study or a direct comparison with Kingma et al. 2023 could have illuminated this more direcly."
                },
                "questions": {
                    "value": "The introduction begins with a relatively high level discussion of inverse problems, which in my view is a bit removed from the specific contributions of the paper. Maybe it could be an idea to motivate the paper more directly by mentioning specific inverse problems that the method is suitable for, such as the super resolution microscopy problem?\n\n\"To achieve this, we adopt the framework proposed by Saharia et al. (2021), which focuses on training with the statistics of the noise at each timestep rather than direct timesteps, thus allowing flexible use of the model during inference.\" Could you clarify what this means?\t\n\nIn the final loss, you drop the term SNR'/SNR. A large portion of the paper is dedicated to the design of the variance schedule mechanism. Would it be possible to include some more discussion / insights into why this term can reasonably be dropped? I realize this if done in many other papers as well, but usually without much discussion."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5967/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697812199877,
            "cdate": 1697812199877,
            "tmdate": 1699636637583,
            "mdate": 1699636637583,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "90KRjC8m9p",
                "forum": "YOKnEkIuoi",
                "replyto": "diXwQDxQP9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your detailed review. We have addressed your concerns in our response and in the text of the paper."
                    },
                    "comment": {
                        "value": "# Official Comment for Reviewer gCsZ\n\nThank you for taking the time to review our work. We appreciate your detailed suggestions and criticisms, which we think will help us improve our paper. Please find below detailed clarification to your comments and questions. We have also included this material in the new version of the paper, highlighting the text in blue to make it easier to find.\n\n## Weakness #1\n\n> *In the abstract, learning the variance schedule is stated as a main contribution, however, it is not clear from the abstract in which way the proposed method differs from existing methods that learn the variance schedule.*\n>\n> *In general, it is not clearly stated what the contributions are beyond previous work, particularly Kingma et al. 2023. It would be a strong improvement to have a clear list of technical contributions in the beginning of the paper, allowing the reader to have an overview from the beginning.*\n\nThanks for pointing out this issue. We understand your concerns and agree with your suggestion. We have included a bullet list in the Introduction (Section 1) explicitly stating the contributions of our work. Also, in Related Work (Section 2), we have included a summary of Variational Diffusion Models (VDMs, Kingma et al. 2023) and explained some of the differences with our method. Moreover, throughout the paper, we have extended the discussions about our technical contributions and their importance for the success of the method. See especially Sections 3.1, 3.2 and 3.4. We also include here a relevant summary.\n\nVDMs (Kingma et al. 2023) constitute the main framework described in the literature for learning the variance schedule.  VDMs formulate a diffusion process for unconditioned distribution sampling, where the latent variables are indexed in continuous time, and the schedule is a learnable function that must satisfy a few minimal conditions. The parameters of the schedule are defined as a monotonic network, and the model is trained by minimizing a weighted version of the noise prediction loss. Their work also uses Fourier features to improve the prediction of high-frequency details. We introduce the Conditional Variational Diffusion Model (CVDM), which includes important generalizations and novelties with respect to VDMs:\n\n- Similarly to Kingma et al. (2023), we learn the schedule as part of the training. However, we extend their approach to the conditioned case. This turns out to be a highly non-trivial task, as detailed below. We also allow for learning a different schedule for each element in the output (e.g., a pixel-wise schedule for images). These extensions require several technical novelties, including a separation-of-variables approach when defining the schedule (details in Section 3.2).\n- We prove that the rate of convergence of the discrete-time diffusion loss to the continuous-time case depends strongly on the schedule functions. Kingma et al. (2023) show that diffusion models are invariant to the schedule selection in the continuous case. Nevertheless, any discretization used for model sampling will introduce the dependency shown in Appendix E.2 on the schedule's derivatives. Our finding motivates the introduction of a novel regularization term that proves to be critical for the performance of our method (details in Section 3.4).\n- We replace the architecture in Kingma et al. (2023) with two networks, one required to be positive (for the conditioning variable) and one monotonic-convolutional network (for the time variable). This allows us to test our model with inputs of different resolutions without retraining. Moreover, by incorporating some schedule properties in the loss function, our method does not need the post-processing of the schedule that Kingma et al. 2023 uses, nor the preprocessing of the input. This results in a cleaner and more straightforward method. \n\nOur approach results in a streamlined implementation that requires minimum fine-tuning for new domains of application, and can be readily used for conditioned problems."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5967/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699979471997,
                "cdate": 1699979471997,
                "tmdate": 1700182388169,
                "mdate": 1700182388169,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "H3lrJU2jDq",
                "forum": "YOKnEkIuoi",
                "replyto": "diXwQDxQP9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We continue our response to your concerns and questions."
                    },
                    "comment": {
                        "value": "## Weakness #2\n\n> *Before eq. 1 it is mentioned that a continuous time diffusion is used, however, the manuscripts proceeds with discrete time steps. Since in the end, the continuous time formulation is used, I wonder if the presentation could be more direct, building on the continuous time formulation in Kingma et al. 2023?*\n\nWe appreciate your insight. We considered using a continuous-time formulation in the spirit of Kingma et al. 2023. In some ways, we still follow a continuous-time formulation. For instance, the schedule is represented by functions instead of finite sequences (in contrast to Ho et al. 2020 for instance). That being said, the forward process and its posterior are indeed first introduced using a time discretization. We chose this formulation for a few reasons:\n\n1. We find it simpler for our case. In particular, given latent variables $\\mathbf{z}\\_s$ and $\\mathbf{z}\\_t$, Kingma et al. 2023 provide expressions for the forward process and the posterior distribution, for **any** values of $t,s$. In our (conditioned) case, that would correspond to $q(\\mathbf{z}\\_t|\\mathbf{x}\\_s,\\mathbf{x})$ and $q(\\mathbf{z}\\_t|\\mathbf{z}\\_s,\\mathbf{y},\\mathbf{x})$ for any $t,s$. We don't need the full generality of these expressions for training or inference, so it is unnecessary to introduce them. The inference is performed for a time discretization anyway, so we find it simpler and more natural to introduce the diffusion process in that context.\n2. Our formulation allows us to derive equation (4) from more elementary ideas, without relying on stochastic calculus.\n3. As we highlight in Section 3.4, a result that holds for continuous time may not hold once time is discretized (which is the case for any practical implementation). In that sense, we prefer to introduce the diffusion process in discrete time, and formulate the continuous-time case as the limit when $T \\rightarrow\\infty$. Then, we can analyze how different properties change from one setting to the other.\n\nWe agree that our introduction to the formulation sounds confusing before equation (1). We have rewritten that part of Section 3.1 to better represent our approach.\n\n\n## Weakness #3\n\n> *The technical novelty of the paper is fairly limited, but while the novel contributions might be minor, it could still be practically important. However, it is not absolutely clear from the paper, to what extent these contributions are important for performance. An ablation study or a direct comparison with Kingma et al. 2023 could have illuminated this more direcly.*\n\nThanks for this suggestion. We have clarified the role played by our specific contributions in the new version of the paper (see for instance Sections 3.2, 3.4 and 4.3). We are also performing an ablation study. Some important points:\n\n1. The regularization term described in Section 3.4 is critical to keep the schedule from converging to an uninformative solution that trivially minimizes the diffusion loss. In this regard, this technical novelty is essential for the method. See details in Section 3.4.\n2. It is non-trivial how to properly condition the schedule on the data $\\mathbf{x}$, because the schedule function $\\gamma$ needs to be monotonic in $t$, but not necessarily on $\\mathbf{x}$. Our factorization of the function $\\beta$ is in our opinion a clever way of solving this problem and is also crucial for our method. See details in Section 3.2.\n3. We performed an ablation study on the effect of having a global unique schedule instead of a pixel-wise dedicated schedule. In our ablation study (Appendix K), we compare global vs. pixel-wise schedules (CVDM-simple). The latter outperforms CDDPM but does not match CVDM's results, highlighting the value of pixel-wise schedules in addressing unique image challenges. We also include an ablation study on the impact of our regularization strategy, which shows the importance of regularized learning for CVDM.\n\nA direct comparison with Kingma et al. 2023 is not really possible because their method is for unconditioned sampling, and extending the idea to the conditioned case is precisely one of the non-trivial contributions of our work, as explained above.\n\nIn general, we think our approach significantly simplifies the use of variational diffusion models, especially for the conditioned case. As mentioned in your list of Strengths, this is important and timely. Our own experience running experiments was that our method is very straightforward to apply and exhibits good results and very robust convergence. In light of this, we think our technical contributions are critical for the success of the method."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5967/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699979595549,
                "cdate": 1699979595549,
                "tmdate": 1700182369216,
                "mdate": 1700182369216,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qKtIODL8Hg",
                "forum": "YOKnEkIuoi",
                "replyto": "diXwQDxQP9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We continue our response to your concerns and questions."
                    },
                    "comment": {
                        "value": "## Questions\n\n> *The introduction begins with a relatively high level discussion of inverse problems, which in my view is a bit removed from the specific contributions of the paper. Maybe it could be an idea to motivate the paper more directly by mentioning specific inverse problems that the method is suitable for, such as the super resolution microscopy problem?*\n\nThanks for the suggestion. Indeed, that would be a better way of motivating our work in the context of a computer science conference and given the contents of the paper. We have added image super-resolution as a motivating problem in the Introduction.\n\n\n\n> *\"To achieve this, we adopt the framework proposed by Saharia et al. (2021), which focuses on training with the statistics of the noise at each timestep rather than direct timesteps, thus allowing flexible use of the model during inference.\" Could you clarify what this means?*\n\nThanks for pointing this out. We have tried to clarify the text at the end of Section 2. Basically, Saharia et al. 2021 define a noise prediction model that takes a different input than the one in Ho et al. 2020, and we have used their approach.\n\n\n\n> *In the final loss, you drop the term SNR'/SNR. A large portion of the paper is dedicated to the design of the variance schedule mechanism. Would it be possible to include some more discussion / insights into why this term can reasonably be dropped? I realize this if done in many other papers as well, but usually without much discussion.*\n\nThanks for the question. We can clarify this. In works that set the schedule as a hyperparameter (i.e Ho et al. 2020), we think this type of strategy is adopted mainly because it yields better results in experiments and maybe because some of the fractions involved can be numerically undesirable. Our case is a bit different. Since we are learning the schedule, there is a new consideration. Basically, during training, the schedule can converge to a solution such that $\\text{SNR}'(t,\\mathbf{x})\\approx 0$ for all $t,\\mathbf{x}$, and the diffusion loss is trivially minimized without learning anything useful. We have included this explanation in Appendix E.3, where the final form of the diffusion loss is derived.\n\n\n\n### References\n\nJonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising Diffusion Probabilistic Models, December 2020. URL `http://arxiv.org/abs/2006.11239`. arXiv:2006.11239 [cs, stat].\n\nDiederik P. Kingma, Tim Salimans, Ben Poole, and Jonathan Ho. Variational Diffusion Models, April 2023. URL `http://arxiv.org/abs/2107.00630`. arXiv:2107.00630 [cs, stat].\n\nChitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David J. Fleet, and Mohammad Norouzi. Image Super-Resolution via Iterative Refinement, June 2021. URL `http://arxiv.org/abs/2104.07636`. arXiv:2104.07636 [cs, eess]."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5967/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699979649000,
                "cdate": 1699979649000,
                "tmdate": 1700182351408,
                "mdate": 1700182351408,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "B1GGsfHoxa",
                "forum": "YOKnEkIuoi",
                "replyto": "diXwQDxQP9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for all your comments. We were wondering if you had additional questions that we could answer for you?"
                    }
                },
                "number": 36,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5967/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700734507664,
                "cdate": 1700734507664,
                "tmdate": 1700734507664,
                "mdate": 1700734507664,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "PPNXenCdnJ",
            "forum": "YOKnEkIuoi",
            "replyto": "YOKnEkIuoi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5967/Reviewer_jHYB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5967/Reviewer_jHYB"
            ],
            "content": {
                "summary": {
                    "value": "This papers proposes a learned scheduling approach for training conditioned diffusion model for solving imaging inverse problems. In effect, the paper takes the variational diffusion model developed by Kingma et al. and replaces its learned scheduling algorithm with one that is conditioned on observations. The paper further extends this approach by learning per-pixel variances. The proposed method is applied to super-resolution microscopy and quantitative phase imaging; it outperforms existing diffusion-based approaches in both contexts."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "The proposed method is effective and, though relatively straightforward, novel.\n\nValidation on real-world data is highly valuable and effectively demonstrates the utility of the proposed method.\n\nThe proposed method is general-purpose."
                },
                "weaknesses": {
                    "value": "The paper could do a clearer job differentating itself from VDM. A bullet-pointed list of contributions would have been appreciated."
                },
                "questions": {
                    "value": "## Minor comment\nThe typical convention in imaging inverse problems is y=A(x), rather than x=A(y)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5967/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698711477723,
            "cdate": 1698711477723,
            "tmdate": 1699636637477,
            "mdate": 1699636637477,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5talFe75wu",
                "forum": "YOKnEkIuoi",
                "replyto": "PPNXenCdnJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We appreciate your review. We have commented on your questions in this response and in the text of the paper."
                    },
                    "comment": {
                        "value": "# Official Comment for Reviewer jHYB\n\nThank you for taking the time to review our work, and for noticing the novel aspects of our method and its practical usefulness. Below, we clarify the specific concerns mentioned in the review. Also, note that we have included these ideas in the text of the new version of the paper, highlighting the changes in blue so that they are easy to spot.\n\n## Weaknesses\n\n> *The paper could do a clearer job differentating itself from VDM. A bullet-pointed list of contributions would have been appreciated.*\n\nThanks for pointing this out and for suggesting the use of a bullet list. We have answered this specific concern for other reviews too, but we also include an answer here to keep reviews and relevant comments organized.\n\nWe agree with your suggestion. We have included a bullet list in the Introduction (Section 1) explicitly stating the contributions of our work. Also, in Related Work (Section 2), we have included a summary of Variational Diffusion Models (VDMs, Kingma et al. 2023) and explained some of the differences with our method. Moreover, throughout the paper, we have extended the discussions about our technical contributions and their importance for the success of the method. See especially Sections 3.1, 3.2 and 3.4. We also include here a relevant summary.\n\nVDMs (Kingma et al. 2023) constitute the main framework described in the literature for learning the variance schedule.  VDMs formulate a diffusion process for unconditioned distribution sampling, where the latent variables are indexed in continuous time, and the schedule is a learnable function that must satisfy a few minimal conditions. The parameters of the schedule are defined as a monotonic network, and the model is trained by minimizing a weighted version of the noise prediction loss. Their work also uses Fourier features to improve the prediction of high-frequency details. We introduce the Conditional Variational Diffusion Model (CVDM), which includes important generalizations and novelties with respect to VDMs:\n\n- Similarly to Kingma et al. (2023), we learn the schedule as part of the training. However, we extend their approach to the conditioned case. This turns out to be a highly non-trivial task, as detailed below. We also allow for learning a different schedule for each element in the output (e.g., a pixel-wise schedule for images). These extensions require several technical novelties, including a separation-of-variables approach when defining the schedule (details in Section 3.2).\n- We prove that the rate of convergence of the discrete-time diffusion loss to the continuous-time case depends strongly on the schedule functions. Kingma et al. (2023) show that diffusion models are invariant to the schedule selection in the continuous case. Nevertheless, any discretization used for model sampling will introduce the dependency shown in Appendix E.2 on the schedule's derivatives. Our finding motivates the introduction of a novel regularization term that proves to be critical for the performance of our method (details in Section 3.4).\n- We replace the architecture in Kingma et al. (2023) with two networks, one required to be positive (for the conditioning variable) and one monotonic-convolutional network (for the time variable). This allows us to test our model with inputs of different resolutions without retraining. Moreover, by incorporating some schedule properties in the loss function, our method does not need the post-processing of the schedule that Kingma et al. 2023 uses, nor the preprocessing of the input. This results in a cleaner and more straightforward method.\n\n## Questions\n\n#### Minor comment\n\n> *The typical convention in imaging inverse problems is y=A(x), rather than x=A(y).*\n\nThanks for pointing this out. We tried to present our method in the context of general inverse problems, so we used the $A(\\mathbf{y}) = \\mathbf{x}$ notation throughout. It is true that all the applications presented involve images, so the notation you suggest could have been used. However, we think it is not worth it to change it now. It could end up being more confusing for the reviewers, who already read the paper with the original notation.\n\n### References\n\nDiederik P. Kingma, Tim Salimans, Ben Poole, and Jonathan Ho. Variational Diffusion Models, April 2023. URL `http://arxiv.org/abs/2107.00630`. arXiv:2107.00630 [cs, stat]."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5967/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699979817393,
                "cdate": 1699979817393,
                "tmdate": 1700182416312,
                "mdate": 1700182416312,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "uXHiZFBOcK",
            "forum": "YOKnEkIuoi",
            "replyto": "YOKnEkIuoi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5967/Reviewer_UQRa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5967/Reviewer_UQRa"
            ],
            "content": {
                "summary": {
                    "value": "The authors aim to solve inverse problems, i.e. recovering an underlying true object from imperfect measurements. The authors propose a conditional variational diffusion model (CVDM) to learn the conditional distribution of the true object given the measurement while being able to report uncertainty unlike typical supervised deep learning methods for inverse problems. CVDMs extend *unconditional* variational diffusion models (VDM; Kingma et al., 2023) to the *conditional* case in order to solve inverse problems and avoid hand-tuning the variance schedule of the diffusion process.\n\nThe authors demonstrate their model by:\n1. showing competitive performance on the BioSR dataset for super-resolution in microscopy\n2. showing superior performance on quantitative phase imaging (phase retrieval) on both the HCOCO dataset and their own clinical dataset."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The authors present an extension of VDMs to the conditional case, which has not yet been demonstrated and would indeed eliminate some hand-tuning when training conditional diffusion models. This is also well motivated by an interesting application to inverse problems in optics where uncertainty estimates would be very useful. The authors demonstrate that their learned schedules correspond well to more structured regions of their input on the super-resolution task."
                },
                "weaknesses": {
                    "value": "While the authors motivate their work well, ~I have some concerns with the experiments performed and their presentation. I would be willing to raise my score if the following concerns are addressed.~\n\n**Update**: The authors have addressed the major concerns, so I have updated my score accordingly.\n\n**Major concerns**:\n\n**Uncertainty results**: One of the main motivations of the paper is the ability to report uncertainty in order to point out artifacts in the solutions. In Figure 2, the authors show error images between the reconstructions and the ground truth. Do the uncertainty estimates correspond well to the regions of the image with more error?\n\n**Performance on other datasets**: The performance is not significantly better than other methods for the BioSR super-resolution dataset. If one of the major goals is to demonstrate the flexibility and robustness of this approach, it would be nice to see comparisons against more conditional generative model datasets, especially those in the CDDPM paper (though I understand that there is a focus on inverse problems).\n\n**Flexibility of super-resolution results**: When applied to super-resolution, this method does not require information about the PSF. This means that the model is learning the PSF implicitly from the data, but also means that the model would need to be retrained in order to get accurate results on data from a new PSF, which might be impractical if too much data is required for training. Again, the flexibility and robustness of this method is highlighted, so it would be nice to see some experiments or discussion addressing this, e.g. comparison against other blind deconvolution methods on datasets with different PSFs.\n\n**Estimating pixelwise schedule**: The schedules demonstrated for structured versus background regions appear to be linear with different slopes for the different regions. Would other/baseline methods perform better using an estimated linear pixelwise schedule with a higher slope on \"structured\" regions?\n\n**Minor concerns**:\n\n**Fourier features**: The original VDM paper showed that a significant amount of the performance was due to the use of Fourier features. It would be helpful to know whether anything like that is the case here.\n\n**Differences from VDM**: It would be helpful to have an explicit list or section summarizing the differences/extensions from VDM.\n\n**Figure design**: Many of the figures are very small and laid out in a way that makes comparing images and reading text difficult, e.g. in Figure 3 it is difficult to see the sections from which the schedules are being estimated."
                },
                "questions": {
                    "value": "In addition to the previous concerns, I would appreciate if the authors could clarify the following:\n\n1. Does the pattern of schedules for structured versus background regions shown in Figure 2 hold true across the whole sample and for all samples?\n1. Are there significant differences in the inference time of this model versus the methods being compared against?\n1. Is the \"US\" in \"US-TIE\" for universal solution? Only TIE is specified in the text."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5967/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5967/Reviewer_UQRa",
                        "ICLR.cc/2024/Conference/Submission5967/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5967/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698725821979,
            "cdate": 1698725821979,
            "tmdate": 1700631694289,
            "mdate": 1700631694289,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Zdy3YDuWIr",
                "forum": "YOKnEkIuoi",
                "replyto": "uXHiZFBOcK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your detailed review. We have addressed your concerns in our response and in the text of the paper."
                    },
                    "comment": {
                        "value": "# Official Comment for Reviewer UQRa\n\nThanks for your detailed assessment of our work and your helpful criticism and suggestions. We have made every effort to include all the constructive feedback we received, and the new revision of the paper reflects that. We have made a number of changes, improving clarity of exposition and including new discussions that were absent before. We have also conducted new experiments and performed an ablation study. In the new version of the paper, changes and new content are in blue text to make them easier to find. Please find below our response to your concerns and questions. \n\n## Weaknesses\n\n> While the authors motivate their work well, I have some concerns with the experiments performed and their presentation. I would be willing to raise my score if the following concerns are addressed.\n\n### Major concerns\n\n> **Uncertainty results:** One of the main motivations of the paper is the ability to report uncertainty in order to point out artifacts in the solutions. In Figure 2, the authors show error images between the reconstructions and the ground truth. Do the uncertainty estimates correspond well to the regions of the image with more error?\n\nThanks for the question. It is indeed relevant to explore the connection between uncertainty and reconstruction error. As a general matter, the answer to your question is that, yes, regions with higher uncertainty exhibit larger reconstruction errors. In the new Appendix M, you can find extended material about uncertainty. We discuss the relationship between uncertainty estimates and the schedule and offer a clear illustration of the correlation between uncertainty and reconstruction error. We have also improved the discussion about uncertainty in Section 5. In summary, even though uncertainty estimation is not the primary aspect of the paper, we agree it is important, so we have extended and improved the parts related to this topic, including a discussion of the point you raise here.\n\n> **Performance on other datasets:** The performance is not significantly better than other methods for the BioSR super-resolution dataset. If one of the major goals is to demonstrate the flexibility and robustness of this approach, it would be nice to see comparisons against more conditional generative model datasets, especially those in the CDDPM paper (though I understand that there is a focus on inverse problems).\n\nThanks for the suggestion. We agree that the method's robustness is emphasized in the paper as a feature of CVDM, and more experiments for conditioned sampling would further support this claim. To better showcase the flexibility of our method, we have conducted additional experiments. In particular, we have used our method for an image super-resolution task using ImageNet 1K (Deng et al. 2009). We compare our results against two diffusion-based methods, SR3 (Saharia et al. 2021) and DDRM (Kawar et al. 2022), using two different metrics (SSIM and PSNR). Using a learned schedule (and no fine-tuning), our method yields comparable results to these two methods, providing further evidence of the flexibility and robustness of CVDM.\n\n> **Flexibility of super-resolution results:** When applied to super-resolution, this method does not require information about the PSF. This means that the model is learning the PSF implicitly from the data, but also means that the model would need to be retrained in order to get accurate results on data from a new PSF, which might be impractical if too much data is required for training. Again, the flexibility and robustness of this method is highlighted, so it would be nice to see some experiments or discussion addressing this, e.g. comparison against other blind deconvolution methods on datasets with different PSFs.\n\nThe BioSR dataset for super-resolution microscopy is actually a good benchmark in this regard. It contains images acquired under varied conditions (i.e., different hardware, wavelength, etc.), and each variation corresponds to a different point spread function (PSF). The aim of the dataset is to help in training models that can be generalized to any fluorescence microscopy system. Therefore, since the model was trained on a wide array of PSFs, certain generalization capabilities are expected. In other words, we would expect the model to perform well in the general domain of fluorescence microscopy. The results obtained in our experiments show that the model was able to learn these different PSFs simultaneously. However, if the problem settings change too much with respect to the training dataset, there is in fact a need for retraining. Even though this is not something desirable, the lack of hyperparameter fine-tuning means that the method can be readily trained on new data, which shows the flexibility of our schedule-learning approach."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5967/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700179999325,
                "cdate": 1700179999325,
                "tmdate": 1700179999325,
                "mdate": 1700179999325,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "eWxDksSc8r",
                "forum": "YOKnEkIuoi",
                "replyto": "tPlwLJJ3fx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5967/Reviewer_UQRa"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5967/Reviewer_UQRa"
                ],
                "content": {
                    "title": {
                        "value": "Response to author comments"
                    },
                    "comment": {
                        "value": "Thank you for the responses, I think you've addressed all my major concerns. I've updated my score to reflect that."
                    }
                },
                "number": 32,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5967/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700632203160,
                "cdate": 1700632203160,
                "tmdate": 1700632203160,
                "mdate": 1700632203160,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "o3tj1BEl12",
            "forum": "YOKnEkIuoi",
            "replyto": "YOKnEkIuoi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5967/Reviewer_tcMU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5967/Reviewer_tcMU"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a conditional extension to the prior work of Variational Diffusion Models, to allow learning the variance schedule which eliminates the need to fine-tune this choice. This goal is achieved by incorporating the conditioning information as an additional input to the diffusion denoising network and as the input to one of the component in the decomposition of the learnable variance schedule. Specifically,  the paper discusses a regularized learning approach that keeps the scale of the SNR curvatures with respect to time steps to be low. Empirically, the method shows promising results on super-resolution microscopy tasks and quantitative phase imaging tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper's primary strength lies in its practical extension of variational diffusion models (VDM) to the conditioning case, including several technical improvements such as the incorporation of a regularization term on the signal-to-noise ratio. \n\nIn addition, by adopting the VDM framework, the paper eliminates the need of prior works that fine tunes the variance schedule. \n\nAnother strength of the paper is on the experiment study which includes two practical downstream benchmarks assessed with meaningful metrics. It also pays attention on the uncertainty quantification, which is rarely highlighted in prior works."
                },
                "weaknesses": {
                    "value": "The biggest weakness is the paper's technical novelty. The proposed approach seems like a straightforward conditional extension to the of variational diffusion models. In addition, the paradigm of turning an unconditional model to a conditional version has been largely explored and established, e.g.  [1]. I can see the decomposition of the learnable variance schedule, and the regularized learning are novel. In Besides that, can the authors comment on the technical non-triviality of this extension?  \n\nAnother weakness is lack of ablation study. For example, how does the method perform without using the regularized learning approach in Section 3.4? \n\nFinally, there is a room for improvement in terms of clarity, especially in the experiment section. See my detailed comments in the below Questions section.\n\n\n[1] Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David J. Fleet, and Mohammad Norouzi. Image Super-Resolution via Iterative Refinement, June 2021. URL http://arxiv.org/abs/ 2104.07636. arXiv:2104.07636 [cs, eess]."
                },
                "questions": {
                    "value": "1. In abstract and intro, what does \"causal factors\" mean?\n\n2. The condition $A(x) = y$ is brought up in the introducation, but is not used in the method section. Does this condition specification matter?\n\n3. Missing a background of Variational Diffusion Models (VDM) before starting the method section. And I would appreciate a more straightforward discussion to how this version extends beyond and distinguishes from VDM. \n\n4. I find the notation $SNR''$ on page 5 not clear enough; it might be worth out writing $SNR''(t,x)$ when it is first introduced. \n\n5. Missing (the reference to) the details on how the base model architecture and other training details for the competing methods. This question is important to understand whether the empirical compairison is a fair one.\n\n6. Missing a description on competing methods, i.e. DFCAN, CDDPM, and  a discussion on how is the proposed method different from them. \n\n7. For the CDDPM, did you fine-tune the hyperparameters, namely the variance schedule?\n\n8. Limited methods used for comparison. There are definitely other qualified competing methods in the diffusion space, e.g. [2], [3], [4]\n\n9. Table1: Maybe I missed this point but what does the \"resolution\" metric mean?\n\n10. Table 1: why there is only one underlined result?\n\n11. Table 1: Why some rows do not have underlines and bolded results?\n\n12. Table 1: How do you define statistically significant? Do you repeat the experiments for multiple times and compute the average results with standard errors? If so, please describe this detail in table or the text. \n\n13. Table 2a: I would suggest to add the \"synthetic\" description to the HCOCO dataset in the caption. \n\n14. Section 4.2.2, what is the \"US-TIE method\"?\n\n15. Figure 3a: maybe I missed this but what do the structure and background in the legend box mean? Are they fixed values instead of learned? \n\n16. Figure 3a: Where does the learned uncertainty reflect in the figure, or it is not? I was thinking of a figure like Figure 4a in [1]. And how do you draw the conclusion on \"We briefly point out that our uncertainty estimation is consistent with the values of \u03b2 as described above\" if there is no comparison between the uncertainty estimation and the values of $\\beta$? \n\n17. I wonder how the uncertainty quantification around the reconstruction can be useful?\n\n18. Appendix A, second paragraph, first sentence, should be \"Ay=x\" instead of \"Ax=y\"? \n\n[1] Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David J. Fleet, and Mohammad Norouzi. Image Super-Resolution via Iterative Refinement, June 2021. URL http://arxiv.org/abs/ 2104.07636. arXiv:2104.07636 [cs, eess].\n[2] Denoising Diffusion Restoration Models. Bahjat Kawar, Michael Elad, Stefano Ermon, Jiaming Song. https://arxiv.org/abs/2201.11793\n[3] Diffusion Models Beat GANs on Image Synthesis. Prafulla Dhariwal, Alex Nichol. https://arxiv.org/abs/2105.05233\n[4] Pseudoinverse-Guided Diffusion Models for Inverse Problems. Jiaming Song, Arash Vahdat, Morteza Mardani, Jan Kautz. https://openreview.net/forum?id=9_gsMA8MRKQ"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5967/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698768205372,
            "cdate": 1698768205372,
            "tmdate": 1699636637283,
            "mdate": 1699636637283,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kn8UuY6BvJ",
                "forum": "YOKnEkIuoi",
                "replyto": "o3tj1BEl12",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your in-depth review. We have addressed your concerns in our response and in the text of the paper."
                    },
                    "comment": {
                        "value": "# Official Comment for Reviewer tcMU\n\nThank you for taking the time to review our work with such great detail. We appreciate your comments about the paper's Strengths, which we think are a good showcase of our main objectives. We also very much appreciate your detailed criticism, which have helped us improve our paper. Please find below a detailed clarification of your comments and questions. We have also included this material in the new version of the paper, highlighting the new text in blue to make it easier to find.\n\n\n## Weaknesses\n\n> *The biggest weakness is the paper's technical novelty. The proposed approach seems like a straightforward conditional extension to the of variational diffusion models. In addition, the paradigm of turning an unconditional model to a conditional version has been largely explored and established, e.g. [1]. I can see the decomposition of the learnable variance schedule, and the regularized learning are novel. In Besides that, can the authors comment on the technical non-triviality of this extension?*\n\nWe can comment about the technical non-triviality of our contributions in more detail. In general, our hypothesis is that the schedule can be learned, eliminating the need for fine-tuning the schedule while exhibiting better results. Kingma et al. (2023) explored this idea in [6], but only for the unconditioned case. We are interested in the case of conditioned sampling, which opens up many more opportunities for application, but a straightforward application of Saharia et al. (2021) does not work at all in this case (the schedule does not converge to anything useful or meaningful).\n\nSo, in fact, learning the schedule for conditioned sampling is a non-trivial challenge and is far from a direct combination of [1] and [6]. As you mention, two of the key ideas that address this problem are the decomposition/factorization of the variance schedule (Section 3.2) and the regularization strategy (Section 3.4), both of which are essential:\n\n- It is non-trivial how to properly condition the schedule on the data $\\mathbf{x}$, because the schedule function needs to be monotonic in $t$, but not necessarily on $\\mathbf{x}$. Our decomposition/factorization of the function $\\beta$ is in our opinion a clever way of solving this problem and is absolutely key for our method. See comments in Sections 3.2 and 4.3.\n- We prove that the rate of convergence of the discrete-time diffusion loss to the continuous-time case depends strongly on the schedule functions. Kingma et al. (2023) show that diffusion models are invariant under schedule selection in the continuous case. Nevertheless, any discretization used for model sampling will introduce the dependency shown in Appendix E.2 on the schedule's derivatives. Our finding motivates the introduction of a novel regularization term that proves to be critical for the performance of our method (details in Section 3.4 and 4.3, and Appendix K).\n\nRegarding implementation details, we replace the architecture in Kingma et al. (2023) with two networks, one required to be positive (for the conditioning variable) and one monotonic-convolutional network (for the time variable). This allows us to test our model with inputs of different resolutions without retraining. Moreover, by incorporating schedule properties in the loss function, our method does not need the post-processing of the schedule that Kingma et al. 2023 uses, nor the preprocessing of the input (addition of Fourier features). These design decisions are arguably less novel, but they result in a cleaner and more straightforward method compared to Kingma et al. (2023)."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5967/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700141696824,
                "cdate": 1700141696824,
                "tmdate": 1700141696824,
                "mdate": 1700141696824,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pt3wG3gQ28",
                "forum": "YOKnEkIuoi",
                "replyto": "o3tj1BEl12",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We continue our response to your concerns and questions."
                    },
                    "comment": {
                        "value": "## Weaknesses (continued)\n\n> *Another weakness is lack of ablation study. For example, how does the method perform without using the regularized learning approach in Section 3.4?*\n\nThanks for this suggestion. We agree that an ablation study would help clarify our technical contributions' impact on the performance. We have answered something similar for a different reviewer, but we also respond here in order to keep the reviews and specific comments organized.\n\nWe have clarified the role played by our specific contributions in the new version of the paper (see Sections 3.2, 3.4 and 4.3). We have also performed an ablation study. Some important points:\n\n1. The regularization term described in Section 3.4, which you mention as an example, is critical to keep the schedule from converging to an uninformative solution that trivially minimizes the diffusion loss. In this regard, this technical novelty is essential for the method. See details in Section 3.4. We have also ran experiments without using this regularization term, with results described in Section 4.3.\n2. Our factorization of the function $\\beta$ is also crucial for our method. Recall that the schedule function $\\gamma$ needs to be monotonic in $t$, but not necessarily on $\\mathbf{x}$, so it is non-trivial how to properly condition the schedule on the data $\\mathbf{x}$. See details in Section 3.2. While trying these changes out, the method simply did not converge.\n3. We performed an ablation study on the effect of having a global unique schedule instead of a pixel-wise dedicated schedule. In our ablation study (Appendix K), we compare global vs. pixel-wise schedules (CVDM-simple). The latter outperforms CDDPM but does not match CVDM's results, highlighting the value of pixel-wise schedules in addressing unique image challenges. We also include an ablation study on the impact of our regularization strategy, which shows the importance of regularized learning for CVDM.\n\n>*Finally, there is a room for improvement in terms of clarity, especially in the experiment section. See my detailed comments in the below Questions section.*\n\nThanks a lot for going into so much detail regarding the experimental section (and the rest of the paper). We include an answer to all your questions below.\n\n\n\n## Questions\n\n1. In abstract and intro, what does \"causal factors\" mean?\n\n    Thanks for pointing this out. We have changed \"causal factors\" to \"parameters\" in the new version of the paper so as not to generate confusion with e.g. causal inference. In general, it means we lack some key information (which we want to recover) about the process that generated the data.\n\n2. The condition $A(x)=y$ is brought up in the introduction but is not used in the method section. Does this condition specification matter?\n\n    This condition specification does not matter in Methods section (our method is general and agnostic about the specific mapping $A$). It is only mentioned in the Introduction to further clarify what is meant by an Inverse Problem, and to introduce the relation between $\\mathbf{x}$ and $\\mathbf{y}$, which is used throughout the paper.\n\n3. Missing a background of Variational Diffusion Models (VDM) before starting the method section. And I would appreciate a more straightforward discussion to how this version extends beyond and distinguishes from VDM.\n\n   Thanks for the suggestion. We have answered similar concerns for other reviewers, too. We also include an answer here. We have addressed your suggestion in several ways. In Related Work (Section 2), we have included a summary of Variational Diffusion Models (VDMs, [6]), to provide more background before starting the Methods section, as you suggest. In Section 2, we have also explained some of the differences with our method, and we have included a bullet list in the Introduction (Section 1) to explain the contributions of our work more clearly. Moreover, throughout the paper, we have extended the discussions about our technical contributions and their importance for the success of the method. See especially Sections 3.1, 3.2, 3.4 and 4.3. We also include here a relevant summary.\nVDMs (Kingma et al. 2023) constitute the main framework described in the literature for learning the variance schedule. VDMs formulate a diffusion process for unconditioned distribution sampling, where the latent variables are indexed in continuous time, and the schedule is a learnable function that must satisfy a few minimal conditions. The parameters of the schedule are defined as a monotonic network, and the model is trained by minimizing a weighted version of the noise prediction loss. Their work also uses Fourier features to improve the prediction of high-frequency details. We introduce the Conditional Variational Diffusion Model (CVDM), which includes important generalizations and novelties with respect to VDMs, as described in detail above (see our answers to Weaknesses)."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5967/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700141818317,
                "cdate": 1700141818317,
                "tmdate": 1700182136171,
                "mdate": 1700182136171,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "P1LnrNmfbu",
                "forum": "YOKnEkIuoi",
                "replyto": "o3tj1BEl12",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We continue our response to your concerns and questions."
                    },
                    "comment": {
                        "value": "## Questions (continued)\n\n4. I find the notation $SNR''$ on page 5 not clear enough; it might be worth out writing $SNR''(t,x)$ when it is first introduced.\n\n    We have followed the suggestion of using SNR$''(t,\\mathbf{x})$ when introducing the term in Section 3.4. Also, we have slightly rewritten that paragraph to further clarify the notation.\n\n6. Missing (the reference to) the details on how the base model architecture and other training details for the competing methods. This question is important to understand whether the empirical compairison is a fair one.\n\n    Thanks for this insight. The architecture details for our method are provided in Appendix G. Since one of our aims is to prove that learning a schedule can improve the results over fine-tuning it, we base both our architecture and that of CDDPM on [1], and reduce the number of parameters to avoid overfitting. To fine-tune CDDPM, we choose a linear schedule as in [1] and perform a grid search to find the best schedule. In that sense, both diffusion models share the same base architecture, with the addition of the schedule network for our method. For non-diffusion models, DFCAN is implemented as in [5] (referenced in Section 4.1) and US-TIE is implemented as in [4] (referenced in Section 4.2).\n\n7. Missing a description on competing methods, i.e. DFCAN, CDDPM, and a discussion on how is the proposed method different from them.\n\n    Thanks for pointing this out. We have added a brief description of these methods in Section 4. Specifically, DFCAN is a regression-based method that introduces the Fourier attention channel mechanism, currently state of the art in super-resolution microscopy. We implemented DFCAN as in [5], and CDDPM is the conditioned DDPM implemented and trained as described in [1].\n\n8. For the CDDPM, did you fine-tune the hyperparameters, namely the variance schedule?\n\n    Yes, we fine-tuned them. We changed our text to emphasize better that the CDDPM schedule was fine-tuned (see Sections 4.1 and 4.2).\n\n9. Limited methods used for comparison. There are definitely other qualified competing methods in the diffusion space, e.g. [2], [3], [4].\n\n    Both DFCAN and US-TIE were chosen for being the state of the art for super-resolution microscopy and QPI, respectively. Regarding diffusion models, there are certainly a number of methods available. The main reason we chose CDDPM is that we wanted to test the effect of learning the schedule, as opposed to fine-tuning it, while controlling for many of the implementation details of the methods. In that sense, CDDPM is sufficiently similar to CVDM to allow us to assess better the impact of learning the schedule.\n\n    To a considerable extent, we have verified our hypothesis that treating the schedule as a hyperparameter is unnecessary because it takes effort and may lead to suboptimal performance. This is of special importance to the users of the method since reducing the number of hyperparameters provides a way of applying this problem to a larger array of problems without the overhead of fine-tuning for the specific case. We find that learning the schedule in this way is straightforward and leads to comparable-to-better performance. Aditionally, we also wanted a way to quantify uncertainty for these methods. \n\n    To provide a more comprehensive understanding of our method's performance, we have conducted further experiments for an image super-resolution task using ImageNet. The results are described in Section 4.3 and Appendix L. For this task, we compare against [1] and one of the methods referenced in your question (Denoising Diffusion Restoration Models, or DDRMs). We get comparable results to [1] and slighlty improve on DDRMs. In any case, we want to clarify that we are not claiming a superiority in results for all tasks and compared to all other diffusion-based methods. To our mind, one of the great strengths of CVDM is that it provides a method for learning the schedule that is robust, provides a way to quantify the uncertainty of the reconstruction, requires no fine-tuning, yields good results (comparable or superior to state-of-the-art methods for the problems we tried), and which can be used to enhance other architectures."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5967/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700141935489,
                "cdate": 1700141935489,
                "tmdate": 1700156567399,
                "mdate": 1700156567399,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gAfCyBJZEG",
                "forum": "YOKnEkIuoi",
                "replyto": "3IMNH5v0M2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5967/Reviewer_tcMU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5967/Reviewer_tcMU"
                ],
                "content": {
                    "title": {
                        "value": "Follow-up question about uncertainty computation"
                    },
                    "comment": {
                        "value": "I would like to thank the authors for their detailed response. Most of my concerns have been well-addressed. I have one follow-up question about the uncertainty computation:\n\nIt seems like the uncertainty is evaluated by the sample variance. Do you compute the sample variance over e.g. 5 reconstruction examples, as in Figure 17, or you can read that from the beta schedule? Also there is a discussion on how the uncertainty is linked to $\\sqrt{\\beta (t,x)}$. I wonder that $t$ do you use in this case, is it $t=0$? This question also applies to the beta-schedule panel in Figure17."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5967/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700339365627,
                "cdate": 1700339365627,
                "tmdate": 1700339365627,
                "mdate": 1700339365627,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4hXRuNg0jD",
                "forum": "YOKnEkIuoi",
                "replyto": "fqkrZX4XSB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5967/Reviewer_tcMU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5967/Reviewer_tcMU"
                ],
                "content": {
                    "title": {
                        "value": "follow-up question regarding uncertainty quantification"
                    },
                    "comment": {
                        "value": "(I meant to ask about this question in my thread but ended up in another reviewer's thread) Thank you for clarifying my questions on uncertainty quantification. I have one more question: have you compared the uncertainty quantification results of the proposed method to other methods in the paper? I was looking for evidence of the proposed approach can have better uncertainty quantification."
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5967/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700366412571,
                "cdate": 1700366412571,
                "tmdate": 1700366412571,
                "mdate": 1700366412571,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qKoLP7CQw0",
            "forum": "YOKnEkIuoi",
            "replyto": "YOKnEkIuoi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5967/Reviewer_qRoi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5967/Reviewer_qRoi"
            ],
            "content": {
                "summary": {
                    "value": "In this paper the authors propose to learn the schedule of the forward process for conditional diffusion models, building up on the work of   [1]. This is an interesting topic since fine-tuning the schedule can be quite time consuming. The main contribution of this paper is to make the schedule dependent on the conditioning variable and to devise an appropriate learning procedure. \n\n\n[1]\u00a0Kingma, Diederik, et al. \"Variational diffusion models.\" Advances in neural information processing systems 34 (2021): 21696-21707."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well written and quite easy to understand, which is great. The numerical experiments/applications are interesting and show that the proposed method provides comparable or superior performance to existing methods that fine-tune the schedule."
                },
                "weaknesses": {
                    "value": "I think that the contribution of this paper is quite marginal and is not suited for ICLR. The main difference with the methodology developed in [1] is the replacement of the unstable SNR term. While this yields good results in practice, I am not sure if this is enough novelty for a conference like ICLR."
                },
                "questions": {
                    "value": "I have no further questions."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed.",
                        "Yes, Other reasons (please specify below)"
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5967/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5967/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5967/Reviewer_qRoi"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5967/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699203361860,
            "cdate": 1699203361860,
            "tmdate": 1699636637168,
            "mdate": 1699636637168,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Wj5v6cvbP4",
                "forum": "YOKnEkIuoi",
                "replyto": "qKoLP7CQw0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "# Official Comment for Reviewer qRoi\n\nThanks for taking the time to read our work. We include a response below. If you could provide more details and evidence, we could answer more specifically your concerns. References below allude to the revised version of our paper, in which we have clarified some points, included additional experiments, and stated our contributions more explicitly.\n\n## Weaknesses\n\n> *I think that the contribution of this paper is quite marginal and is not suited for ICLR.*\n\nWe have to respectfully disagree with your evaluation of our work, at least as it is stated right now. We see no reason why our work would not be suited for ICLR. On the contrary, the topics discussed in our paper are active areas of research in machine learning. See for instance these ICLR 2023 papers: \n\n- Deep learning applied to inverse problems [2], [3], [4].\n- Diffusion models [5], [6], [7].\n- Variational inference [8], [9].\n- Uncertainty quantification [10], [11].\n\nIn our paper, we have used novel technical ideas to tackle a relevant problem in current machine learning research. We have derived analytical insights to solve this problem (see Section 3 and Appendix E, for instance), and we have conducted thorough experimental work to provide compelling evidence for our ideas (see Section 4 and discussion in Section 5). We can answer more specifically if you provide details as to why you consider our paper not suited for ICLR.\n\n> *The main difference with the methodology developed in [1] is the replacement of the unstable SNR term. While this yields good results in practice, I am not sure if this is enough novelty for a conference like ICLR.*\n\nThe differences with [1] go far beyond the replacement of the SNR term. Their framework is for unconditioned sampling only, which we extend in two ways. First, we allow for conditioned sampling, which opens up many more opportunities for application, including the case of inverse problems with which we motivate our work in Section 1. Second, we allow for learning a pixel-wise variance schedule, which further improves performance (see Ablations in Section 4.3).\n\nMoreover, these extensions are highly non-trivial. Learning the schedule for conditioned sampling is a difficult challenge and is far from a direct application of [1]. There are at least two new ideas we use to make it work: the decomposition/factorization of the variance schedule (Section 3.2) and the regularization strategy (Section 3.4), both of which are essential:\n\n- It is non-trivial how to properly condition the schedule on the data $\\mathbf{x}$, because the schedule function needs to be monotonic in $t$, but not necessarily on $\\mathbf{x}$. Our decomposition/factorization of the function $\\beta$ is, in our opinion, a clever way of solving this problem and is absolutely key for our method. See comments in Sections 3.2 and 4.3.\n- We prove that the rate of convergence of the discrete-time diffusion loss to the continuous-time case depends strongly on the schedule functions. [1] show that diffusion models are invariant under schedule selection in the continuous case. Nevertheless, any discretization used for model sampling will introduce the dependency shown in Appendix E.2 on the schedule's derivatives. Our finding motivates the introduction of a novel regularization term that proves to be critical for the performance of our method (details in Section 3.4 and 4.3, and Appendix K).\n\nRegarding implementation details, we replace the architecture in [1] with two networks, one required to be positive (for the conditioning variable) and one monotonic-convolutional network (for the time variable). This allows us to test our model with inputs of different resolutions without retraining. Moreover, by incorporating schedule properties in the loss function, our method does not need the post-processing of the schedule that [1] uses, nor the preprocessing of the input (addition of Fourier features). These two last design decisions are arguably less novel, but they result in a cleaner and more straightforward method compared to [1].\n\nSo we think it is clear that our work has substantial differences with [1], and there is a good deal of technical novelty. The \"replacement of the unstable SNR term\" that you mention is indeed a part of our work, but it is not the most novel or important part. The revised version of the paper makes this more clear. In Section 2 (Related Work), we have included a summary of Variational Diffusion Models (VDMs) [1] to provide more background before starting the Methods section. Also, in Section 2, we have explained some of the differences between VDMs and our method, and we have included a bullet list in Section 1 (Introduction) to state the specific contributions of our work more clearly. Moreover, throughout the paper, we have extended the discussions about our technical contributions and their impact on the performance of the method. See especially Sections 3.1, 3.2, 3.4 and 4.3."
                    }
                },
                "number": 28,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5967/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700485514398,
                "cdate": 1700485514398,
                "tmdate": 1700485514398,
                "mdate": 1700485514398,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RECtjXf6yP",
                "forum": "YOKnEkIuoi",
                "replyto": "qKoLP7CQw0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5967/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Before the rebuttal period is over. Do you have any questions we can help with?"
                    }
                },
                "number": 37,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5967/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700735203857,
                "cdate": 1700735203857,
                "tmdate": 1700735203857,
                "mdate": 1700735203857,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]