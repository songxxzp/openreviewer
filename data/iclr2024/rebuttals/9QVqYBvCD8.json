[
    {
        "title": "Asking Before Acting: Gather Information in Embodied Decision-Making with Language Models"
    },
    {
        "review": {
            "id": "L3Aq0FMODr",
            "forum": "9QVqYBvCD8",
            "replyto": "9QVqYBvCD8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4404/Reviewer_umUa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4404/Reviewer_umUa"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a theoretical framework, conceptualizing scenarios as a Markov Decision Process (MDP). This framework harnesses active querying to efficiently extract information from a language model. Remarkably, the proposed method can tweak its queries to be relevant even with slight alterations to existing agents, ensuring that previously acquired information is both retained and effectively repurposed. The examined issue is both relevant and significant. Agents equipped with the ability to tap into external knowledge repositories exhibit enhanced capability and safety over their counterparts. The integration of LLMs with assistance-seeking mechanisms is a novel endeavor. The results outperform the established baseline, and diverse experimental setups have been designed to underscore the method's efficacy."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "-The paper presents a unique framework for assessing embodied decision-making, enabling agents to proactively seek information.\n-Comprehensive tests were carried out on ALFWord and its derivatives, affirming the method's efficacy.\n-The paper is well-organized and clear-presented."
                },
                "weaknesses": {
                    "value": "- The writing could benefit from improvements, particularly typographical errors like \"suboptimal beahviors\" found in the second paragraph.\n- Why choose to incorporate solely a human model rather than adopting approaches like the RLHF for human feedback?\n- The authors' pursuit to tackle intricate issues in embodied AI, especially everyday tasks beyond mere embodied navigation, is praiseworthy. Nonetheless, showcasing the method's versatility across various realms, including embodied navigation, would enhance the paper's value.\n- It would also be beneficial if the paper could cover works from pre-LLM era on embodied AI task that takes in help signal to guide its downstream task:\n1.Chi, T.C., Shen, M., Eric, M., Kim, S. and Hakkani-tur, D., 2020, April. Just ask: An interactive learning framework for vision and language navigation. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 34, No. 03, pp. 2459-2466).\n2.Zhang, J., Yu, S., Duan, J. and Tan, C., 2022. Good Time to Ask: A Learning Framework for Asking for Help in Embodied Visual Navigation. arXiv preprint arXiv:2206.10606.\n3.Singh, Kunal Pratap, Luca Weihs, Alvaro Herrasti, Jonghyun Choi, Aniruddha Kembhavi, and Roozbeh Mottaghi. \"Ask4help: Learning to leverage an expert for embodied tasks.\" Advances in Neural Information Processing Systems 35 (2022): 16221-16232."
                },
                "questions": {
                    "value": "All my questions are asked in the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "nill"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4404/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4404/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4404/Reviewer_umUa"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4404/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698471784430,
            "cdate": 1698471784430,
            "tmdate": 1699636414174,
            "mdate": 1699636414174,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AVgtO0F9cf",
                "forum": "9QVqYBvCD8",
                "replyto": "L3Aq0FMODr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thanks for your time and efforts in reviewing our paper! We highly appreciate your thoughtful and constructive suggestions. Your thoughtful and constructive suggestions have been invaluable to us, and we have carefully considered each comment. Our responses to your queries are outlined below:\n\n---\n\n***Q1. why not use RLHF?***\n\nIn summary, we use human models during evaluation, to enable real time human interaction and save human efforts, while RLHF is a training method to learn human values. To be specific:\n\n- In ABA, we focus on the human (external information source) in the loop setting, where the agent can interact with humans in real time during deployment.\n\n    While typical RLHF methods like [1] collect human feedback dataset and train the model. During rollout, RLHF cannot help model the interactions with humans.\n\n- In ABA, for the same question, the human may provide different answers in different scenarios. For instance, asking \"where is the cup?\" may yield different responses in different rooms\n\n    While in RLHF, the learning objective is the concept of values / preferences, which is fixed, and cannot fit in our setting.\n\nWhile we have not incorporated RLHF in the current work, we acknowledge the potential for future research to explore combining RLHF to enhance the asking quality of ABA.\n\n\n[1] Ouyang, Long, et al. \"Training language models to follow instructions with human feedback.\" Advances in Neural Information Processing Systems 35 (2022): 27730-27744.\n\n---\n\n***Q2,4. navigation and missing related works***\n\nThanks for pointing out these related works! We have added them to the related work section and highlighted the modifications in blue.\n\n---\n\n***Q3. writing issues***\n\nThanks! We have fixed the typos in our manuscript and these modifications are highlighted in blue for your convenience.\n\n---\n\nWe sincerely appreciate your thorough review and constructive suggestions. If you have any further comments or inquiries, please do not hesitate to let us know. And we genuinely hope for your reconsideration of the score."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4404/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700152454811,
                "cdate": 1700152454811,
                "tmdate": 1700152454811,
                "mdate": 1700152454811,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TugKzavh6p",
                "forum": "9QVqYBvCD8",
                "replyto": "L3Aq0FMODr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer, we would like to thank you again for your efforts and time in providing thoughtful feedback and comments. We\u2019ve revised the paper according to your suggestions and replied to all the questions and concerns. Since the discussion period is ending soon, we would greatly appreciate it if you could let us know whether you have any additional comments.\n\nThanks a lot!"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4404/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700543442915,
                "cdate": 1700543442915,
                "tmdate": 1700543442915,
                "mdate": 1700543442915,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hka9CfofWP",
                "forum": "9QVqYBvCD8",
                "replyto": "AVgtO0F9cf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4404/Reviewer_umUa"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4404/Reviewer_umUa"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thanks to the author for addressing all my doubts, however after much consideration, i would still like to keep my rating."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4404/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700682482254,
                "cdate": 1700682482254,
                "tmdate": 1700682482254,
                "mdate": 1700682482254,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5d0tECFgjv",
            "forum": "9QVqYBvCD8",
            "replyto": "9QVqYBvCD8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4404/Reviewer_mCAD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4404/Reviewer_mCAD"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, a new prompting and LM fine-tuning method is introduced. The goal of Asking Before Acting (ABA) is to gather information (\u201casking\u201d) from the environment or external sources before performing an action (\u201cacting\u201d). In addition to a zero-shot method, there is also ABA-FT which is fine-tuned on labeled trajectories."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Originality: The paper addresses an inefficiency of current LLMs in embodied LM. It is much easier to directly ask a question than directly explore the environment. This is also an intuitive idea. \n- Significance: ABA could provide shorter policies. The new versions of AlfWorld provide a more challenging version of a widely used benchmark."
                },
                "weaknesses": {
                    "value": "- Comparison with previous works: One of the major weaknesses is that several works with competitive baselines are omitted from the paper. For example, in AlfWorld, Reflexion (1) and AdaPlanner (2) achieve similar or better results on AlfWorld than ABA. For the robotics task, there is no comparison with works like Cliport (3). For the finetuned version of ABA, there is no comparision with finetuned models or imitation learning methods. \n- For the new dataset variants introduced, Multiround AlfWorld and Ambigious AlfWorld are not evaluated on methods other than ReACT, ABA, ABA-FT. \n- A key part of ABA is receiving/guidance from the environment or external sources. However, in the paper, a second LLM is used as the 'human' or external source. There is no ablation showing that the external source is providing guidance and not just the answer. \n- An evaluation on more decision making datasets such as programming datasets, block world, etc. would strengthen the paper significantly given the general high performance of LLMs on AlfWorld.\n\n(1): Shinn, Noah, Beck Labash, and Ashwin Gopinath. \"Reflexion: an autonomous agent with dynamic memory and self-reflection.\" arXiv preprint arXiv:2303.11366 (2023).\n(2): Haotian Sun, Yuchen Zhuang, Lingkai Kong, Bo Dai, & Chao Zhang. (2023). AdaPlanner: Adaptive Planning from Feedback with Language Models.\n(3): Shridhar, Mohit, Lucas Manuelli, and Dieter Fox. \"Cliport: What and where pathways for robotic manipulation.\" Conference on Robot Learning. PMLR, 2022."
                },
                "questions": {
                    "value": "- What is the expert policy used to train ABA-FT?\n- Is there any visual model used for the robotic control experiments?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4404/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4404/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4404/Reviewer_mCAD"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4404/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698628188537,
            "cdate": 1698628188537,
            "tmdate": 1699636413999,
            "mdate": 1699636413999,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "OpuGX2pp6P",
                "forum": "9QVqYBvCD8",
                "replyto": "5d0tECFgjv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thanks for your time and efforts in reviewing our paper! We highly appreciate your thoughtful and constructive suggestions. We have carefully considered each comment. Our responses to your queries are outlined below:\n\n---\n\n***Q1, Q2 and Q4. insufficient experiments, new baselines and benchmarks***\n\n**New baselines:**\n\nWe've carefully considered your recommendations, and here's our feedback:\n\n1. *Reflexion [1] and Adaplanner [2]:*\n\n    These methods focus on learning from previous mistakes through multiple rollouts, while ABA aims to perform tasks within a single shot. Therefore we are orthogonal and focus on different settings. We acknowledge the potential for future research to explore combinations with [1,2] to enhance performance.\n\n\n2. *CLIPort [3]*\n\n   We believe [3] is not suitable here since:\n\n   - Different settings. Both ABA and ReAct are few-shot methods, while [3] needs to collect an expert dataset to do imitation learning.\n\n   - In section 4.2, our tasks involve the agent asking questions or reasoning to gather information, a scenario not directly adaptable to imitation learning-based methods like [3].\n\n3. *BUTLER in ALFWorld variants*\n\n    We have already compared BUTLER in the original ALFWorld. We show ABA which use $K=2$ trajectories can significantly outperform BUTLER with $10^5$ training trajectories. For similar but more challenging environments, we believe it is not necessary to compare with it again.\n\n\n**New benchmarks:**\n\nRegarding new environments, our experiments cover three types, including text-based tasks, robot arm manipulation, and real-world embodied environments, totaling 29 different tasks. As acknowledged by other reviewers, our experiments are \u201cthorough\u201d (from P7Hr), \u201csufficient\u201d (from 23Y9), and \u201ccomprehensive\u201d (from umUa) experiments. \nIf there are specific aspects or types of experiments you believe are lacking or could be supplemented, we would greatly appreciate further clarification and any suggested benchmarks. \n\n---\n\n\n***Q3.  There is no ablation showing that the external source is providing guidance and not just the answer.***\n\nIn Section 3.3 and Appendix A, we showed how the human model is designed. It prompts the LLM with environmental information and is prompted to answer the questions. The human model does not have access to the oracle action, and it will not provide the answer.\n\n---\n\n***Q5. What is the expert policy used to train ABA-FT?***\n\nAs outlined in Appendix E, we designed a rule-based policy according to the PDDL planning trajectories provided along with the environment to collect the data.\n\n---\n\n***Q6. Is there any visual model used for the robotic control experiments?***\n\nAs outlined in appendix J, we use a hand designed captioning module, which can access the simulator information and label the object type and its ground truth coordinates. As discussed in Huang et al. (2023), this module can be implemented through the depth image and a combination of object detection model, an object segmentation model, and a video tracker. But we temporarily leave this module hand-designed since it is not the key point of our work.\n\n---\n\nWe appreciate your thorough evaluation and remain open to further discussion or clarification on any points. And we genuinely hope for your reconsideration of the score."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4404/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700152695596,
                "cdate": 1700152695596,
                "tmdate": 1700152695596,
                "mdate": 1700152695596,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uN9CEiqCLk",
                "forum": "9QVqYBvCD8",
                "replyto": "5d0tECFgjv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer, we would like to thank you again for your efforts and time in providing thoughtful feedback and comments. We\u2019ve revised the paper according to your suggestions and replied to all the questions and concerns. Since the discussion period is ending soon, we would greatly appreciate it if you could let us know whether you have any additional comments.\n\nThanks a lot!"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4404/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700543434764,
                "cdate": 1700543434764,
                "tmdate": 1700543434764,
                "mdate": 1700543434764,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Spn4Cf9cZy",
                "forum": "9QVqYBvCD8",
                "replyto": "uN9CEiqCLk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4404/Reviewer_mCAD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4404/Reviewer_mCAD"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you to authors for addressing my concerns. However, I still keep my score at a 3. While formally, the setting of ABA (not finetuned) is different than Reflexion and Adaplanner, in practice it does not seem so different. In terms of using an LLM as the human and the datasets used as evaluation, prompting does not eliminate the potential for simply providing the answer or for being incorrect. Additionally, I agree with reviewer  P7Hr's review."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4404/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700547012956,
                "cdate": 1700547012956,
                "tmdate": 1700547012956,
                "mdate": 1700547012956,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qgXvMaOx2k",
                "forum": "9QVqYBvCD8",
                "replyto": "VCC20F8g1v",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4404/Reviewer_mCAD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4404/Reviewer_mCAD"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarifications from the authors. \n- As for the comparison between ABA and previous works, I do acknowledge that ABA does not use an evaluator as part of the learning process and can be considered zero-shot. That being said, ABA still requires multiple 'asking' interactions or calls to the 'human' before an answer is give (as noted in section 3.2, second paragraph in the paper: \"By providing K such trajectories, we learn through ICL ..\"). Previous works and ABA both use some form of prompting with environmental feedback. While ABA is different, previous works significantly limit novelty.\n- Use of LLM as human in terms of oracle answer. Thank you for the authors for the example. I agree that for the robot arm manipulation task this not an a problem. However, this is not necessarily true for AlfWorld. For the example given in Appendix B at the bottom of page 15, the correct action is 'put mug 1 in/on side table 1.' The LLM does have access to this information and can output the 'answer' instead of just the context to the answer. \n- Correctness of LLM. Appendix C shows a large variance of the human model in terms of correct answers. No specific actions are taken to address hallucinations in ABA even though in the qualitative examples, hallucinations are pointed out in the baseline examples."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4404/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700697140392,
                "cdate": 1700697140392,
                "tmdate": 1700697140392,
                "mdate": 1700697140392,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6uW8qvIRYL",
                "forum": "9QVqYBvCD8",
                "replyto": "5d0tECFgjv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your feedback.\n\n---\n\n**Q1.** Whether [1,2] should be used as baselines?\n\nWe would like to begin by summarizing the overall discussion. \n\n- In the reviewer\u2019s original review, mCAD asks for more baselines like [1-2]. \n\n- In our original response, we explained these methods are not suitable for baselines since they have different settings. [1,2] allow rollout in the same environment multiple times, whenever they fail, they can restart the environment and learn from previous mistakes. In contrast, we focus on solving the task within 1 trial. Therefore, it is not proper to compare with [1,2] directly.\n\n- In the reviewer\u2019s following feedback, mCAD agrees [1,2] and our method are different formally, but mCAD suggests they are similar in practice.\n\n- In our following response, we explained that it does not make sense to claim these few-shot methods incorporating environment restarting equals one-shot methods. We cite [1] to illustrate that with only 1 shot, [1] degenerate to ReAct, which is a baseline cited in our paper. So, [1,2] are not similar to our method in practice.\n\n- In the previous feedback, mCAD acknowledged that our method is zero-shot, while [1,2] are not, but mCAD proposed new similarities between our methods and [1,2]: (1) both methods need multiple interactions to give an answer, (2) both methods use prompting.\n\nThis time, our response is as follows:\n\nFirst, we believe it is way enough to prove [1,2] cannot be directly used as baselines according to previous rebuttal. \n\nAs for the new points raised by the reviewer, we believe mCAD might have misread our paper: reviewer mCAD seems to confuse the following three concepts (a) multiple actions are taken in 1 trajectory; (b) multiple offline trajectories used for In-Context-Learning as in ABA; (c) [1,2] include online trajectories as prompting.\n\n- In the reviewer\u2019s feedback, mCAD claims we need to do several asking actions in 1 trajectory (type (a)), but mCAD cited the ICL part (type(b)) to support this claim. \n\n- mCAD suggested that we use ICL prompt (type (b)), while [1,2] also use prompting (which is type(c), but mCAD mistaking it for type(b)). \n\nBesides this misreading, it is quite weird to ask someone to compare two methods simply because both of these methods use prompting regardless of other settings.\n\n---\n\n**Q2.** Whether the human model can output ground truth action?\n\nWe thank the reviewer for acknowledging that the previous criticism does not exist in Section 4.2. Now let\u2019s look at Section 4.1, ALFWorld, to solve the reviewer\u2019s concern. To finish the task, the agent needs to find the object, pick it up, wash it / heat it / cool it, or even open a desk lamp to check it, before placing it to the target location. As outlined in Appendix A, the human model only knows the placement of all the objects. In this paper, we propose that, instead of finding the object by onerous trial and error, it is more efficient to query in natural language. Therefore, in the first step \u201cfinding the object\u201d, the information may seem like the action, but this is exactly what the agent learned to ask. Furthermore, we would like to remind the reviewer that, for all the following steps, the human model does not know what task is assigned to the agent, it does not know what to do with the target object, it does not know the target location, so it can not produce the ground truth action.\n\n---\n\n**Q3.** Should we address hallucination in our paper?\n\nWe thank the reviewer for reading the related paragraph. However, as you may agree, the human model does not belong to the ABA method. It is just a proxy of real humans during evaluation, so as to evaluate ABA with minimal human involvement, which is not the key component of this paper. What's more, this result can be easily improved by using larger and stronger LLM. The Appendix C shows Vicuna 7B human model results, which only shows up in a small fraction of experiments in Section 4.1, while other results in Section 4.1 and Section 4.2 use GPT-35, GPT-4 as human model.\n\nThe question about hallucination is raised out of nowhere. We do not even mention the word \u201challucination\u201d in any related analysis or in our main paper. Although LLMs are well known for suffering from hallucination, how to solve this problem, however, is out of the scope of this paper."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4404/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700731149507,
                "cdate": 1700731149507,
                "tmdate": 1700734641252,
                "mdate": 1700734641252,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vryykks0x3",
            "forum": "9QVqYBvCD8",
            "replyto": "9QVqYBvCD8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4404/Reviewer_23Y9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4404/Reviewer_23Y9"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors propose the ABA method to empower agents to gather external contextual information before decision-making, which is inspired by the behavior of humans completing tasks in unknown environments. Agents benefit from the newly proposed ABA paradigm and can avoid unnecessary trial and error, enhancing its efficiency and performance. Experiments demonstrate the effectiveness of the proposed methods."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The proposed ABA idea is interesting. Compared to traditional self-explore agents, ABA agents can circumvent potentially laborious trial and error.\n- Leveraging natural language and ICL to inquire information from humans or LLM is reasonable.\n- The authors formulaically define the Contextual MDP with Human / External information sources in the loop based on the Contextual MDP, which provides a solid foundation to follow for future research.\n- Extensive details and demonstrations are provided in the appendix, which makes the work easy to follow.\n- The experiments are sufficient."
                },
                "weaknesses": {
                    "value": "Weaknesses:\n1. For embodied decision-making tasks, some related works need to be discussed. For example, previous works (e.g. [1]) explore the use of knowledge graph as external commonsense and extract pertinent information via GNN. Also, [2] extracts knowledge from VLM during the decision process. Both works aim to gather external information for improving navigation decisions in unseen environments, which is similar to the ABA idea.\n\n    [1] Room-and-object aware knowledge reasoning for remote embodied referring expression.\n\n    [2] Room-Object Entity Prompting and Reasoning for Embodied Referring Expression.\n\n2. Given that the core of the ABA method is to obtain effective external assistance, and obtaining external assistance has costs such as time, resources, and human efforts. Therefore, how to balance the inquiry frequency and performance is a missing topic in this work.\n\n3. There are still some typos, and the authors need to further polish the writing. \n- Page 4: Missing comma in the sixth line of subsection 3.2.1\n- Page 9: \"open do- main image\" in the conclusion section\n- Page 14: \"Section ??\"\n\n4. Combining the method with a real robot and verifying this work would be even better.\n\n5. Suggestion: Further simplify the formula."
                },
                "questions": {
                    "value": "See Weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4404/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698741199813,
            "cdate": 1698741199813,
            "tmdate": 1699636413905,
            "mdate": 1699636413905,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "BOySjsAHu4",
                "forum": "9QVqYBvCD8",
                "replyto": "vryykks0x3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thanks for your time and efforts in reviewing our paper! We highly appreciate your thoughtful and constructive suggestions. Your thoughtful and constructive suggestions have been invaluable to us, and we have carefully considered each comment. Our responses to your queries are outlined below:\n\n---\n\n***Q1. balance the performance and the efficiency***\n\nWe appreciate your observation regarding the balance between performance and efficiency. In ABA, our key design focuses on prompting the agent to ask questions only when necessary, achieved through the injection of a proper prior. In the ABA-FT variant, we further enhance this efficiency by treating known information as a type of metadata, aiding the decision-making process on whether to ask questions.\n\nTo demonstrate the efficiency of these designs, we conducted an ablation study by counting the total number of questions asked in V7B ALFWorld successful trials, and the results are as follows (which is also added to Appendix L):\n\n|                               | # Questions |\n|-------------------------------|-------------|\n| ALFWorld                      | $1.1$       |\n| ALFWorld with ambiguous tasks | $1.39$      |\n| Multiround ALFWorld           | $2.53$      |\n\nThe results indicate that the average number of questions closely aligns with the minimum necessary questions. This study substantiates our claim that ABA effectively minimizes the number of questions asked. We will leave minimizing the number of questions to our future work.\n\n---\n\n***Q2. Fix the typos***\n\nThanks! We have promptly rectified these errors in our manuscript, and the modifications have been highlighted in blue for your convenience.\n\n---\n\n***Q3. Missing related works***\n\nWe are grateful for your recommendation of additional relevant works. We have incorporated these insightful contributions into our related works section, alongside other vision-language navigation works like TD-STP, SEvol which we believe to be related to the embodied decision making setting. The modifications have been highlighted in blue.\n\n---\n\nWe sincerely appreciate your thorough review and constructive suggestions. If you have any further comments or inquiries, please do not hesitate to let us know. And we genuinely hope for your reconsideration of the score."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4404/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700152335517,
                "cdate": 1700152335517,
                "tmdate": 1700152335517,
                "mdate": 1700152335517,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hrxyHSxXkW",
                "forum": "9QVqYBvCD8",
                "replyto": "vryykks0x3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer, we would like to thank you again for your efforts and time in providing thoughtful feedback and comments. We\u2019ve revised the paper according to your suggestions and replied to all the questions and concerns. Since the discussion period is ending soon, we would greatly appreciate it if you could let us know whether you have any additional comments.\n\nThanks a lot!"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4404/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700543425841,
                "cdate": 1700543425841,
                "tmdate": 1700543425841,
                "mdate": 1700543425841,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "teGSeMvK3Z",
            "forum": "9QVqYBvCD8",
            "replyto": "9QVqYBvCD8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4404/Reviewer_P7Hr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4404/Reviewer_P7Hr"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a novel approach, \"Asking Before Acting\" (ABA), aimed at enhancing the decision-making efficiency of Large Language Models (LLMs) in unfamiliar environments. The core concept is inspired by human behavior, where individuals often seek additional information before taking action, thereby avoiding unnecessary trial and error. The ABA approach empowers agents to inquire proactively using natural language, enhancing their interaction within various environments. The paper begins by acknowledging the proficiency of LLMs in various tasks but highlights their inefficiency in environments with limited or ambiguous information. The ABA methodology is introduced as a solution, allowing agents to ask open-ended questions to gather essential information, leading to more efficient and informed decision-making. This approach is distinct from previous works that often restricted interactions or required human intervention for providing information. To further enhance ABA's performance, the authors introduce ABA-FT, which reformulates metadata associated with question formulation, helping the model understand the rationale behind asking questions. This fine-tuning process leads to notable improvements, especially in challenging tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- The introduction of the ABA methodology is a novel concept in the realm of AI and decision-making. By enabling LLMs to ask questions before taking actions, the authors bridge the gap between human interactive learning and machine autonomy. This approach mimics human behavior, representing a shift towards more intuitive, adaptive AI systems.\n- The authors have conducted thorough experiments across diverse environments, which adds credibility to their claims. By testing the ABA methodology in various scenarios, including text-based tasks, robot arm manipulations, and real-world open-domain tasks with image inputs, they demonstrate the model's versatility and applicability in different contexts."
                },
                "weaknesses": {
                    "value": "- The problem in the paper is formed as Contextual MDP, while I think it's better formulating the problem into a more suitable domain like POMDP, which is much well-accepted and clearly defined. Is there a necessity to use Contextual MDP? I hope the authors can further explain the motivation.\n- The paper's methodology heavily relies on the capabilities of Large Language Models (LLMs). I think the method itself does not make much sense. From my point of view, it seems just like the authors design some tasks with ambiguity and use the \"ask before action\" paradigm to help solve such ambiguity. But the model does not resolve such ambiguity by itself, i.e., through rapid trial-and-error. On the other hand, it still depends on the human to help it. So why not the human provide the complete information at the beginning? Besides, I don't see the proposed \"ask before action\" paradigm as a big contribution, as we have already see many works related to the LLM agency in which LLMs are driven to finish more complex interactions and tasks.\n- There lacks error analysis conducted on instances where ABA underperformed or failed. What insights were derived from these analyses?  Besides, I think additional QA in ABA actually imports more information compared with other baselines, which definitely lead to better performance. Maybe other baselines should also use information like \u201cthe second red block from the left\u201d for a equal comparison."
                },
                "questions": {
                    "value": "See weakness above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4404/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698758133992,
            "cdate": 1698758133992,
            "tmdate": 1699636413805,
            "mdate": 1699636413805,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5ZyCrTKnWt",
                "forum": "9QVqYBvCD8",
                "replyto": "teGSeMvK3Z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (2/2)"
                    },
                    "comment": {
                        "value": "***Q3. Why use Contextual MDP rather than POMDP:***\n\nAlthough Contextual MDP is a type of POMDP, we opted for the former because:\n\n- Contextual MDP provides a latent context $c$ which helps to model the task information, while POMDP does not. \n\n- $c$ helps better formulation: we can ask pertinent questions to infer the context $c$, the human model inside the environment $H$ will provide different answers to the same questions according to the different $c$. while POMDP can not.\n\n- Contextual MDPs are well defined and widely accepted, especially in RL generalization theory, multi-task, and meta RL domains. Please refer to [9] for a thorough survey.\n\n---\n\n***Q4. Error analysis on ABA:***\n\nWe provided error analysis of a typical failure case in Appendix F, and we appended several new failure cases at the end of Appendix F (modifications are highlighted in blue). The analysis can be summarized as follows:\n\nTwo key failure types are identified:\n\n- *undesirable answers from human models during evaluation*\n    \n    Note we use human models to mimic humans during evaluation to minimize human involvement, but this may sometimes provide undesirable answers.\n\n- *mismatches between agent commonsense and the environment*\n\n    For instance, the task is to collect eggs from the garbage can, but the agent believes the eggs are no longer suitable for eating and proposes to buy new ones. \n\nWe believe incorporating real humans during deployment and refining prompting can mitigate these failures, leaving room for future research. For detailed information, please refer to Appendix F.\n\n---\n\nOnce again, we sincerely appreciate your feedback, and we hope our responses address any concerns you may have. Your insights are crucial to the improvement of our work, and we welcome any additional feedback, and we genuinely hope for your reconsideration of the score. \n\n---\n\n[1] Khanh Nguyen and Hal Daume \u0301 III. Help, anna! visual navigation with natural multimodal assistance via retrospective curiosity-encouraging imitation learning. arXiv preprint arXiv:1909.01871, 2019.\n\n[2] Khanh Nguyen, Debadeepta Dey, Chris Brockett, and Bill Dolan. Vision-based navigation with language-based assistance via imitation learning with indirect intervention. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 12527\u201312537, 2019.\n\n[3] Kunal Pratap Singh, Luca Weihs, Alvaro Herrasti, Jonghyun Choi, Aniruddha Kembhavi, and Roozbeh Mottaghi. Ask4help: Learning to leverage an expert for embodied tasks. Advances in Neural Information Processing Systems, 35:16221\u201316232, 2022b.\n\n[4] Felipe Leno Da Silva, Pablo Hernandez-Leal, Bilal Kartal, and Matthew E Taylor. Uncertainty- aware action advising for deep reinforcement learning agents. In Proceedings of the AAAI con- ference on artificial intelligence, volume 34, pp. 5792\u20135799, 2020.\n\n[5] Iou-Jen Liu, Xingdi Yuan, Marc-Alexandre Co\u02c6te \u0301, Pierre-Yves Oudeyer, and Alexander Schwing. Asking for knowledge (afk): Training rl agents to query external knowledge using language. In International Conference on Machine Learning, pp. 14073\u201314093. PMLR, 2022.\n\n[6] Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, et al. Inner monologue: Embodied reasoning through planning with language models. arXiv preprint arXiv:2207.05608, 2022b.\n\n[7] Shah, Dhruv, B\u0142a\u017cej Osi\u0144ski, and Sergey Levine. \"Lm-nav: Robotic navigation with large pre-trained models of language, vision, and action.\" Conference on Robot Learning. PMLR, 2023.\n\n[8] Huang, Wenlong, et al. \"Voxposer: Composable 3d value maps for robotic manipulation with language models.\" arXiv preprint arXiv:2307.05973 (2023).\n\n[9] Kirk, Robert, et al. \"A survey of generalisation in deep reinforcement learning.\" arXiv e-prints (2021): arXiv-2111."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4404/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700151844617,
                "cdate": 1700151844617,
                "tmdate": 1700151844617,
                "mdate": 1700151844617,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pbWXOuFzml",
                "forum": "9QVqYBvCD8",
                "replyto": "teGSeMvK3Z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (1/2)"
                    },
                    "comment": {
                        "value": "Thanks for your time and efforts in reviewing our paper! We highly appreciate your thoughtful and constructive suggestions. Your thoughtful and constructive suggestions have been invaluable to us, and we have carefully considered each comment. Our responses to your queries are outlined below:\n\n---\n\n***Q1. about the setting and contribution: the \"asking before action\" paradigm***\n\nAfter reading the review, we would like to clarify our setting in case of any potential misunderstandings:\n\nCurrently, LLM based agents are designed to solve tasks on their own without external interactions, which is identified to be inefficient in scenarios with limited information.\nTo address this concern, we concentrate on a special type of setting with human / external information sources in the loop (refer to Def 3.1), and propose the \u201casking before action\u201d paradigm. This distinguishes our work from purely autonomous agents.\n\nWe believe human / external information in the loop is important and promising [1-6]. \nWe are not primarily concerned with completing complex tasks through trial-and-error but with facilitating decision-making through interaction with humans. \n\nWe take a significant step forward in the Human-in-the-Loop (HITL) setting. Previous works including [1-6] ask for oracle action, template questions, etc. ABA proposes gathering necessary information in natural language. This contributes to a novel setting, a set of newly designed benchmarks, and helps extend the boundary of current research.\n\nLooking ahead, we foresee combining ABA with recent advances in purely autonomous works, such as [7] for navigation and [8] for pick-and-place tasks, to build more intelligent embodied agents.\n\n**To summary, our contributions are:**\n\n1. identify a novel setting (~Def 3.1) that can possibly contribute to building a more embodied AI in the real world.\n\n2. design new methods which can mimic human behavior, and \"representing a shift towards more intuitive, adaptive AI systems\".\n\n3. a set of benchmarks with a set of human model designs that can facilitate later research in this direction.\n\n---\n\n***Q2. about the scenarios: Why Not Provide Complete Information at the Beginning/Feed to Other Baselines?***\n\nWe appreciate your question about complete information. We believe providing complete information is impractical for real-world tasks due to scale differences between simulators and reality. \n\nWhile simulators may handle scenarios with dozens of objects, the real world poses challenges in enumerating all relevant information. To illustrate, consider seeking assistance in preparing lunch\u2014an exhaustive list of utensils and ingredients would require significant human effort and might overlook unforeseen circumstances. Therefore, for real-world scenarios, providing complete information is not viable, and we have not supplied it to other baselines."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4404/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700152026121,
                "cdate": 1700152026121,
                "tmdate": 1700152026121,
                "mdate": 1700152026121,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gVH07Qu0Q1",
                "forum": "9QVqYBvCD8",
                "replyto": "teGSeMvK3Z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4404/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer, we would like to thank you again for your efforts and time in providing thoughtful feedback and comments. We\u2019ve revised the paper according to your suggestions and replied to all the questions and concerns. Since the discussion period is ending soon, we would greatly appreciate it if you could let us know whether you have any additional comments.\n\nThanks a lot!"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4404/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700543402908,
                "cdate": 1700543402908,
                "tmdate": 1700543402908,
                "mdate": 1700543402908,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]