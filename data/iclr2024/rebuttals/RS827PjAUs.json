[
    {
        "title": "InstructProtein: Aligning Human and Protein Language via Knowledge Instruction"
    },
    {
        "review": {
            "id": "P6o9vnybvi",
            "forum": "RS827PjAUs",
            "replyto": "RS827PjAUs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3320/Reviewer_DyDT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3320/Reviewer_DyDT"
            ],
            "content": {
                "summary": {
                    "value": "While showing revolutionary abilties in classical language sequences processing, Large Lanuage Models fall short at processing protein sequences, for example, protein function annotation. This paper makes effort to allow LLMs work better in protein processing tasks.\n\nThe authors claim the main challenge lies on the corpus diffenrence between the areas of human and protein languages.\nTo align the two languages, the authors propose (1) incrementally pre-training a LLM using both protein corpus and text corpus and (2) supervised instruction tuning LLMs by collecting and utilizing a knowledge-graph-enhanced instruction dataset.\n\nWhen applying the instruction-tuning, the authors propose a relatively new data-collection framework that utilizes the knowledge-graph to make the instuctions reveal more causal knowledge and a data-sampling technique to overcome the data-inbalance of commonly- and uncommonly-researched proteins.\n\nExperiments demonstrate the proposed methods can help LLMs achieve SOTA on several protein processing tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- aligning protein 'language' with human language where LLMs originally trained on is one key and promising field to make LLMs solve protein processing tasks. In general, this paper can contribute to this field, i.e. achieving new SOTA by incremetally pre-training and collecting new data to conduct instruction finetuning.\n- collecting instuction-tuning dataset from knowledge-graph is novel and insightful.\nThis can help to pose causal knowledge priori on finetuning LLMs.\nThe motivation is clearly clarified, and I think it can motivate further works in broader fields.\nBut the writing lacks details and citations of related works. I will detail the weakness in the next part.\n- the data-sampling strategy is interesting and relatively new from my perspective. The experiments, althought with some weakness, demonstrate that the data-sampling strategy can heavily boost the performances."
                },
                "weaknesses": {
                    "value": "- Regarding the data-collection. Prompt each triplet to ChatGPT and get the results as the instruction is an important step. But will this assume that ChatGPT can already be prompted to understand the protein input and make output correctly? Especially, in the Figure 4 which is an example of how ChatGPT is prompted, the ChatGPT can infer the information 'it is in the leptin family' and this information is important to pose the causal knowledge. How you guarantee that the output is correct and useful? 'ChatGPT' can understand protein is not a desiable assumption.\n\n- Lacking of details. Regarding the data-collection, more details about the knowledge-graph need to be provided. You claim knowledge-graph can provide causal knowledge. The motivation can be more straghtforward if you tell what relationships the KG can provide and help the downstream tasks. Regarding the sampling, how the protein KG embedding is initialized? and what are the training details?\n\n- More citations needed. The authors provide an overview of different instruction methods but I cannot see any related citations in the context. Also, regarding the sampling strategy, the authors should cite highly-related works in the context rather than putting all to the related-works far-away.\n\n- More ablation studis needed. Ablation experiments on the incremental pre-training is necessary. And as  there is no enough details about training KG embeddings, I suspect the training is too tricky. The authors should provide ablations studies about only clusering by the editing distance to demonstrate the necessary of the embedding training. Also, ablation studies about the hyperparameters choices are needed."
                },
                "questions": {
                    "value": "Please address my concerns list in the Weakness Part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3320/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698722127041,
            "cdate": 1698722127041,
            "tmdate": 1699636281515,
            "mdate": 1699636281515,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jXOsoaJxqF",
                "forum": "RS827PjAUs",
                "replyto": "P6o9vnybvi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3320/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3320/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal for Reviewer DyDT (1/2)"
                    },
                    "comment": {
                        "value": "We would like to express our great appreciation to reviewer DyDT for their comments on our paper. The response to your concerns is as follow:\n\n> Regarding the data-collection. Prompt each triplet to ChatGPT and get the results as the instruction is an important step. But will this assume that ChatGPT can already be prompted to understand the protein input and make output correctly? Especially, in the Figure 4 which is an example of how ChatGPT is prompted, the ChatGPT can infer the information 'it is in the leptin family' and this information is important to pose the causal knowledge. How you guarantee that the output is correct and useful? 'ChatGPT' can understand protein is not a desiable assumption.\n\nThe methods shown in Figure 3a and 3b assume that LLMs understand proteins and are able to come up with novel tasks and output desired answers. Compared to them, our innovation lies in the removal of such an assumption regarding LLMs possessing inherent protein-related knowledge, as depicted in Figure 3c. We retrieve the facts needed to generate the answer through KG and prompt LLMs how to generate tasks through KGC templates. All LLMs need to do is to faithfully convert the  triplet to natural language. \n\nIn Figure 4, our retrieval process involves not only acquiring the triplet (MRCPG..., function, hormone) but also capturing associated knowledge (MRCPG..., family, leptin) that exhibits a causal relationship with the triplet. By utilizing these two interlinked pieces of information, we prompt ChatGPT to generate instructions. Figure 8 offers a detailed breakdown of the process involved in converting a triplet into instruction data. This breakdown encompasses inputs (prompt) and outlines ChatGPT's corresponding outputs.\nWe will add these analysis in the final version.\n\n> Lacking of details. Regarding the data-collection, more details about the knowledge-graph need to be provided. You claim knowledge-graph can provide causal knowledge. The motivation can be more straghtforward if you tell what relationships the KG can provide and help the downstream tasks. Regarding the sampling, how the protein KG embedding is initialized? and what are the training details?\n\nThanks for your advice. I would like to elaborate on the components involved:\n\n(1) **Knowledge Graph**: Our knowledge graph comprises triples denoting (protein, relation, annotation). As delineated in Section 4.1, the annotations encompass various attributes such as superfamily, family, domain, conserved site, active site, binding site, location, function, and involved biological processes of proteins. Notably, proteins utilized in downstream tasks have been excluded from the training data to maintain integrity.\n\n(2) **Causal Knowledge**: The mentioned annotations are distinct and independent entities. In the realm of protein function exploration by biologists, the customary approach involves commencing with easily studied features and deducing inferences based on the interconnections among these features. The objective of integrating causal knowledge is to equip language models with the capability to reason based on the relationships among annotations. This causal knowledge specifically encompasses the causal relationship from family and key sites to protein function and biological processes (A protein with an anaphylatoxin/fibulin domain indicates that it is probably located in an extracellular region).\n\n(3) **KG Embedding**: Following the TransE approach, we initiate embeddings for entities and relationships through a random initialization procedure [1]. We employ the SGD optimizer with a learning rate of 1.0. The dimensions of entities and relations' embeddings are set to 200. After 1000 epochs, the loss eventually converges to 0.168. The L2 distance utilized for clustering proteins is set to 1.4. We will add these details in the final draft.\n\nWe will add these details in the final version."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3320/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700455311186,
                "cdate": 1700455311186,
                "tmdate": 1700455311186,
                "mdate": 1700455311186,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "iReFILii7s",
            "forum": "RS827PjAUs",
            "replyto": "RS827PjAUs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3320/Reviewer_modh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3320/Reviewer_modh"
            ],
            "content": {
                "summary": {
                    "value": "The paper you described proposes InstructProtein, a large language model designed to bridge the gap between natural language and biological sequences, specifically proteins."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper introduces an approach to leverage large language models for comprehending biological sequences, such as proteins.\n\n2. The paper introduces a knowledge graph-based instruction generation framework to construct a high-quality instruction dataset. \n\n3. Experimental results show that InstructProtein outperforms state-of-the-art large language models."
                },
                "weaknesses": {
                    "value": "1.It is mentioned in the text that the higher the absolute value of the pLDDT score, the better. However, I believe it is not that straightforward. The pLDDT score is an indicator of the quality of a protein's structure, and in the text, protein sequences are generated using a language model. The unstructured regions in the protein sequence have a significant impact on the protein's function, and correspondingly, the pLDDT score may be lower. To compare the quality of generated protein sequences, it's important to evaluate whether the distribution in multiple dimensions aligns with real proteins as shown in Figure 5. In addition, the visualized results should incorporate real protein visualization results. \n\n2.In addition, There are alternative evaluation metrics for evaluating the generated sequences , such as assessments based on \u03b1\u03b2 structures, barrel helices, thermostability, metal element binding, etc. From an AI perspective, tools like Biopython can also be used to analyze biological aspects, such as pI values and electrostatic potential.\n\n3.When conducting baseline comparisons, it is more convincing to compare against Mol-Instructions in addition to LLaMA and Alpaca. Mol-Instructions is a dataset constructed from text data of proteins based on UniProtKB, and fine-tuned on LLaMA-7B. Therefore, this paper should give the comparison results against Mol-Instructions. \n\n4.In the section 4.2 , \"For a fair comparison, we designed a template for each model through prompt engineering so that the model could follow our instructions and output the answers.\" What I understand is that for other models, they will fine-tune based on templates. Can you add supplementary information in the appendix regarding the hyperparameters and dataset size for model fine-tuning? This would make the results more reliable.\n\n5.For ablation study, the article could delve into topics like how to address key residue mutations in overcoming the GO task or why the introduction of annotations leads to performance improvements. Additionally, the paper could elaborate on why fragment clusters based on protein properties can help avoid such issues."
                },
                "questions": {
                    "value": "see above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3320/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698732379472,
            "cdate": 1698732379472,
            "tmdate": 1699636281416,
            "mdate": 1699636281416,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gcyAJ1JB2E",
                "forum": "RS827PjAUs",
                "replyto": "iReFILii7s",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3320/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3320/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal for Reviewer modh (1/2)"
                    },
                    "comment": {
                        "value": "We would like to express our great appreciation to reviewer modh for their comments on our paper. The unclear content have been revised in manuscript, and the response to your concerns is as follow:\n\n> It is mentioned in the text that the higher the absolute value of the pLDDT score, the better. However, I believe it is not that straightforward. The pLDDT score is an indicator of the quality of a protein's structure, and in the text, protein sequences are generated using a language model. The unstructured regions in the protein sequence have a significant impact on the protein's function, and correspondingly, the pLDDT score may be lower. To compare the quality of generated protein sequences, it's important to evaluate whether the distribution in multiple dimensions aligns with real proteins as shown in Figure 5. In addition, the visualized results should incorporate real protein visualization results.\n\nRegarding Figure 5, our evaluation focuses on the model's proficiency in adhering to structure-related instructions. In this context, the pLDDT score serves as a suitable evaluation metric. Specifically, when presented with an instruction such as 'I would like an all-alpha protein', the sequences generated by the model should demonstrate an increased proportion of alpha-helix and a decreased proportion of Intrinsically Disordered Protein (IDP) regions and other secondary structures. The high pLDDT score effectively reflects the low proportion of IDP regions, thus serving as a pertinent evaluation metric. Furthermore, Figures 5 (b,c) visually represent the embedding and predicted structures, highlighting significant differences in protein embeddings generated by distinct instructions. Notably, the folded structure aligns consistently with the provided instructions. In response to your suggestion, we've incorporated visualization results of real proteins, depicted in Figure 13. Upon observation, we note a striking similarity between the distribution of generated protein representations and that of real proteins. This congruence signifies the model's remarkable instruction-following ability. We will add these analysis in the final draft.\n\n> In addition, There are alternative evaluation metrics for evaluating the generated sequences, such as assessments based on \u03b1\u03b2 structures, barrel helices, thermostability, metal element binding, etc. From an AI perspective, tools like Biopython can also be used to analyze biological aspects, such as pI values and electrostatic potential.\n\nThanks for providing alternative evaluation metrics for the generated sequences. The experiments is Section 4.3 are designed to demonstrate the model's instruction-following ability rather than merely assessing sequence quality. Therefore, the evaluation metrics need to correspond to the instructions (i.e., structure-related instruction with structure-related metrics, etc). Furthermore, in response to your suggestions, to assess generated sequences based on metal element binding, we additionally design three proteins with the instructions of ``I would like a protein that enables metal ion binding''. However, their binding ability cannot be concluded without wet experimental verification. So we compared it to existing protein to evaluate them as shown in Figure 15.\n\n> When conducting baseline comparisons, it is more convincing to compare against Mol-Instructions in addition to LLaMA and Alpaca. Mol-Instructions is a dataset constructed from text data of proteins based on UniProtKB, and fine-tuned on LLaMA-7B. Therefore, this paper should give the comparison results against Mol-Instructions.\n\nWe leverage the checkpoint from \"zjunlp/llama-molinst-protein-7b\" and report the results as shown below:\n\n| Model (ACC)| Location (bin) | Location (Sub) | GO (BP) | GO (MF) | GO (CC) | Fold Rank (Fold) |\n| --- | --- | -- | --- | --- | --- | --- |\n| Mol-Instructions | 57.52 | 18.36   | 50.00 | 50.00 | 50.00 |  12.81 |\n| InstructProtein  | 85.19  | 70.79|71.49|85.83 |79.79 | 55.57 |\n\nFrom the results, we found three shortcomings of this model. Firstly, we have observed that employing a naive data cleaning strategy does not offer immunity to label imbalance issues. This observation further emphasizes the superiority and effectiveness of our proposed knowledge instruction methodology. Secondly, due to the lack of diversity of Mol-Instructions templates (excluding true/false questions), the model cannot understand the questions in the GO task and answer them accordingly. We propose that the cooperation of KG and LLMs to ensure the diversity of data is key for text and protein alignment. Finally, Mol-Instructions uses BPE to tokenize proteins, which makes it more difficult for the model to distinguish the nuances of proteins than amino acid-based tokenization, resulting in poor results on Fold Rank. Further, we leverage their model to design proteins as shown in Figure 14. The results demonstrate the model lacks the ability to follow structural instructions."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3320/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700454905544,
                "cdate": 1700454905544,
                "tmdate": 1700454905544,
                "mdate": 1700454905544,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0p2G7YWsYz",
            "forum": "RS827PjAUs",
            "replyto": "RS827PjAUs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3320/Reviewer_Cqaz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3320/Reviewer_Cqaz"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new model called InstructProtein that enables bidirectional generation capabilities between natural language and protein sequences within a single large language model (LLM). The key ideas are:\n- Pre-train an LLM on both protein sequences and natural language text to acquire representations for both modes.\n- Generate a  instruction dataset from a protein knowledge graph using a proposed debiased sampling strategy and knowledge causal modeling.\n- Perform supervised instruction tuning on the LLM using the generated instructions to align the protein and natural language modalities.\n\nThe model is evaluated on classification tasks for protein sequence understanding tasks. Results show  improvements over open source LLMs."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The idea of using instruction tuning to align proteins and text is innovative and enables bidirectional generation between the two modes. This opens up new possibilities for protein design and engineering.\n- The proposed instruction generation methodology using knowledge graphs to improve instruction quality and the debiased sampling handles annotation imbalance and knowledge causal modeling provides causal links. These proposed method is able to improve instruction dataset quality.\n- Comprehensive evaluations in classification tasks shows the improvement on the proposed methods."
                },
                "weaknesses": {
                    "value": "-Additional baselines should be incorporated for a more comprehensive analysis. The current comparison lacks an evaluation against more advanced Large Language Models (LLMs) such as ChatGPT[1] , GPT-4 [2] , and Claude-2[3] . It is crucial to understand the performance disparities between the proposed method and these well-established models.\n\n-The evaluation is restricted to classification tasks. There is a need to extend the assessment to more free-form instruction-based tasks[4] . One of the predominant applications of current chat assistant models is to interact with users. Hence, an evaluation that transcends beyond classification tasks is imperative to reflect more realistic usage scenarios.\n\n-There is an absence of experimentation on the model's generalization capabilities. Recent studies in domain-specific instruction tuning suggest that training confined to a particular domain may impede generalization due to a lack of diversity in the training data [5]. I urge you to emphasize the aspect of 'diversity' in your study. Could you demonstrate the generalization abilities of your model in various contexts?\n\n-Lack of scale up experiments. I am not sure if the conclusion holding in larger LLMs such as 7B,13B?\n\n-Lack of experiments on different model family, such as LLaMA[6] and LLaMA-2[7].\n\n[1] OpenAI. (2022). Introducing chatgpt. https://openai.com/blog/chatgpt, 2022. \\\n[2] OpenAI (2023). GPT-4 Technical Report \\\n[3] Anthropic (2022). Instroducing claude. https://www.anthropic.com/index/introducing-claude \\\n[4]  Dubois et al (2023). AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback \\\n[5]  Zhang et al (2023). AlpaCare:Instruction-tuned Large Language Models for Medical Application \\\n[6]  Touvron et al (2023). LLaMA: Open and Efficient Foundation Language Models \\\n[7] Touvron et al (2023). Llama 2: Open Foundation and Fine-Tuned Chat Models"
                },
                "questions": {
                    "value": "- Can you show your results on compare with more powerful LLMs e.g ChatGPT, GPT-4, and Claude-2?\n\n- Can you show results on some open-ending text generation tasks both in-domain and general domain. For general domain, I suggest to follow Alpaca-farm.\n\n- Can you show results on different size of LLMs across different LLM families ?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3320/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3320/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3320/Reviewer_Cqaz"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3320/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698949559265,
            "cdate": 1698949559265,
            "tmdate": 1699636281356,
            "mdate": 1699636281356,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LAqMxZY4Lq",
                "forum": "RS827PjAUs",
                "replyto": "0p2G7YWsYz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3320/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3320/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal for Reviewer Cqaz (1/2)"
                    },
                    "comment": {
                        "value": "Thanks for your constructive and valuable comments, which have helped us improve the paper considerably. We will address these confusion and move this to the main text in the final version to make our paper stronger.\n\nBefore the point-by-point response, we would like to underscore the contributions of our work. Firstly, our study identifies and highlights the prevalent issue of annotation imbalance within the current protein corpus, as elaborated in Section 2. We propose a comprehensive framework designed to generate high-quality text-protein-aligned instruction data sourced from an imbalanced knowledge base. We believe this instruction dataset will greatly faciliate future LLM research in biology. Secondly, we introduce InstructProtein, a model specifically trained on our constructed instruction data, demonstrating proficiency in comprehending the nuances of protein language. \n\nIt is crucial to note that this article's primary focus centers on the translation between natural language and protein language. While our framework enables interaction with users through text-based communication, broader interaction akin to ChatGPT in general domain exceeds the current scope of our study.\n\n> Additional baselines should be incorporated for a more comprehensive analysis. The current comparison lacks an evaluation against more advanced Large Language Models (LLMs) such as ChatGPT , GPT-4, and Claude-2. It is crucial to understand the performance disparities between the proposed method and these well-established models.\n\nTo comprehend the performance disparities between InstructProtein and these established models, we conducted the localization annotation experiments of 100 proteins. Presented below is the statistical results as well as a specific case along with the corresponding response:\n\n| model                      |ChatGPT |Claude-2| GPT-4 | InstructProtein |\n| ---------------------- | ----- | ----- | ----- | ---- |\n| Localization  (acc)   | 0.15 | 0.23 |  0.18   | 0.67 | \n\n```\nUser: What cellular component is the protein located in? Please give only one prediction. MKLAIGRLLSPLFLKNPQKPLIITKRFYSTPGERRIKDILTEKLSPSSLRVIDVSGGCGSMYQVAIKSKAFQGKNTLAQHRLVNSILKEEIRNMHGLNLSTEVEDDISAGGSTTSS\n\nChatGPT: Based on the provided amino acid sequence, the prediction for the cellular component of the protein is the cell membrane. (Wrong)\n\nGPT4: Based on the sequence provided, I would predict that this protein is located in the mitochondrion.  Here's the rationale for my prediction: ...(Wrong)\n\nClaude-2: Nucleus. My rationale: (1) It lacks a signal peptide, indicating it is not a secreted protein. (2) It does not contain any predicted transmembrane domains, suggesting a soluble localization. (3) It has abundant lysine and arginine residues providing a positive charge. (Wrong)\n\nInstructProtein: The protein is located in mitochondrion. (Correct)\n```\n\nThe results yield three pivotal observations. Firstly, we are surprised to discover that ChatGPT and Claude-2's predictions solely encompassed cytoplasm, nucleus, cell membrane, and secreted locations. This finding underscores that annotation imbalance impacts even these well-established models. Notably, the performance degradation due to data imbalance persists despite model enhancements or increased training data, further emphasizing the significance of our contributions of the high-quality instruction dataset. Secondly, while the responses from them may initially appear plausible, their prediction accuracy is notably deficient. This highlights a crucial aspect regarding the precision of their predictions, indicating a large performance disparity. Additionally, we employed ChatGPT and Claude-2 to design the globin-like, immunoglobulin-like, and tim beta-alpha-barrel protein, and the outcomes are visually presented in Figure 14. We observed that Claude-2 ignores all instructions and output proteins with similar structures no matter what instructions were given. ChatGPT, on the other hand, can only understand basic instructions (globin-like, immunoglobulin-like). Only InstructProtein can faithfully follow instructions to generate desired proteins.\n\nHere, we would like to explain why we did not consider ChatGPT or GPT-4 as baselines before. Until the day we submitted this manuscript to ICLR, ChatGPT often refused to generate protein sequences, as shown in Figure 1. We have tried our best to write the appropriate prompt, but for some cases, these LLMs still tend to decline protein sequence generation, which makes automated benchmark comparison impossible."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3320/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700453922655,
                "cdate": 1700453922655,
                "tmdate": 1700454052142,
                "mdate": 1700454052142,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "mlyKPEquwK",
            "forum": "RS827PjAUs",
            "replyto": "RS827PjAUs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3320/Reviewer_Ex2Y"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3320/Reviewer_Ex2Y"
            ],
            "content": {
                "summary": {
                    "value": "In this work, the authors developed LLM called InstructProtein that has bidirectional generation capabilities: (1) translating the protein sequence to its textual function description (2) translating natural language instruction to the protein sequence. \nTo achieve this, the LLM is pre-trained on protein and natural language corpora. Specifically, the protein UniRef100 and sentences from PubMed abstracts are used for pre-training. To further obtain good performance on downstream tasks, the authors constructed a high-quality instruction dataset. This dataset is generated based on the knowledge graph that is constructed from the annotations of UniProt/Swiss-Prot. Overall, a KG triple to instruction generator (based on ChatGPT) was used . The chain-of-thought strategy and debiased sampling strategy were used for this generation process. In total, 2.8 million data is constructed.\nExperiments on de novo design and three protein function classification tasks (1) Protein localization prediction (2) Protein function annotation (3) Metal Ion Binding prediction showed that the protein knowledge instructions can boost the performance of protein understanding and design tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This is an interesting work on applying large language model to bioinformatics. Some related work have tried to align protein with human language. However, they either only showed unidirectional cross-modal capability, focusing solely on converting protein language to texts, or did not align the protein and human language very well. InstructProtein improves this by pre-training on UniRef100 and sentences from PubMed abstracts, providing a good foundation model on protein domain and filling the gap between the two languages and enabling the bidirectional generation. This work also contributes the first high-quality protein instruction dataset, by designing an effective data generation framework."
                },
                "weaknesses": {
                    "value": "For the first conclusion in 4.2: The results (comparing with OPT, LlaMa, Alpaca) demonstrate that training with the corpus where proteins and natural language coexist is beneficial to LLMs, enhancing their proficiency in protein language understanding. However, I think this argument can not be concluded based on these results. Because the performance of the InstructProtein is contributed by both pre-training and finetuning. Without finetuning LLMs on the instruction corpus, we can not conclude that the coexist of proteins and natural language is beneficial (even this conclusion is quite intuitive)."
                },
                "questions": {
                    "value": "Do we have any quality evaluation on the generated instruction dataset?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3320/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698956102547,
            "cdate": 1698956102547,
            "tmdate": 1699636281272,
            "mdate": 1699636281272,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6k4ibt0epE",
                "forum": "RS827PjAUs",
                "replyto": "mlyKPEquwK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3320/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3320/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal for Reviewer Ex2Y"
                    },
                    "comment": {
                        "value": "We thank Reviewer Ex2Y for reviewing our paper and providing thoughtful feedback on our work. We have revised the manuscript to make this paper easier to follow. Here, we provide details on comments below.\n\n> For the first conclusion in 4.2: The results (comparing with OPT, LlaMa, Alpaca) demonstrate that training with the corpus where proteins and natural language coexist is beneficial to LLMs, enhancing their proficiency in protein language understanding. However, I think this argument can not be concluded based on these results. Because the performance of the InstructProtein is contributed by both pre-training and finetuning. Without finetuning LLMs on the instruction corpus, we can not conclude that the coexist of proteins and natural language is beneficial (even this conclusion is quite intuitive).\n\nThank you for highlighting the potential misunderstandings that the conclusion might induce. The essence of this conclusion lies in highlighting the limitation of the current Natural Language Processing (NLP) corpus in furnishing protein comprehension abilities to Large Language Models (LLMs). To further substantiate the advantages of a corpus integrating both proteins and natural languages, we are providing additional experimental results, presented below:\n\n| model / ACC            | GO-BP | GO-MF | GO-CC |\n| ---------------------- | ----- | ----- | ----- |\n| Pre-train (UniRef100 + PubMed)                | 53.41 | 57.79 | 54.33 |          \n| Pre-train + Fine-tune (Knowledge Instruction)        | 71.49 | 85.83 | 79.69 |\n\nThe pre-training is conducted with the UniRef100 and Pubmed datasets that respectively contain proteins  and biomedical literature, while the finetuning is conducted using the proposed Knowledge Instruction approach with aligned natural language and protein language corpora. We can observe that the improvement of the performance is mainly due to the instruction tuning stage. We will add this results to the final draft.\n\n> Do we have any quality evaluation on the generated instruction dataset?\n\nWe advocate assessing the quality of the generated instruction dataset based on both correctness and diversity. To mitigate the potential generation of erroneous data by Large Language Models (LLMs), we construct a Knowledge Graph (KG) based on the well-maintained UniProbKB database and regared it as a reliable knowledge source. Then, we sample from this KG and convert the sampled triples to instructions. In this way, the correstness of the instruction dataset can be tracked and guaranteed by the UniProbKB.\nDiversity is quantified with information entropy. For instance, considering subcellular location-related instructions, Figure 2 highlights annotation imbalance. The original data distribution's information entropy is calculated as $H(x)=-\\sum_x p(x)\\log p(x) = 3.17$. Through our proposed KG triplet retrieval method, this entropy increases to $3.68$. This increment in information entropy denotes enhanced diversity within the dataset, illustrating increased coverage and richness of information in the generated instructions. We will add the above analyses to the final draft."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3320/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700453508344,
                "cdate": 1700453508344,
                "tmdate": 1700453508344,
                "mdate": 1700453508344,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]