[
    {
        "title": "Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations"
    },
    {
        "review": {
            "id": "dihvmtwq2E",
            "forum": "2Y5Gseybzp",
            "replyto": "2Y5Gseybzp",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3986/Reviewer_QeBS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3986/Reviewer_QeBS"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a unified framework for multiple weakly supervised learning settings, including noisy label, partial label, and multiple label candidates. The unified framework can be described in a formulation shown in Eq5, and multiple learning problems can be solved under the framework. The proposed framework shows good performance on all those problems."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The exploration of multiple learning problem settings involving imprecise labels holds significant importance for researchers. It is intriguing to observe the presentation of a unified perspective on these diverse problems.\n\nThe unified framework is sound and effective. \n\nThe proposed method shows good performance on multiple learning settings. The experiments on the performance comparison are complete and convincing. Most of recent SOTA methods are included as baselines."
                },
                "weaknesses": {
                    "value": "1. It is good to see the proposed method can be seamlessly combined with the data augmentation techniques, but it would be helpful to examine the model's performance without data augmentation techniques. It seems that the method's performance is sensitive to the quality of data augmentation, but not all kinds of tasks can be easily benefit from data augmentation. An ablation study would be helpful.\n\n2. There are also some other related works on unifying multiple problem settings of weakly/imprecise supervised learning. Some discussions on this topic can improve this paper. For example,\n[1] Centroid Estimation With Guaranteed Efficiency: A General Framework for Weakly Supervised Learning, TPAMI\n[2] Weakly Supervised AUC Optimization: A Unified Partial AUC Approach, arxiv 2305.14258\n\n\n3. The presentation can be further improved. There are typos and errors in the paper, e.g., missing punctuations, broken cross references to the figures, etc."
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3986/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698801859394,
            "cdate": 1698801859394,
            "tmdate": 1699636360416,
            "mdate": 1699636360416,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mrn277691a",
                "forum": "2Y5Gseybzp",
                "replyto": "dihvmtwq2E",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3986/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3986/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer QeBS"
                    },
                    "comment": {
                        "value": "Thanks for your recognition of the significance of our work and your valuable suggestions. Our response is as follows,\n\n> 1. \"It is good to see the proposed method can be seamlessly combined with the data augmentation techniques, but it would be helpful to examine the model's performance without data augmentation techniques. It seems that the method's performance is sensitive to the quality of data augmentation, but not all kinds of tasks can be easily benefit from data augmentation. An ablation study would be helpful.\"\n\nThanks for this valuable suggestion. \nWe totally understand your point that strong augmentation might be difficult to apply such as on text data or audio data. \nHowever, strong augmentation, proposed in FixMatch [1], has been demonstrated very important and critical for achieving effective performance in SSL.\nFor PLL, many baseline methods also use strong augmentations. \nFor NLL, the strong augmentation is less important compared to other settings. \nThus, we provide an ablation study of the strong augmentation for PLL and NLL:\n\n|           PLL           | CIFAR-10, partial ratio 0.5 | CIFAR-100, partial ratio 0.1 |\n|:-----------------------:|:---------------------:|:-----------------:|\n|           PiCO          |         93.58         |       69.91       |\n|           Ours          |         95.91         |       74.00       |\n|           PiCO (w/o strong aug)         |     91.78            |   66.43           |\n| Ours (w/o strong aug) |            94.53            |            72.69         |\n\n\n|           NLL           | CIAFR 10, noise ratio  0.8 | CIFAR 100, noise ratio 0.8 |\n|:-----------------------:|:--------------------------:|:--------------------------:|\n|           SOP           |        94.00                    |           63.30                |\n|           Ours          |        94.31                    |              66.46               |\n|   SOP (w/o strong aug)  |        66.85                   |                  36.60          |\n|  Ours (w/o strong aug)  |        93.56                    |                65.89            |\n\nFor PLL, it is shown that the strong augmentation indeed affects the performance very much for both the baseline PiCO and our method. \nFor NLL, removing the strong augmentation has less effect on our method but has a detrimental effect on SOP.\nWe have included the above ablation study in Appendix D. 7. \n\n\n> 2. \"There are also some other related works on unifying multiple problem settings of weakly/imprecise supervised learning. Some discussions on this topic can improve this paper. For example, [1] Centroid Estimation With Guaranteed Efficiency: A General Framework for Weakly Supervised Learning, TPAMI [2] Weakly Supervised AUC Optimization: A Unified Partial AUC Approach, arxiv 2305.14258\"\n\nThanks for mentioning these related works and we have added discussion about them in the revised version of related work. \n\n\n> 3. \"The presentation can be further improved. There are typos and errors in the paper, e.g., missing punctuations, broken cross references to the figures, etc.\"\n\nThanks for pointing this out. \nWe are sorry for the errors and typos in the paper and the confusion caused. We have updated the errors and typos we found and fixed the broken references in the revised paper. \n\nWe hope our response can resolve your concerns."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699932631744,
                "cdate": 1699932631744,
                "tmdate": 1699933297082,
                "mdate": 1699933297082,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hPxZS2tqCN",
            "forum": "2Y5Gseybzp",
            "replyto": "2Y5Gseybzp",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3986/Reviewer_yf7f"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3986/Reviewer_yf7f"
            ],
            "content": {
                "summary": {
                    "value": "The article addresses the challenge of learning with imprecise labels in machine learning tasks, such as noisy or partial labels. Traditional methods often struggle with multiple forms of label imprecision. The authors introduce a novel framework named Imprecise Label Learning (ILL) that serves as a unified approach to handle various imprecise label scenarios. ILL employs the expectation-maximization (EM) technique, viewing precise labels as latent variables and focusing on the entire potential label distribution. The framework demonstrates adaptability to different learning setups, including partial label learning and noisy label learning. Remarkably, ILL outperforms existing techniques designed for imprecise labels, establishing itself as the first integrated approach for such challenges."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The article offers a comprehensive solution to the prevalent challenge of imprecise annotations, enhancing the adaptability and applicability of machine learning models.\n2. The inclusion of experimental results across multiple settings provides empirical evidence of the framework's robustness and superior performance."
                },
                "weaknesses": {
                    "value": "1. The article's innovation is limited, as the approach of considering ground-truth labels or Bayes label distribution as latent variables and using variational inference for approximation in weakly supervised learning is already a common method[1-2], which suggests that the presented techniques may not be as novel as claimed.\n\n   [1] Xu, N., Qiao, C., Geng, X., & Zhang, M. L. (2021). Instance-dependent partial label learning. Advances in Neural Information Processing Systems, 34, 27119-27130. \n\n   [2] Yao, Y., Liu, T., Gong, M., Han, B., Niu, G., & Zhang, K. (2021). Instance-dependent label-noise learning under a structural causal model. Advances in Neural Information Processing Systems, 34, 4409-4420.\n\n2. The article's treatment in section 3.2, where \"P(S|X, Y ; \u03b8) reduces to P(S|Y ),\" does not hold true under the instance-dependent PLL setting. When considering that the generation process of candidate labels in conjunction with S is feature-dependent[1,2], the simplification presented in the article may not be universally applicable and may overlook specific nuances associated with instance-dependent partial label learning.\n\n   [1] Xu, N., Qiao, C., Geng, X., & Zhang, M. L. (2021). Instance-dependent partial label learning. Advances in Neural Information Processing Systems, 34, 27119-27130. \n\n   [2] Xu, N., Liu, B., Lv, J., Qiao, C., & Geng, X. (2023). Progressive purification for instance-dependent partial label learning. In International Conference on Machine Learning (pp. 38551-38565). PMLR.\n\n3. Some important baselines should be compared, such as [1] in PLL and [2,3] in NLL.\n\n   [1] Wu, Dong-Dong, et al. \"Revisiting consistency regularization for deep partial label learning.\" International Conference on Machine Learning. PMLR, 2022.\n\n   [2] Jiang, Lu, et al. \"Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels.\" International conference on machine learning. PMLR, 2018.\n\n   [3] Han, Bo, et al. \"Co-teaching: Robust training of deep neural networks with extremely noisy labels.\" Advances in neural information processing systems 31 (2018).\n\n4. The article lacks detailed exposition on the derivation process of the loss functions for the three imprecise annotations configurations stemming from equation 5, potentially leaving readers without a clear understanding of the underlying methodology.\n\n5. The article contains typographical errors in the last sentence of the 2-nd paragraph on page 6, \"However, our framework is much simpler and more concise as shown in **??**.\""
                },
                "questions": {
                    "value": "1. Could the authors provide a more comprehensive derivation of the loss functions for the three imprecise annotations configurations derived from equation 5 to ensure clarity and thorough understanding for the readers?\n\n2. Given that the method of using ground-truth labels or Bayes label distribution as latent variables coupled with variational inference in weakly supervised learning is highlighted in prior works, how does the presented framework distinguish itself or advance beyond these existing approaches in terms of innovation or application?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3986/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3986/Reviewer_yf7f",
                        "ICLR.cc/2024/Conference/Submission3986/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3986/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698823372343,
            "cdate": 1698823372343,
            "tmdate": 1700623206232,
            "mdate": 1700623206232,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1wdAKd270S",
                "forum": "2Y5Gseybzp",
                "replyto": "hPxZS2tqCN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3986/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3986/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer yf7f (1/2)"
                    },
                    "comment": {
                        "value": "Thanks for your valuable feedback. In fact, we found that most of the weakness mentioned here has already been discussed in the Appendix with detailed results. Here, we provide a more detailed explanation and point out the related sections in our Appendix.\n\n\n> 1. \"The article's innovation is limited, as the approach of considering ground-truth labels or Bayes label distribution as latent variables and using variational inference for approximation in weakly supervised learning is already a common method[1-2], which suggests that the presented techniques may not be as novel as claimed.\"\n\nThank you for mentioning these related works, and we have included them in our related work.\nIndeed, our contribution is certainly *not* to present the first interpretation of variational inference on the latent ground-truth labels, but to present the *first* complete EM view *without any approximation/assumption on the data*, thus it can handle different types of imprecise labels and even a mixture of them robustly.\nFor example, in [1], extra prior distribution is needed in the variational approximation and applies to only partial labels. \nIn [2], it also requires an encoder-decoder similar architecture to capture the distribution of the latent variable for noisy labels. \n\nBeyond the novelty in unifying existing settings on PLL, SSL, and NLL, our framework can be easily implemented in different settings and achieve SOTA results with faster convergence. We hope that our contributions can be understood and valued in this way.\n\n[1] Xu, N., Qiao, C., Geng, X., & Zhang, M. L. (2021). Instance-dependent partial label learning. Advances in Neural Information Processing Systems, 34, 27119-27130.\n\n[2] Yao, Y., Liu, T., Gong, M., Han, B., Niu, G., & Zhang, K. (2021). Instance-dependent label-noise learning under a structural causal model. Advances in Neural Information Processing Systems, 34, 4409-4420.\n\n\n> 2. \"The article's treatment in section 3.2, where \"P(S|X, Y ; \u03b8) reduces to P(S|Y ),...instance-dependent partial label learning.\"\n\nThanks for mentioning the instance-dependence situation. In fact, we think there is a little misunderstanding here. \nAs mentioned in the last paragraph of Section 3.1, $P(I|X, Y;\\theta)$ depends on the nature of imprecise information $I$. If $I$ is not instance-dependent, it can be largely ignored. If $I$ is instance-dependent, it should be maintained and optimized as a supervised term. \nIn fact, in Section 3.2, $P(I|X, Y;\\theta)$ is indeed maintained for noisy label learning and semi-supervised learning. \nIts performance is verified on instance-dependent noisy label learning as shown in Table 3 and Table 15.\nFor instance-dependent partial label learning as in [1, 2], it should be also maintained as $P(S|X, Y ; \\theta)$. \nHere we provide a comparison of our method to [1, 2] in the benchmark of instance-dependent partial label learning. \nWe follow the training recipe in [2] to train our methods and report the average accuracy of 3 runs.\n\n|        |   MNIST   | Kuzushiji-MNIST | Fashion-MNIST |  CIFAR-10 | CIFAR-100 |\n|:------:|:---------:|:---------------:|:-------------:|:---------:|:---------:|\n| VALEN [1]  |   99.03   |      90.15      |     96.31     |   92.01   |   71.48   |\n|   RCR [3] |   98.81   |      90.62      |     96.64     |   86.11   |   71.07   |\n|  PiCO  |   98.76   |      88.87      |     94.83     |   89.35   |   66.30   |\n|   POP [2]  | **99.28** |      91.09      |     96.93     |   93.00   |   71.82   |\n|  Ours  |   99.19   |    **91.35**    |   **97.01**   | **93.86** | **72.43** |\n\nThe discussions and results on instance-dependent partial label learning are included in the revised Appendix D. 3.2. \n\n[1] Xu, N., Qiao, C., Geng, X., & Zhang, M. L. (2021). Instance-dependent partial label learning. Advances in Neural Information Processing Systems, 34, 27119-27130.\n\n[2] Xu, N., Liu, B., Lv, J., Qiao, C., & Geng, X. (2023). Progressive purification for instance-dependent partial label learning. In International Conference on Machine Learning (pp. 38551-38565). PMLR.\n\n[3] Wu, D. et al. (2022). Revisiting Consistency Regularization for Deep Partial Label Learning, ICML."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699932366070,
                "cdate": 1699932366070,
                "tmdate": 1699932366070,
                "mdate": 1699932366070,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pKX7oMGugh",
                "forum": "2Y5Gseybzp",
                "replyto": "6eD3k3lRJ7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3986/Reviewer_yf7f"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3986/Reviewer_yf7f"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for your great efforts in addressing my questions. Your response has addressed most of my concerns with a substantial amount of experiments. I appreciate the use of a unified framework to tackle various weakly supervised learning settings in this paper. However, the approach of treating true labels as latent variables and employing variational inference for learning, in my opinion, still lacks significant innovation. Therefore, I decided to increase the score by one point."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700623152187,
                "cdate": 1700623152187,
                "tmdate": 1700623152187,
                "mdate": 1700623152187,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ySgv5MKdbF",
                "forum": "2Y5Gseybzp",
                "replyto": "hPxZS2tqCN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3986/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3986/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We deeply appreciate the increased rating. \nIn terms of the EM formulation, we totally agree that there exist previous methods treating the true labels as latent variables and even utilizing variational inference as ours. However, note that for our EM formulation, the significant difference and innovation lie in that we do not require any assumption on the probability, e.g. conditional independence between Y and I or X (with our NFA modeling), whereas previous methods usually do. \nThis flexibility allows our approach to generalize to many different settings and different types of data.\nWe hope we have made this point more clear.\nThanks again for your efforts in improving this work."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700624360432,
                "cdate": 1700624360432,
                "tmdate": 1700624545086,
                "mdate": 1700624545086,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Rc8hA9CAaS",
            "forum": "2Y5Gseybzp",
            "replyto": "2Y5Gseybzp",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3986/Reviewer_torK"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3986/Reviewer_torK"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a unified framework for handling various learning problems with imprecise label configurations. Previous studies have achieved success in dealing with imprecise configurations of individual labels, but their methods often have significant differences. These methods are tailored to specific forms of imprecise labels, but in practical applications, annotations can be very complex and may involve multiple coexisting imprecise label configurations. Therefore, applying previous methods to situations where both noisy labels and partial labels occur simultaneously can be challenging. To address this problem, the author presents a different perspective, considering the provided imprecise label information as information that imposes deterministic or statistical constraints on the actual applicable true labels. Then, the model is trained to maximize the probability of the given imprecise information. The author demonstrates the advanced performance of their method through comparative experiments on multiple datasets, showcasing the adaptability of the ILL framework in handling a mixture of various uncertain label configurations."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper proposes a unified framework called imprecise label learning (ILL) for handling various configurations of imprecise labels. Compared to previous methods, this framework does not require specific designs for each imprecise label configuration. Instead, it models the imprecise label information using Expectation Maximization (EM) and treats precise labels as latent variables. This unified framework can adapt to settings involving partial label learning, semi-supervised learning, noise label learning, and their combinations, demonstrating strong adaptability and flexibility.\n\n2. Through experiments, it has been demonstrated that ILL outperforms existing specific techniques in handling imprecise labels. It achieves robust and effective performance in various challenging settings, including partial label learning, semi-supervised learning, noise label learning, and their combinations. This indicates that the framework possesses excellent performance and wide applicability in handling imprecise labels.\n\n3. The work presented in this paper provides insights for further research in the field of imprecise label learning, unleashing the full potential of imprecise label learning in more complex and challenging scenarios where obtaining precise labels is difficult. This has significant implications for solving real-world problems with inaccurate labels."
                },
                "weaknesses": {
                    "value": "The author proposes a new framework for unified learning with imprecise labels, which can learn from any type of imprecise label. However, the experimental data in the current article are obtained from balanced and relatively small datasets, lacking sufficient experimental evaluation. At the same time, the article does not discuss the computational complexity or scalability of this framework. Although the article mentions the limitations of some previous methods in dealing with specific forms of imprecise labels, it does not provide a detailed discussion on the scalability of this framework in large-scale datasets or complex scenarios.\n\nMoreover, in terms of the presentation of the paper, the author's description of existing methods is not clear enough. The paper uses a large number of formulas and tables for description, lacking visual explanations. The comparison of the experimental results also appears vague and unclear."
                },
                "questions": {
                    "value": "The author proposed a unified framework based on imprecise label learning, demonstrated through experiments the good performance of the unified framework in three different imprecise label scenarios, and its superiority in mixed imprecise label learning tasks compared to current methods capable of handling mixed imprecise labels. The main significance of the unified framework lies in providing a portable and scalable method for addressing various imprecise label tasks, where the use of EM to uniformly model imprecise label information can be extended to multiple scenarios. However, challenges such as potential local optima and computational complexity in the EM method still need to be addressed.\n\nFurthermore, the author noted in the conclusion that experimental data were obtained from relatively small and balanced datasets and that designing different loss functions according to different scenarios was necessary when designing the model. This further limits the portability of this framework. In particular, the handling of probabilistic models for various imprecise label information has a significant impact on the effectiveness of the method, and we must reconsider model design solutions when dealing with different data and tasks."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3986/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698905045359,
            "cdate": 1698905045359,
            "tmdate": 1699636360226,
            "mdate": 1699636360226,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ccpPOj0skU",
                "forum": "2Y5Gseybzp",
                "replyto": "Rc8hA9CAaS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3986/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3986/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer torK (1/2)"
                    },
                    "comment": {
                        "value": "> 1. \"The experimental data in the current article are obtained from balanced and relatively small datasets, lacking sufficient experimental evaluation. At the same time, the article does not discuss the computational complexity or scalability of this framework. Although the article mentions the limitations of some previous methods in dealing with specific forms of imprecise labels, it does not provide a detailed discussion on the scalability of this framework in large-scale datasets or complex scenarios.\"\n\nThank you for your valuable feedback. \n\nWe compare our method with previous baselines on the **standard** benchmarks of each setting, which are commonly used in prior works.\nIn NLL, Clothing1M and Webvision are indeed large-scale datasets with realistic instance-dependent noise. \nAdditionally, to resolve your concern in large-scale datasets, we also provide the ImageNet results of our method for semi-supervised learning which we did not include in our main paper before:\n\n| # Labels  | 100k  | 400k  |\n|-----------|-------|-------|\n| FixMatch  | 43.66 | 32.28 |\n| FlexMatch | 41.85 | 31.31 |\n| FreeMatch | 40.57 | -     |\n| SoftMatch | 40.52 | 29.49 |\n| Ours      | 39.41 | 28.03 |\n\n\nAs for imbalanced and open-set settings which are *beyond* the scope of our research purpose to unify SSL, PLL, and NLL, we would like to point out that applying our framework to these settings is *as challenging as* applying existing previous ones because learning on various restricted $X$ is a different problem of learning on various imprecise $Y$.\nThe study of transferring to restricted data distribution requires an additional large amount of work and is out of the scope of our current study, where our main focus is the unification of learning with different imprecise labels, instead of different data. \nThese two settings have been known to be challenging in the ML community for years, and they could perhaps not be solved in one framework. We intend to look after them in the future work.\n\nRegarding the computation complexity, since our method is quite simple and the loss function is derived as closed-form, our algorithm is usually *faster* than the baselines. We provide a run time analysis to verify it here:\n\n| Setting | Algorithm | CIFAR-100 Avg. Runtime (s/iter) |\n|:-------:|:---------:|:-------------------------------:|\n|   SSL   | FreeMatch |              0.2157             |\n|   SSL   |    Ours   |              **0.1146**             |\n|   PLL   |    PiCO   |              0.3249             |\n|   PLL   |    Ours   |              **0.2919**             |\n|   NLL   |    SOP    |              0.1176             |\n|   NLL   |    Ours    |              **0.1021**             |\n\nNote that the runtime is averaged over all training iterations; thus, the performance gap is significant. We have included the runtime analysis in the revised Appendix D.8.\n\n\n> 2. \"Moreover, in terms of the presentation of the paper, the author's description of existing methods is not clear enough. The paper uses a large number of formulas and tables for description, lacking visual explanations. The comparison of the experimental results also appears vague and unclear.\"\n\n\nWe appreciate your feedback on the presentation of our paper. \nWe recognize the importance of clear description, especially for the existing complicated methods. \nPlease understand that this is mainly because we intend to provide a comprehensive evaluation across many different settings to show our method could cover various imprecise labels.\nTo improve the clearness of the experimental results, we have included an overview visual comparison with a bar plot to demonstrate the significance of our method in revised Appendix D. 2.\nThe results are computed as the average accuracy of different settings for each dataset. \nIt is demonstrated that the proposed method, in general, achieves better performance compared to recent SOTA baselines or achieves performance comparable to them."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699932115787,
                "cdate": 1699932115787,
                "tmdate": 1699932115787,
                "mdate": 1699932115787,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mYZKy6Rjq9",
                "forum": "2Y5Gseybzp",
                "replyto": "Rc8hA9CAaS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3986/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3986/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Followup Response to Reviewer torK"
                    },
                    "comment": {
                        "value": "Thank you again for your insightful suggestions regarding the improvement and expansion of our work.\n\nIn our previous response, we hope we address your concerns regarding large-scale experiments and the analysis of time complexity. \nAs for the discussion on the potential for local optima in the EM algorithm, we did not encounter any convergence issues across the various settings we examined in our study. \nHowever, we acknowledge the importance of this aspect and agree that incorporating regularization and conducting a theoretical analysis on this topic would be valuable for future work.\nFurthermore, exploring the extension of our methodology to imbalanced or other specific data distributions presents intriguing directions for future research.\n\nWe are open to further discussions and would be more than willing to address any additional questions or clarifications you might have.\nYour continued feedback is greatly appreciated, and we look forward to any further insights from you."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700534458330,
                "cdate": 1700534458330,
                "tmdate": 1700534714315,
                "mdate": 1700534714315,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qmxgUVZrPe",
            "forum": "2Y5Gseybzp",
            "replyto": "2Y5Gseybzp",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3986/Reviewer_AiQR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3986/Reviewer_AiQR"
            ],
            "content": {
                "summary": {
                    "value": "The author proposes a new general framework for learning with imperfect labeling information in the multi-class classification setting, called the Imprecise Label Learning (ILL) framework. The framework works in an expectation-maximization fashion and assumes that imperfect label information I is provided among instance X, while the Y is a latent variable. The author shows how to adopt a general form of ILL framework to different previously considered settings with imperfect information: Partial label learning (PLL), Semi-supervised learning (SSL), Noisy label learning (NLL), and mixed configuration (in the appendix) and compare them against many popular baselines that focus on specific configurations on many configurations of artificial benchmarks created using CIFAR-10/100 and additional datasets (and even more experiments with different settings is provided in the appendix). The proposed framework achieves strong results, often beating all the baselines in the comparison."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper has strong motivation, creating a unified framework for imprecise labels in multi-class classification that can handle different settings of imperfect label information.\n2. The general framework is nicely rooted in EM.\n3. The proposed framework achieves strong results in empirical comparison. \n4. The empirical comparison includes many different settings, and for each setting, the proposed method is compared with a large number of SOTA baselines."
                },
                "weaknesses": {
                    "value": "1. The work gives a general framework outline in the main paper and focuses on the loss functions used for different settings (PPL, SSL, NLL),\nBut I'm missing the important pieces to get a full picture of the proposed approach, it seems to me more like the outline than a concrete solution that can be implemented in different ways (what authors mention In the paper). Unfortunately, the main paper is very sparse in details about the actual implementation of many of its elements.\n\n2. More details can be found in Appendix C and D. It is unclear to me when NFA from Appendix C.3 is used in the main paper or not. In Appendix D, all modifications to the training are mentioned without explanation and motivation.\n\n3. NIT: Broken reference\n\n   > However, our framework is much simpler and more concise as shown in ??"
                },
                "questions": {
                    "value": "In some experiments, the fully supervised model (with correct label information) gets worse results than the ILL framework. Actually, ILL beats the fully supervised model by a lot. At the same time, other solutions never do that, so the natural question is if there are any other differences between the supervised model and ILL, then application of EM/different loss? What is the authors' hypothesis as to why it achieves better performance?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3986/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699581839333,
            "cdate": 1699581839333,
            "tmdate": 1699636360149,
            "mdate": 1699636360149,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xmLnRDooYY",
                "forum": "2Y5Gseybzp",
                "replyto": "qmxgUVZrPe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3986/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3986/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer AiQR (1/2)"
                    },
                    "comment": {
                        "value": "We appreciate your valuable feedback and we are sorry for the confusion caused for you. We hope our response in the following could make our method more clear.\n\n> 1. \"The work ... it seems to me more like the outline than a concrete solution that can be implemented in different ways (what authors mention In the paper).\"\n\nSorry for the confusion caused. Our work is certainly not just an outline, but with novel design and concrete solutions to achieve promising results. We intend to demonstrate the universality and generality of the proposed method so we have to include many different settings into the paper, which might overlook some details of our proposed framework. \nHere, we highlight our contributions more clearly:\n - At a conceptual level, we proposed a unified EM framework that accommodates *any* imprecise labels by taking the imprecise information $I$ abstractly. We demonstrated its effectiveness on various settings, including PLL, SSL, NLL, and the mixture of them.\n - At a solution level, thanks to the unified formulation (Eq. 5), our derived formulations and algorithms in each setting are clearly different from previous baselines. Indeed, it can be implemented in different ways when handling different types of $I$, but in general they all share the same EM formulation by replacing the $I$ with actual imprecise labels.  \n - Compared with existing baselines: previous baselines in each individual setting can be treated as (usually) simplified versions of our framework. This is probably why our method looks like an outline of previous methods while it is certainly not. On different benchmarks of each setting, our unified framework presents promising results. More importantly, without changing the framework, our method can handle more complicated scenarios robustly, where previous specifically designed methods fall short in performance, as shown in Table 4. \n - Extend to broader scenarios: our framework can naturally extend to more imprecise configurations except for the settings discussed in our main paper. This is mainly achieved by the NFA modeling of imprecise label $I$, where NFA can represent each form of imprecise label setting and the proposed EM framework can be conducted on the trellis of NFA with linear time complexity. We omit the NFA details in main paper because the studied settings have rather simple NFA and thus their formulations can be derived in closed-form.\n\n> 2. \"Unfortunately, the main paper is very sparse in details about the actual implementation of many of its elements.\"\n\nThank you for your feedback. We are sorry if we missed any details in the main paper as we have to move a significant amount of details to the appendix due to space limit.\nPlease understand that our intention was to present the framework in a manner that highlights its adaptability and generalizability across different settings.\n\nIn the revised version of the paper, we have included more concrete and detailed derivations of how the framework can be applied in various scenarios in Appendix C, thereby providing a more comprehensive understanding of its practical implementation.\nThe source is also included in our submission for reproducibility.\nHope the above revision can provide more details of the proposed framework and its application to each setting. \n\n> 3. \"More details can be found in Appendix C and D. It is unclear to me when NFA from Appendix C.3 is used in the main paper or not.\"\n\nThanks for pointing out the NFA.\nOur idea of NFA is that any imprecise label information $I$ can be represented as NFA, and the trellis expanded from the NFA can be used to compute the expectation over \n$P(Y|I, X;\\theta^t)$ in EM formulation, as shown in Appendix C.1 and C.2.\nThe NFA representation of $I$ in general can be reflected as all possible labelings imposed by $I$, where we can conduct the EM on it. \nThe benefit of designing the NFA representation is to demonstrate the adaptability of the proposed method because we can represent any type of imprecise label as an NFA and thus accommodate into our proposed framework. \n\nIn the settings studied in this paper, the NFA representation of PLL would be the candidate labels as transition paths and each sample as states. The NFA of NLL and SSL would just be all labels as transition paths and each sample as states, since the imprecise label information $I$ here does not constrain any labeling. \nSince the settings studied in this paper have relatively simple NFA representations, we can directly derive the closed-form formulation of $P(Y|I, X;\\theta^t)$ from Equation 5 as we did in the main paper. \nIt can be easily extended to other settings such as multiple instance learning, learning with count/proportion, etc, by constructing a more complex NFA of each case, and actually using a forward-backward algorithm on it to compute EM. \n\nWe have explicitly included the above discussion in the NFA section in Appendix C. 6 and hope it can make the NFA interpretation more clear."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699931873432,
                "cdate": 1699931873432,
                "tmdate": 1699931873432,
                "mdate": 1699931873432,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jUE9mGUoME",
                "forum": "2Y5Gseybzp",
                "replyto": "qmxgUVZrPe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3986/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3986/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer  AiQR (2/2)"
                    },
                    "comment": {
                        "value": "> 4. \"In Appendix D, all modifications to the training are mentioned without explanation and motivation.\"\n\nWe are sorry for this confusion. Again, please understand that this is mainly due to the space limit. We would like to provide more explanation and discussion here.\n\nIn fact, the two techniques we mentioned in Appendix D.1 are common techniques in each setting. \nFor example, in SSL, strong-weak augmentation is an important strategy for SSL algorithms widely used in existing works such as FixMatch and FlexMatch [1,2].\nThus, it is important to adopt strong-weak augmentation to achieve better performance in SSL.\nThis is similar in PLL settings (PiCO [3] also used strong augmentation).\nStrong-weak augmentation and entropy loss are also adopted in SOP [4] of NLL. However, we found these techniques are less important for our formulation of NLL. \nWe provide a brief ablation study on the entropy loss of SSL, and both techniques for NLL and PLL here to demonstrate our discussions above.\n\n|           SSL           | CIFAR-100, 200 labels | STL 10, 40 labels |\n|:-----------------------:|:---------------------:|:-----------------:|\n|           Ours          |         22.06         |       11.09       |\n| Ours (w/o entropy loss) |         22.41         |       11.23       |\n\nFrom the ablation on entropy loss of SSL, it shows that entropy loss only affects the performance trivially.\n\n|           PLL           | CIFAR-10, partial ratio 0.5 | CIFAR-100, partial ratio 0.1 |\n|:-----------------------:|:---------------------:|:-----------------:|\n|           PiCO          |         93.58         |       69.91       |\n|           Ours          |         95.91         |       74.00       |\n|           PiCO (w/o strong aug)         |     91.78            |   66.43           |\n| Ours (w/o strong aug) |            94.53            |            72.69         |\n| Ours (w/o entropy loss) |            95.87           |       73.75            |\n\nFrom the ablation on entropy loss and strong augmentation of PLL, we can observe that strong augmentation is important for both PiCO and our method to achieve better performance. Entropy loss has minimal effect on our method.\n\n|           NLL           | CIAFR 10, noise ratio  0.8 | CIFAR 100, noise ratio 0.8 |\n|:-----------------------:|:--------------------------:|:--------------------------:|\n|           SOP           |        94.00                    |           63.30                |\n|           Ours          |        94.31                    |              66.46               |\n|   SOP (w/o strong aug)  |        66.85                   |                  36.60          |\n|  Ours (w/o strong aug)  |        93.56                    |                65.89            |\n|  SOP (w/o entropy loss) |        93.04                    |                62.85            |\n| Ours (w/o entropy loss) |        94.16                    |                66.12           |\n\nFrom the ablation on NLL, it is shown that the performance SOP is subjected more to the entropy loss especially for strong augmentation. Removing these techniques has a less detrimental effect on the performance of our method.\n\nWe have included the above ablation study in Appendix D. 7. \n\n\n[1] Kihyuk Sohn et al. FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence\n\n[2] Yidong Wang et al. FlexMatch: Boosting Semi-Supervised Learning with Curriculum Pseudo Labeling.\n\n[3] Haobo Wang et al. PiCO: Contrastive Label Disambiguation for Robust Partial Label Learning.\n\n[4] Liu Sheng et al. Robust Training under Label Noise by Sparse Over-parameterization.\n\n\n\n> 5. \"NIT: Broken reference\"\n\nWe apologize for the oversight regarding the broken reference and appreciate your attention to this detail. We have carefully reviewed and corrected all references in the revised version of the paper to ensure they are complete and accurate.\n\n\n> 6. \"In some experiments, the fully supervised model...why it achieves better performance?\"\n\nWe appreciate your observation regarding the performance of the ILL framework compared to fully supervised models in Table 1 of PLL.\nOur hypothesis is that the EM consistency term of ILL may lead to better generalization and robustness. \nSimilar observations can be also found in SSL works such as in SoftMatch [1].\n\n[1] Hao Chen, et al. SoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning.\n\nIf you think our response resolved your concerns and questions, please consider increasing the rating."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699931972241,
                "cdate": 1699931972241,
                "tmdate": 1699932492698,
                "mdate": 1699932492698,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2yYX7dEoeb",
                "forum": "2Y5Gseybzp",
                "replyto": "CdikWuVuWY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3986/Reviewer_AiQR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3986/Reviewer_AiQR"
                ],
                "content": {
                    "title": {
                        "value": "Re: Response to Reviewer"
                    },
                    "comment": {
                        "value": "I thank the authors for the exhaustive response and apologize for joining the discussion so late, but there is a lot to process in terms of other reviewers' comments and authors' responses to their reviews, which I've read carefully. Below I include some additional comments:\n\n**Presentation:**\nWhile the new additions to the manuscript are welcome and improve the paper's readability, and their comments made the paper clearer for me, I believe the problem with the confusing presentation of the paper remains, and the authors did not sufficiently address it. What I believe is needed is a clear outline of what and how it is calculated for each derived setting (PLL, NLL, SSL) and, in general cases, for example, presented in the form of pseudocode. While the authors include the source code, which is nicely structured and formatted, I believe the paper itself should give a clear explanation of the procedure that was implemented.\n\n**Novelty:**\nI cannot evaluate the novelty of the approach in comparison to the previous works, as I do not know some of them. \n\n**Empirical evaluation:**\nI believe the evaluation based mostly on artificial datasets created based on CIFAR-10/100 is enough for this work. I believe it would be interesting to see how closed forms for PLL, NLL, SSL compare to the general approach using NFA.\n\n---\n\nFor the moment, I'm keeping my score as it is."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740286265,
                "cdate": 1700740286265,
                "tmdate": 1700740286265,
                "mdate": 1700740286265,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]