[
    {
        "title": "StructComp: Substituting propagation with Structural Compression in Training Graph Contrastive Learning"
    },
    {
        "review": {
            "id": "duQIbs6gkc",
            "forum": "a4DBEeGfQq",
            "replyto": "a4DBEeGfQq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5510/Reviewer_kF3D"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5510/Reviewer_kF3D"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies improving efficiency of graph contrastive learning. The authors propose a structural compression framework, StructComp, that adopts a low-rank approximation of the diffusion matrix to obtain compressed node embeddings. They show that the original GCL loss can be approximated with the contrastive loss computed by StructComp, with an additional benefit of the robustness. Experiments on seven benchmark datasets show that StructComp greatly reduces the time and memory consumption while improving model performance compared to the vanilla GCL models and scalable training methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "(+) The proposed structural compression idea is new and interesting;\n\n(+) The presentation and organization are clear and easy to follow;"
                },
                "weaknesses": {
                    "value": "(-) The applicability of StructComp seems to be limited;\n\n(-) Several claims have not been verified;\n\n(-) Some related works have not been compared or discussed;"
                },
                "questions": {
                    "value": "1. The applicability of StructComp seems to be limited:\n\n- Theoretically, StructComp has to rely on the approximation of the diffusion matrix for a specific graph and GNN model, as demonstrated in Theorem 4.1. How well StructComp can approximate to more complicated graphs such as heterophilous graphs, and more complicated while commonly used GNNs such as GraphSage, GIN, GAT, or even more interesting variants such as PNA?\n\n- Empirically, what is the exact setting of StructComp for node classification? Can StructComp be applied to both transductive and inductive node classification?\n\n- How well can StructComp approximate different augmentations in GCL?\n\n2. Several claims have not been verified:\n\n- The paper claims that StructComp can work for large scale graphs, while the benchmarked datasets are rather small or medium scale. Although it\u2019s claimed that ogbn-products and arxiv are large datasets, while they are indeed medium scale datasets according to OGB (https://ogb.stanford.edu/docs/nodeprop/). To support the claim, it\u2019s expected to evaluate StructComp in large datasets such as papers100M, reddit, or OGBG-LSC datasets.\n\n- The paper also claims that StructComp has better robustness and stability with the additional regularization, while no evidence\u2019s been found.\n\n3. Some related works have not been compared or discussed:\n\n-  Some GCL works have not been discussed in the paper, for example, [1,2,3].\n\n- Why not comparing efficient GCL baselines such as CCA-SSG, and GGD discussed in the paper?\n\n4. How the time and memory cost are computed? Do they count in the preprocessing steps?\n\n\n**References**\n\n[1] Calibrating and Improving Graph Contrastive Learning, TMLR\u201923.\n\n[2] Single-Pass Contrastive Learning Can Work for Both Homophilic and Heterophilic Graph, TMLR\u201923.\n\n[3] Scaling Up, Scaling Deep: Blockwise Graph Contrastive Learning, arXiv\u201923.\n\n[4] Structure-free Graph Condensation: From Large-scale Graphs to Condensed Graph-free Data, arXiv\u201923."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5510/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5510/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5510/Reviewer_kF3D"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5510/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698642089750,
            "cdate": 1698642089750,
            "tmdate": 1700561852415,
            "mdate": 1700561852415,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TDsJ0HXNJv",
                "forum": "a4DBEeGfQq",
                "replyto": "duQIbs6gkc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer kF3D[1/4]"
                    },
                    "comment": {
                        "value": "Thank you for your detailed review. We would like to address your questions/concerns below:\n\n**Q1:Theoretically, StructComp has to rely on the approximation of the diffusion matrix for a specific graph and GNN model, as demonstrated in Theorem 4.1. How well StructComp can approximate to more complicated graphs such as heterophilous graphs, and more complicated while commonly used GNNs such as GraphSage, GIN, GAT, or even more interesting variants such as PNA?**\n\n\n\nIn order to verify the approximation quality to the diffusion matrix of StructComp, we test the performance on a deep GNN architecture called SSGC [1]. We transferred the trained parameters of StructComp to the SSGC encoder for inference. For full graph training in GCL, both the training and inference stages were performed using the SSGC encoder. Table 1 shows our experimental results, indicating that even with a deeper and more complicated encoder, StructComp still achieved outstanding performance.\n\n\n\nTable 1: The results of GCLs with SSGC encoders over 50 random splits.\n\n| Method                        | Cora         | Citeseer     | Pubmed       |\n| ----------------------------- | ------------ | ------------ | ------------ |\n| SCE                           | 81.8$\\pm$0.9 | 72.0$\\pm$0.9 | 78.4$\\pm$2.8 |\n| SCE$_{\\text{StructComp}}$     | 82.0$\\pm$0.8 | 71.7$\\pm$0.9 | 77.8$\\pm$2.9 |\n| COLES                         | 81.8$\\pm$0.9 | 71.3$\\pm$1.1 | 74.8$\\pm$3.4 |\n| COLES$_{\\text{StructComp}}$   | 82.0$\\pm$0.8 | 71.6$\\pm$1.0 | 75.6$\\pm$3.0 |\n| GRACE                         | 80.2$\\pm$0.8 | 70.7$\\pm$1.0 | 77.3$\\pm$2.7 |\n| GRACE$_{\\text{StructComp}}$   | 81.1$\\pm$0.8 | 71.0$\\pm$1.0 | 78.2$\\pm$1.3 |\n| CCA-SSG                       | 82.1$\\pm$0.9 | 71.9$\\pm$0.9 | 78.2$\\pm$2.8 |\n| CCA-SSG$_{\\text{StructComp}}$ | 82.6$\\pm$0.7 | 71.7$\\pm$0.9 | 79.4$\\pm$2.6 |\n\n\n\nTo the best of our knowledge, current mainstream GCL models, whether single-view models such as SCE, COLES, GLEN [2], or multi-view models such as DGI, GRACE, CCA-SSG, GGD, and their variants, all use SGC or GCN encoders. These unsupervised GCL models can achieve performance surpassing supervised GNNs (such as GAT, SAGE) with simple encoders on many datasets. Few GCL models have focused on whether using different encoders can achieve better performance. Moreover, GCL training is more complicated than supervised GNNs, so introducing complex encoders may make the models more difficult to train. Considering this, we did not extensively explore how using other encoders would affect StructComp. We believe this is a good question, and we will investigate it further in future work.\n\nOn the other hand, we have not implemented StructComp on heterophilous graphs , as the chosen basic GCL methods - SCE, COLES, GRACE, and CCA-SSG - are not suitable for heterophilous graph. In our future work, we will explore applying StructComp to more complex graph data structures.\n\n\n\n**Q2:Empirically, what is the exact setting of StructComp for node classification? Can StructComp be applied to both transductive and inductive node classification?**\n\nOur StructComp can also be used to handle inductive node classification tasks. We provide additional experiments on inductive node classification in Table 2. Clearly, the GCL models trained with StructComp also perform exceptionally well on inductive node classification tasks.\n\nTable 2: The results on two inductive datasets. OOM means Out of Memory on GPU.\n\n| Method                        | Flickr Acc | Flickr Time | Flickr Mem | Reddit Acc | Reddit Time | Reddit Mem |\n| ----------------------------- | ---------- | ----------- | ---------- | ---------- | ----------- | ---------- |\n| SCE                           | 50.6       | 0.55        | 8427       | -          | -           | OOM        |\n| SCE$_{\\text{StructComp}}$     | 51.6       | 0.003       | 43         | 94.4       | 0.017       | 1068       |\n| COLES                         | 50.3       | 0.83        | 9270       | -          | -           | OOM        |\n| COLES$_{\\text{StructComp}}$   | 50.7       | 0.003       | 48         | 94.2       | 0.024       | 1175       |\n| GRACE                         | -          | -           | OOM        | -          | -           | OOM        |\n| GRACE$_{\\text{StructComp}}$   | 51.5       | 0.010       | 221        | 94.3       | 0.079       | 8683       |\n| CCA-SSG                       | 51.6       | 0.125       | 1672       | 94.9       | 0.21        | 5157       |\n| CCA-SSG$_{\\text{StructComp}}$ | 51.8       | 0.007       | 99         | 95.2       | 0.56        | 457        |"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700150111599,
                "cdate": 1700150111599,
                "tmdate": 1700298821125,
                "mdate": 1700298821125,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wYj8D6mZTQ",
                "forum": "a4DBEeGfQq",
                "replyto": "duQIbs6gkc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer kF3D[2/4]"
                    },
                    "comment": {
                        "value": "**Q3: How well can StructComp approximate different augmentations in GCL?**\n\nFor multi-view GCLs, we designed a new data augmentation method, Dropmember, for our StructComp. It is important to note that Dropmember is not designed to approximate other graph data augmentation methods, but rather because previous graph data augmentation methods cannot be used under the StructComp framework. According to the analysis in DropMessage [3], common graph data augmentations can be unified under a single framework, and we have proved that our Dropmember falls within this framework as well.\n\n**Q4:The paper claims that StructComp can work for large scale graphs, while the benchmarked datasets are rather small or medium scale. Although it\u2019s claimed that ogbn-products and arxiv are large datasets, while they are indeed medium scale datasets according to OGB. To support the claim, it\u2019s expected to evaluate StructComp in large datasets such as papers100M, reddit, or OGBG-LSC datasets.**\n\nWe have conducted extra experiments on the ogbn-papers100M dataset according to your suggestion. We use StructComp to train four representative GCL models. Here, we compressed ogbn-papers100M into a feature matrix $X_c \\in R^{5000*128}$ and trained GCL using StructComp. The table also presents the results of GGD trained with ClusterGCN. Although GGD is specifically designed for training large graphs, when dealing with datasets of the scale of ogbn-papers100M, it still requires graph sampling to construct subgraphs and train GGD on a large number of subgraphs. In contrast, our StructComp only requires training a simple and small-scale MLP, resulting in significantly lower resource consumption compared to GGD+ClusterGCN.\n\n\n\nTable 3: The accuracy, training time per epoch and memory usage on the Ogbn-papers100M dataset.\n\n| Method                        | Acc          | Time  | Mem   |\n| ----------------------------- | ------------ | ----- | ----- |\n| GGD                           | 63.5$\\pm$0.5 | 1.6h  | 4.3GB |\n| SCE$_{\\text{StructComp}}$     | 63.6$\\pm$0.4 | 0.18s | 0.1GB |\n| COLES$_{\\text{StructComp}}$   | 63.6$\\pm$0.4 | 0.16s | 0.3GB |\n| GRACE$_{\\text{StructComp}}$   | 64.0$\\pm$0.3 | 0.44s | 0.9GB |\n| CCA-SSG$_{\\text{StructComp}}$ | 63.5$\\pm$0.2 | 0.18s | 0.1GB |\n\n\n\n**Q5:The paper also claims that StructComp has better robustness and stability with the additional regularization, while no evidence\u2019s been found.**\n\nWe have conducted extra experiments to study the robustness of StructComp. We randomly add 10\\% of noisy edges into three datasets and perform the node classification task. On the original dataset, the models trained with StructComp showed performance improvements of **0.36**, **0.40**, **1.30** and **1.87**, respectively, compared to the models trained with full graphs. With noisy perturbation, the models trained with StructComp showed performance improvements of **0.80**, **1.27**, **2.47**, and **1.87**, respectively, compared to full graph training. This indicates that GCL models trained with StructComp exhibit better robustness.\n\n\n\nTable 4: The results over 50 random splits  on the perturbed datasets.\n\n| Method                        | Cora         | CiteSeer     | PubMed       |\n| ----------------------------- | ------------ | ------------ | ------------ |\n| SCE                           | 78.8$\\pm$1.2 | 69.7$\\pm$1.0 | 73.4$\\pm$2.2 |\n| SCE$_{\\text{StructComp}}$     | 79.3$\\pm$0.9 | 69.3$\\pm$0.9 | 75.7$\\pm$2.8 |\n| COLES                         | 78.7$\\pm$1.2 | 68.0$\\pm$1.0 | 66.5$\\pm$1.8 |\n| COLES$_{\\text{StructComp}}$   | 79.0$\\pm$1.0 | 68.3$\\pm$0.9 | 69.7$\\pm$2.6 |\n| GRACE                         | 77.6$\\pm$1.1 | 64.1$\\pm$1.4 | 64.5$\\pm$1.7 |\n| GRACE$_{\\text{StructComp}}$   | 78.3$\\pm$0.8 | 69.1$\\pm$0.9 | 66.2$\\pm$2.4 |\n| CCA-SSG                       | 75.5$\\pm$1.3 | 69.1$\\pm$1.2 | 73.5$\\pm$2.2 |\n| CCA-SSG$_{\\text{StructComp}}$ | 78.2$\\pm$0.7 | 69.2$\\pm$0.8 | 76.3$\\pm$2.5 |"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700150179235,
                "cdate": 1700150179235,
                "tmdate": 1700308237992,
                "mdate": 1700308237992,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "C4SGfaIU2w",
                "forum": "a4DBEeGfQq",
                "replyto": "duQIbs6gkc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer kF3D[3/4]"
                    },
                    "comment": {
                        "value": "**Q6:Some GCL works have not been discussed in the paper, for example, [1,2,3].**\n\nIt should be noted that the goal of these studies and our work are different. The aim of SPGCL is to handle homophilic graphs and heterophilic graphs simultaneously. BlockGCL attempts to explore the application of deep GNN encoder in the GCL field. Contrast-Reg is a novel regularization method which is motivated by the analysis of expected calibration error. On the other hand, StructComp is a framework designed to scale up the training of GCL models: it aims to efficiently train common GCL models without performance drop. It is not a new GCL model that aims to achieve  SOTA performance compared to existing GCL models. So our work is orthogonal to these three previous works. In fact, StructComp can be used as the training method for SP-GCL, BlockGCL and Contrast-Reg. In future work, we will further investigate how to train these recent graph contrastive learning methods using StructComp.\n\n\n\nIn terms of scalability, which is the main goal of our work, we have conducted extra experiments to compare SP-GCL, BlockGCL, Contrast-Reg and StructComp-trained baseline. The results confirm that the aforementioned three GCL models are not designed for reducing training costs. \n\n\n\nTable 5: The results of StructComp-trained GCLs and some GCL baselines over 50 random splits. For SP-GCL, we are unable to get the classification accuracy on CiteSeer since it does not take isolated nodes as input.\n\n| Method                                                       | Cora Acc     | Cora Time | Cora Mem | CiteSeer Acc | CiteSeer Time | CiteSeer Mem | PubMed Acc   | PubMed Time | PubMed Mem |\n| ------------------------------------------------------------ | ------------ | --------- | -------- | ------------ | ------------- | ------------ | ------------ | ----------- | ---------- |\n| BlockGCL                                                     | 78.1$\\pm$2.0 | 0.026     | 180      | 64.5$\\pm$2.0 | 0.023         | 329          | 74.7$\\pm$3.1 | 0.037       | 986        |\n| SP-GCL                                                       | 81.4$\\pm$1.2 | 0.016     | 247      | -            | 0.021         | 319          | 74.8$\\pm$3.2 | 0.041       | 1420       |\n| Contrast-Reg                                                 | 79.2$\\pm$1.3 | 0.048     | 355      | 69.8$\\pm$1.6 | 0.097         | 602          | 72.4$\\pm$3.5 | 0.334       | 11655      |\n| SCE$_{\\text{StructComp}}$                                    | 81.6$\\pm$0.9 | 0.002     | 23       | 71.5$\\pm$1.0 | 0.002         | 59           | 77.2$\\pm$2.9 | 0.003       | 54         |\n| COLES$_{\\text{StructComp}}$                                  | 81.8$\\pm$0.8 | 0.002     | 24       | 71.6$\\pm$0.9 | 0.003         | 60           | 75.3$\\pm$3.1 | 0.003       | 61         |\n| GRACE$_{\\text{StructComp}}$                                  | 79.7$\\pm$0.9 | 0.009     | 37       | 70.5$\\pm$1.0 | 0.009         | 72           | 77.2$\\pm$1.4 | 0.009       | 194        |\n| CCA-SSG$_{\\text{StructComp}}$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; | 82.3$\\pm$0.8 | 0.006     | 38       | 71.6$\\pm$0.9 | 0.005         | 71           | 78.3$\\pm$2.5 | 0.006       | 85         |"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700150254065,
                "cdate": 1700150254065,
                "tmdate": 1700402546137,
                "mdate": 1700402546137,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2MWW53Hf1K",
                "forum": "a4DBEeGfQq",
                "replyto": "duQIbs6gkc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer kF3D[4/4]"
                    },
                    "comment": {
                        "value": "**Q7:Why not comparing efficient GCL baselines such as CCA-SSG, and GGD discussed in the paper?**\n\n*We have compared the performance of CCA-SSG with CCA-SSG trained using StructComp in the experimental section of the original submission. The specific results can be found in table 1 and table 2 of section 6.* Clearly, the performance of CCA-SSG trained with StructComp far surpasses the original CCA-SSG. Moreover, we add a comparison between StructComp and GGD in the new submission, the specific results are shown in the table below. The performance and resource consumption of various GCL models trained with StructComp are superior to GGD.\n\nTable 6: The results of StructComp-trained GCLs and GGD.\n\n| Method                        | Cora Acc     | Cora Time | Cora Mem | CiteSeer Acc | CiteSeer Time | CiteSeer Mem | PubMed Acc   | PubMed Time | PubMed Mem |\n| ----------------------------- | ------------ | --------- | -------- | ------------ | ------------- | ------------ | ------------ | ----------- | ---------- |\n| GGD                           | 79.9$\\pm$1.7 | 0.013     | 118      | 71.3$\\pm$0.7 | 0.018         | 281          | 74.0$\\pm$2.4 | 0.015       | 311        |\n| SCE$_{\\text{StructComp}}$     | 81.6$\\pm$0.9 | 0.002     | 23       | 71.5$\\pm$1.0 | 0.002         | 59           | 77.2$\\pm$2.9 | 0.003       | 54         |\n| COLES$_{\\text{StructComp}}$   | 81.8$\\pm$0.8 | 0.002     | 24       | 71.6$\\pm$0.9 | 0.003         | 60           | 75.3$\\pm$3.1 | 0.003       | 61         |\n| GRACE$_{\\text{StructComp}}$   | 79.7$\\pm$0.9 | 0.009     | 37       | 70.5$\\pm$1.0 | 0.009         | 72           | 77.2$\\pm$1.4 | 0.009       | 194        |\n| CCA-SSG$_{\\text{StructComp}}$ | 82.3$\\pm$0.8 | 0.006     | 38       | 71.6$\\pm$0.9 | 0.005         | 71           | 78.3$\\pm$2.5 | 0.006       | 85         |\n\n\n\n**Q8:How the time and memory cost are computed? Do they count in the preprocessing steps?**\n\nWe compute the time and memory cost in the same way as previous work on scalable GNNs: the time is the training time per epoch and memory is the peak GPU memory cost during training. The preprocessing time for our StructComp is strictly less than common scalable methods (e.g., ClusterGCN, GraphSaint and GraphAutoScale), since it only performs METIS once (like ClusterGCN) and does not need to do random sampling in each epoch. METIS is highly scalable and even papers100M (with 100M nodes) can be processed within an hour on a commercial CPU. Thus for big graphs, the prepocessing time is dominated by the training time, and more importantly, it only needs to be done once and the partition result can be shared by all experiments.\n\n------------------------------------------------------\n\nThe discussion of all the aforementioned issues will be added into the revised version of our paper. We appreciate your insightful feedback once again.\n\n[1]H. Zhu, and P. Koniusz. Simple spectral graph convolution. ICLR 2020.\n\n[2]H. Zhu, and P. Koniusz. Generalized Laplacian Eigenmaps. Neurips 2022.\n\n[3]Fang, T., Xiao, Z., Wang, C., Xu, J., Yang, X., and Yang, Y. Dropmessage: Unifying random dropping for graph neural networks. AAAI 2023."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700150342952,
                "cdate": 1700150342952,
                "tmdate": 1700150677860,
                "mdate": 1700150677860,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Mkode2ozM0",
                "forum": "a4DBEeGfQq",
                "replyto": "duQIbs6gkc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A friendly reminder for discussion and we appreciate your input"
                    },
                    "comment": {
                        "value": "Dear Reviewer kF3D,\n\nWe thank you again for your insightful and constructive review. We have worked hard and have thoroughly addressed your comments in the rebuttal.\n\nAs the discussion period soon comes to an end, we are looking forward to your feedback to our response and revised manuscript. Many thanks again for your time and efforts.\n\nBest regards,\n\nAuthors of Submission 5510"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700469907577,
                "cdate": 1700469907577,
                "tmdate": 1700469907577,
                "mdate": 1700469907577,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MxXp1SirP9",
                "forum": "a4DBEeGfQq",
                "replyto": "Mkode2ozM0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Reviewer_kF3D"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Reviewer_kF3D"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the reply"
                    },
                    "comment": {
                        "value": "Thank you for the extensive additional experiments and the comprehensive discussion. Most of my concerns are resolved, nevertheless, there remain some questions regarding the response:\n\n- Regarding Q1: Since the heterophilous graphs have received lots of attention from the community, it'd be better if StructComp could be implemented for both kinds of graphs, with the suitable GCL method such as SP-GCL.\n- Regarding Q8: In practice, the pre-processing time must be considered to find the best trade-off in terms of performance and efficiency, considering different scales of the graphs (the small, medium scale graphs in the original submission; and the large-scale graphs presented in the authors' response). It's important to present the efficiency results including the full pipeline of different methods, i.e., the overall time/mem cost for training the model, and the overhead for inference."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700474178277,
                "cdate": 1700474178277,
                "tmdate": 1700474178277,
                "mdate": 1700474178277,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Ld4zfJ1qyp",
                "forum": "a4DBEeGfQq",
                "replyto": "duQIbs6gkc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Further Response to Reviewer kF3D[1/2]"
                    },
                    "comment": {
                        "value": "Thank you for your feedback . We would like to address your questions/concerns below:\n\n**Regarding Q1: Since the heterophilous graphs have received lots of attention from the community, it'd be better if StructComp could be implemented for both kinds of graphs, with the suitable GCL method such as SP-GCL.**\n\nWe provide experiments of training SP-GCL with StructComp to verify the performance of StructComp on heterophilous graphs. The experimental results are shown in Table 7. Overall, the SP-GCL trained by StructComp is superior to full graph training. This is our initial attempt to use StructComp to handle heterophilous graphs, and it is obviously a valuable direction worth further research.\n\nTable 7. The results on heterophilous datasets.\n\n|                              | Chameleon Acc  | Chameleon Time | Chameleon Mem | Squirrel Acc   | Squirrel Time | Squirrel Mem | Actor Acc      | Actor Time | Actor Mem |\n| ---------------------------- | -------------- | -------------- | ------------- | -------------- | ------------- | ------------ | -------------- | ---------- | --------- |\n| SP-GCL                       | 65.28$\\pm$0.53 | 0.038          | 739           | 52.10$\\pm$0.67 | 0.080         | 3623         | 28.94$\\pm$0.69 | 0.041      | 802       |\n| SP-GCL$_{\\text{StructComp}}$ | 66.65$\\pm$1.63 | 0.011          | 168           | 53.08$\\pm$1.39 | 0.009         | 217          | 28.70$\\pm$1.25 | 0.013      | 159       |\n\n**Regarding Q8: In practice, the pre-processing time must be considered to find the best trade-off in terms of performance and efficiency, considering different scales of the graphs (the small, medium scale graphs in the original submission; and the large-scale graphs presented in the authors' response). It's important to present the efficiency results including the full pipeline of different methods, i.e., the overall time/mem cost for training the model, and the overhead for inference.**\n\nAs we said in our previous response, the pre-processing of our StructComp only needs to perform METIS once. The specific time for METIS on our CPU is shown in Table 8.\n\nTable 8. Preprocessing time.\n\n|       | Cora   | Citeseer | Pubmed | Computers | Photo | Flickr | Reddit | Arxiv | Products | 100M |\n| ----- | ------ | -------- | ------ | --------- | ----- | ------ | ------ | ----- | -------- | ---- |\n| METIS | 0.075s | 0.059s   | 0.60s  | 1.4s      | 0.58s | 1.7s   | 26.9s  | 15.7s | 225s     | 1.4h |\n\nFor small and medium datasets, the time required by METIS is very short. Therefore, in these basic GCL models, the overall time required for full graph training is still more than that of StructComp. The results are shown in Table 9.\n\nTable 9. The overall time (seconds) and memory usage (MB) on small and medium datasets.\n\n|                               | Cora Mem | Cora Time | Citeseer Mem | Citeseer Time | Pubmed Mem | Pubmed Time | Computers Mem | Computers Time | Photo Mem | Photo Time |\n| ----------------------------- | -------- | --------- | ------------ | ------------- | ---------- | ----------- | ------------- | -------------- | --------- | ---------- |\n| SCE                           | 82       | 0.16      | 159          | 0.20          | 1831       | 1.9         | 920           | 1.5            | 329       | 0.60       |\n| SCE$_{\\text{StructComp}}$     | 23       | 0.17      | 59           | 0.16          | 54         | 0.67        | 29            | 1.4            | 16        | 0.62       |\n| COLES                         | 115      | 0.20      | 204          | 0.32          | 1851       | 1.7         | 1018          | 3.1            | 378       | 1.5        |\n| COLES$_{\\text{StructComp}}$   | 24       | 0.18      | 60           | 0.21          | 61         | 0.75        | 39            | 1.5            | 21        | 0.64       |\n| GRACE                         | 441      | 1.7       | 714          | 2.5           | 11677      | 18.9        | 5943          | 29.6           | 1996      | 21.2       |\n| GRACE$_{\\text{StructComp}}$   | 37       | 0.24      | 72           | 0.87          | 194        | 1.3         | 54            | 2.6            | 59        | 2.2        |\n| CCA-SSG                       | 132      | 1.0       | 225          | 1.1           | 825        | 12.3        | 2418          | 10.5           | 1197      | 11.2       |\n| CCA-SSG$_{\\text{StructComp}}$ | 38       | 0.17      | 71           | 0.31          | 85         | 0.9         | 40            | 1.6            | 41        | 1.1        |"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700554967574,
                "cdate": 1700554967574,
                "tmdate": 1700558154208,
                "mdate": 1700558154208,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VS8ebHpt6c",
                "forum": "a4DBEeGfQq",
                "replyto": "duQIbs6gkc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Further Response to Reviewer kF3D[2/2]"
                    },
                    "comment": {
                        "value": "As the scale of the graph dataset increases, all GCL models need to use graph sampling or graph partitioning techniques to construct subgraphs and then train GCL on subgraphs. Therefore, pre-processing like METIS is necessary, there are no issue where pre-processing increases the overall time. In our StructComp, METIS only needs to be performed once. Then, we can use the results of the graph partitioning to train various GCL models. *Tables 3 and 4 in the original submission have already proven that StructComp has achieved the best trade-off between performance and efficiency on large graphs.* To further illustrate this point, we provide the overall time results on 100M.\n\nTable 10. The overall time and memory usage on the Ogbn-papers100M dataset.\n\n| Method                        | Acc          | Time (Prepreocess + Training)    | Mem   |\n| ----------------------------- | ------------ | -------------------------------- | ----- |\n| GGD+Cluster-GCN               | 63.5$\\pm$0.5 | 1.4h + 1.6h $\\times$ 10 =  17.4h | 4.3GB |\n| SCE$_{\\text{StructComp}}$     | 63.6$\\pm$0.4 | 1.4h + 0.18s$\\times$ 10  =  1.4h | 0.1GB |\n| COLES$_{\\text{StructComp}}$   | 63.6$\\pm$0.4 | 1.4h + 0.16s$\\times$ 10 = 1.4h   | 0.3GB |\n| GRACE$_{\\text{StructComp}}$   | 64.0$\\pm$0.3 | 1.4h + 0.44s$\\times$ 10  =  1.4h | 0.9GB |\n| CCA-SSG$_{\\text{StructComp}}$ | 63.5$\\pm$0.2 | 1.4h + 0.18s$\\times$ 10  =  1.4h | 0.1GB |\n\n**Regarding the overhead for inference.** Firstly, the overhead for inference is the same whether or not StructComp is used. The overhead for inference is solely related to the specific encoder used. Secondly, our work is only focused on the training process, as it is the most resource-intensive part of the entire pipeline. In contrast, inference is much simpler compared to training, and there are already straightforward and effective methods available for accelerating inference with GNN encoders [1,2]. For the 100M dataset, we utilized these methods to speed up the inference process. In our experiments, we utilized the same encoder for each dataset.  The corresponding inference overheads are displayed in Table 11.\n\nTable 11. The overhead for inference. Due to the large size of 100M, we employed neighbor sampling during the inference process. For all other datasets, we performed full graph inference.\n\n|      | Cora   | Citeseer | Pubmed | Computers | Photo  | Flickr | Reddit | Arxiv | Products | 100M  |\n| ---- | ------ | -------- | ------ | --------- | ------ | ------ | ------ | ----- | -------- | ----- |\n| Mem  | 24MB   | 63MB     | 122MB  | 72MB      | 40MB   | 362MB  | 1.1GB  | 434MB | 5.9GB    | 5.5GB |\n| Time | 0.001s | 0.001s   | 0.003s | 0.002s    | 0.002s | 0.01s  | 0.03s  | 0.01s | 0.05s    | 159s  |\n\n[1] Hu, W., Fey, M., Zitnik, M., Dong, Y., Ren, H., Liu, B., Catasta, M. and Leskovec, J. Open graph benchmark: Datasets for machine learning on graphs. Neurips 2020.\n\n[2] Gasteiger, J., Qian, C. and G\u00fcnnemann, S. Influence-based mini-batching for graph neural networks. LOG 2022."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700555019464,
                "cdate": 1700555019464,
                "tmdate": 1700556469610,
                "mdate": 1700556469610,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "amGYeuEeDm",
                "forum": "a4DBEeGfQq",
                "replyto": "VS8ebHpt6c",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Reviewer_kF3D"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Reviewer_kF3D"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the reply"
                    },
                    "comment": {
                        "value": "Thank you for the follow-up experiments and discussion. I have increased my score accordingly."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700561825700,
                "cdate": 1700561825700,
                "tmdate": 1700561825700,
                "mdate": 1700561825700,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "AaEoXdzQBe",
            "forum": "a4DBEeGfQq",
            "replyto": "a4DBEeGfQq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5510/Reviewer_iDuQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5510/Reviewer_iDuQ"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces StructComp, a scalable training framework for Graph Contrastive Learning (GCL). By replacing the message-passing operation in GCL with node-compression, StructComp achieves significant reductions in both time and memory consumption. The authors provide both theoretical analysis and empirical evaluations to underscore the effectiveness and efficiency of StructComp in training GCL models."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The storyline is relatively clear, it is easy to follow for the authors.  \n2. The experiment results are amazing, especially the time-saving.  \n3. The used method is quite simple."
                },
                "weaknesses": {
                    "value": "1. Lack of discussion of graph partition: The paper lacks a comprehensive discussion on graph partitioning. Given that the efficacy of the method hinges on graph partitioning\u2014a classic NP-hard problem\u2014a detailed exploration of its impact on the proposed method is warranted. A cursory introduction does not suffice.  \n2. Inadequate theoretical provements: The theoretical justifications provided are somewhat limited. The authors' attempt to establish the equivalence between the compressed loss and the original loss is based solely on the ER model, which may not be representative of real-world datasets.  \n3. Lack of the discussion about the limitations."
                },
                "questions": {
                    "value": "1. Adding more discussions about graph partition: The authors should delve deeper into the topic of graph partitioning, as highlighted in the first weakness.\n\n2. Considering not over-claiming your work: It's crucial to avoid overstating the contributions. While the authors assert that they have provided theoretical proof, the strong assumptions (like the ER model) limit its applicability. It might be prudent to either temper such claims in the abstract and introduction or offer more exhaustive proof.\nIn essence, while I acknowledge the novelty and results presented in this paper, I urge the authors to provide a more in-depth rationale behind their impressive outcomes. Without this, the paper leans more toward a technical report than a comprehensive research paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5510/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698752664700,
            "cdate": 1698752664700,
            "tmdate": 1699636564096,
            "mdate": 1699636564096,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qumVRErwjy",
                "forum": "a4DBEeGfQq",
                "replyto": "AaEoXdzQBe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer iDuQ[1/3]"
                    },
                    "comment": {
                        "value": "Thank you for your comments! Below are our responses.\n\n**Q1:Lack of discussion of graph partition.**\n\nOur main contribution is a novel scalable framework for training GCLs and empirically show that even with off-the-shelf partition algorithms, our framework achieves remarkable speedup. We believe that no need for a specially designed partition algorithm is actually a big advantage. \n\nWe agree that different graph partition algorithms will have an impact on the performance of StructComp. We have conducted extra experiments on graph partition. In Table 1, we demonstrate the effects of three algorithms, algebraic JC, variation neighborhoods, and affinity GS, on the performance of StructComp. These three graph coarsening algorithms are widely used in scalable GNNs, from which we can obtain the specific graph partition matrix P. The experimental results suggest that different graph partition methods has little impact on StructComp on these datasets. \n\nTable 1: The results of different graph partition methods.\n\n| Method                            | Cora         | CiteSeer     | PubMed       |\n| --------------------------------- | ------------ | ------------ | ------------ |\n| VN+SCE$_{\\text{StructComp}}$      | 81.3$\\pm$0.8 | 71.5$\\pm$1.0 | 77.5$\\pm$2.7 |\n| JC+SCE$_{\\text{StructComp}}$      | 81.2$\\pm$0.9 | 71.5$\\pm$1.1 | 77.3$\\pm$2.7 |\n| GS+SCE$_{\\text{StructComp}}$      | 81.5$\\pm$0.8 | 71.4$\\pm$1.0 | 77.4$\\pm$3.0 |\n| METIS+SCE$_{\\text{StructComp}}$   | 81.6$\\pm$0.9 | 71.5$\\pm$1.0 | 77.2$\\pm$2.9 |\n| VN+COLES$_{\\text{StructComp}}$    | 81.4$\\pm$0.9 | 71.6$\\pm$0.9 | 75.5$\\pm$3.0 |\n| JC+COLES$_{\\text{StructComp}}$    | 81.4$\\pm$0.9 | 71.5$\\pm$1.0 | 75.3$\\pm$3.0 |\n| GS+COLES$_{\\text{StructComp}}$    | 81.8$\\pm$0.8 | 71.6$\\pm$1.0 | 75.5$\\pm$3.2 |\n| METIS+COLES$_{\\text{StructComp}}$ | 81.8$\\pm$0.8 | 71.6$\\pm$0.9 | 75.3$\\pm$3.1 |\n\nGraph partition is a common technique for scalable supervised GNN (e.g., ClusterGCN[1], GAS[2]), thus we have not introduced its details in our paper. To our knowledge, Metis is the mainstream graph partitioning method for scalable supervised GNNs. Previous work has not deeply investigated the impact of graph partitioning methods on scalable GNNs. We believe that this is a valuable research topic and we notice that there is an active submission at ICLR 2024 regarding this issue on scalable supervised GNNs ."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700150906954,
                "cdate": 1700150906954,
                "tmdate": 1700150906954,
                "mdate": 1700150906954,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cVfV56Msm9",
                "forum": "a4DBEeGfQq",
                "replyto": "AaEoXdzQBe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer iDuQ[2/3]"
                    },
                    "comment": {
                        "value": "**Q2:Inadequate theoretical provements: The theoretical justifications provided are somewhat limited.**\n\nWe understand your concern that the ER model may seem a strong assumption and possibly not entirely reflective of real-world scenarios. However, random graphs like the ER graph and the CSBM is widely adopted for GNN analysis(e.g., [3-8]). In our paper, we choose ER over CSBM since they have no significant difference in unsupervised GCL. We will specify the data distribution we used for analysis in the abstract and introduction. We would also like to point out that strong assumptions are common in the analysis of neural networks, e.g., infinite width in NTK [9], shallow layers [10], removing non-linearity [11], and strong data distribution assumptions [3-8]. \n\nAccording to the suggestion of the reviewer, we give an extra analysis on arbitrary graphs. For non-random graphs, the approximation gap of losses is simply bounded by the Eq 4. Suppose the loss $\\mathcal{L}$ is $L$-Lipschitz continuous,\n\\begin{equation}\n    \\begin{split}\n        |\\mathcal{L}(P^\\dagger P^TXW)-\\mathcal{L}(\\hat{A}^kXW)|\\leq L \\underbrace{\\Vert P^\\dagger P^T - \\hat{A}^k\\Vert}_\\text{Eq 4.}  \\Vert X\\Vert  \\Vert  W\\Vert .\n    \\end{split}\n\\end{equation}\n\nAnd for a spectral contrastive loss $\\mathcal{L}'$ , assume the graph partition are even, we have:\n\\begin{equation}\n\\mathcal{L}'(P^TXW)=-\\frac{2}{n}\\sum_{i=1}^n e^T_{1,i}e_{2,i}+\\frac{1}{n^2}\\sum_{i=1}^n \\sum_{j=1}^n (e^T_{1,i} e_{2,j})^2\n        =-\\frac{2}{n}\\sum_{k=1}^{n'}\\sum_{i\\in S_k}e^T_{1,i}e_{2,i}+\\frac{1}{n^2}\\sum_{i=1}^n \\sum_{l=1}^{n'} \\sum_{j\\in S_l} (e^T_{1,i} e_{2,j})^2\n\\end{equation}\n\\begin{equation}\n        =-\\frac{2}{n'}\\sum_{k=1}^{n'}E^T_{1,i}E_{2,i}+\\frac{1}{nn'}\\sum_{i=1}^n \\sum_{l=1}^{n'}  (e^T_{1,i} E_{2,j})^2\n        =-\\frac{2}{n'}\\sum_{k=1}^{n'}E^T_{1,i}E_{2,i}+\\frac{1}{nn'}\\sum_{k=1}^{n'}\\sum_{i\\in S_k} \\sum_{l=1}^{n'}  (e^T_{1,i} E_{2,j})^2\n\\end{equation}\n\\begin{equation}\n        =-\\frac{2}{n'}\\sum_{k=1}^{n'}E^T_{1,i}E_{2,i}+\\frac{1}{n'^2}\\sum_{k=1}^{n'}\\sum_{l=1}^{n'}  (E^T_{1,i} E_{2,j})^2=\\mathcal{L}'(P^\\dagger P^TXW),\n\\end{equation}\n\nwhere $e_{1,i}$ denotes the representations of a recovered node and $E^T_{1,i}$ denotes the representations of a compressed node. The above analysis shows that our approximation is reasonable for fixed graphs.\n\nEmpirically, we want to highlight *Figure 3 in the original submission* as it greatly validates our approximation on real-world datasets. We have trained two encoders $U$ and $W$ with the compressed loss $\\mathcal{L}(X_c; U)$ and the original loss $\\mathcal{L}(A,X;W)$, respectively. And we plot the trends of the origianl loss on $U$ and $W$ (i.e., $\\mathcal{L}(A,X;U)$ and $\\mathcal{L}(A,X;W)$). The figure clearly shows that vanilla training method and StructComp yields extremely similar trends, which justifies our approximation.\n\n**Q3:Lack of the discussion about the limitations.**\n\nThank you for your feedback. We will provide a detailed discussion of the limitations of StructComp in the revised version. To our knowledge, StructComp is the first training framework specifically designed for GCL models, focusing only on basic and common GCL models. Our future work will involve generalizing StructComp to more complex GCL models, graph data structures."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700150949441,
                "cdate": 1700150949441,
                "tmdate": 1700150949441,
                "mdate": 1700150949441,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sa3tJ1W8Hq",
                "forum": "a4DBEeGfQq",
                "replyto": "AaEoXdzQBe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer iDuQ[3/3]"
                    },
                    "comment": {
                        "value": "The discussion of all the aforementioned issues will be added into the revised version of our paper. We appreciate your insightful feedback once again.\n\n[1]Chiang, W. L., Liu, X., Si, S., Li, Y., Bengio, S., \\& Hsieh, C. J. Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks. KDD 2019.\n\n[2]Fey, M., Lenssen, J. E., Weichert, F., \\& Leskovec, J. Gnnautoscale: Scalable and expressive graph neural networks via historical embeddings. ICML 2021\n\n[3]Wei, R., Yin, H., Jia, J., Benson, A. R., \\& Li, P. Understanding non-linearity in graph neural networks from the bayesian-inference perspective. Neurips 2022.\n\n[4]Wu, X., Chen, Z., Wang, W. W., \\& Jadbabaie, A. A Non-Asymptotic Analysis of Oversmoothing in Graph Neural Networks. ICLR 2023.\n\n[5]Su, J., Zou, D., Zhang, Z., \\& Wu, C. Towards Robust Graph Incremental Learning on Evolving Graphs. ICML 2023.\n\n[6]Keriven, N., Bietti, A., \\& Vaiter, S. Convergence and stability of graph convolutional networks on large random graphs. Neurips 2020.\n\n[7]Keriven, N., Bietti, A., \\& Vaiter, S. On the universality of graph neural networks on large random graphs. Neurips 2021.\n\n[8]Keriven, N. Not too little, not too much: a theoretical analysis of graph (over) smoothing. Neurips 2022.\n\n[9]Jacot, A., Gabriel, F., \\& Hongler, C. Neural tangent kernel: Convergence and generalization in neural networks. Neurips 2018.\n\n[10]Hsu, D., Sanford, C. H., Servedio, R., \\& Vlatakis-Gkaragkounis, E. V. On the approximation power of two-layer networks of random relus. COLT 2021.\n\n[11]Awasthi, P., Das, A., \\& Gollapudi, S. A convergence analysis of gradient descent on graph neural networks. Neurips 2021."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700151169944,
                "cdate": 1700151169944,
                "tmdate": 1700151169944,
                "mdate": 1700151169944,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mrIxvnpi9v",
                "forum": "a4DBEeGfQq",
                "replyto": "AaEoXdzQBe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A friendly reminder for discussion and we appreciate your input"
                    },
                    "comment": {
                        "value": "Dear Reviewer iDuQ,\n\nWe thank you again for your insightful and constructive review. We have worked hard and have thoroughly addressed your comments in the rebuttal.\n\nAs the discussion period soon comes to an end, we are looking forward to your feedback to our response and revised manuscript. Many thanks again for your time and efforts.\n\nBest regards,\n\nAuthors of Submission 5510"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700469842990,
                "cdate": 1700469842990,
                "tmdate": 1700469842990,
                "mdate": 1700469842990,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xqx4tP4D62",
                "forum": "a4DBEeGfQq",
                "replyto": "AaEoXdzQBe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A friendly reminder for discussion"
                    },
                    "comment": {
                        "value": "Dear Reviewer iDuQ,\n\nThe rebuttal phase ends today and we have not yet received feedback from you. We believe that we have addressed all of your previous concerns. We would really appreciate that if you could check our response and updated paper.\n\nLooking forward to hearing back from you.\n\nBest Regards,\n\nAuthors"
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700702335662,
                "cdate": 1700702335662,
                "tmdate": 1700702335662,
                "mdate": 1700702335662,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qOmghInatf",
            "forum": "a4DBEeGfQq",
            "replyto": "a4DBEeGfQq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5510/Reviewer_v4Cz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5510/Reviewer_v4Cz"
            ],
            "content": {
                "summary": {
                    "value": "This paper aim at resolving the scalability issue of graph contrastive learning training. In graph representation learning, the most compiutation  overhead comes from message passing, where its complexity grows exponentially wrt the num of layers in GNN. \n\nTo overcome this scalability issue, the authors propose **StructComp** trains the encoder with the compressed nodes. StructComp allows the encoder not to perform any message passing during the training stage."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "I like the idea of using compressing nodes to replace the need of message passing."
                },
                "weaknesses": {
                    "value": "- The theoritical results only hold in linear-GNN, which over-simplifies the problem. It is well know that deep neural network behave different from linear model in contrastive learning [1]. Without consider non-linearity, the problem in Eq. 4 is simply matrix decomposition problem (e.g., [2] section 3).\n\n[1] Understanding the Role of Nonlinearity in Training Dynamics of Contrastive Learning. https://arxiv.org/abs/2206.01342\n[2] Understanding Deep Contrastive Learning via Coordinate-wise Optimization https://arxiv.org/pdf/2201.12680.pdf\n\n- Experiment datasets are too small (even arxiv dataset is small)... please try some large-scale graph datasets (e.g., Yelp, Reddit datasets that previously GraphSaint paper) to validate the effectiveness. Especially when this paper is focussing on improving the scalability issue. \n\n- Repeat experiment multiple times instead of just once. For example Figure 4."
                },
                "questions": {
                    "value": "How theoritical results could be generalized to non-linear models?\n\nDoes the proposed method work for graphs with multiple node/edge types?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5510/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698820810159,
            "cdate": 1698820810159,
            "tmdate": 1699636564010,
            "mdate": 1699636564010,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "m0QepZ5gf1",
                "forum": "a4DBEeGfQq",
                "replyto": "qOmghInatf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer v4Cz[1/2]"
                    },
                    "comment": {
                        "value": "Thank you for your detailed review. We would like to address your questions/concerns below:\n\n**Q1: How theoretical results could be generalized to non-linear models?**\n\nThanks for the insightful question. We explain how to extend the results to non-linear deep models below. \n\nEq. (4) provides the motivation of structural compression on a linear GNN (which can also be considered as an approximation to one layer in a multi-layer non-linear GNN). The analysis can be extended to non-linear deep GNNs. For instance, given a two-layer non-linear GCN $\\sigma(\\\\hat{A}\\sigma(\\\\hat{A}XW_1)W_2)$, we first approximate $\\hat{A}$ by $P^&dagger; P^T$, then the whole GCN can be approximated as\n\n$$\n\\begin{align*}\n    \\sigma(P^&dagger; P^T\\sigma(P^&dagger; P^TXW_1)W_2)&=\\sigma(P^&dagger; P^TP^&dagger;\\sigma(P^TXW_1)W_2)\\\\\n    &=P^&dagger;\\sigma(\\sigma(P^TXW_1)W_2).\n\\end{align*}\n$$\n\nThe first equality holds because $P^&dagger;$ is a partition matrix and the last equality follows from the fact that $P^TP^&dagger; = I$. Therefore, our analysis provides theoretical justifications of using StructComp as a substitute for non-linear deep GNNs. We will add this extended analysis to the revision. Note that previous studies on scalable methods for training GNNs, such as GraphSaint [1], FastGCN [2], Adapt [3], GRADE [4] also rely on various types of approximation to the propagation matrix, however, their analyses only focus on the approximation quality to a single layer or only work for linear GNNs. On the contrary, our analysis of StructComp can be easily extended to non-linear deep GNNs, which is another advantage of our framework.\n\n\n**Q2:Experiment datasets are too small (even arxiv dataset is small)... please try some large-scale graph datasets (e.g., Yelp, Reddit datasets that previously GraphSaint paper) to validate the effectiveness.**\n\nThe ogbn-products dataset used in our experiments has **2,449,029** nodes, which is much larger than both Yelp and Reddit you suggested. We have also conducted extra experiments on Flickr and Reddit to show the performance of StructComp under inductive setting. The experimental results are as follows. StructComp shows remarkable scalability on these datasets. \n\nTable 1: The results on two inductive datasets. OOM means Out of Memory on GPU.\n\n| Method                        | Flickr Acc | Flickr Time | Flickr Mem | Reddit Acc | Reddit Time | Reddit Mem |\n| ----------------------------- | ---------- | ----------- | ---------- | ---------- | ----------- | ---------- |\n| SCE                           | 50.6       | 0.55        | 8427       | -          | -           | OOM        |\n| SCE$_{\\text{StructComp}}$     | 51.6       | 0.003       | 43         | 94.4       | 0.017       | 1068       |\n| COLES                         | 50.3       | 0.83        | 9270       | -          | -           | OOM        |\n| COLES$_{\\text{StructComp}}$   | 50.7       | 0.003       | 48         | 94.2       | 0.024       | 1175       |\n| GRACE                         | -          | -           | OOM        | -          | -           | OOM        |\n| GRACE$_{\\text{StructComp}}$   | 51.5       | 0.010       | 221        | 94.3       | 0.079       | 8683       |\n| CCA-SSG                       | 51.6       | 0.125       | 1672       | 94.9       | 0.21        | 5157       |\n| CCA-SSG$_{\\text{StructComp}}$ | 51.8       | 0.007       | 99         | 95.2       | 0.56        | 457        |\n\nAccording to the suggestions of other reviewers, the experiments on the ogbn-papers100M (which has **111,059,956** nodes) are conducted as well. The experimental results are shown in Table 2. Here, we compressed ogbn-papers100M into a feature matrix $X_c \\in R^{5000*128}$ and trained GCL using StructComp. Table 2 also presents the results of GGD trained with ClusterGCN. Although GGD is specifically designed for training large graphs, when dealing with datasets of the scale of ogbn-papers100M, it still requires graph sampling to construct subgraphs and train GGD on a large number of subgraphs. In contrast, our StructComp only requires training a simple and small-scale MLP, resulting in significantly lower resource consumption compared to GGD+ClusterGCN.\n\nTable 2: The accuracy, training time per epoch and memory usage on the Ogbn-papers100M dataset.\n\n| Method                        | Acc          | Time  | Mem   |\n| ----------------------------- | ------------ | ----- | ----- |\n| GGD+ClusterGCN                | 63.5$\\pm$0.5 | 1.6h  | 4.3GB |\n| SCE$_{\\text{StructComp}}$     | 63.6$\\pm$0.4 | 0.18s | 0.1GB |\n| COLES$_{\\text{StructComp}}$   | 63.6$\\pm$0.4 | 0.16s | 0.3GB |\n| GRACE$_{\\text{StructComp}}$   | 64.0$\\pm$0.3 | 0.44s | 0.9GB |\n| CCA-SSG$_{\\text{StructComp}}$ | 63.5$\\pm$0.2 | 0.18s | 0.1GB |"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700148770139,
                "cdate": 1700148770139,
                "tmdate": 1700308034740,
                "mdate": 1700308034740,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LvSwwMcOM9",
                "forum": "a4DBEeGfQq",
                "replyto": "qOmghInatf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer v4Cz[2/2]"
                    },
                    "comment": {
                        "value": "**Q3:Repeat experiment multiple times instead of just once. For example Figure 4.**\n\nWe emphasize that all of the experiments in the original submission are results of multiple repetitions. On Cora, Citeseer, PubMed, Computers, and Photo, we repeated the experiment 50 times. On Arxiv and Products, we repeated the experiment 5 times. Figure 4 shows the average accuracy of 50 repetitions.\n\n**Q4:Does the proposed method work for graphs with multiple node/edge types?**\n\nCurrently, we have not implemented StructComp on graphs with multiple node/edge types, as the chosen basic GCL methods - SCE, COLES, GRACE, and CCA-SSG - are not suitable for these types of graph data. In our future work, we will explore applying StructComp to more complex graph data structures.\n\n--------------------------------\n\nThe discussion of all the aforementioned issues will be added into the revised version of our paper. We appreciate your insightful feedback once again.\n\n\n\n[1] H. Zeng, H. Zhou, A. Srivastava, R. Kannan, and V. K. Prasanna. Graphsaint: Graph sampling based inductive learning method. ICLR 2020.\n\n[2] J. Chen, T. Ma, an C. Xiao. Fastgcn: fast learning with graph convolutional networks via importance sampling. ICLR 2018.\n\n[3] W. Huang, T. Zhang, Y. Rong, and J. uang. Adaptive sampling towards fast graph representation learning. NIPS 2018.\n\n[4] R Wang, X Wang, C Shi, L Song. Uncovering the Structural Fairness in Graph Contrastive Learning. Neurips 2022."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700148792544,
                "cdate": 1700148792544,
                "tmdate": 1700301947681,
                "mdate": 1700301947681,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kdBqZmWhBy",
                "forum": "a4DBEeGfQq",
                "replyto": "qOmghInatf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A friendly reminder for discussion and we appreciate your input"
                    },
                    "comment": {
                        "value": "Dear Reviewer v4Cz,\n\nWe thank you again for your insightful and constructive review. We have worked hard and have thoroughly addressed your comments in the rebuttal.\n\nAs the discussion period soon comes to an end, we are looking forward to your feedback to our response and revised manuscript. Many thanks again for your time and efforts.\n\nBest regards,\n\nAuthors of Submission 5510"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700469795007,
                "cdate": 1700469795007,
                "tmdate": 1700469795007,
                "mdate": 1700469795007,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iGEbVtRv85",
                "forum": "a4DBEeGfQq",
                "replyto": "qOmghInatf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Extra experiments on more complicated graphs"
                    },
                    "comment": {
                        "value": "According to the suggestion from reviewer kF3D, we have conducted experiments to train SP-GCL with StructComp, in order to verify the performance of StructComp on heterophilous graphs. The experimental results are shown in Table 3. Overall, the SP-GCL trained by StructComp is superior to full graph training. This is our initial attempt to use StructComp to handle heterophilous graphs, and it is obviously a valuable direction worth further research.\n\nTable 3. The results on heterophilous datasets.\n\n|                              | Chameleon Acc  | Chameleon Time | Chameleon Mem | Squirrel Acc   | Squirrel Time | Squirrel Mem | Actor Acc      | Actor Time | Actor Mem |\n| ---------------------------- | -------------- | -------------- | ------------- | -------------- | ------------- | ------------ | -------------- | ---------- | --------- |\n| SP-GCL                       | 65.28$\\pm$0.53 | 0.038          | 739           | 52.10$\\pm$0.67 | 0.080         | 3623         | 28.94$\\pm$0.69 | 0.041      | 802       |\n| SP-GCL$_{\\text{StructComp}}$ | 66.65$\\pm$1.63 | 0.011          | 168           | 53.08$\\pm$1.39 | 0.009         | 217          | 28.70$\\pm$1.25 | 0.013      | 159       |"
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700557488383,
                "cdate": 1700557488383,
                "tmdate": 1700557488383,
                "mdate": 1700557488383,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Ti3ACbXk4R",
                "forum": "a4DBEeGfQq",
                "replyto": "qOmghInatf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A friendly reminder for discussion"
                    },
                    "comment": {
                        "value": "Dear Reviewer v4Cz,\n\nThe rebuttal phase ends today and we have not yet received feedback from you. We believe that we have addressed all of your previous concerns. We would really appreciate that if you could check our response and updated paper.\n\nLooking forward to hearing back from you.\n\nBest Regards,\n\nAuthors"
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700702288785,
                "cdate": 1700702288785,
                "tmdate": 1700702288785,
                "mdate": 1700702288785,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ruxtljuUs1",
            "forum": "a4DBEeGfQq",
            "replyto": "a4DBEeGfQq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5510/Reviewer_PXMh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5510/Reviewer_PXMh"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes Structural Compression (StructComp), a new training framework that improves the scalability of graph contrastive learning (GCL) models. The key idea is to substitute propagation with a sparse, low-rank approximation of the diffusion matrix to compress the nodes. Contrastive learning is performed on these compressed nodes, reducing computation and memory costs. Theoretical analysis shows the compressed loss approximates the original loss and StructComp implicitly regularizes the model.  Experiments on various single-view and multi-view GCL methods demonstrate StructComp's improvements in performance and efficiency."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThe paper is well-written and easy to follow. The problem is motivated well, and the method is explained clearly. \n\n2.\tScalability is a major bottleneck hindering wider adoption of graph neural networks. This work makes an important contribution by enabling efficient training of GCL models."
                },
                "weaknesses": {
                    "value": "1. Additional experiments could help verify claims on scalability and robustness of StructComp: \n\n- Evaluating on larger datasets like papers100M and or OGBG-LSC datasets  would better support scalability claims, since the experimented datasets are rather small or medium scale.  \n\n- Would be great to verify the model stability/robustness with the proposed regularization, since it is claimed in the presentation. \n\n\n2. Would be great to discuss the approximation quality to the diffusion matrix  of StructComp for more complicated graphs and other models architectures (like GAT, GraphSAGE) .\n\n3. There is a lack of  comparisons with certain related works, such as recent graph contrastive learning methods  [1-2] \n\n\n[1] ] Wang, H., Zhang, J., Zhu, Q., & Huang, W. (2022). Can Single-Pass Contrastive Learning Work for Both Homophilic and Heterophilic Graph?. arXiv preprint arXiv:2211.10890.\n\n[2] Li, J., Sun, W., Wu, R., Zhu, Y., Chen, L., & Zheng, Z. (2023). Scaling Up, Scaling Deep: Blockwise Graph Contrastive Learning. arXiv preprint arXiv:2306.02117."
                },
                "questions": {
                    "value": "See the weakness above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5510/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698838670299,
            "cdate": 1698838670299,
            "tmdate": 1699636563926,
            "mdate": 1699636563926,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "IxSnHAI5hd",
                "forum": "a4DBEeGfQq",
                "replyto": "ruxtljuUs1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer PXMh[1/3]"
                    },
                    "comment": {
                        "value": "Thank you for your detailed review. We would like to address your questions/concerns below:\n\n**Q1:Evaluating on larger datasets like papers100M and or OGBG-LSC datasets would better support scalability claims, since the experimented datasets are rather small or medium scale.**\n\nWe have conducted extra experiments on the ogbn-papers100M dataset according to your suggestion. We use StructComp to train four representative GCL models. Here, we compressed ogbn-papers100M into a feature matrix $X_c \\in R^{5000*128}$ and trained GCL using StructComp. The table also presents the results of GGD trained with ClusterGCN. Although GGD is specifically designed for training large graphs, when dealing with datasets of the scale of ogbn-papers100M, it still requires graph sampling to construct subgraphs and train GGD on a large number of subgraphs. In contrast, our StructComp only requires training a simple and small-scale MLP, resulting in significantly lower resource consumption compared to GGD+ClusterGCN.\n\n\n\nTable 1: The accuracy, training time per epoch and memory usage on the Ogbn-papers100M dataset.\n\n| Method                        | Acc          | Time  | Mem   |\n| ----------------------------- | ------------ | ----- | ----- |\n| GGD                           | 63.5$\\pm$0.5 | 1.6h  | 4.3GB |\n| SCE$_{\\text{StructComp}}$     | 63.6$\\pm$0.4 | 0.18s | 0.1GB |\n| COLES$_{\\text{StructComp}}$   | 63.6$\\pm$0.4 | 0.16s | 0.3GB |\n| GRACE$_{\\text{StructComp}}$   | 64.0$\\pm$0.3 | 0.44s | 0.9GB |\n| CCA-SSG$_{\\text{StructComp}}$ | 63.5$\\pm$0.2 | 0.18s | 0.1GB |\n\n\n\n**Q2:Would be great to verify the model stability/robustness with the proposed regularization, since it is claimed in the presentation.**\n\nWe have conducted extra experiments to study the robustness of StructComp. We randomly add 10\\% of noisy edges into three datasets and perform the node classification task. On the original dataset, the models trained with StructComp showed performance improvements of **0.36**, **0.40**, **1.30** and **1.87**, respectively, compared to the models trained with full graphs. With noisy perturbation, the models trained with StructComp showed performance improvements of **0.80**, **1.27**, **2.47**, and **1.87**, respectively, compared to full graph training. This indicates that GCL models trained with StructComp exhibit better robustness.\n\n\n\nTable 2: The results over 50 random splits  on the perturbed datasets.\n\n| Method                        | Cora         | CiteSeer     | PubMed       |\n| ----------------------------- | ------------ | ------------ | ------------ |\n| SCE                           | 78.8$\\pm$1.2 | 69.7$\\pm$1.0 | 73.4$\\pm$2.2 |\n| SCE$_{\\text{StructComp}}$     | 79.3$\\pm$0.9 | 69.3$\\pm$0.9 | 75.7$\\pm$2.8 |\n| COLES                         | 78.7$\\pm$1.2 | 68.0$\\pm$1.0 | 66.5$\\pm$1.8 |\n| COLES$_{\\text{StructComp}}$   | 79.0$\\pm$1.0 | 68.3$\\pm$0.9 | 69.7$\\pm$2.6 |\n| GRACE                         | 77.6$\\pm$1.1 | 64.1$\\pm$1.4 | 64.5$\\pm$1.7 |\n| GRACE$_{\\text{StructComp}}$   | 78.3$\\pm$0.8 | 69.1$\\pm$0.9 | 66.2$\\pm$2.4 |\n| CCA-SSG                       | 75.5$\\pm$1.3 | 69.1$\\pm$1.2 | 73.5$\\pm$2.2 |\n| CCA-SSG$_{\\text{StructComp}}$ | 78.2$\\pm$0.7 | 69.2$\\pm$0.8 | 76.3$\\pm$2.5 |"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700146607475,
                "cdate": 1700146607475,
                "tmdate": 1700307894115,
                "mdate": 1700307894115,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Eya4fcwoTx",
                "forum": "a4DBEeGfQq",
                "replyto": "ruxtljuUs1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer PXMh[2/3]"
                    },
                    "comment": {
                        "value": "**Q3:Would be great to discuss the approximation quality to the diffusion matrix of StructComp for more complicated graphs and other models architectures (like GAT, GraphSAGE).**\n\nIn order to verify the approximation quality to the diffusion matrix of StructComp, we test the performance on a deep GNN architecture called SSGC [1]. We transferred the trained parameters of StructComp to the SSGC encoder for inference. For full graph training in GCL, both the training and inference stages were performed using the SSGC encoder. Table 3 shows our experimental results, indicating that even with a deeper and more complicated encoder, StructComp still achieved outstanding performance. To the best of our knowledge, current mainstream GCL models, whether single-view models such as SCE, COLES, GLEN [2], or multi-view models such as DGI, GRACE, CCA-SSG, GGD, and their variants, all use SGC or GCN encoders. These unsupervised GCL models can achieve performance surpassing supervised GNNs (such as GAT, SAGE) with simple encoders on many datasets. Few GCL models have focused on whether using different encoders can achieve better performance. Moreover, GCL training is more complicated than supervised GNNs, so introducing complex encoders may make the models more difficult to train. Considering this, we did not extensively explore how using other encoders would affect StructComp. We believe this is a good question, and we will investigate it further in future work.\n\n\n\nTable 3: The results of GCLs with SSGC encoders over 50 random splits.\n\n| Method                        | Cora         | Citeseer     | Pubmed       |\n| ----------------------------- | ------------ | ------------ | ------------ |\n| SCE                           | 81.8$\\pm$0.9 | 72.0$\\pm$0.9 | 78.4$\\pm$2.8 |\n| SCE$_{\\text{StructComp}}$     | 82.0$\\pm$0.8 | 71.7$\\pm$0.9 | 77.8$\\pm$2.9 |\n| COLES                         | 81.8$\\pm$0.9 | 71.3$\\pm$1.1 | 74.8$\\pm$3.4 |\n| COLES$_{\\text{StructComp}}$   | 82.0$\\pm$0.8 | 71.6$\\pm$1.0 | 75.6$\\pm$3.0 |\n| GRACE                         | 80.2$\\pm$0.8 | 70.7$\\pm$1.0 | 77.3$\\pm$2.7 |\n| GRACE$_{\\text{StructComp}}$   | 81.1$\\pm$0.8 | 71.0$\\pm$1.0 | 78.2$\\pm$1.3 |\n| CCA-SSG                       | 82.1$\\pm$0.9 | 71.9$\\pm$0.9 | 78.2$\\pm$2.8 |\n| CCA-SSG$_{\\text{StructComp}}$ | 82.6$\\pm$0.7 | 71.7$\\pm$0.9 | 79.4$\\pm$2.6 |"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700146647736,
                "cdate": 1700146647736,
                "tmdate": 1700146647736,
                "mdate": 1700146647736,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qL0aDRugIx",
                "forum": "a4DBEeGfQq",
                "replyto": "ruxtljuUs1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer PXMh[3/3]"
                    },
                    "comment": {
                        "value": "**Q4:There is a lack of comparisons with certain related works, such as recent graph contrastive learning methods [1-2].**\n\nIt should be noted that the goal of these studies and our work are different. The aim of SPGCL is to handle homophilic graphs and heterophilic graphs simultaneously. BlockGCL attempts to explore the application of deep GNN encoder in the GCL field. On the other hand, StructComp is a framework designed to scale up the training of GCL models: it aims to efficiently train common GCL models without performance drop. It is not a new GCL model that aims to achieve  SOTA performance compared to existing GCL models. So our work is orthogonal to these two previous works. In fact, StructComp can be used as the training method for both SP-GCL and BlockGCL. In future work, we will further investigate how to train these recent graph contrastive learning methods using StructComp.\n\nIn terms of scalability, which is the main goal of our work, we have conducted extra experiments to compare SP-GCL, BlockGCL and StructComp-trained baseline. The results confirm that the aforementioned two GCL models are not designed for reducing training costs. \n\n\n\nTable 4: The results of StructComp-trained GCLs and some GCL baselines over 50 random splits. For SP-GCL, we are unable to get the classification accuracy on CiteSeer since it does not take isolated nodes as input.\n\n| Method                                                       | Cora Acc     | Cora Time | Cora Mem | CiteSeer Acc | CiteSeer Time | CiteSeer Mem | PubMed Acc   | PubMed Time | PubMed Mem |\n| ------------------------------------------------------------ | ------------ | --------- | -------- | ------------ | ------------- | ------------ | ------------ | ----------- | ---------- |\n| BlockGCL                                                     | 78.1$\\pm$2.0 | 0.026     | 180      | 64.5$\\pm$2.0 | 0.023         | 329          | 74.7$\\pm$3.1 | 0.037       | 986        |\n| SP-GCL                                                       | 81.4$\\pm$1.2 | 0.016     | 247      | -            | 0.021         | 319          | 74.8$\\pm$3.2 | 0.041       | 1420       |\n| SCE$_{\\text{StructComp}}$                                    | 81.6$\\pm$0.9 | 0.002     | 23       | 71.5$\\pm$1.0 | 0.002         | 59           | 77.2$\\pm$2.9 | 0.003       | 54         |\n| COLES$_{\\text{StructComp}}$                                  | 81.8$\\pm$0.8 | 0.002     | 24       | 71.6$\\pm$0.9 | 0.003         | 60           | 75.3$\\pm$3.1 | 0.003       | 61         |\n| GRACE$_{\\text{StructComp}}$                                  | 79.7$\\pm$0.9 | 0.009     | 37       | 70.5$\\pm$1.0 | 0.009         | 72           | 77.2$\\pm$1.4 | 0.009       | 194        |\n| CCA-SSG$_{\\text{StructComp}}$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; | 82.3$\\pm$0.8 | 0.006     | 38       | 71.6$\\pm$0.9 | 0.005         | 71           | 78.3$\\pm$2.5 | 0.006       | 85         |\n\n\n\n------------------------------------------------------------\n\nThe discussion of all the aforementioned issues will be added into the revised version of our paper. We appreciate your insightful feedback once again.\n\n\n\n[1]H. Zhu, and P. Koniusz. Simple spectral graph convolution. ICLR 2020.\n\n[2]H. Zhu, and P. Koniusz. Generalized Laplacian Eigenmaps. Neurips 2022."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700146698003,
                "cdate": 1700146698003,
                "tmdate": 1700146698003,
                "mdate": 1700146698003,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JAgh9E2Aia",
                "forum": "a4DBEeGfQq",
                "replyto": "ruxtljuUs1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A friendly reminder for discussion and we appreciate your input"
                    },
                    "comment": {
                        "value": "Dear Reviewer PXMh,\n\nWe thank you again for your insightful and constructive review. We have worked hard and have thoroughly addressed your comments in the rebuttal.\n\nAs the discussion period soon comes to an end, we are looking forward to your feedback to our response and revised manuscript. Many thanks again for your time and efforts.\n\nBest regards,\n\nAuthors of Submission 5510"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700469753275,
                "cdate": 1700469753275,
                "tmdate": 1700469753275,
                "mdate": 1700469753275,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6pIJMGLgXf",
                "forum": "a4DBEeGfQq",
                "replyto": "ruxtljuUs1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Extra experiments on more complicated graphs"
                    },
                    "comment": {
                        "value": "According to the suggestion from reviewer kF3D, we have conducted experiments to train SP-GCL with StructComp, in order to verify the performance of StructComp on heterophilous graphs. The experimental results are shown in Table 5. Overall, the SP-GCL trained by StructComp is superior to full graph training. This is our initial attempt to use StructComp to handle heterophilous graphs, and it is obviously a valuable direction worth further research.\n\nTable 5. The results on heterophilous datasets.\n|                              | Chameleon Acc  | Chameleon Time | Chameleon Mem | Squirrel Acc   | Squirrel Time | Squirrel Mem | Actor Acc      | Actor Time | Actor Mem |\n| ---------------------------- | -------------- | -------------- | ------------- | -------------- | ------------- | ------------ | -------------- | ---------- | --------- |\n| SP-GCL                       | 65.28$\\pm$0.53 | 0.038          | 739           | 52.10$\\pm$0.67 | 0.080         | 3623         | 28.94$\\pm$0.69 | 0.041      | 802       |\n| SP-GCL$_{\\text{StructComp}}$ | 66.65$\\pm$1.63 | 0.011          | 168           | 53.08$\\pm$1.39 | 0.009         | 217          | 28.70$\\pm$1.25 | 0.013      | 159       |"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700557340869,
                "cdate": 1700557340869,
                "tmdate": 1700557340869,
                "mdate": 1700557340869,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BmXkBzzX8f",
                "forum": "a4DBEeGfQq",
                "replyto": "ruxtljuUs1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5510/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A friendly reminder for discussion"
                    },
                    "comment": {
                        "value": "Dear Reviewer PXMh,\n\nThe rebuttal phase ends today and we have not yet received feedback from you. We believe that we have addressed all of your previous concerns. We would really appreciate that if you could check our response and updated paper.\n\nLooking forward to hearing back from you.\n\nBest Regards,\n\nAuthors"
                    }
                },
                "number": 27,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5510/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700702729854,
                "cdate": 1700702729854,
                "tmdate": 1700702729854,
                "mdate": 1700702729854,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]