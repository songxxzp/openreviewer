[
    {
        "title": "Explainable Multi-Objective Model Selection for Time Series Forecasting"
    },
    {
        "review": {
            "id": "zWpDMAEo9e",
            "forum": "4WRoRL0YKR",
            "replyto": "4WRoRL0YKR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2425/Reviewer_Sacq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2425/Reviewer_Sacq"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a novel method, X-PCR, for explainable mulit-objective model selection and uses it for time series forecasting. The contribution comes from several folds, 1) it is the first explainable and resource-aware model selection framework, 2) successfully applies it to the task of time series forecasting, 3) adequate experiments -- 1000 experiments across 114 data sets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper proposes a promising direction conducive to the democratization of machine learning methods. \nIt is novel to consider computing resources when designing the objective function for model selection. \nBesides the time series forecasting, X-PRC can be easily generalized for other learning tasks.\nThe authors conducted experiments under a large amount of data and experimental conditions."
                },
                "weaknesses": {
                    "value": "The details of the paper are not clear enough, such as how to describe the consumption of computing resources in PCR function.\nDoes different scales among multiple PCR functions cause problems for optimization?\nI have some concern about the efficiency of this method due to a exhaustive search.\nI don't particularly understand where the interpretability of the method is reflected. Can it give some evidenc or confidence interval of model selection results?"
                },
                "questions": {
                    "value": "The details of the paper are not clear enough, such as how to describe the consumption of computing resources in PCR function.\nDoes different scales among multiple PCR functions cause problems for optimization?\nI have some concern about the efficiency of this method due to a exhaustive search.\nI don't particularly understand where the interpretability of the method is reflected. Can it give some evidenc or confidence interval of model selection results?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2425/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2425/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2425/Reviewer_Sacq"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2425/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698403809047,
            "cdate": 1698403809047,
            "tmdate": 1699636177915,
            "mdate": 1699636177915,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kFL3HmerB1",
                "forum": "4WRoRL0YKR",
                "replyto": "zWpDMAEo9e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2425/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2425/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "- resource consumption was profiled via CodeCarbon, as mentioned in Sec 4\n- scaling of PCR functions is taken care of by relative index scaling, as explained in Sec 3.2\n- exhaustive search is not efficient at all, hence we only used it as a baseline approach for model selection\n- we explained why we understand our method as interpretable in Sec 3.4, and tried to exemplary show this practically in Fig 5\n\nIt is very frustrating to see copy-paste reviews like this (weaknesses & questions)"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2425/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700151203327,
                "cdate": 1700151203327,
                "tmdate": 1700151203327,
                "mdate": 1700151203327,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rGBwTtX9J9",
            "forum": "4WRoRL0YKR",
            "replyto": "4WRoRL0YKR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2425/Reviewer_m8sj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2425/Reviewer_m8sj"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed a method to estimate forecasting model\u2019s performance, complexity (number of parameters and model size)and resource consumption (training and inference time, power draw) based on dataset meta-features. Then the predicted numbers enable multi-objective selection based on a weighting of different objectives. The authors tested their method on Monash datasets and it beats competing approaches such as AutoML and achieves 85% of predictive performance at only 20% of the computation cost required for exhaustive search."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The resource aware perspective is interesting and relevant. The provided code repo and demo greatly improves reproducibility."
                },
                "weaknesses": {
                    "value": "The idea of using dataset meta-features to find good models for a new dataset is not new. It\u2019s been explored in many transfer HPO methods. The earliest work to me is [1] where the meta-features are used to find a good initialization HP. Many methods not based on meta-features are also proposed afterwards such as [2] (There is a long list in this field, just to give some examples on how early this idea has been explored). The difference to this work is 1) most of them do not focus on time series dataset and 2) they work on learning good hyperparameters instead of model choice.\n\nFollowing the above, the model choice is just the first step and the hyperparameters of the models play an important role in the final performance and resource consumption.\n\n[1] M. Feurer, J. T. Springenberg, and F. Hutter, \u201cUsing meta-learning to initialize bayesian optimization of hyperparameters,\u201d in ECAI workshop on Metalearning and Algorithm Selection (MetaSel), 2014, pp. 3\u201310\n\n[2] Wistuba, Martin, Nicolas Schilling, and Lars Schmidt-Thieme. \"Learning hyperparameter optimization initializations.\" 2015 IEEE international conference on data science and advanced analytics (DSAA). IEEE, 2015.\n\nThe other concern is the unnecessary complexity. For a fixed model, should the per-sample inference time and power draw be more or less the same? For those models in GluonTS, they have fixed context and prediction length and looking at the per-sample metric would make the usage of the predictor unnecessary. Also, why does the number of parameters and model size need to be predicted? They should be the same for all datasets. For the training time, why not also look at per-sample time? They should also be similar across the dataset. Finally, looking at Figure 6, predicting a model's performance based on the proposed dataset features seems the hardest and that\u2019s where we need to be the most accurate.\n\nIn the end, I think it makes more sense to compare to transfer or meta-learning AutoML methods in this setting. It\u2019s not a fair comparison in the current setting for AutoML."
                },
                "questions": {
                    "value": "PCR is only mentioned firstly at Section 3.1 and should be explained much earlier.\n\nHow do the authors come up with the weights in Table 1?\n\nThe resource consumption is evaluated on one hardware, how much of the conclusion can be generalized to other hardwares? Will the order of the models change on a different hardware?\n\nThe model is currently encoded as a one-hot vector, but the number layers, parameters etc. should be part of the input features rather than the property to be predicted."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2425/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698604049420,
            "cdate": 1698604049420,
            "tmdate": 1699636177826,
            "mdate": 1699636177826,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FbYxiKQX0e",
                "forum": "4WRoRL0YKR",
                "replyto": "rGBwTtX9J9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2425/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2425/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "### Regarding identified weaknesses:\n\n- We are thankful for the proposed related literature we missed out on, however - from a first look - they suffer from the same issue as the works discussed in Sec 2 - overly focusing on predictive capabilities.\n\n- Per-sample inference time and power draw are strongly correlated, but not necessarily the same, since different models might utilize the hardware more or less efficiently.\n\n- It is indeed true that predicting a model's predictive performance is hardest (as shown in Fig 6), however the point we want to make is that model selection and meta-learning should still consider resource trade-offs and efficiency.\n\n### Regarding questions: \n\n- The weights were selected to establish a good trade-off among all properties.\n- The other feedback shall be adressed in future work."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2425/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700150745167,
                "cdate": 1700150745167,
                "tmdate": 1700151241163,
                "mdate": 1700151241163,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "koW8TEyGje",
            "forum": "4WRoRL0YKR",
            "replyto": "4WRoRL0YKR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2425/Reviewer_4DT3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2425/Reviewer_4DT3"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an explainable model selection method, X-PCR to provide understandable and controllable recommendations of DNNs on time series forecasting tasks. X-PCR uses meta-learning to assess the suitability of any DNN in terms of (p)redictive error, (c)omplexity and (r)esource demand. X-PCR is tested on 114 data sets considering 11 DNNs. The experiment show X-PCR outperforms the random selection strategy and AutoKeras [1]\n\n[1]. Haifeng Jin, Qingquan Song, and Xia Hu. Auto-keras: An efficient neural architecture search system. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining, pp. 1946\u20131956, 2019."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The topic is interesting. The idea of designing a user-centric XAI framework is novel to some extent."
                },
                "weaknesses": {
                    "value": "I have lost the novelty of this study. The current claim that \"X-PCR is the first explainable and resource-aware model selection\" is not convincing as I didn't see a clear motivation for designing an explainable and resource-aware model selection method. \n\nThe proposed idea lacks support from my perspective. For example, how the authors determine to choose the three aspects of (p)redictive error, (c)omplexity and (r)esource demand. Are they from a survey from practice or from the existing literature review?\n\nAs X-PCR is a model selection method, it is compared to a random model selection strategy but not another model selection strategy. Therefore, it is unclear how efficient X-PCR on model selection."
                },
                "questions": {
                    "value": "Why use AutoKeras as the baseline method? If you think the NAS system can be the baseline why not use the SOTA method that is specifically designed for time series such as [2]?\nWhy not compare X-PCR to other model selection methods?\n\n[2] Lyu, Zimeng, and Travis Desell. \"ONE-NAS: an online neuroevolution based neural architecture search for time series forecasting.\" Proceedings of the Genetic and Evolutionary Computation Conference Companion. 2022."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2425/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698842401084,
            "cdate": 1698842401084,
            "tmdate": 1699636177752,
            "mdate": 1699636177752,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "V2YPToxC4L",
                "forum": "4WRoRL0YKR",
                "replyto": "koW8TEyGje",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2425/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2425/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "### Comments regarding identified weaknesses:\n\n- \"clear motivation for designing an explainable and resource-aware model selection method\" was given in Sec 2.3, based on extensive related work\n\n- the three focused aspects were proposed based on personal experience and related work\n\n\n### Regarding questions:\n\n- AutoKeras was chosen because autoML is another approach to model selection\n- It is not feasible to test and compare ourselves with the suggested method [2], as it does not come with public implementation"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2425/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700150282695,
                "cdate": 1700150282695,
                "tmdate": 1700151285864,
                "mdate": 1700151285864,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]