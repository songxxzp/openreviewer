[
    {
        "title": "SITReg: Multi-resolution architecture for symmetric, inverse consistent, and topology preserving image registration using deformation inversion layers"
    },
    {
        "review": {
            "id": "xtF1k5DwrO",
            "forum": "gfh8ZbSlyf",
            "replyto": "gfh8ZbSlyf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3299/Reviewer_eYpy"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3299/Reviewer_eYpy"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a deep learning-based approach to deformable image registration, which enforces symmetry, inverse consistency, and topology preservation. In contrast to previous approaches, which enforce these constraints via loss functions, the approach proposed here achieves this via construction. Additionally, the paper uses a multi-resolution feature representation for image registration. The approach is evaluated on the tasks of inter-subject brain MR registration, evaluated on the LPBA40 and Oasis datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper addresses an important topic in biomedical image analysis. Developing robust and reliable methods for image registration is still an unsolved problem. The paper contains a good summary of the state-of-the-art in terms of previous publications. Similarly, the proposed method is compared against a number of strong baselines, including VoxelMorph, SYMNet and cLapIRN."
                },
                "weaknesses": {
                    "value": "The symmetric formulation proposed in section 3.1 seems not entirely new. Indeed, the authors acknowledge this by stating that a similar approach has been used in recent registration methods (Estienne et al., 2021; Young et al., 2022). The multi-resolution formulation proposed in section 3.2 seems rather natural (also in the symmetric setting), so I am unclear on how this is different from standard multi-resolution formulations, which are ubiquitous in image registration settings. \n\nThe evaluation of the registration accuracy is limited to the assessment of Dice overlap and Hausdorff distance after registration. It would have been good if the authors had used some additional non-brain datasets which have landmarks (e.g. lung CT images from the EMPIRE10 challenge) and thus allow the calculation of quantities such as the target registration error. Furthermore, the improvements in registration accuracy seem rather than marginal. No visual examples of the registrations are provided."
                },
                "questions": {
                    "value": "- What is the key novelty in section 3.2? How is this different from the traditional multi-resolution (except the symmetric formulation)?\n- Can you comment on the significance of the improvement of the registration results?\n- The advantage of symmetry and inverse consistency over loss-based approaches is not clear, as all methods seem to provide symmetric and inverse consistent registrations apart from numerical accuracy. Can you comment on this?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3299/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698787491588,
            "cdate": 1698787491588,
            "tmdate": 1699636278954,
            "mdate": 1699636278954,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NcdN6kgTyh",
                "forum": "gfh8ZbSlyf",
                "replyto": "xtF1k5DwrO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**The symmetric formulation proposed in section 3.1 seems not entirely new. Indeed, the authors acknowledge this by stating that a similar approach has been used in recent registration methods (Estienne et al., 2021; Young et al., 2022).**\n\nIt is true that Estienne et al. (2021) propose a by construct symmetric network. However,  their formulation is clearly different from the ideas in Section 3.1, and does not guarantee inverse or cycle consistency by construct. The method by Young et al. (2022) does not employ any approach close to our symmetric formulation, and we rather referred to it due to its similar multi-resolution feature extraction approach.\n\n**What is the key novelty in section 3.2? How is this different from the traditional multi-resolution (except the symmetric formulation)?**\n\nWe agree that the principle itself behind the multi-resolution approach is rather standard and we have not claimed otherwise in our article.\n\nThe main challenge with the multi-resolution approach was to make it computationally feasible for large volumetric data (as in image registration). For that, we developed the new implicit deformation inversion layer (which can have impact outside this subfield) which uses 5 times less memory than implementing the same idea in the SVF framework. Also, designing the deformation prediction networks $u^{(k)}$ to output deformations invertible by the deformation inversion layer required non-trivial mathematical work of obtaining the optimal invertibility bounds (Appendix E).\n\nThe idea of first extracting features independently in multiple resolutions using a ResNet encoder and then using those features to gradually update the deformation is also partially new. While Young et al. (2022) proposed a similar architecture, in our architecture the information flows back from the lower to the higher resolution levels only through the deformations, as opposed to their heavier U-net style approach.\n\n**Can you comment on the significance of the improvement of the registration results?**\n\nPlease refer to the global response for a detailed clarification on why we believe there is a clear improvement compared to the baselines.\n\nRegarding statistical significance, this is indicated in Tables 1 and 2 with an asterisk, and it was calculated using a permutation test (explained in Appendix K). This obviously does not yet guarantee ultimate clinical significance, but showing that would be clearly beyond the scope of our paper (or a single ICLR paper in more general).\n\n**The advantage of symmetry and inverse consistency over loss-based approaches is not clear, as all methods seem to provide symmetric and inverse consistent registrations apart from numerical accuracy. Can you comment on this?**\n\nWhile it may seem that cycle consistency loss is small for all of the methods, the improvement of two magnitudes by our method compared to the baselines is actually visually very significant. This is now well demonstrated in Figure 6 of Appendix H in the updated manuscript.\n\nAs for inverse consistency, the performance of SYMNet is indeed very good, and we only claim to achieve similar performance in this metric. That is visually demonstrated in the new Figure 7 of Appendix H."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3299/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700062091079,
                "cdate": 1700062091079,
                "tmdate": 1700120008714,
                "mdate": 1700120008714,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jjSp1qk5Gt",
                "forum": "gfh8ZbSlyf",
                "replyto": "xtF1k5DwrO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We once more thank Reviewer eYpy for their questions and comments. We hope our clarifications about the novelty of our work, and why we believe our method brings a clear improvement compared to the baselines, have thoroughly answered the main questions of the reviewer. Please let us know if any additional clarifications would be useful for strengthening the initial positive perception of our article."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3299/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700661331750,
                "cdate": 1700661331750,
                "tmdate": 1700661331750,
                "mdate": 1700661331750,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3iVbi45Xs3",
                "forum": "gfh8ZbSlyf",
                "replyto": "jjSp1qk5Gt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3299/Reviewer_eYpy"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3299/Reviewer_eYpy"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response to the comments raised. As I and the other reviewers have pointed out, there is a lot of prior work on exactly this topic and the discussion of the differences of the methods is still weak."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3299/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700667520711,
                "cdate": 1700667520711,
                "tmdate": 1700667520711,
                "mdate": 1700667520711,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TovMGFqz4f",
                "forum": "gfh8ZbSlyf",
                "replyto": "xtF1k5DwrO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank the reviewer for highlighting this aspect the would benefit from additional clarifications. To address this, we have written a new _Appendix G: Related work_, whose __length is approximately 2.5 pages__, which in detail explains the methods found in literature that are closest to our work or otherwise relevant to it. The Appendix G consists of four subsections _G.1 Classical registration methods_, _G.2 Deep Learning Methods (Earlier work)_, _G.3 Deep Learning Methods (Recent Methods Parallel To Our Work)_, and _G.4 Novel aspects of our method_.\n\nWe hope that this new, thorough and detailed discussion clarifies the position of our work with respect to existing literature, highlights the differences, and makes it clear what the novel aspects of our method are compared to the alternatives."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3299/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700739335944,
                "cdate": 1700739335944,
                "tmdate": 1700739335944,
                "mdate": 1700739335944,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "XzX9JtUsuC",
            "forum": "gfh8ZbSlyf",
            "replyto": "gfh8ZbSlyf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3299/Reviewer_2iyN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3299/Reviewer_2iyN"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers the deformable medical image registration with symmetric, inverse consistent, and topology-preserving properties, which is achieved by construction via a multi-resolution deep neural network. The proposed method is compared with three existing methods, i.e., SYMNet, VoxelMorph, and cLapIRN. The experimental results demonstrate the effectiveness of the proposed approach."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper works on an interesting research problem. It integrates existing strategies to achieve all the symmetric, inverse consistent, and topology-preserving properties in one network using an end-to-end training."
                },
                "weaknesses": {
                    "value": "1. Insufficient study on related work. Unlike what is stated in the paper, the LDDMM method has been used in deep learning, such as DeepFlash[1], NODEO[2], R2Net[3], etc. Also, the inverse consistency by construction using multistep deep registration [4], which is quite close to this paper, is missing in the related work and experimental comparison. \n\n[1] Wang and Zhang, DeepFLASH: An Efficient Network for Learning-based Medical Image Registration, CVPR 2020. \n[2] Wu et al., Nodeo: A neural ordinary differential equation based optimization framework for deformable image registration, CVPR 2022. \n[3] Joshi and Hong, R2Net: Efficient and flexible diffeomorphic image registration using Lipschitz continuous residual networks, Medical Image Analysis, 2023. \n[4] Greer et al., Inverse Consistency by Construction for Multistep Deep Registration, MICCAI 2023. \n\n2. Unclear presentation with unexplained statements. Such as, 1) \"However, SYMNet does not guarantee symmetricity by construct\", why? How to draw this conclusion? 2) Denoting the feature extraction network by h, how is this feature extraction network designed? Do we need to pretrain it or train together with the following network? 3) Squaring and scaling are not enough to guarantee the diffeomorphic property of deformations, we need an additional loss term or strategies to enforce the smoothness of the initial velocity fields first. However, this paper uses the same loss term on the smoothness of deformations in non-diff VoxelMorph, is it a reasonable choice? \n\n3. Insufficient experimental results. This paper should compare the two most related works, i.e., [Iglesias 2023] that is mentioned in the introduction and the above [Greer 2023] that is missing in the paper, and some traditional methods, like SyN in ANTs and Symmetric LDDMM. Also, can you show more qualitative results to demonstrate the improvement of the proposed method and analyze the contribution of each design accordingly? \n\n4. All the strategies used in this paper are what were used before, so, what are the challenges of this work? Is it necessary to have such a complicated network in practice?"
                },
                "questions": {
                    "value": "Please check the weakness section for the questions."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3299/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698890756850,
            "cdate": 1698890756850,
            "tmdate": 1699636278882,
            "mdate": 1699636278882,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ViQQ67gBix",
                "forum": "gfh8ZbSlyf",
                "replyto": "XzX9JtUsuC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Insufficient study on related work. Unlike what is stated in the paper, the LDDMM method has been used in deep learning, such as DeepFlash[1], NODEO[2], R2Net[3], etc.**\n\nWe do not claim in the paper that LDDMM has not been used in deep learning at all but instead that it has not been used much due to its computational cost. The methods you proposed, although interesting, do not qualify as examples of applying the diffeomorphic LDDMM in deep learning in our setup. In more detail:\n\n- DeepFlash does not involve optimization over diffeomorphisms. Instead, it uses initial velocity fields generated by a traditional LDDMM method as the optimization targets. Hence, it is not applicable to our unsupervised setting.\n- NODEO is a very interersting method but to mitigate computational cost it has to do significant modifications to the default LDDMM framework and as a result it actually loses the by construct diffeomorphic properties. To achieve invertibility they have to use a separate loss function on the Jacobian determinants (Equation 10).\n- R2Net, similarily to NODEO, has to make simplications to the theoretical LDDMM framework. As a result, it does not guarantee diffeomorphisms by construct, but instead applies a loss function on the Jacobian determinants to enforce that (Equation 10)."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3299/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700061880752,
                "cdate": 1700061880752,
                "tmdate": 1700061880752,
                "mdate": 1700061880752,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "B4gKEedC6Y",
                "forum": "gfh8ZbSlyf",
                "replyto": "XzX9JtUsuC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Also, the inverse consistency by construction using multistep deep registration [4], which is quite close to this paper, is missing in the related work and experimental comparison.**\n\nThe paper by Greer et al. (2023) is an interesting work independent of ours. It was published after the submission deadline of ICLR, and hence it was not discussed in our paper. We now included it in the related work section of the revised version."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3299/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700061897790,
                "cdate": 1700061897790,
                "tmdate": 1700061897790,
                "mdate": 1700061897790,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Y5gTOT2bEb",
                "forum": "gfh8ZbSlyf",
                "replyto": "XzX9JtUsuC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**1) \"However, SYMNet does not guarantee symmetricity by construct\", why? How to draw this conclusion?**\n\nOur statement simply reflects the fact that, while its optimization target is symmetric, there is nothing in the SYMNet architecture that would directly enforce the predictions to be symmetric. That is also experimentally shown by the cycle consistency metric results, and in the new Figure 6 (Appendix H). We added a reference to the figure in the text."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3299/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700061915045,
                "cdate": 1700061915045,
                "tmdate": 1700061915045,
                "mdate": 1700061915045,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yZ3MKNgz1T",
                "forum": "gfh8ZbSlyf",
                "replyto": "XzX9JtUsuC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**2) Denoting the feature extraction network by h, how is this feature extraction network designed? Do we need to pretrain it or train together with the following network?**\n\nWe explain the design in the beginning of Section 3.2: \"in practice h is a ResNet (He et al., 2016) style convolutional network and features at each resolution are extracted sequentially from previous features.\" No pretraining is used."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3299/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700061925939,
                "cdate": 1700061925939,
                "tmdate": 1700061925939,
                "mdate": 1700061925939,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xGAFMgv7kn",
                "forum": "gfh8ZbSlyf",
                "replyto": "XzX9JtUsuC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**3) Squaring and scaling are not enough to guarantee the diffeomorphic property of deformations, we need an additional loss term or strategies to enforce the smoothness of the initial velocity fields first. However, this paper uses the same loss term on the smoothness of deformations in non-diff VoxelMorph, is it a reasonable choice?**\n\nIt is true that both our method and the non-diff VoxelMorph apply the same loss on deformations to enforce smoothness. However, even if VoxelMorph is not diffeomorphic, our method still is, and this is guaranteed by the architectural constraints (Theorem 3.3)."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3299/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700061935282,
                "cdate": 1700061935282,
                "tmdate": 1700061935282,
                "mdate": 1700061935282,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pAylK2Re7c",
                "forum": "gfh8ZbSlyf",
                "replyto": "XzX9JtUsuC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**This paper should compare the two most related works, i.e., [Iglesias 2023] that is mentioned in the introduction and the above [Greer 2023] that is missing in the paper, and some traditional methods, like SyN in ANTs and Symmetric LDDMM.**\n\nBoth of these works are very recent, parallel with, and independent of our work. According to the ICLR reviewer guide, an empirical comparison with such methods is not expected. We have nevertheless included our updated paper to include references to these (Iglesias was included already before). SyN, on the other hand, is extremely slow (ANTs implementation ~30 min per one registration), and it has already been compared against our strong baselines with in general worse performance (Balakrishnan et al., 2019; Mok & Chung,\n2020a;b). Hence, including it here would be both challenging and not expected to bring additional value."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3299/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700061957738,
                "cdate": 1700061957738,
                "tmdate": 1700061957738,
                "mdate": 1700061957738,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "H3lK54Z4Wx",
                "forum": "gfh8ZbSlyf",
                "replyto": "XzX9JtUsuC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Also, can you show more qualitative results to demonstrate the improvement of the proposed method and analyze the contribution of each design accordingly?**\n\nWe updated the paper by including Appendix H, which demonstrates the imporovements in deformation regularity (Figure 5) and cycle consistency (symmetricity) (Figure 6), and showcases similar performance to SYMNet in inverse consistency (Figure 7).\n\nIn short, our symmetric formulation ensures symmetricity, and together with the topology preserving design of the deformation prediction networks $u^{(k)}$, it ensures also inverse consistency and cycle consistency. Deformation regularity is also ensured by the latter. The multi-resolution architecture is required to achieve good tissue overlap metric performance."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3299/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700061972981,
                "cdate": 1700061972981,
                "tmdate": 1700061972981,
                "mdate": 1700061972981,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xqp2EGhzet",
                "forum": "gfh8ZbSlyf",
                "replyto": "XzX9JtUsuC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**All the strategies used in this paper are what were used before, so, what are the challenges of this work? Is it necessary to have such a complicated network in practice?**\n\nMultiple works in the past have tried to enforce one or all of the properties (symmetricity, inverse consistency, topology preservation), either by a loss function or by construct. However, only classical iterative registration algorithms have enforced all of them by construct, see e.g. Ashburner (2007) or Avants et al. (2008). There papers are very highly cited (~8000 and ~5000 citations), and their main point is exactly proposing a method which fulfills the properties by construct. The challenge we set out to tackle was to develop the first such method in the deep learning setting.\n\nTo summarize, our novel methodological innovations were the trick to make the method symmetric (Section 3.1) and the new implicit deformation inversion layer (with potential impact outside this subfield), which uses 5 times less memory, making it feasible to apply the multi-resolution architecture for the large volumetric data in image registration. The work also involves non-trivial mathematical work of obtaining the optimal invertibility bounds (Appendix E). We showed how to integrate these innovations with well-established architectural building blocks for a method whose overall performance exceeded that of the existing methods. (To clarify, our innovations could be integrated with simpler networks to ensure the desirable properties, but for sota performance the best available building blocks need to be adopted, hence the \"complexity\".)"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3299/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700061985962,
                "cdate": 1700061985962,
                "tmdate": 1700061985962,
                "mdate": 1700061985962,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "27W9N4Rle9",
                "forum": "gfh8ZbSlyf",
                "replyto": "XzX9JtUsuC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## References\n\n- Arsigny, Vincent, et al. \"A log-euclidean framework for statistics on diffeomorphisms.\" Medical Image Computing and Computer-Assisted Intervention\u2013MICCAI (2006)\n- Mok, Tony CW, and Albert Chung. \"Fast symmetric diffeomorphic image registration with convolutional neural networks.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.\n- Mok, Tony CW, and Albert CS Chung. \"Large deformation diffeomorphic image registration with laplacian pyramid networks.\" Medical Image Computing and Computer Assisted Intervention\u2013MICCAI 2020: 23rd International Conference, Lima, Peru, October 4\u20138, 2020, Proceedings, Part III 23. Springer International Publishing, 2020.\n- Mok, Tony CW, and Albert CS Chung. \"Conditional deformable image registration with convolutional neural network.\" Medical Image Computing and Computer Assisted Intervention\u2013MICCAI 2021: 24th International Conference, Strasbourg, France, September 27\u2013October 1, 2021, Proceedings, Part IV 24. Springer International Publishing, 2021.\n- Hering, Alessa, et al. \"Learn2Reg: comprehensive multi-task medical image registration challenge, dataset and evaluation in the era of deep learning.\" IEEE Transactions on Medical Imaging 42.3 (2022): 697-712.\n- Joshi, Ankita, and Yi Hong. \"R2Net: Efficient and flexible diffeomorphic image registration using Lipschitz continuous residual networks.\" Medical Image Analysis 89 (2023): 102917."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3299/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700061996243,
                "cdate": 1700061996243,
                "tmdate": 1700061996243,
                "mdate": 1700061996243,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "eznekwLJ8a",
                "forum": "gfh8ZbSlyf",
                "replyto": "XzX9JtUsuC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We again thank Reviewer 2iyN for their time and suggestions. We hope our responses have been useful in clarifying the concerns. Please let us know if there are any other questions and we are happy provide additional clarifications. If the reviewer finds our replies satisfactory, can they please consider updating their rating?"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3299/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700660840020,
                "cdate": 1700660840020,
                "tmdate": 1700660840020,
                "mdate": 1700660840020,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "nFfX6xXiGs",
            "forum": "gfh8ZbSlyf",
            "replyto": "gfh8ZbSlyf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3299/Reviewer_nQ7w"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3299/Reviewer_nQ7w"
            ],
            "content": {
                "summary": {
                    "value": "This paper is about a new deformable image registration method which is able to extract multi-resolution features that are symmetric, inverse consistent, and topology-preserving. The new framework is new and symmetric and inverse consistent by construct. Based on the deep equilibrium network framework, a new deformation inversion layer is proposed."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is well written with good introduction and descriptions of symmetric, inverse consistent, and topology-preserving registration methods. \n\nThe proposed DL architecture is inverse consistent and symmetric by construct, rather than by using loss functions. \n\nThe use of deformation inversion layers seems interesting, based on the deep equilibrium network framework."
                },
                "weaknesses": {
                    "value": "Although the new framework is interesting, as listed in Table 2, the accuracy improvement is not significant. \n\nAs shown in Table 3, the computation efficiency and memory usage have not improved."
                },
                "questions": {
                    "value": "1.\tIn Figure 1, the images x_1 and x_2 are not defined previously and are unclear to me.\n\n2.\tCannot find Figure 3.2 in Section 3.2\n\n3.\tIs the image registration framework diffeomorphic?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N.A."
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3299/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699093663304,
            "cdate": 1699093663304,
            "tmdate": 1699636278796,
            "mdate": 1699636278796,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Ytu69zqo6L",
                "forum": "gfh8ZbSlyf",
                "replyto": "nFfX6xXiGs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your comments, and especially for acknowledging that the proposed deformation inversion layer is interesting, which we believe might even have a wider impact outside this particular subfield.\n\n**Although the new framework is interesting, as listed in Table 2, the accuracy improvement is not significant.**\n\nWhile it is true that the accuracy improvement based on the tissue overlap metrics alone is not very large (although statistically significant) compared to one of the baselines (cLapIRN), the significance lies in the fact that our method achieves the accuracy with significantly more regular deformations. We added a new figure to the appendix to demonstate that visually (Figure 5, Appendix H).\n\nFor a more detailed response on our results, which we actually believe showcase a significant improvement compared to the baselines, please see the global response.\n\n## Questions\n\n**In Figure 1, the images x_1 and x_2 are not defined previously and are unclear to me.**\n\nThanks for spotting this typo. We fixed it in the updated version.\n\n**Cannot find Figure 3.2 in Section 3.2**\n\nThe intended reference was Figure 2 but it was shown incorrectly due to a mistake in latex syntax. It has been fixed in the updated version.\n\n**Is the image registration framework diffeomorphic?**\n\nYes, Theorem 3.3 proves that the architecture is topology preserving (invertible), and smoothness is guaranteed by the B-spline representation (Appendix I)."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3299/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700062049221,
                "cdate": 1700062049221,
                "tmdate": 1700062179154,
                "mdate": 1700062179154,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Ty8wtzkSs7",
                "forum": "gfh8ZbSlyf",
                "replyto": "nFfX6xXiGs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3299/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We again thank the Reviewer nQ7w for their time and suggestions. Our joint response clarifies why we believe there is a clear improvement in the results compared to the baselines. Also, we've explained how the 5x memory saving in the deformation inversion layer is essential to apply the multi-resolution registration (please see our reply to eYpy). We cordially ask the reviewer to consider increasing their score, if they are satisfied with our replies. We are still happy to provide additional clarifications."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3299/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700660473028,
                "cdate": 1700660473028,
                "tmdate": 1700660473028,
                "mdate": 1700660473028,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]