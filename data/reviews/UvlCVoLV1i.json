[
    {
        "id": "n5sVlxzsgT",
        "original": null,
        "number": 1,
        "cdate": 1666447706250,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666447706250,
        "tmdate": 1666447706250,
        "tddate": null,
        "forum": "UvlCVoLV1i",
        "replyto": "UvlCVoLV1i",
        "invitation": "ICLR.cc/2023/Conference/Paper2333/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes approach that enables simple hyperparameter search in scenarios where either label information is delayed or when the training on full dataset is too costly.  The paper proses to use an auxiliary neural network to predict missing labels and a method to search for probable dataset to select a subset of data to use for training. The proposed solutions are tested on three datasets (Air, WormMotion, HandMEG) and compared to two baselines \u2013 the results show that the introduced methods outperform baselines.",
            "strength_and_weaknesses": "Strengths:\nThe idea of predicting model hyperparameters is interesting\n\nWeaknesses (for details, see section below):\nThe paper is very difficult to follow\nThe validation is limited\nLack of comparisons to previous works.\nLimitations are not discussed\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: \nThe paper is very difficult to follow. The current presentation makes it really hard to assess the paper properly. The reviewer encourages the authors to rewrite the paper focusing on presentation clarity. Below are some suggestions.\n\n\u2022\tAbstract, it is unclear what the term \u201cprobable dataset\u201d. Please clarify. \n\n\u2022\tIntroduction. Introduction should contain at least clear answers to the following questions: (1) What the authors try to achieve? (2) Why the authors try to achieve it? (3) How the authors try to achieve it? (4) What are the contributions of the paper? (5) What is the impact of the paper on the research community?\n\n\u2022\tPositioning to previously published methods. The introduction does not position the work well w.r.t. previous art. Please position the proposed method w.r.t. previous art it the introduction.\n\n\u2022\tFigure 1. Caption should be auto-explanatory. Please extend the text of the caption to simplify the understanding of the figure.\n\n\u2022\tEvaluation metric. It is unclear why the AES metric is the proper metric to compare models.\n\n\u2022\tEvaluation datasets. The chosen evaluation datasets are rather not commonly used in the ML community. Could the authors comment on why these datasets have been chosen?\n\n\u2022\tEvaluation. The model is only compared to two baselines CP and SPD. How would the model compare previously published methods for hyperparameter model prediction (e.g., the ones mentioned in the related work section)?\n\n\u2022\tTable 1. Please add standard deviation estimates over multiple random seeds.\n\n\u2022\tWhat are the limitations of the proposed pipeline?\n\n\nQuality and Novelty:\nThe quality and novelty of the paper are hard to assess due to presentation clarity. The experimental validation looks rather poor \u2013 no comparison to previous methods, the evaluation is performed on rather simple datasets. The limitations of the proposed approach are not discussed. The model uses simple and standard machine learning techniques, this the individual blocks does not have novelty; however, the overall pipeline could have some aspects of novelty that are obscured with current presentation.\n\nReproducibility:\nThere is no mentioning about code release. The pipeline components look rather simple and thus the whole pipeline should be reproducible. \n",
            "summary_of_the_review": "Overall, the paper studies an interesting problem of model hyperparameter prediction on uncertain data. However, the paper have several important weaknesses that makes it hard to recommend the paper for acceptance: (1) the presentation of the paper is very difficult to follow, (2) the evaluation is rather weak, (3) the paper is not properly positioned w.r.t. previous art.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2333/Reviewer_Au4D"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2333/Reviewer_Au4D"
        ]
    },
    {
        "id": "sQgE3V_Pa4",
        "original": null,
        "number": 2,
        "cdate": 1666654610712,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666654610712,
        "tmdate": 1666654610712,
        "tddate": null,
        "forum": "UvlCVoLV1i",
        "replyto": "UvlCVoLV1i",
        "invitation": "ICLR.cc/2023/Conference/Paper2333/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper tries to adjust hyper parameters in two types of uncertain dataset information: 1) dataset labels are postponed to be obtained so hyper parameters need to be adjusted without complete dataset information. 2) hyper parameters are adjusted with a subset training dataset since training models with complete training dataset is time consuming. More specifically, this paper proposes several loss functions to search for probable dataset when the complete dataset information is not obtained. The authors conduct experiments on 9 real world datasets to demonstrate the performance of the proposed method.",
            "strength_and_weaknesses": "**Strengths**:\n\n1. This paper proposes an interesting task: to adjust hyper parameters under different uncertain dataset information settings.\n\n2. The paper proposes several losses to search for probable dataset when the complete dataset information is missing.\n\n3. The paper conducts experiments on multiple real world datasets.\n\n**Weaknesses**:\n\n1. It\u2019s not very clear to me how to train the AR-D. The paper mentions that \u2018we let the dataset regression function architecture AR-D be the same with AR-A in $L_{R2}$ since we want to search for the dataset that AR-A performs well and a dataset with architecture AR-A should best fit the AR-A model.\u2019 Initializing AR-D with the parameters of pertain AR-A? Otherwise, if only using the same architecture, is there a guarantee that the AR-A will perform better than AR-B? \n\n2. The experimental part is limited. In the current version, only classification tasks on small datasets have been conducted. I would expect more strong experimental results to support the main claim of the paper. For example, how does the proposed probable dataset searching strategy affect more complex tasks with much bigger datasets?\n\n3. The AES evaluation metric (Eq.8) is not well justified/motivated. How to determine the weights of \u2018Wrong\u2019 and \u2018Training\u2019?\n\nMinors:\n\n1. I would suggest remaking figure.1 to improve the figure quality.\n\n2. Eq. equation 1 -> Eq.1.\n\n3. A few typos: \n\n  * Page 6, paragraph CP, \u2018always make type 3 prediction\u2019 -> \u2018always makes type 3 prediction\u2019.\n  \n  * Page 6, paragraph SDP 1, \u2018will also performs well\u2019 -> \u2018will also perform well\u2019.\n  \n  * Page 6, paragraph SDP 1, try to be consistent to use dataset 1 or data 1.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The method part is clear while I find it kind of diffucult to follow the experimental section.\n\nQuality: This paper contributes some new ideas but the empirical evaluation is limited.\n\nNovelty: The proposed idea is somehow interesting.\n\nReproducibility: With the current version, I might feel it's not easy to reproduce the main resutls of this paper as some of the details are missing.",
            "summary_of_the_review": "Overall, this paper contributes some new ideas but the empirical evaluation is limited. Also, the presentation needs to be improved.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2333/Reviewer_xHNU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2333/Reviewer_xHNU"
        ]
    },
    {
        "id": "KnFpG-6vTN3",
        "original": null,
        "number": 3,
        "cdate": 1666681197935,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666681197935,
        "tmdate": 1666681197935,
        "tddate": null,
        "forum": "UvlCVoLV1i",
        "replyto": "UvlCVoLV1i",
        "invitation": "ICLR.cc/2023/Conference/Paper2333/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper mainly discusses adjusting hyper parameters in two types of uncertain dataset information, including the postponed dataset labels and only using a subset training dataset. To infer the probable complete dataset information, this paper presents a probable dataset searching method that searches the variables in our dataset representation. Experimental results have been conducted on 9 real-world data with two types of uncertain dataset information. ",
            "strength_and_weaknesses": "Strength:\n(1) To deal with the uncertain information in a dataset, this paper proposes a probable dataset searching method to predict architecture comparison.\n(2) Different experimental settings are studied, and the authors validate the performance of the proposed method in 9 real-world data with two types of uncertain dataset information. \n\nWeakness:\n(1) This paper utilizes a neural network to approximate the dataset regression function and apply several loss functions to search for the probable dataset. In this case, the authors adopt several existing technologies, so the technical contribution is weak.\n(2) The authors state that they propose a probable dataset searching method to predict architecture comparison. However, many SOTA methods are missing in the comparison experiments. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The manuscript is written in a fairly clear fashion. The major concern is that the methodological contribution is weak. ",
            "summary_of_the_review": "This paper mainly discusses adjusting hyper parameters in two types of uncertain dataset information, including the postponed dataset labels and only using a subset training dataset. However, the overall technical novelty should be strengthed and more related SOTA comparisons are needed. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2333/Reviewer_d4iE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2333/Reviewer_d4iE"
        ]
    }
]