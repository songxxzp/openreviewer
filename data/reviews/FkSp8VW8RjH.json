[
    {
        "id": "JOWlxyxa4G",
        "original": null,
        "number": 1,
        "cdate": 1666316191153,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666316191153,
        "tmdate": 1666316221872,
        "tddate": null,
        "forum": "FkSp8VW8RjH",
        "replyto": "FkSp8VW8RjH",
        "invitation": "ICLR.cc/2023/Conference/Paper2584/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "## Overview\nIn this paper, PIXEL, a pixel-based encoder of language is introduced to circumvent the vocabulary bottleneck problem. PIXEL is built on ViT-MAE and is pretrained on the same corpus as BERT. Specifically, the authors proposed to render text onto blank images and patchify raw pixels into image tokens and masking 25% of the tokens. Following He et al. (2022), the author then trained PIXEL by using a decoder to reconstruct the masked pixels of the input images. The authors evaluated PIXEL on syntactic and semantic tasks in typologically diverse languages and demonstrated its robustness to orthographic attacks and linguistic code-switching. Although the downstream performance is falling short comparing with BERT and mBERT, the proposed method shows its novelty and potential by providing a new view of tackling the vocabulary bottleneck problem in both mono-lingual and multi-lingual setting. \n\n",
            "strength_and_weaknesses": "## Strength\n- Avoid vocabulary bottleneck problem.\n- Show more robustness to orthographic attacks and code-switching\n- Perform better on non-Latin languages on syntactic tasks and semantic tasks comparing to Bert.\n- Demonstrate the possibility of pixel-based language model without injecting a priori glyph knowledge.\n\nWeaknesses\n- Average performance on downstream tasks still lags far behind Bert and mBert.\n- Data preprocessing (text rendering) is tricky and laborious and will cause inevitable latency in real application.\n- The generated text pixels during pretraining is blurred and fuzzy which makes the model learning less explainable.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally well-written.\n\nQuestions\n- For word level tasks in Latin, how to you think that a word might be splitted into two patches?\n- It would be interesting if the authors could provide some examples(cases) or any other possible ways to better illustrate how it avoids the vocabulary bottleneck problem (especially in non-Latin languages). \n- The authors claimed \u201cPIXEL is more robust than BERT to orthographic attacks and linguistic code-switching\u201d. However, \u201cin lexical code-switching experiments, PIXEL performs on-par with BERT\u201d. Also, in Table 5, it seems we cannot conclude that \u201cPIXEL is more robust than BERT to linguistic code-switching\u201d.",
            "summary_of_the_review": "Although it might be not that useful, I like this idea and it gives a new perspective  for text representation",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2584/Reviewer_2dJC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2584/Reviewer_2dJC"
        ]
    },
    {
        "id": "skNE86so_OZ",
        "original": null,
        "number": 2,
        "cdate": 1666399787097,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666399787097,
        "tmdate": 1666399787097,
        "tddate": null,
        "forum": "FkSp8VW8RjH",
        "replyto": "FkSp8VW8RjH",
        "invitation": "ICLR.cc/2023/Conference/Paper2584/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, authors proposed a new methodology by rendering text as images, making it possible to transfer representations across languages based on orthographic similarity or the co-activation of pixels. The pre-trained step is learning reconstructing the pixels of masked patches instead of predicting a distribution over tokens.\n\nIn the empirical study, authors find that PIXEL substantially outperforms BERT on syntactic and semantic processing tasks on scripts that are not found in the pretraining data, but PIXEL is slightly weaker than BERT when working with Latin scripts.",
            "strength_and_weaknesses": "Strength\n\nIt is interesting to see authors propose to render the text to image for language modeling. \n\nI believe the robust to orthographic attacks and code-switching will be very useful in web security domains. For example, such attack pattern very common in phishing email as the fraudster try to bypass the classifier.\n\nWeaknesses\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity\nOverall it is clear.\n\nQuality and Novelty \nOverall the quality is great. The experiments are thorough and detailed. However, some ablation studies will be helpful, for example\nI am curious why authors choose RGB channel? This seems not very useful in general text besides emojis. \nAlso I am curious if the font of the text can influence the model performance?\n\nAlso what is the computation time for the proposed method (both training and inference) for the proposed method? \n\nReproducibility\nThe experiment set up is clear. Authors promise to publish the implementation and model checkpoints and weights, so I believe it would be reproducible.",
            "summary_of_the_review": "Overall I feel this paper is novel and has strong real-world application. However, my minor concern is the novelty is limited given visual text representations is already proposed by Salesky et al. (2021). Therefore I would recommend \"marginally above threshold\".",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2584/Reviewer_znCA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2584/Reviewer_znCA"
        ]
    },
    {
        "id": "iAGgbBUGPKt",
        "original": null,
        "number": 3,
        "cdate": 1666663141119,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666663141119,
        "tmdate": 1666663141119,
        "tddate": null,
        "forum": "FkSp8VW8RjH",
        "replyto": "FkSp8VW8RjH",
        "invitation": "ICLR.cc/2023/Conference/Paper2584/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents Pixel, a masked language modeling approach similar to BERT that first renders text as an image and then encodes the sequence of patches using a ViT. During pre-training, the setup resembles the masked autoencoder \u2013 spans of patches are masked, only unmasked patches are encoded and a decoder is used to predict the masked patches. During fine-tuning, the decoder is replaced with a classification head similar to BERT. Pixel is motivated by the need to remove the need for large vocabularies that increase model capacity via embedding layers and make prediction layers very expensive, while being able to generalize to a large set of scripts and languages.\n\nExperiments include pre-training Pixel on the same data as BERT (Wiki + Books) and fine-tuning on a large set of tasks including pos tagging, dependency tagging, NER, GLUE/XNLI and extractive QA. Results show that while BERT often outperforms Pixel on English tasks and latin scripts, Pixel can transfer better to previously unseen scripts. They also conduct analysis on robustness to low-level orthographic attacks and code-switching.\n",
            "strength_and_weaknesses": "Strengths:\n1. This paper takes on a new and interesting approach to a very well-established masked language model pre-training/fine-tuning paradigm. It is quite an interesting and refreshing setup.\n2. The paper includes an extensive set of experiments, covering POS tagging, dependency parsing, extractive QA, GLUE, XNLI, NER.\n3. Being able to non-trivially handle new scripts from only fine-tuning data is an impressive feature of the system.\n\nWeaknesses:\n1. It would have been really interesting to see the byte-based vocabulary baseline (something like ByT5). Since most of the experiments involve shorter sequences (right?), is length of the resulting byte-based sequences a concern? In some cases where the vocabulary clearly has very poor coverage, comparing against BERT seems like a slightly unfair comparison with BERT mostly fine-tuning on a sequence of unks. \n2. The discussion on patch span masking is a bit unclear. How was the resolution of the rendered text chosen? Within the same height and sequence length, how many words tend to end up in a patch? Or do patches often contain subwords? I may have missed these details but it seems relevant for understanding how things work. Were there any experiments that varied these parameters to clarify the decisions? A figure illustrating the approach with an example might also be helpful.\n3. The robustness experiments currently lack decided conclusions/takeaways. It doesn\u2019t seem like Pixel is firmly more robust than BERT. Also, the orthographic attack graphs might need error bars?\n4. What if Pixel is provided inputs that are rendered vastly differently during fine-tuning? It would fail to generalize right? Or would the approach be to run OCR and get the text, render it with the Pixel text renderer and then predict? It might be worth adding a discussion that goes over some of these points, and more generally delves into design decisions that are crucial.\n\nNit: maybe the paper title should be masked language modeling with pixels. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally comprehensive, but some details are hard to find (for instance, see previous section for suggestions). It might also be worth restructuring the results section so that it highlights conclusions a bit better \u2013 it\u2019s a bit hard to parse right now.\n\nThis paper is novel and interesting, and the experiments are comprehensive. A bit more discussion on design decisions, ablations, qualitative analyses might enhance the quality further.\n\nThe paper states that code, checkpoints etc will be shared for reproducibility.\n",
            "summary_of_the_review": "Recommending weak accept (open to changing this after discussions) because the paper proposes an interesting approach to masked language modeling with a comprehensive set of experiments, but there is a slight lack of clarity in a few places. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2584/Reviewer_zqCz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2584/Reviewer_zqCz"
        ]
    },
    {
        "id": "tdLv6WPXJc",
        "original": null,
        "number": 4,
        "cdate": 1666739398882,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666739398882,
        "tmdate": 1666739398882,
        "tddate": null,
        "forum": "FkSp8VW8RjH",
        "replyto": "FkSp8VW8RjH",
        "invitation": "ICLR.cc/2023/Conference/Paper2584/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this work, the authors developed a clever twist to the traditional neural language modeling paradigm by building a model that operates on image patches of the text. It learns to output \u201cmasked\u201d patches using an MSE loss. Through this, the model alleviates issues with fixed or non-transferable vocabulary. When fine-tuned on a suite of downstream syntactic and semantic tasks, PIXEL observes commendable performance often on par with BERT etc. or better for languages whose writing scripts are unfamiliar to BERT. The authors also show that the model can handle code-switching and works well in the face of character-level noise.",
            "strength_and_weaknesses": "Strength:\nI commend the authors for the innovation here. Although a simple idea, it is highly effective and clever, and presents a very exciting alternative to BERT & friends. I look forward to future research on what these models encode and share across languages/writing systems.\n\nQuestions:\n- It would be useful to have a more detailed discussion on the fertility of the pixel maps, ie., how many patches correspond to a word on average and the relationship to some of the tasks. For example, I am curious if there is a relationship between this and the question answering performance of PIXEL as the authors allude to as well.\n- It would help to order the languages in the results tables based on [UNK]%. and insert a row showing the difference between BERT and pixel for each result table.\n- Any hypotheses for why its performs much worse than BERT on COLA specifically?\n- I understand the space and time constraints but I would be excited to see that perhaps training PIXEL on two very different script systems leads to big performance gains than traditional models and PIXEL trained on english only. Especially if the other language has a rich morphology for example.\n- How hard was hyper-parameter tuning for this model? what do the loss curves look like?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Extremely clear and well written+motivated! I enjoyed reading the paper.\nQuality: The authors evaluated many different aspects of this model and sufficiently demonstrated its capabilities.\nNovelty: To the best of my knowledge, this is the first paper to use pixel-based language systems as language models.\nReproducibility: The authors will provide a public link with access to many aspects of the model it seems.",
            "summary_of_the_review": "Given the issues with vocabulary and tokenization in NLP, I think this paper offers a very innovative solution and I am curious to see how this research direction pans out.\n\nNB:I would give this paper a 9/10 if the option existed.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2584/Reviewer_HZPD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2584/Reviewer_HZPD"
        ]
    }
]