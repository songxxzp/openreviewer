[
    {
        "id": "kt_ftelcWb9",
        "original": null,
        "number": 1,
        "cdate": 1666589788435,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666589788435,
        "tmdate": 1668981890803,
        "tddate": null,
        "forum": "oyzMyylgINj",
        "replyto": "oyzMyylgINj",
        "invitation": "ICLR.cc/2023/Conference/Paper3180/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a novel training method for Spiking Neural Networks. Typically, the non-differentiability of the spiking neuron was by-passed with a differentiable approximation (e.g. the triangle function). However, each spike depends on two variables: the previous neuron's voltage, and a voltage threshold above which the spike is created. In prior works, the network optimized over the voltage during training, but kept the voltage threshold as a constant, due to training instability issues. This work resolves these instability issues by introducing a separate gradient approximation for the voltage threshold, consisting of the triangle function modulated by a sigmoid function. During backpropagation, the voltage and voltage threshold will receive separate gradients based on this method. Empirical experiments are performed to demonstrate the stability of this method, and the authors demonstrate significant improvements in experiments for image classification and object detection over prior works, with much smaller model sizes.",
            "strength_and_weaknesses": "Overall, the motivation and method is very intuitive, and the proposed solution is simple and makes sense. The authors provide a good amount of background, and justify well the need for the proposed contribution. While the method is quite simple, the improvements in the experiments are quite impressive, especially considering the significant reduction in model size. \n\nOne open question is how much the regularization in Section 5.3 contributes to the work. It seems to only be briefly mentioned, but is not ablated, and it's unclear how important this is to the improvements seen in the experiments.",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the paper itself is well written, and the simplicity of the method lends itself to ease of replicability. Overall, the work seems original, and the results are impressive.",
            "summary_of_the_review": "Overall, the proposed method seems like a simple modification to existing SNN networks which provides a significant improvement. However, I may be missing some context as to the novelty of this work.\n\nEDIT: After reviewing the discussions from the other reviewers, it seems like there are legitimate concerns about the novelty and experiments of this work. Taking this in mind, I am modifying my review to a 5 (although more of a 5.5). ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3180/Reviewer_A7Jv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3180/Reviewer_A7Jv"
        ]
    },
    {
        "id": "oT6XPwZ1cuU",
        "original": null,
        "number": 2,
        "cdate": 1666666105150,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666666105150,
        "tmdate": 1666666105150,
        "tddate": null,
        "forum": "oyzMyylgINj",
        "replyto": "oyzMyylgINj",
        "invitation": "ICLR.cc/2023/Conference/Paper3180/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper propose LT-SNN, a novel SNN training algorithm with self-adaptive learnable potential threshold to improve SNN performance. To stabilize the SNN training even further, the author propose separate surrogate gradient path (SGP), a simple-yet-effective method that enables the smooth learning process of SNN training. The proposed method is validate on multiple event-based datasets, including both image classification and object detection tasks.",
            "strength_and_weaknesses": "Strength\n\n1. The proposed method is shown to outperform SOTA on multiple event-based datasets.\n2. The paper is well written and easy to follow.\n\n\nWeakness\n\n1. I don't see a clarification for the problem importance. Why learnable threshold is important in SNN? If the authors want to make SNN more biologically plausible, should the threshold lie in the specific range? I don't see any discussion or insight in the paper.\n2. The proposed method is not well motivated. For example, the authors propose a separate gradient path in sec. 5.1, but why we should use a separate path instead of single one? Is there any insight or theoretical guarantee? Also, for Eq.9, the authors select the sigmoid function as the activation. Why would the authors select this particular activation function? Is there any biologically insight?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\nThe paper is clearly written.\n\nQuality:\nThe experiments show good results. But the problem importance and  the motivation of the proposed method is missing.\n\nNovelty:\nThe novelty is trivial.  \n\nReproducibility:\nThe authors fail to provide code.",
            "summary_of_the_review": "Although the paper gets better results with more parameters, the problem importance and the motivation of the proposed method is unclear. Therefore, I give a weak reject for the paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3180/Reviewer_fvZZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3180/Reviewer_fvZZ"
        ]
    },
    {
        "id": "BGNIuAvYbm",
        "original": null,
        "number": 3,
        "cdate": 1666681131195,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666681131195,
        "tmdate": 1666681244962,
        "tddate": null,
        "forum": "oyzMyylgINj",
        "replyto": "oyzMyylgINj",
        "invitation": "ICLR.cc/2023/Conference/Paper3180/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors proposed a layer-wise learnable threshold approach for SNNs. The proposed method design two separate surrogate gradient paths for the gradient of membrane potential and learnable threshold. Different classification and object detection tasks reflect the effectivenesses of the proposed LTSNN training scheme.",
            "strength_and_weaknesses": "\nWeaknesses and questions:\n\n-1. The experiments recorded in Table 1 are not clear to me. \n\n       a. Why do \"such constraints in the training process largely limits the learnability of SNN\"? What's the definition of \"learnability\"?\n       b. What is the definition of \"true binary spikes\"? Biologically, an action potential is triggered when the membrane potential is higher than a threshold. The output potential should NOT be a binary value in any case. The spike (action potential) is binary. \n       c. How hardware deals with layer-wise varied spikes is out of the scope of the paper. I assume the \"hardware\" means neuromorphic hardware. Biologically, each neuron has a different dynamic threshold. The current neuromorphic hardware can barely mimic the simplest biological neuron. Thus, algorithm and theoretical study should not be limited or favored to existing neuromorphic hardware. \n       d. DSR and LTSNN used different base models, VGG-11 for DSR and VGG-9 for LTSNN. Is it fair?\n\n-2. The falsified hypothesis 1 is based only on VGG-9 and DVS-CIFA10 is not convincing. In other words, how general of observation 1? In addition, I am not convinced by the experiments associated with Figure 2. If we stop training STSG before 80 epoch, STSG also has stabilized training, right? In other words, why the authors stopped training LTSNN at epoch 100? What would happen if the authors train LTSNN 200 epoch?\n\n -3. Super unclear of section 5.3! The L in Eq. 12 is the same as the one in Eq. 13? What's L_{CE}, MSE, O(t), and T? More importantly, why the MSE regularizer is necessary? \n\n-4. For the experiments associated with Table 4, why did the authors not use the same architecture of other competing approaches? What's the logic behind the experimental design?",
            "clarity,_quality,_novelty_and_reproducibility": "The motivation for the work is very unclear to me at the moment. In addition, I did not see much novelty either. Writing needs significant improve!",
            "summary_of_the_review": "Too many things are unclear to me at the moment, as discussed in the section on \"strengths and weaknesses.\" In addition, many works have developed different dynamic threshold schemes for SNNs. The authors did not mention them at all. For example, in \"Biologically Inspired Dynamic Thresholds for Spiking Neural Networks,\" the authors define dynamic thresholds without learning. More importantly, I do not think the proposed approach is able to imitate \"the self-adaptiveness of the biological nervous system.\" \n\nIn summary, I do not recommend the submission. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3180/Reviewer_Dob4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3180/Reviewer_Dob4"
        ]
    },
    {
        "id": "Z8ma5HlVdn",
        "original": null,
        "number": 4,
        "cdate": 1667352542053,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667352542053,
        "tmdate": 1667352542053,
        "tddate": null,
        "forum": "oyzMyylgINj",
        "replyto": "oyzMyylgINj",
        "invitation": "ICLR.cc/2023/Conference/Paper3180/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors address the thorny problem of training spiking deep neural networks that are marred with problems of non-differentiable nonlinearity, sparse responses and limited expressive power. The authors propose an adaptive threshold mechanism so that the threshold is trained using a different differentiation path from that used for the weight updates.\nIn extensive experiments the authors demonstrate advantages of their approach.",
            "strength_and_weaknesses": "\nStrength \nThe paper offers a new view on learning adaptive thresholds in SNNs. Their SNNs acheve competitive performance on standard tasks even with by an order of magnitude fewer parameters. The paper is well organized and clearly written.\n\nWeaknesses\nWhile the authors bring up the question of biological relevance of SNNs and their learning mechanisms, they don't elaborate on this topic and don't provide evidence that their approach is more biologically realistic as compared to other SNN training schemes.\nThe authors do not comment if their code will be publicly available raising questions about replicability of their research.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written clearly and quite convincingly. ",
            "summary_of_the_review": "This is an impressive piece of work substantially improving on SOTA SNN training. However, questions remain about replicability of this work. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3180/Reviewer_kp4g"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3180/Reviewer_kp4g"
        ]
    },
    {
        "id": "iosxoUyr5a",
        "original": null,
        "number": 5,
        "cdate": 1667444392600,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667444392600,
        "tmdate": 1670749809486,
        "tddate": null,
        "forum": "oyzMyylgINj",
        "replyto": "oyzMyylgINj",
        "invitation": "ICLR.cc/2023/Conference/Paper3180/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes an effective way to train the spike thresholds of spiking neural networks, while the naive surrogate gradient method fails to do so. The proposed method achieves SOTA performance on several image classification tasks and an object detection task.",
            "strength_and_weaknesses": "Strength:\n\n1. The proposed method is simple, and can be directly plugged into other existing methods.\n\n2. There are experiments on non-classification tasks. It is encouraged to explore the performance of SNNs on various tasks.\n\n3. It is interesting to see the potential of quantized small-scale SNNs.\n\nWeaknesses:\n\n1. In table 2, does \"GPW for all\" mean that all neurons share the same learnable Vth? And does \"SGP\" mean that each layer has its own Vth? For the experiments shown in Fig. 2, does each layer have its own trainable Vth?\nFor each experiment, the authors need to make clear statements on whether all the neurons share the same Vth, or each layer has its own Vth, or each neuron has its own Vth. I also suggest the authors to combine eqns. 6 and 11 in one place, and clarify the range of the summation in eqn. 11.\n\n\n2. I think the catastrophic performance drop in fig. 2a is not hard to understand. Let me first guess that each layer has its own trainable Vth. For one layer, you need to sum up dL/dVth_i for each neuron i in that layer to get dL/dVth. Since dL/dVth_i, dL/du_i, and dL/dWij have the same order, |dL/dVth| will be hundreds of or thousands of times large than |dL/dWij|, depending on the model width. Therefore, a learning rate suitable for updating Wij may be too large for updating Vth. So we can easily overcome the issue by using a small learning rate for Vth (e.g., set init lr=0.1 and 0.001 for W and Vth, respectively). Your proposed method basically shrinks dL/dVth_i with a sigmoid function, so it has a similar effect as using smaller lr.  Can you compare the two methods experimentally? Can you show the benefit of your proposed voltage-dependent shrinkage scheme?\n\n3. I am concerned about the direct performance gain of the proposed method. The authors do not show the performance when disabling threshold training and keeping other settings the same. So it is not clear whether the sota results are achieved due to the proposed method or, say, network structures. Table 2 seems to show the direct effect of the proposed method, but the baseline uses a different network structure (the title of table 2 is misleading!). I would appreciate it if the authors could conduct ablation studies.\n\nMinor: \n1. Fig.1: DSR-VGG11 adopts learnable thresholds, as repeatedly pointed out in the manuscript.\n2. In eqns. 6 and 9, a minus sign is missed. ds/du and ds/dVth have opposite signs.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: clear, but should state the training setting more clearly in sec 5. Refer to weakness 1.\n\nQuality: This work makes sense, but does not provide juicy information.\n\nNovelty: The idea of training thresholds is not novel. But the authors make the idea work for the surrogate training framework using a simple trick.\n\nReproducibility: I think the method is easy to implement.",
            "summary_of_the_review": "I give a \"reject\" because:\n\n1. I challenge sec 4 and the motivation of the proposed method totally. You do not need to create a hypothesis and then give some observations. The issue is easy to handle: shrink dl/dVth or shrink the corresponding lr. See weakness 2.\n\n2. The experiments are not carefully designed. I give some examples as following. In fig. 2(a), you do not fine-tune the lr for training vth (see bullet 1). In tables 1 and 2, DSR and TET use vgg-11, but you use vgg-9 (btw, I am confused about the term \"true binary spike\", DSR just uses binary spike). No ablation studies, which are super important in this work, see weakness 3.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3180/Reviewer_btjV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3180/Reviewer_btjV"
        ]
    }
]