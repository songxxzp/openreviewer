[
    {
        "id": "_yYBJ-Y4L5M",
        "original": null,
        "number": 1,
        "cdate": 1665929375826,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665929375826,
        "tmdate": 1665929375826,
        "tddate": null,
        "forum": "HtoA0oT30jC",
        "replyto": "HtoA0oT30jC",
        "invitation": "ICLR.cc/2023/Conference/Paper1884/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents a geometry-free method for novel view synthesis of objects utilizing probabilistic diffusion. Main contributions are a novel scheme for stochastic sampling of conditioning examples, a refined U-Net architecture for denoising, and a new metric for evaluating 3d consistency of novel view synthesis approaches. ",
            "strength_and_weaknesses": "Strengths:\n- A metric for qualitatively evaluating 3D consistency of novel view synthesis is a great contribution to the field.\n- It is exciting to see that the proposed diffusion method is able to infer very consistent 3D structure only from view pairs.\n- The cross attention scheme in the presented X-UNet makes sense in the given setting.\n- The paper is very well written, well motivated and gives a useful overview about the area, structuring some related methods\n- The generated novel views have impressive visual quality\n- The individual contributions (stochastic sampling, diffusion and architecture changes) are evaluated in ablation studies.\n\nWeaknesses:\n- The authors present a novel metric for evaluating 3D consistency but put not enough effort on evaluating that metric itself. At least I would expect a comparison like in Table 2 which compares related methods under the new metric. Of course, it is expected that geometry-based methods outperform the presented method. It would be interesting to see how close 3DiM gets though. Also might be a good sanity check for the metric.\n- The authors provide some details about the metric in the supplemental materials, in which they mention that they use Instant-NGP instead of NeRF but provide no further information about for example efficiency. I wonder how different architectures compare in a speed/metric quality tradeoff.\n- Some details of the experimental setup are not clear to me (see below)\n- There are very few qualitative results in the paper and supplemental. Only two object categories of one dataset are shown and compared.\n- There is no dedicated related work section. Most important related work is cited and sufficiently introduced in the introduction but many works are missing.\n ",
            "clarity,_quality,_novelty_and_reproducibility": "- The paper is easy to understand, well written and of high quality in general.\n- It is also original in a sense that it reconceptualizes novel view synthesis as a diffusion process\n- The authors provide detailed algorithmic information and code snippets for JAX in the supplemental materials, which should make reproduction easier",
            "summary_of_the_review": "In summary, I tend to vote for accepting the paper as it provides novel insight into geometry-free novel view synthesis (e.g. diffusion is able to capture 3D information based on 2D conditioning) and a list of smaller useful contributions, such as a novel metric for evaluating 3D consistency. It would be great if the authors could address the weaknesses, especially in experimental evaluations, as well as answer the following questions.\n\nQuestions and requests:\n- I hope that the method actually starts from pure noise when generating novel views with a trained model (inference). The paper does not make that clear and Figure 2 and Figure 4 suggest that it receives a noisy version of the target. If that is the case it would heavily dampen significance.\n- I would be interested in an analysis of cross attention pairs in the U-Net. The authors have the suspicion that it helps exploiting symmetries. A qualitative analysis of what-attends-to-what would increase insight.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1884/Reviewer_o2Dj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1884/Reviewer_o2Dj"
        ]
    },
    {
        "id": "IIy2Au_kWmR",
        "original": null,
        "number": 2,
        "cdate": 1666581864737,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666581864737,
        "tmdate": 1666581864737,
        "tddate": null,
        "forum": "HtoA0oT30jC",
        "replyto": "HtoA0oT30jC",
        "invitation": "ICLR.cc/2023/Conference/Paper1884/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose 3DiM, a diffusion model for novel view synthesis. The input to the model is a set of images with poses representing different views of the same object plus a target pose; the output of the model is a new image of the same object from the target pose. By applying the model repeatedly, the authors can generate many novel views.\n\nThe model consists of a U-Net-style diffusion image-to-image model. Notably, it only takes a single conditioning image as input, and in order to condition on multiple frames, the conditioning is varied through the diffusion process. The authors additionally modify the traditional U-Net used in diffusion modeling with a few architecture tweaks and show via an ablation that their modifications are an improvement over the default network structure.\n\nFinally, the authors propose a new metric for measuring the 3D consistency of their model. This metric is measured by training a NeRF on a subset of the model outputs and evaluating by comparing the NeRF outputs to the rest of the model outputs.",
            "strength_and_weaknesses": "Strengths:\n- The model results are very promising. The rendered views are detailed and geometrically consistent with the input views. \n- The approach, details, and results are described clearly, including author reasoning for the choices they have made.\n\nWeaknesses:\n- The authors note that although one might expect to condition jointly on all available views, \"We found this solution to perform poorly ... We also find that, as we increase the maximum number of input frames k, the worse the sample quality becomes.\" This is counterintuitive. It seems likely that rather than being a fundamental aspect of the problem, this is a weakness of the model architecture or something else. The value of one of the core contributions \u2013 stochastic conditioning \u2013 relies on this observation, so it would be better if the authors spend more time to experiment with and explain why this is the case, rather than taking it for granted.\n- It seems like stochastic conditioning relies on having the number of diffusion steps be significantly greater than the number of input views. Additionally, it seems like the order in which the input views are used may have a significant impact on the resulting image and perhaps the resulting image quality or consistency. It would help if the authors investigate the impact of number of diffusion steps as well as impact of view ordering for stochastic conditioning.\n- Between the two weaknesses listed previously, it seems like stochastic conditioning could prove to be a poor choice and have limited significance. If you reduce the number of diffusion steps (as many contemporary works aim to do), stochastic conditioning could prove to perform poorly, or be incredibly sensitive to the order of views. Similarly, if stochastic conditioning is simply a workaround for a network architecture that cannot scale to multiple input views, stochastic conditioning will quickly become irrelevant once the network architecture is improved.\n- Relatively minor \u2013\u00a0The modified U-Net has several modifications; however, the ablations only compare *all* modifications against *no* modifications, without individually showing that the modifications are useful.",
            "clarity,_quality,_novelty_and_reproducibility": "The quality and clarity of the work are high. The problem and constraints are described clearly. The contrasts with other approaches or other works are also explained in depth. The choices made are each explained.\n\nThe originality of the work is moderately high. The original contributions are the choice of problem and model class (diffusion models), the modified U-Net, stochastic conditioning, and a novel metric for generation quality. Each individually is not a large contribution but taken together this work represents a significant exploration of the area.\n\nThe reproducibility of the work is sufficient and hyperparameters are provided in the supplementary work. ",
            "summary_of_the_review": "Overall, the paper is above the acceptance threshold. It is well-written and reasoned, with a novel approach and interesting results which suggest a number of further research directions. However, as mentioned in the weaknesses section, one of the fundamental contributions of this work (stochastic conditioning) is underexplored; the need for it could be better justified and its behavior could be better evaluated and quantified. Given that this is fundamental to the approach and may significantly limit the significance of the work, I believe the paper is not *strongly* above the acceptance threshold.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1884/Reviewer_wGc3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1884/Reviewer_wGc3"
        ]
    },
    {
        "id": "RJAIP0Am3vv",
        "original": null,
        "number": 3,
        "cdate": 1666615267864,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666615267864,
        "tmdate": 1666615267864,
        "tddate": null,
        "forum": "HtoA0oT30jC",
        "replyto": "HtoA0oT30jC",
        "invitation": "ICLR.cc/2023/Conference/Paper1884/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper explores the use of diffusion models for novel view synthesis. The authors introduce a geometry-free image-to-image model, dubbed X-UNet, based on a new stochastic conditioning sampling algorithm. They compare their work with state-of-the-art baselines on SRN ShapeNet dataset, apparently, achieving better qualitative results. Regarding quantitative scores, the authors point out some limitations of standardised metrics and, consequently, propose a new evaluation protocol.",
            "strength_and_weaknesses": "Main Weaknesses:\n- Figs. 1, 2, 4 and 5 are not referred to in the text. Partially due to this fact, it is a little hard to follow the overall functioning of the methodology. Initially, Fig. 2 seems to show that, yet the \"green\" block appears \"inside\" Fig. 3 diagrams. In the latter, the little \"dice\" is not mentioned in the caption and its meaning is not completely clear. It is also not clear how the X-UNet architecture (Fig. 4), relates to the other diagrams in Fig. 2 and 3. It could be a good idea to who the overall architecture initially and clearly relate its block with the following diagrams in the subsequent figures.\n- The provided \"webpage\" in the supplementary material is not working properly. I also believe the supplementary should be in a separate pdf other than along with the main paper.\n\n\nMain Strengths:\n- The paper is well-written and based on very recent and updated literature.\n- The proposed method is sound and tackles a relevant problem with an original method.\n- The authors overcome the limitations of the standard evaluation metrics with the proposal o a new evaluation protocol.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is mostly clear. The methodology is sound and principled. All three proposals (e.g. the stochastic conditioning, the X-UNet, and the evaluation protocol) seem to be original. Authors add code in the supplementary material.",
            "summary_of_the_review": "The paper introduces a novel and well-principled method for novel view synthesis. The diagrams and overall architecture pipeline could be better presented. Qualitative results are better than state-of-the-art. However, quantitative scores fall short. Regarding this issue, the authors point out the reasons for this problem and propose a novel evaluation protocol. In summary, I believe the paper is worthy of publication conditioned to the improvement of presentation.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1884/Reviewer_Am8T"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1884/Reviewer_Am8T"
        ]
    },
    {
        "id": "hvv-h5TYBw",
        "original": null,
        "number": 4,
        "cdate": 1667232719236,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667232719236,
        "tmdate": 1667232719236,
        "tddate": null,
        "forum": "HtoA0oT30jC",
        "replyto": "HtoA0oT30jC",
        "invitation": "ICLR.cc/2023/Conference/Paper1884/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces an approach for rendering novel views from a single image. The approach is based on a pose-conditional image-to-image diffusion model. The paper shows the proposed approach can be generalized to the shapes that are not seen during the test time. The results of the proposed approach are superior then the results optained by prior art.",
            "strength_and_weaknesses": "**Strengths**\n1. The paper introduces a new approach for the novel view synthesis using the diffusion model. The generated images are plausible and consistent over the various viewpoints. The approach shows compelling results on the ShapeNet dataset.\n2. The approach introduces an interesting approach for rendering novel views from a single image. The paper explains the proposed idea in detail.\n3. The authors proposed a new approach to measure view consistency. By applying NeRF with the viewing direction, the better reconstruction of the radiance field indicates that the input images are more consistent across viewing directions, which is a reasonable and good attempt.\n\n**Weakness**\n1. The paper exposition requires significant improvement. The paper does not read well. For instance, the caption Figure 3 states, \"There are two main components to our sampling procedure 1) the autoregressive generation of multiple frames, and 2) the denoising process to generate each frame\". However, it is unclear which step indicates which section in the main paper, and there is no description of how the two steps can be utilized for the training. It is also confusing what the subfigures for Step 1 and Step 2 indicate. I think step 2 explains Eq 5 and Eq 6 since the input of the denoising model is the random viewpoint of the clean image, and I think Sec 2.1 corresponds to Figure 2. Then, what is Step 1 indicate? What are dice in the figure mean? Why does the pose of the dices varies while the poses of the images next to the dices are not changing?\n2. In addition, the paper requires an overview figure that can clearly show the flow of the training and testing phases. The figure should be consistent with the sentence in the abstract, \"a pose conditional image-to-image diffusion model, which takes a source view and its pose as inputs, and generates a novel view for a target pose as output\". The reader would expect the pipeline that takes the input image with its pose and target pose as the condition and the network to produce the novel view. The current figures need to explain how the trained network can be used to generate target view images. Instead, Figures 2 and 3 show additional clean images required for the training, and in Figure 4, the network does not require camera poses, but the network only requires noise and clean image pairs.\n3. Please build a connection between sections and figures. For instance, I think \\epsilon_\\theta in Sec 2.1 is described to be used in Eq. 6 in Sec 2.2, right? It would be good to mention how the notations and equations can be connected, resulting in the final equation.\n4. The limited dataset demonstrates the proposed approach, where the scenes are synthetic. Can the proposed method be applied to real images? For instance, I wonder if a bus on the road identified by a semantic segmentation mask can be view-interpolated. This would be tricky for the proposed approach since the synthetic images used for the training is biased toward specific camera intrinsic parameters. Given the image of the different camera intrinsic, not observed in the training scene, the view-interpolation would be failed. Another dataset that can be applied to the proposed approach is the DTU MVS dataset [Jensen et al. 2014]. The such dataset would be helpful to show the benefit of the proposed approach.\n5. Another limitation of the proposed approach is that approach is trained with the view-aligned 3D shapes. The input image and its viewing direction need to be an input of the proposed framework, limiting the applicability of the proposed approach. How can the approach be applied when the initial pose of the object is not provided? \n6. The technical contribution is not significant. It is an adaptation of the well-developed diffusion model [Salimans & Ho 2022, Ho et al. 2020, Kingma & Welling 2013] for the view of consistent image synthesis. The key modification is to provide random viewpoint images for denoising.\n7. At the time of ICLR submission, the project page of this paper was unveiled in the public domain for a few days. @AC: Would this violate the ICLR submission policy?\n8. I think the term \"3D consistent\" is misleading since the proposed approach is not utilizing 3D shapes. Instead, view consistency would be better terminology.\n9. The approach requires 256 denoising steps to generate a single image. It would take significant inference time. The runtime of the proposed approach should be compared with the baseline approaches. The current version of the paper lacks computational comparison.\n10. The proposed approach is actually performing worse than other baseline approaches, such as PixelNeRF and CodeNeRF, in terms of PSNR and SSIM. Although PixelNeRF performs better in terms of PSNR, the result in Figure 5 is much worse than the images shown in the PixelNeRF. It is suspicious the results are cherry-picked images. Authors claim that it is not necessary to achieve the top PSNR, but this is not very convincing since the view interpolation has the ground truth solution. The comparison with the GT solution is essential. \n11. Minor comment: CodeNeRF is not mentioned on page 6.\n12. In Figure 6, it is questionable that the black-silhouette images can be interpolated as the orange-colored chairs. Is this the ablation study tested with unseen images? I suspect the approach is overfitted to the training dataset.\n\n**Reference**\n\n[Jensen et al. 2014] Rasmus Jensen, Anders Dahl, George Vogiatzis, Engil Tola, and Henrik Aan\u00e6s. Large scale multi-view stereopsis evaluation. In CVPR, pages 406\u2013413, 2014.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper includes supplementary material that explains the detail of the implementation. The proposed approach is reproducible.",
            "summary_of_the_review": "The paper introduced an interesting approach for the view synthesis of an object using the diffusion model. It is also interesting to see that the additional random view images would help to generate view-consistent images. However, the paper requires significant revision in the exposition of the proposed approach to be more clearly to be understood. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "At the time of ICLR submission, the project page of this paper was unveiled in the public domain with full authorship for a few days. @AC: Would this violate the ICLR submission policy?",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1884/Reviewer_Zv2q"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1884/Reviewer_Zv2q"
        ]
    }
]