[
    {
        "id": "3MzUxBNC4p",
        "original": null,
        "number": 1,
        "cdate": 1666645392024,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666645392024,
        "tmdate": 1666645392024,
        "tddate": null,
        "forum": "nQBQByfLeSC",
        "replyto": "nQBQByfLeSC",
        "invitation": "ICLR.cc/2023/Conference/Paper5253/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies the problem of measuring globalness of neural network explainers. The work considers the globalness of explanations from a theoretical angle and inspected a list of properties that a metric of globalness should satisfy. ",
            "strength_and_weaknesses": "Strength: \n\n+ The work considers globalness of explanations from a theoretical perspective. I don't know this area well, but there is no such theoretical study before, I feel this contribution is solid. \n+ The work analyzes a list of properties that a metric of globalness should satisfy. \n\nWeaknesses:\n\n- The analysis is somewhat shallow. I feel that most analyses are not far from my intuitive understanding. \n- The proposed approach of Wasserstein Globalness is not examined against those properties analyzed in the first part of the work.\n- The writing of the submission is poor. It is hard to understand,  partially because it contains many typos. \n\nBesides these weaknesses, I don't see a clear goal of experiments. \n",
            "clarity,_quality,_novelty_and_reproducibility": "This submission has a list of writing issues that make it hard to understand. \n\n1.  \"Let $\\mu \\in P(\\mathcal{E})$ be one such probability distribution\". Where is this distribution from? What's a random event? It seems that the distribution is derived from the model and the data, but you may want to make it clear so the reader does not have to guess. \n\n2. $\\mu$ is used a second time in \"$\\mu \\in P(X \\times Y)$\".  \n\n3. The reading of Property 5 is bumpy. You may want to move the definition of S to the sentence before (4). Additionally, I don't understand why we need to consider G is NOT invariant to S?\n\n4. In property 6, what do you mean by \"combining\" two explanations?\n\n5. The notation in 3.4 is problematic: $\\mathcal{E}$ is the space of explanations, but the discussion seems to define a metric for $P(\\mathcal{E})$, the distribution space of explanations.  \n\n6. I'd like to see a clear statement of the goal of the experiment section at the beginning of section 5. \n",
            "summary_of_the_review": "Overall, this work studies the interesting problem of measuring globalness of explanations in a more rigorous way. However, there is a disjoint between the analysis and the proposed approach. It is also unclear the benefit of the this new metric of globalness. The writing of the work should be improved. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No concern.",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5253/Reviewer_CcYU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5253/Reviewer_CcYU"
        ]
    },
    {
        "id": "xsigEky26eE",
        "original": null,
        "number": 2,
        "cdate": 1666780973612,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666780973612,
        "tmdate": 1666780973612,
        "tddate": null,
        "forum": "nQBQByfLeSC",
        "replyto": "nQBQByfLeSC",
        "invitation": "ICLR.cc/2023/Conference/Paper5253/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper introduces Wasserstein Globalness, a model-agnostic method for measuring the globalness (the inverse of locality) of explainers.\n",
            "strength_and_weaknesses": "*Strengths*\n\n* The idea becomes rather clear even for a non-expert, and the paper could be of interest to the explainability community.\n\n* The paper reads well and is easy to follow.\n\n*Weaknesses*\n\n* As a non-expert in explainability, I found it hard to position the work or assess the novelty/originality of this paper.\n\n* The experiment are rather simple, which is good for illustrative purposes, but leaves open questions regarding relevance and generality of the analysis.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is rather clear even for a non-expert. However, I found it hard to assess the novelty/originality of the work. This is reflected in my confidence score. The authors have not shared code for their experiments, but provide details for replicating the methods/experiments.\n",
            "summary_of_the_review": "A potentially interesting paper that introduces a concept and evaluates it on simple test scenarios. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5253/Reviewer_8L8j"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5253/Reviewer_8L8j"
        ]
    },
    {
        "id": "nhzivjNQzJ",
        "original": null,
        "number": 3,
        "cdate": 1667098271755,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667098271755,
        "tmdate": 1667098271755,
        "tddate": null,
        "forum": "nQBQByfLeSC",
        "replyto": "nQBQByfLeSC",
        "invitation": "ICLR.cc/2023/Conference/Paper5253/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper promotes the use of the Wasserstein distance between the distribution of explanations produced by an explainer algorithm and the uniform distribution as a way to access whether the explainer is local (provides sample specific information) or global (class specific). Five desired properties are introduced to motivate the choice, and proofs are provided that the proposed use of the Wasserstein distance concurs with these properties.",
            "strength_and_weaknesses": "# Strengths\n\n1.  Clear motivation of the chosen measure with the 5 properties.\n2.  An important problem the paper aims to address.\n3.  Empirical demonstration with some theoretical justification, and the code provided.\n4.  A well written manuscript.\n\n# Weaknesses\n\n1.  Some claims do not take into account the existing literature.\n    1.  In the intro it is claimed that there are no obvious metrics to compare the explainers, yet the field of developing such metrics is a highly active one.\n        1.  Remove and Retrain ROAR: Sara Hooker et al. A benchmark for interpretability methods in deep neural networks. In Advances in Neural Information Processing Systems, pages 9737\u20139748, 2019\n        2.  Retain and Retrain RAR: Md Rahman, et al. Interpreting models interpreting brain dynamics. Scientific Reports, 12(1):1\u201315, 202\n        3.  Accuracy Information Curves, Softmax Information Curves: Andrei Kapishnikov, Subhashini Venugopalan, Besim Avci, Ben Wedin, Michael Terry, and Tolga Bolukbasi. Guided integrated gradients: An adaptive path method for removing noise. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 5050\u20135058, 202\n    2.  The abstract claims introduction of a novel measure of globalness, yet I've come across this concept already in the paper below. Admittedly the method in that paper was developed to demonstrate an application. This work may be a mathematical treatment of that method. Please explain.\n        1.  Md Rahman, et al. Interpreting models interpreting brain dynamics. Scientific Reports, 12(1):1\u201315, 202\n2.  Judging by experiments, sensitivity of the Wasserstein measure to globalness is low.\n    1.  In all experiments the changes of the measure are within hundredth units, while the variance, where shows is much larder.\n    2.  In Figure 6 accuracy drops to random, while the measure only slightly decreases and even then not for all methods.\n    3.  What is the source of variability in assessing the distribution of explainer predictions? Multiple classifiers each trained with random seeds and explained at each sample? Multiple samples on the same classifier? Something else?\n3.  Lack of demonstration of the computational complexity and wall clock timing of the method.\n    1.  Wasserstein distance is computationally demanding to compute, especially in high dimensions. There's a danger, that the proposed method will be intracktable in practice despite for toy problems. The paper would benefit from demonstrations on the issue.\n4.  The meaning of the distance of the value of it in separating one method from another in terms of behavior of explaners at individual input samples is not clearly demonstrated.\n    1.  It is unclear what does it mean for the value to be 0.99 or 0.98, what changes in detected explainers? Figure 5 contains examples of saliency maps, yet interpretation or connection of the proposed G measure with what is displayed is not clear.\n    2.  It is clear, that if the metric is close to 0 all saliency maps for each sample must have very few things in common, and a high value of the metric means there is a single global per class feature. Rigorous demonstration that this is indeed the case would help evaluate the value of the proposed method.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and is a quality work. The code is currently not available, but proposed for release. Thus it is not easy, if at all possible, to reproduce the results at the review stage.\n\nAs for novelty, I have some reservations. The abstract claims introduction of a novel measure of globalness, yet I've come across this concept already in the paper below. Admittedly the method in that paper was developed to demonstrate an application. This work may be a mathematical treatment of that method. It would be good to have an explanation and discussion of this.\n\nMd Rahman, et al. Interpreting models interpreting brain dynamics. Scientific Reports, 12(1):1\u201315, 202",
            "summary_of_the_review": "A clear paper with a solid and reasonably well-presented idea on an important topic. However, it lacks some demonstration of the claims and does not systematically explore the usefulness of the proposed method.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5253/Reviewer_arKF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5253/Reviewer_arKF"
        ]
    }
]