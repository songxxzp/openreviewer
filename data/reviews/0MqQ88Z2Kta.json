[
    {
        "id": "_dbL_5bI03r",
        "original": null,
        "number": 1,
        "cdate": 1666457843882,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666457843882,
        "tmdate": 1666457843882,
        "tddate": null,
        "forum": "0MqQ88Z2Kta",
        "replyto": "0MqQ88Z2Kta",
        "invitation": "ICLR.cc/2023/Conference/Paper773/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors of the paper have examined a selection of Large Language Models to determine whether their output can be assigned to various personality traits that have been internalized by the training data, and whether this assignment is also consistent within a model. For this purpose, they introduce the \"OCEAN\u201c-score, which is based on the Big Five personality theory. The scoring results are determined in a zero shot setting with a newly introduced Q&A dataset based on psychometric tests (named \u201eMachine Personality Inventory\u201c (MPI)). With the result that a clear personality assignment can be identified in the LLMs, the authors developed a procedure to induce the behavior regarding a certain personality trait via a sequence of different prompts, which are built on each other, the so-called \"chain prompting\u201c.",
            "strength_and_weaknesses": "Strengths:\n- The experiments are presented in a comprehensible way and supported with examples.\n- The experimental design is well thought, structured and consistent, e.g. it is understandable why and how the dataset was used and where all the data came from; how the evaluations were conducted.\n- The experiment of chain prompting does not raise any further questions, the procedure and the results are conclusive and well evaluated.\n- The research questions are repeated regularly and answered precisely.\n- The work is set into the context of real-world applications.\n\nWeaknesses:\n- The term \u201epersonality\u201c does not correspond to the generally used concept of a \u201ehuman personality\u201c. This should be highlighted as early and clearly as possible. Otherwise the hypothesis of whether an LLM has a \"personality\" cannot be answered on the loose defintion taken by the authors. (\u201eHuman personality refers to \u201aindividual differences in characteristic patterns of thinking, feeling and behaving\u2019. While it is hard to dig into models\u2019 thinking and feeling, we focus on studying their personality-like behaviors. We, therefore, borrow the concept of \u201cpersonality\u201d from psychology as human-like personality behavior\u201c) It would be better to refer to \"personality traits\" or \"behavioral traits\".\n- The definition should also not be in a footnote on the second page, it would be preferable in the introduction, in this case in the second paragraph.\n- The authors state in the conclusion on page 9 that they \u201e[...] explore whether LLMs possess human-like patterns in thinking, feeling, and behaving\u201c, although thinking and feeling were clearly excluded as non-investigable. This should be adjusted.\n- It is unclear in table 2 how many MPI items were used to test? As shown in the appendix (table 8), this makes a big difference.\n- It should be specified how it can be interpreted that the results partly diverge strongly when the experiment is carried out with a different number of MPI items (table 8).\n",
            "clarity,_quality,_novelty_and_reproducibility": "Quality of the work could be rated as high, as the work is presented transparently and comprehensibly. The experiments are reasonably structured.\n\nThe clarity is on a mediocre level. It can be rated very high with regard to the experimental procedure, the evaluation, the dataset construction, the data origin and the OCEAN-score, since the points mentioned are well comprehensible and coherent.\nSome clarity is lost due to the underlying concept of \"personality\", which cannot simply be transferred from humans to machines, but should be more specifically defined or expressed with a different terminology. The results presented in Table 8 should also be discussed to provide more clarity.\n\nAlthough another paper with a similar experiment, also based on the \"Big Five\" was already published in April 2022 (arXiv:2204.12000), both experiments differ. Not only do the authors create a new dataset, but the approach to evaluation and chain prompting is also new in this regard. Also, they only refer to LLMs. Therefore, the originality is to be rated high.\n",
            "summary_of_the_review": "I would recommend the paper with some reservations, because the clear procedure in the experiments, the developed MPI dataset and the procedure of chain prompting are clearly coherent and useful contributions. But it would be important to correct the \"personality\" concept and to add an interpretation of the deviating results with different MPI item numbers, as this could possibly change the answer to the relevant research question.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper773/Reviewer_YTcu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper773/Reviewer_YTcu"
        ]
    },
    {
        "id": "1Sf7-5HYVo4",
        "original": null,
        "number": 2,
        "cdate": 1666533691532,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666533691532,
        "tmdate": 1666533691532,
        "tddate": null,
        "forum": "0MqQ88Z2Kta",
        "replyto": "0MqQ88Z2Kta",
        "invitation": "ICLR.cc/2023/Conference/Paper773/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper evaluates the pretrained language models (LLM) from a novel perspective, where the Big Five personality labels are considered. More specifically, the author provides question templates and statements for PLMs to make choices in a zero-shot generation scheme. The personality score of a PLM is based on the summation of the OCEAN scores of its choices in a set of MPI questions. Besides, the author proposed a chain prompting method to induce the generation personality of LLMs. The empirical results show that GPT-3 behaves more like humans, and the chain prompting method has its effectiveness considering the OCEAN scores.",
            "strength_and_weaknesses": "Strength:\n1. The author introduces a novel and interesting evaluation dimension for LLMs, where the personality of the model is considered. The Big Five personality factors seem useful to evaluate the personality of deep models, which might have potential enhancements to text style transfer and chatbot systems. \n\n2. The MPI for LLMs is interesting, treating the LLMs as patients with the questionnaire, based on the strong zero-shot ability of LLMs.\n\nWeakness:\n1. The concept of \"personality\" for a pretrained language model lacks a rigorous definition. The paper discusses evaluating and inducing personality into language models. However, the concept of \"personality\" seems different in evaluating and inducing part. When evaluating the personality of LLM, the concept of \"personality\" is more similar to a self-evaluation with multiple questions. However, when inducing personality, the concept of \"personality\" is more close to the textual style of the generation results. The gap between the two parts makes me confused about how the \"personality\" is defined by the author.\n\n2. I am not convinced that the MPI can reflect the LLM's personality. Although LLMs can make choices based on their zero-shot abilities, the choices are made based on the probability of language modeling, but not on a deep understanding of the statement. Besides, LLMs can make mistakes in zero-shot generation schemes. So why the generated choices can reflect the personality of LLMs?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly stated, and easy to follow. The experiments seem reproducible.",
            "summary_of_the_review": "The paper introduces an interesting evaluation perspective of language models, the personality. The method has its own novelty. However, the concept of personality is not well-defined, and an obvious gap exists between evaluating and inducing parts.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper773/Reviewer_v3tK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper773/Reviewer_v3tK"
        ]
    },
    {
        "id": "Rq4Jjy41wR",
        "original": null,
        "number": 3,
        "cdate": 1666596352742,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666596352742,
        "tmdate": 1666677259220,
        "tddate": null,
        "forum": "0MqQ88Z2Kta",
        "replyto": "0MqQ88Z2Kta",
        "invitation": "ICLR.cc/2023/Conference/Paper773/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper mainly studies two question, whether the Large Language Models (LLMs) has personality and is it possible to induce a specific personality in the LLMs. \n\nFor the first question, the author proposes a new dataset MPI to evaluate Large Language Models's machine personality built upon the Big Five Theory. The paper finds that the LLM, especially GPT3-175B, achieves human level consistency across the five personality described in the Big Five Theory. \n\nFor the second question, to test whether a given LLM has multiple personalities, the paper designs a chain prompting experiment to induce the LLM's specific personality and finds higher personality score with better internal consistency. ",
            "strength_and_weaknesses": "Strength\n1. Unlike most previous work on controlling the LLMs to generate text of a specific personality, this paper is the first to research the personality of the LLMs themselves.\n2. The research question on whether LLMs have personality is novel but hard to quantify. By leveraging the Big Five theory and existed personality assessment inventories, the proposing the MPI datasets quantifies the LLMs personality well.\n3. The proposed MPI datasets provided a quantitative assessment and can be adopt as guidance for LLMs behavior controls.\n\nWeaknesses\n1. Lack details on Prompt Template Design. \n\nThe authors claims that\n-  \"To let models perform personality assessment, we manually design the MPI template with instructions and five candidate options for multiple-choice question-answering\". \n- \"Note that we hand-engineered the template to make LLMs most responsive to our prompts\". \n- \"Prompt templates for multiple-choice question-answering are human-designed and selected from one of the best-performing templates based on responsiveness and answer validity.\"\n\nIt is nothing new that the template design can affect the LLM generated content heavily. The paper does not study enough the impact of template variation which could be an important factor of the problem setting. How the best performing templates are selected are concerning in that if the responsiveness are evaluated on a specific LLM, there might be a risk of overfitting.\n\n2. Lack ablation study on Decode strategy. \nThe paper uses temperature = 0.1 and top-p = 0.95. The impact of different decoding strategy on the final evaluation results are not clear both on mean and standard deviation. Will a specific LLM change its personality, or have huge instability over the internal consistency, if the decoding strategy is different? Also, the random seeds are not considered too which makes the concreteness of the conclusion a bit concerning.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity The paper is well written and easy to follow. The figures and tables are clear.\nQuality The work is overall solid and the main claim are well-supported. It would be better if more ablation study can be done as described in the weaknesses section.\nNovelty This work is novel in that the authors studies directly the personalities of the LLMs instead of guiding to generate text of certain targeted personality.\n\nReproducibility It seems the author does not mention any plans on open source the MPI datasets and code.",
            "summary_of_the_review": "This article investigates a novel problem on evaluating the personality of LLMs, and the experiments and datasets are well designed to validate the problem. More information about the template design and the ablation study of the decoding strategy would make the conclusions of this paper more concrete.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper773/Reviewer_w6LV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper773/Reviewer_w6LV"
        ]
    },
    {
        "id": "86IXZsCHdv",
        "original": null,
        "number": 4,
        "cdate": 1666694817019,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666694817019,
        "tmdate": 1666694817019,
        "tddate": null,
        "forum": "0MqQ88Z2Kta",
        "replyto": "0MqQ88Z2Kta",
        "invitation": "ICLR.cc/2023/Conference/Paper773/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies personalities of pre-trained language models. The paper makes two contributions.\n\nFirst, the paper proposes to test the personality of a pre-trained model by prompting the model to answer a series of questions. The questions are selected based on the Big Five Personality Factors theory, and the answers can be used to check if the model has a consistent personality. Using this protocol, the paper evaluates the personality of five language models and finds that larger models (T0++ and GPT-3) display human-level personality consistency. \n\nSecond, the paper proposes a method to induce a given personality trait from GPT-3. Given a personality trait (described by a single word), the paper prompts GPT-3 to find a set of related keywords and then combine them into sentences. The paper compares this multi-step prompting method to vanilla prompting. The proposed method has a higher consistency score and higher correlation with humans when responding to different scenarios.",
            "strength_and_weaknesses": "Strengths: This paper studies an interesting problem. The proposed evaluation method is sound and provides useful insight. The proposed prompting method can be useful for building conversational agents with a specific personality, since it outperforms vanilla prompting.\n\nWeaknesses: While the paper is sound overall, it also leaves a lot of open questions and future work. I wish some of the directions were studied in the paper. For example, I am curious to see if large language models can maintain a consistent personality over a multi-turn conversation. I am also curious to see if the personality can be reflected on other downstream tasks (as the paper mentions).\n\nThe human study is also a little limited with only 62 valid responses. Given the small sample size, I think the results need to be analyzed with a statistical significance test.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear. The paper studies a novel problem and has solid results. The results seem reproducible.",
            "summary_of_the_review": "The paper explores an interesting direction and proposes reasonable methods. The experiments seem mostly sound. However, the paper is only an initial step, and I feel like the experiment setting can be extended to more complex tasks such as dialogue. Therefore, I weakly recommend acceptance.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper773/Reviewer_43Q3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper773/Reviewer_43Q3"
        ]
    }
]