[
    {
        "id": "QeGQ-vnF5K",
        "original": null,
        "number": 1,
        "cdate": 1666592670171,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666592670171,
        "tmdate": 1666592670171,
        "tddate": null,
        "forum": "qxcQqFUTIpQ",
        "replyto": "qxcQqFUTIpQ",
        "invitation": "ICLR.cc/2023/Conference/Paper1764/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies byzantine robust decentralized learning. In this setting, a fraction of workers is byzantine. First, the paper argues why the consensus is vulnerable to byzantine attacks, then they propose DISSENSUS, a decentralized attack to steer away from the true consensus. Finally, they come up with a robust called aggregation self-centered clipping which converges to a neighborhood of a stationary point. ",
            "strength_and_weaknesses": "-Weaknesses\n1)The aggregation strategy proposed in the paper has been proposed before and is not a novelty of this paper. Moreover, the idea of centralized clipping is not new, for example, paper [1] looked at this idea before in distributed setting, and this paper is an extension of that to the decentralized setting.\n[1]Karimireddy, Sai Praneeth, Lie He, and Martin Jaggi. \"Byzantine-Robust Learning on Heterogeneous Datasets via Bucketing.\" arXiv preprint arXiv:2006.09365 (2020).\n-Strength\n1)The reviewer did a good job reviewing relevant papers.\n2)The paper does a good job of motivating the problem.\n3)The experimental results are sound.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The only problem with this paper is contributions are only marginally significant, and the assistance of this paper in comparison to [1] is not substantial.\n[1]Karimireddy, Sai Praneeth, Lie He, and Martin Jaggi. \"Byzantine-Robust Learning on Heterogeneous Datasets via Bucketing.\" arXiv preprint arXiv:2006.09365 (2020).",
            "summary_of_the_review": "The aggregation strategy proposed in the paper has been suggested before and is not a novelty of this paper. But, the authors provided a study of this method in a decentralized setting and did a good job comparing it with previous methods and providing experiments that support their idea. Compared to the previous versions of the paper, the authors add more comparisons with previous results in control/optimization literature. In summary, the strengths outweigh the weaknesses.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1764/Reviewer_wSS2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1764/Reviewer_wSS2"
        ]
    },
    {
        "id": "ttWOQhIuDd",
        "original": null,
        "number": 2,
        "cdate": 1666648960581,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666648960581,
        "tmdate": 1666661056601,
        "tddate": null,
        "forum": "qxcQqFUTIpQ",
        "replyto": "qxcQqFUTIpQ",
        "invitation": "ICLR.cc/2023/Conference/Paper1764/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This submission discusses using the technique ClippedGossip in the decentralized optimization setting to counter potential Byzantine agents in the network. \n\nThe authors provide convergence guarantee in terms of first-order condition to show the attainment of consensus in the network, and give numerical experiments to show the effectiveness of the ClippedGossip technique in providing robustness in several attack/data heterogeneity settings.",
            "strength_and_weaknesses": "Strength:\n\n-> The paper is well-structured and the narrative flows finely.\n\nWeakness:\n\n-> There can be further clarification about the experimental settings.\n\n-> Some proof steps do not naturally connect. Specific comments are in the following section.\n\n-> I suggest the authors submit core code for numerical experiments.",
            "clarity,_quality,_novelty_and_reproducibility": "Regarding theory/statements/proofs:\n\n-> Lemma 3. It should be $\\forall i,j \\in [n-b]$\n\n-> Please justify Lemma 4.\n\n-> In subsection E.1, bullets 4 and 5 have the same descriptions.\n\n-> Page 27, Lemma 8 proof.  Applying inequality \"(16)\" to the last term, not inequality (18).\n\n-> Page 29, Lemma 10 proof, I do not follow the second inequality when bounding $A_1$. Where does that square come from, and how does $\\tau_i^{t+1}$ get into the argument? \n\n-> Page 30, proof to theorem I': I do not understand why it is reasonable to apply Lemma 10 with $\\eta = 0$. When the step size is 0, no update happens. As this bound needs to hold for every $t$, this step does not seem reasonable.\n\nRegarding experiments:\n\n-> It is not obvious that how the spectral gap $\\gamma$ can be explicitly fixed or controlled. Could authors explain this issue?\n\n-> In terms of comparison methods, I wonder if authors have thought of gradient tracking, which is a potential practice for decentralized optimization (ref. [A general framework for decentralized optimization with first-order methods by Xin et al., Proceedings of the IEEE (Volume: 108, Issue: 11, November 2020)]). \n\n-> It is not immediately obvious to me how aggregators are implemented in this case. In the centralized setting, aggregators are usually applied on the server. I wonder if authors apply the aggregator on every node when they iterate?",
            "summary_of_the_review": "There are several places where further clarification about theoretical proof and numerical experiments can be helpful for me to determine the correctness of the submission. It is not immediately clear to me that the selected numerical baseline is the most appropriate baseline, and I would like to examine the proof closer.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1764/Reviewer_3Jpb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1764/Reviewer_3Jpb"
        ]
    },
    {
        "id": "icSL_R2fo4",
        "original": null,
        "number": 3,
        "cdate": 1666722879633,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666722879633,
        "tmdate": 1666722879633,
        "tddate": null,
        "forum": "qxcQqFUTIpQ",
        "replyto": "qxcQqFUTIpQ",
        "invitation": "ICLR.cc/2023/Conference/Paper1764/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a novel algorithm to deal with Byzantine resilient decentralized optimization for data training. ",
            "strength_and_weaknesses": "+ The algorithm dose not rely on additional graph connectivity\n+ The performance is better than some existing algorithms\n\n- The algorithm does not guarantee accuracy of the optimization process\n- The idea behind the algorithm is unclear. In particular, the Clipping idea involves a parameter \\tau but its role is not well explained and illustrated. \n- The paper has an adaptive selection process for \\tau_i, but it cannot be computed only rely on local information. In particular, it involves \\delta_max, which seems not an available information. ",
            "clarity,_quality,_novelty_and_reproducibility": "The work idea is original.  In general, the paper is easy to follow, except for the \\tau issue. ",
            "summary_of_the_review": "The paper proposes a novel algorithm to deal with Byzantine resilient decentralized optimization for data training, which has better performance compared with some existing works. However, the idea behind the algorithm is not clearly explained. In particular, the role of the \\tau parameter and the adaptive selection process for \\tau_i is unclear to me. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1764/Reviewer_vfZ6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1764/Reviewer_vfZ6"
        ]
    }
]