[
    {
        "id": "6fgvj83QaH",
        "original": null,
        "number": 1,
        "cdate": 1666175086298,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666175086298,
        "tmdate": 1666669299968,
        "tddate": null,
        "forum": "JHW30A4DXtO",
        "replyto": "JHW30A4DXtO",
        "invitation": "ICLR.cc/2023/Conference/Paper1036/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a machine-learning-based approach for generating columns for LP relaxations of vertex cover problems (VCPs). The paper (implicitly) assumes that the VCPs are generated from some distribution and it proposes to learn a classifier to predict if a MIS is a part of the optimal solution, given a training set of VCP problem instances. Then, the standard column generation algorithm is used with the learned classifier to choose columns. The experiments using real data sets show that the proposed approach tends to produce better solutions.",
            "strength_and_weaknesses": "Strength:\n- A motivated new approach to combinatorial optimization\n\n\nWeaknesses\n- The approach is not general, i.e., specifically designed for a series of optimization problems generated from similar distributions\n- The idea itself is interesting, but there is no new technique introduced\n\nThe proposed idea of learning relevant columns (MISs) from a series of problems would make sense when such similar problems are available. But, the approach has the limitation that it is not suitable to apply for new problems obtained from different distributions. The learning techniques themselves are quite standard. So, I feel that the technical contribution of the paper is not significantly strong though the idea itself is promising.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written. The technical results seem novel. ",
            "summary_of_the_review": " The idea itself is promising, but the technical contribution of the paper seem not significantly strong.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1036/Reviewer_igoj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1036/Reviewer_igoj"
        ]
    },
    {
        "id": "hm010sGdmz",
        "original": null,
        "number": 2,
        "cdate": 1666671310780,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666671310780,
        "tmdate": 1666671310780,
        "tddate": null,
        "forum": "JHW30A4DXtO",
        "replyto": "JHW30A4DXtO",
        "invitation": "ICLR.cc/2023/Conference/Paper1036/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a Column Generation method for Vertex Coloring Problem, based on Machine Learning. The column in this case is a maximal independent set, which can potentially share the same color. Specific features were designed for this problem: 1) problem-specific features derived from the graph; 2) statistical measures computed from sample solutions; 3) linear program (LP) features. Various ML classifiers (KNN, Decision Trees, SVM) are trained on instances with known optimal solutions, in order to predict high quality maximal independent sets (MIS). The MLCG algorithm samples randomly generated MIS or uses a genetic algorithm like procedure to evolve new ones and keeps a subset of the highest quality ones. The generated columns are then fed into the Gurobi solver. A good sized experimental evaluation shows that MLCG outputs higher quality columns compared with other strategies, like random CG, Reduced Cost, MLF and Full. ",
            "strength_and_weaknesses": "Strengths:\nFor the specific Vertex Coloring Problem, the features that are defined are natural and prove to be relevant in characterizing the quality of MIS. The method is clear and combines well understood ML classifiers. The experimental evaluation confirms the quality of the method.\n\nWeaknesses:\nIt is not clear how this method can be used for problems other than Vertex Coloring, although the authors claim that the method is generic, and mention in conclusion that vehicle routing may lend itself to a similar treatment. \nThe size of the test graphs is small, with only 100 vertices. Any indication of how this method would scale for larger graphs?",
            "clarity,_quality,_novelty_and_reproducibility": "The ideas of the paper are explained very clearly. There is some novelty in the design of the features for ML algorithms, and in combining other existing algorithms.",
            "summary_of_the_review": "The paper shows an improvement in Column Generating quality with the help of ML classifiers, for Vertex Coloring. While there is some novelty in the design of the features and of the method, the scope is still very focused on a single type of problem (VC), and the experimental evaluation is still limited to a small number of graphs of modest size.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1036/Reviewer_795f"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1036/Reviewer_795f"
        ]
    },
    {
        "id": "7j9zTX0e5kp",
        "original": null,
        "number": 3,
        "cdate": 1667173922329,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667173922329,
        "tmdate": 1667173922329,
        "tddate": null,
        "forum": "JHW30A4DXtO",
        "replyto": "JHW30A4DXtO",
        "invitation": "ICLR.cc/2023/Conference/Paper1036/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper combines the machine learning technique within the traditional column generation method for solving combinatorial optimization problems. Specifically, the authors propose to use machine learning algorithms to predict high quality columns that belong to an optimal integer solution. Here the machine learning model is trained using training instances that correspond to columns (MISs in the case of VCP), where the features of each instance are constructed from various perspectives. \n\nThe main contribution of this paper is, it presents a nice integration of MIP technique with the prediction power of machine learning. Instead of fully replying on ML predict the optimal solution for combinatorial optimization problem, here in this paper it simply leverages the power of ML technique for column selection. This idea in alignment with many recent literatures about learning to branch, learning to cut in MIP, becomes an increasingly exciting area in both communities.\n",
            "strength_and_weaknesses": "Main strength: This paper is very nicely written with little typos and easy to follow. The numerical experiments are extensive and convincing. The main idea of this paper is novel and interesting and is extendable for many other types of combinatorial optimization problems, it provides another bridge between communities of ML and MIP. \n\nMain weakness: 1. The constructed features for training instances seem too arbitrary, a detailed explanation of the intuition and analysis can be helpful.     \n2. In the numerical experiment, all the benchmark methods are variants of column generation. A more detailed comparison with other state-of-art methods for VCP should be considered (either based on tighter LP relaxations or combinatorial properties of VCP). Based on the same reason, since for many classic combinatorial optimization methods there have already been quite successful combinatorial algorithms in the literature, simply extending the same idea of this paper to tackle those other problems cannot be trusted to outperform other algorithms. \n\nminor comments/questions: 1. In the formulation given by (1)-(3), since in the graph of VCP, every node can only be colored exactly once, should the $\\geq$ in (2) be equality?     \n2. You mentioned that the set covering formulation (1)-(3) has a tight LP relaxation. Can you add a reference for this statement? Is it also true that, if you select a subset $\\tilde{\\mathbb{S}}$ of $\\mathbb{S}$ and replace $\\mathbb{S}$, the binary IP (1)-(3) still has a tight LP relaxation?  \n3. In constraint (5), $\\tilde{\\mathbb{S}}$ should be $\\tilde{\\mathbb{S}}_v$, which has not been defined until later in Section 3.1.   \n4. In Algorithm 1, at every iteration you keep the top $\\epsilon$ percentage of MISs, here in convention $\\epsilon$ is used to denote small constant. Here you should either say \"top $\\epsilon$ of \" or use some other notation such as $\\kappa$. ",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity, quality, novelty and reproducibility of this work are all significant enough to be accepted as a conference preceding. ",
            "summary_of_the_review": "Overall, I think this paper has made significant contribution to the community of MIP or CO by leveraging the power of ML techniques. Even though this type of method is completely empirical-based and often times not the optimal method in practice, such attempt is still encouraging and in my opinion, it's not impossible to see major breakthroughs in combinatorial optimization in the future through unconventional approaches like ML. Based on the novelty and potential carried in this paper, I recommend this paper to be accepted. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1036/Reviewer_DZnS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1036/Reviewer_DZnS"
        ]
    }
]