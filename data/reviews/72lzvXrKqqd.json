[
    {
        "id": "MI4R-cHC6P",
        "original": null,
        "number": 1,
        "cdate": 1666621515872,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666621515872,
        "tmdate": 1669826997286,
        "tddate": null,
        "forum": "72lzvXrKqqd",
        "replyto": "72lzvXrKqqd",
        "invitation": "ICLR.cc/2023/Conference/Paper3905/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper tackles the problem of OoD detection in the case where the distribution of training classes is not-uniform. In other words, the authors tackle OoD detection in the case of long-tail image recognition. The authors first make the observation that a number of existing OoD methods (either implicitly or explicitly) make the assumption that the training set is balanced, and then propose a simple re-weighting strategies to address this. \n\nOn an ImageNet evaluation, with varying degrees of long-tailness, the authors show their re-weighting strategies boost the performance of a number of baselines (including maximum softmax probability and the more recent GradNorm). Specifically, the re-weighting takes into account the empirical distribution of training classes.\n\nThe authors theoretically analyze the problem through the lens of causality, by presenting different candidate causal graphs which model the data generation process. ",
            "strength_and_weaknesses": "Strengths:\n* The authors tackle an interesting problem, OoD detection for long-tailed training data. It is interesting because real-world data is rarely balanced and, as the authors observe, the performance of existing methods drops substantially in this regime. \n* The re-weighting strategies which the authors propose are intuitive and easy to implement. It makes sense to incorporate the empirical class prior of the in distribution data to the OoD scoring rule, and the authors show an easy way in which it can be done. Despite this, they markedly improve the performance of a number of baselines. \n* The authors provide a detailed ablation, controlling for model architecture, different amounts of data long-tallness, as well as a useful breakdown of the OoD performance when only the 'Head','Middle' or 'Tail' classes are taken from the closed-set categories. Intuitively, they find that the biggest problem is distinguishing 'Tail' closed-set categories from open-set classes.\n\nWeaknesses:\n* The main weakness for me is that the authors don't seem to mention or compare to [1], which is published work on the problem of OoD detection for long-tail recognition. This method also reports substantial boosts over baselines (though on small-scale OoD benchmarks). The authors should discuss and compare to this method if possible, or else explain why it cannot be done.\n* While I appreciate the efforts to impose a theoretical framework on the problem, I believe it makes the paper more confusing than clarified. I do not think that the proofs and arguments derived from the causal framework add anything to the argument which could not be more clearly expressed through a few lines describing the intuitions.\n* (Minor): There are a number of typos throughout the paper. For example, P_xout * P_yin = P_xout * P_yin in Assumption 1. \n\n[1] Partial and Asymmetric Contrastive Learning for Out-of-Distribution Detection in Long-Tailed Recognition, Wang et al., ICML 22",
            "clarity,_quality,_novelty_and_reproducibility": "I think the paper is relatively well written, with strong empirical findings and a strong motivation. My main issue on clarity is that I believe the causal framework proposed to analyse the problem obfuscates rather than clarities the problem.",
            "summary_of_the_review": "Overall, I think this is an interesting paper which proposes a simple solution to an important problem, which nonetheless demonstrates substantial boosts on a large-scale benchmark. Significant extra exploration is undertaken to provide additional details to explain the method. My main issue is that prior work in this space is not discussed or compared to, and hence I am hesitant to recommend a strong acceptance.\n\n**UPDATE AFTER AUTHOR RESPONSE:**\n\nAfter reading the other reviews and the (especially) the authors' responses, I have decided to upgrade my rating. Overall, I like this paper because it provides strong empirical results with a very simple method, to tackle an important and realistic problem. \n\nHowever, I would strongly suggest the following improvements to the paper:\n1) The authors should discuss [1]. Though it is a valid distinction that [1] trains with OoD data, it is not a completely different task. For instance, Outlier Exposure is still often referred to inference-only OoD detection papers, with reasonable discussion given on why inference-only methods operate in a different setting.\n2) I concur with the other reviewers that the theoretical causal framework does not add much to the paper's narrative, but rather distracts from the main findings.\n\n[1] Partial and Asymmetric Contrastive Learning for Out-of-Distribution Detection in Long-Tailed Recognition, Wang et al., ICML 22",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3905/Reviewer_vuMZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3905/Reviewer_vuMZ"
        ]
    },
    {
        "id": "y0Dt8ZJPHe",
        "original": null,
        "number": 2,
        "cdate": 1666637590033,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666637590033,
        "tmdate": 1666637692418,
        "tddate": null,
        "forum": "72lzvXrKqqd",
        "replyto": "72lzvXrKqqd",
        "invitation": "ICLR.cc/2023/Conference/Paper3905/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper modifies OOD detection methods which assume a balanced class distribution such that they are applicable to distributions with unbalanced classes.",
            "strength_and_weaknesses": "Strengths:\n\n- The paper tackles the important problem of transferring OOD detection methods that are known to work for class-balanced distributions to unbalanced ones.\n\n- The experimental results show good improvements compared to the presented implementations of the baseline methods.\n\nWeaknesses and open questions:\n\n- Assumption 1: What does $P_{X^{out} Y^{in}}$ mean exactly? This is central for the paper and as I read it it is not explained.\n\n- It is not clear why causal graphs are necessary to understand the independence of certain variables.\n\n- The claim that \"researchers assume that the pre-trained model f can simulate the ID conditional distribution\" should be substantiated. The methods proposed by this paper are motivated by achieving this simulation, so it is important to exhibit why it is necessary or desired.\n\n- The presented theorems are trivial.\n\n- Eq. (7) should be justified, as this is not the only possibility for aligning the minimizer of the score function with the class priors. For example, $max_i softmax_i f(x) / P_{Y^{in}}(i)$ would have the same minimizer but different behaviour away from the minimum.\n\n- For the reweighting strategy of Eq. (12), having a minus sign in front of the base score seems extremely unintuitive. That the cosine should get a minus sign is clear, but why does it also affect $S_{Method}$?\n\n- \"the system with a more concentrated probability distribution has lower energy, while the system with a more divergent probability distribution (more similar to the uniform distribution) has higher energy (LeCun et al., 2006). Thus, the energy of ID data is smaller than OOD data.\" -- This is not clear for the logits of a classifier trained with cross-entropy loss. The cited slides (LeCun et al., 2006) mainly describe models where the energy is regularized. How can those be connected with inference-time OOD detection?\n\n- The sign of Eq. (14) is wrong, since the *negative* energy is the base OOD detection score $S_{Method}$. This means that $-S_{Method}(f,x) = -T\u00b7\\log \\sum_k e^{f_i(x)/T}$. What does this mean that the AUROCs in Table 1 for RW+Energy?\n\n- In Figure 4, I would suggest showing only one of the similar metrics AUROC and FPR, and using the space to show all datasets.\n\n- Results for the balanced standard datasets should definitely be shown. Both for assessing the baselines compared to other publications and for checking how the proposed method (should only affect RW) impacts performance.\n\n- I think this paper could benefit from an analysis how the base methods which do not account for class imbalance fail. E.g. is it because ID samples from rare classes are being rejected too often, or because OOD samples receive imbalanced predictions that are close to the class priors rather than to the uniform distribution? The \"Analysis of Detection Results on Different ID Classes\" answers this partially, but it focuses on the improvements rather than on nature of the original problems.\n\n- The following previous works investigate class-dependent thresholding and should be discussed and potentially compared to.\n  - [Guarrera et al. 2022: Class-wise Thresholding for Robust Out-of-Distribution Detection]\n  - [Wang et al. 2022: Partial and Asymmetric Contrastive Learning for Out-of-Distribution Detection in Long-Tailed Recognition]\n\n- It is not clear to me whether the compared and improved methods are state of the art in the regarded setting as the paper claims. Many publications have worked with Vision Transformers pretrained on larger datasets -- which can be considered a different setting for OOD detection in particular as pointed out by [Hendrycks et al. 2022: Scaling Out-of-Distribution Detection for Real-World Settings] -- and achieve much better performance. This as well as other related works that work only with ID data should be discussed and compared to in order to provide context. It could also help emphasize that all methods that ignore potentially imbalanced classes need to be reconsidered.",
            "clarity,_quality,_novelty_and_reproducibility": "- While the paper contains quite many grammar errors, the general presentation is clear and easy to follow.\n- There are not very many previous works on OOD detection with imbalanced classes, and the proposed methods are to my knowledge novel in this area.\n- The experiments are described in detail and code for the evaluations in included in the appendix. The model checkpoints are not available; they would be useful to reproduce the exact results and compare them with other scoring methods. ",
            "summary_of_the_review": "The paper contains interesting approaches to OOD detection with a class-imbalanced in-distribution. However, as detailed above, particularly its methodology currently contains several problematic issues.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3905/Reviewer_G6VC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3905/Reviewer_G6VC"
        ]
    },
    {
        "id": "S2pbtqy9DQ",
        "original": null,
        "number": 3,
        "cdate": 1666696314682,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666696314682,
        "tmdate": 1666696314682,
        "tddate": null,
        "forum": "72lzvXrKqqd",
        "replyto": "72lzvXrKqqd",
        "invitation": "ICLR.cc/2023/Conference/Paper3905/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a very simple solution to an important problem of OOD detection. The authors study the effect of class imbalance in the training set. The idea is that if there is class imbalance, the current techniques that perform inference time OOD detection will fail as they assume uniform class probably distribution. To remedy this, the authors propose a simple fix in which: (1) If the methods explicitly use uniform prior, they replace it with training class probability distribution, or (2) For the methods that do not use class probabilities, they have a simple reweighting mechanism. Strong experimental results are obtained.",
            "strength_and_weaknesses": "The method is really simple, yet elegant. The authors clearly describe the motivation and present the fix they propose. It is well explained.\n\nOne of the most appealing features about the method was its ability to work with many other techniques. The authors show experiments of four such methods - MSP, ODIN, Energy and GradNorm. The method improves performance across board on all experiments.\n\nI also liked how extensive ablations were performed.\n\nOne question I had was what happens when you use your method on balanced dataset? I think it should go back to the original formulation and there should be no loss in performance compared to baseline. Does that happen?\n\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "I think the paper is well written and all experiments are performed well. The novelty seems to be good - even though its such a simple fix, the approach is general purpose and improves performance across the board on imbalanced datasets. It also seems reproducible. The authors have provided most details.",
            "summary_of_the_review": "I think the paper proposes a simple solution, which they have demonstrated to be quite effective. Overall, I like the paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3905/Reviewer_uGHp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3905/Reviewer_uGHp"
        ]
    },
    {
        "id": "APmAaGapqF",
        "original": null,
        "number": 4,
        "cdate": 1666717373801,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666717373801,
        "tmdate": 1666717373801,
        "tddate": null,
        "forum": "72lzvXrKqqd",
        "replyto": "72lzvXrKqqd",
        "invitation": "ICLR.cc/2023/Conference/Paper3905/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper explores the importance of ID class prior for OOD detection; two methods are proposed, replace and reweight, which can enhance the current logit-space OOD detection scores and improve the performance a lot. Both medical and theatrical analyses are conducted and provided. The experiments on benchmark datasets support their motivation.",
            "strength_and_weaknesses": "Another branch of OOD detection is feature-space detection scores, such as KNN. I think a discussion of the potential extension of their method on feature space may be good since logit-space scores may not well fit some real-world applications, even since not all applications have a good assumption.\n\nFig 2 shows the performance of the balanced and imbalanced dataset, which, if an OOD set is close to the tailed categories of ID data, such as the OOD set highly close to the minor categories, and what's the performance of their method? I think reporting some per-category or hard case OOD is also interesting instead of reporting the full dataset score.\n\nAssumption 1 seems good for natural images, while for those images with a huge domain gap between natural images, not the MINIST vs Fasion-MINIST one, how does assumption 1 fit for this case?\n\nAs for model selection, they only selected the ResNet for verification, it is reasonable for the standard setting, but considering that there are so many pretrained models existing, VIT, CLIP which was pretrained on large-scale data, reporting the scores for pretrained model with supervised or zero-shot setting is also necessary for the extension of this method since most of the recent OOD tasks are suing pretrained models.\n\nWhat's the performance on other scores, such as Maxlogit ? \n\nThe performance of AUROC and FPR95 are pretty low on Textures, which is interesting; even though Detection methods with the help of their method on other more natural-image-like datasets look good, textures still fail to perform OOD detection.\n\nThose selected datasets are pretty standard, and I wonder what the performance of zero-shot performance is with pretrained models (i.e, CLIP) when we use this method.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written and easy to understand, the motivation of this paper is clear and reasonable, and the results reported in this paper are promising. However, there are still some unresolved questions that need to be addressed.",
            "summary_of_the_review": "The idea of this paper is new and looks novel; the analysis of this paper supports their motivation. They also provide a good theatrical analysis of their discovery and idea. In general, I think this is a good finding for OOD detection.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3905/Reviewer_dyEV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3905/Reviewer_dyEV"
        ]
    }
]