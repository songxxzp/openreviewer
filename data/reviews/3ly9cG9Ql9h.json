[
    {
        "id": "aoENYxohYyU",
        "original": null,
        "number": 1,
        "cdate": 1666497082398,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666497082398,
        "tmdate": 1669005337821,
        "tddate": null,
        "forum": "3ly9cG9Ql9h",
        "replyto": "3ly9cG9Ql9h",
        "invitation": "ICLR.cc/2023/Conference/Paper2029/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work proposes to replace hand-written prompts used in CLIP style models with GPT-generated prompts for zero-shot image classification. The authors show that their approach (CuPL) of using LLMs to generate diverse text prompts, can improve classification accuracy while removing the need for hand-crafted prompts.",
            "strength_and_weaknesses": "Strengths\n1. The approach is simple and effective. They show that by using the knowledge baked into LLMs like GPT can be used to improve zero-shot classification accuracy. I think this contribution is neat! \n\n2. While some analysis is still missing in the paper (See weaknesses), I think the authors did a thorough empirical evaluation of their approach. I appreciated the author's effort on showing how different model sizes, number of LLM prompts, number of image prompts, LLM temperature affect performance. Per class accuracy difference (Figure 7) was also quite informative to look at! \n\nWeaknesses: \n1. Higher accuracy yes, but it doesn't remove the need for hand-designed prompts. As the authors mention in Figure 7, CuPL leads to significant accuracy boosts for certain classes (like mushrooms), but doesn't do well in other classes (canoe). This kinda means that hand-designed prompts can't be completely replaced because they bake in domain knowledge about the dataset. \n\n2. I am curious how the GPT prompts are helping improve classification accuracy. It would be nice to sort of look at which words in the image prompt (maybe by looking at attention distribution) are important. Doing this both for standard as well as LLM based image prompts might help understand why there is such a drastic jump ( +/- ~40%) in accuracy for different classes.  \n    - I found the 40% accuracy jump for `mushroom' quite surprising. My first intuition was that the proposed approach will work better for classes that have distinct parts (cars, scooters, chair, etc). I wonder why LLM based prompt helped for a category like a mushroom?\n\n3. Diversity Analysis (Figure 5) done on single LLM-prompt. It's quite possible that different LLM prompts, produces the same Image prompt. So an analysis of how different all the image prompts generated from different LLM prompts for a single image are would be nice. \n\n4. In figure 6, \n    - how did they choose which prompt to select when using fewer prompts. For instance, when only using 1 LLM prompt, which prompt did they use? \n    - I also didn't understand the caption for Figure 6 (left). The caption says that CuPL outperforms the baseline with just 3 hand-written sentences. But in the figure, CuPL is outperforming the baseline even with 1 LLM prompt. Can the authors please clarify? \n\n5. May I suggest adding a baseline that only uses 'a photo of a {}' prompt? The proposed approach lies somewhere in the spectrum of no-effort (using one standard prompt for everything), and high-effort (using standard hand-written prompts). We see where it lies with respect to high-effort. It'd be great to also see how the proposed approach compares to a _no-effort_ baseline.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and easy to follow. I think using GPT for generating prompts for CLIP style models is unique. The experiments are quite exhaustive demonstrating the effectiveness of the approach. The authors do a good job discussing each detail, and the work seems easy to reproduce.",
            "summary_of_the_review": "Overall, I like the paper. The paper presents a simple contribution and shows its effectiveness through thorough empirical evaluation. However, some analysis is still missing from the paper to build a better understanding of why the proposed approach is working. After reading the paper, apart from empirical evidence, there is little else to see the benefits of using the proposed approach. I think providing some of the analysis mentioned in my review will make the paper stronger and more insightful.\n\nUpdate after rebuttal: I thank the authors to provide answers to my questions and incorporating all feedback! I think the paper presents a simple to understand/implement/use contribution that is very effective! I quite like the paper and I am bumping my rating to 8 to reflect that. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2029/Reviewer_LiMR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2029/Reviewer_LiMR"
        ]
    },
    {
        "id": "zPvlPe6IhIC",
        "original": null,
        "number": 2,
        "cdate": 1666615819765,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666615819765,
        "tmdate": 1666726568469,
        "tddate": null,
        "forum": "3ly9cG9Ql9h",
        "replyto": "3ly9cG9Ql9h",
        "invitation": "ICLR.cc/2023/Conference/Paper2029/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes to generate prompts for zero-shot learning inference with CLIP by querying the large language model like GPT. The results show that the class prompts generated from GPT improves the zero-shot classification performance across many datasets. ",
            "strength_and_weaknesses": "Strength\n\n+It is interesting to generate prompts from LLM. Querying the description of an object class from LLM makes a lot sense because LLM is learned from large text corpus, covering knowledge about most of vocabularies. \n\nWeakness\n\n-I found this paper has little technical novelty. The proposed method generates prompts for each class from the outputs of a LLM i.e., GPT-3 and then use those prompts for zero-shot inference with the pretrained CLIP, which is straightforward and expected to achieve some improvement. \n\n-The author's main contribution is querying GPT but the design decision of why a particular prompt is chosen to query GPT3 for CuPL base and full are not discussed or ablated.\n\n-To my knowledge, using GPT-3 is not entirely free, which makes the method less appealing. Does this approach work well with other free LLM?\n\n-In Fig. 5, increasing the temperature of LLM also increases the randomness of the outputs. What is the standard deviation at each temperature?\n\n-The performance improvement are very minor and comes with a decrease in performance on other similar classes as shown in figure 7. This insight indicates that such a simple query setup is suboptimal for finegrained setting. The authors have not tried to mitigate this basic drawback. \n\n-Detailed analysis on what makes the GPT3 prompts work better than human designed ones is missing when it is the main contribution of the work. For example in figure 5 we see that GPT3 prompts only surpass generic hand designed prompts at ~0.56 temperature. Why is this so? How do the outputs of the language model change with this temperature setting and what contributes to this change. If the method is this sensitive to temperature value, it adds to additional labelling cost of running the GPT3 model to ablate over the temperature value. How sensitive is this temperature value on different datasets? This needs to be analysed and discussed in light of labelling cost of generic human prompts.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is written well and easy to understand because the method is rather simple. It might not be easy to reproduce the results because this requires users to query GPT-3 many times, which is not free.",
            "summary_of_the_review": "Due to the weakness mentioned above, I think this paper does not have sufficient contributions for ICLR. I would recommend a reject and suggest the authors submit it to a workshop.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2029/Reviewer_DGAE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2029/Reviewer_DGAE"
        ]
    },
    {
        "id": "uaFxvqjQ7N",
        "original": null,
        "number": 3,
        "cdate": 1666758333311,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666758333311,
        "tmdate": 1666758958403,
        "tddate": null,
        "forum": "3ly9cG9Ql9h",
        "replyto": "3ly9cG9Ql9h",
        "invitation": "ICLR.cc/2023/Conference/Paper2029/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper presents combines CLIP with large language models like GPT3 to create customized prompts for zero-shot image classification. Specifically authors leverage the knowledge contained in LLMs in order to generate many descriptive sentences that are customized for each object category for prompting CLIP models. Experiments on 15 downstream classification datasets show the effectiveness of the proposed method over handcrafted prompts that were used in the original CLIP adaptation.",
            "strength_and_weaknesses": "**Strengths**: \n\n- The paper is well-written and easy to follow.\n- The idea is very simple and performs reasonably well on standard classification datasets.\n\n**Weaknesses**:\n\n- The technical novelty of the paper is very limited. It simply combines GPT3 with CLIP without a clear motivation. It is not surprising that output of a large language model will have better descriptions/knowledge compared to vanilla prompt engineering like \"a photo of a\". So, what is the main contribution of the paper need to be clearly discussed in the paper. Why someone will adopt this approach given that it often requires higher computational resources for inferencing a GPT3 model (and sometime not accessible for all)?\n\n- Although the proposed framework uses a strong LLM like GPT3, the zero-shot classification performance on downstream datasets are very minimal. Training a continuous prompt, e.g., CoOp in Learning to Prompt for Vision-Language Models using 1-2 labeled samples performs significantly better than hand engineered prompts. It is often very practical to have 1-2 labeled samples per class inn many applications.  It is not clear why learning a single prompt using few labeled samples is not practical but the use of GPT3 can be considered practical for zero-shot classification? A thorough comparison and discussion with other prompt learning methods should be included in the paper.\n\n- How does the proposed framework with only one prompt compare to the baseline that uses prompt like \"a photo of a\" (no ensemble of prompts)? This is a very important experiment to verify the effectiveness of the proposed framework in fair manner.\n\n- What other generative LLMs besides GPT3 can be used and how are they comparable to the current one?\n\n- The experiments only show performance on CLIP, while there exists many other recent vision-langauge models, e.g., DeCLIP, FILIP, CLOOB, CyCLIP etc. Authors should perform experiments on a variety of V&L models to demonstrate the generalizability of the proposed method for generating better prompts.\n\n- Like original CLIP, CuPL still requires handcrafted prompts for LLM which is suboptimal. Identifying the right hand-crafted prompt is a non-trivial task, which often requires significant amount of time and domain-specific heuristics.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written with clear presentation of the technical details, figures and tables. However, as discussed above, the novelty of the work is very limited. Also, how the proposed method can be applied for classification on new datasets without significant manual engineering and access to GPT3 is not clear.",
            "summary_of_the_review": "I\u2019d like to rate the current submission as a clear rejection due to very limited technical novelty and lack of convincing experiments. Despite all the changes, I still feel the paper will not have enough contributions to be accepted for ICLR.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2029/Reviewer_ECmW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2029/Reviewer_ECmW"
        ]
    },
    {
        "id": "7kwQ74Als1c",
        "original": null,
        "number": 4,
        "cdate": 1666852459015,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666852459015,
        "tmdate": 1667104475180,
        "tddate": null,
        "forum": "3ly9cG9Ql9h",
        "replyto": "3ly9cG9Ql9h",
        "invitation": "ICLR.cc/2023/Conference/Paper2029/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Open vocabulary models require natural language prompts as an intermediate medium between category and visual content, thus it is important to choose a good prompt. In this paper, the authors study how to use a pretrained language model to help generate better language prompts for open vocabulary tasks. The authors feed the categories with language prompt templates to an LLM and use the output of the LLM as the image prompts. The authors show that the prompts generated by their method can achieve better performance on zero-shot image classification benchmarks. ",
            "strength_and_weaknesses": "Strength:\n- The paper is well written. The method is intuitive and the performance gain is good.\n- The authors did different ablation studies to show how different design choices would affect performance including the number of prompts, diversity of prompts, model size, etc. These ablations are helpful for the audience to understand the full picture of this method.\n\nWeaknesses:\n- Although the general idea is good, the authors only consider one task in this paper which is zero-shot image classification. It is more interesting for tasks like open vocabulary segmentation/detection etc. This method can even be used for image caption retrieval where LLM is used to paraphrase the caption. It is more convincing that the proposed method can universally work on different tasks.\nEven for imagenet, it is more interesting to see the performance on the full imagenet21k instead of the 1k set. In addition, original CLIP is evaluated on different relatives of Imagenet like imagenet-v2, imagenet-R etc. which would also be good to have in this paper.\n- It would be better if there can be a clear analysis or explanation of why the standard prompts and CuPL prompts have different preferences as shown in figure 7. It is a really interesting phenomenon to me, and it may also reveal some hints on how to improve CuPL.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity questions:\nHow are \u201chyperparameters\u201d like the number of prompts and which specific prompts to choose decided? Is there a \u201cvalidation set\u201d?\nIs there qualitative or anecdotal analysis of how \u201cdiverse\u201d the generated image prompts are after increasing the temperature? For example, would higher temperatures also \u201churt\u201d by introducing more incorrect knowledge?\n\nMinor comments:\nFigure 6: CuPL outperforms the baseline even with just three hand-written sentence. Should be one hand-written sentence.\nAlso, how many prompts are there for Figure 6 left figure? If it is 10, it means that 10 CuPL image prompts can outperform 80 standard image prompts which is less than 25 in the caption.\n\nThe paper is novel and easy to reproduce.",
            "summary_of_the_review": "The authors propose a novel method that is simple and has the potential to apply to many different tasks. However, the authors did not show that this method is widely applicable which makes the paper weaker. My decision is borderline accept.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2029/Reviewer_UY2k"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2029/Reviewer_UY2k"
        ]
    }
]