[
    {
        "id": "kG_HHhZTXU",
        "original": null,
        "number": 1,
        "cdate": 1666540564138,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666540564138,
        "tmdate": 1666541302878,
        "tddate": null,
        "forum": "DaYt6DAA-JK",
        "replyto": "DaYt6DAA-JK",
        "invitation": "ICLR.cc/2023/Conference/Paper6047/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents an approach, MiDAS, to classify new samples in the situation where there are multiple domains and domain concepts drift over time. The proposed method has two components: a domain-invariant encoder, and an adapetive model selector. The encoder creates domain-invariant representations for data samples and the selector uses Lipschitz smoothness to estimate the best-fit model for a new sample. Experimental evaluation is performed on several fake-news datasets.\n",
            "strength_and_weaknesses": "Strengths:\n\n+This paper introduces the problem of concept drift in misinformation clearly. The motivation of designing a domain-adaptive approach is clear.\n\n+The proposed framework is well described with figures and details. The first part, the encoder, aims to learn domain-invariant representations for data samples. Based on the learned representations, this paper introduces the Lipschitz continuity and extends this to find the best-fit model from multiple source models. \n\n+Experiments are performed on multiple fake news datasets to test the performance of the proposed approach on classifying unseen/drifted distributions. Ablation studies are performed by changing the number of training datasets, types of loss functions, masked language model training, and loss weights.\n\nWeaknesses:\n\nFirst, this paper focuses on the application of fake news detection. However, the connection between the proposed model with fake news seems not strong. Very little analysis of fake news data distributions is provided. Datasets are not described in detail. The unique challenges in fake news detection are not introduced. If the proposed method is a general approach for any concept-drift problems, the experiments are only conducted on fake-news datasets.\n\nSecond, the motivation for using Lipschitz smoothness to estimate/find the best source model/function for an unlabeled and potentially drifting sample is not strong. The reasons for using this notion should be better elaborated.\n\nThird, some notations can be better clarified. For instance, how is function theta specified is not clearly described in the methodology section. Equation 3 seems to use absolute difference, but the reason why this can be used for estimating the smoothness of source functions remains unclear. The motivation for using probabilistic Lipschitzness can be better explained. It would be more convincing if examples or proofs of changes in perturbations are provided.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The coherence of this paper can be improved. Especially, how the proposed work can solve unique challenges in fake news concept drift problems can be clarified. Notations should be described in detail.\n\nQuality: The proposed method seems not well motivated. It is unclear how Lipschitzness smoothness is the best fit for fake news concept drift problems.\n\nNovelty: the proposed idea is interesting. I think the intuition behind proposing this idea can be strengthened.\n\nReproducibility: code is provided in the supplemental material.\n\nMinor comments: in Abstract, there is a typo: \u201ca doman-invariant encoder\u201d. Page 6: Ablation Study: \u201cmasked language model trainig\u201d.\n",
            "summary_of_the_review": "This paper presents a solution for classifying samples when multiple source domains are present and concept drifts exist. The target application is fake news detection, however, the connection of the proposed framework with this specific application is not strong. The motivation for using Lipschitzness should be better described.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6047/Reviewer_WVAw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6047/Reviewer_WVAw"
        ]
    },
    {
        "id": "gTAtW2vzt1w",
        "original": null,
        "number": 2,
        "cdate": 1666590769596,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666590769596,
        "tmdate": 1666590769596,
        "tddate": null,
        "forum": "DaYt6DAA-JK",
        "replyto": "DaYt6DAA-JK",
        "invitation": "ICLR.cc/2023/Conference/Paper6047/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors in this paper present Multi-Integrated Domain Adaptive Supervision (MiDAS), a framework for fake news detection that ranks the relevance of existing models to new samples. MiDAS learns domain-invariant representations by integrating multiple pre-trained and fine-tuned models with their training data. To determine each model's relevance to a new sample, MiDAS applies local Lipschitz smoothness of the invariant representation in latent space. Empirical results show MIDAS improves significantly on generalization accuracy across 9 diverse fake news datasets.",
            "strength_and_weaknesses": "Strength:\n\n1. This paper focuses on an interesting problem, the detection of fake news, especially Covid-19 news. It is impactful and has a sociological significance. \n\n2. The idea of extending local Lipschitz smoothness in measuring the relevance of a new sample to existing models is somewhat novel. \n\n3. The paper is illustrative with an ablation study by varying the number of training datasets, types of loss functions, masked language model training, and loss weights. \n\nWeakness:\n\n1. The main idea of this paper is based on prior work: local Lipschitz smoothness from (Chen et al., 2022). However, comparison results with the method  LIGER from (Chen et al., 2022) are missing. \n\n2. The sizes of the datasets used in the evaluation are quite small and the numbers of samples are in the thousands. To demonstrate the scalability of the proposed method, much larger datasets are recommended. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and easy to follow. \n\nTypos: \nsection 4.1:  \"TO train E\" -> \"To train E\" \ncaption of Figure 1:  should be  {M}_{(i = 1)}^k \n\nGiven the prior work local Lipschitz smoothness (Chen et al., 2022), the novelty of this paper is thin. It'd be great if the proposed method could be compared with the method LIGER from (Chen et al., 2022). \n\nAny t-test results for the comparisons in Table 2 and 3? ",
            "summary_of_the_review": "This paper presents a multi-domain adaptative approach for early fake news detection, which integrates pre-trained and fine-tuned models along with their training data to learn a domain-invariant representation. In this representation, the proposed framework adaptively selects the highest-ranked model to perform classification according to the relevancy between a new sample and model training datasets.\n\nIn general, the idea of using randomized Lipschitz smoothness measure to generate source model relevancy rankings is reasonable and effective for fake news detection. \n\nHowever, the contribution of the paper is incremental given the prior work local Lipschitz smoothness (Chen et al., 2022). \n\nThere are missing technical details:\n1. What are the t-test results for Table 2 and 3? \n2. What are the results in terms of other metrics such as F1 and coverage for Table 2 and 3? \n3. Complexity analysis of the proposed method? \n\nTo demonstrate the scalability and efficiency of the proposed method, evaluation on much larger datasets is recommended. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6047/Reviewer_i2cY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6047/Reviewer_i2cY"
        ]
    },
    {
        "id": "PsBoL61RMFq",
        "original": null,
        "number": 3,
        "cdate": 1666651557056,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666651557056,
        "tmdate": 1666651557056,
        "tddate": null,
        "forum": "DaYt6DAA-JK",
        "replyto": "DaYt6DAA-JK",
        "invitation": "ICLR.cc/2023/Conference/Paper6047/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper introduces a novel approach to  the problem of out-of-domain  texts for fake news classification.  The method involves an adaptive model selector which employs Lipschitz smoothness concept to estimate model's relevancy.  \nThe paper shows superiority over a number of baselines and previously introduced methods.  \n\n",
            "strength_and_weaknesses": "strengths\n* the paper proposes a novel approach  that is superior to the presneted previosu approaches \n* the paper provides concise overview of the Lipshitz smoothness concept to explain its efficiency for the problem \n* the analysis is conducted on multiple test sets \n* ablation study and parameter analysis provides additional soundness to the paper  \n\n\nweaknesses: \n* more as a point of observation, the propsed method  does not use any features that makes it specifivcally focused on fake news detection or COVID dataset. It could have been applied and verified on groups of datasets for a variety of classificationn tasks. That could have made the work more impactful, and the empirical groundings more sound. This is my major concern towards this work: if the porposed method is correct, it should generalize across any text classification tasks (that satisfy Lipschitz smoothness requirements) and applying it towards a certain subrgroup of text classification (even as \"trendy\" as fake news and covid fake news in particular) diminishes the potential contribution, making the paper more apt for a focused workshop rather than the main conference venue.  \n\n* there's a few novel points introduced in the paper: a use of certain architecture, application of concept of Lipschitz smoothness, parameter analysis. However, there's some lack of clarity. The paper would benefit from more detailed explaining  why certain choices were made, what is the intended scope of the method, does it imply any retrsictions on the data or the models involved, etc?",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\n\nGiven that the paper introduces complex ideas, I'd suggest providing more details about the  approach to solution as well as the proposed method in a few sections. Some material may0Car be   \n\nIntroduction\n\n\"This degree of knowledge is defined by the overlap between an unlabeled sample and existing models\u2019 training datasets\"  - overlap in what sense?\n\n3 PROBLEM SETUP AND STRATEGY\n\n\"... where we have access to the training data Xi and weights wi.\" - Could you provide a more elaborated definition on \"w_i\"?  weights as model parameters?\n\n\"Each SM yields hidden embeddings through a feature extractor backbone, or foundation model\" - this implies certain assumpton sabout the Source Models. This should be stated clearly in the scope fo this work.\n\n\n4.\n\n\"we use the masked language modeling loss from BERT and AlBERT pretraining.\"  - please, explain the choice of the LMs\n\n\n4.2 RANDOMIZED LIPSCHITZ SMOOTHNESS - I'd suggest moving this section partially or entirely to apendix to provide more space for explaning some MiDAS specific details as well as other details o fthe current work to increase clarity.   \n\n5.\n\n\"NVIDIA T100 GPUs.\"  - I was not able to verify Nvidia T100 GPUs (there are V100 and T1000 or T400). Either there's a typo, or  please provide a footnote with more details if it's a speacial case.\n\n\n\"an \u2018oracle\u2019 fine-tuned AlBERT model trained on the held-out dataset.\" - if AlBERT is used for the oracle, is it BERT's or AlBERT's LMs that are used fro MiDAS.\n\n\n**Novelty**\n\nFrom what I could judge by related work section and the refernces, the paper introduces a novel and original approach. \n\n",
            "summary_of_the_review": "The main observation about this paper is that it seem to introduce a general method applicable to text classification, yet only verifies it for quite a narrow, albeit important, area of covid-related fake news detection. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6047/Reviewer_5EyG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6047/Reviewer_5EyG"
        ]
    },
    {
        "id": "K7jTGF4RW0",
        "original": null,
        "number": 4,
        "cdate": 1666686435800,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666686435800,
        "tmdate": 1666687669686,
        "tddate": null,
        "forum": "DaYt6DAA-JK",
        "replyto": "DaYt6DAA-JK",
        "invitation": "ICLR.cc/2023/Conference/Paper6047/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper introduces MiDAS, a novel method to address the problem of out-of-domain texts for fake news classification. MiDAS applies an adaptive model selector that utilizes the Lipschitz smoothness idea to estimate the model's relevancy. The author shows supremacy over several baselines and previously introduced methods.",
            "strength_and_weaknesses": "Strength:\n1. This paper focuses on an exciting problem, detecting fake news, especially COVID-19 news. It is impactful and has sociological value.\n2. Using local Lipschitz smoothness is a new way to figure out how well a new sample fits existing models, which is very exciting.\n3. An ablation study is used as an example in the study. The number of training datasets, types of loss functions, masked language model training, and loss weights are all changed.\n\nWeakness:\n1.\n2.\n3.",
            "clarity,_quality,_novelty_and_reproducibility": "Given the prior work on Lipschitz smoothness by Chen et al., (2022), the novelty of this paper is very small. It will be great if the author could compared their work with the work from the reference above.\nThe author should look through the problem setup and strategy (Section 3):  \n\"... where we have access to the training data Xi and weights wi.\" - Could you provide a more elaborated definition on \"w_i\"? Using weights as model parameters? \"Each SM yields hidden embeddings through a feature extractor backbone or foundation model\"\u2014this implies certain assumptions about the source models. This should be stated clearly in the scope of this work.-- please check~",
            "summary_of_the_review": "In order to learn a domain-invariant representations, the multi-domain adaptive method for premature false news detection presented in this study combines pre-trained and improved models with their training examples. According to the similarities between a new sample and model training datasets, the designed system adaptively selects the highest-ranked model to carry out classification in this representation. In general, it makes perfect sense and performs well for detecting fake news to use randomized Lipschitz smoothness metric to produce source model relevancy rankings.\n\nA few novel points are introduced in the paper: the use of particular architecture, the application of the concept of Lipschitz smoothness, and parameter analysis. However, there is some lack of clarity. The paper would benefit from a more detailed explanation of why confident choices were made, the intended scope of the method, does it imply any restrictions on the data or the models involved, etc.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No comments",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6047/Reviewer_35Bs"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6047/Reviewer_35Bs"
        ]
    }
]