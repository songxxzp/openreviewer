[
    {
        "id": "jdgMysJTSo",
        "original": null,
        "number": 1,
        "cdate": 1665974695084,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665974695084,
        "tmdate": 1665974695084,
        "tddate": null,
        "forum": "ILQVw4cA5F9",
        "replyto": "ILQVw4cA5F9",
        "invitation": "ICLR.cc/2023/Conference/Paper884/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces a learning-based distributed multi-view image coding (LDMIC) method. LDMIC consists of independent encoders and a decoder equipped with a cross-attention mechanism based joint context transfer module. The proposed method does not need synchronization between cameras and is insensitive to the epipolar geometry relations between images. Experimental results show that LDMIC outperforms existing multi-view image coding methods in saving bitrate.\n",
            "strength_and_weaknesses": "Strength\n- This paper introduces a distributed multi-view image coding framework that decouples the inter-view operations at the encoder, which is a good property in a distributed camera system.\n- This paper proposes a joint context transfer module at the decoder to capture inter-view correlations for image reconstruction.\n- Extensive experimental results show that the proposed method outperforms existing single and multi-view image codecs in PSNR.\n\nWeaknesses\n- The authors claim that the proposed joint context transfer module \"can serve as a plug-and-play component to enhance the performance of learning-based MIC methods\" in the last paragraph of Page 2. However, no supporting experiments are shown\n- It appears to me that the technical part of the proposed method is straightforward and not very novel.\n- It is unclear what is the fast variant of the proposed method. Is it the one using the checkerboard model? Please clarify.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written and the originality is fair.",
            "summary_of_the_review": "This paper introduces a simple yet effective method for distributed multi-view image coding, and experiments demonstrate the effectiveness of the method. I would like to give a weak accept rating. However, one of my concern is that the problem tackled by this paper (multi-view image coding) seems to be very specific and only attract a limited amount of audiences in ICLR. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper884/Reviewer_WX5p"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper884/Reviewer_WX5p"
        ]
    },
    {
        "id": "72fPIGEaTc",
        "original": null,
        "number": 2,
        "cdate": 1666243816150,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666243816150,
        "tmdate": 1666243816150,
        "tddate": null,
        "forum": "ILQVw4cA5F9",
        "replyto": "ILQVw4cA5F9",
        "invitation": "ICLR.cc/2023/Conference/Paper884/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors proposed a learning-based multi-view coding framework comprising of  individual encoding and joint decoding of a set of multi-view images. Under their framework, inter-view coherency can be used for improving the coding performance while eliminating the need of communication among the distributed encoders for individual views. The proposed method was designed to be symmetric: each view is treated equally, and independent of the number of viewpoints. To this end, they incorporated joint context transfer modules into the decoder, where the features from a specific viewpoints are enhanced by those from the other viewpoints via the multi-head cross attention module. The experimental results include extensive comparisons with previous works in terms of the coding performance and computational efficiency, ablation studies for verifying their distributed framework and joint decoding design, and subjective evaluations.",
            "strength_and_weaknesses": "Strengths\n\n- The paper is well written and easy to follow. The story (background) behind this work is well composed in a succinct manner. The proposed method is clearly motivated and well explained to the details. \n\n- Although there are some previous works on distributed coding of multi-view images, this is the first work to develop a view-symmetric framework with deep learning and achieve the coding performance comparable to the SOTA joint encoding-decoding schemes.\n\n- The experimental evaluation is extensive with convincing results. Especially, the proposed method clearly outperforms NDIC (the method closest to the authors') in terms of the coding efficiency. Moreover, the presented results include many insights: the effectiveness of inter-view cross attention compared to the conventional disparity-based prediction, the advantage of the view-symmetric design over the asymmetric one, and the effectiveness of the joint encoder-decoder training for making the latent representation more efficient.\n\nWeaknesses\n\n- I have a concern for Fig. 4 (c) and (f). The authors state that these graphs are drawn for the selected cameras (C1 and C4). However, most of the methods presented in these graphs take joint decoding or joint coding-decoding scheme, where the information from all the cameras are jointly used. Therefore, it is theoretically impossible/meaningless to define the bitrate only for the selected cameras. \n\n- As the authors admitted, a simple average pooling for merging multi-view information is not sufficient enough; as shown in Table 3, increasing the number of views did not much contribute to the reconstruction quality.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity, Quality, and Reproducibility: The paper is clear and easy to follow. The proposed method was presented to the details. However, I have several suggestions to improve the clarity and reproducibility.\n\n- The meaning of \"the fast variant\" of the proposed method is not clear enough. I guess this refers to the one where the auto-regressive model is replaced by the checkerboard model in the context modeling for entropy coding. \n\n- The competing baselines are categorized in the text. It would be better if this categorization was clearly presented in Fig. 4 and Table 1 as well.\n\n- More implementation details for the ablation study is helpful for readers. For example, I cannot imagine how Joint Enc-Dec was implemented. Moreover, the authors did not mention how \"the pre-trained encoder\" was obtained (what were the condition and dataset for the pre-training) for the w/o joint training case.\n\nNovelty: I think this work has sufficient novelty for presentation at ICLR. Although there are some previous works on distributed coding of multi-view images, this is the first work to develop a view-symmetric framework with deep learning and achieve the coding performance comparable to the SOTA joint encoding-decoding schemes.",
            "summary_of_the_review": "The paper is well written, the authors' proposal has sufficient novelty, and experimental results are extensive and informative for the community. However, I have several concerns for the correctness (Fig. 4 (c) and (f)) and clarity. I would like to recommend acceptance for this work, but not strongly so. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No specific concerns.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper884/Reviewer_8AGJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper884/Reviewer_8AGJ"
        ]
    },
    {
        "id": "9ldIW8LbjJm",
        "original": null,
        "number": 3,
        "cdate": 1666598500303,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666598500303,
        "tmdate": 1666598500303,
        "tddate": null,
        "forum": "ILQVw4cA5F9",
        "replyto": "ILQVw4cA5F9",
        "invitation": "ICLR.cc/2023/Conference/Paper884/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed a learning-based approach for multi-view image coding. Specifically, the proposed method decouples the inter-view operations during the encoding and thus is suitable for the distributed system. Thorough evaluations demonstrate the effectiveness of the proposed method in terms of PSNR and SSIM.",
            "strength_and_weaknesses": "- Strengths:\n  - This paper is well-written and easy to follow.\n  - The proposed method performs favorably against existing image compression methods.\n  - The proposed protocol for the distributed system is interesting and useful.\n- Weaknesses:\n  - Since this task is mainly about compressing multiview images, there should be some priors that can be leveraged. Such as epipolar constraints. However, I do not see any special design of the proposed method in addition to handling multi-frame. Is there any reason for not using these priors to encode multiview images better?\n  - I do not see many technical novelties in this paper. The proposed architecture is similar to VQVAE and VQGAN. The authors do not specifically point out how you integrate the existing architecture into this task and why does it help to get better compression results?",
            "clarity,_quality,_novelty_and_reproducibility": "This paper reads well and is easy to follow. However, the technical novelty seems to be limited. As the proposed architecture is similar to existing methods such as VQVAE and VQGAN, I wonder why the authors want to leverage this architecture to tackle this task. Also, I encourage the authors to provide the implementation and the pre-trained model for reproducibility.",
            "summary_of_the_review": "This paper achieves the best performance on the task of multiview image coding. However, I do not see many technical novelties in the method or architecture design. The most exciting part is that one can use the proposed method for the distributed system. I lean toward accepting this paper but rejecting it is also acceptable.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper884/Reviewer_XGBn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper884/Reviewer_XGBn"
        ]
    },
    {
        "id": "3qnhEmZKOY",
        "original": null,
        "number": 4,
        "cdate": 1666847689134,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666847689134,
        "tmdate": 1666847689134,
        "tddate": null,
        "forum": "ILQVw4cA5F9",
        "replyto": "ILQVw4cA5F9",
        "invitation": "ICLR.cc/2023/Conference/Paper884/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed a novel deep learning based framework to effectively encode the distributed multi-view images. Unlike previous multi-view image coding (MIC) architectures that utilized a shared encoder to explore the inter-view redundancy, the proposed method moved this part to decoder and successfully reduced the computational costs in MIC. The experiments demonstrate the robustness and efficiency of proposed method.",
            "strength_and_weaknesses": "Strength:\n+ The paper is well written and easy to follow\n+ The results are good compared with SOTA\n+ The experiments are comprehensive and well evaluate the performance on different datasets\n\nWeakness:\n- It will be great if there's a short discuss of failure cases. ",
            "clarity,_quality,_novelty_and_reproducibility": "I believe that this paper is of high quality",
            "summary_of_the_review": "In summary, this paper proposed a novel coding algorithm that can decouple the encoding of images acquired by distributed cameras. The method seems to effective and the results are good. The paper is well written and the comparison experiments are comprehensive. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper884/Reviewer_11ke"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper884/Reviewer_11ke"
        ]
    }
]