[
    {
        "id": "bj_y0Rc3336",
        "original": null,
        "number": 1,
        "cdate": 1665833004929,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665833004929,
        "tmdate": 1665833027354,
        "tddate": null,
        "forum": "uwBUzlm0GS",
        "replyto": "uwBUzlm0GS",
        "invitation": "ICLR.cc/2023/Conference/Paper2237/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper is 16 pages (+references), while the strict upper bound for ICLR is 9 pages. Thus I treat this paper as desk rejected.",
            "strength_and_weaknesses": "Exceeds page limit.",
            "clarity,_quality,_novelty_and_reproducibility": "Exceeds page limit.",
            "summary_of_the_review": "Exceeds page limit, desk reject.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2237/Reviewer_KSN3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2237/Reviewer_KSN3"
        ]
    },
    {
        "id": "IwUPDjAcmzW",
        "original": null,
        "number": 2,
        "cdate": 1666601889809,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666601889809,
        "tmdate": 1666601889809,
        "tddate": null,
        "forum": "uwBUzlm0GS",
        "replyto": "uwBUzlm0GS",
        "invitation": "ICLR.cc/2023/Conference/Paper2237/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes a new family of activation functions called LAUs (Logmoid Activation Units). LAUs have two parameters \u03b1 and \u03b2, and the authors comprehensively discuss the change of LAUs and their derivatives with different \u03b1 and \u03b2. The authors also prove that Logmoid-1 (a special case of LAUs) makes Feed-forward neural network achieves lower approximation error than Swish with both mathematical and experimental results. The authors show that LAUs perform better than baseline activation functions on different datasets and architectures.",
            "strength_and_weaknesses": "Strength:\nThe proposed LAUs are simple and easy to implement.\n\nWeakness:\n1.\tInsufficient experiments. Pade is introduced in Section Related Works, but the authors did not compare LAUs with Pade among all the benchmark experiments. Besides, there are too many experiments on tiny datasets and networks, making the improvements not very impressive and convincing. Similar to Pade, I suggest the authors provide results of LAUs on ImageNet-1K with MobileNet-V2. Furthermore, there are many powerful activation functions like ACON (Activate or Not: Learning Customized Activation) and PWLU (Learning specialized activation functions with the Piecewise Linear Unit) that the authors did not see. To make the results more convincing, I suggest authors compare LAUs with ACON and PWLU.\n2.\tThis paper is badly written. Section 4.1 suddenly appears without any introduction, which makes readers confused. And Section 4.2 is unnecessary because Section 5 provides experiments about Logmoid-1. All the tables are not centered. Table and figure captions are not clear enough for readers to understand. \n3.\tLimited novelty. There are many Sigmoid-based activation functions like Soft-Root-Sign and ACON, and it is convenient to provide different Sigmoid-based activation functions with search methods. So I do not see much novelty in this paper.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: bad\nQuality bad\nNovelty: limited\nReproducibility: best\n",
            "summary_of_the_review": "The proposed LAUs are Sigmoid-based activation functions. The overall novelty is limited, and missed essential experiments. The paper is bad-written with the problem of duplication and lack of logical coherence.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2237/Reviewer_Ea8B"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2237/Reviewer_Ea8B"
        ]
    },
    {
        "id": "aBQBcU9b765",
        "original": null,
        "number": 3,
        "cdate": 1666681474093,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666681474093,
        "tmdate": 1666681474093,
        "tddate": null,
        "forum": "uwBUzlm0GS",
        "replyto": "uwBUzlm0GS",
        "invitation": "ICLR.cc/2023/Conference/Paper2237/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces a new logmoid activation unit, that has nice properties to approximate continuous function and introduce performance gain over other activation functions across multiple datasets.",
            "strength_and_weaknesses": "Strength:\n1. an interesting activation function with two parameters that covers the geometry of existed activation functions.\n\n2. theoretical analysis in terms of approximating continuous functions.\n\n3. excellent results achieved over multiple network structures and datasets.\n\nWeakness:\nthe experiments are far from extensive.\n1. we do not know if this activation works for other tasks like detection/segmentation.\n2. it is unknown if this activation works for transformer.\n3. it is unknown if this activation works well with dynamic operators like SE in MobileNet-V3.\n4. it is unknown if this activation works well for large scale dataset (ImageNet-1K, ImageNet-22K).\n",
            "clarity,_quality,_novelty_and_reproducibility": "I like the idea and the theoretical analysis, but not satisfied with the experiments. A good activation function should be able to work well for multi-tasks, multi-architectures and large scale dataset, which is not validated in the paper. ",
            "summary_of_the_review": "This paper is borderline: interesting idea, good analysis, but weak experiments (see weakness)",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2237/Reviewer_MpkZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2237/Reviewer_MpkZ"
        ]
    }
]