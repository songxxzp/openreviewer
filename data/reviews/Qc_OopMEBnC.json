[
    {
        "id": "hDgVBWfV4zd",
        "original": null,
        "number": 1,
        "cdate": 1666356071026,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666356071026,
        "tmdate": 1666356478748,
        "tddate": null,
        "forum": "Qc_OopMEBnC",
        "replyto": "Qc_OopMEBnC",
        "invitation": "ICLR.cc/2023/Conference/Paper3111/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This work proposed a label correction method to tackle the label noise in the segmentation task.  They propose an algorithm to correct the Markov label noise.\n",
            "strength_and_weaknesses": "Strength: \nThe Markov model for segmentation label noise considers spatial correlation.\n\nWeakness:\nThe spatial correlation proposed by the authors contradicts the input 2D image. Whether the authors consider three-dimensional spatial correlations.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The contributions are only marginally significant or novel.\n",
            "summary_of_the_review": "This paper proposed a Markov process to model segmentation label noise. The issue that this paper focuses on are important but not very attractive. The method needs to be extended for better tackle the problem of the 2D/3D segmentation label noise. Whether it is more convincing to experiment with real data labeled by different intern doctors. More specifically,\n1. It is strongly recommended that the input be changed to 3D voxel segmentation to match SC.\n2. The results of the Brats 2020 dataset should show multi-class results.  Is this method capable of handling the multi-class segmentation label noise problem?\n3. Fig.3 is hard to follow with the 3-step Markov process.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3111/Reviewer_VNP8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3111/Reviewer_VNP8"
        ]
    },
    {
        "id": "Oas-eVhtDs",
        "original": null,
        "number": 2,
        "cdate": 1666634737583,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666634737583,
        "tmdate": 1669114768122,
        "tddate": null,
        "forum": "Qc_OopMEBnC",
        "replyto": "Qc_OopMEBnC",
        "invitation": "ICLR.cc/2023/Conference/Paper3111/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposed a method for learning image segmentation from noisy annotation. The noise model proposed models human annotation errors that are spatially correlated and dependent on local image features. Results of the approach is compared to a wide range of prior work using artificially added noise in three different datasets and on a single dataset with real noise.",
            "strength_and_weaknesses": "Strengths\n------------\n- The approach addresses the important and relevant problem of learning to segment from noisy labels.\n\n- The proposed method seems relatively simple and the ideas underlying it makes sense.\n\n- The approach is compared to a wide range of relatively recent prior work and shows superior results.\n\nWeaknesses\n----------\n- Sentences in abstract seem condenced to the point where some meaning is lost.\n\n- Table 1 list Dice scores of the model along with other methods for learning with noisy labels in datasets with artificial noise added. Noise is added according to the noise models that is also used by the proposed approach to remove the noisy labels. While this is of course a nice sanity check of the proposed approach, it is perhaps not surprising that the proposed approach would excel at this. I would suggest the authors discuss the limitations of this experiment more clearly.\n\n- Only a single experiment is done with real noisy labels. I would have appreciated more experimentation on real data. Noisy labels in segmentation is generally the rule rather than the exception, particularly with medical images. I think i\nt would have greatly strengthened the manuscript if the authors had made a greater effort to show their method can help to solve this problem.\n\n- Code is not provided, which could hurt reproducibility.\n",
            "clarity,_quality,_novelty_and_reproducibility": "On clarity, I find the work to be relatively easy to read and follow.\n\nOn quality, the limited experimentation on real data makes me question how broadly these results generalize.\n\nOn novelty, the approach claims to be the first noise model that is tailored for segmentation tasks. Have no evidence otherwise.\n\nOn reproducbility, it is a shame the authors have not chosen to share code to reproduce the experiments.\n",
            "summary_of_the_review": "I have put the paper marginally below the acceptance threshold. I do like the paper and the approach, but I would have expected a little bit more in terms of showing that it works with real data.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3111/Reviewer_VpVv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3111/Reviewer_VpVv"
        ]
    },
    {
        "id": "JbF6Jh0NnP6",
        "original": null,
        "number": 3,
        "cdate": 1666857825871,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666857825871,
        "tmdate": 1670864917369,
        "tddate": null,
        "forum": "Qc_OopMEBnC",
        "replyto": "Qc_OopMEBnC",
        "invitation": "ICLR.cc/2023/Conference/Paper3111/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper presents an approach to correct noise annotation for segmentations by making use of spatially-aware operations about flipping labels on the boundary of the segmentation. The proposed method uses clean validation data to calculate the bias of the predicted segmentations and uses the specific noise model together with the inferred noise parameters to correct the predictions of the trained segmentation model. This process can be applied iteratively until the predictions are unbiased. The paper compares the proposed method on three medical imaging datasets (ISIC, JSRT and BRATS) as well as the cityscapes dataset and shows superior performance to relevant baselines. The experiments on the medical imaging datasets introduce synthetic noise to the segmentations while the cityscapes task uses coarse-grained segmentations to predict the fine-grained ones.",
            "strength_and_weaknesses": "Strengths:\n- The paper is well-written and easy to follow.\n- The method appears to be novel and produces competitive or superior performance on the shown experiments.\n- The method is an interesting step towards spatially-aware modelling of segmentation noise.\n\nWeaknesses:\n- The experiments seem like they might be biased. The medical imaging experiments only use the proposed noise model to add synthetic label noise. How would the model perform with a mismatch in label noise? One potential avenue for studying this would be to use a dataset such as LIDC-IDRI that comes with multiple annotators and define the ground truth as a majority voting of the individual labels and select a single rater as the noisy annotations.\n- The method implicitly assumes contiguous regions without holes to be segmented. How would this method perform with potential holes within the segmentation masks?\n\n\nMisc:\n- In the related work you mention that superpixel based approaches are not capable of addressing the challenges of noisy segmentation labels. Could you elaborate on this?\n- I am curious how this method would compare to weak segmentation methods that only use bounding boxes etc as labels. One could argue that the problems that are solved in both cases are very similar.\n- I am curious about the relationship between this method and methods that aim to model spatially aware uncertainty of the segmentation predictions (e.g. [1]). Would spatial awareness in the modelling be sufficient to then calibrate the predictions based on the estimated bias of the annotations?\n- p3: \"net-work learning\" -> \"network learning\"; \"Section 3.1, We aim\" -> \"we aim\"; the penultimate paragraph could use a bit of editing\n- p4: \"N_S\" is only introduced in definition 2 but used earlier\n- Section 3.1 could be improved by adding a bit more intuition about the equations.\n- Notation: I generally would prefer reading $\\mathbb{E}[Y]$ than $\\mathbb{E}Y$\n- p5: exits -> exists ?\n- page 8 mentions sparse labels - what do you mean by that?\n- How many seeds do you use for the standard deviations?\n\n[1] Monteiro, Miguel, et al. \"Stochastic segmentation networks: Modelling spatially correlated aleatoric uncertainty.\" Advances in Neural Information Processing Systems 33 (2020): 12756-12767.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally easy to follow. The clarity could be improved at places. I believe the method to be novel and most details are captured to ensure reproducibility.",
            "summary_of_the_review": "The paper introduces a novel method for training with noisy segmentation labels but might be biased in its evaluation and comparison to relevant baseline methods. Furthermore, I am not sure whether the assumptions made for the noise-model are as widely applicable as claimed.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3111/Reviewer_LKDX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3111/Reviewer_LKDX"
        ]
    }
]