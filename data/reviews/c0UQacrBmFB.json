[
    {
        "id": "mnUZlaPca7m",
        "original": null,
        "number": 1,
        "cdate": 1666045444294,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666045444294,
        "tmdate": 1666045642513,
        "tddate": null,
        "forum": "c0UQacrBmFB",
        "replyto": "c0UQacrBmFB",
        "invitation": "ICLR.cc/2023/Conference/Paper3366/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes an end-to-end architecture from transfer learning that learns a feature compensation for the input data. For this purpose, a clustering of the data is performed on a pre-processing step and the similarities between an input example and each of the clusters are used as inputs to two MLPs that essentially decide i) the magnitude ($W$) of the transformation to apply to the given input example and ii) the direction ($\\Delta$) of that transformation. The method is validated on a set of benchmark datasets for transfer learning from ImageNet, using different backbone pre-trained networks. Different training strategies are compared.",
            "strength_and_weaknesses": "Strengths:\n- The problem addressed by the paper is relevant.\n- The methodology is clear and well-described.\n- The experiments are fair and show that the method is competitive with SOTA in some cases.\n\nWeaknesses:\n1. In the introduction, the authors remark that \"due to the overlap between the source domain and the target domain, not every data example needs transferring, and how much transferring is needed for a data example is subject to its position in the overall data distribution\". Nonetheless, in their algorithm, clustering is performed using the target data. Thus, the computed similarities will not tell how far a given target example is from the source distribution. Therefore, I don't see how they are useful to assess \"how much transferring is needed\" for that example. When the source distribution is very different from the target, the method seems inappropriate. The poor results on MIT Indoor-67 reinforce this suspicion.\n2. Are the displacements $\\Delta$ normalized? Otherwise, the role of the predicted magnitude $W$ is redundant.\n3. The experimental results are not particularly convincing. In particular, it is unclear which of the training strategies proposed in section 3.3 is the best one. In addition, it would be interesting to visualize what kind of transformations the model is learning, i.e. if it's learning $\\Delta$s that pull representations towards the cluster centroids (or something else).\n4. A theoretical analysis of the proposed methodology is missing. It is presented as a mere heuristic without any theoretical guarantees.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear, as stated before. I also appreciate the fact that the authors have attached the project source code, allowing for reproducibility. However, the methodology is not particularly sound, neither technically nor empirically.",
            "summary_of_the_review": "The paper lacks any theoretical guarantees. Moreover, as explained in 1. in the section \"Weaknesses\", I am not fully convinced by the appropriateness of the proposed method. The experimental results are not excellent either. All these issues justify my recommendation for rejection.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3366/Reviewer_thJK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3366/Reviewer_thJK"
        ]
    },
    {
        "id": "V_N2lQXhe6",
        "original": null,
        "number": 2,
        "cdate": 1666592521397,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666592521397,
        "tmdate": 1666592521397,
        "tddate": null,
        "forum": "c0UQacrBmFB",
        "replyto": "c0UQacrBmFB",
        "invitation": "ICLR.cc/2023/Conference/Paper3366/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a method for identifying the mismatch between a source domain and a target domain for transfer learning. The method relies on first identifying cluster centers using all the training data, and then comparing the current input data example to these center for determining how much compensation should be applied for the network to adapt to that particular example. This method requires to add two MLP network to the network architecture: one for compensation, and a second for soft gating this compensation. The experiments consider 5 benchmark datasets which are trained as downstream tasks of a backbone network trained on ImageNet-1k. The authors test several network architectures. The results show that the proposed method gains in terms of classification precision in some cases.",
            "strength_and_weaknesses": "Strengths:\n- The paper tackles an important problem of identifying the mismatch between a source domain and a target domain before transfer.\n- The paper is, in general, well-aligned with literature in the area.\n\nWeaknesses:\n- The paper does not provide explanations / intuitions to most technical decisions. For instance, the proposed method is very quickly explained in roughly half a page (sections 3.1 - 3.2). For example, why is it reasonable to use DEC? Why is compensation necessary - what are the underlying factors that make it necessary once the closest cluster centers have been identified? Why is cosine similarity, and no other measure, applicable in this case? \n- It is very unclear to me how the proposed method is actually helping to identify the mismatch between a source domain and a target domain. In several parts of the paper, it is mentioned that the cluster centers are calculated on the full training set, and according to my understanding it is the whole training set of the target domain for which cluster centers are being calculated? I think it would greatly benefit the explanation of the method if it would clearly distinguish which parts of it come from the source domain and which from the target domain.\n- In the experiments, I do not see any reasoning as to what the proposed method works in some cases but not in others. In which cases doing this kind of clustering + compensation approach would work better? This kind of description is very important to really see the contribution of the proposed method to the problem of transfer learning.",
            "clarity,_quality,_novelty_and_reproducibility": "Although the writing in general is clear, the proposed method is not clear and it is only very briefly explained in half a page. The most important technical decisions remain unexplained / unjustified. This also undermines the quality and novelty of the paper, which at this stage I cannot clearly see. The reproducibility of the paper is fair for researchers in the area.",
            "summary_of_the_review": "As explained in the 'Strengths and Weaknesses' section, I think that the paper lacks a lot of technical details regarding the proposed method and key technical decisions. The method itself does not seem to related well with the original research question (i.e. the mismatch between a source and a target domain). Finally, the authors do not provide insights into the experimental results that explain in which scenarios would the method be applicable, which undermines the contribution of the paper. For these reasons, I recommend a reject.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3366/Reviewer_9GK7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3366/Reviewer_9GK7"
        ]
    },
    {
        "id": "GXo8c7bjcs",
        "original": null,
        "number": 3,
        "cdate": 1666593383248,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666593383248,
        "tmdate": 1666593556728,
        "tddate": null,
        "forum": "c0UQacrBmFB",
        "replyto": "c0UQacrBmFB",
        "invitation": "ICLR.cc/2023/Conference/Paper3366/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper studies how to effectively fine-tune a pre-trained network for a downstream task. The challenge here is to identify the mismatch between source and target distributions. To this end, this paper proposes context-aware feature compensation, which learns context information among the training data. They first perform clustering on the training data, which is used to learn cluster-to-data similarity matrix. Then, the similarity matrix is used to generate compensation embeddings using two MLPs. The compensation embeddings are then concatenated with the original training data. Experiments are performed on different fine-tuning datasets, with a broad comparison of recent fine-tuning methods.",
            "strength_and_weaknesses": "### Strength\n\n- The method is interesting. Studying the contextual relation between source and target domains is novel.\n- The related work section is sufficient. So much literature is surveyed.\n- Experimental datasets and comparison methods are representative.\n\n### Weakness\n\n- Although the idea of learning contextual relation is novel, this approach is not. It remains unclear whether clustering can model the context information, or if the results of clusters and original inputs can solve the mismatch between source and target domains in transfer learning.\n- The claim that \"this method only adds two MLPs to the backbone network\" is not correct. As can be seen from Figure 1, there are more than two MLPs: it still has an autoencoder (DEC), which is much more complicated than MLPs.\n- The method part is extremely confusing and not clear, which should be rewritten. I find figure 1 hard to understand, specifically how to compute $\\mathbf{X} \\textcopyright \\mathbf{S}$ and $\\mathbf{W} \\cdot \\Delta$. (I even think that should be $\\cdot$ instead of $.$, since you claim it's a product.)\n- The success of \"compensation\" heavily relies on DEC (deep embedding clustering). If DEC does not give the correct clustering results, the method will fail. How to justify this? Additionally, DEC brings extra computations, which should be highlighted in the paper.\n- This method will consume a lot of training time than comparison methods, according to Sec. 3.3. We see that there is more than one step of fine-tuning, which is more complicated than existing work. Authors should compare your training and inference time in the experiments.\n- In experiments, you should also list the number of training parameters of each method for a more fair study since this method introduces extra neural network modules.\n- More importantly, the performance on general fine-tuning tasks of this method is NOT good. According to table 1, This approach only succeeds using Resnet-101, while it does not generate competitive results in Resnet-50 and VGG16. Hence, it is difficult to say that this approach actually works in different backbones.\n- No experiments to explain why this method works. Lack of detailed analysis.\n- With regards to related work, I think this paper misses two very important references on the same topic:\n\n[1] Jang Y, Lee H, Hwang S J, et al. Learning what and where to transfer[C]//International Conference on Machine Learning. PMLR, 2019: 3030-3039.\n\n[2] Murugesan K, Sadashivaiah V, Luss R, et al. Auto-Transfer: Learning to Route Transferrable Representations[J]. arXiv preprint arXiv:2202.01011, 2022.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity:** The method part lacks clarity.\n\n**Quality:** Medium quality\n\n**Novelty:** Somewhat novel.\n\n**Reproducibility:** Authors provides code, which seems reproducibility can be qualified.",
            "summary_of_the_review": "This paper aims to tackle transfer learning in context view. I find it a little novel, but the approach is not novel, with so many flaws, as listed in weakness section. Experimental results are not comparable, with missing references. Therefore, I tend to reject this paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3366/Reviewer_AuzT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3366/Reviewer_AuzT"
        ]
    },
    {
        "id": "bUfeTj2CyxF",
        "original": null,
        "number": 4,
        "cdate": 1667778935624,
        "mdate": 1667778935624,
        "ddate": null,
        "tcdate": 1667778935624,
        "tmdate": 1667778935624,
        "tddate": null,
        "forum": "c0UQacrBmFB",
        "replyto": "c0UQacrBmFB",
        "invitation": "ICLR.cc/2023/Conference/Paper3366/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes an feature compensation method by two MLPs that computes the distance of data points to data centers. .The method is evaluated on a set of benchmark datasets for transfer learning from ImageNet, showing somewhat on par result using this technique.",
            "strength_and_weaknesses": "Strengths:\nthe paper is well written, methodology is well-described, and the problem addressed is relevant.\n\nWeaknesses.\nThe author is describing how to use data centers to do data compensation, however, how this is related to data transferring is poorly described. For examples, is data centers computed on target data set? how is its feature vector computed, using the pretrained network? using distance to get compensation factor seems only to be working under a strong assumption that this is used for classification, and it only works for image classification tasks? why using distance to centers work? all these questions are not answered properly.\n\nBased on the experimental setup, it is just finetuning the pretrained network using some downstream tasks. It just barely competes with SOTA methods, seems that with or without such 2 layers of compensation networks does not change the result at all.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity 3/4\nQuality 2/4\nReproducibility 3/4\nHowever, the paper lacks novelty, its technique lacks theories backing it up and not sound at all.",
            "summary_of_the_review": "This paper is well written and it addresses a problem relevant to transfer learning. However, it is just an empirical work that lacks theory backing the idea, such that using distance to data clusters to do compensation as data transferring. Finally, the results are just on par with existing SOTA methods, not proving the effectiveness of this method.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3366/Reviewer_a21v"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3366/Reviewer_a21v"
        ]
    }
]