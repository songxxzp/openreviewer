[
    {
        "id": "dhQ2UdzQJy",
        "original": null,
        "number": 1,
        "cdate": 1666585054849,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666585054849,
        "tmdate": 1666585054849,
        "tddate": null,
        "forum": "ZmYHoQm0SWH",
        "replyto": "ZmYHoQm0SWH",
        "invitation": "ICLR.cc/2023/Conference/Paper3848/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the how discretization over the time horizon affect the error of LQR value estimation compared with the true continuous-time LQR value. The main result is about the mean squared error (MSE) of the Monte-Carlo policy evaluation, which reveals a trade-off between discretization time interval $h$ and the number of trajectories $M$. When the budget of total sample points is fixed, one can use this bound to find the optimal discretization time interval $h$ to minimize the MSE. Lastly, the authors use numerical simulations to demonstrate their theoretical findings in both LQR settings and nonlinear settings.",
            "strength_and_weaknesses": "Strength:\n\nThis paper has a very good motivation to study the impact of discretization for general value estimation in reinforcement learning (RL) and optimal control. The main theoretical results are presented clearly with the discussion of their implications.\n\nWeakness:\n\n1.  It is hard to see the broader impact of this work. The problem setting seems to be restrictive: The results in this work only applies time-invariant LQR system, state-feedback controllers, and a specific form of disturbances. To address this concern, I encourage the authors to be more specific about what the \u201cimplications\u201d are for more general settings. For example, if one wants to optimize the policy to minimize the continuous-time objective, how should the temporal discretization be chosen? Do the optimal temporal discretization depend on the current policy?\n2. The discussion about the technical difficulty for deriving the main result is not sufficient in the main body. As the authors discussed below Corollary 1, the error terms can be understood as a Riemann sum approximation error and the variance term. Before this work, are there existing results that bound Riemann sum approximation error? I believe this is important to clarify, because I feel bounding the variance term (It is usually called the stochastic error in RL literature) via independent trials is a standard technique.\n3. For the numerical simulations, I recommend the authors to do a more careful comparison with the theoretical optimal temporal discretization $h$, because I feel the trend of bias-variance trade-off can be expected even without the theoretical analysis in this work. It is more important to see how well the actual optimal $h$ matches the theoretical prediction $h^*(B)$.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is easy to follow. However, as I discussed for the previous question, the novelty of this work is not discussed sufficiently, especially for the main proof techniques.",
            "summary_of_the_review": "This paper studies a relatively restrictive problem setting, and it is unclear whether the results or the proof techniques here apply to more general settings. Besides, I feel the technical contributions are not significant enough, and the numerical simulations are not sufficient to verify the theoretical findings quantitatively. Therefore, I recommend for reject.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3848/Reviewer_pVUY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3848/Reviewer_pVUY"
        ]
    },
    {
        "id": "bznt8wIPfXR",
        "original": null,
        "number": 2,
        "cdate": 1666919700725,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666919700725,
        "tmdate": 1666919719657,
        "tddate": null,
        "forum": "ZmYHoQm0SWH",
        "replyto": "ZmYHoQm0SWH",
        "invitation": "ICLR.cc/2023/Conference/Paper3848/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper examines the time discretization for continuous value estimation. By analyzing Monte-Carlo value estimation for LQR systems for both finite-horizon and infinite discounted horizon settings, the authors finds that there is a fundamental trade-off between approximation error and statistical error in value estimation, which indicates there is an optimal choice for time discretization that depends on the data budget. The authors also demonstrate the trade-off in numerical simulation of LQR instances and non-linear mujoco environments. ",
            "strength_and_weaknesses": "**Strength**\n- The one dimension example presented in the paper is helpful for understanding \n- The experiments in the paper clearly support the theoretical analysis and results.\n\n\n**Weakness & Questions**\n\n- For the non-linear case, why you choose a very short horizon. What happens if you choose $T=1000$ which is default in mujoco, and $\\gamma = 0.001$ ? Will you get similar results here? \n\n- For practise usage, it seems that we still don't know how to choose the optimal time discretization. Do you have any guidance or idea how to choose that in practise? ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and The claim drawn from previous theoretical analysis is well supported by the empirical results. ",
            "summary_of_the_review": "Overall I think this is an interesting paper, which shows a trade-off for time discretization choice, which could be a potentially important guidance for practical usage. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3848/Reviewer_UU8T"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3848/Reviewer_UU8T"
        ]
    },
    {
        "id": "4xlUYlRk7X8",
        "original": null,
        "number": 3,
        "cdate": 1667616157793,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667616157793,
        "tmdate": 1670871022918,
        "tddate": null,
        "forum": "ZmYHoQm0SWH",
        "replyto": "ZmYHoQm0SWH",
        "invitation": "ICLR.cc/2023/Conference/Paper3848/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the problem of approximating a continuous system from discrete measurements with a finite data budget. They first consider the simplest and canonical case of Monte-Carlo value estimation in a Langevin dynamical system with quadratic instantaneous costs. They obtain analytical expressions of the least-squares error that exactly characterize the approximation-estimation trade-off with respect to the step-size parameter. Second, they present a numerical study that illustrates and confirms the trade-off in both linear and non-linear systems, including several MuJoCo control environments. The findings imply that practitioners should pay attention to carefully choosing the step-size parameter of the estimation to obtain the most accurate results possible.",
            "strength_and_weaknesses": "Strengths:\n1. \tThe problem considered in this paper is important, and the results provide insights for practitioners on how to choose suitable stepsize for approximating continuous systems with discrete measurements.\n2. \tThe linear system considered in this paper is typical, and the theoretical results are rich and complete, with a clear explanation.\n3. \tThe numerical results match the theory well.\n \nWeaknesses\n1. \tCorollary 2 calculates the optimal step size using a Taylor expansion and omits high-order terms w.r.t. $h$. However, such estimation is only correct when $h$ is small, and the approximation error of $h^{*}$ is not given in Corollary 2. Therefore, we do not know whether the estimation is good and precise enough.\n2. \tIn the numerical experiments, the author considered a three-dimensional linear system. However, they only consider several special cases where $A=cI$, which is too special and too similar to the 1-D case. I think considering more general cases will provide more insights for the high-dimensional case. For example, $A=\\diag\\{c_1, c_2, c_3\\}$ where $c_1>c_2>c_3$.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and easy to follow, but some improvements are needed. See weaknesses and the following questions for details. ",
            "summary_of_the_review": "Additional Problems: \n\nThe problem considered in this paper is closely related to stochastic differential equations. Specifically, using discrete measurements to approximate SDEs is similar to using the numerical solution to solve SDEs (for example, Euler-Maruyama method). What is the difference between your findings and those traditional results in numerical SDE?\n\nThe theoretical results seem to be restricted to the linear case, can authors make more discussions on the difficulty of extending results to nonlinear cases?\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3848/Reviewer_GwC4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3848/Reviewer_GwC4"
        ]
    }
]