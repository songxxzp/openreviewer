[
    {
        "id": "VHUfmZo7_-Q",
        "original": null,
        "number": 1,
        "cdate": 1666552757896,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666552757896,
        "tmdate": 1670952212923,
        "tddate": null,
        "forum": "wfU0emciOcM",
        "replyto": "wfU0emciOcM",
        "invitation": "ICLR.cc/2023/Conference/Paper5102/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper theoretically studied the joint-embedding training dynamics in a linear setting - which may be suitable for a multimodal environment. They studied both contrastive and non-contrastive cases and showed that contrastive negative pairs are essential for preventing representations from becoming a rank-one solution. The analysis largely follows Tian et al. (2021), Wen & Li (2021), and Jing et al. (2022) using gradient flows. Lastly, the authors provide a numerical simulation that verifies their claims. ",
            "strength_and_weaknesses": "Strength:\n1. The authors considered the normalization step in the contrastive/non-contrastive loss when conducting the analysis of their dynamics. This is a big improvement over previous theoretical works (Tian et al. (2021), Wen & Li (2021), Jing et al. (2022)) on this topic.\n2. The phenomenon of the two-stage training dynamics is novel. Most previous theoretical work ignores training dynamics and only focuses on generalization bounds that are unable to explain such phenomena.\n\n\nWeaknesses:\n1. The non-contrastive setting is known to collapse. In fact, all successful non-contrastive methods like BYOL/DINO rely on asymmetric architecture. This is already proven by Tian et al. (2021). The authors derive an obvious conclusion (align->1, balance->0) that does not provide any insight into the problem. \n2. The overall claim on contrastive loss is shallow. The authors show that under perfect conditions, align-> one and balance->same rank as input. For linear settings, this is obvious that the optimal solution exists. However, the analysis seems impossible to scale to nonlinear settings as the definition of `balance` becomes trivial for nonlinear networks.\n3. There is no discussion on possible follow-up based on this work. For example, based on theoretical discovery, Tian et al. (2021) and Jing et al. (2022) propose the corresponding solution. It is unclear how this theory can boost empirical advancement.\n ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written. All theorems/lemmas are provided with solid assumptions and proof.\nThe simulation does not provide any detail.",
            "summary_of_the_review": "This is a well-written theory paper studying contrastive learning dynamics but only limited to the small scope and seems not to provide real insight. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5102/Reviewer_KDMd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5102/Reviewer_KDMd"
        ]
    },
    {
        "id": "L0ihBycQX0K",
        "original": null,
        "number": 2,
        "cdate": 1666840712459,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666840712459,
        "tmdate": 1666840712459,
        "tddate": null,
        "forum": "wfU0emciOcM",
        "replyto": "wfU0emciOcM",
        "invitation": "ICLR.cc/2023/Conference/Paper5102/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the authors examine the role of contrastive loss across modalities (such as in CLIP).  They demonstrate that the contrastive loss promotes the learning of \u201caligned\u201d and \u201cbalanced\u201d representations.  The authors investigate the learning dynamics of the optimization process (under specific listed conditions) and show that the dynamics can be interpreted in the form of two stages.",
            "strength_and_weaknesses": "The strength of the paper lies in its supposed mathematical rigor and derivations.  A weakness of this paper is that it is limited to a linear data-generating model, and therefore the conclusions are unable to directly translate to understanding multimodal contrastive losses used in practice.\n\nI enjoyed how the authors included both contrastive and non-contrastive loss formulations.  The authors analyze the non-contrastive loss (such as BYOL) in comparison with the contrastive loss to demonstrate why contrastive losses are better (in terms of going beyond alignment only).",
            "clarity,_quality,_novelty_and_reproducibility": "In terms of clarity, I believe the paper would benefit from more summarizations and takeaway comments describing each key formula or theorem.  It is virtually impossible to completely check the math thoroughly in this work in the timespan allotted to the reviewers.  As such, it is quite difficult to truly gauge the correctness of this work.\n\nThere are also numerous typos and grammatical errors (e.g. Now, we consider the contrastive The main\u201d on page 8, etc.) which should be cleaned up.\n\nI believe that the topic this paper tackles is quite novel, and I believe the experiments listed in the work have no issues with reproducibility.",
            "summary_of_the_review": "Given the novelty of the work, as a comprehensive step towards understanding multimodal contrastive losses, I am inclined to support this paper for acceptance.  This is predicated on the correctness of the listed mathematics - I willingly confess that a large caveat of my review is that I was not able to carefully check all the math or the claims in this paper.  Therefore, I will provide a marginal acceptance and look forward to extended discussions with the AC.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5102/Reviewer_kjwZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5102/Reviewer_kjwZ"
        ]
    },
    {
        "id": "lEuOmJG716w",
        "original": null,
        "number": 3,
        "cdate": 1666867284791,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666867284791,
        "tmdate": 1671440306090,
        "tddate": null,
        "forum": "wfU0emciOcM",
        "replyto": "wfU0emciOcM",
        "invitation": "ICLR.cc/2023/Conference/Paper5102/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper set out to investigate the learning dynamics of contrastive learning (e.g.CLIP) in, investigate how contrastive learning learn to align the representations from different views efficiently.",
            "strength_and_weaknesses": "Strengths:\n(a) The paper provided a fresh view that the alignment and balance of representation play a important role in the training dynamics of contrastive learning, and the training can be decoupled into two stages.\n(b) The paper is backed by a series of theory-grounded definitions and proof.\nWeaknesses:\n(a) The experiment part only covers simulation results, not real data, the model only cover linear models.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written and original, the method is theory-grounded and novel.",
            "summary_of_the_review": "This paper is well-written and original, it provides an interesting view in investigating the training dynamic of contrastive learning with alignment and balance of feature representations, however, the experiment seems only done on simulated data and linear models.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5102/Reviewer_SHU1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5102/Reviewer_SHU1"
        ]
    }
]