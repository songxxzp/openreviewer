[
    {
        "id": "hW0hPExN-M",
        "original": null,
        "number": 1,
        "cdate": 1666599086480,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666599086480,
        "tmdate": 1666599086480,
        "tddate": null,
        "forum": "1KaSx3GrBBm",
        "replyto": "1KaSx3GrBBm",
        "invitation": "ICLR.cc/2023/Conference/Paper2775/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper investigates the role of architectures in self-supervised learning. The authors conduct exhaustive experiments with different architectures and downstream datasets under the setting of SSL. They show that there is no one network that performs consistently well across the scenarios and hence they propose to learn the network architectures in SSL. Experimental results show that self-supervised searched architectures outperform handcrafted ones across different downstream datasets.",
            "strength_and_weaknesses": "Pros:\n1. The motivation is clear. I think it is important to rethink the design of architectures in the context of self-supervised learning.\n2. This paper provides insight for future research. For instance, Fig. 3 shows that larger models do not always perform better in SSL, which is counterintuitive but interesting.\n\nCons:\n1. Can the problems of Figures 1 to 3 be solved if the author's proposed method (NAS+SSL) is used? Is it true, for example, that the larger the size of the model discovered by NAS, the better the performance? Are the problems with the hand-designed models in Figure 2 still present? I have the same question for Figures 1&3 and I hope the authors can draw Figures 1 to 3 with the NAS searched model for comparison. \n\n2. What can we conclude from the results of the NAS to design a model for SSL? Currently, SSL gradually surpasses supervised learning on various downstream tasks by pretraining weights. So I am curious if NAS under SSL can also outperform NAS under supervised learning, by pretraining the model structure.\n\n\n\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Good\n\nQuality: Good\n\nNovelty: Fair\n\nReproducibility: Fair",
            "summary_of_the_review": "I am willing to raise my score if the authors can address my concerns.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2775/Reviewer_5FVM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2775/Reviewer_5FVM"
        ]
    },
    {
        "id": "ze960HmjZFC",
        "original": null,
        "number": 2,
        "cdate": 1666801122413,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666801122413,
        "tmdate": 1666801390408,
        "tddate": null,
        "forum": "1KaSx3GrBBm",
        "replyto": "1KaSx3GrBBm",
        "invitation": "ICLR.cc/2023/Conference/Paper2775/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper attempts to combine the neural architecture search (NAS) process with self-supervised learning (SSL) so as to learn structures suitable for pre-trained datasets (e.g. ImageNet-1K, iNat-2021) in a self-supervised task like SimCLR. Extensive analysis and experiments are included to demonstrate its arguments.",
            "strength_and_weaknesses": "Strength\n- Extensive experiments and analysis.\n- Interesting perspective and attempt to try NAS in self-supervised learning.\n\nWeaknesses\n- In short, I think this paper does not decouple the advantages of NAS itself from SSL, while the architecture obtained from the search may have significant advantages in terms of MAdds.\n\n-----\n\n- **About the statements in Section 3** I agree with this statement \"ImageNet performance is not indicative of downstream performance for SSL\" alone, as evidenced by many previous attempts in pixel-level contrastive learning like DenseCL and PixPro. However, the statement in here does not support the main point of this paper. \n\t- First of all, the paper does not give a specific setting for the 116 sampled models, which means that many of them may be in a situation where they perform poorly and are unlikely to be adopted. \n\t- In addition, the sampling of the MobileNet structure is too concentrated in terms of the size and performance of the sampled models, as illustrated by the distribution of ImageNet results for MobileNet in Figure.2, the model size for MobileNet in Figure.3, and the top/bottom param ratio in Figure.4. \n\t- And this means that the conclusion obtained using spearman rank correlation on such a small space has a high probability of being problematic. We can also see from Figure.13 in the Appendix that MobileNet presents better correlations than ResNet on almost most of the datasets when Pearson coefficients are used. For the few remaining datasets, the lower overlap (e.g. Aircraft) or higher performance (e.g. Sports 8, also too small with only about 1.5K images in total) do not make it universally available.\n\t- At the same time, if the analysis is performed only at the architectural level, the influence of SSL on it should be stripped, because this part of SSL are pre-trained on ImageNet-1K while using linear evaluation as a metric, which will inevitably be helpful for ImageNet-1K related tasks (e.g. CIFAR). If measured using supervised training, I think the performance on ImageNet would be at least highly correlated with the performance of other **classification tasks** (Especially considering the higher correlation already seen in terms of Pearson coefficients so far).\n\n- The experimental section is missing an important baseline, i.e., the performance of the model obtained by using supervised training instead of SSL for search.\n- For MobileNet, MAdds is a very important metric. The model given in the paper seems to have an overall stride of only 16 (inferred from Appendix D), and the latency loss is removed in the search process, which may result in a model with significantly larger MAdds than MobileNetV2.\n",
            "clarity,_quality,_novelty_and_reproducibility": "- Good clarity and reproducibility.\n- Please refer to the previous section for possible problems in quality and novelty.",
            "summary_of_the_review": "This paper wants to show that for SSL, the architecture obtained by NAS will have a significant advantage over the handcrafted architecture. However, neither the theoretical analysis nor the experimental part can exclude the benefits from the NAS itself, and no further experiments have been conducted for other self-supervised learning methods.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2775/Reviewer_JRjb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2775/Reviewer_JRjb"
        ]
    },
    {
        "id": "pne0s6lk0lh",
        "original": null,
        "number": 3,
        "cdate": 1667849363410,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667849363410,
        "tmdate": 1667849729192,
        "tddate": null,
        "forum": "1KaSx3GrBBm",
        "replyto": "1KaSx3GrBBm",
        "invitation": "ICLR.cc/2023/Conference/Paper2775/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The study provides evidence that a network architecture plays a significant role in contrastive SSL, by utilizing 116 variants of ResNet and MobileNet architecture, which were evaluated across 11 downstream tasks in the contrastive SSL setting.\nIt showed that no one architecture demonstrated a consistently good result, thus suggesting future researchers focus on learning architecture as well as the weights of the network in the SSL setting. They conducted two experiments: 1) network variation experiment on downstream tasks with observation of correlation between the models in downstream performance, and 2) applying NAS algorithm to the SSL setting to search for the optimal architectures on unlabeled pretraining dataset via contrastive learning.\n",
            "strength_and_weaknesses": "[Strengths]\n\nS1: The study found out the implicit underlying assumption of the current literature and pointed out that it can be incorrect.\n\nS2: The results have shown that the SSL architecture outperforms the handcrafted architectures, and have included concrete experiments regarding the distributional shift.\n\n[Weaknesses]\n\nW1: Only one optimization objective (SimCLR) has been used. They could have checked if the proposing method works across many different learning objectives.\n\nW2: Idea of combing NAS and SSL is not novel.\n\nW3: In the downstream transfer experiment, the searched architecture did not show promising performance on out-of-distribution dataset, except for the comparison of MobileNetV2, and this results are not surprising.\n\nW4: Although 116 variations of network were experimented, there are just two backbone network architectures.",
            "clarity,_quality,_novelty_and_reproducibility": "[Clarity]\n1. Clarified the assumptions of the current research.\n2. Clarified the main objective of the study is to show that the choice of network is highly impactful in SSL and handcrafting the architecture is very hard.\n3. Authors raised research questions in a clear context.\n4. Clearly states the three main contributions\n5. Clearly explains the reason behind the choice of the NAS algorithm and dataset\n\n\n[Quality]\n1. Appropriate references were made.\n2. Tables, figures, and appendix are effectively supporting the arguments made.\n\n\n[Novelty]\nThis work possesses novelty to a certain degree in that the author(s) tried to use NAS in aid of SSL, and conducted a large scale experiments on the variant of networks. However, the novelty is not substantial (limited) as there are a number of work that have similar approach in combining NAS and SSL. A preprint titled \u2018CSNAS: Contrastive Self-supervised Learning Neural Architecture Search via Sequential Model-Based Optimization\u2019 (https://arxiv.org/abs/2102.10557) is one of the examples. Despite the fact, as author(s) mentioned, in the beginning of Section 4, there is a distinction between their idea and prior work.\n\n\n[Reproducibility]\n1. Provided the details of 1) how they varied the architecture of each network they used , 2) the number of epochs and batch size when pretraining with the machine they used for training.\n2. Provided the metric used (Spearman\u2019s rank correlation coefficient) when evaluating the correlation between ImageNet and downstream performance.",
            "summary_of_the_review": "From the extensive study, readers can agree to the statement that there is no one architecture that performs well across different downstream tasks in SSL, and that NAS+SSL can be a solution for mitigating the problem, where researchers have to handcraft the network architecture. However, as mentioned in the section above, the novelty of this idea is limited in that the combination of NAS and SSL has been experimented widely in the literature.\nHowever, this study opens up many possible research questions regarding the effectiveness on architecture search for SSL, thus can be act as a ground research of future studies.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2775/Reviewer_6dkS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2775/Reviewer_6dkS"
        ]
    },
    {
        "id": "zO6rRX7nMqT",
        "original": null,
        "number": 4,
        "cdate": 1667902904887,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667902904887,
        "tmdate": 1667902904887,
        "tddate": null,
        "forum": "1KaSx3GrBBm",
        "replyto": "1KaSx3GrBBm",
        "invitation": "ICLR.cc/2023/Conference/Paper2775/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper conducts an empirical investigation on the role of architectures in self-supervised learning. Based on the empirical study, the authors apply the neural architecture search in the current SSL framework and demonstrate improved performance in several downstream tasks.",
            "strength_and_weaknesses": "**Strength**: the structure of the paper is clear and the paper is well-written. The experiments are sufficient and well-designed.\n\n\n**Weaknesses**:\nThe novelty of the paper is very limited. There are several messages from section 3:\n\n    1. ImageNet performance is not indicative of downstream performance for SSL.\n    2. Larger networks do not always perform better in contrastive SSL.\n    3. There is no winner in the battle of top vs. bottom heavy networks in SSL.\n    4. It is necessary to allocate the right portion of parameters to different layers of a given network topology.\n\nAll the messages are trivial,  not mathematically rigorous, and are generally observed in different machine-learning tasks.    Although I do agree that the empirical study is sufficient  as a motivation and can support the  general key takeaway: ``we need\nto move beyond handcrafted architectures in SSL'', but section 3 doesn't convey any new insights about SSL. \n\nThe second part of the paper (section 4) applies NAS in SSL, this combination is also a trivial extension and the resulting improvement is not surprising. \n\nI suggest the author treat the empirical study as the first step towards designing a new NAS algorithm to improve the SSL results or provide a more theoretical understanding of the described phenomenon.\n\n\n**Others**:\n1. The title of table 1 is misleading,  ``NAS vs handcraft architecture '' will be more clear.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**:\nThe discussions of the experiment setting and results are sufficient. However, an introduction to the SSL and NAS is required to make the paper self-contained.\n\n**Quality**:\nThe experiment section is qualified but \n\n\n**Novelty**:\nThere is no new model or algorithm provided in the paper.  The heuristic conclusion from the empirical study is not surprising and lacks of scientific rigors. The novelty of applying NAS in SSL is limited.\n\n**Reproducibility**:\nNo code is provided for this empirical study, so the difficulty of reproducing the results is high.",
            "summary_of_the_review": "I recognize the value of empirical study and believe the architecture choice is crucial for semi-supervised learning.\nHowever, the novelty of the paper is limited and the message of the study is vague, unsurprising, and not rigorous. The paper will be more suitable for venues like workshops or benchmark tracks.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2775/Reviewer_ZDfX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2775/Reviewer_ZDfX"
        ]
    }
]