[
    {
        "id": "dtoFvYIPOA9",
        "original": null,
        "number": 1,
        "cdate": 1666426615813,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666426615813,
        "tmdate": 1666485495122,
        "tddate": null,
        "forum": "ZZCJv2biATn",
        "replyto": "ZZCJv2biATn",
        "invitation": "ICLR.cc/2023/Conference/Paper5482/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper tries to learn domain-general representation by achieving the target conditioned representation independence (TCRI). Specifically, the proposed TCRI method not only addresses the domain invariant property but also assumes that the domain-general feature and domain-specific feature are conditionally independent of each other when given class label $Y$ and domain label $e$. By introducing two constraints to the general loss function which ensure 1) a good predictor, and 2) conditional independence, the TCRI method is demonstrated to achieve domain generality compared to other OOD generalization methods. Theoretical analysis and experimental comparisons are provided to validate TCRI.",
            "strength_and_weaknesses": "Strength:\n- This paper is based on a reasonable SCM to analyze the data-generating process. As a result, the existing method only solves the domain invariant constraints, failing to address the target conditional independence. Hence, TCRI can reasonably achieve better performance than other methods by addressing the target conditional independence.\n- This paper has good theoretical support, making TCRI a solid research work.\n\nWeakness:\n- It is unclear how the target conditioned representation independence property can be break down into the proposed total-chain-information-criterion $I(\\Phi(X), \\Psi(X); Y)=I(Z_c, Z_e; Y)$ and $\\Phi(X)\\indep\\Psi(X)|Y \\forall e_i$. There is no detailed derivation.\n- Furthermore, how the two properties $I(\\Phi(X), \\Psi(X); Y)=I(Z_c, Z_e; Y)$ and $\\Phi(X)\\indep\\Psi(X)|Y \\forall e_i$ can be solved by the proposed $L_{\\Phi\\oplus\\Psi}$ and $L_{\\text{CI}}$. Please give more details.\n- How to choose the hyper-parameter $\\alpha$ and $\\beta$ are not discussed. Additionally, there is no experimental analysis of the importance of each loss term.\n- The experiments are quite insufficient. All experiments are conducted on coloredMNIST which is a very small dataset synthesized artificially, not a real-world dataset as indicated by the title of Section 6.1. So the realistic applicability is quite doubtful.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is moderate in clarity and quality. The proposed method is somewhat novel. Codes are provided to ensure reproducibility.",
            "summary_of_the_review": "I have carefully read the whole paper. This paper is well-motivated, however, there are still some concerns (see weaknesses). If the authors can address my concerns, I will consider raising my score.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethics concerns apear.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5482/Reviewer_ZJFn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5482/Reviewer_ZJFn"
        ]
    },
    {
        "id": "FiyYBU7Td9",
        "original": null,
        "number": 2,
        "cdate": 1666655485686,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666655485686,
        "tmdate": 1666655485686,
        "tddate": null,
        "forum": "ZZCJv2biATn",
        "replyto": "ZZCJv2biATn",
        "invitation": "ICLR.cc/2023/Conference/Paper5482/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper provides necessary and sufficient conditions for domain generalization. Experimental results on a few benchmark datasets are provided.",
            "strength_and_weaknesses": "Strengths: A theoretical foundation for generating representations that are domain-invariant and domain generalizable are provided.\nWeaknesses: Poorly written paper. Experimental results using synthetic data or variations of MNIST are not convincing.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is hard to read. Mathematical jingoism has obscures the presentation.",
            "summary_of_the_review": "The paper presents an approach for domain generalization. The writing style is harsh. Experimental results are not convincing.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5482/Reviewer_N8XZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5482/Reviewer_N8XZ"
        ]
    },
    {
        "id": "CIudRdGyQB",
        "original": null,
        "number": 3,
        "cdate": 1666726162302,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666726162302,
        "tmdate": 1666726162302,
        "tddate": null,
        "forum": "ZZCJv2biATn",
        "replyto": "ZZCJv2biATn",
        "invitation": "ICLR.cc/2023/Conference/Paper5482/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes an objective for domain generalization. The main findings involve two types of representations: domain invariant - the distribution of the target conditioned on such a representation is the same across training environments; and domain domain-general - the representation is domain invariant across all possible environments. The paper proves, by construction that a representation that captures only a subset of causal features could be domain-invariant but not necessarily domain-general. \n\nA criterion (Target Conditioned Representation Independence - TCRI ) helpful for domain generality is proposed, using two representations, one domain invariant $\\Phi(X)$ and one domain-specific $\\Psi(X)$. Informally, this criterion is satisfied when the two representations jointly have enough information while being independent when conditioned on the target. The paper proves that if $\\Phi(X)$ and $\\Psi(X)$ satisfy TCRI and $\\Phi(X)$ satisfies domain independence then $\\Phi(X)$ is domain-general.\n\nThen, a loss function is proposed to satisfy this criterion and experimentally it is shown that it can achieve better word-case performance. An important aspect is that the loss used for conditional independence (based on HSIC criterion) can be used for model selection using only training domain data.\n",
            "strength_and_weaknesses": "**Strong points**\n\nS1. The paper tackles an important problem in domain generalization and proposes a sound method for it. The presented downsides of using representations that are domain-invariant but not necessary domain-general are valid and the proposed method solves them.\n\nS2. By improving on other invariant predictors, like IRM, the proposed method has a large potential for domain generalisation and represents a good contribution.\n\nS3. In general, model selection for domain generalization is a hard problem, and the proposed method seems to achieve a good selection using only the training data.\n\n**Weak Points**:\n\nW1. In practice, even when the proposed model selection is used, the performance for all environments is quite low. This hints that the constraints could be too hard to achieve and the model is hard to optimize. What is the performance of the model if the model selection is using testing domain data (oracle selection)? \n\nW2. Some additional explanations in the proofs are needed.  In step iv of the proof of Lemma 5.3, the variables $Z_c^{i\u2032}$ are aggregated in one of the two representations, but how to choose which one? Is it possible that the variables be aggregated into the representation $\\Psi(X)$ that is *not* optimized to be domain-invariant? \n\nW3. Is it necessary to have the two representations? Could an assumption such as \n$I(\\Phi(X); Y) = I(Z_c, Z_e; Y)$, together with domain-invariance assumption be enough to get the same result as Lemma 5.3 and Theorem 5.4? These assumptions would be satisfied when optimizing $ \\mathcal{L_\\Phi} + \\lambda \\mathcal{L}_{IRMv1\u2019}$, i.e. the usual way of training IRM. \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The work is mainly clear, but some questions remain to be answered (W2, W3). The proposed method is novel and seems to have good results in the worst-case scenario.",
            "summary_of_the_review": "The paper was some good observations and it is useful for domain generalization, especially in cases where the worst-case is crucial and model selection is hard.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5482/Reviewer_FowA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5482/Reviewer_FowA"
        ]
    },
    {
        "id": "GijwUqaVOA8",
        "original": null,
        "number": 4,
        "cdate": 1666928938692,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666928938692,
        "tmdate": 1666928938692,
        "tddate": null,
        "forum": "ZZCJv2biATn",
        "replyto": "ZZCJv2biATn",
        "invitation": "ICLR.cc/2023/Conference/Paper5482/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed a Target Conditioned Representation Independence objective for domain generalization. It claims that a domain-invariant representation may not extend to test domains and refine it to a domain-general representation. Based on this, this paper proposed the TCRI objective and evaluate it on synthetic and real-world data.",
            "strength_and_weaknesses": "Strengths:\n- This paper is well written.\n- This paper gives a new attempt to explain and solve domain generalization in the view of causality. \n- This paper contains detailed proof and designs the method based on the analysis.\n\nWeaknesses:\n- The method requires a classifier for each domain, and it is evaluated on a three-domain setting {0.1, 0.2, 0.9}. How the results would be if there are more domains? Why choose {0.1, 0.2, 0.9} in the experiment?\n- This paper focuses on methodology. Only one real-world dataset is analyzed. It would be better to have more results.\n- The method achieves much better results under \u201c-90%\u201d setting, but for the other settings, the results are not as strong as expected, showing the limitation.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "See above.",
            "summary_of_the_review": "The proposed method is interesting. It lacks evaluation results.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5482/Reviewer_xK43"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5482/Reviewer_xK43"
        ]
    }
]