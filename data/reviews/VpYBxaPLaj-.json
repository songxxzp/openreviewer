[
    {
        "id": "DTtkfkliB5_",
        "original": null,
        "number": 1,
        "cdate": 1665691526816,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665691526816,
        "tmdate": 1669361064705,
        "tddate": null,
        "forum": "VpYBxaPLaj-",
        "replyto": "VpYBxaPLaj-",
        "invitation": "ICLR.cc/2023/Conference/Paper4879/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper presents a simple improvement to universal adversarial perturbations to make them robust to transformations.  The paper motivates empirical experiments via theoretical observations.",
            "strength_and_weaknesses": "How does the ability to craft perturbations which are robust under transformations depend on the invariance properties of the victim network to such transformations?  For example, is it easier to craft UAPs which are robust to horizontal flips for models trained with horizontal flip data augmentations.  How does this depend on the model used for crafting as well?\n\nThis paper contains virtually no ablations, for example on the choice of optimizer in the attack.  The authors use a different optimization strategy for example in the SGD baseline instead of PGD, so that is important to ablate.\n\nMy biggest qualm with this work is that the paper is packed with theory and notation, yet the proposed method is extremely simple and does not require any of the theory for motivation.  In fact, while I was reading the theory, I wrote down a note to myself asking if the authors tried a very simple and obvious baseline, and that baseline turned out to be exactly their proposed method.  The technique of EOT is widely used in the adversarial example and poisoning literature, for example, so it makes sense to use it here as well.  Simplicity is a good thing as simple methods are easier to understand and implement, but loading up a paper with entirely unnecessary theory and notation so that it is harder for the reader to understand the work defeats the purpose.  The algorithm only appears on page 6 of 9 in a method paper.",
            "clarity,_quality,_novelty_and_reproducibility": "The method may be novel, although I am not aware of other recent work on UAPs.  The writing is good in terms of the grammar, but the simple and intuitive method is hidden behind a wall of theory.",
            "summary_of_the_review": "I like the simplicity of the approach and the empirical robustness gains, but the presentation is hard to follow, and there are numerous experiments missing that would have been a better use of space than the theory.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4879/Reviewer_pw3U"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4879/Reviewer_pw3U"
        ]
    },
    {
        "id": "5mIevFkHexn",
        "original": null,
        "number": 2,
        "cdate": 1666163149188,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666163149188,
        "tmdate": 1666163149188,
        "tddate": null,
        "forum": "VpYBxaPLaj-",
        "replyto": "VpYBxaPLaj-",
        "invitation": "ICLR.cc/2023/Conference/Paper4879/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work introduces robust Universal Adversarial Perturbations (UAPs). The objective of robust UAPs is to increase the resilience of UAPs against image transformations. Robust UAPs are obtained by incorporating transformation functions into the UAP generation process. Evaluation on CIFAR10 and ImageNet demonstrate the increased performance of robust UAPs compared to baseline approaches. ",
            "strength_and_weaknesses": "## Strengths\n(+) This work deals with the topic of the robustness of Universal Adversarial Perturbations (UAPs). This is an important topic, since, as the authors demonstrate, the effectiveness of UAPs decreases under image transformations.  \n(+) The provided experimental results are convincing, showing that the proposed method outperforms the compared baselines.  \n\n## Weaknesses\n(-) The contribution of this work is limited. In essence, this work shows that to overcome the susceptibility of UAPs to transformations, transformations need to be incorporated into the UAP crafting process. The increased robustness is hence expected.  \n(-) The proposed algorithm has only limited novelty and is a collection of proven methods in the literature, namely batch-training [A, B], expectation over transformations [Athalye et al., 2018], and PGD [Madry et al., 2017]. It would be beneficial if the authors could differentiate their algorithm from the ones in the literature [Shafahi et al., 2020, A, B].  \n(-) To further demonstrate the robustness of the UAP, the authors should evaluate the robust UAPs on hold-out transformation, which were not observed during training.  \n(-) The authors mainly evaluated the robust UAP in the context of untargeted attack success rate. It would be further interesting to see a performance evaluation of the targeted attack success rate.  \n(-) I am further curious about the data efficiency and transferability of robust UAPs.  \n* Data efficiency: How do robust UAPs perform when only limited data is accessible during the training process? Please also note, that in the literature data-free methods exist.  \n* Transferability: It is common to analyze the transferability of UAPs [Moosavi-Dezfooli et al. 2017, A, B, C]. I would be curious about the transferability of robust UAPs, compared to existing methods.   \n\n(-) The authors mainly evaluated robust UAPs on VGG, Inception, and ResNet18. Recently, transformer architectures gained popularity. I am curious if the concept of robust UAPs holds for transformer-based models as well.  \n(-) The related work section is insufficient. To name only a few missing works: [A-E].  \n\n[A] Generalizable Data-free Objective for Crafting Universal Adversarial Perturbations; T-PAMI 2018  \n[B] Understanding Adversarial Examples from the Mutual Influence of Images and Perturbations; CVPR 2020  \n[C] Regional Homogeneity: Towards Learning Transferable Universal Adversarial Perturbations Against Defenses; ECCV 2020  \n[D] Art of singular vectors and universal adversarial perturbations; CVPR 2018  \n[E] Defense against Universal Adversarial Perturbations; CVPR 2018  \n",
            "clarity,_quality,_novelty_and_reproducibility": "## Clarity\nThis work clearly written and technically sound to the best of my judgment.\n\n## Quality \nThe paper quality is sufficient in my opinion. \n\n## Novelty\nIn my judgment, this work holds only limited novelty. \n\n## Reproducibility\nThis work is reproducible (code provided) to the best of my judgment. \n",
            "summary_of_the_review": "While it is indeed true that the efficiency of UAPs suffers under transformations, simply showing that this can be mitigated by introducing transformations into the crafting process does in my opinion not hold enough contribution to be accepted at ICLR. Additionally, as pointed out in my weaknesses section, this work lacks several crucial evaluations to fully judge the effectiveness of the proposed robust UAPs.  ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4879/Reviewer_jAxg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4879/Reviewer_jAxg"
        ]
    },
    {
        "id": "5OrvxBwsAJJ",
        "original": null,
        "number": 3,
        "cdate": 1666636682325,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666636682325,
        "tmdate": 1666636715894,
        "tddate": null,
        "forum": "VpYBxaPLaj-",
        "replyto": "VpYBxaPLaj-",
        "invitation": "ICLR.cc/2023/Conference/Paper4879/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors consider the problem of making universal adversarial perturbations (UAPs - those that can be applied to any input and trigger classification for a certain class) under a set of transformations. The authors present a new algorithm. It involves applying SGD over  examples (in the outer loop) and randomly chosen transformations (in the inner loop). The caveat is that for each batch the algorithm estimates robustness (i.e. adversarial success rate under the transformation set) in the optimization loop, allowing the algorithm to move on to the next batch only after the resulting UAPs are estimated to be robust to a certain level. It turns out that in practice this algorithm has higher adversarial success rate than just performing SGD alone, especially on complex sets of transformations.",
            "strength_and_weaknesses": "Strengths: the method outperforms baselines on adversarial success rate, especially under large sets of transformations.\n\nWeaknesses: the SGD baseline is underspecified. It would be interesting to see the extent to which the presented algorithm outperforms SGD while contextualizing compute used. Some questions: \n* How much compute is used to perform RobustUAP compared to SGD?\n* How much compute is used to obtain robustness estimates?\n* What happens when this same amount of compute is used to run SGD?\n* What happens as you vary the number of SGD iterations? Does SGD improve its ASR or does it just asymptote?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and the methods are novel. It would be nice to compare with more extensive baselines (see above). ",
            "summary_of_the_review": "A well written paper that tackles an important problem with new ideas. The only lacking aspect is extensive baselines. My score will increase if the authors run more extensive baselines.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4879/Reviewer_CA3y"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4879/Reviewer_CA3y"
        ]
    },
    {
        "id": "oZKbLD-CwU",
        "original": null,
        "number": 4,
        "cdate": 1666670267832,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666670267832,
        "tmdate": 1666670267832,
        "tddate": null,
        "forum": "VpYBxaPLaj-",
        "replyto": "VpYBxaPLaj-",
        "invitation": "ICLR.cc/2023/Conference/Paper4879/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a robust universal adversarial perturbation which is robust to many transformations such as rotation, pixel intensity. It proposes a robustness estimation approach which can be leveraged to conduct adversarial attack.",
            "strength_and_weaknesses": "positives:\n+ it is important to improve the robustness of universal perturbation, especially when applying them in physical attack. \n\n\nnegatives:\n- the proposed method is straightforward since it just combines the idea of physical attack and digital universal perturbation attack.\n- But experiments conducted in this paper almost focus on the digital domain, instead of real-world physical transformation. Due to that, it is hard to measure the effectiveness of the proposed method. ",
            "clarity,_quality,_novelty_and_reproducibility": "It is well written and easy to follow. \nIt is limited in its novelty and experimental evaluation, as mentioned above.  ",
            "summary_of_the_review": "The problem discussed in this paper is important when applying universal perturbation attack to real-world physical attack. But my concerns are the limited novelty and experimental evaluation, thus it needs to be significantly improved before being accepted. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4879/Reviewer_BeFR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4879/Reviewer_BeFR"
        ]
    }
]