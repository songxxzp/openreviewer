[
    {
        "id": "ARcN6_32LWO",
        "original": null,
        "number": 1,
        "cdate": 1666091489924,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666091489924,
        "tmdate": 1666091984732,
        "tddate": null,
        "forum": "sOXU-PEJSgQ",
        "replyto": "sOXU-PEJSgQ",
        "invitation": "ICLR.cc/2023/Conference/Paper3422/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Authors propose a new method for uncertainty estimation in image classification and segmentation considering a semisupervised setting. Their approach takes advantage of also unlabelled data, which is a novel aspect in uncertainty estimation. They propose so called consistency loss which forces softmax output to consistence (defined as consistency of predictions between training epochs). The proposed approach is validated numerically using CIFAR10&100, image segmentation (ISIC2017) and in a active learning experiment. ",
            "strength_and_weaknesses": "Strengths:\n- They take advantage of unlabelled sampled. Having unlabelled samples is a common situation in practical problems and especially very natural situation in active learning problems. \n- Numerical results looks good: they reach state-of-art in most of experiments, often with a large margin\n- They also provide theoretical considerations supporting their approach\n\nWeaknesses:\n- It seems that the approach is only applicable with networks with softmax output (i.e. classification or segmentation), not clear if can be extended to regression etc?\n- It is not clear to me that what are actually the metrics used in active learning methods. I guess \"entropy\" results is computed from softmax output? \"MC-dropout\" is also based on entropy? Your method is based on softmax or entropy?\n\nMinor weaknesses / comments :\n- Baselines are based on quite old studies (the latest is from 2018). There are also several more recent approach. But on the hand, MCdropout is still one of best performing solutions and none are considering semisupervised setup, so this is also just a minor comment. \n- Furthermore, numerical results considers only a single set such that training and evolution sets are quite similar (i.e. I would say those are \"same distributions\"). Some confidence studies considers out-of-distribution detection, meaning that they study if method can detect a sample which is from a significantly different distribution (e.g. Dirty MNIST introduced by Mukhoti & Gal, https://paperswithcode.com/dataset/dirty-mnist). I would like to see also this aspects of their method. But can also be future study. \n- Another similar study could be if method can separate aleotoric (uncertainty due to noise etc) and epistemic uncertainty (uncertainty due to lack of training data etc). This is meaningful in active learning if different levels of aleatoric noise are present as it is pointless to pick samples with high aleotoric noise. See Yarin Gal's work. But can also be future study.\n\nQuestions:\n- Double sum consistency loss is expensive to compute as the authors mention. But can it be avoided? Does the loss sense make any sense without taking only difference of consistency and softmax output  (i.e. computing $\\sum_s\\max\\{0,c_s-\\kappa_s\\}$?\n- In training, does minibatch include fixed ratio of labelled and unlabelled samples or is this ratio random? If latter, is it a problem if no labelled samples end up to the mini batch?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written. Clarity and originality are sufficient. ",
            "summary_of_the_review": "The approach seems novel and relatively simple, and numerical experiments also looks very promising. There are a few points that I would have liked to be see in their study (see \"Minor weaknesses / comments / questions\" above), but on the hand, I agree that not all can be included into this paper and those could also be part of future study etc. Therefore I would recommend acceptance. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3422/Reviewer_L49h"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3422/Reviewer_L49h"
        ]
    },
    {
        "id": "VwHzV02z6Cl",
        "original": null,
        "number": 2,
        "cdate": 1666633912384,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666633912384,
        "tmdate": 1670454218416,
        "tddate": null,
        "forum": "sOXU-PEJSgQ",
        "replyto": "sOXU-PEJSgQ",
        "invitation": "ICLR.cc/2023/Conference/Paper3422/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes an approach to estimate the confidence of the predictions using unlabeled data in the semi-supervised setup. The main idea is that training consistency, i.e., the frequency of training data getting the same prediction in sequential training epochs, can serve as a surrogate for the model\u2019s prediction. \n",
            "strength_and_weaknesses": "Strength: \n\n-The problem of overconfident predictions is important and requires major attention from the community. \n-The paper is well-written and easy to understand.  \n-Extensive experiments are conducted to evaluate the performance of the model. \n\n\n\nWeaknesses:\nMAJOR:\n-In Figure 1, the paper attempts to show that the training consistency correlates with the distance to the decision boundary and then claims that the distance to the decision boundary can be interpreted as confidence. This claim does not seem to be correct. Since the output space is not calibrated, the distance to the decision boundary in the output is also overconfident and cannot be used to represent confidence. We can see this more clearly by noting that the linear classifier that performs the classification on top of the representations is also estimating a relative distance to the decision boundary. Therefore, the overconfidence problem would not exist in the first place if the distances in the representation space were correlated with confidence. \n-Another point is that the distance in the output may correlate with confidence only on the samples that are close to the decision boundary as depicted in Figure 1. This is obvious because we also observe in conventional networks that low predicted probability shows low confidence. The challenge is actually on samples that are distant from the decision boundary. Therefore, the assumptions made based on the observation in Figure 1 are not accurate and only consider the samples close to the boundary while there is no clue or intuition for samples not close to the boundary.\n-The novelty is limited. The main idea is the simple adaptation of the correctness measure proposed by (Moon et al., 2020) to the semi-supervised training setup. Other choices for the adaptation could be considered to augment the contribution. \n-L_{corr} in Equation 3 is not defined.  \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is almost clear and seems reproducible. However, the novelty and the scientific quality in terms of contributions are limited.\n",
            "summary_of_the_review": "The novelty and contribution of the paper are limited. In addition, assumptions made based on the exploratory evaluations are not accurate and require further justification. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3422/Reviewer_qWap"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3422/Reviewer_qWap"
        ]
    },
    {
        "id": "TtbLzxph8i7",
        "original": null,
        "number": 3,
        "cdate": 1666757381264,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666757381264,
        "tmdate": 1666757381264,
        "tddate": null,
        "forum": "sOXU-PEJSgQ",
        "replyto": "sOXU-PEJSgQ",
        "invitation": "ICLR.cc/2023/Conference/Paper3422/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper introduces a consistency ranking loss that enables the model's softmax output to be a close approximation of consistency. Consistency in turn correlates well with confidence estimation. In other words, if the model's prediction for a sample is consistent as the training progresses, it is likely to have high confidence in its prediction for that sample. Their method can leverage unlabeled data and thereby works well in limited label settings. They show that their method of estimating confidence outperforms other methods for image classification and image segmentation tasks. ",
            "strength_and_weaknesses": "Strength(s):\n1. Using consistency as a surrogate for the correctness and the model's confidence is an interesting and novel idea. The experiment demonstrating a high correlation between consistency and confidence was quite convincing.\n2.  The authors nicely transferred their learning about consistency being a decent surrogate to confidence into a loss function that enables softmax outputs to be as close to consistency as possible.\n3. Their method can leverage unlabeled data and thereby works well in limited label settings. This is again novel as prior works have mainly focussed on the supervised training setting.  \n4. Their experiment with active learning was again a clever way to demonstrate their method's superiority.\n\nWeakness(es)/Suggestion(s):\n1. It seems that results on CIFAR10 and CIFAR 100 should be supported by a real-world dataset(s) where we actually see some uncertainty in the outcomes like predicting the weather or predicting a future event from the current data.  Recent work in deep probability estimation actually addresses this issue and also proposes some datasets [1]. I feel the proposed method is an interesting one and therefore, should be tried on some real-world uncertainty prediction datasets. It would only strengthen the paper. \n2. Additionally, some existing methods like [1], [2], [3], and [4] for the model calibration should be added to the comparisons. This again would strengthen the paper. If you feel that the above methods would obviously not outperform the proposed method, the reasons for the same should be included in the relevant work section.\n3. For figure 3, some details like which dataset was used, how many training samples were labeled, etc. are missing. \n\n[1] Deep probability estimation: https://arxiv.org/pdf/2111.10734.pdf\n[2] Deep ensembles: https://arxiv.org/pdf/1612.01474.pdf\n[3] Mix and Match: https://arxiv.org/pdf/2003.07329.pdf\n[4] MMCE: https://proceedings.mlr.press/v80/kumar18a/kumar18a.pdf\n",
            "clarity,_quality,_novelty_and_reproducibility": "The method is novel and clearly explained. I was not able to find the code in the supplementary material or the main paper. Therefore, authors are encouraged to share the code for reproducibility purposes.",
            "summary_of_the_review": "The method proposed in the paper tackle many important issues like confidence estimation in semi-supervised settings which was not adequately addressed in the previous work. Additionally, the proposed method is sound, novel, and elegant. Therefore, my recommendation would be marginally above the acceptance threshold (6).",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3422/Reviewer_ZHpU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3422/Reviewer_ZHpU"
        ]
    },
    {
        "id": "8zEnXT_6gk6",
        "original": null,
        "number": 4,
        "cdate": 1666876300039,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666876300039,
        "tmdate": 1669057677010,
        "tddate": null,
        "forum": "sOXU-PEJSgQ",
        "replyto": "sOXU-PEJSgQ",
        "invitation": "ICLR.cc/2023/Conference/Paper3422/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In a nutshell, authors extend confidence estimation in DNNs to semi-supervised learning. To my understanding, the way they have approached the problem is that the more consistent the prediction for a given data sample x_i across different stages of training (including weights) is, the more confident the model will be; and that is independent of y_i, i.e. consistency is the proxy. To some extent it reminds me of this work (https://link.springer.com/article/10.1007/s00521-019-04332-4) where the authors annotated unlabelled data based on uncertainty estimation. The results presented (and visualised, e.g. figure 1) are promising, but half of the paper (especially the first half) tries to mathematically formulate the problem unnecessarily. Even the theorem might be redundant, with the most relevant being eq. 2.",
            "strength_and_weaknesses": "Strengths:\n\na)\tA simple but effective method, that works competitively with respect to other methods.\nb)\tThe authors also show some results in medical image segmentation\nc)\tIn theory, it should generalise well in other datasets\n\nWeaknesses:\n\na)\tI think it is a weak formulation and some quantification of the bias of the estimator would be useful \u2013 to be honest, though appendix covers me but it is also not an excuse to use the appendix to write a longer paper\nb)\tI appreciate the use of medical images but results on more datasets would demonstrate the generalisation of the method, as CIFAR and ISIC2017 might be not the best ones for this task\nc)\tI think most of the formulas and maths in the first half of the paper, mainly pages 2 and 3 are redundant in my opinion. You want to explain something very simple and the maths just makes it more complicated than it is.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Firstly, in related work pg2, in the second sentence from last, there is a missing citation \"?\".\nSecondly, the paper would benefit from removing some redundant formulations, and instead adding more important ones from the appendix. Especially on pages 2,3.\nThirdly, the idea of expanding confidence in semi-supervised learning settings might be kind of novel and original but some ablation studies to understand limitation and stress test it would have been useful.\nReproducibility is at the bare minimum, as it is only the maths available (and might not be everything needed there), and the fact that they have used Resnet-18 for the active learning and other Resnet variants for other parts of the paper. I would have expected to see a pseudo-code/algorithm at the very least.",
            "summary_of_the_review": "Good paper, with some useful intuitions around expanding confidence in semi-supervised settings, but the paper lack proper organisation, useful ablations/experiments, and a more compelling provision of the importance of this work. It would require some moderate improvements to make it publishable, but it is nevertheless an important piece of work.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3422/Reviewer_pST4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3422/Reviewer_pST4"
        ]
    }
]