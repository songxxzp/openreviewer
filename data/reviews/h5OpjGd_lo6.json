[
    {
        "id": "r47_NYMZlH",
        "original": null,
        "number": 1,
        "cdate": 1666412860862,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666412860862,
        "tmdate": 1670796143072,
        "tddate": null,
        "forum": "h5OpjGd_lo6",
        "replyto": "h5OpjGd_lo6",
        "invitation": "ICLR.cc/2023/Conference/Paper2800/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper studies data generation-based zero-shot learning that mainly uses a large PLM to generate training data and then trains a small tiny task model (TAM) to perform classification. The major challenge that the paper tries to address is that the synthetic data are usually noisy, and hence the paper proposes a meta-learning empowered framework to automatically learn sample weights over the synthetic dataset -- the goal is to upweight the accurate samples and downweight the noisy ones. Different from previous meta-learning approaches that assume a clean validation set for learning sample weights, this paper uses a noise-robust loss function calculated on the synthetic dataset for the outer-loop optimization, thus removing the requirement for manually annotated data. The proposed method SunGen is compared with ZeroGen on eight classification tasks and demonstrates significant improvements.",
            "strength_and_weaknesses": "Pros:\n* The paper targets an important and timely topic in zero-shot learning -- generation-based approaches recently have become a promising and popular direction for zero-shot learning, but the major challenge of how to effectively leverage the potentially noisy synthetic dataset has remain unresolved. The proposed method that applies the idea of meta-learning to automatically learn sample weights without requiring manually-labeled clean dev sets is new and interesting.\n* The method is empirically effective across eight classification tasks, outperforming the ZeroGen baseline, and even achieving comparable performance to fully-supervised training that uses the clean training data (though they are mostly of smaller size than the generated dataset).\n* The paper is overall clearly written and well organized.\n\nCons:\n* The theoretical analyses are not informative. I believe that Assumption 2 is too strong (or even wrong) and makes the entire proofs trivial. Assumption 2 essentially states that the optimal solution on the clean set induced by the noise robust loss function is exactly the same with that induced by the standard cross-entropy loss. However, previous studies (e.g., Zhang and Sabuncu) have shown that noise robust losses usually worsen the converged solution compared to standard cross-entropy when used on clean datasets, so it's hardly the truth that they actually lead to similar optima. I believe Assumption 2 is actually what requires more formal proofs (Theorems 1 & 2 will trivially hold given Assumption 2). The empirical validation presented in D.1 is not convincing since similar training curve trends do not imply similar global/local optima. \n* The choice of noise robust loss function needs to be further articulated. The paper directly picks reversed cross-entropy loss without explaining the reason. There are many functions that can satisfy Eq. (3) -- even a constant loss function that does nothing for training. It is therefore necessary to justify why reversed cross-entropy loss is used (rather than other noise robust loss functions in, e.g., Ghosh et al. & Zhang and Sabuncu). This may be done empirically as ablation studies.\n* It would have made the empirical evaluation more complete if the method was compared with other noise-robust training strategies (e.g., label smoothing & temporal ensembling used in Meng et al.) and on more difficult classification tasks (e.g., the NLU tasks from the GLUE benchmark).\n* (Minor) There are a few typos and unnatural language usages that need further proofreading. For example, (1) \"despite we can generate unlimited training data in theory\" -> \"despite the unlimited training data that one can generate in theory\" (2) \"we may recover the clean distributional\" -> \"we may recover the clean distribution\" (3) \"the bi-level optimization approaches has been proven\" -> \"the bi-level optimization approaches have been proven\" (4) \"To attack the noise data\" -> \"To address the noise in data\"\n* (Minor) There seem to be too much whitespace at the bottom of each page -- the authors may need to follow the official template for formatting.\n\n---\n**Post-Rebuttal Updates**:  \nI'd like to thank the authors for providing very detailed responses and revisions to address my raised concerns above. I especially liked the additional analyses w.r.t. the noise-robust loss function, including its comparison to the standard cross entropy loss in terms of their optimization difficulty & optimal solutions, the empirical effectiveness of the chosen loss function (RCE loss) over other noise-robust training strategies and other alternative loss functions, and the relaxed theoretical assumption (Assumption 3 and Theorem 3). More detailed comments are below:\n* It's interesting to see that the noise-robust loss functions result in different optimization difficulties compared to the standard cross-entropy loss, though it's still a bit unclear to me whether their optimal solutions would be actually the same (or at least very similar). The loss surface plots and training curves are definitely good empirical evidence, but I'd be interested to know a more principled answer to this (of course, this is obviously beyond the scope of this paper, and I won't count this as a weakness of the paper at all).\n* Even if the optimal solutions induced by the noise-robust loss function concur with those of the standard cross-entropy loss, the **actual converged solutions** may differ due to optimization difficulties. Therefore, I believe that a more relaxed assumption (Assumption 3) is indeed necessary here, and I'm happy to see the new theoretical analyses built on this.\n* The new results on the three GLUE tasks and the ablations for comparing different loss functions/noise-robust training strategies look good to me.\n* The authors' responses to my further clarification questions all make sense to me. I think it'll be good to discuss the efficiency and time costs in the next paper version (I understand that the time cost is affordable due to the small classification model used, but it'll be beneficial to let the readers have a sense of how the method scales to larger models/datasets). Other than that, there is only one point that I don't quite get: \n\"Besides, our training process is \u201conce for all\u201d. In other words, once we derive the sample weights, we can use them to sample high-quality subsets at different scales.\"\n-> Do you intend to say that you could apply some filtering method based on the learned sample weights to select a subset of the synthetic training set in order to improve training efficiency?\n\nBased on the above considerations, I believe that the updated paper has addressed almost all of my concerns (the remaining issues are very minor and can be apparently fixed easily). Overall, this is a good paper with an important research goal, clear presentations, novel ideas, solid implementations, good theoretical insights, and promising empirical performance. I'll be happy to support the paper for acceptance.",
            "clarity,_quality,_novelty_and_reproducibility": "* Clarity: The paper is overall clear and well organized.\n* Quality: The contribution of the paper is interesting, targeting an important and timely topic in zero-shot learning. The empirical performance is also good. Nevertheless, there are a few missing empirical evaluations that could have made the contribution more convincing (see cons above). There are also concerns regarding the theoretical analyses that the authors may need to consider revising (see cons above).\n* Novelty: The paper proposes a novel approach for generation-based zero-shot learning built on meta-learning without requiring manually labeled clean dev sets.",
            "summary_of_the_review": "I appreciate the attempt to address the major challenge with leveraging synthetic datasets generated by PLMs -- the existence of label noise. The proposed method is also novel and interesting. However, there are a few points (e.g., strong theoretical assumptions, missing discussions of loss function choices, and other empirical evaluations) that need further revisions to be made convincing.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2800/Reviewer_23fs"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2800/Reviewer_23fs"
        ]
    },
    {
        "id": "dsNQGV64to",
        "original": null,
        "number": 2,
        "cdate": 1666563804412,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666563804412,
        "tmdate": 1666596879698,
        "tddate": null,
        "forum": "h5OpjGd_lo6",
        "replyto": "h5OpjGd_lo6",
        "invitation": "ICLR.cc/2023/Conference/Paper2800/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The task this paper targeted is to train a model purely on a synthetic dataset without a clean oracle validation set. The paper proposed a bi-level algorithm where the coarse level uses a noise-robust loss optimizing re-weighting each data sample, and the fine level trains a model under the given weighted data sample dataset using regular cross-entropy loss. The noise-robust loss used is the reversed cross-entropy loss. The paper verified the effectiveness of this approach by both proved the convergency of this algorithm and empirically shows accuracy improvement over 8 text classification tasks.",
            "strength_and_weaknesses": "Strength\n1. The bi-level optimization idea is novel and natural, and the proof is easy to follow. By using the noise-free loss over learning the data sample weighting instead of optimizing the model directly, the search space is much smaller and thus easier to optimize.\n2. The experiment results are sufficient and well-supported the effectiveness of this approach.\n3. Overall the paper is clear and well-written and easy to follow. \n\nWeaknesses:\n1. In the ablation study, it would be good to provide some analysis between the proposed bi-level framework verses a single level baseline where the model is optimized using reversed cross-entropy directly.\n2. In table 5, both ZEROGEN and SUNGEN's diversity is much smaller than Gold. It is unclear whether it is because of the model generated \"hard\" examples or noisy examples.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "1. Clarity. The paper is well-written and succinct. \n2. Quality. The quality of this paper is good with both clear theoretical proof and empirical results.\n3. Novelty. As mentioned in Section -Method Remark, The paper is novel in that it first decoupled the noise removal from network training so that the proposed framework enjoys the merit from the noise-robust loss and avoids getting the model's performance undermined.\n4. Reproducibility. The authors will open-source their source code with acceptance of the paper.",
            "summary_of_the_review": "The bi-level approach proposed in this paper is intuitive and is supported by good experimental results. The lack of analysis on the choice of noise-robust loss function and the lack of baseline for training directly with reversed cross entropy loss weakens the arguments of this paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2800/Reviewer_h9eZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2800/Reviewer_h9eZ"
        ]
    },
    {
        "id": "Z5avReQd1F4",
        "original": null,
        "number": 3,
        "cdate": 1666771842119,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666771842119,
        "tmdate": 1666771842119,
        "tddate": null,
        "forum": "h5OpjGd_lo6",
        "replyto": "h5OpjGd_lo6",
        "invitation": "ICLR.cc/2023/Conference/Paper2800/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes SUNGEN, a framework to automatically construct high-quality data for zero-shot classification problems. The method first employs pretrained language models to generate samples for a given task and then learns the sample weights indicating data quality without requiring any human annotation. The paper provides theoretical proof that the proposed method can be noise-free. Moreover, experiments on eight text classification tasks demonstrate the strong performance of the proposed method and its ability to identify and ignore noisy samples.",
            "strength_and_weaknesses": "Strengths:\n1. The research problem of avoiding noisy samples in the new paradigm of data-generation-based zero-shot setting is well-motivated, and the underlying assumption of this work that there is no human annotation available for validation looks more realistic though challenging.\n2. The proposed method looks pretty convincing both theoretically and empirically. The experiment performance is very strong compared to several fair baselines.\n3. Further analysis especially the visualization in Figures 1 and 3 provides clear evidence for the hypothesis that the proposed method is effective for filtering out noisy labels.\n4. The paper is clear and well-written.\n\nWeaknesses:\nI didn't see significant weaknesses in this paper such that it should not be accepted. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written. The method is novel by proposing a self-guided data generation framework that is robust to noisy labels while requiring no human annotations. The results should be largely reproducible with their provided code and their plan for open-sourcing.",
            "summary_of_the_review": "The paper proposes a novel method to automatically avoid noisy synthetic data in the paradigm of data-generation-based zero-shot learning. Clear analysis is provided both theoretically and empirically to show the effectiveness of the proposed method. The paper is worth acceptance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2800/Reviewer_1YN5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2800/Reviewer_1YN5"
        ]
    },
    {
        "id": "ePJuJsWL_MW",
        "original": null,
        "number": 4,
        "cdate": 1666819056562,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666819056562,
        "tmdate": 1666853564031,
        "tddate": null,
        "forum": "h5OpjGd_lo6",
        "replyto": "h5OpjGd_lo6",
        "invitation": "ICLR.cc/2023/Conference/Paper2800/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper focuses on the problem of utilizing pretrained large-scale language models for training data generation (based on careful prompts), to be used in training zero-shot classifiers. This approach stands out as an alternative to fine-tuning the language model for a new task (again for data generation) or direct prompt-based zero-shot classification.\n\nThe paper mainly aims to tackle the problem of managing sample noise in the training data generated by the language model, in an automatic way (avoiding human intervention). For this purpose a bi-level optimization approach (meta-learning-like) is proposed, where the outer loop estimates the sample training weights based on a robust loss function and the inner loop trains the classification model based on the given sample weights.",
            "strength_and_weaknesses": "Positives:\n- The experimental results look very promising with significant improvements over sensible baselines\n- The approach overall is rational and makes sense\n- The theoretical analysis is a plus (though does not seem to give strong insights)\n\nNegatives:\n- Some claims in the paper are not fully convincing, e.g. \"In Sec. 4, we theoretically show that using Lrobust as the outer objective, our method can find a set of sample weights w\u2217 with just the synthetic validation set, such that w\u2217 maximizes the model performance on the clean data.\" This appears to be valid only for certain types of noises, one can easily come up with structured noise cases (as common in reality) where the weighting can easily attend to noisy samples. In particular, if the model generated samples are consistently problematic (rather than having uniform noise or being noisy only in a subset of samples), then the theoretical proof would not apply.\n- \"Since lrobust is now used to optimize the sample weights w, which is in a much smaller search space and has simpler structure than \u03b8, thus is easier to optimize.\" Here, I get the intuition, however, I am not sure if it is definitely correct. In particular, one can see sample weights as a continuous relaxation to the sample selection problem. As sample selection is a combinatorial problem, it is likely to be a much harder optimization problem, compared to the naturally-continuous model parameter optimization problem (despite having a lot more optimization variables and similarly being non-convex).\n- The method is evaluated as a whole bundle with PLM. No baselines are presented as alternatives to various model components. I couldn't see a detailed model ablation study, and I wonder about alternative choices in certain parts of the model, e.g. what happens if we were to use a different robust loss or just xent loss in the outer loop?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper appears to be clear-enough and technical details are mostly sufficient. However, it is not clear how the hyper-parameters were tuned, in the absence of clean validation sets.",
            "summary_of_the_review": "Overall, the paper appears to be promising with strong positive results. However, it lacks in certain model and experimental aspects as discussed above. In particular, in my preliminary rating, I find the the lack of clarity regarding model selection and the lack of experiments evaluating major model choices (in particular on the effects of robust loss) as major experimental limitations.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2800/Reviewer_mEap"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2800/Reviewer_mEap"
        ]
    }
]