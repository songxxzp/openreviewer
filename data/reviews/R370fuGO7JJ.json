[
    {
        "id": "UGDJjv5Br5G",
        "original": null,
        "number": 1,
        "cdate": 1666626636423,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666626636423,
        "tmdate": 1666627697343,
        "tddate": null,
        "forum": "R370fuGO7JJ",
        "replyto": "R370fuGO7JJ",
        "invitation": "ICLR.cc/2023/Conference/Paper4812/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This work develops a deep network for assessing diabetic retinopathy (DR) in retina fundus images by implementing a multi-scale attention mechanism, and a brand-new loss function.\nExperimental results show that the effectiveness of the developed method.\n",
            "strength_and_weaknesses": "Strengths:\n1.\tThis work develops a CNN based on a multi-scale attention for DR grading.\n2.\tThe experimental results verify the effectiveness of the developed method.\nWeaknesses:\n1.\tThis work has limited technical novelties. The multiscale attention strategy is to simply learn attention maps at different scales.  Such technical novelties are not enough for publication in ICLR\n2.\tThe experimental results are not convinced. It seems that the authors only report the results of the developed method. It neglects the comparisons with state-of-the-art methods.\n3.\tIn the experiments, the authors do not provide any ablation study experiments.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarify of this work is not bad and the writing of this work is easy to follow. \nHowever, the quality and the originality of this work is not acceptable. This work has a limited technical novelties. Moreover, the experiments are not convinced, and the authors mainly focus on the results of the developed method.\n",
            "summary_of_the_review": "1.\tThe technical novelties of this work are not enough for publication in ICLR. \n2.\tThe experiments are not convinced. The authors do not provide comparisons against state-of-the-art methods and any ablation study experiments.\n3. \tWriting issues: The sentence \u201cThis paper presents a deep learning-based method for automatically assessing diabetic retinopathy in retina fundus pictures.\u201d appears two times in the Abstract.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4812/Reviewer_mS2T"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4812/Reviewer_mS2T"
        ]
    },
    {
        "id": "51JI51AX-v1",
        "original": null,
        "number": 2,
        "cdate": 1666634037570,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666634037570,
        "tmdate": 1666634037570,
        "tddate": null,
        "forum": "R370fuGO7JJ",
        "replyto": "R370fuGO7JJ",
        "invitation": "ICLR.cc/2023/Conference/Paper4812/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper presents a deep-learning method for the automatic assessment of diabetic retinopathy in retina fundus pictures. A multi-scale attention mechanism is developed to enhance the discriminative power of the model. In contrast to the previous methods, the attention mechanisms used in this work are combined with the network architecture to automatically learn to focus on salient features at various phases of the feature extraction. Furthermore, a novel loss function, named modified grading loss, is proposed to improve the training convergence by accounting for the distance between distinct grades\nof various DR categories. \n",
            "strength_and_weaknesses": "Strength: \n-The paper is well-written and easy to understand. \n-Developing applications of deep learning in other domains especially healthcare is highly important and requires major attention from the community. \n\n\n\n\nWeaknesses:\nMAJOR:\n-A major shortcoming of the paper is the lack of novelty. The attention mechanism, network architectures, the idea of passing different scales of the same input to different networks, and the grading loss function are cited from previous works and the current work seems as an adaptation of a previously developed model for the special tasks of DR classification. Further, the task itself is also a simple classification problem that does not incur novel challenges. A very similar paper to the current work is also published: \u201cAl-Antary, Mohammad T., and Yasmine Arafa. \"Multi-scale attention network for diabetic retinopathy classification.\" IEEE Access 9 (2021): 54190-54200.\u201d. \n-The reasoning for developing soft attention is vague and requires further clarification. Perhaps, conducting a relevant experiment can be beneficial to clarify its usefulness.  \n-The description of the grading loss function is vague and requires a formal formulation to clarify the concept. \n-Only a single dataset is used for the evaluation. This limits the comprehensiveness of the validations. \n-How is the ROC curve for the 4-class classification problem computed? \n\n\nMINOR: \n\n-\u201c(DR)\u201d in the first line of the introduction requires a space. \n-\u201cThis is a figure\u201d in Figure 2 is redundant. \n-Section 3.1.1: \u201cthis approach adopt\u201d -> \u201cthis approach adopts\u201d\n-Section 3.1.1: \u201cIn this work we intoduced\u201d requires a comma after work and also there is a typo in introduced. \n-Section 4.1: \u201cthe suggest approach\u201d -> \u201cthe suggested approach\u201d\n-Section 4.1: \u201cshown\u201d -> \u201cshows\u201d\n-Section 4.1: \u201cclass 3 qnd 4\u201d -> \u201cclass 3 and 4\u201d\n-Section 4.1: \u201cclass 3, 4\u201d -> \u201cclasses 3 and 4\u201d\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is almost clear and reproducible. However, the novelty and the scientific quality in terms of contributions are notably limited.\n",
            "summary_of_the_review": "The paper combines several ideas from previous works including a multi-scale attention mechanism and grading loss function to improve the classification of DR in retina images. The methodology lacks novelty and the problem itself is not challenging enough. Furthermore, the experimental setup is simple and does not present enough evaluations and ablation studies to validate the claims in the paper including the necessity of soft or multi-scale attention and the grading loss. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4812/Reviewer_5o7H"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4812/Reviewer_5o7H"
        ]
    },
    {
        "id": "HCtuRnXOWb",
        "original": null,
        "number": 3,
        "cdate": 1666656548927,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666656548927,
        "tmdate": 1666656548927,
        "tddate": null,
        "forum": "R370fuGO7JJ",
        "replyto": "R370fuGO7JJ",
        "invitation": "ICLR.cc/2023/Conference/Paper4812/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The work proposes to combine a multi-scale attention mechanism with a deep convolutional neural network to improve discriminative abilities of the features used for diabetic retinopathy grading. The modified training loss is used for improving model convergence by comparing various grades of the disorder. The experiments are performed on the publicly available dataset to show advantages of the method over other attention-based techniques.  ",
            "strength_and_weaknesses": "The paper addresses an important problem of diabetic retinopathy (DR) grading, what's important in encouraging further improvements and automation of medical procedures. The background of the problem is clearly explained along with existing methods used for the prediction of the DR disorder. \n\nHowever, the work suffers from some significant omissions that affect its quality:\n1) As specified in the experiments section, other techniques for DR grading using attention mechanisms have been proposed. It's not clear how the method differs from them. \n2) Comparison of results is missing - there is no Table 1 that is referred to in the text.\n3) Results are not satisfactory, the performance of the model is quite poor, what hasn't been discussed. A details explanation of results, ideas for improvements and future work would be beneficial.\n4) It's mentioned that the used dataset was imbalanced, what can be also seen in the presented confusion matrix. Majority of samples were classified as category 0. Have you tried any techniques to address this issue, such as reweighing/over/undersampling, etc.?\n5) Weighted softmax has been used in other studies before. How exactly does the new loss function differ from that? It's not clear.\n6) Selection of specific neural networks hasn't been explained. It would be interesting to compare different topologies. \n7) Background section contains explanation of well known techniques. It's sufficient to refer to them instead of introducing them in details. Similarly, attention mechanism is known, so there is no need for such detailed introduction of this technique.",
            "clarity,_quality,_novelty_and_reproducibility": "The novelty, quality and reproducibility of the work is limited due to some missing results and other omissions specified in the previous comment.",
            "summary_of_the_review": "The presented paper looks incomplete. Some additional work should be done to improve its quality, provide more detailed analysis of results and justify the novelty of the method.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4812/Reviewer_zeSz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4812/Reviewer_zeSz"
        ]
    }
]