[
    {
        "id": "D_TrinH0H4a",
        "original": null,
        "number": 1,
        "cdate": 1666576724762,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666576724762,
        "tmdate": 1666576724762,
        "tddate": null,
        "forum": "pjyM7D09M5",
        "replyto": "pjyM7D09M5",
        "invitation": "ICLR.cc/2023/Conference/Paper1597/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper challenges a common belief that a disentangled representation is useful for downstream tasks. Following up Steenkiste et al., 2019 and Locatello et al. 2019b,  the authors focused on the informativeness of the representation and its correlation with the performance of downstream tasks.",
            "strength_and_weaknesses": "Strong points:\n\n-extensive experimentation and evaluation\n\n-effective use of logistic regression as a measure of informativeness\n\n-a comparison between the effects of disentangled representation vs. deliberate entanglement of disentangled representations on downstream task\n\nWeak points:\n\n-lack of theoretical contribution\n\n-there are far more types of disentangling VAEs against one general-purpose representation learning method (BYOL). Since downstream test performance is averaged over different VAEs, is this a fair comparison?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and clear",
            "summary_of_the_review": "Adding logistic regression as a measure of informativeness to previous measures of disentanglement, it is clear from experiments that this measure should be of value in evaluating learned representations in connection with downstream accuracy.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1597/Reviewer_ZFjG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1597/Reviewer_ZFjG"
        ]
    },
    {
        "id": "5sQLUgt6_K",
        "original": null,
        "number": 2,
        "cdate": 1666602894203,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666602894203,
        "tmdate": 1666602894203,
        "tddate": null,
        "forum": "pjyM7D09M5",
        "replyto": "pjyM7D09M5",
        "invitation": "ICLR.cc/2023/Conference/Paper1597/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper performs a large scale empirical study to investigate whether disentangled representations provide a clear benefit for the final performance on downstream tasks. First, the ground-truth disentangled representation (normalized true factors) are compared to a rotated version of the same representations. The authors show that the two types of representations yields no significant difference in the final downstream performance. The second paper contribution compares the final performance of two models (a WReN and a Transformer) on an abstract reasoning tasks, using representations learned both via disentanglement-oriented learning methods (DisVAEs) and an entangled representation learning method (BYOL). They report a better downstream performance using representations based on BYOL. Finally, the authors show that the Informativeness is the metric that correlates the most with downstream performance on both DisVAE and BYOL representations, with disentanglement bringing only a small extra benefit.",
            "strength_and_weaknesses": "STRENGHTS\n\n(+) The experimental setting, is for the most part, reasonable and well-designed.  The paper is well-written and easy to follow. The experiments try to tackle relevant questions in the representation learning community.\n\nWEAKNESSES\n\nThe evidence presented is not enough to back up all claims of this paper. In particular, I have the following concerns:\n\n(-) In the first contribution, the true disentangled representations are compared only with a rotated version of themselves. Even if the rotated representations are not disentangled according to the metrics, I think that they are still a much more similar to a disentangled representation than the typical representations learned by deep learning models. Therefore, comparing between the two is not enough to claim that disentanglement is not beneficial for downstream performance in general. A fairer comparison would be between true disentangled representations and entangled representations learned by a standard VAE, where \\lambda_1 and \\lambda_2  of Equation 3 are both set to 0. \n\n(-) Table 1. Two concerns: first, for which DisVAEs model does the reported accuracy refer to? Is it an average between the models? Second, reporting the step with the highest validation accuracy for both DisVAE and BYOL can be misleading, since it hides information about *when* that accuracy is achieved. It might be the case where BYOL achieves an overall better accuracy, but much later than DisVAEs. In that case, using a DisVAE model for representation learning could still be valuable. It is generally fairer to fix a specific number of training steps, or to run an early stopping strategy. More generally, it can be interesting to have more information about the speed of convergence of these model. Furthermore, I would have expected to see the standard deviations of performance of the 5 different runs of WReNs and Transformers reported in Table 1.\n\n(-) Figure 1 should be moved closer to section 4.2, for the sake of readability.The results of  Figures 5 and 6 show that informativeness has a strong correlation with downstream tasks. However, it seems that disentanglement somewhat implies informativeness, and that the representations trained with BYOLS exhibit high disentanglement scores on dSprites, at least in the case of the beta-VAE and FactorVAE scores. I am not sure that correlations alone are enough to make any conclusions about the usefulness of disentanglement. In order to conclude that informativeness is more beneficial than disentanglement on downstream tasks, I would like to see a comparison of the absolute values of disentanglement scores and informativeness scores for the two representations, showing that BYOL representations have higher informativeness, lower disentanglement, and higher downstream performance than DisVAE representations. Finally, it is still not very clear to me how the authors selected the final DisVAEs representation to be used in the figures.\n\nOn the minors side, Figure 1 should be moved closer to section 4.2, for the sake of readability.",
            "clarity,_quality,_novelty_and_reproducibility": "The claims discussed in the paper are relevant for the research community. The experiments seems well-designed, except for the points highlighted in the previous section. The writing style is generally clear and concise. The authors report all the details needed for reproducibility; however, they do not share the code of the experiments (but commit to sharing it after publication).",
            "summary_of_the_review": "This paper tries to tackle some relevant problems of the representation learning community. While the experiments are generally well-designed, it does not seem to me that the presented evidence is enough to support the major claims of this paper.  Some additional experiments are needed, and some concerns in the experimental settings need to be addressed, in order to make this manuscript suitable for publication.\n\nMinor points:\n - The term \u201cFactorVAE\u201d is often spelled incorrectly on page 8.\n - The second point of contributions in the introduction start with the sentence \u201cWe show that what information...\u201d that is a bit hard to read. I would recommend rephrasing that sentence.\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1597/Reviewer_Pb5b"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1597/Reviewer_Pb5b"
        ]
    },
    {
        "id": "hUeMJd5NFGW",
        "original": null,
        "number": 3,
        "cdate": 1666673573607,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666673573607,
        "tmdate": 1666673619403,
        "tddate": null,
        "forum": "pjyM7D09M5",
        "replyto": "pjyM7D09M5",
        "invitation": "ICLR.cc/2023/Conference/Paper1597/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies dimension-wise disentangled representations for downstream applications. Through extensive experiments, the authors conclude that disentanglement is not a necessity for achieving good performance in downstream tasks, and general-purpose representation learning methods could achieve better (or at least competitive performance) than disentanglement methods.\n\nThe authors show that Logistic regression accuracy on factor classification well-correlates with downstream task performance. The reason that we feel disentanglement is useful for downstream tasks is presumably due to the positive correlation between LR and disentanglement metrics.\n",
            "strength_and_weaknesses": "Strength:\n\n--The authors challenge the necessity of dimension-wise disentanglement for downstream tasks via extensive amounts of ablation studies. Through experiments, the authors examined 1) effects of attenuating disentanglement, 2) general-purpose vs disentangled training, 3) How different disentanglement/informativeness metrics correlate with downstream tasks, and 4) the correlation between LR and some disentanglement metrics. Every claim/reasoning is supported by experiments.\n\n--The authors conduct multiple runs of experiments, and cover different kinds of model architectures and disentanglement training methods and metrics. The exploration is pretty thorough. \n \nWeakness:\n\n--The exploration should be expanded to other tasks and domains.\n\n--There are a lot of general-purpose pre-training algorithms, but the authors mostly focus on BOYL.\n\n--Though two-stage training is acceptable, what if the experiments are conducted in a joint-training setup where disentangling losses are used to regularize the supervised loss?\n",
            "clarity,_quality,_novelty_and_reproducibility": "I don\u2019t have specific concerns on clarity, quality and reproducibility.",
            "summary_of_the_review": "Overall, I think the paper shows something interesting, and I\u2019m inclined to recommend this paper.\n\n1.     One thing I\u2019m not sure about is how thoroughly that people have studied the importance of disentanglement for downstream tasks. This work is related to one previous ICLR submission (https://openreview.net/pdf?id=1JN7MepVDFv) where the authors studied the relationship between multi-task learning and disentanglement. The authors showed that disentanglement emerges naturally from MTL. The paper was rejected due to the main issue that MTL results in more extraction of information and that it is hard to disentanglement from the disentanglement metrics used. The authors (of the MTL work) also claimed that it is inconclusive whether disentangled representations have a clear positive impact on the model performance. In this work, the authors give a clearer explanation.\n\n2.     Recent SSL framework also shows that a linear head on top of a pre-trained general-purpose encoder can achieve near-SOTA performance. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1597/Reviewer_hRSM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1597/Reviewer_hRSM"
        ]
    },
    {
        "id": "T77WPX8OMo",
        "original": null,
        "number": 4,
        "cdate": 1666725241023,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666725241023,
        "tmdate": 1666725241023,
        "tddate": null,
        "forum": "pjyM7D09M5",
        "replyto": "pjyM7D09M5",
        "invitation": "ICLR.cc/2023/Conference/Paper1597/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors call into question the conventional thinking that downstream tasks (the take a representation as input) benefit from a disentangled representation. Their results are that the informativeness of the representation not the disentangled nature of is what results in improved downstream performance.",
            "strength_and_weaknesses": "As I was reading the paper I was confused by these two statements:\n\n\"However, on the abstract visual reasoning task, we find that rotating disentangled representations, i.e., multiplying the representations by an orthonormal matrix, has no impact on sample efficiency and final accuracy.\"\n\n-and-\n\n\"Our finding demonstrates that disentanglement does not affect the downstream learning trajectory, which is against the commonly believed usefulness of disentanglement. On the other hand, it is not surprising since we apply an invertible linear transform. We can observe that Logistic Regression (LR) accuracy remains 100% before and after rotation, indicating that a simple linear layer could eliminate the effects of rotation.\"\n\nIt appeared the authors believed that the multiplication would destroy the disentangled representation, and used this to prove their thesis. But, they later acknowledged that LR is capable of reversing the multiplication. I am at a loss for why to include this in the paper, and why to have it so early in the text.\n\nThe authors have a good experiment design, using learners that provide a disentangled representation (various VAE based approached) and compare against learned representations created by BYOL (which makes no claim to disentanglement). These representations are used to perform abstract visual reasoning tasks. They use the accuracy of using a logistic regression on the learned representation (informativeness) as a metric to show the usefulness of the representation.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written. The experiment is very thorough. A researcher should be able to reproduce the results. ",
            "summary_of_the_review": "The authors demonstrate for RPM downstream tasks the informativeness (the ability for the logistic regression to achieve a level of accuracy using the representation) is more indicative of downstream performance that the disentanglement of the representation. My biggest issue with the paper is their use of the orthonormal matrix multiplication to re-entangle the representation. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1597/Reviewer_RvuP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1597/Reviewer_RvuP"
        ]
    },
    {
        "id": "YYHLNW-Z6z",
        "original": null,
        "number": 5,
        "cdate": 1666833990911,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666833990911,
        "tmdate": 1666833990911,
        "tddate": null,
        "forum": "pjyM7D09M5",
        "replyto": "pjyM7D09M5",
        "invitation": "ICLR.cc/2023/Conference/Paper1597/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper investigates the correlation between dimension-wise disentanglement scores and downstream performance. In particular, it does so when using MLPs or Transformers to perform the task of abstract visual reasoning using the learned representation. After observing a poor correlation on this task, it concludes that disentanglement is not *necessary* for good downstream performance.",
            "strength_and_weaknesses": "**Strengths:**\n- **Clear writing:** this paper was easy to read and understand, communication was clear.\n- **Important question/investigation:** The usefulness of disentanglement for downstream tasks is an open and important question.\n\n**Weaknesses:**\n- **Not clear who claimed disentanglement is *necessary* for downstream tasks:** \n  - I agree with the authors that it is often said/believed that disentangled representations *can* be beneficial for downstream tasks. \n  - However, throughout this paper, including in the title, the authors speak of the *necessity* of disentanglement representations for downstream tasks, claiming that they \"challenge the necessity of disentanglement for downstream tasks\". It is not clear to me who has claimed that disentanglement is *necessary*, i.e. why it should be surprising that there exists a downstream task for which disentanglement does not help---this seems like a trivial statement.\n  - This is a major weakness since \"challenging the necessity of disentanglement\" is perhaps the central contribution of this paper.\n  - A more interesting and non-trivial alternative question could be: when does disentanglement help, and when does it not? This is what prior works investigated [2,3,4], Naturally, there will be tasks for which it helps and tasks for which it does not.\n- **Incorrect evaluation of sample efficiency:**\n  - The authors use learning curves (gradient step vs. accuracy) to evaluate \"sample efficiency\". While each step sees new samples, this is fundamentally flawed since it convolutes sample efficiency (the performance with N samples) and update/step efficiency (the performance with M gradient updates).\n  - This is a major weakness since sample efficiency is one of the most commonly-purported downstream benefits of disentanglement [1,2,3,4], making it central to the authors' claims.\n- **Insufficient comparison to related studies on disentanglement and downstream performance:**\n  - Many works have thoroughly investigated the correlation between disentanglement and downstream performance [2,3,4]. These works were much wider in their scope (tasks, datasets, representations) and reached different conclusions. Despite the attempt to undermine these studies in the related work and on page 9, I was left unconvinced that the results in this paper are novel or should underline/question those that came before. A better comparison and explanation would help, or perhaps a more specific claim could be made (e.g. relating to this one reasoning task with neural-net architectures).\n- **Minor:**\n  - *Rotation-of-factors issue is well-known and studied:* The authors claim to \"find that rotating disentangled representations [...] has no impact on [...] final accuracy\". This seems unsurprising given the well-known issue of rotation of factors in a linear factor-analysis model [5, sec. 9.6], which also leads to the condition in independent components analysis (ICA) that at most one of the factors can be Gaussian [6]. It was also discussed in [7]. Finally, note that it has also been investigated by a very recent (perhaps concurrent) work [8] which proposes a new notion of disentanglement that is unaffected by such rotations [8].\n  - *The term \"informativeness\" is either overloaded or not cited:* The authors seem to use the term \"informativeness\" to refer to the linear-classifier performance in classifying the ground-truth factors from the learned (disentangled) representation. If so, this is precisely the definition of the \"informativeness\" metric in [7], but the authors never mention this relation. If this is in fact the same metric, the authors should appropriately cite, or if not, they should use a different name/term to avoid overloading an existing metric for evaluating disentangled representations.\n  - *Unclear to me why disentanglement should help the specific abstract-reasoning task used:* Are only a subset of the factors needed? Do only a subset of the factors change? Is it surprising that disentanglement does not help?\n  - *Incorrect and imprecise statements:*\n    - In the second paragraph of the introduction, the authors claim that the abstract-reasoning task is general and widely-adopted, while other downstream evaluation tasks are \"trivial or domain-specific\", citing many past evaluations. I have to disagree with this presentation of abstract visual-reasoning as the holy-grail of downstream evaluations, and suggest that the wording be toned down.\n    - *\"Locatello et al. (2019b) proves their agreement on VAE methods\"* -- Locatello et al. do not prove the agreement of different disentanglement metrics -- many of them measure different things.\n   - *\"it takes hours to develop the Gradient Boosting Trees required [to evaluate DCI disentanglement]\"*: GBTs are not _required_ to evaluate DCI disentanglement---any classifier can be used, including those with a lower cost (e.g. random forests).\n\n[1] Bengio, Y., Courville, A., \\& Vincent, P. (2013). Representation learning: A review and new perspectives. _IEEE Transactions on Pattern Analysis and Machine Intelligence_, 35(8), 1798-1828.\n\n[2] Locatello, F., Bauer, S., Lucic, M., R\u00e4tsch, G., Gelly, S., Sch\u00f6lkopf, B., \\& Bachem, O. (2020). A Sober Look at the Unsupervised Learning of Disentangled Representations and their Evaluation. _Journal of Machine Learning Research_, 21, 1-62.\n\n[3] Van Steenkiste, S., Locatello, F., Schmidhuber, J., \\& Bachem, O. (2019). Are disentangled representations helpful for abstract visual reasoning?. _Advances in Neural Information Processing Systems_, 32.\n\n[4] Dittadi, A., Tr\u00e4uble, F., Locatello, F., W\u00fcthrich, M., Agrawal, V., Winther, O., ... \\& Sch\u00f6lkopf, B. (2021). On the Transfer of Disentangled Representations in Realistic Settings. In _International Conference on Learning Representations_.\n\n[5] Mardia, K. V., Kent, J. T., \\& Bibby, J. M. (1979). _Multivariate Analysis_. Academic Press, London.\n\n[6] Hyvarinen, A., Karhunen, J., \\& Oja, E. (2001). _Independent Component Analysis_. Wiley.\n\n[7] Eastwood, C., \\& Williams, C. K. I. (2018). A framework for the quantitative evaluation of disentangled representations. In _International Conference on Learning Representations_.\n\n[8] Eastwood, C., Nicolicioiu, A. L., von K\u00fcgelgen, J., Keki\u0107, A., Tr\u00e4uble, F., Dittadi, A., \\& Sch\u00f6lkopf, B. (2022). DCI-ES: An Extended Disentanglement Framework with Connections to Identifiability. _arXiv preprint arXiv:2210.00364_.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity:** Good. (see strength above)\n\n**Quality:** Poor.\n- Main contribution of \"challenging the necessity of disentangled representations\" is questionable (see weaknesses above).\n- Incorrect evaluation of sample efficiency (see weaknesses above).\n\n\n**Novelty:** Poor/limited.\n  - Many works have thoroughly investigated the correlation between disentanglement and downstream performance. Novelty of this work is unclear in relation to those works, except for the questionable focus on \"necessity\".",
            "summary_of_the_review": "While this paper is well written and explores a question that is both open and important, it ultimately fails to meet the standards required for acceptance. In particular: (1) its central claim---disentanglement is not *necessary* for downstream tasks---seems trivial; (2) its evaluation of sample efficiency is incorrect (this is one of the main purported benefits of disentanglement); and (3) its novelty/difference in comparison to prior such evaluations is not made sufficiently clear.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1597/Reviewer_r3zU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1597/Reviewer_r3zU"
        ]
    }
]