[
    {
        "id": "S4sAxaygbI",
        "original": null,
        "number": 1,
        "cdate": 1666575543293,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666575543293,
        "tmdate": 1666575543293,
        "tddate": null,
        "forum": "sP1fo2K9DFG",
        "replyto": "sP1fo2K9DFG",
        "invitation": "ICLR.cc/2023/Conference/Paper4940/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper presents the decision diffuser for decision-making. The core idea is to model the decision making as a conditional generative model, which is different from the complex reinforcement learning-based works. Specifically, the method models a policy as a conditional generative model where the diffusion process is applied over states and gets return-maximizing trajectories. The experimental results show the performance on par with recent offline RL-based methods. ",
            "strength_and_weaknesses": "## Strength\n- Modeling decision-making as the conditional generative model is novel and also interesting to the community.\n- Via conditional generative process, the method shows the ability to compose skills in order to maximize the rewards. This is impressive. \n- The paper in general is of high quality in terms of supportive experiments, and motivation. \n\n## Weakness\nI'm not an expert in decision-making/Reinforcement learning. So I'm not entirely sure if I follow the problem definition. To be specific, what's the design choice that leads to the ability to compose skills? And do other reinforcement learning-based method have the same ability? It would be better to make it simpler. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is of high quality, clarity, and novelty. Since I'm not an expert in refinement learning/decision-making. I'm not entirely sure about the reproducibility.",
            "summary_of_the_review": "From my perspective, the paper is of high quality. It presents a well-motivated story. \n- Good motivation for modeling decision-making as a generative model. \n- More importantly, the method shows the ability to compose skills, which impresses me a lot.\n- The experimental results are also impressive. Though the conditional generative model is simple, it shows the performance on par with other complex reinforcement learning. \n\nAlthough I'm not very clear about some details of the diffusion process in the composition of skills, I tend to accept this paper given the impressive results. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4940/Reviewer_WRRm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4940/Reviewer_WRRm"
        ]
    },
    {
        "id": "hyN4gooGEz",
        "original": null,
        "number": 2,
        "cdate": 1666659113139,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666659113139,
        "tmdate": 1666659113139,
        "tddate": null,
        "forum": "sP1fo2K9DFG",
        "replyto": "sP1fo2K9DFG",
        "invitation": "ICLR.cc/2023/Conference/Paper4940/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes Decision Diffuser, a diffusion-based model for sequential decision making where only the states of a trajectory are modeled and an inverse dynamics model is used to predict actions. Classifier free guidance is used to bring in conditional information, in the form of maximizing returns, satisfying constraints or composing together skills. This is used with low-temperature sampling at inference time yielding improved results. The proposed method is evaluated to generate trajectories for return maximization with offline reinforcement learning datasets. Kuka Block stacking and Unitree-go-running environments are used to assess the performance of generated trajectories in constraint satisfaction and skill composition tasks, respectively.\n",
            "strength_and_weaknesses": "Strengths:\n- The paper is well written. Diffusion modeling for planning is an exciting and timely contribution given that diffusion models are beating state of the art in various other tasks in synthesis.\n- The proposed technique is shown to tackle compositionality of skills and constraints at inference time, which is interesting.\n\nWeaknesses:\n- One limitation of diffusion models is that the generations are slow. It would be great if authors can comment on the runtime characteristics of the proposed model.\n- It would be good to discuss limitations of the model. Some questions I have: \n  * How are the out-of-distribution generalization characteristics of the model? \n  * Can the model capture variable length trajectories? \n  * I am intrigued by the skill composition idea. Currently only \u201cAND\u201d style composition is demonstrated. What other compositions does this method can support?\n  * How does the method perform with limited data?\n\nOther comments:\n- The loss function used to train the model combines losses which are used to train the diffusion model and inverse dynamics models equally. What implications does equal weighting have?\n- The paper relies on diffusion models and class conditioning capabilities of such models (i.e. classifier free guidance) but I found it odd that the modeling choice is not mentioned in the abstract. \n- What is the performance metric used in Figure 4? Similarly, Table 3 is lacking an explanation of the metric used. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and organized. The proposed method is evaluated empirically across a broad range of offline reinforcement learning scenarios for return maximization. Skill composition and constraint satisfaction are also explored.\n\nDiffusion models are proposed to be used for sequential trajectory data in Jammer et al. (2022), where both states and actions are modeled jointly. The model proposed in this paper separates these two and uses an inverse dynamics model to model actions. Furthermore, they adopt a classifier free guidance approach (as opposed to classifier guidance in Jammer et al., 2022). These incremental advancements yield superior results in offline reinforcement learning settings.\n\nJanner, M., Du, Y., Tenenbaum, J.B. and Levine, S., 2022. Planning with Diffusion for Flexible Behavior Synthesis. arXiv preprint arXiv:2205.09991.",
            "summary_of_the_review": "The paper explores diffusion models for planning, which is a timely contribution since diffusion models are beating state of the art in various problems. It offers incremental advancements over the state of the art in this domain however the proposed advancements are shown to yield superior performance on various tasks. I think this is a good paper and I recommend acceptance.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4940/Reviewer_pyhf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4940/Reviewer_pyhf"
        ]
    },
    {
        "id": "SshJMBuVSRt",
        "original": null,
        "number": 3,
        "cdate": 1666701539661,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666701539661,
        "tmdate": 1669720797188,
        "tddate": null,
        "forum": "sP1fo2K9DFG",
        "replyto": "sP1fo2K9DFG",
        "invitation": "ICLR.cc/2023/Conference/Paper4940/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "**Update after rebuttal** I am very happy to see a very extensive and detailed authors' rebuttal with a number of additional evaluations and results. Most of my questions have been answered and my criticism has been addressed to a sufficient degree. Though there could be some detailed follow-up discussions, I think overall the paper is now ready for acceptance - I am on the fence between a 6 and an 8, but am very slightly leaning towards the latter, so I will raise my score from 5 to 8.\n\nThe paper explores the use of a diffusion model to generate reward-conditioned state-trajectories to reach goals and satisfy constraints in MDPs given a large set of state-action-reward trajectories (solving decision-making via conditional generative modeling). In contrast to previous work on synthesizing high-expected-return policies from expert data, this paper uses a classifier-free guided diffusion model. Additionally, the paper proposes to diffuse over state-trajectories only, rather than state-reward trajectories; which is empirically shown to lead better policies but requires learning an inverse dynamics model. The method is compared against a number of state-of-the-art competitors on two standard benchmarks (D4RL tasks, and Kuka Block stacking tasks). Finally, the paper shows how conditional generation of trajectories can not only be used for conditioning on high-rewards but also other subsets of training trajectories which either satisfy certain constraints or belong to a certain type of skill (such as a particular gait for running).",
            "strength_and_weaknesses": "**Main contributions, Impact**\n1) Use of classifier-free guided diffusion. Classifier-guided diffusion requires a Q-value estimation procedure such that Q-values can be used to guide diffusion (which has been explored in Janner et al. 2022). The current work avoids this via classifier-free guidance which requires low-temperature sampling in datasets where demonstrations are of mixed quality. Empirically, this leads to improvements over previous methods - with a grain of salt it seems to be easier to pick out the high performing trajectories than learning good Q-value estimates. Impact: low to medium - it remains unclear under what exact conditions (both theoretically and empirically) classifier-free guidance / low-temperature sampling outperforms Q-value guidance and why.\n\n2) Diffusion of state-trajectories only, rather than state-action trajectories (which is compared to in the paper and shown to perform worse). This comes at the cost of requiring a good inverse dynamics model. Current impact: low - similar to 1) the empirical results are in favor of the version proposed in the paper but it remains unclear what the practical cost of requiring the inverse dynamics model is; in particular how robust the method is against errors and imperfections in the inverse dynamics estimate (is performance very brittle or quite robust). Under what conditions is it better to rely on an approximate inverse dynamics model, and when is it better to diffuse state-action trajectories?\n\n3) The paper shows how to incorporate combinations of constraints and skills: by identifying subsets of training trajectories corresponding to an individual constraint/skill and augmenting them with a label that can later be used to condition on. The approach is fairly straightforward, but interesting. Impact: low - the approach is currently only minimally explored in the paper and further conceptual/theoretical characterization of the kinds of constraints and the corresponding requirements for the dataset would be needed for higher impact.\n\n**Strengths**\n *  Very well written paper\n *  Empirical results show benefits of proposed method compared to high-quality SOTA methods on standard benchmarks\n * Incorporating constraints and combining skills via constraints is interesting.\n\n**Weaknesses**\n *  Often the paper\u2019s main aim seems to be to reach the minimal result sufficient for publication, which is mainly to achieve good benchmark results. While this is a valid strategy to avoid risks, it also creates a sense of lack of ambition and depth. I personally think there are some very interesting ideas presented in the paper but they often seems to be addressed in a minimal sense. Beyond the empirical comparisons, a strong characterization of the advantages and disadvantages of these ideas is missing; and I would be very excited to see such a discussion and analysis (both empirically and theoretically). I think it would help raise the significance of each of the main contributions mentioned above.\n * To make the point above more concrete: \n   * It remains unclear when precisely and why classifier-free guidance and state-prediction only is preferable - when and why is it beneficial to avoid estimating Q-values at the cost of requiring an inverse dynamics model (how robust is each approach to errors in the approximate Q-values/dynamics, what are the conditions w.r.t. the dataset that make low-temperature sampling a good choice, etc).\n   * It remains unclear what exact conditions are needed for constraints/skills to be \u201ccombinable\u201d (see comment under improvements).\n * The current experiments on combining skills are a bit hard to interpret - while they lead to somewhat visually different gaits it is unclear whether these should be considered successful combinations of skills. What\u2019s missing is a clearly stated and (quantitatively) measurable goal for combining skills (which is well defined in the case of combining constraints).\n\n**Improvements**\n1) Naively it seems that the approach introduced allows to combine individual constraints / skills, as long as there is a separate subset of training trajectories for each constraint/skill and the combination at test time is a conjunction of constraints such that the intersection of the corresponding sets of trajectories constitutes a set of valid solutions (which corresponds to the situation in Fig 1). Is this a hard condition? Can something theoretical be said about the allowed combinations of individual constraints (conjunction, disjunction, exclusive disjunction)? What happens theoretically and empirically if satisfying a combination of constraints requires novel trajectories that have no support in the training data (i.e. such that simply \u201cfiltering\u201d out the right training trajectories via conditioning and some mild generalization is not sufficient)?\n\n2) Combining skills needs some quantitative goal/metric, and an empirical evaluation. The videos are interesting and promising, but it is unclear how to interpret the results, let alone how other methods could be compared in terms of performance.\n\n3) Perturbation analysis comparing the Diffuser and Decision Diffuser in terms of robustness to noise or errors in the Q-value estimates/inverse-dynamics model respectively. While theoretical results would be nice, empirical results are probably easier to obtain and might already be insightful. Related: how well do both methods handle quite noisy dynamics? Since the latter two requires running additional experiments, potentially even designing toy environments, I do not have a hard expectation to see these results after the rebuttal; but they would certainly make the paper stronger.\n\n4) Discussion of limitations should be expanded\n * What are restrictions/requirements on the dataset, particularly w.r.t. allowing for combinable constraints/skills?\n * The current method is limited to fully observable MDPs, partial observability and latent variables might pose a hard to overcome problem, with self-delusions [1] potentially being a fundamental obstacle).\n * It seems unlikely that the method can be used to improve significantly beyond the performance of demonstrations (unlike RL, at least in theory). \n\n**Minor comments**\n\nA) What is the relation between constraint conditioning as presented in the paper and more general task conditioning (via natural language prompts) as in e.g. DeepMind\u2019s Gato?\n\nB) Sec. 3 \u201cIt is useful to solve RL from offline data, both without relying on TD-learning and without risking distribution-shift.\u201d - what are the conditions/requirements for the latter to be possible (at least informally)? In order to not *risk distribution shift* strong conditions on training-data coverage seem required.\n\nC) What is the fundamental difference between constraints and skills - are they more than simply two different names to refer to subsets of trajectories in the training data?\n\nD) \u201cIn contrast to these works, in addition to modeling returns, Decision Diffuser can also model constraints or skills and generate novel behaviors by flexibly combining multiple constraints or skills during test time.\u201d - while this has not been explored in previous publications, is there a fundamental problem that prevents previous methods from using the same approach as used in this paper (i.e. augmenting data with a one-hot indicator for constraints/skills, and conditioning on that during generation)?\n\nE) P4, typo: \u201cchoices fof diffusion\u201d\n\n[1] Shaking the foundations: delusions in sequence models for interaction and control, Ortega et al. 2021\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very well written, perhaps a slightly more expanded discussion and detailed comparison against previously proposed methods such as the Diffuser could be helpful to clearly and compactly state the novelty. The quality of the experiments shown is high, including comparison against strong SOTA methods. What I would have liked to see for an even higher quality paper is some critical discussion and analysis (via ablations or control experiments) of the main innovations (see Improvements). The method is a fairly incremental improvement of e.g. the Diffuser and the idea of using generative modeling for decision making has by now been widely explored - yet I think the paper has sufficient novelty. Sufficient details for reproducibility of the work seem present in the appendix.",
            "summary_of_the_review": "The paper makes some incremental, but sensible improvements to previously proposed work - and the empirical results justify the modifications. While the main ingredients that went into the improvements have been reported before, the particular combination is novel. To me personally, the paper could be more impactful and of higher quality by justifying the introduced changes beyond mere overall performance on some benchmarks and discussing advantages and disadvantages in detail (including some insight into when and why the introduced modifications are beneficial compared to the previous method). Another novelty introduced is the possibility to combine constraints/skills - this is an interesting idea, but currently it is explored rather superficially, a deeper exploration (as suggested earlier in my review) would make the work stronger. Overall I am quite on the fence for this paper - while there is a clear and sensible main idea and empirical results are in favor of the idea, the paper also has a bit of a flavor of \u201cwe tried something and it worked, but we didn\u2019t really look into it any further\u201d. I think that\u2019s potentially a missed chance, since the paper could be quite strong with a bit more work and attempting to answer some of the harder questions. I am therefore currently voting for a borderline rejection, and would not be upset if the paper got accepted - but to me personally the paper is currently on  the level of a very well written and very strong workshop contribution; promising main results but a bit of a lack in depth and clear and well-understood main findings. I am happy to reconsider my final verdict in light of the other reviews and author discussion.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4940/Reviewer_9svn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4940/Reviewer_9svn"
        ]
    },
    {
        "id": "vHNcS_jb1F",
        "original": null,
        "number": 4,
        "cdate": 1667281255095,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667281255095,
        "tmdate": 1669938341205,
        "tddate": null,
        "forum": "sP1fo2K9DFG",
        "replyto": "sP1fo2K9DFG",
        "invitation": "ICLR.cc/2023/Conference/Paper4940/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents Decision Diffuser, a conditional generative model for sequential decision making. It frames offline sequential decision making as conditional generative modeling by considering  two other variables: constraints and skills. Conditioning on a single constraint or skill during training leads to behaviors at test-time that can satisfy several constraints together or demonstrates a composition of skills. Experiments are conducted on a couple of different decision making tasks.",
            "strength_and_weaknesses": "Pros:\nThis paper is well motivated and easy to follow. Inspired from diffusion models in vision domain, this paper formulate the decision making process as a condition generation problem and which can naturally achieved by leveraging diffusion models. I like the way that this paper very clearly introducing the technical background and formulate the problem. From the experimental results, the proposed Decision Diffuser is promising on a couple of evaluating tasks.\n\nCos:\nMy main concern is the limited technical novelty. The key contribution of this work is to formulate the decision making problems as a conditional generation problem. Based on this, this paper train a diffusion model on offline datasets. However, it is more like an application of diffusion models on decision making tasks. I don't see obvious novelty from either model design and/or training objectives.\nThe evaluations are weak. It only evaluate the DD variants on a few tasks. No comparisons of DD with the other state-of-the-art approaches are shown. Also, no ablation and discussion are shown. It is not convincing to me without such extensive study.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well motivated and easy to follow. Inspired from diffusion models in vision domain, this paper formulate the decision making process as a condition generation problem and which can naturally achieved by leveraging diffusion models. I like the way that this paper very clearly introducing the technical background and formulate the problem. From the experimental results, the proposed Decision Diffuser is promising on a couple of evaluating tasks.\nMy main concern is the limited technical novelty. The key contribution of this work is to formulate the decision making problems as a conditional generation problem. Based on this, this paper train a diffusion model on offline datasets. However, it is more like an application of diffusion models on decision making tasks. I don't see obvious novelty from either model design and/or training objectives.\nThe evaluations are weak. It only evaluate the DD variants on a few tasks. No comparisons of DD with the other state-of-the-art approaches are shown. Also, no ablation and discussion are shown. It is not convincing to me without such extensive study.\nIt did not submit the source code, so the reproducibility is hard to be validated.",
            "summary_of_the_review": "This paper is well motivated and easy to follow. Inspired from diffusion models in vision domain, this paper formulate the decision making process as a condition generation problem and which can naturally achieved by leveraging diffusion models. I like the way that this paper very clearly introducing the technical background and formulate the problem. From the experimental results, the proposed Decision Diffuser is promising on a couple of evaluating tasks.\nMy main concern is the limited technical novelty. The key contribution of this work is to formulate the decision making problems as a conditional generation problem. Based on this, this paper train a diffusion model on offline datasets. However, it is more like an application of diffusion models on decision making tasks. I don't see obvious novelty from either model design and/or training objectives.\nThe evaluations are weak. It only evaluate the DD variants on a few tasks. No comparisons of DD with the other state-of-the-art approaches are shown. Also, no ablation and discussion are shown. It is not convincing to me without such extensive study.\nIn addition, it did not submit the source code, so the reproducibility is hard to be validated. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4940/Reviewer_87NB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4940/Reviewer_87NB"
        ]
    }
]