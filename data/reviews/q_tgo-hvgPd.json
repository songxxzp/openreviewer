[
    {
        "id": "9QGWwkZSdF",
        "original": null,
        "number": 1,
        "cdate": 1666494799102,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666494799102,
        "tmdate": 1666494799102,
        "tddate": null,
        "forum": "q_tgo-hvgPd",
        "replyto": "q_tgo-hvgPd",
        "invitation": "ICLR.cc/2023/Conference/Paper5943/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper introduces a new quality diversity algorithm, CMA-MAE, that try to address some limitations of the baseline algorithm CMA-ME. The authors introduce a learning rate $\\alpha$ into the acceptance threshold, which encourages CMA-MAE to spend more time on the promising zones before transitioning to exploration. The performance of the proposed algorithm is evaluated in three QD benchmark domains and the results show that the proposed algorithm outperforms state-of-the-art QD algorithms.",
            "strength_and_weaknesses": "Strength\n\n- The paper is overall well written and easy to understand.\n- The experimental results show that the proposed method is robust and superior to other QD algorithms.\n\nWeaknesses\n\n- The proposed method is very incremental. Compared with CMA-ME, it just adds the smoothing factor to update the acceptance threshold. \n- The experiments are not very convincing. The authors claimed that the modification allows CMA-MAE to spend more time on the promising zones before transitioning to exploration, thus can make CMA-MAE do better on domains with objectives that are hard to optimize as well as domains with flat objective functions. However, in the experiments, in addition to the common benchmarks, the authors only tested the methods on a simple function with the flat property, which makes the results not very convincing. I suggest the authors to conduct experiments on more problems with the mentioned properties.\n- More ablation studies are needed. The performance of CMA-MAE depends on not only the setting of $\\alpha$ but also that of $min_f$. What is the impact of the setting of $min_f$ on the performance?\n- There are some minor problems, for example, in the section on limitations and future work, the order of the two paragraphs may be wrong.",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity, quality and reproducibility are good, but the novelty is very limited.",
            "summary_of_the_review": "The paper is overall well written and easy to understand. However, the proposed method is very incremental compared with the baseline algorithm, and more convincing experiments are needed to demonstrate the advantages of the method.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5943/Reviewer_prZ5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5943/Reviewer_prZ5"
        ]
    },
    {
        "id": "iW-es3P86t",
        "original": null,
        "number": 2,
        "cdate": 1666688939143,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666688939143,
        "tmdate": 1666688939143,
        "tddate": null,
        "forum": "q_tgo-hvgPd",
        "replyto": "q_tgo-hvgPd",
        "invitation": "ICLR.cc/2023/Conference/Paper5943/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper aims at improving CMA-ME, a quality-diversity (QD) algorithm. The authors focus on the way that the CMA-ME ranks candidate solutions. The authors hypothesize that the rapid change of the fitness threshold value, denoted by t_e, is the cause of three limitation highlighted in the QD community: prematurely abandoning the objective, struggling to explore flat objectives, and having poor performance for low-resolution archives. The proposed approach changes only the way to update the threshold: introducing a damping factor. \n\nThe proposed approach, CMA-MAE, is compared with CMA-ME, MAP-Elites (line) and MAP-Elites on 5 test problems. Higher QD-score and coverage are observed for all test problems.\n\n",
            "strength_and_weaknesses": "# Strength\n\n* A minimal change to the existing approach, CMA-ME, has been proposed, but a statistically significant improvement has been observed in the benchmark problems.\n\n# Weaknesses\n\nTechnical contribution: A simple approach is nice. However, at the same time, the proposal is incremental and its difference is minimal. \n\nTest problem choice: It has not been discussed why these 5 test problems are selected. Because the selection of test problems is a very important part of the experimental design, this must be carefully explained. In this work, why are these 5 test problems are sufficient to reveal the goodness and limitation of the proposed approaches? \n\nDiscussion on the significance: I understand that the results are statistically significant. However, because I am not very familiar with QD community, it is hard to see whether this improvement is meaningful. A discussion on how meaningful these improvements are would improve the readers' understanding, especially for those who are not familiar with QD, which I guess the most audiences in this conference are.\n\nSignificance of this topic: Because the test problems are selected from the existing work where differentiability is assumed, a possible application of the proposed approach is not clear.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is easy to follow. Because of the proposal is incremental and the change is minimal, its novelty is limited. The experimental details are provided.",
            "summary_of_the_review": "It is hard to judge this paper. The technical contribution is minimal. However, this minimal change leads to a statistically significant improvement over the existing approaches. It is not clear how it contributes to ML communities. Probably because of the lack of my knowledge in QD, the significance of the proposed approach may be underestimated. I would currently suggest weak reject, but it may be increased if the authors response convinces me.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Research integrity issues (e.g., plagiarism, dual submission)"
            ],
            "details_of_ethics_concerns": "Section 2 and 3 are very similar to an existing paper [*]. It is not a copy-paste as each sentences are rephrased. Therefore, it may be fine. However, the structure of these sections are very close. \n\n[*] Matthew Fontaine and Stefanos Nikolaidis. Differentiable quality diversity. NeurIPS 2021.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5943/Reviewer_KKju"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5943/Reviewer_KKju"
        ]
    },
    {
        "id": "n8nKsPI0VM",
        "original": null,
        "number": 3,
        "cdate": 1667155523874,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667155523874,
        "tmdate": 1667155523874,
        "tddate": null,
        "forum": "q_tgo-hvgPd",
        "replyto": "q_tgo-hvgPd",
        "invitation": "ICLR.cc/2023/Conference/Paper5943/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a variant of an already existing algorithm CMA-ME for Qualty-Diversity (QD) problems by introducing a learning rate based annealing function.",
            "strength_and_weaknesses": "Strength:\n\n1) The paper presents a systematic study with adequate empirical experiments.\n\nWeakness:\n\n1) Significance and relevance of QD problem in machine learning along with some warm-up examples should have been given in the introduction.\n\n2) The simple algorithmic change in CMA-ME is seemingly not significant enough to warrant a publication in ICLR. The theoretical proofs seem quite standard and straightforward.\n\n3) For Figure 3, why are you plotting the QD score of different algorithms against number of iterations? WOn't it be such that these different algorithms will perform different amounts of jobs in their inner loops and hence, their \"iterations\" will not consume same amount of time?\n\n4) The proposal was not adequatey validated through comparison against evolutionary algorithms of different genre than CMA-ES, like DE for QD problems. Also the multi-objective optimization approaches like the following one should have been compared:\n\nThomas Pierrot, Guillaume Richard, Karim Beguir, and Antoine Cully. 2022. Multi-objective quality diversity optimization. In Proceedings of the Genetic and Evolutionary Computation Conference (GECCO '22). Association for Computing Machinery, New York, NY, USA, 139\u2013147. https://doi.org/10.1145/3512290.3528823\n\n5) Why the parametric ANOVA test was used instead of non-parametric statistical tests?\n\n6) Despite focusing on derivative-free QD algorithms, did you really handle a non-dfferentiable function like Weirstrass? Or I am missing something here?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Given the earlier works on CMA-ME and QD problems, the novelty seems less than expected for ICLR. The linguistic quality of the paper needs very significant improvement. \n\nThe reproducibility aspect is appreciable, the authors released detailed source codes. ",
            "summary_of_the_review": "The paper presents an interesting study with appreciable set of experiments. However, the novelty and innovative content seem somewhat less for a conference like ICLR. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5943/Reviewer_9oqX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5943/Reviewer_9oqX"
        ]
    }
]