[
    {
        "id": "OnPXcnedeQT",
        "original": null,
        "number": 1,
        "cdate": 1666646692180,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666646692180,
        "tmdate": 1666646692180,
        "tddate": null,
        "forum": "OTiSSCBm1QD",
        "replyto": "OTiSSCBm1QD",
        "invitation": "ICLR.cc/2023/Conference/Paper711/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes an approach to measure the temporal relevance in video models and studies the relationship between the performance of video model and its temporal modeling capability. ",
            "strength_and_weaknesses": "### Pros:\n\n+  Understanding the temporal modeling for action recognition is an important task. \n\n### Cons:\n\n- The definitions of relevance scores are not clear.\n  - How is the relevance score $\\mathbf{\\mathit{R}}$ accumulated from $l_k$? Also, should it make more sense to be $\\mathbf{\\mathit{R}}_k$ since it is class specific?\n  - What is $z^+$ and $z^\\beta$ rule? Any intuitive explanation? \n  - The model to be analyzed employs a ReLU activation. What if other activations are used, eg. PReLU and GELU?\n  - It is easy to get confused between $a_i$ in Eq (1) and $a_{ij}$ in the Temporal Relevance Matrix.\n\n- ATR can be interpreted as a metric to measure the effective temporal receptive field. But the models that are studied in the paper have different *nominal* temporal receptive field (which can be directly obtained from the number of temporal convolutions being used along with their kernel size and stride). Therefore, does it make more sense to consider being normalized by the nominal temporal receptive field or consider effective and nominal temporal receptive field jointly?\n\n- It is an somewhat surprising observation that video models with more input frames learn shorter-range temporal information. But how come the model does this? I don't see any further explanation..\n\n- Many conclusions being drawn are either \"no strong correlation\" or \"no strong indication\". What can we learn from these conclusions? Or from an opposite perspective, should we conclude that the technique that is being used in the paper is not a good indicator to perform such temporal analysis??",
            "clarity,_quality,_novelty_and_reproducibility": "+ Clarity: The techniques are not clearly explained and notions are confusing.\n\n+ Novelty: This is in general an analysis paper. But some conclusions are not decisive (eg \"no strong correlation\", \"no strong indication\"). It is hard to tell what we can learn from the paper.\n\n+ Reproducibility: the training and evaluation protocols follow publicly available resources. However, it is hard to reproduce due to the unclarity of the techniques.",
            "summary_of_the_review": "An analysis without many concrete conclusions. It is hard to tell what we can learn from the paper and how the conclusions can benefit designing a better video model.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "no.",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper711/Reviewer_4NU1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper711/Reviewer_4NU1"
        ]
    },
    {
        "id": "26hqAB2Ydp",
        "original": null,
        "number": 2,
        "cdate": 1666672992847,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666672992847,
        "tmdate": 1666672992847,
        "tddate": null,
        "forum": "OTiSSCBm1QD",
        "replyto": "OTiSSCBm1QD",
        "invitation": "ICLR.cc/2023/Conference/Paper711/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The work focuses on the temporal analysis of CNN-based action recognition models. The authors proposed a new computation metric to compare the effective relevance field along the temporal dimension. The paper delves into different aspects such as dataset effects and variations in network backbone architecture, and finally answers some of the questions pertaining to action models for video understanding.",
            "strength_and_weaknesses": "**Strengths**\n\n- The authors have answered some unexplored questions about the temporal understanding of video action models. The analysis shows that backbone depth doesn\u2019t have a significant impact, and that accuracy and avg ATR are inversely related most of the time. \n\n- Experiment with Input frames shows an increasing number of frames doesn\u2019t directly translate to learning information from more frames.\n\n**Weakness**\n\n-  The extension of CLRP is not clear. In the original work [1], Section 4, the authors discussed the concept of two ways to model non-target class. CLRP2 equation looks exactly the same as mentioned in the proposed extension approach (Section 3.1). It appears that the original CLRP work is used as it is.\n\n- Temporal relevance Computation - Section 3.2 - The equation looks like only LRP is used for the ATR metric. Is it LRP or the CLRP?\n\n- Analysis:\n\n  - Selection of 3D CNN architecture - There could be a comparison table of performance with runtime and trainable parameters between a few architectures to justify the selection of I3D. There are several popular architecture which could have been used such as R3D and R21D are very popular architectures.\n\n  - Datasets: Difference in Batch size Training  - Why K400 and SSv2 are trained with different batch sizes 1028 vs 128? Won\u2019t that impact the numbers shown in Table 1? \n\n  - Temporal Module - In Fig. 4, do different architectures have a different number of frames as input while training? If so, isn\u2019t it unfair as in Figure 3, the number of frames matters, and the comparison is across different backbones here.\n  \n  - Fig. 5 - Missing values for R-152 backbones for I3D-f32 and TAM2D-f32.\n  \n  - Table 2 needs to be more detailed. It does not convey the whole story. What happens on the Kinetics dataset or a single dataset (like SSv2 in this case) different architecture?\n\n- Learning of Action Model - 3rd point - Can the authors clarify what do they mean by \u201cretrained a few 16-frame models\u201d? Don\u2019t the models train already on the K400 and SSv2 datasets?\n\n- From all the analysis, could there be a recommendation to get the best performance out of the CNN-based temporal action model for both 3D and 2D?\n\n**References:**\n\n[1] Gu, Jindong et al. \u201cUnderstanding Individual Decisions of CNNs via Contrastive Backpropagation.\u201d ACCV (2018).\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is poorly written. It needs more work to get the final version. There\u2019s confusion in presentations sometimes about architecture and plots. The subsections of analysis (network depth impact of a number of frames, different datasets) are not new directions, but, since it has never been looked at from this point of view, some sub-sections have surprising conclusions.\n",
            "summary_of_the_review": "The extension of the metric already exists. Some of the experiment settings don\u2019t look convincing to make the conclusion on those aspects. The paper still needs more work for certain sub-sections to have a conclusion on that analysis.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper711/Reviewer_6sPt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper711/Reviewer_6sPt"
        ]
    },
    {
        "id": "GaPUOtxPXT4",
        "original": null,
        "number": 3,
        "cdate": 1666689610161,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666689610161,
        "tmdate": 1666689610161,
        "tddate": null,
        "forum": "OTiSSCBm1QD",
        "replyto": "OTiSSCBm1QD",
        "invitation": "ICLR.cc/2023/Conference/Paper711/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a method to quantify the temporal relationships between frames to effectively analyze temporal relevance for video action models. And then, comprehensive experiments present the effects of various factors on temporal modeling. Finally, based on experimental analysis, this paper answers some important questions related to temporal modeling for action recognition.",
            "strength_and_weaknesses": "Strengths\n1. This is the first work that investigates the effective temporal receptive field, i.e., action temporal relevance (ATR), in action models.\n2. This work well extends layer-wise relevance propagation (LRP) and contrastive layer-wise relevance propagation (CLRP) for quantifying the temporal relationships between frames for action recognition.\n3. This work implements elaborate experiments to present the effects of various factors on temporal modeling and answer some important questions related to temporal modeling for action recognition. Some findings seem surprising compared to our intuition.\n\nWeaknesses\n1. The method proposed in this paper is based on existing methods, LRP and CLRP. The innovativeness in terms of methods is relatively weak.\n2. Although this paper claims to focus on CNN-based methods, it is better to analysis the Transformer-based or pre-trained visual models. I wonder if it is able to apply the proposed techniques on the Transformer-based or Pre-trained models ?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written. Also, the paper proposed approach seems to be novel and useful. Considering the detailed description of the method, the quality and reproducibility of this paper are good.",
            "summary_of_the_review": "This work well extends existing methods for quantifying the temporal relationships between frames for action recognition. Comprehensive experiments are conducted to support the effectiveness of the proposed method. However, the innovation and generalization of the method need further consideration.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper711/Reviewer_GyKL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper711/Reviewer_GyKL"
        ]
    }
]