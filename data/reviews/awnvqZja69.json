[
    {
        "id": "Ew6PM-Q20RC",
        "original": null,
        "number": 1,
        "cdate": 1666568414027,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666568414027,
        "tmdate": 1668795966188,
        "tddate": null,
        "forum": "awnvqZja69",
        "replyto": "awnvqZja69",
        "invitation": "ICLR.cc/2023/Conference/Paper210/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a different formulation for vision tasks, i.e. considering image as a set of unorganized points instead of organized rectangular shape or patches sequence. Each point has raw feature and positional information and they are grouped with clustering algorithm. It shows comparable or sometimes better result as CNN or transformer. The code is also released. ",
            "strength_and_weaknesses": "Strength:\n+ The idea is very interesting and this new architecture could be an alternative architecture for CNN, ViT. It provides a new perspective on how the information of an image is represented.\n+ The idea should be of great interest for the representation learning and computer vision community.\n+ The computation is a hard problem if using clustering on 224x224 image, while the authors use a smart way to address it, similar to Swin Transformer. \n+ The performance is impressive as compared with recent popular architectures.\n+ The propose method also generalizes well on downstream tasks like object detection and segmentation.\n+ The paper is well organized and the writing is good.\n\nWeakness:\n- The paper claims to bridge the gap between representation of image and point cloud. It seems to work well on PointNet. But it is kind of hard to understand. The authors use fixed centers (Fig.5) to save computation, how does this work if the discrete pixels are sparsely sampled from one image? It might be helpful if the authors can provide more explanation about this. It would also be interesting to see the performance of dynamic centers? For example, maybe use only 2 iteration for center updates?\n- The proposed method may have good interpretation ability, but not better than CNN or ViT. The figure 4 might need more explanation since the framework is very different from other architectures. The method seems to cluster similar contexts in early stage, but it is not easy for reader to get this insight from figure 4. ",
            "clarity,_quality,_novelty_and_reproducibility": "This paper proposes a interesting idea and the architecture is novel for representation of image. The writing is good with high-quality figures and tables. The code is provided for reproducibility.",
            "summary_of_the_review": "To summary, I think this paper is very interesting and should be discussed at the main conference. It might be a good alternative architecture for vision tasks. The results are impressive and well-presented. I recommend acceptance.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper210/Reviewer_1Gqf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper210/Reviewer_1Gqf"
        ]
    },
    {
        "id": "VjyZVxIM58",
        "original": null,
        "number": 2,
        "cdate": 1666629939756,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666629939756,
        "tmdate": 1666629939756,
        "tddate": null,
        "forum": "awnvqZja69",
        "replyto": "awnvqZja69",
        "invitation": "ICLR.cc/2023/Conference/Paper210/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors present an alternative approach to image content representation called context clusters. These are compared as alternatives to convolutional networks and vision transformer approaches. \n\nThe work is well presented and well written. They argue for their approach in a scientific manner and set it in place for future use in other vision techniques and applications. ",
            "strength_and_weaknesses": "The paper is well written (although requires an editorial read)  and the experiments provided are detailed. \n\nThe methodology could be more clearly presented though. It should be immediately understandable but the reader has to re-read to follow properly. As a case, I would like to be explicitly told how the context clusters are believed to capture the content better. \n\nThe citations are incorrectly used throughout. \nThe use of italics and bold in paragraphs seems unprofessional and I would prefer it not used. \n\nWhy are some figures bold in Table 1? It is not clear what this means.\n\nThe authors state \"See appendix for more experiments.\" It would read well if a short explanation of what is in the appendix is provided here.  ",
            "clarity,_quality,_novelty_and_reproducibility": "The data and code are cited - so the work is technically reproducible but would not be immediately straightforward I guess? \n\nThe clarity of the methodology could be improved for ease of following. ",
            "summary_of_the_review": "I enjoyed this paper. The authors write with enthusiasm and back up their claim that context clusters are worth further investigation through scientific means. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper210/Reviewer_QuSd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper210/Reviewer_QuSd"
        ]
    },
    {
        "id": "42tbo1k57D",
        "original": null,
        "number": 3,
        "cdate": 1666668668679,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666668668679,
        "tmdate": 1670365903235,
        "tddate": null,
        "forum": "awnvqZja69",
        "replyto": "awnvqZja69",
        "invitation": "ICLR.cc/2023/Conference/Paper210/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new view of images that considers each image as a set of points (the pixels) and uses a clustering algorithm to extract the features from it. The goal is to investigate the way to utilize this new form of visual representations and evaluation the performance that could be achieved. To this end, the paper introduces a novel backbone network that includes the proposed Context Clusters and evaluation this model on several vision tasks as well as a point cloud data application.",
            "strength_and_weaknesses": "Strengths:\n\n- To the best of the reviewer\u2019s knowledge, the topic of considering an image as a set of points and extracting features from it for vision tasks is original and very interesting.\n- The proposed method that uses the clustering algorithm as the basic build block is novel and of significance to the community.\n- The evaluation plan of the paper is comprehensive. It provides experiments on standard vision tasks like image classification and object detection/segmentation and applications for point cloud inputs like object classification.\n- The evaluation results show that the method provides improvements on various tasks over the CNN and ViT baselines  (though not outperforming the state-of-the-art approach).\n\nWeaknesses:\n\n- By using the region partition mechanism, the set of points is no longer unorganized but becomes structured based on their locality. Additional experiments are required to clarify the role of the region partition.\n    - Before applying the context clusters operation, the region partition operation, which is similar to the shifting windows in Swin [1], is introduced to reduce the computational cost. The authors seem to imply that the region partition trades off performance for speed. However, the locality introduced by the region partition could also bring useful inductive bias for the encoder. Therefore, additional experiments are required to answer the following questions:\n        1. If the region partition operation is removed in the clustering process, could the model achieve similar or better performance? What would the clustering map be like in this case?\n        2. It would be nice to introduce Swin as one baseline to investigate this problem.\n\n[1] Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Lin, S., & Guo, B. (2021). Swin Transformer: Hierarchical Vision Transformer using Shifted Windows. *arXiv*. https://doi.org/10.48550/arXiv.2103.14030",
            "clarity,_quality,_novelty_and_reproducibility": "- The paper is well-written and easy to follow. The authors also provide additional explanations of some model designs in the appendix which are much appreciated.\n- Both the topic and the proposed method are both original.\n- The general architecture is reproducible based on the model description, additional hyper-parameters are required to reproduce the experimental results.",
            "summary_of_the_review": "This paper introduces a new form of image representation that considers each image as a set of points and proposes a clustering-based architecture for feature extraction. Both the idea of \u201cimage as set of points\u201d and the proposed architecture are interesting and novel. The experiment result also shows that the method achieves comparable performance to ConvNets and ViTs. A small concern is that the role of the region partition mechanism is unclear since good performance could actually be attributed to this design.\n\n---\n\n## Post-rebuttal updates:\nI appreciate the detailed feedback and the extra experiments. It is very interesting to see that: \n\n1. Removing the partition operation actually improves the performance. This demonstrates the efficiency of the original design.\n2. The clustering behavior reveals superpixel-based grouping. This is anticipated, but demonstrating that it is actually working in this way in the paper is much appreciated.\n3. Slightly worse than Swin in performance. The answers to my questions and the performance difference are also acceptable for a novel model design.\n\nSince most of my concerns have been addressed, I decided to raise the score to 8. This is a good paper and worth acceptance",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper210/Reviewer_Mp7d"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper210/Reviewer_Mp7d"
        ]
    },
    {
        "id": "RPD2fsBpcB",
        "original": null,
        "number": 4,
        "cdate": 1666734437759,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666734437759,
        "tmdate": 1666762450693,
        "tddate": null,
        "forum": "awnvqZja69",
        "replyto": "awnvqZja69",
        "invitation": "ICLR.cc/2023/Conference/Paper210/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This is a pioneering work considering SuperPixel-like idea and point cloud modeling for 2D general visual backbone.\nThe main contributions are:\n- Proposing a model called CoC to explore the possibility of point-cloud-clustering modeling for 2D image processing, and initially verifiing its effectiveness.\n- Providing fresh insights into the design of general vision model, which are not only well suited to cope with dense prediction tasks (detection and segmentation), but also facilitate the combination with 3D point cloud data in order to promise a very general cross-modal vision model.",
            "strength_and_weaknesses": "**[strength]**\n\n- This is a very insightful work towards general visual backbone design. The fusion of SuperPixel idea as well as PointNet structure is natural and elegant. I believe this work reveals the potential of point cloud modeling for 2D image processing, which is certainly a great contribution to the community and is worth exploring.\n- I would say that CoC is modeled in a way that fits well with the nature of visual signal processing, as it has the inductive biases that are as useful as those of convolutional networks (such as locality and multi-scale).\n- The interpretability is also as good as convolution (CoC embodies spatial selectivity, while convolution exemplifies the idea of pattern matching). Besides, CoC acts like the deformable convolution and is clearly more flexible and general than ordinary convolution that operates on regular grids.\n\n\n**[weakness]**\n- **Potential representation weakness**. As an architecture similar to ConvNet and PointNet, CoC could be significantly weaker than Transformers in terms of global modeling capabilities (e.g., interacting two spatially distant objects). What are the authors' insights on this problem?\n- **Related work**. I find the first paragraph in Related Work is way more relevant to CoC than the latter two. It would be much appreciated if the authors could devote more space to the first paragraph, e.g., introduce [R1,R2,R3,R4] in more detail and discuss them with this paper in terms of method philosophy.\n- **Figure clarity**. I recommend using more contrasting colors when visualizing. Currently these two figures (Fig. 4 and 6) do not illustrate the clustering effect of CoC models very well.\n- **Font formats**. The spacing between characters in the headings is too small, making them look cramped. Also, there seems to be too much use of bolding or italics in the body text. I would suggest using a more concise format.\n\n------------\n\n**[open questions]**\n\nI have more questions as follows and would like to discuss them further with the authors:\n\n- From Fig. 5(b), the CoC block has similarities with DAT [R5]. Can the authors further analyze or compare them?\n- I don't think it's necessarily a disadvantage that the methods [R3, R4] can only be used for specific tasks like segmentation; in other words, a point-based (or SuperPixel-based) modeling might be inherently more useful for dense prediction tasks (detection, segmentation, etc.) than classification. The authors mentioned that they expected to see more work that seamlessly integrates CoC and DETR in the future. This is reasonable, but I still expect the authors to come up with some prototypes of CoC for dense prediction :).\n\n----------\n[R1] Varun Jampani, Deqing Sun, Ming-Yu Liu, Ming-Hsuan Yang, and Jan Kautz. Superpixel sampling networks. In ECCV, 2018.\n\n[R2] Zixuan Huang and Yin Li. Interpretable and accurate fine-grained recognition via region grouping. In CVPR, 2020.\n\n[R3] Fengting Yang, Qian Sun, Hailin Jin, and Zihan Zhou. Superpixel segmentation with fully convolutional networks. In CVPR, 2020.\n\n[R4] Qihang Yu, Huiyu Wang, Dahun Kim, Siyuan Qiao, Maxwell Collins, Yukun Zhu, Hartwig Adam, Alan Yuille, and Liang-Chieh Chen. Cmt-deeplab: Clustering mask transformers for panoptic segmentation. In CVPR, 2022a.\n\n[R5] Xia, Zhuofan, et al. Vision transformer with deformable attention. In CVPR, 2022.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very clearly written and of high quality. The authors are very thorough in providing reproduction details (source code, model checkpoints, etc.).\nI think the paper is highly innovative. Its idea of point cloud modeling on 2D images to instantiate generic vision models is groundbreaking. It has a high future value for our field moreover. See \"contribution\" and \"strength\" parts above.",
            "summary_of_the_review": "This work is innovative, insightful, written with ample detail, and highly reproducible.\nI believe it deserves to be published and discussed in ICLR.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper210/Reviewer_cH7t"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper210/Reviewer_cH7t"
        ]
    }
]