[
    {
        "id": "vd66q4hBeH",
        "original": null,
        "number": 1,
        "cdate": 1666171956449,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666171956449,
        "tmdate": 1666171956449,
        "tddate": null,
        "forum": "ejQVau3Z-QQ",
        "replyto": "ejQVau3Z-QQ",
        "invitation": "ICLR.cc/2023/Conference/Paper265/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper presents and extension of the HFGI method for GAN-Inversion, named WaGI. The author propose to replace the StyleGAN generator with a SWAGAN generator, and apply Wavelet loss on the HFGI ADA's module. In addition, they propose a Wavelet fusion method to fuse the into the latent \\w. The authors suggest that previous methods fail to preserve high-frequency details where their method   succeed. The authors prove that the widely used loss term in GAN inversions is biased.  ",
            "strength_and_weaknesses": "## Strength\nThe paper is a natural extension of the HFGI and SWAGAN papers. The authors addressed critical points, in the continuations of the ideas presented in the mentioned papers to extended the HFGI method. \nIn qualitative evaluation the method show better results on the inversion task, especially on text, which is usually a high frequency signal. In addition, it seems like this method is better than HFGI for editing tasks (visually).\n\n## Weaknesses\nThe authors suggest wavelet losses for high-frequency details reconstructions. Another option to try is to use the HFGI method while adding additional latent layers. The HFGI method fuses only the earlier layer of G_0 and therefore is unlikely that high-frequency features will be preserved.\n\nThe authors did not show ablation study on which of the G_0 layers they use for fusion.\n\nThe authors write in the abstract that they proved the loss used for others models is biased to the low frequency features. First, the analysis show the loss is unbiased. Second, I'm not sure if the empirical evidence they provide in order to show the loss is indeed biased in practice, is sufficiently convincing. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written in a clear and easy to follow fashion. The authors claim that they will provide code and models for the public community. The paper is an incremental work combining ideas from two previous papers, namely, SWAGAN and HFGI, yet the implementation is not trivial and the results look good.",
            "summary_of_the_review": "I support the acceptance of the paper due to the importance to the community, the nice implementation details and nice results.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "no ethics concerns ",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper265/Reviewer_Xb3x"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper265/Reviewer_Xb3x"
        ]
    },
    {
        "id": "Q34THF6INc",
        "original": null,
        "number": 2,
        "cdate": 1666531043731,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666531043731,
        "tmdate": 1666531070013,
        "tddate": null,
        "forum": "ejQVau3Z-QQ",
        "replyto": "ejQVau3Z-QQ",
        "invitation": "ICLR.cc/2023/Conference/Paper265/-/Official_Review",
        "content": {
            "confidence": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.",
            "summary_of_the_paper": "This paper find that the normally used L2 loss is biased on low-frequency by using the wavelet transform. Thus this paper proposed the wavelet-based GAN inversion model to effectively lowers distortions on both the low-frequency and high-frequency sub-bands.",
            "strength_and_weaknesses": "Strength:\n1. The performance of this paper is impressive.\n2. This paper is well written.\n\nWeakness:\n1. In table 4, the performance of WaGI is 0.011(L2). In table 6, why the best performance is only 0.015 for model already adding Wavelet fusion?\n2. Artifact problem.  In Figure 6, we can see that even though the proposed method obtain sharper edge, there exists noticeable artifact in the edge part. The artifact looks like ghosting artifact around edgy. Such phenomenon can be also find in Figure 5. I think this artifact is caused by the proposed method. I suggest authors add more discussion about this part.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well written. The method seems have high novelty.",
            "summary_of_the_review": "My major considersion is the ghosting artifact caused by the proposed method.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper265/Reviewer_pcW6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper265/Reviewer_pcW6"
        ]
    },
    {
        "id": "BSENEpf6Bo_",
        "original": null,
        "number": 3,
        "cdate": 1666579875065,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666579875065,
        "tmdate": 1666579875065,
        "tddate": null,
        "forum": "ejQVau3Z-QQ",
        "replyto": "ejQVau3Z-QQ",
        "invitation": "ICLR.cc/2023/Conference/Paper265/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work aims to solve the inherent limitations in both structural and training aspects in the existing GAN inversion, which preclude the reconstruction of high-frequency features. They show that L2 loss in GAN inversion is biased to reconstruct low-frequency features. To overcome this problem, they introduce WaGI which enables to handle high-frequency features by using a wavelet-based loss term and a wavelet fusion scheme.",
            "strength_and_weaknesses": "Strength:\nThe overall idea is quite clear and easy to follow, the inversion results are impressive.\n\nWeaknesses:\n\n1. The main concern is the generalization ability of this method for different GAN models. The designed module of Wavelet loss and Wavelet fusion rely on 'SWAGAN: A Style-based WAvelet-driven Generative Model'. I cannot see how the method can be applied to general GAN models, which will severely constrain the application of this method. This constraint also makes the contribution & impact of this work to be weak.\n\n2. Some findings claimed in this work is not new, and actually well-known and explored, e.g., image L2 loss is biased to low-frequency, similar claim is also delivered in 'A Wavelet-Based Generation Network for Image Inpainting'.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity, Quality and Reproducibility of this work is ok.\nNovelty is not strong enough.",
            "summary_of_the_review": "As mentioned above, the generalization ability of this method is the main concern. Some findings are also not new.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper265/Reviewer_ruHv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper265/Reviewer_ruHv"
        ]
    },
    {
        "id": "YR38c67Ow60",
        "original": null,
        "number": 4,
        "cdate": 1666604430737,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666604430737,
        "tmdate": 1666604430737,
        "tddate": null,
        "forum": "ejQVau3Z-QQ",
        "replyto": "ejQVau3Z-QQ",
        "invitation": "ICLR.cc/2023/Conference/Paper265/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper focuses on the problem that existing GAN inversion models fail to maintain high-frequency features precisely. In this paper, the authors prove that the widely used L2 loss term is biased towards the low-frequency components. To solve this problem, the authors attempt to interpret GAN inversion in the frequency domain and propose a method, WaGI, that contains a new wavelet loss and a wavelet fusion module. The proposed method is proved to be the SOTA GAN inversion model.",
            "strength_and_weaknesses": "Strength:\n1. This paper notices an important problem of the existing GAN inversion models that L2 loss is biased to reconstruct low-frequency features.\n2. The motivation of each module in the proposed WaGI is reasonable and well explained. \n\nWeakness:\n1. The Theorem 1 proves that the L2 loss seems a fair loss without frequency bias, but then the authors also claim that they empirically find the existence of this frequency bias. What is the possible reason that causes the controversy between the theorem and the empirically findings? \n2. The authors claim that the wavelet fusion module can transfer high-frequency knowledge without degradation due to the hierarchical upsampling structure of SWAGAN. Does this mean that the wavelet fusion module is specialized to SWAGAN as generator, and the wavelet fusion module cannot be adapted to the generator without a hierarchical upsampling structure? I am really curious about the performance of using other models as generator.\n3. It's better to provide figures or some simple experimental results as evidences to support the claim in page 5 that \"a substantial amount of image details are placed below f_{nyq/2}\".\n4. It seems like the ground truth images in Figures 5 and 10 are actually the input images. Please check these figures again.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written. The overall quality is good, and the method is somewhat new. The reproducibility is ensured by the code that well be released after the review.",
            "summary_of_the_review": "Generally, this paper notices an important obstacle of the existing methods for the GAN inversion task and proposes a method to solve this problem. However, conditioned upon the issues mentioned in [Weakness], I would give a score 6 for now.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper265/Reviewer_FJXP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper265/Reviewer_FJXP"
        ]
    }
]