[
    {
        "id": "dj91AnhLCAJ",
        "original": null,
        "number": 1,
        "cdate": 1666533176271,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666533176271,
        "tmdate": 1666533176271,
        "tddate": null,
        "forum": "DQou0RiwkR0",
        "replyto": "DQou0RiwkR0",
        "invitation": "ICLR.cc/2023/Conference/Paper1144/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces a new deep-learning-based method for multichannel speech enhancement.\nThe proposed method so called AFnet uses a W-net 2D architecture which considers as the input a multi-channel time-frequency representation and  which predict both the alignment mask and the filtering mask which minimize the reconstruction error.",
            "strength_and_weaknesses": "Strength:\n-well written paper\n-reproducible results (code and dataset)\n-technically correct\n-Convincing results\n\n\nWeaknesses\n-Not very original method",
            "clarity,_quality,_novelty_and_reproducibility": "This work is similar to previous work (2 of the 3 refs. are not cited in the current paper) and it corresponds to a slight modifications of the Yoyama et al, 2020 paper.\n\n-KOYAMA, Yuichiro et RAJ, Bhiksha. Exploring Optimal DNN Architecture for End-to-End Beamformers Based on Time-frequency References. arXiv preprint arXiv:2005.12683, 2020.\n-KIM, Hansol, KANG, Kyeongmuk, et SHIN, Jong Won. Factorized MVDR Deep Beamforming for Multi-Channel Speech Enhancement. IEEE Signal Processing Letters, 2022, vol. 29, p. 1898-1902.\n-KOYAMA, Yuichiro et RAJ, Bhiksha. Exploring Optimal DNN Architecture for End-to-End Beamformers Based on Time-frequency References. arXiv preprint arXiv:2005.12683, 2020.\n\n Despite the better results in comparison to the state of the art, the authors should further justify their changes in the proposed method architecture through a theoretical study, ablation study, etc.\n\nTo my opinion, this is the main weakness of this paper.\n\n",
            "summary_of_the_review": "This is a well-written paper with reproducible results and a suitable evaluation methodology with freely available codes and dataset.\n\nHowever, the proposed work is only an incremental contribution of a previously published work from Yoyama et al, 2020.\n\nThe authors could provide more arguments to explain in what their contribution is significant in comparison to the state of the art from a  theoretical point of view.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "n/a",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1144/Reviewer_6rDM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1144/Reviewer_6rDM"
        ]
    },
    {
        "id": "GnKthloFkj",
        "original": null,
        "number": 2,
        "cdate": 1666595411305,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666595411305,
        "tmdate": 1669870145389,
        "tddate": null,
        "forum": "DQou0RiwkR0",
        "replyto": "DQou0RiwkR0",
        "invitation": "ICLR.cc/2023/Conference/Paper1144/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper presents an align-and-filter structure for neural network-based multi-channel speech enhancement.\nThe paper claims that the proposed decomposition of a filter into an element-wise product of alignment gain and a filtering gain is critical for an improved performance. Furthermore, it is claimed that training with an RTF loss is critical for the success of the proposed method.",
            "strength_and_weaknesses": "I think the basic idea is sensible and relevant: adding the RTF-based loss to improve construction of a multi-channel filter. The presented results indicate that this has a considerable effect on the proposed method.\n\nSome weaknesses which should be addressed\n- \"To the best of our knowledge, the only work that incorporates RTFs for SE is by Wang & Wang (2018), in which, however, the RTF estimation is used as an intermediate step to assist the conventional MVDR beamformer only.\" -- Many DNN-based speech enhancement papers estimate RTFs for speech enhancement. For example, \"ADL-MVDR: All deep learning MVDR beamformer for target speech separation\" is a relatively recent example which estimates a steering vector, which is an RTF. It is true that, in this instance, the vector is used to estimate the filter.\n- Furthermore, very relevant work is the following paper: The PCG-AIID System for L3DAS22 Challenge (https://arxiv.org/abs/2202.10017). The system used there is using a structure very similar to the one used here (W-like, multichannel intermediate output and single-channel final output).\n- I think it should be clarified that the AlignNet is not doing only temporal alignment, but also level adjustment. Even more critical, the results from B.1 should be included in the main text. One of the main questions for me was if the magnitude equalization is really important for this work, and I expected the phase to be the important part. B.1 clearly gives the answer: phase adjustment is sufficient. It's therefore not clear why is this not included in the main text.\n- The above brings another questions. If phase alignment is enough, would it be suffice to have a phase alignment loss only for the final output mask, without using the intermediate mask? I would assume that this would be sufficient, and that having alignment in the middle of the W structure is not necessarily critical. However, it would be good to get clarification from the authors, and to understand if the two-stage structure is critical (or it's suffice to have a skip connection and a combined loss at the output).\n- Leaky ReLU is used for real and imaginary components independently. However, the slope is not defined anywhere in the paper. This is interesting, since it may mean the complex gain values are relatively strongly pushed to be in the first quadrant, which is not very intuitive.\n- Table 1 -- These results indicate that the proposed FilterNet fails on the original unaligned signals. Operating on aligned signals is expected to perform better, but FilterNet on unaligned signals fails completely. This is quite surprising, since multi-channel systems proposed in other papers work well without the two-stage process (align+filter). I'm curious if this failure could be related to the choice of nonlinearity (above).\n- Section 4.2.2 / Table 2 -- It would be interesting to connect these results to Table 1, e.g., what's the gap of the AFnet compared to perfectly adjusted signals from Table 1.\n- Some typos, e.g., \"Nerual BF\"\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is relatively well written, with some typos and inconsistencies.\nThe novelty is relatively small, but sufficient and relevant.\nAppendix has several relevant results, which should be included in the main text.\nComponents of the datasets are publicly available. However, training details seem to be omitted, and it may be relatively difficult to reproduce the exact results without the access to the code for data preparation.",
            "summary_of_the_review": "The paper claims that the proposed two-stage network with an RTF-based loss is a better alternative to single-stage multi-channel processing systems. Experimental results are promising.\nHowever, there are several open questions which need to be addressed before publishing the paper.\n\n---\n\nThe authors addresses most of my comments in their responses, and I've updated the score to 6.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1144/Reviewer_jGjP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1144/Reviewer_jGjP"
        ]
    },
    {
        "id": "G97zEffnY1",
        "original": null,
        "number": 3,
        "cdate": 1666599747275,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666599747275,
        "tmdate": 1666599747275,
        "tddate": null,
        "forum": "DQou0RiwkR0",
        "replyto": "DQou0RiwkR0",
        "invitation": "ICLR.cc/2023/Conference/Paper1144/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work proposes an autoencoder based multi-channel speech enhancement framework. Overall the work is applied and mostly empirical in nature. The proposed framework is based on existing well-established ideas from empirical deep learning. There are no theoretical insights and the contribution in terms of the combination of existing ideas is relatively marginal.",
            "strength_and_weaknesses": "The Paper is very hard to read, where I found lots of details, equations, symbols being intermingled within inline text.\n\n- I couldn't find the motivation behind the proposed framework. Why the choices are made, how they impact the learning process, and what extra they provide over existing studies.\n- This is another classical example of an empirical deep-learning paper where authors have tried to combine various existing ideas without any theoretical backing.\n- The link between speech production/perception as well as multichannel setting with the choices made is clearly missing.\n\n- Authors mentioned that their work is [Inspired by the alignment concept in signal processing]. What is this alignment process? no reference is provided, neither any discussion on why this is important.\n- The alignment and filter network are very similar. Why not just train a single big network with the same capacity?\n  In experiments, authors have shown results with individual networks empirically, but it is unclear if the model capacity is similar or not.\n-  ILD and ITD correspondence to the magnitude and phase spectra is exploited using a complex neural network. \nWhile working in complex STFT domain using conventional methods is well understood, the same is not the case with DNNs. In-fact their are a many works which have shown that the same task can be performed entirely in time domain by using learned filterbanks modelling raw waveform directly in an end-to-end fashion.\nComplex networks are very difficult to optimize in general, especially for speech/audio tasks.\n- Authors are suggested to avoid MSE loss as existing works have highlighted the drawbacks and shown better performance by using STOI or its variants for enhancement tasks. \n- I fail to understand the rationale behind split training. Why not joint training right from scratch? May be some visualization based on the loss landscape of the overall model (in complex and real settings) and what the network is learning in terms of filter responses/saliency maps or geometric properties of network weights is highly encouraged for explainability.\n\n\nExperiments: \n- lots of details are missing, which makes it very hard to reproduce the experiments\n- given the empirical nature of the paper, Authors should submit the code and pre-trained models.\n- details about existing works with which comparison is made are missing. Why these were chosen? I only see FaSNet closely related to this work.",
            "clarity,_quality,_novelty_and_reproducibility": "Not novel enough or at par with the standards of ICLR.",
            "summary_of_the_review": "While the problem addressed is interesting, the proposed ideas are just incremental and not novel enough for the ICLR main conference.\nAuthors are recommended to resubmit to a suitable workshop, but the question about the theoretical contribution is the main weakness of the paper.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1144/Reviewer_aM96"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1144/Reviewer_aM96"
        ]
    },
    {
        "id": "SLwFfsw4-4",
        "original": null,
        "number": 4,
        "cdate": 1667501479746,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667501479746,
        "tmdate": 1667501479746,
        "tddate": null,
        "forum": "DQou0RiwkR0",
        "replyto": "DQou0RiwkR0",
        "invitation": "ICLR.cc/2023/Conference/Paper1144/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper introduces a two-stage model for multi-channel speech enhancement. The first stage predicts STFT domain filters for each microphone that will take them close to a reference microphone's clean signal, by estimating time-varying RTFs. This is called an alignment estimator. The second stage predicts further filters for each channel and filtered channels are summed up to obtain the estimated signal which needs to be close the target signal for the reference microphone. This second step can be seen as a typical deep beamforming network.\n\nThe model for each stage is a W-net model which is like a U-net model but uses complex matrix multiplications and convolutions.",
            "strength_and_weaknesses": "Strengths:\n1. The idea seems novel.\n2. It seems the two-stage model could work well by dividing the beamformer calculation into two separate stages and having individual targets (RTFs) for filters of the first stage.\n3. It is nice that the method seems to be able to handle time-varying environments, but it has not been tested on such environments.\n\nWeaknesses:\n1. The experimentation is only on simulated data. Would the method work well for real data?\n2. Comparison with another sequential multichannel method [Wang 2021] would have been nice. In this method, a beamformed signal based on an initial neural estimate is fed into a second stage (and even more stages) which refines the neural network output, hence the model makes use of spatial information implicitly.\n3. The burden on the second stage is still high since it still needs to do some spectral denoising as well as spatial denoising.\n4. The training uses a single room configuration which is limited. Does it generalize to unseen rooms?\n5. U-net seems better than W-net itself (for mics > 2) in Figure 2. What if we used U-nets in AFNet instead of W-nets? It has been observed that using complex weights in a network is usually not beneficial, and it is better to use real valued weights within the neural network.\n\n[Wang 2021] Wang, Zhong-Qiu, et al. \"Sequential multi-frame neural beamforming for speech separation and enhancement.\" 2021 IEEE Spoken Language Technology Workshop (SLT). IEEE, 2021.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper seems novel in its approach. It also reads well and seems reproducible.",
            "summary_of_the_review": "The paper is nice and innovative but it has some flaws in experimentation as listed in the weaknesses above.\n\nSome specific issues are highlighted below:\n\n1. In Figure 1, one of the align filters are always all ones (the one corresponding to the reference mic) and does not need to be estimated. It should be noted.\n2. In Section 3, the discussion assumes a time-varying single frame STFT domain filtering to describe room impulse response filtering. However, typically RIRs are much longer than a single frame and we may assume they are time-invariant if there is no motion.\n3.  Instead of SSNR, maybe report SI-SNR which is more commonly used. If using SSNR, maybe mention the segment length.\n4. In Section 4.2.3, it seems obvious that alignment masks would give more spatially diverse coefficients when there is an RTF loss on them. When there is no such loss, it is not clear what those initial filters mean and how they contribute to overall system.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "There is not any ethics concern.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1144/Reviewer_4Sgp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1144/Reviewer_4Sgp"
        ]
    }
]