[
    {
        "id": "IM7Ba_b2D_",
        "original": null,
        "number": 1,
        "cdate": 1666675241861,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666675241861,
        "tmdate": 1666675241861,
        "tddate": null,
        "forum": "sAOOeI878Ns",
        "replyto": "sAOOeI878Ns",
        "invitation": "ICLR.cc/2023/Conference/Paper5797/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes an unsupervised and parameter-free method that functionally projects transformer models into the space of all tree-structured models. By using this method, they show that transformers for three different tasks become more tree-like over the course of training, in some cases unsupervisedly recovering the same trees as supervised parsers. Finally, they use tree projections as a tool to predict behaviors associated with compositionally, where they find that induced trees reliably reflect contextual dependence structure implemented by encoders and both tree scores as well as parsing F1 of tree projections better correlate with compositional generalization to configurations unseen in training than in-domain accuracy.",
            "strength_and_weaknesses": "Strength\n- The tree projections require no extra training and parameters and can be applied to any transformer-based models to tree-structured models.\n- The experiments on compositional generalization reveal some of the non-obvious facts for transformer models' behavior in predicting compositional structures.\n\nWeaknesses\n- The conclusion found by the tree projections, i.e., transformer learns a compositional, tree-structured computation is actually not a new finding, which can be found in many previous works.\n- The tree projection here is more like a tool for ablation studies. I can not tell how we can use this tree projection to improve downstream tasks such as compositional generalization.",
            "clarity,_quality,_novelty_and_reproducibility": "The conclusion found by the paper is not new/surprising to me. Some previous work has already discussed that neural models (including pre-trained models but not limited to transformers) in natural language processing have the ability to learn linguistic structures, e.g., Shen et al. (2019), Coenen et al. (2019), Hewitt and Manning (2019). The important point is how we can utilize this to help the downstream tasks, and I cannot see so much discussed in this paper.\n\nReference\n[1] Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks. Yikang Shen, Shawn Tan, Alessandro Sordoni and Aaron Courville. ICLR 2019.\n[2] Visualizing and Measuring the Geometry of BERT. Andy Coenen, Emily Reif, Ann Yuan, Been Kim, Adam Pearce, Fernanda Vi\u00e9gas and Martin Wattenberg. Neurips 2019.\n[3] A Structural Probe for Finding Syntax in Word Representations. John Hewitt and Christopher D. Manning. NACCL 2019.",
            "summary_of_the_review": "This paper provides an interesting tree projection to reveal the transformer's ability to learn tree structure during training. However, the conclusion is not very surprising given that some previous work has already discussed similar findings. I agree that compositionally is an important linguistic property in natural language processing, but NLP people care more about how we can utilize compositionally in downstream tasks instead of whether the model can learn compositionally during training. I recommend the author incorporate this tree projection into enhancing the model's generalizability to compositional generalization, e.g., under domain shift or limited training data.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5797/Reviewer_4grv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5797/Reviewer_4grv"
        ]
    },
    {
        "id": "qHxeK2DeJWd",
        "original": null,
        "number": 2,
        "cdate": 1666714416830,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666714416830,
        "tmdate": 1666714416830,
        "tddate": null,
        "forum": "sAOOeI878Ns",
        "replyto": "sAOOeI878Ns",
        "invitation": "ICLR.cc/2023/Conference/Paper5797/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a method to project the \u201cbehavior\u201d of a transformer model into a binary tree. Crucial to this is the concept of contextual invariance: the representation of a tree node does not depend on anything outside its children. Specifically the method approximates a bracketing of the sentence such that nodes in this tree are maximally invariant under this definition. Given contextual and context-free representations of a span within a transformer model, the distance between them is taken to measure the context-invariance of that span. \n\nThe paper goes on to show that tree-like structure is stronger as model train, and that in two of the three data sets used, the trees obtained match a gold syntax. The degree of the tree \"match\" also correlates with compositional properties of the models as measured on test sets for compositional generalization. \n",
            "strength_and_weaknesses": "The main weakness of the paper is its motivation. Specifically:\n\n* The paper starts by explaining that hierarchical structure is necessary for humans to understand novel utterances, and discusses the concept of composionality. It goes on to introduce context-invariance as a crucial ingredient of it: the meaning of an expression does not depend on anything outside the syntactic tree that the expression spans. While the paper mentions notable exceptions to this assumption: multiple word meanings, idioms, etc, it still contrasts compositional interpretation with context-invariance (first paragraph of page 3). I believe that is wrong. It is clear that both play an important role: there is a certain amount of context-invariance required for efficient generalization but language is far from being context-invariant. The two are not at odds with each-other and there is no reason to believe that humans and computational models can\u2019t do both effectively. \n\n* Following this, the paper sets out to measure the context-invariance in the behaviour of transformers. However it\u2019s not clear what questions does the paper aim to answer. Do we want transformers to be context-invariant? No. Do we want transformers to show compositional generalization? Yes, but that should be measured as part of a real-world task, not an artificial task. That is because real world language tasks require both compositional generalization and context-dependence. For example machine translation is a task where models fail to capture context dependence (wrong word meaning, too-literal translations), and it can be argued they show too much compositional generalization.\n\n* These issues continue in the experimental section: the transformer models investigated are trained on small data sets, in some cases using synthetically-generated language and structure-biased tasks such as predicting logical forms. As such the results do not say much about language in general or about real-world language applications.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written. Methods to assess how the amount of syntactic structure in neural models have been proposed in the past, however there are some differences from previous work: this work does not assume any notion of syntax and looks for the braketing that best approximates context-invariance. ",
            "summary_of_the_review": "The paper does not address a clear research question: it proposes a method to find a sentence braketing using transformer representations, such that is maximizes the context-invariance of the representations (the representation of a span depends only on its words and not on outside context). It analyzes this braketing and the degree to which it approximates the transformer representations across three tasks used for compositional generalization. Compositional generalization should not be studied in isolation but in the context of real language tasks that require both generalization and context-awareness. Even if the paper had done this, I do not see the impact of method introduced in the paper or of the results. I also find the terminology used throughout the paper miss-leading (such as \u201ctree-like computation\u201d or \u201ctree-structuredness\u201d), as it contrasts hierarchical structure with context-dependence when it\u2019s clear that both are necessary ingredients for modeling language. \n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5797/Reviewer_7etS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5797/Reviewer_7etS"
        ]
    },
    {
        "id": "RoBjgMiZAM2",
        "original": null,
        "number": 3,
        "cdate": 1666804192926,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666804192926,
        "tmdate": 1666804192926,
        "tddate": null,
        "forum": "sAOOeI878Ns",
        "replyto": "sAOOeI878Ns",
        "invitation": "ICLR.cc/2023/Conference/Paper5797/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors hypothesize that transformers generalize to unseen sentences by implicitly constructing a tree-structured object bottom-up from inputs. They attempt to understand whether the transformer does indeed perform tree-structured computations by approximating them with with a tree. They introduce a novel method to construct tree representations using a procedure that computes distances between contextual and context-free representations of all subsequences in a sentence. \n",
            "strength_and_weaknesses": "+ The paper is well written and was relatively easy for me to understand. \n+ Theorem 1 is helpful in formalizing how the proposed framework projects transformers to the space of tree structured computations\n+ The results appear convincing, with some minor caveats, mentioned below\n\n- I wish the authors would spend more time motivating why this is an interesting problem, and if there are other ways to explain generalization of transformers. Ultimately, the tree computation hypothesis is just one possible explanation for generalization, I'm curious how to know how this work fits into the broader landscape of work\n- I found section 6.2 interesting, can the authors expand on this point? Unless I'm misunderstanding, this is a central motivation for the paper and requires further explanation. \n",
            "clarity,_quality,_novelty_and_reproducibility": "I found the paper clear and well written, the proposed method seems novel and is explained well enough to reproduce.\n",
            "summary_of_the_review": "The paper is well written and clear, I think the ideas presented are novel, specifically how to project transformers to the space of trees. I would recommend accepting.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5797/Reviewer_2Wg3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5797/Reviewer_2Wg3"
        ]
    },
    {
        "id": "fHhime90m5",
        "original": null,
        "number": 4,
        "cdate": 1666898356595,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666898356595,
        "tmdate": 1666898453662,
        "tddate": null,
        "forum": "sAOOeI878Ns",
        "replyto": "sAOOeI878Ns",
        "invitation": "ICLR.cc/2023/Conference/Paper5797/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a method to measure how much compositional-ness a transformer model behaviours. The whole work relies on the hypothesis, that inner composition should be independent from outer context. Relying on that hypothesis, the paper proposes the concept of *span contextual invariance* and how to measure it. That leads to a method searching for a tree that is *closet* to the computation of a transformer performing on an utterance. Then, two ways are introduced to measure tree-structuredness, one with and one without a gold tree. \n\nTheoretically, the paper proves that under a mild condition,  minimizing the span contextual invariance yields exact tree projection. Empirically, the paper demonstrates how the two metrics can help to unveil the compositional-ness of transformers. The paper also presents some analyses, especially one on how tree-structureness is correlated to generalisation.",
            "strength_and_weaknesses": "The paper tackles the challenging problem with a novel and very interesting idea. The paper makes choices reasonably. First of all, instead of topological tree-structuredness, the paper is looking for *functional* one. This is a novel view for how to understand the compositionality behaviour of a model, and easily turns the problem to optimization. Next, the concept of *span contextual invariance* does reflect the principle of compositionality, and is thus well linguistically motivated. I found the implementation for estimating the tree projection is smart and technically sound. Especially, it can employ the power of the parsing method by Stern et al 2017. \n\nI however found T-shape masking and threshold layer quite tricky, and can't find detail implementation in the paper. It is unclear, e.g. in fig 2, where a threshold layer is put when the number of encoder layers is varying from 2 to 6. And in footnote 2, what does it mean by \"tuning the threshold layer\"? \n\nThe flow of the paper can be more logical. Section 5 uses the proposed t_score and t_parseval to measure tree-structuredness. The key question here is: how good can they measure compositionality? Up to that point, the paper doesn't seem to answer that. And thus it's difficult to see how the conclusions raised in section 5 are reliable. The reader has to wait until section 6.1 for \"... induced trees reflect the contextual dependence structure learnt by a transformer.\" \n\nHowever, it still doesn't answer why the proposed t should be more reliable than p_parseval. Right below Fig 3 \"we conclude that supervised probing is unable to discover latent tree structures as effectively as our method.\" Why is it bad to converge too fast here? The paper even doesn't show the *true* tree-structuredness improving rate. \n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "* Clarity: I enjoyed reading the methodology described in the paper. But the experiments and analyses (sec 5 and 6) are quite difficult to follow. Partly because, as mentioned above, I think section 6.1 should be before section 5. \n\n* Quality: The paper should have a significant impact to the community working on analysing compositionality of DL models. However, some arguments (mentioned above) raised in the paper should be carefully examined. \n\n* Originality: The idea and method proposed in the paper is novel and very interesting. ",
            "summary_of_the_review": "I enjoyed reading the paper and recommend to accept it. The paper has high quality, with novel and very interesting ideas. The work is solid, experiments and analyses are quite thoughtful. \n\nThe paper can improved by\n* adding more details about implementation (T-shape and threshold layer) \n* re-flow some experiments / arguments   ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5797/Reviewer_mpue"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5797/Reviewer_mpue"
        ]
    }
]