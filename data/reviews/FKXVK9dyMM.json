[
    {
        "id": "gXDdfAqMuc",
        "original": null,
        "number": 1,
        "cdate": 1666497315108,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666497315108,
        "tmdate": 1666497315108,
        "tddate": null,
        "forum": "FKXVK9dyMM",
        "replyto": "FKXVK9dyMM",
        "invitation": "ICLR.cc/2023/Conference/Paper2153/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a graph contrastive learning paradigm named LightGCL, the singular value decomposition is adopted for contrastive augmentation to achieve the unconstrained structure refinement with global collaborative relation modeling. Experiments on five datasets validate the effectiveness of the proposed LightGCL compared with ten baselines.",
            "strength_and_weaknesses": "Strength:\n(1) The idea of using SVD to to augment user-item interaction graph structures seems interesting to me.\n(2) \u00a0The codes and datasets of this work are provided for reproducibility.\n(3) The experimental results look promising and show relative improvements over baselines.\n\nWeakness:\n(1) The truncated T-SVD to capture the low-rankness of the multi-view augmented graph, which improves the robustness from the perspective of graph preprocessing in \u201cZhebin Wu, Lin Shu, Ziyue Xu, Yaomin Chang, Chuan Chen, Zibin Zheng: Robust Tensor Graph Convolutional Networks via T-SVD based Graph Augmentation. KDD 2022: 2090-2099\u201d. Compared to this work, which also uses SVD-based graph augmentation and improved robustness, what are your highlights?\n(2) This paper focuses on a general SVD-based graph structure learning, more variants based on SVD (eg. RSVD and SVD++, ) should be designed in the ablation study, instead of only a pre-trained MF to replace it.\n(3) In Section 4.2, the authors did not provide statistical significance tests. The improvement ratio of the proposed LightGCL over the optimal baseline is also not stated.\n(4) Figure 1 shows the overall structure of LightGCL, however, lack of overall description for this figure.\n(5) As we all know, the disadvantage of SVD is that the decomposed matrix often lacks interpretation. Has the author considered this problem in recommendation?\n\nSome papers involving graph contrastive learning are missed, such as:\n-  Lu Yu, Shichao Pei, Lizhong Ding, Jun Zhou, Longfei Li, Chuxu Zhang, Xiangliang Zhang: SAIL: Self-Augmented Graph Contrastive Learning. AAAI 2022: 8927-8935.\n-  Yihang Yin, Qingzhong Wang, Siyu Huang, Haoyi Xiong, Xiang Zhang: AutoGCL: Automated Graph Contrastive Learning via Learnable View Generators. AAAI 2022: 8892-8900.\n- Yixin Zhang, Yong Liu, Yonghui Xu, Hao Xiong, Chenyi Lei, Wei He, Lizhen Cui, Chunyan Miao: Enhancing Sequential Recommendation with Graph Contrastive Learning. IJCAI 2022: 2398-2405.\n- Jun Xia, Lirong Wu, Jintao Chen, Bozhen Hu, Stan Z. Li: SimGRACE: A Simple Framework for Graph Contrastive Learning without Data Augmentation. WWW 2022: 1070-1079.\n- Susheel Suresh, Pan Li, Cong Hao, Jennifer Neville: Adversarial Graph Augmentation to Improve Graph Contrastive Learning. NeurIPS 2021: 15920-15933. \n\nThere are some typos to check, such as:\n- \u201cmasked featurte reconstruction\u201d\u2014>\u201cmasked feature reconstruction\u201d (page 2)\n-\u201cNormalized Discounted Culmulative Gain\u201d\u2014>\u201c Normalize Discounted Cumulative Gain\u201d (page 5)\n-\u201cAddtionally\u201d\u2014>\u201c Additionally\u201d (page 7)\n-\u201cwhile the best configuration of \u03c4 value vary by datasets\u201d\u2014>\u201c while the best configuration of \u03c4 value varies by datasets\u201d (page 9)\n-\u201cwe presents a case study\u201d\u2014>\u201c we presents a case study\u201d (page 9) \n-\u201cour graph augmentation scheme exhibit strong ability \u201d\u2014>\u201cour graph augmentation scheme exhibits strong ability\u201d (page 9) ",
            "clarity,_quality,_novelty_and_reproducibility": "Compared with the existing work (Robust Tensor Graph Convolutional Networks via T-SVD based Graph Augmentation. KDD 2022), the highlights should be more prominent. ",
            "summary_of_the_review": "Overall, the idea of using a  SVD-based graph structure learning to achieve graph augmentation in contrastive learning is interesting and efficient. However, compared with the existing work (Robust Tensor Graph Convolutional Networks via T-SVD based Graph Augmentation. KDD 2022), the highlights should be more prominent. Moreover, some important relevant literatures is missing, and more SVD-based ablation studies should be discussed. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2153/Reviewer_k7CA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2153/Reviewer_k7CA"
        ]
    },
    {
        "id": "ztwnHFitOE",
        "original": null,
        "number": 2,
        "cdate": 1666608554392,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666608554392,
        "tmdate": 1666608554392,
        "tddate": null,
        "forum": "FKXVK9dyMM",
        "replyto": "FKXVK9dyMM",
        "invitation": "ICLR.cc/2023/Conference/Paper2153/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This work proposes a novel method for advancing recommender system with a lightweight and effective graph contrastive learning paradigm. The proposed method is technically sound from a novel perspective of efficient SVD-guided graph augmentation. To demonstrate the effectiveness of the new framework, 10 baselines are compared.",
            "strength_and_weaknesses": "Strong points: \n1.The proposed method is well-motivated and technically sound, by addressing key challenges of current GCL-based recommender systems to automatically generate augmented graph view for effectively incorporating self-supervised learning signals.\n2. A lightweight graph augmentation model is built over an efficiency SVD-based graph structure learning framework.\n3.Comprehensive experiments show the superiority of the proposed method over SOTA baselines.\n4. In-depth model evaluation demonstrates the advantage of the LightGCL approach for alleviating data sparsity, over-smoothing issue, and popularity bias.\n\nWeak points:\n1. For the compared SGL baseline method, three different augmentation schemes are introduced, e.g., node/edge dropout operators, as well as random walk-based sampling approach. The details of configuring the augmentation operators in SGL method can be further described.\n2. For the proposed approach, its advantage lies in the automated graph augmentation via distilling important graph structural information using a decomposition-based method. Compared with baseline SHT, the advantage of LightGCL can be further clarified.\n3. The results need further explanation. For instance, why the methods exhibit different trends on Yelp and Gowalla (Fig. 3).",
            "clarity,_quality,_novelty_and_reproducibility": "The major novelty of enhancing graph contrastive learning by preserving important structural information is reasonable and effective. This paper is well-written and easy to follow. The presentation of methodology is very clear. The authors have released the code and models.",
            "summary_of_the_review": "This paper tackles important challenges of graph contrastive learning in recommender systems. I acknowledge the technical novelty and empirical evidence of this work.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N.A.",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2153/Reviewer_rCJG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2153/Reviewer_rCJG"
        ]
    },
    {
        "id": "wA3B2Cf54D7",
        "original": null,
        "number": 3,
        "cdate": 1666611437074,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666611437074,
        "tmdate": 1670116242718,
        "tddate": null,
        "forum": "FKXVK9dyMM",
        "replyto": "FKXVK9dyMM",
        "invitation": "ICLR.cc/2023/Conference/Paper2153/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents a new SVD-based Graph Contrastive Learning paradigm called LightGCL to learn effective representations of nodes in a user-item interaction graph from unlabeled data that are eventually used to predict users' preferences in downstream recommendation tasks. The key idea is  in the augmentation step where an alternate low-rank view of the original graph is generated by applying SVD on the original graph. The embeddings of each node from two graphs are trained to be similar by minimizing Info Noise Contrastive Loss along with the prediction loss on user-item interactions. \n\nThe proposed approach LightGCL is evaluated against SOTA methods from the various paradigms including: MLP-based Collaborative Filtering (CF), GNN-based CF, Disentangled Graph CF,  Hypergraph-based CF, and self-supervised recsys on five real-world datasets on recall@N and NDCG@N. The experiments indicate superior performance of LightGCL over all the above baselines. Additionally. authors demonstrate LightGCL outperforming a couple of baselines (HCCF and SimGCL) on less popular/interacting segments of items and users. ",
            "strength_and_weaknesses": "Strengths:\n1. The idea of using low-rank SVD to produce augmenting view of the original graph looks neat and well-aligned with the intuition of preserving global structure in the original graph. \n\n2. The results indicate significant improvement in recall@k and ndcg@k with respect to all the baselines on all the datasets. Additionally LightGCL is able to produce good performance on sparse users with respect to the two baselines, SimGCL and HCCF. \n\n3. LightGCL is computationally more efficient to train than the above baselines. \n\n\nWeaknesses: \n1. I did not understand why related work is missing several relevant papers from the domain of Graph Contrastive Learning [1-7]. Many of these papers are well-cited and published at top-tier conference. \n2. The methods from above papers are also not included in the comparison study in the evaluation section.  \n3. The experiments on balance between over-smoothing and over-uniformity requires a bit more convincing. Ideally, if authors could demonstrate some alignment between clusters of entities learnt by the Light GCL and the domain-based clusters, that would be even better.  ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is mostly clear and easy to follow. However, I noticed a couple of undefined notations in Eq(8) on page 4: p_s, n_s, S, \\hat{y_{i, p_s}, \\hat{y_{j, n_s}.\n\nQuality and Novelty: The proposed idea of using SVD decomposition could potentially be a good addition to the choice of augmentation methods. However, as I mentioned above, the comparison with several important papers from graph contrastive learning (GCL) literature is missing. Additionally, in one of the recent empirical studies on GCL literature [1], it was observed that the local-local contrastive learning approaches typically outperform local-global contrastive methods. Given that the current paper falls in the latter category, it might be even more insightful to compare Light GCL with local-local contrastive methods.\n\nReproducibility: The results can be reproduced with the help of provided code link.\n\n\nReferences:   \n[1] Zhu, Yanqiao, et al. \"An empirical study of graph contrastive learning.\" arXiv preprint arXiv:2109.01116 (2021). \n\n[2] Velickovic, Petar, et al. \"Deep Graph Infomax.\" ICLR (Poster) 2.3 (2019): 4. \n\n[3] Hassani, Kaveh, and Amir Hosein Khasahmadi. \"Contrastive multi-view representation learning on graphs.\" International Conference on Machine Learning. PMLR, 2020. \n\n[4]  Peng, Zhen, et al. \"Graph representation learning via graphical mutual information maximization.\" Proceedings of The Web Conference 2020. 2020. \n\n[5] You, Yuning, et al. \"Graph contrastive learning with augmentations.\" Advances in Neural Information Processing Systems 33 (2020): 5812-5823. \n\n[6] Zhu, Yanqiao, et al. \"Deep graph contrastive representation learning.\" arXiv preprint arXiv:2006.04131 (2020). \n\n[7] Zhu, Yanqiao, et al. \"Graph contrastive learning with adaptive augmentation.\" Proceedings of the Web Conference 2021. 2021.\n",
            "summary_of_the_review": "The paper presents an interesting approach for generating alternate view of the graph that could be a useful addition to Graph Contrastive Learning literature. The results look impressive overall, however the comparisons with some of the important papers are missing. EDIT: I am satisfied with author's follow-up edits to the paper and they reasonably address most of my comments. In light of the same, I have updated my rating for the paper. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2153/Reviewer_3y1q"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2153/Reviewer_3y1q"
        ]
    },
    {
        "id": "feDuCOS0Wk",
        "original": null,
        "number": 4,
        "cdate": 1667095403351,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667095403351,
        "tmdate": 1667095403351,
        "tddate": null,
        "forum": "FKXVK9dyMM",
        "replyto": "FKXVK9dyMM",
        "invitation": "ICLR.cc/2023/Conference/Paper2153/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper tackles the emerging topic of graph contrastive learning in recommender system, by proposing a lightweight and effective method. Particularly, the augmented view is automatically generated based on singular value decomposition technique, which is interesting and novel to me. With the augmented user-item graph structures, new contrastive self-supervision signals are derived. By doing so, only one additional augmentation view is needed for contrastive learning, further improving the model efficiency as justified in this work. Extensive experiments are conducted on several benchmark datasets to validate the effectiveness and superiority of the new approach.",
            "strength_and_weaknesses": "1.Reasonable and well-motivated methodology design to advance the GCL-based recommender systems from a novel perspective of decomposition-based augmentation.\n2. Sufficient and appropriate state-of-the-art methods (e.g., some recent models SGL, HCCF, SimGCL) are adopted for performance comparison.\n3. Extensive experiments to demonstrate the effectiveness of the newly proposed solution from various aspects, including model robustness against data sparsity and long-tail issue.\n4. Both the superior performance and lower model complexity are achieved by the new method compared with strong state-of-the-arts.\n\nPlease find my comments below:\n\nAlthough the proposed method is simple yet effective from the experimental perspective, the authors are encouraged to discuss the effectiveness from the theoretical perspectives.\n\nBesides, in performance comparison, I notice that different types of methods are considered as baselines, including representative GNN-based CF models (GCCF and LightGCN), and disentangled graph CF approach-DGCF. Additionally, recently proposed SSL-enhanced recommender systems SGL, SHT, HCCF are also included. For those hypergraph-enhanced approaches, the self-supervised information source mainly comes from information aggregation over hyperedges. The settings of hypergraph structures in those methods can be further described, which may be helpful to understand the effectiveness of SSL-based graph augmentation.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This work has already released source code and data for experimental result reproducibility. Generally speaking, this work shows novelty from an interesting angle for enhancing graph contrastive learning-based recommender system. Both effectiveness and efficiency are guaranteed by the new model.",
            "summary_of_the_review": "Reasonable and well-motivated methodology. Comprehensive experiments are conducted for performance validation. The detailed setting descriptions of hypergraph-enhanced baselines can be provided, and theoretical effectiveness is also encouraged to supplement. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2153/Reviewer_kpFd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2153/Reviewer_kpFd"
        ]
    }
]