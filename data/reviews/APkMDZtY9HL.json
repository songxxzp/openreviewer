[
    {
        "id": "3DsA5jcjRc5",
        "original": null,
        "number": 1,
        "cdate": 1666577609668,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666577609668,
        "tmdate": 1666577609668,
        "tddate": null,
        "forum": "APkMDZtY9HL",
        "replyto": "APkMDZtY9HL",
        "invitation": "ICLR.cc/2023/Conference/Paper596/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors showed how the identification of recurrent patterns from the latent space of a CNN can be utilized for OoD detection problems. They utilize the existing PARTICUL algorithm to distinguish the anomaly patterns from the input and evaluate their approach in two modalities (cross-dataset OoD and perturbation OoD). ",
            "strength_and_weaknesses": "[+] The problem statement and the proposed approach are clear and straightforward. The proposed method provides a graphical interpretation of OoD by mining patterns in the latent representations in CNN-based classifiers. And the key aspects of this work, the robustness and interpretability, have been investigated through experiments.\n\n[-] The major concern is the proposed approach's contribution and novelty. A considerable part of the proposed model appears to overlap with the previous model  (PARTICUL, Xu-Darme et al.(2022)). They modified the PARTICUL algorithm to be a more interpretable and robust confidence measure for OOD detection, but it does not show substantial improvement or novelty in the methodological aspects. \n\n[-] The paper mainly investigates the characteristics of their PARTICUL-based approach itself. It needs to be compared with the standard benchmark for OoD (e.g., Open-OoD). \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written overall. However, it substantially relies on the previously proposed PARTICUL algorithm and the novel finding seems marginal. Their experimental results seem clearly reproducible as the detailed description of the parameters and implementation settings were provided.\n\n",
            "summary_of_the_review": "While the proposed approach is well described and the experiment results somewhat show the robustness and interoperability of the proposed model, its contribution and significance appear marginal because it is largely based on the previous work. Experimental validation could also be improved by adding other widely used benchmarks for OOD. \n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper596/Reviewer_DuyP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper596/Reviewer_DuyP"
        ]
    },
    {
        "id": "01Qi86qFPt",
        "original": null,
        "number": 2,
        "cdate": 1666655273755,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666655273755,
        "tmdate": 1666655273755,
        "tddate": null,
        "forum": "APkMDZtY9HL",
        "replyto": "APkMDZtY9HL",
        "invitation": "ICLR.cc/2023/Conference/Paper596/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper extends a local-based confidence detection method to the image OOD detection task. They further examine the proposed method with variant kinds of perturbations, i.e. blurring, noise, brightness, and rotation. The model is tested on Caltech-101, CUB-200, and StanfordCars. ",
            "strength_and_weaknesses": "Strength:\n\nExtend the local-based confidence detection method to OOD detection task and further explore different perturbations which may contribute to the OOD detection.\n\nWeakness:\n\nCurrent work in Image OOD detection methods usually uses MINIST, ImageNet, and Cifar100 as the validation dataset, while the authors choose Caltech-101, CUB-200, and StanfordCars as the validation dataset. Is there any special reason for such a dataset choice? \nIn addition, the chosen datasets are focused on quite different object categories, (CUB -- birds, and StanfordCars -- cars), which can make the OOD images easier to be distinguished at the feature level. I suggest the authors also complete the experiments on the current popular OOD detection datasets so and compare the performance with proposed methods, i.e. ODIN, Maha, and FSSD.\n\nThe Table 3. Is not very clear. In the table, the authors show correlation coefficients between lambda and confidence measures, while do not provide the quantitative result for each test case. It is not clear the quantitative performance of each perturbation case on different datasets. And more analysis on the inversely correlated cases. For example, why do the blur cases and MCP have a positive correlation, while having an inverse correlation with fNRD?\n",
            "clarity,_quality,_novelty_and_reproducibility": "In my view, this paper is an extension of a local-based confidence detection method for OOD detection tasks. The novelty is limited. \n\nSome experiments are interesting but it is not well demonstrated, like the experiments in Table 3. \n\nThe paper leaks comparisons with current SOTA methods on the common-used datasets on OOD detection tasks, making the paper less supported. ",
            "summary_of_the_review": "In general, I think the novelty of this paper is limited and still has some shortcomings in the experiments. Therefore, I do not recommend this paper generally.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper596/Reviewer_CPyj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper596/Reviewer_CPyj"
        ]
    },
    {
        "id": "ZhTzf8rRTx",
        "original": null,
        "number": 3,
        "cdate": 1666746912718,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666746912718,
        "tmdate": 1666746912718,
        "tddate": null,
        "forum": "APkMDZtY9HL",
        "replyto": "APkMDZtY9HL",
        "invitation": "ICLR.cc/2023/Conference/Paper596/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors propose a new out-of-distribution (OoD) detection method. Specifically, the PARTICUL algorithm is used to find recurring patterns in the training dataset. Then, the degree to which each pattern is included in the data is measured and used as an OoD score. Also, thanks to the use of PARTICUL, the results of the proposed OoD detection method are visually interpretable. Finally, the authors conducted an experiment to detect 1) OoD data of a completely different class from the IoD dataset and 2) OoD data with a distributional shift.",
            "strength_and_weaknesses": "Strength\n1. The interpretability of the proposed method allows us to understand the cues of the data detected as anomalies.\n\n\nWeakness\n1. I believe that the writing quality of the manuscript should be improved.\n- The format of the paper is different from the ICLR format. It is necessary to fix the space between each paragraph and the space at the bottom of the page.\n- There is no explanation of how PARTICUL is trained. In particular, on page 4, there is no explanation of how L_l and L_u are calculated.\n- In Figure 3, each image seems to be unaligned, and in (b), the noise suddenly appears on both sides of the image.\n\n2. The OoD detection methods used as the baseline should be changed. Among those models [1,2,3,4,5] that are generally used as baselines in the OoD detection community, only [1] is used in this paper. If the authors want to use fNRD and FSSD rather than using these models as baselines, I think they should provide a clear reason for it.\n\n3. I have concerns about the applicability and practicality of the proposed method. First of all, the proposed model seems to be applicable only to those models using the CNN architecture. Therefore, unlike the existing approaches [1,2,3,4,5], it seems impossible to utilize the proposed method for other architecture such as Transformer or RNN. Also, I think training p detectors for each class requires a non-trivial amount of time.\n\n4. The improvement of the OoD detection performance is marginal. In Table 1, the proposed method does not consistently perform better than MCP, which is a highly simple method. Also, FPR95 is generally used as an evaluation metric rather than FPR80 in the community. I wonder if there is a particular reason for the authors to use the FPR80.\n\n[1] A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks, Hendrycks et al., ICLR 2017\n\n[2] Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks, Liang et al., ICLR 2018\n\n[3] A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks, Lee et al., NeurIPS 2018\n\n[4] Deep Anomaly Detection with Outlier Exposure, Hendrycks et al., ICLR 2019\n\n[5] Energy-based Out-of-distribution Detection, Liu et al., NeurIPS 2020\n",
            "clarity,_quality,_novelty_and_reproducibility": "The quality of writing should be improved, and the baseline setting should be changed in the experiment. Also, although the interpretable property is attractive, I think the OoD detection performance of the proposed method is not sufficient.",
            "summary_of_the_review": "I believe the quality of the writing, the experimental settings, and the quantitative results should be improved.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper596/Reviewer_2viJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper596/Reviewer_2viJ"
        ]
    },
    {
        "id": "lDNHQZi3rR",
        "original": null,
        "number": 4,
        "cdate": 1668192407269,
        "mdate": 1668192407269,
        "ddate": null,
        "tcdate": 1668192407269,
        "tmdate": 1668192407269,
        "tddate": null,
        "forum": "APkMDZtY9HL",
        "replyto": "APkMDZtY9HL",
        "invitation": "ICLR.cc/2023/Conference/Paper596/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a pattern identification-based OoD detection technique and further leverages a visualization-based approach to interpret the obtained results, providing more tangible results from the human\u2019s perspective. The proposed techniques are based on a previous work PARTICUL, and the evaluation is performed to demonstrate the usefulness of the proposed methods.",
            "strength_and_weaknesses": "Strength:\n\n- Important problem\n- Sound and feasible solution\n- Extensive evaluation to demonstrate the potential usefulness\n- Promise results\n\nWeakness:\n\n- Limited novelty, which is mostly an incremental extension of previous work\n- Limited contribution and insight, the authors mostly discuss how, but unclear why and what is the insight behind the techniques.\n- Interpretable results would be highly demanding, however, this paper again only leverages another existing method for visualization.\n- Not very clear about the implications of the perturbation magnitude and their relation to OoD.",
            "clarity,_quality,_novelty_and_reproducibility": "The overall presentation is ok, however, it lacks insightful discussion about the proposed technique. The novelty and contribution are also\u00a0somehow limited. The authors provide the code for reproduce the results, which is a good sign for reproducibility.",
            "summary_of_the_review": "The paper proposes a sound and feasible method for OoD detection, the evaluation also demonstrates the potential of the proposed method. However, it still posts a few major concerns considering its current status:\n\n- Although the proposed techniques are overall feasible, the novelty is limited, which is mostly based on previous work. The insight of the proposed techniques is also not well discussed.\n\n- The contribution is also limited especially in terms of technical contribution to push the research of OoD, which are mostly based on two previous work for OoD detection, and post an explanation of the results.\n\n- As for the robustness analysis via perturbation, I think this could be interesting. However, the current status does not give too much insight into the impacts and implications of the perturbation, and how the OoD could be connected to robustness, e.g., what is the relation, what is the gap there.\n\nOverall, I do believe the problem this work intends to solve is important. However, it still needs further enhancement to clarify the novelty and contribution.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper596/Reviewer_w3oX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper596/Reviewer_w3oX"
        ]
    }
]