[
    {
        "id": "sKNfZ9dD7O",
        "original": null,
        "number": 1,
        "cdate": 1666074279937,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666074279937,
        "tmdate": 1670823218692,
        "tddate": null,
        "forum": "mTOB_VK_BWk",
        "replyto": "mTOB_VK_BWk",
        "invitation": "ICLR.cc/2023/Conference/Paper3057/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors propose a new knowledge representation method named StarGraph, which serves as an encoder and aims to generate high-quality entity embeddings for downstream score functions. The proposed StarGraph mainly consists of two stages: subgraph sampling and encoding, and the authors manage to optimize the efficiency in both stages. Experiments demonstrate that StarGraph achieves a new SOTA result on a large-scale knowledge graph benchmark (wik90m-v2), while being more parameter efficient than other baseline models.",
            "strength_and_weaknesses": "## Strength\n1. The idea of using subgraphs around entities to generate expressive entity embeddings is reasonable.\n2. The authors propose a bag of tricks to reduce the computational overload for different steps of knowledge representation learning.\n3. The proposed StarGraph significantly outperforms previous SOTA models on the wiki90m-v2 dataset.\n4. Detailed experimental settings and codes are provided, so the reproducibility looks nice.\n\n\n## Weaknesses\n1. **Motivation**  \n    1.1 Why we can use incomplete subgraphs is not well motivated. In the introduction, the authors use Figure 1(a) to demonstrate that complete subgraphs contain a lot of redundant information. However, is there any evidence that this information is redundant? Obviously, the completed subgraph in Figure 1(a) contains more topology information than the incompleted subgraph in Figure 1(b). Although using incomplete subgraphs may lead to competitive results, we can not tell which one is more suitable for knowledge representation learning just through a toy figure illustration.   \n\n    1.2 Why we should use an anchor-based strategy is unclear. Even if using incomplete subgraphs is necessary for large-scale knowledge graphs, we can use a sample-based method (e.g., GraphSAGE) without anchors.\n2. **Related Work**  \n    The authors did a thorough review of related work. However, the differences between StarGraph and some existing works (e.g., NodePiece and GraphSAGE) are not fully discussed.\n3. **Methodology**  \n    3.1 The overall pipeline is unclear. I strongly suggest the authors provide a figure illustration for the overall architecture of StarGraph.\n\n    3.2 In Section 3.2, the authors claim that they use a single transformer block. I am wondering if it is a standard transformer block, i.e., is there a residual connection and layer norm in the used module?\n\n    3.3 The authors highlight two-hop subgraphs in the title. I am not sure whether two-hop is necessary. Can we use one-hop or three-hop subgraphs?\n\n    3.4 The path information is captured by TripleRE in Section 3.2.2. However, it seems that the proposed framework is irrelevant to the path encoders. Therefore, I suggest the authors try more KGE models when encoding paths.\n\n    3.5 I am curious about how to induce Equation (8) from (7). It would be better to provide a detailed derivation.\n4. **Experiments**   \n    4.1 It'd be better to put the main results before ablation studies.\n\n    4.2 The Network ID in Table 2 is confusing.\n\n    4.3 According to Table 3, the combination of anchors and neighbors already leads to the best test MRR, which demonstrates that path and center are unnecessary.\n\n    4.4 As the authors claimed, the main contribution of this paper is a new graph encoder. Therefore, the graph encoder should be able to improve the performance of different decoders not only the proposed TripleRE', e.g., TransE, RotatE, AutoSF.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "## Quality\nExperiments in this paper are convincing and the proposed method shows strong performance. However, some concerns about motivation and ablations should be addressed. (See Strength And Weaknesses for more details.)\n\n## Clarity \nThis paper is overall well written, while the way to introduce Methodology can be improved.\n\n\n## Originality \nMost of the used techniques are well-known, but the authors did a good job of combining them to achieve superior performance.\n\n## Reproducibility    \nDetailed experimental settings and codes are provided, so the reproducibility looks nice.",
            "summary_of_the_review": "This paper proposes an effective method to achieve new SOTA results on large-scale knowledge graph completion. Although the performance is strong, some concerns about motivation and ablations should be carefully addressed before this submission can be published. \n\n===============Update After Rebuttal===============\n\nI have read the author's response (the authors did not upload a revised submission). However, my concerns about the motivation and methodology are not addressed. The author fails to provide sufficient evidence to explain why we must design the model as they do now. In my view, this submission looks more like a technical report than an academic paper. Thus, I am leaning to reject it.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3057/Reviewer_AAWP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3057/Reviewer_AAWP"
        ]
    },
    {
        "id": "lV7A3fGyNrQ",
        "original": null,
        "number": 2,
        "cdate": 1666537634733,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666537634733,
        "tmdate": 1668874783486,
        "tddate": null,
        "forum": "mTOB_VK_BWk",
        "replyto": "mTOB_VK_BWk",
        "invitation": "ICLR.cc/2023/Conference/Paper3057/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Considering the current KG embedding methods of conventional shallow embedding models, which ignore the contextual information,   as well as the generic graph neural networks, which are difficult to expand to a KG with a large number of nodes and are very time-consuming, the authors propose a new knowledge representation learning method based on incomplete two-hop subgraph to leverage the neighborhood information with little computational complexity. ",
            "strength_and_weaknesses": "The strength of the paper:\n\nIn order to save time as well as keep much information from the neighbor nodes,  the authors propose a new method based on an incomplete 2-hop subgraph for knowledge representation learning.  \n\nThe weakness of the paper:\n1. There is an error in the last two rows of the Table. 5 obviously.  \n2. The proposed model is not evaluated enough on different datasets and different tasks. In the paper, the authors only evaluate the proposed method on two datasets on one task.\n3. In fact, the proposed model is a variant of NodePiece and is not innovative enough.\n4. In my opinion,  different types of anchors sampling methods are needed to be investigated in the ablation study.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear in expressing the authors\u2019 ideas, while the proposed method is not innovative enough. \n\nAs for the reproducibility of the paper, the authors describe related parts carefully in the paper, and it is not difficult to reproduce the experimental results from the paper. ",
            "summary_of_the_review": "\nThe current version is not suitable for ICLR.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3057/Reviewer_keWz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3057/Reviewer_keWz"
        ]
    },
    {
        "id": "I7hZdcj50rT",
        "original": null,
        "number": 3,
        "cdate": 1666600732613,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666600732613,
        "tmdate": 1666600732613,
        "tddate": null,
        "forum": "mTOB_VK_BWk",
        "replyto": "mTOB_VK_BWk",
        "invitation": "ICLR.cc/2023/Conference/Paper3057/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed a StarGraph method to learn entity representations for large-scale knowledge graphs. The StarGraph first generates an incomplete two-hop neighborhood subgraph for each target node by picking part of the anchors and nodes within the 2-hop neighborhood. Then a transformer network is applied to obtain the entity representations. \n\n1. The transformer  network is able to mix the information of all nodes in the subgraph, but it fails to model the structure of the subgraph. Therefore, it seems not a good choice to use transformer  to encode graphs. It is neccessary to explain how the transformer  model the graph strucutre. Why do not you not use GNN networks?\n2. When predicting the missing tail entity for (h,r,?), the methods need to sample and encode subgraphs for all the candidate tail entities. It seems  time-consuming. It is better to provide an analysis of  time complexity. \n",
            "strength_and_weaknesses": "Weakness: \n\n1. The transformer  network is able to mix the information of all nodes in the subgraph, but it fails to model the structure of the subgraph. Therefore, it seems not a good choice to use transformer  to encode graphs. It is neccessary to explain how the transformer  model the graph strucutre. Why do not you not use GNN networks?\n2. When predicting the missing tail entity for (h,r,?), the methods need to sample and encode subgraphs for all the candidate tail entities. It seems  time-consuming. It is better to provide an analysis of  time complexity. \n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is generally well written. However, the following two questions should be further considered:\n1. The transformer  network is able to mix the information of all nodes in the subgraph, but it fails to model the structure of the subgraph. Therefore, it seems not a good choice to use transformer  to encode graphs. It is neccessary to explain how the transformer  model the graph strucutre. Why do not you not use GNN networks?\n2. When predicting the missing tail entity for (h,r,?), the methods need to sample and encode subgraphs for all the candidate tail entities. It seems  time-consuming. It is better to provide an analysis of  time complexity. \n",
            "summary_of_the_review": "This paper is generally well written and the solution is ok. If the authors can clarity my questions, I will re-evaluate the paper. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3057/Reviewer_1SnH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3057/Reviewer_1SnH"
        ]
    },
    {
        "id": "c2WE8UeEKDt",
        "original": null,
        "number": 4,
        "cdate": 1666858072647,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666858072647,
        "tmdate": 1666858072647,
        "tddate": null,
        "forum": "mTOB_VK_BWk",
        "replyto": "mTOB_VK_BWk",
        "invitation": "ICLR.cc/2023/Conference/Paper3057/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper argue that Conventional method can not utilize  neighborhood representation effectively for large-scale knowledge graph. The paper propose STARGRAPH, a node selection strategy, to find the superior node in two-hop subgraph. The results show that the proposed method get SOTA results in large-scale knowledge graph link prediction.",
            "strength_and_weaknesses": "\nStrength:\n\nExperiment on the ogbl-wikikg2 link prediction (Table 4) get SOTA results.\n\nWeakness:\n\nThe proposed method in the paper has limitations. The proposed method is to select better nodes in graph, which is a widely used idea [1][2][3]. Such an approach used on the knowledge graph lacks background and motivation. Also, as a KG-independent method, experiments on big graph are missing.\n\nTreating the knowledge graph as a simple directed graph ignores the semantic properties of the knowledge graph, and such work is not conducive to the development of knowledge graph research. For example, whether the selected nodes make important at the knowledge level, the experiment lacks a case study to demonstrate this.\n\nCompared to the previous approach [4], the proposed method experiments on knowledge graph related tasks and it is difficult to show that it is generalizable. \n\n[1]. Alsentzer E, Finlayson S, Li M, et al. Subgraph neural networks[J]. Advances in Neural Information Processing Systems, 2020, 33: 8017-8029.\n\n[2]. Wang X, Ji H, Shi C, et al. Heterogeneous graph attention network[C]//The world wide web conference. 2019: 2022-2032.\n\n[3]. Veli\u010dkovi\u0107 P, Cucurull G, Casanova A, et al. Graph attention networks[J]. arXiv preprint arXiv:1710.10903, 2017.\n\n[4]. Galkin M, Wu J, Denis E, et al. Nodepiece: Compositional and parameter-efficient representations of large knowledge graphs[J]. arXiv preprint arXiv:2106.12144, 2021.",
            "clarity,_quality,_novelty_and_reproducibility": "Well writing, Complete content, The proposed method works but lacks instructions.",
            "summary_of_the_review": "The proposed method is effective, but further reflection on KG is missing.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3057/Reviewer_ZZ4V"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3057/Reviewer_ZZ4V"
        ]
    }
]