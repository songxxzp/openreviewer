[
    {
        "id": "Fwr4y6DSH0",
        "original": null,
        "number": 1,
        "cdate": 1666537931467,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666537931467,
        "tmdate": 1666537931467,
        "tddate": null,
        "forum": "7WgLZCURXxT",
        "replyto": "7WgLZCURXxT",
        "invitation": "ICLR.cc/2023/Conference/Paper4698/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors try to address the multi-instance interactive segmentation task instead of salient interactive segmentation via the Label Propagation algorithm with patch feature representation from Transformers.\n\nIn particular, the authors utilize keys from the last ViT-B layer for feature representation which is later leveraged to construct a graph. A user is assigned to draw scribbles for different objects in an image and apply the Label Propagation algorithm to propagate information through the graph and the remaining nodes. \t\nThe main contribution of this paper is that this work evaluates the representation power of self-supervised ViTs for interactive segmentation tasks.  \n\nExperiments illustrate the effectiveness of the last ViT-B layer with different pre-trainings and demonstrate the robustness against noise and using different ratios of interactive annotations. \n",
            "strength_and_weaknesses": "The main contribution of this work is applying feature representation of self-supervised ViTs and Label Propagation for interactive segmentation tasks. The authors also assess the performance of their algorithm in extreme circumstances with very sparse information on the objects\u2019 position. In addition, the methodology of annotating datasets in an interactive way is carefully described.\n\nThis paper is presented in a clear, coherent manner.  Each module is explained thoroughly and experiments provide detailed information. \n\nHowever, the contributions are not much impressive and not considerable as this paper is just a combination of previous modules. For instance, the authors utilize the last ViT-B layer for building a graph and also follow the prior work (Simeoni et al. 2021).  Moreover, the authors reuse the Label Propagation without significant modification and contribution. \n\nExperiments lack comparison with other methods in interactive object segmentation. For instance,  f-BRS: Rethinking Backpropagating Refinement for Interactive Segmentation - CVPR 2020 or EdgeFlow: Achieving Practical Interactive Segmentation with Edge-Guided Flow - ICCV 2021. It is difficult to convince that this proposal stands out as a state-of-the-art method.  \n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper describes clearly the insight and how their proposed algorithm works. They also analyze their method in complex situations including adding noise and removing a fraction of annotations. However, as I mentioned above, this work is a combination of available modules thus not being considered an enormous novelty.",
            "summary_of_the_review": "The main contribution of this work is utilizing feature representation of ViTs and Label Propagation for interactive segmentation tasks. Although experiments comprehensively analyze the effectiveness of different pre-trainings as well as the performance of proposed methods in extreme conditions, the contribution of this work is minor and does not impress me a lot. Moreover, experiments do not compare with current methods in interactive segmentation tasks which can not prove outstanding results. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4698/Reviewer_KmRX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4698/Reviewer_KmRX"
        ]
    },
    {
        "id": "KukEMEqjf1",
        "original": null,
        "number": 2,
        "cdate": 1666604060633,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666604060633,
        "tmdate": 1666604060633,
        "tddate": null,
        "forum": "7WgLZCURXxT",
        "replyto": "7WgLZCURXxT",
        "invitation": "ICLR.cc/2023/Conference/Paper4698/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents an interactive algorithm for multi-class/multi-instance segmentation based on the vision features obtained from self-supervised pre-training. Previously, such vision features, e.g. DINO features, have been used for unsupervised segmentation. This work extends previous work to the interactive segmentation of multiple instances. Similar to prior work, a graph is constructed based on the features learned in the pre-training stage. Then, class-differentiated scribbles from users are used to initialize partial labels. Finally, a label propagation algorithm (Zhou et al., 2004) is adopted to propagate partial labels to the entire image.  Experiments on VOC 2007 and COCO-panoptic show that the proposed method can achieve reasonable performance and the method is quite robust against noise. ",
            "strength_and_weaknesses": "Strength:\n- The paper shows that pre-trained vision features can be used for semi-supervised multi-class/multi-instance segmentation, where the supervision signals can be as simple as scribbles or even sparse points, which are obtained with low manual cost. \n- The work investigated multiple choices in the system, including the pre-train method to obtain vision features (both supervised and self-supervised), the metrics to build the graph (similarity, RBF, and KNN), and the quality of the supervision signal (partial missing and noisy). \n\nWeakness:\n- The novelty of the work is not high, as it is a simple extension to existing methods (unsupervised segmentation using pre-trained vision features), and there is no big challenge in this extension. The work follows previous work in graph construction and label propagation. \n- The work is not compared with other work. One reason might be that the problem setting is too specific. But how does this setting compare with other interactive segmentation settings?\n- The authors simply ignore small objects, but the segmentation accuracy of small objects is important to the segmentation problem. \n",
            "clarity,_quality,_novelty_and_reproducibility": "- The clarity of the work is fair. But it is not clear whether the scribbles need to cover all semantic classes in an image for the algorithm to work. \n- The novelty of the work is not very high. \n- The work can be reproduced by the description provided. \n- The overall writing still has room for improvement.",
            "summary_of_the_review": "This paper presents a new way to do interactive multi-instance segmentation. However, considering the prior arts on DINO-based unsupervised segmentation and interactive segmentation methods, and the fact that the key components including graph construction and label propagation are not new, the novelty of the work is not high. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4698/Reviewer_JhQx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4698/Reviewer_JhQx"
        ]
    },
    {
        "id": "pmexb-WoKd",
        "original": null,
        "number": 3,
        "cdate": 1666662139909,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666662139909,
        "tmdate": 1666662139909,
        "tddate": null,
        "forum": "7WgLZCURXxT",
        "replyto": "7WgLZCURXxT",
        "invitation": "ICLR.cc/2023/Conference/Paper4698/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposes an interactive segmentation framework that leverages a pre-trained ViT model to perform semi-supervised segmentation tasks on otherwise challenging images. Due to the nature of the proposed framework and ambiguity in evaluation for interactive segmentation framework, no baseline is provided or compared against. The author provides some ablation study within the proposed framework.",
            "strength_and_weaknesses": "Strength\n + An interesting application of ViT in semi-supervised interactive segmentation framework\n + Comprehensive hyper-parameter tuning and experimentation with extreme settings\n\nWeaknesses\n + Although already stated in the paper with understandable reasons, it's still worth pointing out that this work is lacking comparison with existing works and alternative solutions.\n + No evidence is provided as far as I know to substantiate the claim that \"representation of ViT are not able to segment images, with several classes and object instance, in an unsupervised fashion yet\". I believe the claim is true, but proof is needed in the paper.",
            "clarity,_quality,_novelty_and_reproducibility": "Strength\n + Overall clear presentation in problem statement, proposed method, and experiment results\n\nWeaknesses\n + reproducibility is poor without the release of code by the author",
            "summary_of_the_review": "It is an interesting application of ViT in semi-supervised interactive segmentation framework. Comprehensive hyper-parameter tuning and experimentation with extreme settings are provided within the proposed framework. To facilitate reproducibility, I strongly recommend the author publish their code upon acceptance.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4698/Reviewer_Uyni"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4698/Reviewer_Uyni"
        ]
    },
    {
        "id": "c3H57XgcJ-6",
        "original": null,
        "number": 4,
        "cdate": 1666683188938,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666683188938,
        "tmdate": 1666683188938,
        "tddate": null,
        "forum": "7WgLZCURXxT",
        "replyto": "7WgLZCURXxT",
        "invitation": "ICLR.cc/2023/Conference/Paper4698/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a semi-supervised segmentation with self-supervised attention layers for interactive multi-instance segmentation. Remarkable experiment results are obtained when evaluating on Pascal and COCO-panoptic data with very noisy and sparse labels. ",
            "strength_and_weaknesses": "Strength\n\n1.\tMulti-instance segmentation with less label and human interaction is interesting and practically useful research topic.\n\nWeaknesses\n\n1.\tThe paper is not organized and written well so that it is hard to follow and understand the idea.\n2.\tThe motivation is clearly introduced, thus the underlying principle of proposing the SALT is not understandable.\n3.\tThe experiments are not convincing, no comparison with other state-of-the-art methods. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The quality, clarity, and originality of the work cannot reach the bar of ICLR.",
            "summary_of_the_review": "Based on the weaknesses mentioned above, my current decision is reject.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4698/Reviewer_yrjR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4698/Reviewer_yrjR"
        ]
    }
]