[
    {
        "id": "RZIIseQ8tDX",
        "original": null,
        "number": 1,
        "cdate": 1666533444944,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666533444944,
        "tmdate": 1666533444944,
        "tddate": null,
        "forum": "W8UYLEvvYeR",
        "replyto": "W8UYLEvvYeR",
        "invitation": "ICLR.cc/2023/Conference/Paper1903/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a two-stage method to solve instance-dependent label noise learning with anchor points, taking care of robustness and fairness simultaneously.",
            "strength_and_weaknesses": "Strength:\n1. They link instance-dependent label noise and algorithmic fairness, which is a practical and significant in real scenarios.\n\n2. Their experiments are thorough enough and achieve relativelt good performance.\n\nWeaknesses:\n1. I think that considering the fairness in instance-dependent label noise learning is a key contribution in this paper. However, I cannot find any quantative results to evaluate the fairness of their proposed method and baseline methods. These results serve as the important support for this claim.\n\n2. Their technical novelty is limited. Anchor points have been thoroughly studied in recent years. Maybe I have not realized their unique technical contributions compared with previous literatures, e.g., Xia et al., 2020. This question should be clearly explained.\n\n3. I find their proposed method often fails to outperform Transition, e.g., Figure 2(b), Figure 4(b). Does this phenomenon indicates that their proposed method fails to address the severe label noise?",
            "clarity,_quality,_novelty_and_reproducibility": "Quality: ordinary\n\nClarity: good\n\nOriginality: ordinary",
            "summary_of_the_review": "This paper aims to address instance-dependent label noise learning based on anchor points, which is not very novel for this area. Promisingly, they propose to consider fairness in this setting. Fairness problem is associated with instance-dependent label noise naturally. However, this paper lacks the corresponding quantative results to justify their advantages towards fairness.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1903/Reviewer_3mWV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1903/Reviewer_3mWV"
        ]
    },
    {
        "id": "5ZJn3r-pPzH",
        "original": null,
        "number": 2,
        "cdate": 1666617556251,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666617556251,
        "tmdate": 1666617789885,
        "tddate": null,
        "forum": "W8UYLEvvYeR",
        "replyto": "W8UYLEvvYeR",
        "invitation": "ICLR.cc/2023/Conference/Paper1903/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "-This paper considers a general label noise problem (which does not assume any noise models). It proposes a fully heuristic approach: they firstly pre-train the classification model with some clean data, and then update the classification model by alternating between minimizing a loss on learning label confidence score and another loss on weighted training using the learned label confidence weights on each instance and a fairness weight on each subgroup. They also provide some favorable experimental results in the paper.",
            "strength_and_weaknesses": "Pros:\n\n-This paper tries to solve a general label corruption problem by considering both the accuracy and fairness performance measures, which is very **ambitious**. In the paper, they provide a heuristic approach and empirically analyze its effectiveness on some datasets with artificial instance-dependent label noise.\n\nCons:\n\n-First of all, the presentation of the paper is **very unclear** and needs significant improvement. For example, in Section 2 problem setup, the statement \u201clearn a model using dataset $D=${$\\textbf{x}^i,y^i$}, $i=1,...,n$, that classifies each instance into one of $c$ classes based on $\\textbf{\\textbf{x}}$\u201d sounds like it\u2019s transductive learning rather than inductive learning; in the last sentence of this paragraph \u201cusing $\\theta (x)$ we obtain prediction $\\hat{y}$\u201d, how do you obtain the prediction? do you use $\\hat{y}=argmax_{i\\in [c]} \\theta_i(\\textbf{x})$ or others, this should be made explicit; in the next paragraph, what does \u201c$x_i>0.5$\u201d mean? In proposed approach, the optimization problem is written as $\\min_{\\theta\u2019,\\phi\u2019} \\mathcal{L}_\\theta+\\alpha_1\\mathcal{L}_\\phi\\cdot \\mathcal{L}_\\theta$ but what are $\\theta\u2019,\\phi\u2019$? I hope all authors can carefully proofread the whole draft and **write rigorously**. \n\n-Also, the proposed two-step training approach is complicated and contains many heuristics. It would be very helpful if an algorithm can be provided.\n\n-In mainstream label noise literature, anchor points are defined in the clean data domain, that is, an instance $\\textbf{x}$ is an anchor point for the class $i$ if $p(y=i\\mid\\textbf{x})$ is equal to one or very close to one. However, the anchor point concept seems to be **misused** as it means an instance $\\textbf{x}$ that we know both the observed noisy label and its ground-truth label in this paper.\n\n-The proposed method has two stages, pretraining and alternative training. The latter is further based on two objective functions which are combinations of the clean-data loss component and noisy-data loss component. To analyze why such a complicated method works well empirically and how each component contributes to good performance, an **ablation study** removing pretraining and removing each loss component is definitely needed.\n\nQuestions:\n\n-The proposed method is a combination of many loss terms, and therefore has many combination parameters such as $\\alpha_1, \\alpha_2, \\gamma$, is the performance of the proposed method sensitive to these parameters? Sensitivity analysis may be necessary. \n\n-In the proposed method, $\\Phi$ is the network for predicting the label confidence score, but given its loss $\\mathcal{L}_\\Phi$ I don\u2019t see how the instance-dependency is modeled and learned. This needs to be clarified, otherwise, the problem setting of this paper should not be instance-dependent label noise, but general label corruption.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "-The presentation of the paper needs to be improved, please see the detailed comments above.",
            "summary_of_the_review": "-Overall the paper considers an interesting problem, but the current presentation seems not ready, and more experimental analysis is needed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1903/Reviewer_LP3P"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1903/Reviewer_LP3P"
        ]
    },
    {
        "id": "pg1YPmH1Lm",
        "original": null,
        "number": 3,
        "cdate": 1666692988801,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666692988801,
        "tmdate": 1666692988801,
        "tddate": null,
        "forum": "W8UYLEvvYeR",
        "replyto": "W8UYLEvvYeR",
        "invitation": "ICLR.cc/2023/Conference/Paper1903/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper focuses on the problem that current learning methods which handle specially noisy labels may increase the unfairness in prediction. Such a problem exists because in some data sets the minority group often has more noisy annotations. For such kind of data, the paper proposes a method targeting instance-dependent label noise by assuming a group of anchor points, which is sufficient to represent the whole dataset, is available. The paper then proposes to use two models simultaneously: one does the classification, and another predicts how noisy the given label is. The proposed training phase composes of two steps: one step uses only anchor points with both clean and noisy labels to train the two models, followed by another step that alternatively optimizes the two models and uses the predicted noisy level to weigh the non-anchor data points. Finally, the paper did some experiments showing that in various anchor points situations (the number of them, and the bias of them), the proposed method can achieve a good overall performance in both classification and fairness. ",
            "strength_and_weaknesses": "I think the paper considers a combination of two existing problems: fairness in learning from noisy labels, and instance-dependent noise. These two problems have already been considered in existing works. Nevertheless, the paper tries to provide an effective solution to such a combination of problems. From the experimental results, the paper's solution is effective. It is comparable to the Transition method with slightly better performance under some settings. However, from the illustration, the improvement seems marginal and is not significant if considering the standard deviation.\n\nThe paper has claimed to solve the \"balance between accuracy and fairness\". The experimental results have used the harmonic mean of an accuracy metric and a fairness metric to demonstrate the proposed method has achieved the balance. On the other hand, the wording of balance suggests that there is some controversy between the two, such that the current work needs to \"balance\" them. But in the proposed method, I do not see quite strong evidence that a special technique is introduced for increasing the balance at the sacrificing of the classification performance. The subgroup weighting used in the training phase may be a technique to increase the balance. But I think finding the appropriate subgroup is tricky. And such subgroup techniques have been used in previous works (as shown in Section 5->Label noise and fairness).\n\nOverall, the strength of the paper is that it tries to solve a combination of two important problems in learning from noisy labels. While the combination is straightforward, the resulting problem is an important problem and may draw attention from the research community. From the metric, the performance looks good and shows the effectiveness of the solution from a different technical perspective rather than the transition matrix one. \n\nThe weakness of the paper is that despite its claim, I do not think the problem of \"fairness\" has been clearly explained in the paper, and there are few technical contributions towards the \"fairness\" end. The assumption on the representativeness of the anchor points seems too strong and I do not think it could be easily satisfied practically. If saying the anchor points are sufficient, and the data satisfies the clustering distribution, then I am afraid a semi-supervised method could solve the problem easily without knowing any noisy labels. ",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the paper is easy to follow. There are some minor typos but do not impact the understanding. One critical problem with the paper is that it fails to explain the \"fairness\" problem sufficiently. I think the fairness problem applies only to a limited situation when the noise level in minority groups is larger than that in majority groups. However, from the beginning, the paper seems to treat the fairness problem as a universal problem caused by noisy labels, and the \"balance\" wording also suggests there should be a tradeoff between accuracy and fairness. I think the paper should improve on this part, to make the research problem precise and sufficiently explained.\n\nThe paper has proposed an effective solution to the instance-based noise problem with a strong reliance on sufficient anchor points. The experimental results have demonstrated the performance of the proposal compared to a series of baselines from different perspectives. The technical proposed is under the same principle as previous methods in that learns the correlation between the clean and noisy label and weighs the instances by subgroup prediction, but may be different in detailed implementations.  Overall, the proposed method is not totally novel but shows some solutions could be as effective as others. \n\nThe paper has produced pages to explain the experimental details. Although there is no link to shared codes, I do not see any issue in reproducibility. \n\n",
            "summary_of_the_review": "The paper has proposed a solution to an important research problem. The solution is not novel enough, but simple and effective. The concern may be on the assumptions made, and whether a semi-supervised solution can easily solve the problem given such strong assumptions. The clarity on the \"fairness\" part also needs to be increased (maybe significantly). ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1903/Reviewer_GGCC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1903/Reviewer_GGCC"
        ]
    },
    {
        "id": "BIx_YswrVO",
        "original": null,
        "number": 4,
        "cdate": 1666693068428,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666693068428,
        "tmdate": 1667272552134,
        "tddate": null,
        "forum": "W8UYLEvvYeR",
        "replyto": "W8UYLEvvYeR",
        "invitation": "ICLR.cc/2023/Conference/Paper1903/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper aims to study a \"fair\" model for learning with instance-dependent label noise. The authors proposed a simple yet intuitive solution, which is first pre-train a classifier $\\theta$ and a discriminator network $\\phi$ with anchor points. And then use the trained discriminator networks to discriminate the noisy samples from clean samples, and use the predicted clean samples to train the classifier. Which can be theoretically equivalent to the model trained with clean data.",
            "strength_and_weaknesses": "Pros:\n1. The question of interest is interesting and vital, the fairness of label noise learning methods is an important yet under-appreciated topic.\n2. Author attempts to provide theoretical proof to justify that their method is equivalent to the model trained on the clean domain in the ideal case.\n3. Authors provide comprehensive experiment settings, which helps the reviewer understands the detail of the experiments.\n4. The empirical performance of the proposed method is significant compared with selected baseline methods.\n\nCons:\n1. The biggest issue of this paper is the authors' assumption on anchor points, where authors assumed that \"a subset of data for which we know the observed and ground truth labels\" and \"is representative of the target population\". Generally, in the field of label noise learning, only the first assumption holds true, whereas the assumption that anchor points are representative of the target population is too strong. This problem directly hinders the theoretical soundness of this paper, because, in reality, the learned $\\theta$ and $\\phi$ are bound to be biased.\n2. While the authors claimed that they are trying to study the fairness of label noise learning methods, I fail to see any relevant definition or justification regarding fairness. As a contrastive example, [1] studies the well-defined counterfactually fairness, and [1]'s relation to fairness is clearly discussed. \n\nMinor issues:\n1. Authors are suggested to use more commonly used benchmarks such as CIFAR or MNIST.\n2. Authors are encouraged to include more recent baseline methods.\n\n[1] Wu, S., Gong, M., Han, B., Liu, Y., & Liu, T. (2022, June). Fair classification with instance-dependent label noise. In Conference on Causal Learning and Reasoning (pp. 927-943). PMLR.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: This paper is well-written, however, the organization of this paper might need to be improved, for instance, the authors should use some part of the paper to discuss the definition of fairness and its relation to their method.\n\nNovelty: The novelty of this paper is limited, using dual networks to predict the underlying true label of noisy sets and then only using samples that are likely to be clean to train the main model is not novel [1].\n\nReproducibility: Authors released their implementation code, and after examining the code, the experiments are believed to be reproducible.\n\n[1] Jiang, L., Zhou, Z., Leung, T., Li, L. J., & Fei-Fei, L. (2018, July). Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels. In International conference on machine learning (pp. 2304-2313). PMLR.",
            "summary_of_the_review": "Overall, while the topic this paper aims to study is non-trivial and promising, the content of this paper suggests only a very limited relation to the fairness of label noise learning methods. Also, since the authors' assumption on anchor points is too strong, I cannot agree with the premises of this paper, nor the conclusion it draws. Therefore, I vote for the rejection of this paper.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1903/Reviewer_wG5f"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1903/Reviewer_wG5f"
        ]
    }
]