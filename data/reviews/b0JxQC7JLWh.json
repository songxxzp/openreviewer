[
    {
        "id": "PbkEvz0yDk",
        "original": null,
        "number": 1,
        "cdate": 1665946540219,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665946540219,
        "tmdate": 1665946540219,
        "tddate": null,
        "forum": "b0JxQC7JLWh",
        "replyto": "b0JxQC7JLWh",
        "invitation": "ICLR.cc/2023/Conference/Paper2008/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The work provides their \"DEMASKED SMOOTHING\" approach, which the authors argue provide defence framework against patch attacks for segmentation models. They evaluate their model on semantic segmentation datasets ADE20k and COCO-Stuff-10K. They use models trained on existing benchmarks, evaluated on various masking schemes. The authors discuss the results and approach compared to baselines in Section 5.",
            "strength_and_weaknesses": "Strength:\n* The work is well organized, clear to follow with no major grammatical errors\n* The empirical evaluation seems reasonable, along with the prior work.\n* The results on the benchmarked datasets seem promising.\n\n\nWeaknesses:\n* The theoretical grounding is not clearly explained in the main paper.\n* Limitations are not clearly described, evaluation limited to semantic segmentation domain\n",
            "clarity,_quality,_novelty_and_reproducibility": "As detailed above, the work is clear to follow. It seems reasonably reproducible based on the details in Algorithm 1 and Section 4. The authors detail the novelty compared to prior work in Section 2, describing the uniqueness.",
            "summary_of_the_review": "Overall the work is well organized, described clearly and makes an original contribution of reasonable significance. The empirical results look promising, although it seems authors skipped some detailed on limitations and expanding theoretical claims.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None so far, authors addressed this in Section 7.",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2008/Reviewer_F6Ro"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2008/Reviewer_F6Ro"
        ]
    },
    {
        "id": "FrZLcnUf77",
        "original": null,
        "number": 2,
        "cdate": 1666581275300,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666581275300,
        "tmdate": 1668746745214,
        "tddate": null,
        "forum": "b0JxQC7JLWh",
        "replyto": "b0JxQC7JLWh",
        "invitation": "ICLR.cc/2023/Conference/Paper2008/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposed Demasked Smoothing (DS), a certified defense against adversarial patch attacks on semantic segmentation. The empirical performance outruns baseline certified defenses such as DRS.",
            "strength_and_weaknesses": "While to my knowledge I agree that this paper is one of the first certified defenses proposed for semantic segmentation, I have several questions about the current presentation of the results (see the following sections).",
            "clarity,_quality,_novelty_and_reproducibility": "1. While it is true that the defense applies to any segmentation model, the defense requires the use of an off-the-shelf image inpainter, which could be the bottleneck (or even harmful) to certified performance if the inpainter is not reliable. Can the authors do an ablation study on the effect of image inpainter?\n\n2. The certification criterion seems to be largely different from certified patch defense, in that there is no notion of majority vote on masked parts. Rather, the proposed defense aims at recovering a consistent pattern of the masked part and uses it for the final certification. In a way, the recovery is either correct or incorrect, and there is no notion of correctness when there is some inconsistency of demasked results, which intuitively should give stronger certified results. Can the authors comment on this? Also, if I understand correctly, the proposed method cannot certify the maximum size of a certifiable patch, which is another limitation. The certification is more similar to robust segmentation recovery using multiple damasked segmentations from an inpainter. I hope the authors can comment more on the limitation of the proposed method.\n\n3. To make a fair comparison to DRS and Randomized Cropping, can the authors compare semantic segmentation similar to their settings (e.g., using segmentation models robust to random masking)? Is there still any notable performance gain?",
            "summary_of_the_review": "Sufficient novely on certified defense for semantic segmentation, though the certification seems rather restrictive (e.g., requiring very high consistency of image recovery rather than majority voting). More discussions on the working mechanism, limitations, and additional comparisons are needed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2008/Reviewer_TG16"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2008/Reviewer_TG16"
        ]
    },
    {
        "id": "3CdrDgaVJ-s",
        "original": null,
        "number": 3,
        "cdate": 1666651036230,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666651036230,
        "tmdate": 1669113118654,
        "tddate": null,
        "forum": "b0JxQC7JLWh",
        "replyto": "b0JxQC7JLWh",
        "invitation": "ICLR.cc/2023/Conference/Paper2008/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The manuscript addresses adversarial patch attacks for segmentation models. The proposed approach extends previous work on certified patch robustness for image-wide models. It is capable both of certified detection and certified recovery and it can be applied to any semantic segmentation model. The main idea is to apply a set of K masks to the input image, inpaint the void areas with ZITS, and then to detect or undo adversarial patch attack by analyzing all predictions at the given pixel.\n",
            "strength_and_weaknesses": "Strengths\n1. adversarial robustness is an important problem\n2. a previous image-wide approach [salman21arxiv] has been extended for the case of dense prediction.\n\nWeaknesses\n1. This approach is likely going to strongly diminish semantic accuracy at small objects.\n2. The majority of input pixels is inpainted. The manuscript does not seem to consider opportunities of attacking the inpainting algorithm either through adversarial patches or through data poisoning. \n3. The second to last sentence of the proof to theorem 1 is not convincing. \n4. Unclear implied guarantees of certification. Consider the example from Figure 18. An adversarial patch has opportunity to affect only T=4 of K=9 masks. Still, the model is going to make mistakes in the remaining K-T=5 masks. Could these mistakes lead to adversarial patch pass unnoticed?\n5. Unclear relation with respect to adversarial training. Would it make sense to combine these two approaches?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The manuscript is hard to follow (eg. paragraph certified recovery in section 4.1) and has several weaknesses (see above). ",
            "summary_of_the_review": "The reviewer perceives moderate novelty, tough reading and several weaknesses.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2008/Reviewer_FoVC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2008/Reviewer_FoVC"
        ]
    },
    {
        "id": "Rp35c2VA4G",
        "original": null,
        "number": 4,
        "cdate": 1666833833634,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666833833634,
        "tmdate": 1666833833634,
        "tddate": null,
        "forum": "b0JxQC7JLWh",
        "replyto": "b0JxQC7JLWh",
        "invitation": "ICLR.cc/2023/Conference/Paper2008/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a new method to certify the robustness of semantic segmentation models against adversarial patch attacks without extra training.\n",
            "strength_and_weaknesses": "Overall, the paper is interesting and extend the certification for semantic segmentation. \n\nStrength:\n1) This paper is well-written. \n2) This is the first method to certifiably defend against adversarial patch attack on semantic segmentation.  \n3) This method can be applied on any off-the-shelf segmentation model without finetuning or any other adaptation.\n\nWeakness:\n1. One minor weakness is that this paper did not apply to the STOA transformer based methods such as Segformer. Hope to see the performance on Segformer. \n2. Hope the author can provide the code to check the reproducibility of this paper. \n\n[1] SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers.  ",
            "clarity,_quality,_novelty_and_reproducibility": "The clarify and quality are good.  \nFor the reproducibility, it is reasonable to me. However, if the author can release the code, it would be much better. ",
            "summary_of_the_review": "It implements certified defense under patch attacks on semantic segmentation. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2008/Reviewer_XUU4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2008/Reviewer_XUU4"
        ]
    }
]