[
    {
        "id": "EQxLYIKPo09",
        "original": null,
        "number": 1,
        "cdate": 1666582856771,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666582856771,
        "tmdate": 1666583054982,
        "tddate": null,
        "forum": "CL-sVR9pvF",
        "replyto": "CL-sVR9pvF",
        "invitation": "ICLR.cc/2023/Conference/Paper3294/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Model ensembling is a common technology to further boost performance. While most paper study how to ensemble on supervised models, this paper focus on self-supervised models (SSL). Then, this paper discusses where to ensemble and how to ensemble the models training from SSL, proposing a downstream-efficient ensemble method based on weighted cross-entropy objectives. The results on few-shot learning such as imagenet-1k (1%) improve baselines of SSL method (DINO/MSN).",
            "strength_and_weaknesses": "With the development of SSL, it is necessary to study SSL model ensemble. The paper is rich in theoretical basis, Explaining clustering-based self-supervised learning methods from the perspective of maximum likelihood distinctly. This paper proposed a method that can be effective solutions to ensemble multi models, because of ensembling only applying to the head and codebook, not the encoder. This paper is easy to follow, and experiments are enough to support the claims made in this paper. \n\nCouple questions come to mind:\n\n1.This method is effective but I think it's not enough to just ensemble the head and codebook, most researchers are probably more concerned how to ensemble the encoder part.\n\n2.How extensible is this method? The method is verified in the double-branch structure (DINO/MSN) and can it be applied to the most popular MIM methods such as MAE. \n\n3.How to acquire multiple models to ensemble and how to ensure the diversity of the models, it seems to be less described in the paper.\n\n4.If I am not wrong, the authors only fuse different heads, and how these different sub-models are obtained, from the intermediate checkpoints, and how can ensure the diversity of these heads. In my opinion, the diversity of the head counts for then ensemble, and how about choosing other heads from even smaller backbones but with large diversity. How is the method compared with another simple method model soups [1] that ensembles the encoders of different checkpoints and do not increase the inference time.  \nOverall, although the results are impressive, I still wonder the rationale of the methods.\n[1] Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time\n\n5. It is better to add average number in Table 3 for clarify.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper describes clearly, and the proposed ensemble method is novel, but the experiments are insufficient, such as encoder ensemble and comparison with existing methods.\n\n",
            "summary_of_the_review": "Model ensembling for SSL model is an interesting idea to explore, however, it is still in the preliminary stage, and the above mentioned methods and experiments need to be further supplemented. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3294/Reviewer_37Hd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3294/Reviewer_37Hd"
        ]
    },
    {
        "id": "pbwmyclW1co",
        "original": null,
        "number": 2,
        "cdate": 1666641180409,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666641180409,
        "tmdate": 1666641180409,
        "tddate": null,
        "forum": "CL-sVR9pvF",
        "replyto": "CL-sVR9pvF",
        "invitation": "ICLR.cc/2023/Conference/Paper3294/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper systematically studies the ensemble of self-supervised learning. Ensemble has been one of the oldest time-proven strategies in machine learning and has been well-studied in supervised learning. Here, the authors introduce ensemble into the field of SSL. They mainly consider ensembling the projection head and codebook and leaving the encode part as future work. This proposed method is straightforward with rich analysis and proper results. ",
            "strength_and_weaknesses": "## Strength\n(1) The proposed method is straightforward and easy to implement with compelling results.\n\n(2) I believe this paper includes some important and thorough experimental work on ensemble of self-supervised models.\n\n(3) Detailed hyperparameters and training configurations are provided, improving the reproducibility.\n\n## Weakness\n(1) The ensembling of the projection head and codebook is a natural extension of the classifier ensemble in supervised models. It is not too surprising to see a performance improvement. \n\n(2) This paper mainly evaluated ensemble on transfer learning, while the performance on upstream tasks (Imagenet) has been overlooked. ",
            "clarity,_quality,_novelty_and_reproducibility": "Solid contribution.",
            "summary_of_the_review": "I believe this paper, albeit short on technical novelty, does provide a sufficiently novel and important empirical evaluation and details analysis of self-supervised learning ensembling methods and could be accepted - assuming the authors can address the issues I have detailed in my review.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3294/Reviewer_wYk7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3294/Reviewer_wYk7"
        ]
    },
    {
        "id": "wnvOVNHaudW",
        "original": null,
        "number": 3,
        "cdate": 1666644454144,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666644454144,
        "tmdate": 1666644638454,
        "tddate": null,
        "forum": "CL-sVR9pvF",
        "replyto": "CL-sVR9pvF",
        "invitation": "ICLR.cc/2023/Conference/Paper3294/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies the benefits of ensembling for self-supervised learning methods. The paper proposes to ensemble the \u201cnon-representation\u201d part of the SSL models, and proposes different weighting schemes. Extensive experiments are conducted to analyze and evaluate the proposed ensemble method and weighting schemes, which lead to improvements over the non-ensemble models.",
            "strength_and_weaknesses": "Strengths:\n- This could be a pretty timely work that explores ensembling for self-supervised learning models. I like the idea of only ensembling the non-representation part as that incurs little training overhead, plus no extra cost for downstream tasks.\n- I appreciate that the authors included the analysis on the ensemble diversity. This gives a deeper understanding of the effectiveness of different weighting schemes, and could potentially guide the designs of future weighting schemes.\n- The paper includes thorough analysis and ablations on the proposed methods, and shows strong empirical results compared to the baselines and SOTA.\n\nWeaknesses:\n- The connection between the Maximum Likelihood view of SSL and the proposed ensemble method design is not very clear to me. The presentation could be improved with stronger connections between Sec.2 and Sec.3.\n- While the paper does a good job in evaluating a variety of ablations on the proposed ensemble method, it seems to lack other possible baselines for ensembling, e.g., instead of only ensembling the projection head, one baseline is to consider ensembling the base models. It\u2019d be good to compare this baseline to understand whether there is a trade-off between the benefits of ensembling and the cost for extra parameters. In general, the paper should include comparisons to the other related ensemble baseline mentioned in Sec. 4.\n\nOther questions/comments:\n- Can one use the proposed ensembling method on pre-trained SSL models (e.g. DINO)? What\u2019s the performance difference of that to applying ensembling in the pre-training from scratch? I think this is a relevant question to look into since there are already a lot of publicly available pre-trained SSL models, and it\u2019d be best if the ensembling technique can be applied on top of these pre-trained models and still offer improvements.\n- How does one set $\\gamma$ for ENT in practice? From Figure 3.b, it seems to affect the performance pretty much.\n",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity: The paper is overall clearly written.\n- Quality and Reproducibility: The paper includes quite comprehensive experimental results, especially with careful treatments on the baseline methods. Experimental details are provided in the paper and the authors promise to release code later on. The results looks convincing and should be reproducible.\n- Novelty: Ensembling for SSL models, especially in the pre-training stage, does not seem to have been studied in the literature. The proposed ensembling method and weighting scheme appears to be novel and more importantly, lead to decent performance improvements.",
            "summary_of_the_review": "The paper studies a timely topic on ensembling for SSL models. The proposed method is simple and could fit with a variety of SSL models. While the paper can be made better by comparing to more related ensembling baselines to guide practical use, the current presented empirical results is quite comprehensive on its own, and the usefulness of the proposed method is well-justified by the empirical results.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3294/Reviewer_8Pcm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3294/Reviewer_8Pcm"
        ]
    },
    {
        "id": "eZWNUMja_-",
        "original": null,
        "number": 4,
        "cdate": 1667200912633,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667200912633,
        "tmdate": 1667200912633,
        "tddate": null,
        "forum": "CL-sVR9pvF",
        "replyto": "CL-sVR9pvF",
        "invitation": "ICLR.cc/2023/Conference/Paper3294/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies how ensemble methods can improve self-supervised learning algorithms. The considerations are limited to ensembles of projection heads and codebooks but not encoders, to ensure no extra computational cost involved. The authors propose a kind of data-dependent weighted cross-entropy losses. Two sota SSL methods, DINO and MSN are considered as baselines. In various experimental settings, the ensemble methods are observed to largely improve the baselines. ",
            "strength_and_weaknesses": "Strength:\n- This paper is well-written and easy to follow.\n- The ensemble methods only incur a small training cost.\n- It is interesting to see that sota SSL algorithms can be further improved by ensembling in various settings (linear eval, KNN, few-shot, etc.).\n\nWeaknesses:\n- The proposed framework only suits contrastive SSL methods (i.e., align positive pairs). Other SSL methods such as MAE can not be applied.\n- When encoders are not considered for the ensemble, the possibilities for where to ensemble are not too many. The proposed ensemble framework somewhat lacks novelty. The main contribution is to test different weighting schemes.",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity: This paper is well-organized and easy to read.\n- Novelty: The proposed ensemble framework seems to be a little bit simple. But the experiments are sufficient.",
            "summary_of_the_review": "Overall,  the problem this paper studies is interesting. To simplify the design and retain the computational cost, this paper is limited to ensembles of projection heads and codebooks but not encoders, which limits the technical novelty. It is interesting to see the significant improvement in performance under various settings and evaluation metrics. Therefore, I think this is a borderline paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3294/Reviewer_pJds"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3294/Reviewer_pJds"
        ]
    }
]