[
    {
        "id": "Bsn4cj4vVfH",
        "original": null,
        "number": 1,
        "cdate": 1666420684324,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666420684324,
        "tmdate": 1666420684324,
        "tddate": null,
        "forum": "XhgbD4ZNKFA",
        "replyto": "XhgbD4ZNKFA",
        "invitation": "ICLR.cc/2023/Conference/Paper2955/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes a internal cluster validation index that is based on the notion of 'differential entropy' to assess the compactness and separability of a clustering solution. It relies on the assumptions i) that each cluster can be modeled using a Gaussian distribution and ii) that clusters centers also follow a Gaussian distribution.  The proposed index is compared to several alternatives using embeddings obtained from deep neural networks pretrained on image and text datasets. \n",
            "strength_and_weaknesses": "Strength\nThe paper is well-written and clearly explained.\n\nWeaknesses\nThere is no significant technical contribution. Combining internal and external cluster separation is typical in most clustering quality indices.\nDifferential entropy depends on the determinant of the covariance matrix, a well-known measure of cluster variance. \nGaussian assumption is made both for the data distribution inside a cluster and the distribution of cluster centers, which is actually too restrictive.\nThere is no sufficient intuitive justification on why the proposed index would perform better than existing ones.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The method is simple and lacks in terms of originality and novelty. \nThe paper is clearly written and the results seem to be easily reproducible (although no code is provided).\n",
            "summary_of_the_review": "The paper presents an internal cluster validation index that is based on the differential entropy of multidimensional normal distribution. \nGiven a cluster i with data mean \\mu_i and data covariance \u03a3_i its compactness is computed as the entropy of the normal distribution N(\\mu_i, \u03a3_i). The dispersion among clusters is computed as the entropy of the set of cluster centers, assuming that they are Gaussian distributed.\n\nMajor concerns about the paper.\n1) The Gaussian assumption is too restrictive.\n2) Differential entropy is essentially the determinant of \u03a3, which is a well-known measure of cluster variance.  \n3) Experiments focus on embeddings from pretrained deep networks. The method should be evaluated on synthetic datasets with clusters of various shapes and known ground truth. It should also be tested on typical low dimensional benchmark datasets (e.g. from the UCI repository).\n4) There is no sufficient intuitive justification on why the proposed index would perform better than several existing ones also relying on separation and compactness.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2955/Reviewer_HicV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2955/Reviewer_HicV"
        ]
    },
    {
        "id": "81cs1fau8J",
        "original": null,
        "number": 2,
        "cdate": 1666565863906,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666565863906,
        "tmdate": 1666729868663,
        "tddate": null,
        "forum": "XhgbD4ZNKFA",
        "replyto": "XhgbD4ZNKFA",
        "invitation": "ICLR.cc/2023/Conference/Paper2955/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a new measure for internal clustering evaluation. To compute this measure, one first computes the differential entropy for each cluster (assuming that the elements are sampled from a multivariate normal distribution) and then subtracts the differential entropy for the cluster centers from the average entropy of individual clusters. Experimental results on several datasets with known cluster labels show the advantages of the new measure over existing ones.",
            "strength_and_weaknesses": "Strength:\n- Experimental results show significant improvements on the considered datasets\n\nWeaknesses:\n- The assumption about the normal distribution is quite strong, and it is not clear how deviations from this assumption would affect the quality of the measure\n- There is no theoretical or empirical analysis of the properties of the proposed measure\n\nDetailed comments are below.\n\nI am not very familiar with the literature on internal clustering evaluation measures, but there are works on theoretical analysis of such measures, for instance, papers discussing axioms desirable for these measures [1] or providing guarantees for convex clusters (Halkidi & Vazirgiannis, 2001). Then, an empirical evaluation was conducted by Liu et al. (2013), where the effect of noise, density, and shapes was analyzed. The current paper would benefit from more detailed related work where different approaches to comparing clustering measures are discussed.\n\nAdditionally, a more detailed analysis of the proposed measure would help to demonstrate its advantages. For instance, does this measure satisfy some desirable theoretical properties? Is it biased towards big or small clusters? (Such biases are formalized for external cluster evaluation measures, e.g., in [2].) How the measure performs for clusters with different levels of noise, different shapes, etc.? Such theoretical or empirical analysis can show the benefits and limitations of the proposed measure.\n\nMore details throughout the text can be helpful:\n- The beginning of page 2: formalization of distance-based indices would help a reader to understand the motivating example.\n- Formal definitions of the measures from Table 1 are needed to understand the existing measures and the differences between them and the proposed measure. (In Table 1, the intuition behind the measures is given.)\n- More details on the information criterion are needed to understand the analogy at the beginning of page 6.\n- Also, I could not get the main message of the paragraph \u201cEffectiveness\u201d in Section 4.2.\nThe detailed experimental setup can be moved to Appendix, which may give more space to explanations throughout the text.\n\nMinor comments:\n- Note that the differential entropy in equation (2) is for a one-dimensional case, while it is later used for d-dimensional vectors.\n- To compute CP in equation (7), parameters of the multivariate normal have to be estimated, which needs to be mentioned in the text.\n- The variable m (the number of samples in the k-th cluster) can be changed to reflect the dependency on k, e.g., m_k\n\nQuestions for the authors:\n- Q1: The measure assumes that the elements within each cluster and cluster centers have multivariate normal distributions. In practice, this can be violated. What would happen in such cases? How sensitive is the measure to deviations from this assumption? Also, can we approximate the density and then approximate the integral (2) without this assumption?\n- Q2: Could you please specify how accuracy is computed for clustering evaluation?\n\nSome typos:\n- \u201cthese implementation\u201d (page 2, line 3)\n- \u201cthe volume of two cluster vector space are the same\u201d (page 2, line 8)\n- \u201chas also be used\u201d (page 3, line 6)\n- \u201cthe distance form the samples\u201d (page 2, definition of I index)\n- \u201care not good measure\u201d (page 4)\n- \u201cACC and ARI indicates\u201d (page 6, line -7)\n- \u201cbesults\u201d (page 7, line -7)\n- \u201cCH obtain\u201d (page 7, line -5)\n- \u201cTabel\u201d (page 7, line -5)\n- Missing articles throughout the text\n\n[1] Ben-David S., Ackerman M. Measures of clustering quality: A working set of axioms for clustering. NIPS 2008.\n\n[2] G\u00f6sgens M., Tikhonov A., Prokhorenkova L. Systematic analysis of cluster similarity indices: How to validate validation measures. ICML 2021.",
            "clarity,_quality,_novelty_and_reproducibility": "Please, see the detailed comments above.\n\n**Clarity** The paper is generally clearly written, but some background required for the understanding is not included.\n\n**Novelty** To the best of my knowledge, the proposed measure is novel.\n\n**Reproducibility** There are enough details to reproduce the experiments, but code is not provided.",
            "summary_of_the_review": "On the one hand, the experiments show significant superiority of the proposed measure over existing ones on the considered datasets. On the other hand, the properties of the proposed measure are not investigated theoretically or empirically. Thus, it is not clear how it will behave in other tasks. Additional analysis is needed to understand to which datasets the measure is applicable. Therefore, my current rating is borderline reject.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2955/Reviewer_5DqQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2955/Reviewer_5DqQ"
        ]
    },
    {
        "id": "Be3hW8oYE7a",
        "original": null,
        "number": 3,
        "cdate": 1666632937386,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666632937386,
        "tmdate": 1668925093858,
        "tddate": null,
        "forum": "XhgbD4ZNKFA",
        "replyto": "XhgbD4ZNKFA",
        "invitation": "ICLR.cc/2023/Conference/Paper2955/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes an internal validation metric for model selection in clustering based on the average difference in differential entropy between each cluster and the cluster means when each cluster is treated as having a Gaussian distribution, as is the collection of cluster means.\n\nSome experiments are included to show the practical performance in comparison with other internal metrics when data are clustered after being embedded with pre-trained neural networks.",
            "strength_and_weaknesses": "Unfortunately I do not see any substantial strengths in the paper. Although there is some evidence of practical relevance, the experiments are a bit contrived and furthermore the implementation of some other metrics, such as AIC and BIC, is incorrect. First, AIC and BIC in their basic formulations should not be applied to the solution based on a hard mixture, such as k-means. Furthermore, if the authors would like to use these then it is sensible to use the same parameter estimates for them as in the proposed method since AIC and BIC are applicable for GMMs, which is the \"assumption\" underlying the proposed method.\n\nWeaknesses:\n- The authors argue that compactness metrics based on variance are flawed, and yet they propose one which is based solely on the differences between the volumes of the covariance matrices of the clusters and the between class covariance. It is not clear why their proposal is not similarly flawed.\n- There does not seem to be any theoretical underpinning for the proposed approach, whereas if the \"assumption\" is that the data are from a Gaussian mixture then there are well motivated alternatives with sound theoretical underpinnings, such as AIC and BIC.\n- The presentation and notation is unclear.\n- The authors report the performance in terms of ACC and ARI, however other external validation metrics may tell a very different story.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity, both in terms of the writing, and in terms of the arguments put forward in support of the proposed method requires improvement. Without a theoretical justification, or at least a strong heuristic justification for the proposed metric, the proposal overall is not of a quality high enough for publication in a top tier conference such as ICLR. Regarding novelty, it is possible that the proposal is entirely new, however its similarity with likelihood based criteria (the negative entropy is directly connected to the expected log-likelihood) means that it is more tangential to existing methods than the authors seem to have noticed. In terms of reproducibility, I have concerns about the way in which existing metrics were implemented and without absolute clarity it is not certain that the results are reproducible.",
            "summary_of_the_review": "Overall, while there is arguably some evidence for practical relevance, the experiments are a bit too thin and potentially contrived to suit the proposed method, and there are questions regarding the correctness of the implementation of other metrics, to warrant acceptance in a top tier conference. Furthermore, even if there were no issues with the experiments, the lack of a sound justification (either theoretical, or at least a well argued heuristic) for the proposed method means that its performance in general is questionable.\n\nUPDATE:\n\nAfter considering the authors' responses to my and other reviewers' comments, as well as the reviewers' comments themselves, I do not see a reason to adjust my initial score/assessment of the paper.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2955/Reviewer_MXF3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2955/Reviewer_MXF3"
        ]
    },
    {
        "id": "GK8jP6nF2V",
        "original": null,
        "number": 4,
        "cdate": 1666684005272,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666684005272,
        "tmdate": 1669190603310,
        "tddate": null,
        "forum": "XhgbD4ZNKFA",
        "replyto": "XhgbD4ZNKFA",
        "invitation": "ICLR.cc/2023/Conference/Paper2955/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper presents a novel internal validation index for clustering, based on the differential entropy, named internal purity. The method is evaluated on different datasets, encoded with deep net representations, and compared with standard alternatives.",
            "strength_and_weaknesses": "Positive points:\n- The topic is definitely interesting\n- The paper is well written and easy to read\n- The structure of the manuscript is clear\n- The experimental evaluation is rather extensive\n\n\nNegative points:\n\n1) the computation of the index can be problematic.\nThe method is based on the estimation of the differential entropy of the clusters. The estimation of the entropy is based on the assumption that data follows multivariate normal distribution, which I consider a rather strong and problematic assumption:\n\n- In many clustering problems data are not normally distributed\n- There can be problems in estimating covariance matrices in such high dimensional spaces\n- Better alternatives exist: for example, you can consider alternative non parametric bypass entropy estimators. Actually different studies have been conducted on estimating Entropies without making any assumption on the shape (which may be not realistic) and without a direct estimation of the density (which may be very problematic in high dimensional spaces). A starting example can be the non parametric bypass entropy estimator of the Renyi entropy proposed in:\n\nD. Pal, B. Poczos, and C. Szepesvari, \u201cEstimation of R\u00e9nyi entropy and mutual information based on generalized nearest-neighbor graphs,\u201d in Advances in Neural Information Processing Systems 23, 2010, pp. 1849-1857.\n\n\n2) Some comments on the experimental part.\n\n- All the experiments are based on text-images which are pre-encoded with deep net representations. Is this crucial for the applied method? In other words, how well this method could generalize to non-deep representations? What about the application on original representations of non-image and non-text datasets?\nMoreover, in the paper I did not find mention to the size of the embedding, which I guess is high (please report it in the paper). How does the method work in moderately dimensional datasets? I\u2019m sure that other methods would increase their performances. \nFinally: while for representation recent state-of-the-art methods have been used, for clustering only classic approaches have been considered, such as K-means, Dbscan, GMM and HC. What if we use more recent and better performing methods? Moreover, most of these methods are returning convex clusters (i.e. somehow following Gaussianity). \n\nWithout considering these three aspects it is difficult to assess the general applicability of the proposed method\n\n\n-  While the proposed criterion is meant to be used in internal validation, at the end the evaluation is based on external measures, i.e. accuracy and ARI. Of course it is a somehow standard and well established way, still it would be nice at least to discuss alternatives and (possibly) provide examples \u2013 like, for example, evaluation based on context knowledge, in the spirit of what is discussed in papers like: \nUlrike von Luxburg, Robert C. Williamson, Isabelle Guyon: Clustering: Science or Art? ICML Unsupervised and Transfer Learning 2012: 65-80\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written. One comment: authors qualitatively justify their approach using fig 1. I think that clusters of figure 1(b) are definitely not realistic: it is very rare that a clustering algorithm, given the data represented in figure, would output such clusters.\n\nFor what concerns novelty, maybe authors should refer and compare to other works in clustering evaluation which make use of Information theoretic concepts, like for example the (somehow old but just to give an idea):\nVinh, Epps, Bailey: Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance \nJournal of Machine Learning Research 11 (2010) 2837-2854 ",
            "summary_of_the_review": "Somehow interesting paper dealing with a crucial problem. The approach can be better contextualized, some assumptions (like Gaussianity of Clusters) are rather strong, and better alternatives exists.\n\nUPDATE AFTER REBUTTAL\nI carefully read the responses, the clarifications, and the additional material, and I thank the authors for the significant efforts made in clarifying my doubts. Even if I consider that the paper has potential, I\u2019ll maintain my score unchanged, since I still have some doubts, especially on the assumptions: even if I acknowledge the efforts made by the authors in improving this aspect in the rebuttal, I still consider that the Gaussianity assumption is rather strong, and that better alternatives exist.\n------",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2955/Reviewer_7KWv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2955/Reviewer_7KWv"
        ]
    }
]