[
    {
        "id": "LVcs9WJPFej",
        "original": null,
        "number": 1,
        "cdate": 1666537195433,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666537195433,
        "tmdate": 1666537195433,
        "tddate": null,
        "forum": "-94tJCOo7OM",
        "replyto": "-94tJCOo7OM",
        "invitation": "ICLR.cc/2023/Conference/Paper6206/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposed MCTransformer, a framework that combines Monte-Carlo Tree Search (MCTS) with the Transformer architecture in offline reinforcement learning. \nThe MCTS component is responsible for navigating and balancing the exploration/exploitation trade-off, while the Transformer component is responsible for evaluating the new states and also serves as a rollout policy to carry out the simulation phase of the MCTS.\nThe evaluation on SameGame shows that MCTrasnformer outscores Transformer-only and MCTS-only solutions.\n",
            "strength_and_weaknesses": "**Strength:**\nThe main idea of this paper is to combine Monte-Carlo Tree Search (MCTS) with the Transformer architecture in offline reinforcement learning. \n\n**Weakness:**\n- The method seems simply a combination of existing solutions (MCTS and Transformer) with limited novelty. Readers do not learn much from it. \n- Why does this paper choose the game of SameGame only to demonstrate their method? How about 2-player games?\n- In addition, the experiments are not convincing for the following. The authors only compare their method (a combination of Transformer and MCTS) with the random player, the Transformer-only and the MCTS-only. As a combination of existing solutions, the authors need to compare it with many other methods to support their claims. For example, those in Schadd et al. (2008); Takes & Kosters (2009); Schadd et al. (2012); Cazenave (2016); Seify (2020); Cazenave(2020). Even, it is probably more critical to compare with AlphaZero. More are listed as follows. \n  - To evaluate the effectiveness of MCTransformer on the SameGame, the authors should consider evaluating the proposed method with a standardized test set of 20 positions (these positions can be found at www.js-games.de/eng/games/samegame), which were reported in many prior works such as Schadd et al. (2008); Takes & Kosters (2009); Schadd et al. (2012); Cazenave (2016); Seify (2020); Cazenave(2020). \n  - Since the authors use offline data to train the Transformer policy, the author should compare the performance to other offline RL methods, or imitation learning methods (e.g behavior cloning).\n  - To show the effectiveness of using Transformer architecture in controlling the exploration and evaluation, the authors should compare the performance of using a Transformer architecture vs other deep neural network architecture.\n  - To show the effectiveness of the Transformer to carry out the simulation phase (i.e., the rollout policy) in MCTS, the authors should consider comparing the Transformer to heuristic-based policies or other learning-based policies.\n  - Since the author claims the effectiveness of using Transformer as the rollout policy, there is a need to describe the policy in the rollout phase of the MCTS-based method. For example: Is the rollout policy of the MCTS-based is a random policy or heuristic? And how many rollout simulations were performed at the selected leaves?\n\n**Comments for presentation:**\n- \u201cOur approach combines Monte-Carlo Tree Search (MCTS) with the Transformer architecture in an actor-critic setup\u201d is not well-explained in the paper.\n- Need more discussion for Table 3 and  Table 4.\n- Increase the font size of labels in Figure 1.\n- There are some typo mistakes and missing punctuations in the paper. For example: in the first line on page 5, the authors mentioned \u201cShefi\u2019s Seify & Buro (2022) maxmin value normalization method\u201d. Should \u201cShefi\u2019s\u201d be \u201cSeify\u2019s\u201d?\n\n\n**References**\n\n[1]The positions can be found at www.js-games.de/eng/games/samegame.\n Maarten PD Schadd, et al. Single-player Monte-Carlo tree search for SameGame. Knowledge-Based Systems 34, 2012\n\n[2] Cazenave Tristan. Nested rollout policy adaptation with selective policies. Computer Games. Springer, Cham, 2016.\n\n[3] Cazenave Tristan, et al. Stabilized nested rollout policy adaptation. Monte Carlo Search International Workshop. Springer, Cham, 2020.\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\nAlthough there are many typos and grammar errors in the paper, the presentation is easy to follow.\n\n**Quality & Novelty**\nThe work is technically correct, however, this work is simply a combination of Transformers and MCTs with limited novelty. Some additional experiments to justify the use of Transformer architecture in MCTS and offline reinforcement learning are needed.\n\n**Reproducibility**\nThe paper fully provides the information to reproduce the method and to obtain the results as reported, possibly with some effort.\n",
            "summary_of_the_review": "As described in the weaknesses above, it is hard to recommend this paper. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6206/Reviewer_scYv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6206/Reviewer_scYv"
        ]
    },
    {
        "id": "uEAej3YiOBN",
        "original": null,
        "number": 2,
        "cdate": 1666665214634,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666665214634,
        "tmdate": 1666665214634,
        "tddate": null,
        "forum": "-94tJCOo7OM",
        "replyto": "-94tJCOo7OM",
        "invitation": "ICLR.cc/2023/Conference/Paper6206/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes MCTransformer by incorporating Transformer into Monte-Carlo Tree Search. The MCTransformer is then applied to SameGame, and the experiments show that MCTransformer outperforms both Transformer-only and MCTS-only solutions.\n",
            "strength_and_weaknesses": "The main concern for this paper is the novelty. The authors simply used supervised learning to train the transformer network from the data generated by the MCTS-Based program on SameGame. Then, they apply the transformer network to MCTS. The structure is identical to AlphaGo/AlphaZero\u2019s setting except only replacing the neural network from Resnet to Transformer.\n\nBesides, the experiment is unfair and not convincing:\n- Without using neural networks, the MCTS-based program can execute more simulation counts. The author should provide more experiment results to show that the comparison is fair, e.g. comparing the experiment with the same time limit rather than simulation counts.\n- It is very common to combine the MCTS with neural networks, such as AlphaGo, AlphaZero, or MuZero. The authors should compare the MCTransformer to other MCTS-based programs with neural networks.\n\nOther minor issues:\n- The author should consider using MCTransformer to generate the training dataset (step#2 in Figure1) as AlphaZero did. Currently, the performance of MCTransformer may be bound by the MCTS-based program.\n- In Figure 1: The definition of the step#6 and step#7 are unclear.\n- In section 3.5, \u201c... standard MTCS difficult \u2026 \u201d should be \u201c... standard MCTS difficult \u2026\u201d.\n- In section 5.1, \u201cMTCS-based solutions \u2026\u201d should be \u201cMCTS-based solutions \u2026\u201d.\n- Does it require a lot of time for using the Transformer in the rollout?\n- It\u2019s meaningless to compare a well-trained network to a random play in Table 1.\n- The authors should try more simulation counts in the experiment in Figure 2 instead of using the regression line.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is easy to follow. The quality and novelty are poor. The author did not provide the source code for reproducibility. However, since the method is similar to AlphaZero, it is quite easy to reproduce it.",
            "summary_of_the_review": "The novelty of this paper is very poor. The structure is similar to AlphaGo/AlphaZero\u2019s setting except only replacing the neural network from Resnet to Transformer. Overall, I did not find any new results in this paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6206/Reviewer_cK37"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6206/Reviewer_cK37"
        ]
    },
    {
        "id": "95-V2Bisg8",
        "original": null,
        "number": 3,
        "cdate": 1667163210461,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667163210461,
        "tmdate": 1667163428240,
        "tddate": null,
        "forum": "-94tJCOo7OM",
        "replyto": "-94tJCOo7OM",
        "invitation": "ICLR.cc/2023/Conference/Paper6206/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work proposes to combine Decision/Trajectory Transformers (DTs) with MCTS, in order to improve the performance of DTs and also enable better exploration during online evaluation. The paper uses transformers as a prior policy for MCTS during the expansion phase, and also uses the same transformer to perform rollouts. The experiments are performed in the SameGame domain, which is a fully-observable Tetris like game with state-based inputs. The experiments show benefit over using using vanilla MCTS that learns only from monte-carlo returns.",
            "strength_and_weaknesses": "Strengths:\n* The paper tries to fix a key issue with Decision Transformers (DTs; transformers for sequence modelling of RL trajectories) like methods which is that they can't adapt easily at test time to explore more or improve their performance.\n* The particular setup of combining DTs and MCTS is novel, and I could see follow-up working building further on it.\n\nWeaknesses:\n* The writing and presentation is the paper is extremely unclear. The exposition of the method could be a lot better. See the below section for some suggestions. \n* The evaluation is extremely limited and non-standard, both in terms of the domains and algorithms. This makes is hard to assess if the original pitch of the paper empirically holds. \n  * The experiments performed are on a single, non-standard domain of SameGame which is relatively toy-ish as well. I would have liked seeing comparisons on more well-benchmarked domains like MiniGo or Atari. Similarly, there were no comparisons to DecisionTransformers or Online DTs which the paper supposedly improves upon.\n  * I am also not sure what to make of the MCTS comparisons, since from my understanding the paper doesn't use a learned prior policy or value function in the MCTS experiments (similar to AG/AGZ/Muzero), which makes the comparisons a bit unfair IMO. \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n  * The paper lacks clarity in exposition, and requires multiple passes to grok and connect ideas. \n  * Figure 1 should be self-explanatory with an elaborate caption. Nits: The font-sizes in the figure are extremely small. Some things like the rollout component in the figure are left unexplained (what's $rtg_\\pi(s_t)$?)\n  * The MCTS baseline needs more explanation as well. \n  * Consider using `citep` for inline citations so they land inside brackets. \n  * The word transformers is used very liberally, but remember that transformers as just an architecture and can be used in RL in a number of ways. This paper uses transformers to do sequential modelling of trajectories, which should be explicit rather than implicit. Consider replacing transformers by decision transformers or trajectory transformers to avoid the ambiguity. \n\nQuality:\n  * The paper starts off with a great idea, but lacks in execution and clarity.\n\nOriginality:\n * The idea and method itself are pretty original to my knowledge.",
            "summary_of_the_review": "This paper proposes an elegant idea to combine MCTS with Trajectory Transformers to enable the latter to perform online improvement / exploration. While the idea itself is promising, the paper lacks in empirical execution and evidence (it terms of the domains and compared algorithms). The writing and exposition itself need some work. Owing to these factors, I don't think the paper is ready for acceptance at this time, but I do see a lot of legroom in the idea itself so this could be a great paper once the issues are fixed. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6206/Reviewer_XF4h"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6206/Reviewer_XF4h"
        ]
    }
]