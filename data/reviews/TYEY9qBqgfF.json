[
    {
        "id": "xUaV8UryOl5",
        "original": null,
        "number": 1,
        "cdate": 1666384919678,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666384919678,
        "tmdate": 1668699049798,
        "tddate": null,
        "forum": "TYEY9qBqgfF",
        "replyto": "TYEY9qBqgfF",
        "invitation": "ICLR.cc/2023/Conference/Paper1664/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose BAFFLE, backpropagation-free federated learning (FL) framework that uses multiple forward processes instead\nof backpropagation. The main idea is to use Monte-Carlo approximation for stein's identity to approximate the analytical gradient. BAFFLE is mainly designed for two specific setups: low-resource edge devices, and FL systems with malicious clients. The authors prove convergence analysis for their estimator and show the effectiveness of their method in several FL setups (standard classification, robustness to attacks, and communication efficiency).",
            "strength_and_weaknesses": "Strength:\n* First, it is written clearly and relatively easy to follow. \n* Second, the goal of the paper (addressing cases of low-resource end devices and robustness to malicious clients) is important and refreshing. \n* Third, the method, which is relatively simple, is constructed in a thoughtful way to adjust for FL setups. It seems to work in a descent way compared to the standard FedAvg. \n* Forth, although not mandatory in my opinion, Thm 1 & 2 are a nice addition. \n\nWeaknesses/Questions:\n* As the authors stated, there is a noticeable drop in the model accuracy compared to FedAvg, but in my opinion it is fine for a first paper of this kind.\n* Some information is missing, how did you perform the data split between the clients? There are multiple strategies for that. How did you optimized the hyper-parameters of the model? Was there a validation set? The authors should present the Top-1 results for CIFAR-100 for completeness (even though they are probably not so good). \n* Did you consider Softplus as a continuously differentiable alternative to Relu?\n* Did you test how will the model perform in Personalized FL? It is especially interesting to show plots similar to those in Fig. 4 for real datasets that come from a different class distribution (as in PFL).\n* How will the model perform under a more realistic FL setup such as having 100 or 500 clients?\n* Can you quantify the computation gain (in terms of FLOPS or wall-clock time) compared to standard backpropagation?\n* A comparison to more recent baselines other than FedAvg is missing in my opinion.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear, has novel contributions and the results are reproducible (code was provided).",
            "summary_of_the_review": "In my opinion this is a nice paper that deals with an interesting learning setup. The proposed solution is elegant and seems to be relatively efficient.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1664/Reviewer_7JBh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1664/Reviewer_7JBh"
        ]
    },
    {
        "id": "HhMxw5DYjA",
        "original": null,
        "number": 2,
        "cdate": 1666553434026,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666553434026,
        "tmdate": 1668521441324,
        "tddate": null,
        "forum": "TYEY9qBqgfF",
        "replyto": "TYEY9qBqgfF",
        "invitation": "ICLR.cc/2023/Conference/Paper1664/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper presents a method to train federated learning using zero-order optimization. They use a gradient-free optimization approach and evaluate it on several benchmarks.",
            "strength_and_weaknesses": "Strengths:\n- The problem the paper addresses is important. A common use case for FL is with clients with limited computing. As such, the reduction in memory by avoiding backdrop can be significant.\n- The paper is clear and easy to follow\n\nWeaknesses:\n- Limited novelty: Mostly applies an existing zero-order optimization algorithm to FL\n- Limited experimentation: Only uses LeNet, which has very bad performance on cifar10/100 even for the ground truth model and WRN only on MNIST. Not enough to be convincing.\n- Inexact/misleading theoretical results: The authors ignore the dimension factor in both theorem 1&2 which is a critical factor especially as it is much larger than $\\sqrt{k}$. Also, in theorem 2 what we care about is the operator 2 norm of $\\hat{\\Sigma}$, so just the fact that each element has $1/\\sqrt{K}$ std around the desired value isn't enough (again will depend on the dimension). Ignoring the dimension is misleading, as there is no theoretical justification to use this approach with the given K values. The approach may empirically work well, but the theory doesn't support it.\n- Exaggerated claims: \n   The authors in several cases raise claims that, in my opinion, are not supported by the empirical data. For example, they claim that \n   \"BAFFLE achieves comparable performance to conventional FL using a relatively small value of K\". In CIFAR10/100 we see about 7% \n   drop in accuracy even when using K=500, i.e. 1000 forward passes. Running 1000 forward passes on low resource compute is a \n   considerable amount and 7% drop is a considerable degradation in performance. \n\n   They also \"assert that it is difficult to perform inference attack on BAFFLE\". The support for that is very limited at best. They show the \n   distribution of $\\Delta \\mathcal{L}$ is the same between val data and random noise, but I do not agree this shows robustness to \n   inference attacks. The model is trained during many update steps and has to acquire information regarding the task to succeed. The \n   authors need to show that reasonable attacks fail to claim such robustness. \n- Unclear use of TEE. TEE from my understanding is part of the infrastructure to run FL and is agnostic to the exact algorithm. As such, it is not clear why is it important to include as part of the work. If the TEE details are relevant, it should be explained better.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is mostly clear, although I would claim has misleading statements, and easy to follow. The quality of the experimental part is low and the novelty is small. The work is reproducible.",
            "summary_of_the_review": "The authors do now show empirical evidence to support their claims and as such I do not think this paper should be accepted.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1664/Reviewer_wGpR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1664/Reviewer_wGpR"
        ]
    },
    {
        "id": "f4UcFPaewV",
        "original": null,
        "number": 3,
        "cdate": 1666805649031,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666805649031,
        "tmdate": 1666805649031,
        "tddate": null,
        "forum": "TYEY9qBqgfF",
        "replyto": "TYEY9qBqgfF",
        "invitation": "ICLR.cc/2023/Conference/Paper1664/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a zeroth order Federated Learning method BAFFLE using forward only computations to replace back-propagation. The method intends to reduce memory storage and strengthen privacy against white-box vulnerability. The soundness of the finite difference method is justified by theory, experiments show that the method achieve comparable performance to conventional FL methods.    ",
            "strength_and_weaknesses": "Strength: \n- clear presentation\n\nWeakness: \n- Lack of novelty \n- Lack of convergence analysis \n- Lack of guidance on parameter choices and computational comparison \n- Limited experiments: shallow networks, iid environment ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is presented clearly and it is easy to follow.",
            "summary_of_the_review": "The paper proposes a zeroth order Federated Learning algorithm which is back propagation free. The main idea is to replace the gradient evaluation by zeroth order finite difference. This is very well known in zeroth order optimization literature. The more challenging part is to provide guidance on how to set the discretization stepsize and the number of samplings where the paper fail to provide any theoretical guidance. In particular, the more samples we draw, the more accurate the gradient estimation is, but the computational expenses will increase. The balance between the precision on the gradient estimation and the computational cost is a key for zeroth order method, which is a major omission of the paper. \n\nBesides the lack of convergence analysis, the experiment is also insufficient. Only shallow network are considered (two layers), it is expected that when the network goes deeper the gradient is more difficult to be estimated by zeroth order method (noise level increase), hence it will not be as competitive as gradient base method. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1664/Reviewer_EJwi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1664/Reviewer_EJwi"
        ]
    }
]