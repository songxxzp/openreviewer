[
    {
        "id": "TlEaHkfqC_7",
        "original": null,
        "number": 1,
        "cdate": 1666391032235,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666391032235,
        "tmdate": 1666391032235,
        "tddate": null,
        "forum": "NpZ7TIs6ws",
        "replyto": "NpZ7TIs6ws",
        "invitation": "ICLR.cc/2023/Conference/Paper1547/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper presents a neuron-based method to defense against backdoor attacks. They first identify less important neurons in the network and then purify them using a fine-tuning based method. The paper contributes to both the selection of less important neurons and in purifying the network. Compared to the common method of selecting less important neurons based on the activation magnitude, authors argued that activation ignores the strong connections that a neuron may have and may result in selecting important neurons as the least important neurons. The authors proposed Benign salience (BS) that ranks the neurons based on how they contribute to reducing the loss. The neurons that contributed the least are identified as bad neurons. The bad neurons are then purified using an improved fine-tuning strategy. The experiments show that the proposed method outperforms all the baseline methods.",
            "strength_and_weaknesses": "The results are promising.",
            "clarity,_quality,_novelty_and_reproducibility": "I had clarity issues while reading the paper. A major line of work identifying important neurons is missing.",
            "summary_of_the_review": "- I found the writing of the paper a bit problematic. It mentions WIPER as their method but then mainly presents BS as their method. I did not get whether WIPER refers to only improved fine-tuning strategy or it refers to BS plus improved fine-tuning strategy.\n\n- The paper mainly ignores various methods to identify the role of a neuron with respect to the prediction such as integrated gradient, deep lift, layer-wise relevance back propagation. Looking at just activation is indeed not the best way to identify important neurons but I would expect authors to compare their proposed method with the methods from the literature.\n\n- Figure 2 (left): The fine neurons that authors are getting could be the result of the BadNet method that it learns to cleanly separate the poison neurons. Testing gradient based methods on this model would clarify the benefit of BS in comparison to other methods.\n\n- (Section 4.2) I did not fully get the description of L1 and L2. L1 brings sparsity so it should turn the neurons will low weight/activations to zero quickly and L2 normalizes the spikes in the scores and it won't turn neurons to zero. Section 5.4 seems to be correctly discussing the effect of L1 and L2.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1547/Reviewer_1xEU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1547/Reviewer_1xEU"
        ]
    },
    {
        "id": "ARefdKZqPnW",
        "original": null,
        "number": 2,
        "cdate": 1666512186496,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666512186496,
        "tmdate": 1666512679199,
        "tddate": null,
        "forum": "NpZ7TIs6ws",
        "replyto": "NpZ7TIs6ws",
        "invitation": "ICLR.cc/2023/Conference/Paper1547/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a novel backdoor defense method (called WIPER) that includes: i) a new metric, called benign salience, to identify backdoored neurons; and ii) a new adaptive regularization mechanism to assist in purifying the identified bad neurons. ",
            "strength_and_weaknesses": "Strengths: \n- empirical evaluation and effectiveness, i.e. the proposed method yields better quantitative results than the included competitor methods.\n- relevant application: the fact of developing/designing safer and more resilient neural models is always welcome. \n\nWeaknesses: \n- not sure if technical/methodological novelty of this work with respect to the state-of-the-art is enough.\n- not sure if authors are comparing (quantitatively and qualitatively) with all relevant prior work. \n- the organization, presentation and writing of the paper.",
            "clarity,_quality,_novelty_and_reproducibility": "I think overall the paper is interesting and is acceptably clear. The main ideas and goals are clearly stated, and the results are positive. In my opinion, the experimental evaluation of the proposed method that tries to answer the 4 research questions posed is one of the main assets of the paper. However, I'm hesitant about the novelty and technical and methodological contribution of the proposed algorithm. \n\nIn terms of reproducibility, I'd say that the work is reproducible based on the main manuscript, the supplementary materials and the source code provided. \n\nFinally, there are several aspects related to the presentation/organization of the paper that could be improved:\n- the writing of the paper (to avoid typos like \"priro\" -> \"prior\" or \"decrease parameters to 0..\" -> \"decrease parameters to 0.\")\n- Table 4 is not referenced/commented in the body of the manuscript. \n- there is no global figure to introduce the whole approach and problematic in a visual manner (including an illustration of a backdoor attack). \n- the algorithm employed to describe the proposed paper is included in Supplementary Materials, and not in the main paper.\n- captions of some figures are not particularly informative. For instance, in Figure 1. ",
            "summary_of_the_review": "See \"Clarity, Quality, Novelty And Reproducibility\" Section of this review. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1547/Reviewer_etm6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1547/Reviewer_etm6"
        ]
    },
    {
        "id": "yiG95VAI4xB",
        "original": null,
        "number": 3,
        "cdate": 1666606862916,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666606862916,
        "tmdate": 1666607276085,
        "tddate": null,
        "forum": "NpZ7TIs6ws",
        "replyto": "NpZ7TIs6ws",
        "invitation": "ICLR.cc/2023/Conference/Paper1547/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a measure to distinguish benign neurons and malicious neurons. Based on the measure, the authors identify the malicious neurons and update their parameters. Experimental results show the effectiveness of the proposed method.",
            "strength_and_weaknesses": "**Strength**\n1. The empirical results demonstrate the effectiveness of the proposed method.\n2. If I understand correctly, the author defines the importance of a weight parameter using the element-wise product of the weights and their gradients. There is a similar formulation (element-wise product of the input and the gradient) in Saliency Maps [1, 2]. If we could find the similarities between them, it must be very interesting.\n\n**Weakness**\n1. This paper is written badly and requires major revision. I have a terrible time understanding this paper. For example, when citing related works, please use brackets \u201c(\u201d & \u201c)\u201d in most cases to include them, i.e., use \\citep in Latex.\n\n2. It is difficult to understand the formulation of Eqn (2). \n- Since DNN has an extremely large number of parameters, close-to-zero initialization still result in different loss compared to zero-initialization. Why could we replace  $L_{D_c}(w_0)$ with  $L_{D_c}(0)$?\n- In this formulation, BS is defined for the whole model and every neuron share this value inside the model. So how can we distinguish neurons using this shared BS? Is the neuron-wise BS defined as the sum of the products of the parameters and their derivatives inside a specific neuron?\n\n3. Where is Figure 4 in Sec 5.4?\n\n4. If this paper regards it as a pruning method, it neglects an important work, ANP [3]. Since this is another pruning-based method, this paper should compare it.\n\n[1] Avanti Shrikumar, Peyton Greenside, Anna Shcherbina, and Anshul Kundaje. Not just a black box: Learning important features through propagating activation differences. arXiv preprint arXiv:1605.01713, 2016.\n\n[2] Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz Hardt, Been Kim. Sanity Checks for Saliency Maps. In NeurIPS, 2018.\n\n[3] Dongxian Wu and Yisen Wang. Adversarial Neuron Pruning Purifies Backdoored Deep Models. In NeurIPS, 2021.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper misses many details to help readers to understand. Thus, it requires a major revision.\n",
            "summary_of_the_review": "This paper misses many details and is hard to understand. Even if the proposed method might be promising, the author should clarify it well. In my opinion, it requires a major revision. Thus, I recommend rejecting this paper.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1547/Reviewer_krJA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1547/Reviewer_krJA"
        ]
    },
    {
        "id": "RPkMTCOSSM",
        "original": null,
        "number": 4,
        "cdate": 1666668642144,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666668642144,
        "tmdate": 1666668642144,
        "tddate": null,
        "forum": "NpZ7TIs6ws",
        "replyto": "NpZ7TIs6ws",
        "invitation": "ICLR.cc/2023/Conference/Paper1547/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors proposed a novel backdoor defense, which used first-order gradient to identify bad neurons using clean dataset. Also, a new Adaptive Regularization (AR) mechanism is used to fine-tune the model using detected bad neurons. They performed experiments on ten different backdoor attacks with three benchmark datasets. Their proposed method has performed better than other six state-of-the-art defense methods. ",
            "strength_and_weaknesses": "Strong Points:\n\n1. A novel a gradient-based detection method of bad neurons.\n2. The method focused on the last fully connected layers to remove backdoor. \n3. A new Adaptive Regularization (AR) mechanism is proposed to assist in purifying these identified bad neurons via fine-tuning.\n4. Extensive experiment results illustrated the good performances. \n\nWeak point:\n\nThere is a paper published at CCS 2021: \u201cAI-Lancet: Locating Error-inducing Neurons to Optimize Neural Networks\u201d. This paper also considered gradient during finding bad neurons. They also achieved good results with respect to accuracy and ASR. Authors have not mentioned this paper nor compared with. They should include this paper for comparison to prove the effectiveness of their method. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity, Quality, Novelty And Reproducibility are acceptable. ",
            "summary_of_the_review": "The authors used clean data to detect bad neurons and designed a new Adaptive Regularization (AR) mechanism for finetuning. However, they failed to mention and compare a very similar approach published in CCS\u201921, which also achieved good clean accuracy, ASR. Since these two algorithms are belongs to the same category. Lacking this comparison makes its contribution not clear.  ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1547/Reviewer_pBHg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1547/Reviewer_pBHg"
        ]
    }
]