[
    {
        "id": "-6NkJnUU1U",
        "original": null,
        "number": 1,
        "cdate": 1666239669753,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666239669753,
        "tmdate": 1668411037067,
        "tddate": null,
        "forum": "mjzm6btqgV",
        "replyto": "mjzm6btqgV",
        "invitation": "ICLR.cc/2023/Conference/Paper3334/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper provides an efficient algorithm to compute the Nash Equilibria in an adversarial team Markov game. Specifially, in this zero sum Markov game, a team of players try to gain reward as much as possible, and an adversary tries to lose reward as less as possible. The authors propose an algorithm called IPGMAX. In this algorithm, all the team players will first do policy gradient descent for several steps, and this procedure returns the team players' policies in Nash Equilibria. Then the algorithm uses a procedure to look for the response of the adversarial policy (to the team players' policies). The authors show that, team players' policies as well as the the response of the adversarial policy form a Nash Equilibria, and the time cost of the algorithm is polynomial, which can be much better than the exponential ones in prior works. ",
            "strength_and_weaknesses": "Strength\n\nLooking for Nash Equilibrias in Markov Game is an important task, and reducing the time complexity from exponential to polynomial is also a significant contribution.\n\nWeaknesses\n\nThere are many parts not very clear in the IPGMAX algorithm (for details please see the questions below)\n\nMy Questions\n\n1. Proposition 3.1 shows that there must exists such a $t^*$, and Corollary C.1 shows that with high probability, there is one such $t^*$ in the randomly chosen set. However, it is still not very clear to me that how you can find this $t^*$ is this set. Do you mean that it is easy (with low computation cost) to check whether $x^{t}$ is good or not? How much is the computation cost here?\n\n2. In line 6 of Algorithm 1, we need to look for the best response of the adversary. What is the computation cost here?\n\n3. In line 7 of Algorithm 1, we need to compute the gradient of $V_{\\rho}$. What is the computation cost here?\n\n4. It is mentioned that the IPGMAX algorithm is a decentralized one (which may avoid communications between players), but I am wondering whether line 6 and line 7 in Algorithm 1 could be done without any communications? Do you mean that these steps could be done even if all the players (e.g. the team players) do not know others' policies in the last time step?\n\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "I think there are some problems about clarity (see the Questions above).",
            "summary_of_the_review": "Overall, I have some questions about the algorithm in this paper, and give the score of \"weak accept\". I'd like to see the answers from the authors and I will change my score if the answers are convincing. \n\n=========After Rebuttal=========\n\nThe rebuttal explains about the details, and now I can understand how the algorithm works. I believe those details should also be included in the final version, so that the readers can easily understand it as well. \n\nMy remaining concerns (which are also mentioned by the other reviewers) are about the existance of the oracle and whether the given complexity upper bound is tight. I think some further works about the tightness could be done in the future. \n\nOverall, I agree that this work is an important step in efficiently looking for the Nash Equilibria in Marcov Games, and I would like change my score to \"accept\".\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3334/Reviewer_V4b6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3334/Reviewer_V4b6"
        ]
    },
    {
        "id": "twJixwP2en",
        "original": null,
        "number": 2,
        "cdate": 1666645792910,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666645792910,
        "tmdate": 1666645792910,
        "tddate": null,
        "forum": "mjzm6btqgV",
        "replyto": "mjzm6btqgV",
        "invitation": "ICLR.cc/2023/Conference/Paper3334/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper considers multi-agent Markov games; specifically, the problem of computing a Nash equilibrium. Even in normal-form games, it is computationally intractable to compute a Nash equilibrium in two-player general-sum games, much less in games with more players. In this paper, the game is restricted to coalition of players with a common adversary, so-called \"adversarial team Markov games\". In addition to the case when the coalition shares a common objective, the results extend to the case in which the objectives of the coalition share a common potential function (Markov potential games). ",
            "strength_and_weaknesses": "# Strengths\n- The paper introduces the first poly-time algorithm to compute a Nash equilibrium in the setting of adversarial team Markov games. Computing a Nash equilibrium is an important practical problem, but unfortunately the general-case is difficult. Therefore, it is useful and relevant to consider special cases such as the coalition considered here.\n- The algorithm has good scaling with the action sets of each agent; that is, it scales with their sum rather than the product.\n- The techniques used to obtain this result are well described at an overview level and compared to the most relevant related work which is to compute a Nash equilibrium in the analogous normal-form setting. The challenges in generalizing the normal-form setting to Markov game include: nonlinear program with a set of nonconvex constraints, which requires the Arrow-Hurwiz-Uzawa constraint qualification technique.\n\n# Weaknesses\n- The type of game considered is very special. It is only a modest generalization of two-player zero-sum games. More practical would be algorithms that have exponential worst-case but still run on practical examples of n-player Markov games. Still, any generalizations from fully cooperative or competitive two-player games are welcome.\n- The practical scalability of the algorithm is not evaluated. Although it is polynomial, the number of iterations looks very large from inspection of the pseudocode.  Still, this is a theoretical work, so this isn't too significant of a weakness.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "+ The paper is written very clearly and is well organized.\n+ The novelty is put into context well and is clear.",
            "summary_of_the_review": "Based on the above strengths and weaknesses, the paper clearly is in the \"Accept\" category.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3334/Reviewer_1bpS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3334/Reviewer_1bpS"
        ]
    },
    {
        "id": "T4VHUDABob",
        "original": null,
        "number": 3,
        "cdate": 1666661722895,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666661722895,
        "tmdate": 1666661722895,
        "tddate": null,
        "forum": "mjzm6btqgV",
        "replyto": "mjzm6btqgV",
        "invitation": "ICLR.cc/2023/Conference/Paper3334/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies a zero-sum team Markov game. In the game, a team of agents compete with an adversary. Agents in the team have the same reward function, and the sum of the team and the adversary's rewards is zero. The paper in particualr looks at a class of potential games. The main contribution of the paper is to propose a set of algorithms to compute a stationary epsilon-Nash equilibrium of the game. ",
            "strength_and_weaknesses": "Strength: \n\nThe problem is well-motivated and the paper is written well overall. The proposed approach to computing an approximate Nash equilibrium looks non-trivial and brings in many interesting concepts. The authors also provide a good summary about the related work.\n\nWeakness: \n\n- Section 3.3 could have been improved to make the main idea clearer. It is unclear to me what is the main advantage of the proposed methods? In particular, why not just solve Q-NLP without the regularizer in the objective function, which gives a Nash equilibrium directly and seems much more manageable than the current formulation?  \n\n- The approach relies on an oracle to tackle a computational obstacle, which may be crucial. This further deepens the question of how meaningful the proposed methods are compared with solving Q-NLP without the regularizer --- now that there's an oracle to use, so supposedly it also simplifies the problem of solving Q-NLP without the regularizer.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity could be improved in some parts of the paper. The results look novel and very technical.",
            "summary_of_the_review": "A paper on a well-motivated problem, overall well written but with some issues on the clarifty. Results are comprehensive and very technical, but with some weaknesses that raise questions about how meaningful the results are, which may or may not be crucial. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3334/Reviewer_S2Qp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3334/Reviewer_S2Qp"
        ]
    }
]