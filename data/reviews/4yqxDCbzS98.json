[
    {
        "id": "g-uKgOPgBtf",
        "original": null,
        "number": 1,
        "cdate": 1666435694525,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666435694525,
        "tmdate": 1669811417903,
        "tddate": null,
        "forum": "4yqxDCbzS98",
        "replyto": "4yqxDCbzS98",
        "invitation": "ICLR.cc/2023/Conference/Paper2764/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper presents a new way of doing object detection with weak supervisions. The model proposed is called ProbKT and it allows any object detection model to be trained on a general and rich source domain, and then transfer the acquired knowledge on a weakly annotated target domain. The novelty of this work lies in the fact that it allows to train object detection models with arbitrary types of weak supervisions. ",
            "strength_and_weaknesses": "**Strengths:**\n\n1) The paper addresses the important problem of training object detection models with weak supervisions\n2) It is the first paper to allow for more complex weak supervisions\n3) The experimental analysis is comprehensive and well documented\n\n**Weaknesses:**\n\n1) The authors seem to be sweeping under the rug their reliance on DeepProbLog. Indeed, if I understood correctly, the reasoning and backprogation is done through the DeepProbLog framework. If this indeed the case then it needs to be made clearer and a short introduction on the framework should be given. \n2) It is not clear the exact expressivity admitted by the weak supervision, is it only limited to rules? Is it full first order logic?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Novelty:**\n\nThe paper seems novel and relevant. \n\n**Clarity:**\n\nThe paper could improve in its writing. \nSome things could be: \n    1. Introduce better DeepProbLog and clarify how the model relies on it\n    2. Move the related work, right now it is in the middle of the paper\n\n**Reproducibility:**\n\nThe authors have made the code available.\n\n**Future work suggestion:**\n\nA dataset for action detection in autonomous driving has just been released with a broad set of propositional logic constraints in [1]. Maybe in the future this framework could be applied in the autonomous driving field. \n\n**Minor suggestion:** \n- specify the query $q$ in the image\n\n[1]  Eleonora Giunchiglia, Mihaela Catalina Stoian, Salman Khan, Fabio Cuzzolin, Thomas Lukasiewicz. ROAD-R: The Autonomous Driving Dataset with Logical Requirements. Machine Learning, 2022.",
            "summary_of_the_review": "**TL;DR:** the paper seems novel and relevant. however, its relationship with deepproblog needs to be clarified ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2764/Reviewer_tNrs"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2764/Reviewer_tNrs"
        ]
    },
    {
        "id": "Nj6jzWNm5f",
        "original": null,
        "number": 2,
        "cdate": 1666590522266,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666590522266,
        "tmdate": 1666590522266,
        "tddate": null,
        "forum": "4yqxDCbzS98",
        "replyto": "4yqxDCbzS98",
        "invitation": "ICLR.cc/2023/Conference/Paper2764/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces a new method for weakly supervised object detection with knowledge transfer, termed ProbKT. The basic idea is formulating the weakly supervised detection problem as the probabilistic logical reasoning so that the detector can be trained with arbitrary types of weak supervision.  The output of the detector is fed into a neural probabilistic logical reasoning module. Several modifications are also proposed to reduce the computational cost of probabilistic programing specifically for object detection. Experiments show that ProbKT outperforms WSOD-transfer [41] and several baselines on CLEVR-mini, Molecules, MNIST on both detection and counting tasks.",
            "strength_and_weaknesses": "# Strengths\n+ By formulating the weakly supervised object detection as the probabilistic logical reasoning, a unified detection method can be trained on dataset with different supervision signals, which is a novel approach for weakly supervised knowledge transfer.\n+ The paper presentation is clear, with well-defined terms and concepts.\n+ Ablation studies are thorough. The effects of proposed components are validated on several datasets.\n# Weaknesses\n- It would be great if the method can be evaluated on datasets with real world objects like COCO or LVIS.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: 8/10, paper is well written.\n\nQuality: 7/10.\n\nNovelty: 7/10.\n\nReproducibility: 9/10, code is released.\n",
            "summary_of_the_review": "Based on the novelty, the clarity and the thorough experiments, this paper is good for acceptance at ICLR.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2764/Reviewer_q7Gr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2764/Reviewer_q7Gr"
        ]
    },
    {
        "id": "CiF_mfQG_lt",
        "original": null,
        "number": 3,
        "cdate": 1666706480301,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666706480301,
        "tmdate": 1666706480301,
        "tddate": null,
        "forum": "4yqxDCbzS98",
        "replyto": "4yqxDCbzS98",
        "invitation": "ICLR.cc/2023/Conference/Paper2764/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a framework based on probabilistic logical reasoning that allows to train object detection models with arbitrary types of weak supervision. The proposed architecture consists of two components: symbolic reasoning and deep learning architecture. \nSuch a structure is easy to implement weakly supervised learning in the target domain. Experimental results are given to demonstrate the good performance of the proposed model.  \nThe main contribution of the paper is the incorporation of knowledge from other domains into object recognition framework. It is beneficial to use the proposed ProbKT to improve recognition performance on target domain and better generalization compared to existing baselines. \n\n",
            "strength_and_weaknesses": "The paper proposes a new framework that incorporates probabilistic logical reasoning method into the object detection models. \nStrength:  Such a structure is easy to implement prior knowledge from other domains into deep learning models, is also able to train object detection models by leveraging richly annotated datasets from other domains and allowing arbitrary types of weak supervision on the target domain. \nWeakness: \nAlthough the proposed architecture integrates symbolic reasoning into deep learning architecture, it is still unclear from theoretical point of view that why the relabeling will provide performance improvement during symbolic reasoning. \nWith regard to \"weakly supervises learning\", the paper provides a simple example \"The sum of all digitals in the image is considered as weak supervision\". How does the cost function is implemented in the probabilistic logical reasoning stage\nThe proposed model includes the probabilistic reasoning procedure, which is of higher computational complexity. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and is novel in two points: the use of prior knowledge from other domains into object detection and learning in the second procedure is implemented in weakly supervised way. ",
            "summary_of_the_review": "The use of probabilistic logical reasoning for improving the performance of object detection is interesting topic in the AI society.  The integration of probabilistic logical reasoning and deep learning model results in performance gain for object detection.  ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2764/Reviewer_Mz4p"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2764/Reviewer_Mz4p"
        ]
    },
    {
        "id": "_Evfbskehz",
        "original": null,
        "number": 4,
        "cdate": 1666765225102,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666765225102,
        "tmdate": 1669162024576,
        "tddate": null,
        "forum": "4yqxDCbzS98",
        "replyto": "4yqxDCbzS98",
        "invitation": "ICLR.cc/2023/Conference/Paper2764/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Detailed annotations are often not available in practice, and only high-level image information is available on the target dataset; this work presents a fine-tuning method using ProbKT to update object detection models from a pre-trained architecture. Nevertheless, the presented knowledge transfer method can be built upon arbitrary types of weak supervision on the target domain, such as complex logic statements. The authors empirically show on three types of datasets that fine-tuning with ProbKT leads to significant improvement in the target domain and gives better generalization compared to existing baselines.",
            "strength_and_weaknesses": "Strength:\n1. The introduced method for weakly supervised knowledge transfer learning is quite interesting. \n2. The introduced method allows arbitrary types of supervision on the target domain can greatly alleviate the annotation burden.\n3. Extensive experiments show the proposed method is quite effective.\n\nWeakness:\n1. The idea has been published before, and I do not see improvement or substantial differences over the published one.\n\n2. The experiments are conducted on simpler content datasets, like MNIST. I expect some explanation of how to use the ProbKT for large-scale and complex content datasets on object detection, ex: what will the queries look like? \n[ Authors provided feedback on this question, for instance, they said the model could be supervised on the count of detected objects, etc., on the COCO dataset. However, this counting information is already provided from the ordinary ground truth. Specifically, the number of bounding boxes for objects already provided the model with object counts. Therefore, when you supervised the model with queries like, \u201cthere are at least 5 dogs in this image\u201d or \u201cthere are more humans than animals in this image,\u201d what additional information did we provide to the model? In other words, I am still not fully convinced of the author's answer.]\n",
            "clarity,_quality,_novelty_and_reproducibility": "1. The Novelty part is great; however, the paper content is almost identical to one paper in ICML2022 WORKSHOP - Updating Object Detection Models with Probabilistic Programming, and there is no citation to this paper.\n2. The content clarity is fine but can be further improved if the core idea - ProbKT can be explained with more examples on common benchmark object detection datasets. \n3. The reproducibility is good from the authors' released code.\n",
            "summary_of_the_review": "Overall, the presented idea is novel and helps equip the model with logical reasoning as humans on arbitrary input. The experiments show its effectiveness, especially I can imagine it can help more when the quantity of the dataset is not large enough to train a robust model.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "Yes, Other reasons (please specify below)"
            ],
            "details_of_ethics_concerns": "Extensive content overlaps with the paper \" \"Updating Object Detection Models with Probabilistic Programming,\" even the write-up is copied from the paper.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2764/Reviewer_ijtT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2764/Reviewer_ijtT"
        ]
    }
]