[
    {
        "id": "vA_ZyNTw14M",
        "original": null,
        "number": 1,
        "cdate": 1666646818095,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666646818095,
        "tmdate": 1666646844531,
        "tddate": null,
        "forum": "7NUTyhyQt9x",
        "replyto": "7NUTyhyQt9x",
        "invitation": "ICLR.cc/2023/Conference/Paper5449/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper raises a gap in current OOD detection approaches that rely too heavily on the training examples, and falsely mark images out of the train set but with similar semantic meaning. \n\nThe authors coin the term \"intended distribution\" to capture both the training set, but also the rest of the \"semantically similar\" data.\nTwo baseline approaches are proposed to close this gap and estimate the intended distribution:\n- using semantic segmentation, or more precisely the mean confidence of the resulting map. two flavours are proposed: either directly (BS) or via the ODIN method (OS) as a preprocess to the map.\n- using a reference set, or more precisely find the most similar reference image in the SSIM sense and use the latter measure as an OOD indicator.\n\nThe experimental section compares the proposed methods to several SOTA methods from three categories of OOD techniques: supervised, unsupervised, and self-supervised.\n\nThe proposed baselines are",
            "strength_and_weaknesses": "### Strength \nThis paper shows a failure case for existing approaches on semantially similar data, and that a seemingly na\u00efve approach is much less susceptible to such a case. \n\nThe paper attempts to formalize the problem in a very rigorous manner, based on 3 reasonable assumptions in the bottom of page 3.\n\n\n### Weaknesses\nIt is not clear to me that the proposed approaches actually estimate the intended distribution.\nWhile theorem 1 is very attractive, I am missing\n- A design choice that shows the proposed algorithms are alinged with the 3 assumptions, or in any way aimed at the elusive distribution?\n - (in light of theorem 1) why is estimating the training distribution dissimilar than estimating the intended one?\n- And therefore - a non-empirical indication that prior works do not actually estimate the intended \n- For the reference set baseline - why is selection of **one** representative enough? is there a theoretical justification?\n\nSmaller notes\n- clarity of notation, e.g. try to avoid using x' as the result of the map N(x) - this is confusing\n- the definition of S' in the end of definition 1 is hard to read - stating it is a softmax *before* the expression might make the sentence more fluent.\n- \"Unif\" in the end of the SSIM section is not defined.\n- page 5 line 2 - did you mean \"of _pixel_\" rather than \"of _image_\"?",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity\n\nThis paper is written in a clear language but was hard for me to follow and I needed a few passes.\nSince this might be the due to the way the mathematical expressions are not fluent in the text, e.g. the one I mention above:\nthe definition of S' in the end of definition 1: stating it is a softmax *before* the expression might make the sentence more fluent.\n\n---\n\n### Quality\nThis paper seems to ignore some recent works that are not post-hoc.\nFor example, [Energy-based Out-of-distribution Detection](https://proceedings.neurips.cc/paper/2020/hash/f5496252609c43eb8a3d147ab9b9c006-Abstract.html) which shows that the softmax score is not the best predictor of OOD - is this the column in Table 1? if so, please add the citation.\n\n---\n\n### Novelty\n\nThis paper tackles a known problem but defines it in a formal manner with the assumptions leading to Theorem 1.\nThe proposed baseline approaches are made of known existing building blocks - so he main novelty here, hence, is the combination thereof to solve this problem. \n\n---\n\n### Reproducibility\n\nThis paper uses off-the-self tools to construct the baselines. Reproducing the described methods and experiments will not be easy but certainly possible for a talented grad student.",
            "summary_of_the_review": "The paper shows a failure case of exiting OOD approaches and naive baselines that compete well in these scenarios.\nWhile I possibly misunderstand some parts of the theoretical claims (as in- can the intended actually be estimated), the empirical part should be enough to create a discussion in the community.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5449/Reviewer_sQTF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5449/Reviewer_sQTF"
        ]
    },
    {
        "id": "nyH4YsK5bd",
        "original": null,
        "number": 2,
        "cdate": 1666689147298,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666689147298,
        "tmdate": 1666689147298,
        "tddate": null,
        "forum": "7NUTyhyQt9x",
        "replyto": "7NUTyhyQt9x",
        "invitation": "ICLR.cc/2023/Conference/Paper5449/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper argues that semantic information should be considered for OOD detection which should not be just tied to the training data distribution. This argument is interesting and practically useful. Then the authors proposed to leverage the semantic segmentation network and reference set to detect OOD data semantically. Experiments are done on COCO and MNIST datasets.",
            "strength_and_weaknesses": "The proposed problem is meaningful and interesting. However, here are some questions:\n- This paper attempted to introduce the complex notations in Section 2 to define semantic information for OOD detection. However, it is unclear what the exact definition of semantics is. \\delta and \\eta in assumptions are not sufficient to clarify the meaning of semantics. It would be good to share detailed examples for the given definition.\n- In addition, the notations in Section 2 and 3 would be better to be simplified and the writing of this part can be significantly improved to make it more understandable and readable.\n- In OOD detection, the proposed method is heavily dependent on the segmentation network. The experiments are tested on relatively simple datasets and show improvements. In practice, what if the dataset is complex and the segmentation network does not perform well? Moreover, compared with OOD detection, segmentation does not seem to be simpler to solve than OOD detection when data has a large variety. It is not very convincing to heavily rely on segmentation results to detect OOD.\n- The experiments should be conducted on more complex datasets. The evaluations on the same datasets in existing OOD papers are expected.",
            "clarity,_quality,_novelty_and_reproducibility": "Please see the above Strength And Weaknesses section.",
            "summary_of_the_review": "Please see the above Strength And Weaknesses section.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5449/Reviewer_iQtU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5449/Reviewer_iQtU"
        ]
    },
    {
        "id": "rH5ZtT4Aazv",
        "original": null,
        "number": 3,
        "cdate": 1666883003131,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666883003131,
        "tmdate": 1666883003131,
        "tddate": null,
        "forum": "7NUTyhyQt9x",
        "replyto": "7NUTyhyQt9x",
        "invitation": "ICLR.cc/2023/Conference/Paper5449/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper makes the argument that current OOD detectors are faulty since they are tied to the bias in the data collection process. The authors show examples where several existing OOD detectors would have classified an auxiliary test data set as OOD, but the classifier performs well on those examples.  The authors argue that the auxiliary test data set should not have been OOD in the first place since humans could have classified the data correctly using the class labels for the original dataset. \n\nThey also propose a new OOD detector that does not classify that auxiliary dataset as OOD. Some theoretical basis for the results is also presented.\n\n\n\n",
            "strength_and_weaknesses": "The thesis in the paper is provocative in that it is arguing that all the previous OOD detectors are based on a faulty premise that the training data reflects the true distribution (unknown) and thus all OOD detectors are biased; furthermore, they argue that the bias can be corrected -- at least for image classifiers.\n\nI think that any bias in the training data is going to be reflected in the OOD detector is a reasonable thing to expect -- so that statement is not a surprise. That is true for machine learning models trained on a dataset as well -- the models have a similar bias. That is why having good training sets is usually important. \n\nBut, the paper also proposes algorithms which appear to do a better OOD detection. Unfortunately, this is where the paper falls seriously short.   The authors essentially make a one-sided argument that their OOD detector is a better detector overall because it does not classify the custom dataset that the authors constructed (which has high accuracy) on a custom model that the authors trained with blended data as OOD dataset.\n\nBut, it is also likely trivial to construct counter-examples for the authors' OOD detector below: \n\nAuthor's Premise: The authors used a model that was trained on  96.77% MNIST-M and 3.23%  BC-MNIST dataset and argued that it still accurately classifies BC-MNIST dataset, but several existing OOD detectors classify the BC-MNIST dataset as OOD, but their OOD detector does not.  Therefore, their OOD detector is superior.\n\nCounter-example to the author's premise: Let's say instead the model was trained 100% on MNIST-M (or even more extreme case, 100% original MNIST). It seems that the OOD detector by the authors would still call BC-MNIST data as in-distribution because of all the pre-processing described in the appendix that does segmentation into foreground/background and converts colors to black and white.  But in that case, I suspect either of the ML models would perform horribly on the BC-MNIST dataset while the authors' model would predict the BC-MNIST as in-distribution dataset.  So, overall, the experiments are not conclusive in showing the value of the approach.\n\nThe OOD algorithm by the authors is also complex and has a lot of priors built-in. For instance, use of segmentation to separate foreground and background and then removal of colors makes assumptions about the domain. For instance, the authors assume that segments placed away from the center are semantically irrelevant (A.4). These are priors. If they were known, potentially, a classifier should be trained on pre-processed data.  In that case, existing OOD detectors should work well since pre-processing would be part of the model.\n\nI also encourage authors  to evaluate their OOD on situations on which prior OOD methods were evaluated.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The writing is pretty clear. But the paper falls short on empirical results. Much more experimentation is needed and they failed to convincingly show that their OOD detector is superior to existing ones.\n\nThey did show that existing OOD detectors can report some data as OOD even if the classifier can classify it with reasonable accuracy. But, they failed to acknowledge that  their OOD detector can conversely treat data as non-OOD but the model cannot classify it properly. ",
            "summary_of_the_review": "Interesting idea, but validation falls short.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5449/Reviewer_mNjq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5449/Reviewer_mNjq"
        ]
    },
    {
        "id": "8od66TVMsu",
        "original": null,
        "number": 4,
        "cdate": 1667249222225,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667249222225,
        "tmdate": 1667249406117,
        "tddate": null,
        "forum": "7NUTyhyQt9x",
        "replyto": "7NUTyhyQt9x",
        "invitation": "ICLR.cc/2023/Conference/Paper5449/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents a discussion on the definition of the in-distribution (ID) vs. out-of-distribution (OOD) for OOD detection problems, arguing that existing methods fail to semantically extrapolate the in-distribution (e.g. the ID of flying and sitting birds should include and generalize to various backgrounds, e.g. sky, woods, water, etc.). The paper calls such a \"semantically complete\" characterization of the ID the \"Intended Distribution\". Following this argument, the paper proposes to leverage semantic segmentation networks for OOD detection generalizing to the intended distribution. Here, classification OOD methods (e.g. maximum softmax or ODIN) are proposed to be used over the pixels in the foreground, whereas pixels in the background attain the max OOD score. An experimental evaluation on COCO and Vizwiz is presented showing that the proposed methods compares favorably over previous approaches in the intended distribution OOD detection task.",
            "strength_and_weaknesses": "*Strengths*\n+ The paper contributes some helpful conceptual structure for thinking about OOD detection, essentially discussing the balance of OOD detection vs. generalization, arguing that OOD detection should generalize to semantically coherent classes (disregarding potentially spurious background correlations)\n+ The paper is well motivated and integrated into the existing literature.\n\n*Weaknesses*\n- The proposed method essentially defers OOD detection for classification to a segmentation problem, which requires more granular information (pixel-/object-level annotations). I think this aspect is not communicated clearly in the paper yet, and I think to some degree the reported improvements are expected, given the proposed model uses much more semantic information from a segmentation model.\n- On the other hand, the paper does not seem to put in much effort in testing the limits of well trained segmentation models (\"[...] as improving the training of segmentation network is beyond the scope of this paper.\"), which presents the foundation of the proposed approach. Here, I think the paper should go deeper in exploring the strengths and limits of this approach.",
            "clarity,_quality,_novelty_and_reproducibility": "+ The paper is overall well written and easy-to-follow.\n+ The paper seems to include all the details necessary to reproduce the presented results.\n\n* I find the novelty of the paper to be fair, though OOD generalization vs. detection has also been discussed in previous works.\n\n- The paper includes some technical inaccuracies, e.g. an \"AUROC less than 50% [...] implies that the proposed detector is not able to distinguish between the test COCO and Clear Vizwiz datasets.\" is false. A detector cannot distinguish and is random at an AUROC of 50%. Below 50%, the ranking becomes inverse.\n\n---\n\n*Additional Comments*\n* In the definition of the function $S$, the first case should only be on $\\{1, ..., N\\}$, right?\n* Strictly speaking, $C$ in the definition of $\\mathcal{F}$ is not defined on $\\mathcal{X}'$, but only $\\mathcal{X}$, right?",
            "summary_of_the_review": "The paper presents some interesting and valid discussion on OOD detection vs. generalization, proposing to leverage segmentation networks to improve OOD detection that generalizes to semantically coherent classes. However, cost aspects of requiring more granular information for segmentation are not yet sufficiently addressed and discussed in my opinion.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5449/Reviewer_fcgs"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5449/Reviewer_fcgs"
        ]
    }
]