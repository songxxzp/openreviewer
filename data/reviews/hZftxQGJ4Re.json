[
    {
        "id": "Sncm0SxerCd",
        "original": null,
        "number": 1,
        "cdate": 1666568890183,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666568890183,
        "tmdate": 1666568890183,
        "tddate": null,
        "forum": "hZftxQGJ4Re",
        "replyto": "hZftxQGJ4Re",
        "invitation": "ICLR.cc/2023/Conference/Paper927/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper discusses and proposed one ensemble method of GNN. The key idea is based on the high-order relationship of a target node. The proposed idea is relatively easy to understand and implement, which indicates that future researchers can easily generalize it. The proposed methods also outperform baselines.",
            "strength_and_weaknesses": "The high-level idea is easy to understand, traditional GNN work can't handle the high-order relationship. In this work, the authors proposed a new ensemble method, which indicates that the aggregation of the target node's neighbor is a biased estimator of the aggregation of the target node. The proof is also technically sound. The paper also builds a connection between ensemble methods and GNN, which can be useful to large-scale graphs in future research.\n\nQuestions: \n\nActually, the high-order relationship (i.e., high-order WL test) has been discussed in many previous works. Previous work, e.g., [1], [2], and other works, both discuss the high-order relationship. These works already show better performance compared with the 1-WL model(e.g., GIN, GCN, ...). However, the problem is that we don't have enough computational resources for the higher-order relationship(since we need to sample a subgraph for a target node, which is both time and space consuming). Thus, I wonder does the sampling part in this paper share the same limitations. Or maybe it's more efficient/faster than other high-order WL test based models.\n\nAnother concern is the expression power of the proposed model. More discussion regarding the expression power will be appreciated. By far we only know that it's a biased estimator. \n\n[1] Link Prediction Based on Graph Neural Networks\n[2] Distance Encoding: Design Provably More Powerful Neural Networks for Graph Representation Learning",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is easy to understand and well-organized. It's novel since few previous works discussed the correlation between high-order relationships and ensemble methods. The authors also provide the code and data they used.",
            "summary_of_the_review": "It's a good paper for me. The paper provides some insight and builds the connection between high-order relationships and ensemble methods. But I think more discussion is needed. Meanwhile, the experiment part only includes the 1-WL test model, which is not persuasive since it's obvious a higher-order relationship will have a better performance. Also, the runtime comparison may also show the advantage of the proposed model.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper927/Reviewer_Ku1Z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper927/Reviewer_Ku1Z"
        ]
    },
    {
        "id": "P2xF6kaW5w",
        "original": null,
        "number": 2,
        "cdate": 1666754623158,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666754623158,
        "tmdate": 1666754623158,
        "tddate": null,
        "forum": "hZftxQGJ4Re",
        "replyto": "hZftxQGJ4Re",
        "invitation": "ICLR.cc/2023/Conference/Paper927/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposed Deep Graph Ensemble (DGE) to learn effective representations of higher-order networks (HONS). HON is the networks that encode sequential higher-order dependencies. The authors conduct node classification and link prediction to evaluate DGE in comparison to graph neural networks on six datasets.",
            "strength_and_weaknesses": "**Strengths**\n\n(1) This paper addresses interesting research topic : higher-order networks (HONs), which encoder sequential higher-order dependencies.\n\n**Weakness**\n\n(1) I think that the novelty of this paper is limited. The proposed method is similar to path-based graph neural networks (e.g., pathGCN [1]) or random-walk based graph neural networks (e.g., RAW-GNN [2]). \n\n(2) Also, the authors construct graph from the sequential data (paths) and then use GrowHON to construct HONs. I think HON seems very similar to paths (a sequence of nodes). Please clarify what the difference is between HON and paths.  \n\n(3) Since the input datasets used in experiments are sequential data, it would be better to compare proposed DGE with the model for representing sequential data. Also, more comparison with path-based graph neural networks such as pathGCN [1] have to be included.\n\n(4) Can you show qualitative analysis for DGE to verify why it is appropriate approach to deal with HON?\n\n---\n\n[1] Eliasof, Moshe, Eldad Haber, and Eran Treister. \"pathGCN: Learning General Graph Spatial Operators from Paths.\"\u00a0ICML 2022.\n\n[2] Jin, Di, et al. \"RAW-GNN: RAndom Walk Aggregation based Graph Neural Network.\"\u00a0IJCAI 2022.",
            "clarity,_quality,_novelty_and_reproducibility": "**************Clarity**************\n\nThe paper is clearly written to understand overall method.\n\n**************Quality**************\n\nMore baselines have to be included to show the significance of proposed models.\n\n**********Novelty**********\n\nThe proposed method has a limited novelty. \n\n******************************Reproducibility******************************\n\nThe authors share their source code in the supplement. The paper has good reproducibility.",
            "summary_of_the_review": "Overall, I am leaning towards rejection. My major concern is the novelty and the lack of comparison with related works. If you address my concerns, I will raise my score. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper927/Reviewer_tGTJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper927/Reviewer_tGTJ"
        ]
    },
    {
        "id": "aoMIBhJyhM",
        "original": null,
        "number": 3,
        "cdate": 1666983151852,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666983151852,
        "tmdate": 1666983151852,
        "tddate": null,
        "forum": "hZftxQGJ4Re",
        "replyto": "hZftxQGJ4Re",
        "invitation": "ICLR.cc/2023/Conference/Paper927/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes an ensemble of GNNs that exploits variance in the neighborhood subspaces of nodes in graphs with higher-order dependencies and consistently outperforms baselines on semisupervised and supervised learning tasks.\n\nThe title and abstract looked interesting so I was expecting to see some interesting results, but the content is quite disappointing. The method/theory is too vague to be useful. Authors should answer my following concerns\n\n1. Just given a normal graph from arbitrary domains, what do you do?\n2. The conditional node, how do you decide if you want to condition?\n3. What's the benefit of condition? The similar argument doesn't make sense\n4. For regular gnn, how do you use ensemble to make them better?",
            "strength_and_weaknesses": "Title and abstract looked interesting\n\n\n\n1. Just given a normal graph from arbitrary domains, what do you do?\n2. The conditional node, how do you decide if you want to condition?\n3. What's the benefit of condition? The similar argument doesn't make sense\n4. For regular gnn, how do you use ensemble to make them better?",
            "clarity,_quality,_novelty_and_reproducibility": "N/A",
            "summary_of_the_review": "This paper proposes an ensemble of GNNs that exploits variance in the neighborhood subspaces of nodes in graphs with higher-order dependencies and consistently outperforms baselines on semisupervised and supervised learning tasks.\n\nThe title and abstract looked interesting so I was expecting to see some interesting results, but the content is quite disappointing. The method/theory is too vague to be useful. Authors should answer my following concerns\n\n1. Just given a normal graph from arbitrary domains, what do you do?\n2. The conditional node, how do you decide if you want to condition?\n3. What's the benefit of condition? The similar argument doesn't make sense\n4. For regular gnn, how do you use ensemble to make them better?",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper927/Reviewer_mus1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper927/Reviewer_mus1"
        ]
    },
    {
        "id": "4Fn99CrqQe3",
        "original": null,
        "number": 4,
        "cdate": 1667371329970,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667371329970,
        "tmdate": 1672027772153,
        "tddate": null,
        "forum": "hZftxQGJ4Re",
        "replyto": "hZftxQGJ4Re",
        "invitation": "ICLR.cc/2023/Conference/Paper927/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this work, the authors propose Deep Graph Ensemble (DGE) to tackle the additional information available in higher order networks $-$ something which standard Message Passing GNNs methods are unable to process without loss of information. The authors propose to do this by leveraging an ensemble of standard MPNNs - which are used to solve the 3 design challenges associated with HONs  $-$ variable number of conditional nodes, different and potentially non-overlapping neighborhoods, and the importance of the nodes. The authors then present results of the DGE (with different aggregation strategies",
            "strength_and_weaknesses": "**Strengths:**\n1. The idea towards using GNNs to solve problem on HONs is interesting as well as identifying different ways to use the HON to construct the inputs for the GNNs\n2. Most sections of the paper are well written and clear\n\n**Weaknesses, corresponding suggestions and questions**\n1. Unfortunately, to the reader it appears like the work is present as the first work of using GNN's for higher order networks and has altogether missed relevant GNNs works on Higher order networks - both comparing against them  e.g. [1]. Please compare and contrast with this work - and other appropriate related works.\n2. The paragraph on total model size comparison is unclear and appears to be unfair as well. Firstly, why limit the number of GNN layers in the baseline GNN models? The provided image in Fig 4 is also hard to read - and appears like until the budget is increased considerably the baseline models appear to do better.  Moreover, it is unclear how to select the right number of GNNs ($l$) to be used in the ensemble - can this be written as a function of the graph statistics?.\n3. Standard GNNs are known to suffer in the link prediction task and are not representative baselines - as has been widely studied and documented. Please add comparison with a method such as [2]\n4. What happens if you perform simple GNN ensembling - same input graph for all GNNs in the ensemble - but with neighborhood sampling (using MEAN, POOL, etc) without using your proposed training procedure? How does this compare?\n\n**Minor:**\n1. A drawback of the proposed approach - from the results in the appendix - it appears like that the DGE takes longer to converge - in terms of epochs how big is the difference? Are these all with the same parameter budgets as well?\n2. DGE-pool and DGE-concat (Even without shared parameters) seems to perform worse than the baselines models in most cases - is there any reasoning for this? Please address this in Section 4.3\n\n**References:**\n1. Jin, Di, et al. \"Graph Neural Network for Higher-Order Dependency Networks.\" Proceedings of the ACM Web Conference 2022. 2022.\n2. Zhang, Muhan, and Yixin Chen. \"Link prediction based on graph neural networks.\" Advances in neural information processing systems 31 (2018).",
            "clarity,_quality,_novelty_and_reproducibility": "Reproducibility - Code provided by authors \n\nNovelty and quality - Please see weakness 1\n\nClarity - Please see strength 2\n\n",
            "summary_of_the_review": "Unfortunately, in the current state , the weaknesses of the paper out weigh the strengths. However, I am happy to increase my scores if the authors can answer the questions appropriately.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper927/Reviewer_3FqL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper927/Reviewer_3FqL"
        ]
    }
]