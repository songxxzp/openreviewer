[
    {
        "id": "pIcmH-fepPU",
        "original": null,
        "number": 1,
        "cdate": 1666336660992,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666336660992,
        "tmdate": 1666342358022,
        "tddate": null,
        "forum": "UyC1dXUA-n",
        "replyto": "UyC1dXUA-n",
        "invitation": "ICLR.cc/2023/Conference/Paper131/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposed a strategy to make the temperature learnable. ",
            "strength_and_weaknesses": "Strength:\nThis paper proposed a simple strategy to make the temperature learnable. The proposed method simply changes two lines of the training codes to improve the performance.\n\nWeakness:\n1. This paper is badly written and hard to follow.\n2. The key idea of the paper is to make the temperature learnable, which is straight and lacks novelty.\n3. The proposed method is pretended too much. The authors impose the proposed method related to manifold learning, but it is not well proven and discussed theoretically.\n4. The experiments cannot comprehensively demonstrate the effectiveness of the proposed method. From the experimental results, one could see that the proposed method could only improve slightly.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is badly written and hard to follow.  The idea is straightforward and lacks novelty. The authors impose the proposed method related to manifold learning, but it is not well proven and discussed theoretically.",
            "summary_of_the_review": "This method is too simple and lacks novelty. The authors impose the proposed method related to manifold learning, but it is not well proven and discussed theoretically. The experiments cannot well demonstrate the effectiveness of the proposed method.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper131/Reviewer_YGrh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper131/Reviewer_YGrh"
        ]
    },
    {
        "id": "okKSr0h6AXH",
        "original": null,
        "number": 2,
        "cdate": 1666605008510,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666605008510,
        "tmdate": 1666605008510,
        "tddate": null,
        "forum": "UyC1dXUA-n",
        "replyto": "UyC1dXUA-n",
        "invitation": "ICLR.cc/2023/Conference/Paper131/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper designs a new distance metric called Oblique(d/m, m) instead of the fashionable cosine similarity for the contrastive learning paradigm. To verify the effectiveness of the proposed simple method, the authors perform extensive experiments. ",
            "strength_and_weaknesses": "##Strength\uff1a\nThe proposed new distance metric is neat and could be easily used for the contrastive learning paradigm.\n\n##Weaknesses:\nAlthough the proposed method could be easily generalized to the existing multi-modal pretraining works using the contrastive learning paradigm, the effects cannot be verified well in the provided experiment results. As shown in Table 4, using the proposed metric only brings limited retrieval performance improvement compared to the vanilla baseline. The authors could provide more results to verify and defend the superiority of the proposed method.\n\nAlthough the technical implementation of the proposed method is clear, there are some statements and arguments needed to be further claimed. \n- \u201cHere, the problem is that the numerical values of distances at equilibrium might be out of the distance range (e.g. [-1, 1] for the cosine similarity).\u201d Why the numerical values of distances could be out of the range of [-1, 1] for the cosine similarity?\n- \u201cFor instance, if there is a reasonable amount of false negative samples, then the model would learn a smaller negative distance for not being punished too hard when encountering false negative samples.\u201d\n\n- The reviewer finds that the font of the paper is different from other submission manuscripts. Does the paper use the proper template?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Quality: The paper is likely to have a modest impact on the community. Clarity: The paper is well organized but the presentation has minor details that could be improved. Originality: The main ideas of the paper are not novel or have limited novelty. Please see the weaknesses.",
            "summary_of_the_review": "The paper is not well written and hard to follow. The experiments are not solid for comprehensively evaluating the proposed method.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper131/Reviewer_W5p4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper131/Reviewer_W5p4"
        ]
    },
    {
        "id": "pnWtjW67WWW",
        "original": null,
        "number": 3,
        "cdate": 1666669605251,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666669605251,
        "tmdate": 1666669605251,
        "tddate": null,
        "forum": "UyC1dXUA-n",
        "replyto": "UyC1dXUA-n",
        "invitation": "ICLR.cc/2023/Conference/Paper131/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work strives to learn a visual-textual embedding space from weakly label image-text pairs from the internet. \nIn a typical contrastive learning with cosine-similarity, the noise in training data prevents the deep network to produce a solution with alignment-uniformity, and the network achieves a suboptimal system of equilibrium instead. This work resorts to oblique manifold as embedding space that tackles the equilibrium problem. Empirical improvement on zero-shot image to text retrieval task is observed.",
            "strength_and_weaknesses": "+ In general, this paper is easy to read. Formulation of the problem and description of the method are clear and rigorous.\n+ The idea of using oblique manifold to learn a visual-textual embedding space is novel.\n+ The finding on learnable softmax temperature is a distance scaling factor of contrastive learning on noisy dataset is interesting.\n\n- Missing some related literatures such as hyperbolic embedding space.\n\nThe motivation in choosing oblique manifold is a bit weak to some extent. The main arguments are 1) its geometry is spherical, where proper definition of uniformity is available, and 2) inner product saves computational cost.\n- Why the uniformity in embedding space is a valid goal to embed text, given the structure of text can be hierarchical?\n- While it is true that unbounded Euclidean space does not have proper uniform distribution defined (Sec 3.2 ii), no neural network is able to learn in unbounded space. We can simply clip to bounded range where uniform distribution is available.\n- In terms of computational cost, do authors take into consideration l2 normalization steps in their algorithm?  \n- Also, is the computation of distance function a bottleneck for optimizing underlying deep learning models? It sounds like a these difference in computational cost are marginal.\n- The statement of \"numerical values of distances at equilibrium might be out of the distance range (e.g. [-1,1] for the cosine similarity)\" is somehow unclear for me. Any two vectors naturally have a cosine similarity value constrained in [-1,1]. Why it might be out of range?\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "\nThe paper is clear written and easy to follow. The problem and methodology are nicely formulated.\nIf I have to name a few flaws in presentation, there are some symbols do not can clear explanations. For example:\n- Eq. (2)  H(.|.) denotes cross-entropy loss.\n- [CLS] in section 3.1.\n\nThe idea sound novel, but the motivation needs to be strengthened.\nThe reviewer trust the reproducibility of this work.",
            "summary_of_the_review": "This paper proposes to learn visual-textual embedding space on oblique manifold. The idea is interesting and novel, and the paper is well written. The reviewer feels pleasant to read the paper. Waiting to see the clarification of motivations and some statements.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper131/Reviewer_bLt8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper131/Reviewer_bLt8"
        ]
    },
    {
        "id": "gyx_Dc999FE",
        "original": null,
        "number": 4,
        "cdate": 1666669751898,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666669751898,
        "tmdate": 1666669751898,
        "tddate": null,
        "forum": "UyC1dXUA-n",
        "replyto": "UyC1dXUA-n",
        "invitation": "ICLR.cc/2023/Conference/Paper131/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes to employ the oblique manifold as the embedding space for contrastive visual-textual alignment learning, where the feature representations are mapped onto the oblique manifold endowed with the negative inner product as the distance function. Discussions and experiments on multiple different topologies endowed with different distances demonstrates the superiority and effectiveness of the proposed approach.",
            "strength_and_weaknesses": "Strengths:\n- The proposed algorithm is easy to implement and proved effective with multiple datasets.\n- This paper provides detailed discussion on the properties of the embedding topology and make fair comparison with other topologies including Sphere, Euclidean, and Oblique.\n\nWeaknesses:\n- In Introduction, the authors discussed the noise problem in contrastive alignment learning, and it seems that the proposed embedding space would handle the problem better than others. However, it may lack the relevant discussions in the body part or experiments.\n- This paper claims that \u201cthe sphere and oblique manifold have a proper uniform distribution defined as the surface area measure\u201d, which might be the reason why Sphere and Oblique performs better than Euclidean. However in Table 2, it seems that the conclusion would be largely affected by the Temperature init. \n- It may lack the discussion/visualization on the comparison of the learned distribution with Sphere and Oblique, which should give a more clear explanation on why Oblique performs better than Sphere.\n- Oblique Manifold has been utilized in other feature learning tasks, such as [i] and more discussions should be added.\n[i] Transductive Few-Shot Classification on the Oblique Manifold, ICCV 2021.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "This Paper is clearly written with good quality. The originality might be minor with using the Oblique Manifold in alignment learning. From the provided pseudo-code, this paper should be easy to reproduce.",
            "summary_of_the_review": "Overall, this paper utilized a new distance function for contrastive visual-textual learning, although simple and effective, this paper does not provide new things up with Oblique Manifold, and it lacks deeper analysis/demonstration on how the method solves existing problems. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper131/Reviewer_NGQV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper131/Reviewer_NGQV"
        ]
    }
]