[
    {
        "id": "hzoRgy0m8Xn",
        "original": null,
        "number": 1,
        "cdate": 1666329452635,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666329452635,
        "tmdate": 1666329452635,
        "tddate": null,
        "forum": "6jfbOWzWTcE",
        "replyto": "6jfbOWzWTcE",
        "invitation": "ICLR.cc/2023/Conference/Paper5904/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies offline reinforcement learning with differential function approximation (DFA) indexed by a parameter. Leveraging the ideas in DFA and the pessimism principle, the authors propose a value-iteration-based algorithm and analyze the suboptimality of the learned policy. The theoretical results generalize previous asymptotic analysis for DFA by constructing a finite-sample uncertainty quantification for the fitted value functions. A variant based on variance reduction is also provided and analyzed. The authors also discuss a few implications of this framework. ",
            "strength_and_weaknesses": "Strength:\n\n1. This paper provides a new algorithm and finite-sample analysis for offline RL with DFA. The theory seems sound because the main arguments look correct to me, although the analysis is too overwhelming hence I did not check all the details. \n\n2. This paper provides a comprehensive discussion of the application of existing results to the DFA setting, including the pessimistic value iteration and its variance reduction results. \n\n3. The authors did a good job in positing this paper in the related literature, and include detailed discussion on the implications, making this paper fruitful and dense. \n\nWeakness:\n\n1. All the results seem to be generalizations of existing algorithms and theoretical results. It may be helpful if the technical novelty can be discussed more thoroughly. ",
            "clarity,_quality,_novelty_and_reproducibility": "Quality: This paper is of good quality overall. \n\nClarity: The results are clearly stated and related to the existing literature. \n\nOriginality: Although the FDA setting seems less studied, I have the impression that the technical novelty of this paper is limited, or at least the authors need to highlight such novelty more. ",
            "summary_of_the_review": "I find this paper to be good overall. It provides new algorithms and analyses that generalize the existing ones to the FDA setting, and is quite intensive and comprehensive, covering almost all aspects of value iteration with offline data. This is a solid work although I find the technical novelty to be not very pronounced.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "I have not ethics concerns. ",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5904/Reviewer_tREF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5904/Reviewer_tREF"
        ]
    },
    {
        "id": "iwdIcw1TAQ",
        "original": null,
        "number": 2,
        "cdate": 1666634714891,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666634714891,
        "tmdate": 1666708036483,
        "tddate": null,
        "forum": "6jfbOWzWTcE",
        "replyto": "6jfbOWzWTcE",
        "invitation": "ICLR.cc/2023/Conference/Paper5904/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies parametric offline rl with a class of general differentiable function class approximation (DFA). The differentiable function class they consider is the set of functions $f(\\theta, \\phi)$ whose argument can be decomposed into two parts: $\\theta$ is the parameter vector and $\\phi$ is the feature map. They further assume that $f$ is third-time differentiable with respect to $\\theta$ and their derivatives are jointly continuous wrt $\\theta$ and $\\phi$. This function class is a generalization of linear model where $f$ is not necessarily dot product of its arguments. \n\nUnder two assumptions: (1) realizability + Bellman completeness, and (2)  the behavior policy is well exploratory over all dimensions of the gradient of DFA wrt $\\theta$, they obtain a guarantee in a form that is similar to the linear MDP; though here they consider a much more general function class. Their bound scales linearly with d, H times the uncertainty quantifier across the trajectory of target policy. They also incorporate variance information to remove the factor $H$ in their learning bound.",
            "strength_and_weaknesses": "**Strengths** \n\n- A generalization result of offline linear MDP to differentiable function class and incorporation of variance information \n\n- The paper is well-written and easy to read \n\n- The remark about feature representation and parameters looks interesting and can give some room to think more about the problem of representation learning in offline RL.\n\n**Weaknesses** \n\n- The data coverage assumption 2.3 is pretty some as it is equivalent to the uniform feature coverage assumption when realized to linear MDP, which is among the strongest data coverage assumption. \n\n- Optimization oracle at line 4 of Algorithm 1 is pretty strong as obtaining the global minimizer for a non-convex differentiable objective is difficult unless it is an overparameterized neural nets (see also the next point)\n\n- However, the dependence on $d$ in the learning bound makes their result inapplicable to overparameterized neural networks where $d$ could be a high-order polynomial of the number of samples\n\n- The assumption about third-time differentiability also cannot apply to neural networks (not necessarily overparameterized) with non-smooth activation such as ReLU. ",
            "clarity,_quality,_novelty_and_reproducibility": "- RHS of the equation in Corollary 3.3.: Remove the dot product <,> inside $\\hat{f}$\n\n- \u201dPFQL draws a unified view of model-based and model-free learning\u201d: This is a bit unclear to me how PFQL is relevant ot model-based learning. \n\n- It\u2019s interesting to root of 1/4 in Theorem 3.1. Where it comes from? \n\n- \u201dAssumption 2.3 reduces to 2.4\u201d \u2014> \u201cAssumption 2.3 reduces to Example 2.4\u201d",
            "summary_of_the_review": "See the strengths and weaknesses section. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5904/Reviewer_4N32"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5904/Reviewer_4N32"
        ]
    },
    {
        "id": "IwQ8VTgMS_",
        "original": null,
        "number": 3,
        "cdate": 1666784424254,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666784424254,
        "tmdate": 1666784424254,
        "tddate": null,
        "forum": "6jfbOWzWTcE",
        "replyto": "6jfbOWzWTcE",
        "invitation": "ICLR.cc/2023/Conference/Paper5904/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies offline reinforcement learning with differentiable function class approximation (DFA). This function class incorporates a wide range of models with nonlinear/nonconvex structures. The authors show that offline RL with DFA is provably efficient via analyzing the pessimistic fitted Q-learning (PFQL) algorithm. They further improve the guarantee with a tighter instance-dependent characterization. ",
            "strength_and_weaknesses": "This paper provides novel theoretical results for the offline RL with function approximation. The authors of this paper study the differentiable function approximation, which is new to the area of offline RL, though some parts of the related theory are first studied by [Zhang et al. (2022)]. Their analysis is further improved based on the idea of variance awareness. Thus, the contribution is significant to this area. \n\nThere are also several questions regarding this submission:\n\n1. Can the authors provide some explanations on why in Theorem 3.2 and Theorem 4.1, the results only hold for $K \\geq K_0$? What is the technical consideration behind $K_0$. How are $\\kappa_1$ and $\\kappa_2$ defined?\n\n2. Is it possible to have an improvement on other factors ( e.g., $d$ ) beyond only an $H$ in the result in Theorem 4.1 based on the idea of variance awareness?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the writing of this paper is clear to readers. The novelty is significant. And the authors provide detailed proof which can reproduce the main theoretical results.",
            "summary_of_the_review": "The technical contribution of this paper is significant. It provides novel ideas in the theoretical analysis of offline RL. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5904/Reviewer_eR8G"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5904/Reviewer_eR8G"
        ]
    },
    {
        "id": "nnwOoVfLwmF",
        "original": null,
        "number": 4,
        "cdate": 1666902809591,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666902809591,
        "tmdate": 1669670783328,
        "tddate": null,
        "forum": "6jfbOWzWTcE",
        "replyto": "6jfbOWzWTcE",
        "invitation": "ICLR.cc/2023/Conference/Paper5904/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies offline RL with a differentiable function class. With the assumption that the covariance of the gradient of every function (w.r.t. the parameters) in the function class has a positive minimum eigenvalue, this paper proves sample complexity bounds that scale with the number of the parameters. The results in this paper recover existing results for linear models and generalized linear models (up to an additional $\\sqrt{d}$ factor in the instance-dependent bound).",
            "strength_and_weaknesses": "Strength:\n- The differentiable function class considered in this paper generalizes linear/generalized linear models. The sample complexity bounds for generalized linear models in this setting seem to be new.\n\nWeakness:\n- The two equations in Assumption 2.3 is required for every possible parameter $\\theta$, which seems to be very strong. It\u2019s unclear to me whether there are other function classes (beyond linear and generalized linear models) that can satisfy Assumption 2.3. For example, does a two-layer neural network with constant number of neurons satisfy Assumption 2.3?\n",
            "clarity,_quality,_novelty_and_reproducibility": "I find some of the claims in this paper confusing:\n\n- The paragraph after assumption 2.2 states that \u201cwe make the following stronger coverage assumption \u2026\u201d. Why the following coverage assumption is stronger? Does Assumption 2.3 imply Assumption 2.2?\n- The \u201cFaster convergence in learning\u201d paragraph (Page 7) uses the example that $\\nabla f(\\theta^\\star,\\phi)=0$ to demonstrate the faster rate. Does this statement requires  $\\nabla f(\\theta^\\star,\\phi(s,a))=0$ for every possible $s,a$? Does this example contradict with Assumption 2.3 (in particular, $\\mathbb{E}[\\nabla f(\\theta^\\star,\\phi(s,a)) \\nabla f(\\theta^\\star,\\phi(s,a))^\\top]\\ge \\kappa I$?\n- The \u201cFeature representation vs. Parameters\u201d paragraph (Page 7) states that \u201cwhen changing the model f with more complex representations, the learning hardness will not grow as long as the number of parameters needs to be learned does not increase\u201d. It\u2019s unclear to me what is the implication of this statement. It seems to me that this statement exactly means that the complexity of the function class does not increase with the feature dimension (when the number of parameters is fixed), so increasing the feature dimension further does not increase the expressivity of the function class fundamentally.\n- It\u2019s unclear to me why there is an extra $\\sqrt{d}$ factor in Theorem 4.1. The conclusion section suggests that it comes from the covering argument for the differentiable function class. Could the authors elaborate? In particular, why can\u2019t the uniform convergence techniques used in linear MDPs be applied here?\n",
            "summary_of_the_review": "My main concern is whether the differentiable function approximation setting considered in this paper contains new settings that is unknown in prior works. However, given that the results in this paper require some novel techniques, I will recommend a weak accept at this point.\n\n=== after rebuttal ===\nAfter reading through the authors' response, I tend to keep my score as weak accept.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5904/Reviewer_7cjK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5904/Reviewer_7cjK"
        ]
    }
]