[
    {
        "id": "wDXqg58LPgm",
        "original": null,
        "number": 1,
        "cdate": 1666085897278,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666085897278,
        "tmdate": 1666085897278,
        "tddate": null,
        "forum": "LNpMtk15AS4",
        "replyto": "LNpMtk15AS4",
        "invitation": "ICLR.cc/2023/Conference/Paper6333/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper provides a method for improving the robustness of score-based DAG learning methods to heterogeneous noise.  It works by iteratively up-reweighting the poorly fitted observations and then rerunning the base method.\n",
            "strength_and_weaknesses": "The method seems useful and clearly improves performance in simulations, as well as on the well-known Sachs data.  \n\nThe weaknesses are: \n1. It is computationally more expensive - this is presumably inevitable given that it involves running the main method several times.\n2. No mention is made of the possibility of spurious outliers.  These are generally dealt with in statistics by _down_-weighting, not up-weighting. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very clearly written, and easy to follow.  As far as I am aware this approach is novel.  The simulation and real data results suggest that the method works well, and there is associated code that can (presumably) reproduce the authors' results.",
            "summary_of_the_review": "This seems like a nice contribution to the literature, allowing for more accurate learning of DAG structure with score-based algorithms.  Please do ensure you take into account my comments below in your revision.  \n\n### Comments \n\n1. What happens if the observations are just statistical outliers, and don't really contain any useful information?  I could easily imagine just a few observations totally disrupting your algorithm in this context, because they would presumably be massively up-weighted and might overwhelm your fitting algorithm.\n\n2. You say that you can fit your method to 'any score-based causal discovery method'.  This is not correct - first, and most obviously, you need the individual data; second the data must be assumed to be independent; and third it is not clear to me whether the method would work for other classes of graphs.\n\n3. \"However, it is no doubt that integrating a strong backbone DAG learner with ReScore is the only way to truly advance in this field.\"  This statement is much too strong; it's not at all clear that another approach might work just as well as yours, or even better!\n\n4. In the proof of Theorem 1, you write down the conditional variance formula at the bottom of page 15 but you implicitly assume that $\\mathbb{E} [(X^TWX)^{-1} X^TW N^j \\mid X] = 0$.  This is fine (since it's used on the previous line), but you need to state that this is what you're doing, or the proof is hard to follow.  I would suggest giving the conditional variance formula before you start and then noting that this second term is zero.\n\n### Typos/Minor Points\n\n - page 4: \"combinatorial optimizaiton\" $\\to$ \"combinatorial optimization\";\n - page 5: \"hard less-fitted samples\" $\\to$ \"less well-fitted samples\";\n - page 6: \"negative llog-likelihood\"\n - page 9: \"In sheer contrast\" $\\to$ \"In stark contrast\"\n - page 15: \"one is easy to obtain that\" $\\to$ \"one can easily obtain that\"\n - below (9) \"of that term\" - which term? The one from (8), presumably!\n - page 16: \" 'case a.'. \" should be just \" 'case a.' \" and the open quote should be inverted.\n - just below \"standard Gaussian distribution\": not really, since the variances are not all 1.\n - below (10) \"equivalent to minimize the first term\": I think you mean the second term.\n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6333/Reviewer_m1MC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6333/Reviewer_m1MC"
        ]
    },
    {
        "id": "C1fvH2GjOr",
        "original": null,
        "number": 2,
        "cdate": 1666615409322,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666615409322,
        "tmdate": 1666616011285,
        "tddate": null,
        "forum": "LNpMtk15AS4",
        "replyto": "LNpMtk15AS4",
        "invitation": "ICLR.cc/2023/Conference/Paper6333/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a simple model-agnostic framework to boost causal discovery performance by dynamically learning the adaptive weights for the score function. In particular, the proposed method leverages the bilevel optimization scheme to alternatively train a standard DAG learner first and then reweight the samples that the DAG learner fails to fit well.",
            "strength_and_weaknesses": "Strength:\n\n1. The paper is well presented. \n2. The proposed sample reweighting method can help causal discovery in heterogeneous data by auto-learnable adaptive weights.\n3. The proposed sample reweighting trick is simple and is flexible to combine with any score-based continuous optimization method in causal discovery.\n\nWeakness:\n\n1. It seems after adding the sample reweighting step, the reported empirical performance, especially FDR, instead gets worse in some cases. Is it because bilevel optimization is harder?\n\n2. With the sample reweighting step, the algorithm is computationally much more expensive.\n\n3. It would be more intuitive to understand the benefit of reweighting if the authors could provide illustrative examples.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity and Quality: \nThe paper is well organized and presented. It provides both theoretical guarantee and practical evaluation.\n\nNovelty: \nThe sample reweighting trick to improve causal discovery performance is novel, as far as I know. \n\n",
            "summary_of_the_review": "The paper is well organized and presented. The sample reweighting trick to improve causal discovery performance is novel, as far as I know. It is also simple and flexible to adapt to other continuous optimization methods.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6333/Reviewer_x5dL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6333/Reviewer_x5dL"
        ]
    },
    {
        "id": "Pj6nm4cl9q",
        "original": null,
        "number": 3,
        "cdate": 1666615681831,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666615681831,
        "tmdate": 1669819362462,
        "tddate": null,
        "forum": "LNpMtk15AS4",
        "replyto": "LNpMtk15AS4",
        "invitation": "ICLR.cc/2023/Conference/Paper6333/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents a model-agnostic framework that improves pre-existing score-based models for causal discovery. This is done by adapting the score weights for each sample while training the backbone model, thus alternating between training the backbone model and updating the weights.\nThe weights are updated in such a way as to give a larger impact to the less-fitted samples, which might be more informative to the backbone model. This framework is claimed to have a particularly large impact when dealing with heterogeneous data (even in cases when we do not know what samples come from which cohort).",
            "strength_and_weaknesses": "Strengths:\n\n* The exposition of the method is quite clear.\n\n* The proposed framework is very flexible, as it can be used on top of many other score-based methods.\n\nWeaknesses / questions about things that are unclear:\n\n* A main concern is that *the paper claims improvements for any score-based method, while this claim is only supported for the case of differentiable score-based methods*. In the experiments, the proposed framework is applied only with differentiable methods. Also, the framework is motivated from observed shortcomings of differentiable methods (bullets page 1&2). It is possible that the proposed framework also gives improvement with discrete score-based methods, but such a claim is not supported by the paper. The scope of the claim needs to be made clear, starting in the abstract.\n\n* Can you explain an example of how single datapoints may provide \"crucial causal information\", or how without reweighting there is  \"overfitting\" (both page 2)? I think figure 1 starts to demonstrate such issues, but does not explain these two points.\n\n* In Theorem 1, what does it mean to say \"asymptotically\", when the vector of weights is held fixed (and so its length can't increase to accommodate more datapoints)?\n\n* The argmax in (6) will often equal the empty set, because the set $\\mathbb{C}(\\tau)$ is open (so there is a supremum, but no maximum). Replace the inequalities between the $w$'s and the $\\tau$-terms by $\\leq$ to make the set closed.\n\n* The statement and proof of Theorem 2 are incorrect. The proof can only show that $w_i^* \\geq w_j^*$. Because in the proof, when supposing the contradiction, if $w_i^* = w_j^*$, there is no such $\\epsilon$. (BTW, the $\\mathbb{C}$ should be $\\mathbb{C}(\\tau)$. Also, you don't need this set to be open.) But this substantially weakens the statement of the theorem: it now leaves open the possibility that all weights are set equal.\n\n* Theorem 2 seems to suggest that the weights are increasing as a function of the losses (over the different datapoints). Can you explain why this is not what we see in Figure 3? (A possible reason might be related to the text \"in the optimization phase\" in Theorem 2. It is not  clear exactly what point of the bilevel optimization algorithm this refers to.)\n\n* Synthetic data experiment, bottom page 8: what does it mean that the \"noise scale is flipped\"?\n\n* Sachs data: This dataset contains (I think) 14 different interventional regimes, which are pooled together in this experiment. Pooling is not the most effective way to deal with these data (see eg Mooij, Magliacane and Claassen, 2020). As such, I disagree with the conclusions that this experiment \"highlight[s] the ineffectiveness of score-based causal discovery methods when dealing with real-world data\" and that \"integrating a strong backbone DAG learner with ReScore is the only way to truly advance in this field\". Further, due to these regimes, this experiment should be listed under \"heterogenous data\".\n\nMinor comments (not necessarily part of decision assessment):\n\n* I am not familiar with the terminology \"disadvantaged\" domain/data point; I think you mean \"underrepresented\"?\n\n* (page 5) \"Initially, ... are assumed\": This sentence is unclear. I think you want to say that a *family* of functions and a *family* of noise distributions need to be chosen. The use of the word \"specific\" confuses me though.\n\n* For the experiments with heterogenous data, you could consider comparing to a method that uses non-adaptive weights, set inversely proportional to the group sizes.\n\n* The manuscript contains many grammatical mistakes, as well as places where the wrong word was chosen (eg \"alternative(ly)\" when \"alternating(ly)\" is meant; \"phrases\" when \"phases\" is meant; ...). Please thoroughly proofread the manuscript and correct these errors.",
            "clarity,_quality,_novelty_and_reproducibility": "The structure of the paper is very clear, and overall the paper is easy to follow. Exceptions are detailed above.\n\nThere are problems with the theoretical results, detailed above.\n\nThe proposed method is novel to the best of my knowledge.\n\nI see no problems with reproducibility.\n\n\n",
            "summary_of_the_review": "The proposed method is novel as far as I know, and the experimental results suggest it often yields impressive performance improvements. Because of some issues with the current manuscript, I am currently recommending rejection, but if these issues can be addressed, I expect to recommend acceptance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6333/Reviewer_Q3NX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6333/Reviewer_Q3NX"
        ]
    },
    {
        "id": "S-cnc1zrfJ0",
        "original": null,
        "number": 4,
        "cdate": 1666973222869,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666973222869,
        "tmdate": 1666973222869,
        "tddate": null,
        "forum": "LNpMtk15AS4",
        "replyto": "LNpMtk15AS4",
        "invitation": "ICLR.cc/2023/Conference/Paper6333/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work addresses the problem of errors in structure learning algorithms.  The authors propose to reweight poorly fit samples in order to improve the efficacy of the underlying algorithm. A proof is shown under linear models for specific scoring rules in the asymptotic regime. Empirical results show the proposed method improving state of the art structure learning algorithms. ",
            "strength_and_weaknesses": "Strengths: \n* The relative frailty of structure learning algorithms is a major roadblock to practical usage, so this task is very well motivated. \n* The authors present an algorithm which is simple and intuitive\n* Empirical results are very compelling\n\nWeaknesses:\n* The authors reweight samples with the intuition that these correspond to spurious edges, however it is not entirely clear to me why this should be limited to one reweighting step. Can the authors give some sort of intuition on why only one boosting step is used? What would happen if multiple reweighting steps were employed?\n* Theorem one is incredibly limited in scope. I don't think this necessarily a problem but the authors should reconcile their claim that the approach is applicable to any score base learner with the assumptions that restrict the space of models and algorithms substantially. \n* The approach deals with recovering directed graphs, but the authors frame in terms of causal discovery. In the case of causal discovery, only an equivalence class is recovered, not a fully directed graph. Do the authors have suggestions or intuition regarding the modifications necessary to have the algorithm work when an algorithm (e.g., GES) returns an equivalence class after every step?",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, I think the authors have written a clear and well organized paper. Outside of the issues that I raised I think the quality is quite good and the novelty is quite high, in my view. ",
            "summary_of_the_review": "As I mentioned above, I think this is a well motivated and simple solution to a very compelling problem. I think the idea that the procedure can be applied a wide variety of algorithms is quite compelling. My reservations are listed above in the weaknesses, and is largely in the theoretical underpinnings and some of the details of the proposed approach. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6333/Reviewer_ueyq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6333/Reviewer_ueyq"
        ]
    }
]