[
    {
        "id": "n3MR6Aey37A",
        "original": null,
        "number": 1,
        "cdate": 1666336755808,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666336755808,
        "tmdate": 1666336755808,
        "tddate": null,
        "forum": "JLLTtEdh1ZY",
        "replyto": "JLLTtEdh1ZY",
        "invitation": "ICLR.cc/2023/Conference/Paper4010/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper is devoted to verifying deep reinforcement learning (DRL) policies and proposes a latent space model (Wasserstein auto-encoded MDP, WAE-MDP) that addresses a number of issues pertaining to earlier latent space models by minimising the optimal transport between the behaviours of the agent executing the original policy and the distilled policy. Here, formal guarantees for the distilled policy are provided. Experimental results demonstrate the proposed approach to be faster in distilling policies and better in terms of the overall result quality.",
            "strength_and_weaknesses": "I should admit that I am no expert in this particular area and so I may have overlooked some of the important details of the work.\n\nHaving said that, I should bring the authors' attention to the fact that the paper is not helping much in this regard. Although it has a section on \"background\", in my opinion, it still does extremely little when introducing preliminary knowledge - the authors cut to the chase and start throwing bulky \"two-storey\" formulas, equations, and theorems with no motivation whatsoever. It may be okay for an expert in the field, e.g. the authors themselves, but an average reader like me will get lost immediately. The algorithm description provided follows the same style, which makes it really hard to appreciate the presentation provided.\n\nIn my view, \"formal verification\" means logical reasoning about a system and formally proving certain properties of the system. This paper does not make it clear what kind of reasoning engine is applied when verifying the properties. I should also say that it does not discuss the practicality of the proposed approach (say, from the scalability perspective).",
            "clarity,_quality,_novelty_and_reproducibility": "In my view, clarity is where the paper immediately falls short. It is extremely difficult to follow if you do not work in that specific area. Quality- and novelty-wise I believe the paper may perform well. In terms of representation, the authors provide the source code of their implementation and notebook videos of how the policies offered by the proposed approach behave in practice.",
            "summary_of_the_review": "As I feel completely lost in the text, I am afraid I cannot give this paper a positive score. However, as I mentioned above, I could have overlooked important merits of the paper, hence, my score is \"borderline reject\".",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4010/Reviewer_MegB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4010/Reviewer_MegB"
        ]
    },
    {
        "id": "BjHbp8pWb5f",
        "original": null,
        "number": 2,
        "cdate": 1666601855734,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666601855734,
        "tmdate": 1669783335617,
        "tddate": null,
        "forum": "JLLTtEdh1ZY",
        "replyto": "JLLTtEdh1ZY",
        "invitation": "ICLR.cc/2023/Conference/Paper4010/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper learns a discrete abstraction of the state-action space of the MDP underlying an RL setup. This abstraction has smaller latent space and the distilled RL policy is more tractable for formal verification approaches such as model checking of bisimulation guarantees. The paper uses Waserstien autoencoders to overcome several limitations with the use of VAEs and builds on recent work by Delgrange et al in AAAI'22.",
            "strength_and_weaknesses": "Strengths:\n\n+ The paper presents a framework for learning RL policy distillations with bisimulation guarantees. This enables formal verification over learned discrete abstraction of continuous environment. This approach improves upon VAE-MDP in terms of learning speed and model performance. \n\nWeaknesses: \n\n- While the paper talks about formal verification, it fails to clearly identify the kind of formal guarantees it aims to establish beyond bisimulation and reachability guarantees. While it makes a theoretical claim of verifying general discounted omega-regular properties, the experimental evaluation fall far short of it. \n\n- The experimental results are limited to toy examples - cartpole, pendulum, mountain car, acrobot and lunarlander. It would be helpful to consider more complex RL environment such as highD control examples.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is quite dense, with a lot of dependency on the appendix.  Many of the proofs of the critical claims are in the appendix. Graphs in Figure 4 are very difficult to read. Some clarification on novelty of the paper is requested in the Weaknesses section of the paper. ",
            "summary_of_the_review": "This paper might be more suitable for COLT, SODA or STOCS. It is not clear if this paper has enough novelty and relevance to a machine learning audience. The paper is mostly about MDP abstraction. In addition to clarifying the weaknesses identified in this review, the authors are requested to draw a stronger connection to RL. The mismatch in theory and experiments in the paper suggest that this is a work in progress. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4010/Reviewer_67Kn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4010/Reviewer_67Kn"
        ]
    },
    {
        "id": "TEduvWgqgek",
        "original": null,
        "number": 3,
        "cdate": 1666636866235,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666636866235,
        "tmdate": 1666636866235,
        "tddate": null,
        "forum": "JLLTtEdh1ZY",
        "replyto": "JLLTtEdh1ZY",
        "invitation": "ICLR.cc/2023/Conference/Paper4010/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces the Wasserstein auto-encoded MDP (WAE-MDP), which is a latent space model that aims to overcome some of the shortcomings of a prior latent space model (VAE-MDP). Their method learns a (small) discrete representation of the state-action space. Their approach lends itself to formal guarantees on behaviour (based on the theory of bisimulation). In addition to enabling formal guarantees, the authors demonstrate their method is 10 times faster than VAE-MDP in distilling policies.",
            "strength_and_weaknesses": "# Strengths\nThe paper is well written, well motivated, and properly evaluated. The theoretical claims are presented clearly and the proofs are correct (as far as I could tell).\n\nI wanted to commend the authors on Figures 1 and 2, which really nicely complement the text and help clarify the methods discussed.\n\n# Weaknesses\nThe main weakness for me is the complexity of the method presented, although that is difficult to resolve. The paper is quite clear, but there are a few points where it could be made clearer:\n1. There is a _lot_ of notation. It would be useful to provide an index of notation inthe appendix, as it can be hard to keep track of all of them.\n1. In the top of page 4, it is not clear whether $\\bar{\\mathcal{R}}$ and $\\bar{\\bf{P}}$ are learned or not. I think they are, but this should be made explicit. In particular, they should include the parameterization $\\theta$ (which is present in Figure 2) to make it clearer.\n1. In section 3.1, shouldn't there be an assumption on the scales of the metrics $d_S$, $d_A$, and $d_R$ being similar? Otherwise simply adding them doesn't make sense.\n1. Below Theorem 3.1 there is an objective presented. If I understand correctly that objective is the loss version of the equation in Thm 3.1. If so, what's the motivation for the last ($\\beta$-weighted) term?\n\n# Questions / suggestions\n1. In section 2 MDPs are introduced as having a single initial state $s_I$. Do the results not hold if one has an initial state distribution instead?\n1. In the bottom of page 2 it says $s\\models \\top$ if $\\ell(s)\\cap \\top \\ne\\emptyset$. Should it not be $\\top\\subseteq\\ell(s)$ instead? In the form presented $s\\models \\top$ as long as at least _one_ **AP** in $\\top$ is in $\\ell(s)$, which I don't think is what is meant.\n1. In the **Bisimulation** section of page 4, what is meant by \"the largest bisimulation relation\"?\n1. In the paragraph above Lemma 3.2 it says \"along with setting $D$ to $W_{\\overrightarrow{d}}$, yield ...\". This suggests your loss is somehow computing $(1 + \\beta)W_{\\overrightarrow{d}}$, or am I missing something?\n1. In Figure 4(c), why are no learning curves shown for RL policy? Where are the lines for original (DQN) and original (SAC)?\n1. In the paragraph below Algorithm 1 it appears the indicators \"former\" and \"latter\" are swapped.\n1. The authors use the term \"Gumble\", but it should be \"Gumble\".\n1. In the **Latent distributions** paragraph on page 7, it should read \"We emphasi**ze** that this trick alone...\"\n1. In the first paragraph of the conclusion it should say \"Our method overcome**s** the limitations...\"",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is quite clear and of high quality. The method presented is novel, as far as I can tell.\nThe authors have included technical details for their method, and have provided source code for reproducibility.",
            "summary_of_the_review": "A nice paper that provides a theoretically-motivated methodology for learning a latent space model on which formal verification can be performed.\n\nI support accepting the paper, provided the clarity points above are addressed.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4010/Reviewer_JqQE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4010/Reviewer_JqQE"
        ]
    },
    {
        "id": "sHO2eW6MihM",
        "original": null,
        "number": 4,
        "cdate": 1666762503987,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666762503987,
        "tmdate": 1668620718120,
        "tddate": null,
        "forum": "JLLTtEdh1ZY",
        "replyto": "JLLTtEdh1ZY",
        "invitation": "ICLR.cc/2023/Conference/Paper4010/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper focuses on improving the performance of deep reinforcement learning. The authors proposed Wasserstein auto-encoded Markov Decision Processes (WAE-MDPs) for solving this problem. Experimental results show that WAE-MDPs outperform VAE-MDPs. ",
            "strength_and_weaknesses": "Strengths\n\nThe authors proposed a novel method called WAE-MDP.\nThe authors provided theoretical guarantees for WAE-MDP.\nExperimental results show that WAE-MDP outperforms VAE-MDP\n\nWeaknesses\n\nThe authors claim that one of the reasons why VAE-MDP does not work well is due to the mode collapse of VAE. However, limited evidence is provided that VAE suffers from mode collapse.",
            "clarity,_quality,_novelty_and_reproducibility": "The authors improve VAE-MDP by replacing a VAE with a WAE. The authors proposed a new objective function and provided theories for it. I consider the method novel. \nThe presentations of the paper are generally straightforward. In Figure 4, does the horizontal axis represents the number of training step? ",
            "summary_of_the_review": "The authors propose a novel method called WAE-MDP. Experimental results show that WAE-MDP outperforms VAE-MDP",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4010/Reviewer_cw5C"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4010/Reviewer_cw5C"
        ]
    }
]