[
    {
        "id": "XSyjiTOTHn",
        "original": null,
        "number": 1,
        "cdate": 1666549979407,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666549979407,
        "tmdate": 1666549979407,
        "tddate": null,
        "forum": "zVrw4OH1Lch",
        "replyto": "zVrw4OH1Lch",
        "invitation": "ICLR.cc/2023/Conference/Paper4530/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The work studies the generalization of fairness constraints  in Machine Learning systems.  The authors argue that while current algorithms are optimized for generalizing on the whole dataset, their efficacy on minority classes for imbalanced datasets have not been extensively covered They introduce their Flexible Imbalance Fairness Aware (FIFA) classification, combined with logit based losses.  The authors conclude their work by empirically showcasing the performance on relevant datasets for over-parameterized models.",
            "strength_and_weaknesses": "Strengths\n* The paper is well written, clear to follow.\n* It motivates the problem and lists the related work reasonably.It tackles an important problem in the domain, especially with the advent of large  overparameterized models.\n\n\nWeakness\n* The novelty of the technical contributions itself doesn't seem quite significant, specifically the integration with existing classification based approaches.\n* The overall empirical evaluation is  reasonably extensive, answering the questions raised in the introduction. However, it would be nice if the authors could elucidate further the  complexity/real world mapping of these datasets to real world challenges we observe.",
            "clarity,_quality,_novelty_and_reproducibility": "The work is clear, reasonably easy to follow and seems novel to the best of my knowledge. The reviewer would be able to reproduce these based on the details provided.",
            "summary_of_the_review": "Overall, the paper tackles an important problem in the domain, especially with the rapid growth of large overparameterized. The paper is clear, well written and easy to follow. While the empirical significance is reasonably novel, the introduced technical novelty isn't as significant. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None, so far. The authors have addressed this in pg 10.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4530/Reviewer_WVpp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4530/Reviewer_WVpp"
        ]
    },
    {
        "id": "g87trcy4P4",
        "original": null,
        "number": 2,
        "cdate": 1666779272196,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666779272196,
        "tmdate": 1666779272196,
        "tddate": null,
        "forum": "zVrw4OH1Lch",
        "replyto": "zVrw4OH1Lch",
        "invitation": "ICLR.cc/2023/Conference/Paper4530/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In settings where the goal is to learn a classifier that does not exhibit disparate impact, it is common to constrain the learning process via fairness constraints or an adversarial learning procedure. Typically, the disparate impact effects are reduced on the training set, but bias is still observed on the test set. In this paper, the authors propose a new margin-based loss function that is then minimized via exponentiated gradient descent. The intuition behind the loss is that the decision boundary of the final classifier should be further away from small sub-groups in the dataset.",
            "strength_and_weaknesses": "**Strengths**\\\nThe paper addresses an important problem and the choice of the loss does indeed make intuition sense. Further, the empirical results indeed suggest that one makes significant improvements using the proposed loss function modifications in this work. \n\n**Weaknesses**\n- Clarification about the importance of group sizes: I am confused about why the bounds in the paper and the key intuition is around group size as opposed to some other measure of group difficulty. One could envision a case where a smaller group is perhaps more homogenous, so it still easy to 'learn' with smaller samples versus a larger group whose inputs have more feature noise. I would've expected a term in these bounds that captures group difficulty. Any insight on this issue?\n- Adult dataset: I'd suggest the authors consider the recently introduced adult dataset by Ding et. al. (Retiring Adult dataset) as a replacement for the standard Adult dataset.\n- On first reading, it was unclear what parts of section 5 are new to this work, and which ones aren't. For example, I know the ExpGrad formulation is due to Agarwal, but several parts of that section are not well-delineated. For example, is Theorem 5.1 also based on the modification of the equivalent theorem from the Agarwal paper? \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and mostly free of typos. While certain parts of the work were dense, at a high level the work was easy to follow.\n\nThe key insight of this work is mostly original even though significant portions of the work build on the previous Cao et. al paper as well as the formulation of Agarwal et. al.\n\nOverall, the work addresses an important problem with a new margin-based loss function that improves the generalization of the fairness property of a model at test-time.",
            "summary_of_the_review": "Overall, the work addresses an important problem with a new margin-based loss function that improves the generalization of the fairness property of a model at test-time.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4530/Reviewer_Kgun"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4530/Reviewer_Kgun"
        ]
    },
    {
        "id": "8bY0qFXicXo",
        "original": null,
        "number": 3,
        "cdate": 1667324741698,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667324741698,
        "tmdate": 1667324741698,
        "tddate": null,
        "forum": "zVrw4OH1Lch",
        "replyto": "zVrw4OH1Lch",
        "invitation": "ICLR.cc/2023/Conference/Paper4530/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper presents a regularization-based training loss modification that promotes larger margins for minority subgroups in order to improve fairness constraint generalization.",
            "strength_and_weaknesses": "Strengths:\n1. Margin-based approach makes sense in theory and by intuition.\n2. Good comparisons against the well-known reductions-based approaches by Agarwal et al. (2018).\n3. Good empirical results.\n\nWeaknesses:\n- Would be interesting to have comparisons against more than a single work; namely, a glaring baseline that's missing is the TensorFlow Constrained Optimization package, even more so given that this work focuses on over-parameterized models (NNs).\n  - The same authors of the TFCO package also published work specifically focused on generalization of fairness constraints:\n> Cotter, Gupta, Jiang, Srebro, Sridharan, Wang, Woodworth and You. \"Training Well-Generalizing Classifiers for Fairness Metrics and Other Data-Dependent Constraints\".\n  - These references should at least be discussed in related work, but in truth they should also serve as baselines for empirical results.\n- Bad fairness constraint generalization can only mean that performance on one subgroup generalizes better than performance on the other group; it would be interesting to see group-wise loss (or group-wise TPR or FPR), and how these change with difference values for fairness constraint tolerance.\n  - Since this difference in generalization between different subgroups likely stems from the imbalanced nature of the dataset, it would be interesting to see comparison against methods from the imbalanced learning literature (not only the single method from fairness literature).\n\nMinor point:\n- Most references have double parentheses.",
            "clarity,_quality,_novelty_and_reproducibility": "- Paper is well written and clearly presented.\n- This work has clear close ties with other papers in the generalization literature, but I believe its application to fairness _with imbalanced data_ is novel enough to warrant a publication.",
            "summary_of_the_review": "The paper presents a somewhat novel approach to improving fairness constraint generalization based on enlarging margins of minority subgroups. It is missing some discussion of important related work, and important baselines for fairness constraint generalization as well.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4530/Reviewer_XQ8s"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4530/Reviewer_XQ8s"
        ]
    }
]