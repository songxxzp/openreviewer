[
    {
        "id": "bysoHy-Iy8",
        "original": null,
        "number": 1,
        "cdate": 1666422694605,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666422694605,
        "tmdate": 1668576997393,
        "tddate": null,
        "forum": "h9O0wsmL-cT",
        "replyto": "h9O0wsmL-cT",
        "invitation": "ICLR.cc/2023/Conference/Paper6186/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors study the task of training regression models with the guarantee of label differential privacy (DP). Based on a global prior distribution on label values, which could be obtained privately, they derive a label DP randomization mechanism that is optimal under a given regression loss function.",
            "strength_and_weaknesses": "Strength: The authors try to extend the method and results of labeled DP solving classification problem to regression. The problem is good.\nWeaknesses: They map the response (maybe in a continuous region (interval)) to finite possible values. ",
            "clarity,_quality,_novelty_and_reproducibility": "The authors try to extend the method in paper \"Deep Learning with Label Differential Privacy\" for classification to regression. The authors try to use step function to represent the tilde  Y space. It seems a good paper if the derivation is correct.\n\n",
            "summary_of_the_review": "It is an interesting problem. \n\nThere are some typos, authors should read the draft once more before submission.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6186/Reviewer_Qh4U"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6186/Reviewer_Qh4U"
        ]
    },
    {
        "id": "jVxHQ8rDi6",
        "original": null,
        "number": 2,
        "cdate": 1666674921909,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666674921909,
        "tmdate": 1666675214188,
        "tddate": null,
        "forum": "h9O0wsmL-cT",
        "replyto": "h9O0wsmL-cT",
        "invitation": "ICLR.cc/2023/Conference/Paper6186/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper provides an optimal label randomization mechanism that ensures local differential privacy given the prior distribution of labels. For a known loss function, the proposed mechanism is optimal. If the prior is unknown, this paper proposes to use the private histogram to estimate the prior. In this case, the gap between the proposed method and the optimal mechanism is proved to be O(\\sqrt{|Y|/n}), where $|Y|$ is the cardinality of the label domain. Compared to prior work Ghazi et al. (2021a), the proposed mechanism works for general regression losses. This paper also empirically compares the label loss of the proposed method with some baselines on real data. ",
            "strength_and_weaknesses": "Strengths: 1. This paper is clearly written. Also, it provides extensive experiments on real data.\n\nLimitations: 1. In the practical setting, the label party is typically able to see the public feature data.\n2. In practice,  the overall generalization error is usually more concerning. I was wondering if there is any way to also consider the second term in Eq. (1) like in Ghazi et al. (2021a)?\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well written. I enjoyed reading this paper. Compared to Ghazi et al. (2021a), the proposed method is not technically novel.\n",
            "summary_of_the_review": "This paper provides an optimal mechanism for privatizing the labels that minimize the loss between noisy labels and true labels. The proposed method is a strict generalization of 0/1 loss appeared in Ghazi et al. (2021a). Theoretically, this paper shows the optimality of the proposed mechanism. Empirically, the authors demonstrate the effectiveness through extensive experiments.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6186/Reviewer_hzx9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6186/Reviewer_hzx9"
        ]
    },
    {
        "id": "tGBrpuz-jQ2",
        "original": null,
        "number": 3,
        "cdate": 1666737980642,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666737980642,
        "tmdate": 1666762077962,
        "tddate": null,
        "forum": "h9O0wsmL-cT",
        "replyto": "h9O0wsmL-cT",
        "invitation": "ICLR.cc/2023/Conference/Paper6186/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the regression task with label differential privacy. It proposes a label flipping mechanism with the guarantee of $(\\varepsilon, \\delta)$-label DP and further proves that it is the optimal label-DP mechanism which achieves the minimum expected loss between the original label and the flipped label. Finally it evaluates the proposed label DP mechanism and classical Laplace Mechanism on three different datasets. The result shows the efficacy of the proposed mechanism.",
            "strength_and_weaknesses": "**Strength**\n1. The writing of this paper is very clear.\n2. This paper proposes a novel label-DP algorithm and proves its optimality w.r.t. the expected loss between the original label and the flipped labels.\n3. The experiments are conducted on the real world datasets and the results are convincible.\n\n**Weaknesses**\n1. As stated, the proposed label-DP mechanism is optimal w.r.t. the first term in the RHS of Equation (1). However, the mechanism will also influence the minimum of the second term, which is the bayes optimal error to predict $\\hat{y}$ from $x$. Think of this simplified setting: when $y$ is deterministic given $x$, the bayes optimal error is equivalent to the variance of $\\hat{y}$ condition on $y$. By considering this additional variance, it is potential to come up with a better label-DP mechanism w.r.t. the entire RHS of Equation (1).\n2. Is it possible that the number of optimal bins is smaller than the number of different labels?",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity is good and the method is novel.",
            "summary_of_the_review": "Given that the algorithm is novel and proved to be optimal in a general setting, I give the score of 8.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6186/Reviewer_deEc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6186/Reviewer_deEc"
        ]
    },
    {
        "id": "jzewTLFC6x",
        "original": null,
        "number": 4,
        "cdate": 1666836976348,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666836976348,
        "tmdate": 1668529753399,
        "tddate": null,
        "forum": "h9O0wsmL-cT",
        "replyto": "h9O0wsmL-cT",
        "invitation": "ICLR.cc/2023/Conference/Paper6186/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Paper proposes regression with label differential privacy and introduces randomized response on bins as a new mechanism to induce differential privacy on labels.",
            "strength_and_weaknesses": "Proposed method is interesting and of practical use where one might want label differential privacy. Empirical evaluation shows that the proposed method performs better than other common DP methods such as Laplace, Exponential, and staircase. \n\nPaper is clearly written and is easy to follow. Assuming the proofs go through (I did not check them in detail), I think the paper will make positive contribution to the DP community. My only question is that there should be some discussion on why it is not compared against other label-DP methods such as [1].\n\n[1] Ghazi, B., Golowich, N., Kumar, R., Manurangsi, P., & Zhang, C. (2021). Deep learning with label differential privacy. Advances in Neural Information Processing Systems, 34, 27131-27145.",
            "clarity,_quality,_novelty_and_reproducibility": "paper is clearly written and is easy to follow",
            "summary_of_the_review": "paper is easy to follow and has the potential for a net positive impact.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6186/Reviewer_dKhp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6186/Reviewer_dKhp"
        ]
    }
]