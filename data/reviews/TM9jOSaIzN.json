[
    {
        "id": "_ymuf09B7l",
        "original": null,
        "number": 1,
        "cdate": 1666521576059,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666521576059,
        "tmdate": 1666521616591,
        "tddate": null,
        "forum": "TM9jOSaIzN",
        "replyto": "TM9jOSaIzN",
        "invitation": "ICLR.cc/2023/Conference/Paper1378/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors developed a natural images reconstruction model from fMRI with hierarchical variational autoencoders. Their model achieved better reconstructions compared to the state of the art and our ablation study indicates that the hierarchical structure of the latent space is responsible for that performance.\nThe main contributions are as follows: 1. The paper leveraged the hierarchical manner of human brain during visual stimuli and proposed a novel architecture with hierarchical variational autoencoders to reconstruct neural images. 2. Their architecture replicates the natural hierarchy of visual information processing in the latent space of a variational model. 3. Their experimental analysis suggests that hierarchical latent models provide better priors for decoding fMRI signals.",
            "strength_and_weaknesses": "Strength:\n1. This is the first approach that uses HVAEs in the context of neural decoding.\n2. The proposed method combines decoding models with neuroscience priors and the motivation makes sense.\n3. The experiments are relatively sufficient.\n\n\nWeaknesses:\n(major)\n1. Experiments have serious data leakage problem. The HVAE were pretrained in ImageNet and the dataset GOD you used is still collected based on ImageNet. Accordingly, I think the results of this paper is unbelievable.\n2. Although authors has pointed out why they only used GOD dataset, there is still a lot of preprocessed datasets that can be used such as BOLD 5000 and NSD. NSD dataset is collected based on MS-COCO which can avoid aforementioned problem.\n3. The compared methods are not comprehensive. I suggest that the authors add the method proposed in \"Mind Reader:\nReconstructing complex images from brain activities\"  in which the reconstruction quality is relatively better than the compared methods you have chosen.\n4. The article introduced less content about HVAE, formula (1) is even traditional VAE, and used a lot of space introducing the background and evaluation indicators of neuroscience.  By the way, formula (1) and formula (2) needn't two labels.\n\n\n(minor)\n1. The writing of this paper is terrible.  A major refine of this manuscript is necessary.  Informal expressions such as \"{fMRI,Image} pairs\" and \"Naturally, if our fMRI data are more fine grain, we can add additional latent layers\" should be avoided.  Typos such as text in line 3 of page 5 should be corrected. In the experimental results, text wrapping charts is not acceptable for readers.  The structure of the article needs a careful adjustment such as the last two paragraphs of 3.1 should be placed into experimental details.\n2. The main results part should contain a series of subtitle for easy understanding.",
            "clarity,_quality,_novelty_and_reproducibility": "The novelty this paper is modest but easy to understand. However, major flaw with respect to data using exists which leads to unbelievable experimental results.  The paper contains a large number of informal expressions and clerical errors, the structure is not clear, and the layout is confusing. According to this, the clarity and quality of the paper are  poor. The reproducibility is poor since the code is not available.",
            "summary_of_the_review": "The work applies an existing method to an existing task. The novelty this paper is modest but easy to understand. My major concern is the flaw with respect to data using exists which leads to unbelievable experimental results. Besides, the writing of this paper is terrible. I think the quality of the paper is not up to the average quality of the papers accepted by ICLR. I suggest the authors should change their experimental data and carefully revise the manuscript.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1378/Reviewer_sMBW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1378/Reviewer_sMBW"
        ]
    },
    {
        "id": "-J2IXddOTu",
        "original": null,
        "number": 2,
        "cdate": 1666577094234,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666577094234,
        "tmdate": 1666577094234,
        "tddate": null,
        "forum": "TM9jOSaIzN",
        "replyto": "TM9jOSaIzN",
        "invitation": "ICLR.cc/2023/Conference/Paper1378/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors used a hierarchical VAE to learn representations from natural images and leverage their latent space hierarchy to learn voxel-to-image mappings. They showed that mapping V1/V2 responses to the early layer and higher visual areas to the deep layer of the latent hierarchy allow them to achieve superior image decoding performance than state-of-the-art approaches. ",
            "strength_and_weaknesses": "Strength: Their image decoding results are very impressive, far better than state-of-the-art.\nWeakness: The insights are perhaps obvious, and the technical innovation is relatively minor. \n\nThe comparison between V1/V2 versus ventral and dorsal is not completely fair and problematic.  These comparisons are confounded with different numbers of parameters, and thus the conclusion about the contribution of the different visual areas, ventral and dorsal streams are  potentially problematic.  It seemed that the more neural responses are used, the best would be the performance. For instance, if they include V3 in the ventral stream's model, would  the performance be even better?   To their credit,  they did show that the hierarchy is important, and their argument that the critical comparison is within the naive baseline which has the same number of parameters is not unreasonable. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clear enough and well written. ",
            "summary_of_the_review": "This paper achieved the best performance in image decoding based on fMRI signals. The motivation is sound, the idea obvious. The technical innovation is minor.  it would become the new baseline for future algorithms to compare against. The comparison between V1/V2, ventral and dorsal streams are potentially problematic and incomplete. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1378/Reviewer_eDwx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1378/Reviewer_eDwx"
        ]
    },
    {
        "id": "9ki3-KFKl9",
        "original": null,
        "number": 3,
        "cdate": 1666626259399,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666626259399,
        "tmdate": 1666626259399,
        "tddate": null,
        "forum": "TM9jOSaIzN",
        "replyto": "TM9jOSaIzN",
        "invitation": "ICLR.cc/2023/Conference/Paper1378/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This study analyzes existing functional magnetic resonance imaging (fMRI) data from human participants that passively viewed a series of images. The analysis is based on using hierarchical variational autoencoders and then using fitting to map the activations of units in the model to the activation of voxels in order to reconstruct the images. Compared to a few baselines, the authors claim to obtain better qualitative results in reconstructions and better quantitative results in discriminating images across trials without cross-validation across images.",
            "strength_and_weaknesses": "Strengths\n\nIt is interesting to link neural representations to machine learning representations, if done correctly. \n\nWeaknesses\nThe title is somewhat misleading. While the word \u201cimagery\u201d can be used to denote the processing of images, a lot of people in the community have used the word to denote visual imagination, which is not what this study is about. The authors briefly mention decoding dreams and such in the conclusion as potential future work, but this is not what is shown here.\n\nIt is unclear what the goal of the algorithm should be. One goal could be to attempt to reconstruct images from fMRI voxel activity. The qualitative comparison of perhaps cherry-picked examples is not a convincing result and certainly not a rigorous way of presenting results. The authors present some quantitative results in Fig. 4, but they do not define what 2-way, 5-way, and 10-way represent. More critically, why is it relevant to reconstruct images? The purpose of the visual system is to extract useful information, not to reconstruct images. One should get a much better reconstruction from the activity of neurons in the retina. Whatever cortex does, it is not reconstruction. \n\nA central issue is to understand what goes into the training set and what goes into the test set. The first question is whether any of the results represent cross-validation across images. My understanding is that the authors are only using cross-validation across trials, which is not very interesting. Any powerful enough model can memorize the dataset. In this case, the only question is how consistent the data are across trials. If this is the main point, it would be useful to show the degree of consistency in the data across trials, showing the actual data across repetitions and measures of self-consistency. \n\nA different question, and a more interesting one is to perform cross-validation across very different images. In this case, there are a lot of questions that should be addressed. First, are the images in the training set and test set from the same categories (i.e., same imagenet labels)? How different are the images in the training set and the test set? How well can simple classifiers match the images in the test set to those in the training set? These are critical questions to assess what the models are doing or trying to do.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "As noted above, there are crtitical questions about the methodology that are not clearly described.\n\nfMRI data have very low quality and signal-to-noise ratio. \n",
            "summary_of_the_review": "This is an effort to try to reconstruct images from fMRI data. Although the proposed method performs better than the baselines suggested by the author, it is unclear whether this can really extrapolate and provide any real insights about the underlying representations",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1378/Reviewer_J68Z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1378/Reviewer_J68Z"
        ]
    },
    {
        "id": "jpBpVWpyAa",
        "original": null,
        "number": 4,
        "cdate": 1666742436620,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666742436620,
        "tmdate": 1671518419378,
        "tddate": null,
        "forum": "TM9jOSaIzN",
        "replyto": "TM9jOSaIzN",
        "invitation": "ICLR.cc/2023/Conference/Paper1378/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a novel method for decoding images from FMRI, using a hierarchical VAE. First, a VAE is trained on images from imagenet. Then the encoder is removed, and a mapping is learned from the images to the latent variables of the VAE. The VAE is divided into lower and higher level areas (i.e., it's hierarchical), and lower and higher level brain recordings are used to feed into corresponding areas. The results are impressive, and to my knowledge, represent a new state of the art. \n\nAfter reading the other reviews, and the authors' responses to them, I am going to reduce my score from 10 to 8, as they used the test set to set hyperparameters. While they claim that the hyperparameters were not particularly impactful on the results, this is a clearly big mistake in terms of ML practice and should be avoided at all costs. Nevertheless, I believe their results still hold (as they used pretty standard hyperparameters, apparently), and the hierarchical nature of their model clearly makes a difference, and is worth publishing.\n\nAfter reading the response to my reduction in score, I'm not clear that the authors totally understand that hyperparameters should not be tuned on the test set. They seem to think it is ok to tune training hyperparameters using the test set. This is still not the case. Again, I think there is still much to like here.",
            "strength_and_weaknesses": "This is an excellent paper, with excellent results. \n\nStrengths:\n\n+ The approach is well-motivated by reference to lower and higher brain areas corresponding to lower and higher layers of the decoder.\n\n+ Although the above point has been made before, the novelty here is that the decoder is used to map to the latent variables at different levels of the hierarchical VAE, rather than to the feature layers of a CNN.\n\n+ The results are very strong, both quantitatively and qualitatively.\n\n+ The direct comparison to a factored model with the ROIs randomly assigned to the hierarchy is a nice demonstration that it is the hierarchy that matters, not the division into regions. \n\nWeaknesses, with concrete, actionable feedback\n\n- There are a few things that could be corrected easily, in terms of typos, etc. See below.\n\n- why didn't you include LOC in the Ventral pathway model?\n\n- The poorer results based on mapping all of the voxels to one latent might be a result of the LOC voxels being noisier. A fairer comparison would be to create three more baseline models, each one using the same areas as the three hierarchical models, but without the hierarchy. This would make a stronger argument for the approach. \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "In the abstract, you say: \"The current architectures are bottlenecked because they fail to effectively capture the hierarchical processing of visual stimuli that takes place in the human brain. Motivated by that fact,...\"\nThis is not a fact, it is an opinion. Please fix.\n\nFigure 2b has a bug - you show the lower visual areas feeding into Z_2 and the higher ones into Z_1, which is the opposite of what the Figure caption says. Also, in the caption: \"using by discarding\" -> \"by discarding.\" Also, there is no (a) or (b) in the figure. You could say \"top\" and \"bottom\" instead.\n\nabstract, main text: You mention that you decode \"natural\" images and train the VAE on \"natural\" images. These images are not natural - that wording refers to images of natural scenes, like forests, woods, etc. Just remove the word \"natural\" everywhere.\n\nTypos, wording:\n1st line of page 3:  object -> objects\nFig 2 caption: using by -> by\nsec 3.3, line 3: contain -> contains\npage 6, line 3: thought -> though\nline 7: fact -> facts\n6th line from the bottom: \"compares our method\" - which method? I assume the ventral pathway. Again - why didn't you include LOC?\n4th line from the bottom: you say you average the fMRI responses corresponding to the same category. I assume you mean corresponding to the same image, not category. If you are averaging responses over categories, that definitely needs more explanation.\n\nPage 7, middle: \"Qualitatively...\" Qualitatively, the ventral and the dorsal both look about the same to me, and this is born out in the quantitative scores, which are very close. \n5th line from the bottom: there -> three. But I would just remove the whole \"i.e., we aim to compare...\" phrase - it isn't needed. Then replace the sentence that starts \"The former ones...\" with: \"The three models, PS, DP, and VP, are hierarchical, whereas the naive baseline includes...\" \n3rd line from the bottom: \"by breaking down brain to two...\" -> by breaking down the fMRI responses from two regions, V1 and V2, and discarding all other voxels, we are able to achieve better performance compared to mapping all the voxels into one latent vector. \n\nPage 8: \"Furthermore, we observe that the SSIM gives a modest but consistent performance gain compared to PCC.\" No! That just means that SSIM is a slightly more lax measurement. The two measurements are not directly comparable. There is no reason (based on the numbers) to prefer one to the other. \n2nd line from the bottom: subject -> subjects.",
            "summary_of_the_review": "I can find few weaknesses and many strengths in this work. There is novelty (mapping to latents rather than features), a nice comparison between using just V1 and V2, using the dorsal pathway, and using the ventral pathway, as compared to a non-hierarchical model that uses all of the voxels. However, the final paper should include comparisons with each of the three models using the same areas without the hierarchy.\n\nAgain, in summary, I am reducing my score based on the hyperparameter tuning.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1378/Reviewer_H6z7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1378/Reviewer_H6z7"
        ]
    }
]