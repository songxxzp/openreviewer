[
    {
        "id": "c9sCOvl5iV",
        "original": null,
        "number": 1,
        "cdate": 1666620133680,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666620133680,
        "tmdate": 1666620133680,
        "tddate": null,
        "forum": "1-B8dz847_",
        "replyto": "1-B8dz847_",
        "invitation": "ICLR.cc/2023/Conference/Paper2444/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work proposed a novel learning problem for binary classifications, namely Confidence-Difference (ConfDiff) classification, in which the learner is only given unlabeled data pairs $x,x'$ equipped with confidence difference specifying the difference in the probabilities of being positive $P(y'=1|x') - P(y=1|x)$. The authors proposed to solve the problem via ERM by constructing an unbiased risk estimator. Estimation error bound was derived, and the robustness of the risk estimator was analyzed. Experiments demonstrated effectiveness of the proposed method.",
            "strength_and_weaknesses": "**Strong points.**\n\nThe proposed learning problem is interesting. The proposed method is backed by strong theoretical analyses and empirical results. The paper is well-written and easy to understand.\n\n**Weak points.**\n\nThe concern I have is that whether the proposed learning problem is a valid weakly supervised learning paradigm. Confidence labels (posterior class probabilities $P(Y=1|X)$) certainly contains more information than the usual labels. On the other hand, unlabeled data pairs and differences somewhat constitute a weaker learning problem. Thus, to me, it is not entirely clear whether learning with unlabeled data pairs and confidence differences is a weaker or stronger learning problem.\n\nAlso, in the experiments, Pcomp was compared against. However, as mentioned in Section 2.3, in Pcomp classification, the learner only knows unlabeled pairs, and within each pair $x,x'$, which one is more likely to have positive label than the other (whether $P(y'=1|x') > P(y=1|x)$). Clearly, ConfDiff classification has access to more information. Thus, it is expected that ConfDiff can outperform Pcomp. Nevertheless, it is okay to use Pcomp as a baseline.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-organized and well-written. I enjoyed reading it. Overall it is novel at large. The reproducibility is good.",
            "summary_of_the_review": "I vote for a weak accept as I think the paper overall meets the standard, and its contributions outweigh its shortcomings.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "Not applicable.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2444/Reviewer_dSMd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2444/Reviewer_dSMd"
        ]
    },
    {
        "id": "ewtfnMNoXo",
        "original": null,
        "number": 2,
        "cdate": 1666680083014,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666680083014,
        "tmdate": 1666680083014,
        "tddate": null,
        "forum": "1-B8dz847_",
        "replyto": "1-B8dz847_",
        "invitation": "ICLR.cc/2023/Conference/Paper2444/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes to learn from observing probability differences between pairs of labels, in a binary classification setting. The premise is that obtaining such information is sometimes easier than obtaining single probability estimate, and richer than simple qualitative comparisons. \n\nThe paper demonstrates that such information is sufficient to converge towards the optimal risk, deals with the case of corrupted estimates, and also propose a correction to avoid the loss becoming negative through a ReLu correction. \n\nSome experiments are done, in particular to compare with a qualitative feedback. ",
            "strength_and_weaknesses": "+: the paper is clearly written, and I think the proofs are correct (I am less familiar with generalisation bounds, so I cannot give strong guarantees for Theorem 3 and the next ones, but the reasoning seems ok to me). \n\n+: As far as I know, the proposed framework is original\n\n-: it is not clear at all to me, despite the two high-level examples given in the introduction, that providing accurate probability differences for pairs of data is much easier/simpler than providing single probability estimates. While I would agree that providing qualitative comparison (Pcomp framework) is easier, it is not so clear for probability differences. And the argument put forward later on that different experts may disagree on probabilistic estimates is equally true for probabilistic differences. Do we have actual evidence (and not illustrative example, that I have a hard time really figuring out) that this is indeed the case in some applications? Maybe the authors could elaborate a bit more on their examples to provide a fuller story, where the estimates are explicitly mentioned?\n\n-: while Pcomp and Pconf can be adapted easily to multi-class setting, it seems intuitively harder to adapt the current proposal to more than two classes, both from a theoretical perspective but also from a practical perspective (it seems very demanding and hard to elicit probability differences over all pair of classes). Could some comments be provided with respect to that? \n\n-: I do not understand why the framework is not compared, in Table 1 (or in appendices tables) to both Pconf and the framework where data are fully observed (rather than using various Pcomp variants).\n\n-(minor): I wonder why in the test non-binary data sets were turned into binary data sets. UCI and other repositories contain plenty of native binary data sets, and it is unclear why those particular data sets were chosen, and why the separation was chosen the way it was? ",
            "clarity,_quality,_novelty_and_reproducibility": "Overall the paper is clear and well-written.",
            "summary_of_the_review": "The paper proposes a new learning framework considering as supervision differences of probabilities. While the theoretical analysis is interesting, it is unclear how practical this framework is, nor how realistic is the assumption that we can have good estimates of probability differences. It is also unclear how the framework could extend beyond binary classification. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2444/Reviewer_sacA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2444/Reviewer_sacA"
        ]
    },
    {
        "id": "4Hgpg9Ltr_",
        "original": null,
        "number": 3,
        "cdate": 1667522997323,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667522997323,
        "tmdate": 1667522997323,
        "tddate": null,
        "forum": "1-B8dz847_",
        "replyto": "1-B8dz847_",
        "invitation": "ICLR.cc/2023/Conference/Paper2444/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies a weakly supervised learning setting, in which one has limited access to the *confidence labels* of the training examples. Previous work in this line includes the setup with pointwise confidence scores (Pconf), and the setup where pairwise comparisons of the confidence scores are available (Pcomp). This work presumes more fine-grained information than the latter: Unlabeled data pairs with confidence difference (ConfDiff). This learning setup is then formulated as empirical risk minimization and a corresponding unbiased risk estimator is constructed, together with an estimation error bound.\n\n",
            "strength_and_weaknesses": "### Strength  \n\n- The paper is technically well formulated. The proposed learning setting was rigorously set up and an unbiased risk estimator is derived for the empirical risk minimization. \n- The paper is well written and easy to follow. Even people outside this particular field should be able to grasp the general idea proposed therein. \n\n### Weaknesses\n\n- In my opinion, the biggest weakness of this paper is its setting. Is the setting realistic? The paper doesn't provide sufficient motivation in the introduction; it also lacks realistic experimental setup to support the ConfDiff setting. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written. As far as I can tell, the reproducibility is high (although I didn't read all the proofs.)\n\nRegarding the novelty, while I do think the ConfDiff setting is new, I am doubtful if it is a realistic or useful setting in practice, as mentioned above.",
            "summary_of_the_review": "As mentioned earlier, my key issue of this paper is that I don't think the ConfDiff setting is realistic. \n\nIn terms of the level of information required in training, ConfDiff sits in between Pconf and Pcomp, in theory. In practice, however, I don't see a situation where one obtains the exact difference between two confidence scores, **without** first estimating the pointwise confidence scores. Even the experiments in the paper have to first do the point estimation. \n\nIt was mentioned in the paper that *the confidence difference is given by annotators in real-world applications*. Has such annotation procedure ever actually applied in the real world? We have to realize that it is extremely hard for a human annotator to give exact confidence difference between two examples. I would say the annotation settings of Pconf and Pcomp are, comparably speaking, more realistic. In the case of former, each annotation provides more information. (Also I'd say the annotator might have to do pointwise estimates first before giving exact confidence differences). In the case of latter, the annotation is much simpler for the annotator as it is only a qualitative paired comparison.\n\nIn any case, I think the paper should motivate the proposed setting better, ideally with some real-world applications. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2444/Reviewer_bMCm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2444/Reviewer_bMCm"
        ]
    }
]