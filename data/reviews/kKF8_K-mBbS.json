[
    {
        "id": "Tw1-EuIvtBZ",
        "original": null,
        "number": 1,
        "cdate": 1666519450581,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666519450581,
        "tmdate": 1666675653128,
        "tddate": null,
        "forum": "kKF8_K-mBbS",
        "replyto": "kKF8_K-mBbS",
        "invitation": "ICLR.cc/2023/Conference/Paper2065/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors present a molecular docking method based on diffusion model. They suggest a diffusion process for this space and an architecture that learns on this process. The authors present results on a version of PDBbind. ",
            "strength_and_weaknesses": "Strengths:\n\n* Clearly written and structured; hyperparameter selection clearly described\n* The principle idea to use diffusion models to predict 3D coordinates of atoms of a molecule is good (however not new; see weaknesses)\n\nWeaknesses\n\n* the work is not novel, but the use of diffusions for molecule conformations has been suggested before (see ref [1], [7])\n* the work is poorly embedded into related work and almost fully ignores decades of work in molecular docking\n* the mathematical formulation is sloppy and potentially wrong (see below), with notation overloads and inconsistencies\n* there is only a single experiment on one dataset which limits the conclusions\n* the work is strongly focused on a specific problem in an application domain, with no idea put forward how this would be relevant for ML in general\n* the method comparison neglects scientific standards to perform repetitions, provide error bars or confidence intervals and statistical tests. Almost all performance metrics are shown without error bars\n* the paper contains many ad-hoc and un-justified decisions\n* the paper contains many incorrect or tenuous claims\n",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity\n\nThe paper is well structured and clearly written, but the math is sloppy (see Minor Comments).\n\n### Quality\n\na) This work does not embed itself into prior and similar works. It almost fully ignores a the decade-old field of molecular docking. Furthermore, it also ignores close works in machine learning (e.g. [1]).\n\nb) There are several severe problems in the experimental part of this paper.\n\ni) Only a single experiment on a dataset called PDBBind is performed, while there are many more benchmark datasets in the community (e.g. different variants of the DUD datasets).\n\nii)Inconsistencies with previous comparisons and focus on single metric that uses a threshold that is convenient for the author's method. In a previous method comparison ([5], Figure 4, comparable with Figure 3 of this paper) or another one ([7], Figure 2), the docking methods exhibit much better performance than in the presented work. Furthermore, the docking community has established multiple more metrics that are informative. One reason could be that the hyperparameters of the docking methods have not or insufficiently been adjusted to the author's training set. The authors should compare their method on previously established benchmarks in the community, ensure a fair comparison, and relate their results to prior results and show other metrics.\n\niii) A large number of methods has not been compared. There is a large battery of docking methods that have not been compared, VirtualFlow, Autodock, Glide, GOLD, ... [5]. The authors should compare their method against other docking methods.\n\niv) Complete absence of baselines. Method comparisons should contain a number of baselines such that the improvement over those can be judged. For example, a generic transformer or MPNN or even MLP could be compared. The authors should include baselines into the method comparison, e.g. generic transformers or SE3-equivariant tranformers, MLPs, generic MPNNs.\n\nv) Except for the author's method in Table 1, all performance metrics in text, tables and figures are missing error bars. There is an absence of re-runs, error bars, confidence intervals and statistical test to determine whether the claimed improvement arises not just by chance. The others should perform multiple training runs or repetitions for each run; for docking methods this might mean that the hyperparameter should be adjusted to the training data. The authors should provide error bars or confidence intervals for all metrics and perform statistical tests.\n\nc) The diffusion process and the model and its architecture contain many ad-hoc decisions. These are hardly justified or possible alternatives explained. For example, there are many possible representations on which the diffusion operates (e.g. [1]); there are many options for representing the protein (compare AlphaFold [6]) or the ligand. For example, an alpha-fold like representation as \"residual gas\" and a transformer-like architecture could also be used as model. The author's should justify their choices, perform ablations studies of the main architectural components and include other architectures as baselines.\n\nd) It is unclear from which component the claimed performance gain arises: the formulation of the problem as diffusion process or from the neural network architecture. The authors should investigate from which of the many components of their work, the performance improvement mainly arises.\n\ne) The proof of proposition 1 is either sloppy or wrong:\n- It is unclear how equation (5) is derived from equation (4). The differential quotient $d(x(t))/dt = lim_{t\\to0} (x(t)-x(0))/t$ in equation (5) seems different from taking the limit $t\\to0$ of the difference $x(t)-x(0)$ in equation (4). It is further unclear, whether/under which conditions the $min_{R,p}$ at the RHS may compute with a potential $lim$-operation. Isn't it a $min_{R(t),p}$? Seeing intermediate steps might be helpful.\n- Description of the proof between equation (5) and equation (6) \"The derivative in the LHS of Equation 5 at t = 0 is\": Is here really the LHS meant and not the RHS? Assuming the latter case: It would be helpful, if the intermediate steps would all be given. My best assumption for the derivative of the first term is: $d/dt (R(t)(B(t\\theta,x(0))-\\bar{x}_0)= (R'(t)(B(t\\theta,x(0))-\\bar{x}_0)+ (R(t)d/dt(B(t\\theta,x(0))-\\bar{x}_0)=(R'(t)(B(0,x(0))-\\bar{x}_0)+ (R(t)d/dt(B(t\\theta,x(0))-\\bar{x}_0)=(R'(t)(x(0)-\\bar{x}_0)+ (R(t)d/dt(B(t\\theta,x(0))-\\bar{x}_0)$ with the interpretation, that $x=x(0)$. But isn't then the inner derivative like $ d/dt(B(t\\theta,x(0))=B'(t\\theta,x(0)\\theta$ missing?\n- Is the step to take gradients wrt. to $v, \\omega$ related to the min_{R,p} operation? Or why, does it make sense to take the gradient at this step?\n- in general: there seem several name collisions in the proof, which make it hard to understand, e.g. x is used as a parameter of A, but also as a function x(t)\n\nf) For proposition 2:\n- Could a highly symmetric molecule part (e.g. with 3 identical atoms attached to a center atom, which is further) attached to a single bond, to which a second unsymmetric molecule part is attached, and a 120\u00b0-SO(2)-rotation together with some further SO(2) rotations in the unsymmetric part be a potential counter example to the proposition? (==> for the single bond there seem more parametrizations, which leave the molecule unchanged)\n\n### Novelty\n\nThe main idea to use diffusion models to generate 3D coordinates of molecules and their atoms has been suggested at least by [1,7] and also [6]. The so-called \"paradigm shift\" that the authors claim, has already been done before. The remaining novelty about problem representation and adjustment to docking falls into the application field.\n\n### Reproducibility\n\nThe dataset is publicly available, but the code has not been upload as supplementary material, which means that reproducibility is low. The authors should upload the dataset and the code as supplementary material\n\n### Other, minor comments\n\nMany incorrect or tenuous statements:\n\na) In 4.2 in the formula for overline x, the summation index is missing. In proposition 1, there is also an error in this formula, since over a constant x is summed.\n\nb) Also in Proposition 1, a time dependent x(t) is introduced that is then never used again. The formulas below contain the non-time-dependent x again.\n\nc) \"DIFFDOCK significantly outperforms all previous methods\": incorrect because no statistical test has been performed.\n\nd) Figure 2 caption \"when there is a global symmetry in the protein (aleatoric uncertainty)\": Unclear, missing or incorrect description of \"aleatoric uncertainty\". Does the EquiDock model provide separate estimates for aleatoric and epistemic uncertainty? If it is aleatoric, it cannot be reduced by modeling (unavoidable uncertainty), however, DiffDock somehow decreases it.\n\ne) \"However, these approaches learn distributions over the full Euclidean space R3n with 3 coordinates per atom, making them ill-suited for molecular docking where the degrees of freedom are much more restricted.\" This claim is put forward without any experimental evidence and the mentioned methods are further ignored and not even compared.\n\n### Questions:\n\n- What does ${l,r}$ in the direct sum of formula (15) refer to (esp. r, is only a single l used)? \n- Is the magnitude of the distance vector between nodes somewhere used in (15) or does the equation only use the direction?\n- What does $\\mu$ in formulas (16) and (18) refer to? Is it an MLP? Are they $\\mu$'s related (shared)?\n- Could the authors elaborate, why the coarse-grained representations don't allow for parity or non-parity?\n- Why is the tangent space for torsions SE(3) invariant and not SE(3) equivariant?\n- Can you provide a reference, which argues, that an RMSD < 2A is an important criterion? Figure 3 seems to show, that this is exactly the range, where DiffDock performs well. Lowering the threshold, it seems that other methods could gain additional advantages.\n\n### References\n\n[1] Xu, M., Yu, L., Song, Y., Shi, C., Ermon, S., & Tang, J. (2021, September). GeoDiff: A Geometric Diffusion Model for Molecular Conformation Generation. In *International Conference on Learning Representations*.\n\n[2] Mysinger, M. M., Carchia, M., Irwin, J. J., & Shoichet, B. K. (2012). Directory of useful decoys, enhanced (DUD-E): better ligands and decoys for better benchmarking. *Journal of medicinal chemistry*, *55*(14), 6582-6594.\n\n[3] Thomsen, R., & Christensen, M. H. (2006). MolDock: a new technique for high-accuracy molecular docking. *Journal of medicinal chemistry*, *49*(11), 3315-3321.\n\n[4] Gorgulla, C., Boeszoermenyi, A., Wang, Z. F., Fischer, P. D., Coote, P. W., Padmanabha Das, K. M., ... & Arthanari, H. (2020). An open-source drug discovery platform enables ultra-large virtual screens. *Nature*, *580*(7805), 663-668.\n\n[5] C\u0327\u0131narog\u0306lu, S. S., & Timuc\u0327in, E. (2019). Comparative assessment of seven docking programs on a nonredundant metalloprotein subset of the PDBbind refined. *Journal of Chemical Information and Modeling*, *59*(9), 3846-3859.\n\n[6] Jumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M., Ronneberger, O., ... & Hassabis, D. (2021). Highly accurate protein structure prediction with AlphaFold. *Nature*, *596*(7873), 583-589.\n\n[7] Hoogeboom, E., Satorras, V. G., Vignac, C., & Welling, M. (2022, June). Equivariant diffusion for molecule generation in 3d. In *International Conference on Machine Learning* (pp. 8867-8887). PMLR.\n",
            "summary_of_the_review": "The novelty of the proposed method is low because similar works using diffusion processes for molecules have been suggested before. The relevance for machine learning is very limited because many settings of the application domain have been used, therefore, it is unclear how to transfer this to similar ML problems. Technically, there are many severe problems, such as the limited experiments, problems in the method comparison, inconsistencies with previous method comparisons, missing error bars, and sloppy mathematical formalisms. Together with the many false and tenuous claims, the work defies some basic scientific practices.\n\nHowever, with some improvements this work will be highly interesting for the molecular docking community and will be a valuable contribution there.\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2065/Reviewer_Yi6P"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2065/Reviewer_Yi6P"
        ]
    },
    {
        "id": "CzREHZd4RUv",
        "original": null,
        "number": 2,
        "cdate": 1666680269595,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666680269595,
        "tmdate": 1666680269595,
        "tddate": null,
        "forum": "kKF8_K-mBbS",
        "replyto": "kKF8_K-mBbS",
        "invitation": "ICLR.cc/2023/Conference/Paper2065/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors propose DiffDock, an approach to global molecular docking as a generative modeling problem that aims to map the non-Euclidean manifold of ligand poses to the degrees of freedom involved in docking sampling by developing a diffusion process on this space. They propose an objective formalism that aims to maximize the expected proportion of predictions with RMSD < some tolerance \u03f5 motivating the training of a generative model that learns a distribution over ligand poses conditioned on the protein structure as context. In addition, a confidence model is proposed which is trained on the poses sampled by the diffusion model to rank them based on its confidence that they are within an error tolerance. Therefore posing and scoring is achieved by this process. The paper evaluates PDBBind dataset with the task of blind docking evaluated by the RMSD compared to the reference co-crystal structure. DiffDock is then compared to SOTA search-based and deep-learning methods. When evaluating the top scoring pose being <2A\u02da from the co-crystal ligand, DiffDock **significantly** outperforms all compared methods with also being 3 to 12 times faster than the best search-based method.",
            "strength_and_weaknesses": "**Strengths**:\n\nThe proposed diffusion generative model formalism and application to the problem solving a global docking objective is novel and theoretically sound. The addition of the score-based generative model as a ranking mechanism takes the applicability of the diffusion probabilistic method to the next level in terms of posing, scoring, and creating a useful tool.\n\nThe comparison to search-based methods (as a quasi-null model) exemplified the significance of the results presented in the manuscript, and clearly DiffDock provides a significant improvement with the experimental protocol performed by the authors. The plots showing the fraction of RMSD vs. other factors further demonstrate the significant improvements compared to other methods and how well the distributions capture the data-generating process. \n\nWeaknesses:\nA large weakness of the work appears to be the lack of curation and preparation of the ligand and protein structures obtained from PDBBind. Structure-based drug design is only useful if the structures have been properly prepared by quantifying ionization/tautomeric states for ligands and H-bond optimization/protonation for proteins (garbage in~garbage out). When evaluating the code, it was clear that raw structures were input with minimal curation/preparation. If these raw structures were used as input to the other docking methods, then it is no surprise they performed poorly. The authors should describe their protein-ligand structure preparation protocol in detail. \n\nIt is not clear if PDBBind is the best dataset to use for evaluating the global docking problem, as all structures are holo-structures (co-crystal structures; i.e. structures in the ligand-bound conformation). A more relevant test set would be an apo (no ligand bound) structure of the same protein, similar to what is available in the PSCDB (http://idp1.force.cs.is.nagoya-u.ac.jp/pscdb). While this task would be more challenging, it would be more relevant for real-world problems encountered in drug discovery. It is well known in the docking community that predicting <2A\u02da poses to holo-structures is much easier if the protein and ligand are prepared correctly, but recapitulating the crystallographic pose when docking to apo structures is much more challenging, even when integrating orthogonal biophysical data collected experimentally.\n\nIt appears that only C\u03b1 atoms are used for the node and edge featurization of the protein. This is a large limitation as structure-based drug design requires explicit representation of rotamers for amino acids as the orientation/protonation of these residues can dramatically alter what interactions can be made and ultimately whether a molecule will bind with sufficient potency to warrant detection in an in vitro assay.\n\nSome of the molecules generated by this approach are not physically possible to produce and would be incredibly unstable on planet earth.",
            "clarity,_quality,_novelty_and_reproducibility": "The manuscript is clear and reads well. The theory is well described in detail. As mentioned above, more detail is required regarding data curation and protein-ligand preparation for all methods tested in the manuscript. Details matter when evaluating predictive methods in structure-based drug design, as the movement of a proton or alternative rotamer on a protein can completely change an interaction necessary for binding.",
            "summary_of_the_review": "The authors propose DiffDock, a generative diffusion model tailored to the task of molecular docking. The approach fundamentally differs from regression-based frameworks and leverages a generative modeling approach to capture a diffusion process over the manifold describing ligand pose transformations and docking degrees of freedom. DiffDock demonstrates significant improvements over SOTA search-based and deep-learning approaches to global docking on the PDBBind dataset. It is not clear how exactly the protein-ligand structure data was curated and prepared from the PDBBind dataset or why the PDBBind database was chosen for the task of global docking. Still, the data was presented clearly, and the theory was well described. As outlined above, there are clear gaps that must be addressed before DiffDock will be useful for real-world applicability in drug discovery, and it is clear that there is a lack of domain expertise in computational chemistry and structure-based drug design. However, I believe the theoretical contributions and novelty of the manuscript warrant acceptance to ICML following revision.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2065/Reviewer_UKAX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2065/Reviewer_UKAX"
        ]
    },
    {
        "id": "YhbLnS_1_sn",
        "original": null,
        "number": 3,
        "cdate": 1666692808825,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666692808825,
        "tmdate": 1666692808825,
        "tddate": null,
        "forum": "kKF8_K-mBbS",
        "replyto": "kKF8_K-mBbS",
        "invitation": "ICLR.cc/2023/Conference/Paper2065/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "DiffDock is a diffusion model for molecular docking. The authors of the paper formulate the docking problem as a generative modeling task. In order to preserve the key conformational constraints of the molecules, compounds are mapped to a product space of the degrees of freedom, i.e. translation, rotation, and torsional angles. In such created space a diffusion procedure can be defined after ensuring that torsions are orthogonal to the roto-translations, and the mapping is bijective. The diffusion is defined in the product space with a stochastic differential equation and a score model. Furthermore, a confidence model is trained using RMSD values of docked compounds. The experiments show advantage of the proposed method over other classical and neural dockers in the blind docking task. ",
            "strength_and_weaknesses": "Strengths:\n- The authors indicate the problems with regression-based models and explain the motivation of using diffusion models in the context of pose prediction.\n- The problem definition and the execution of the model are very good. The authors notice that molecular conformations lie in a submanifold where all the operations should be performed instead of moving the atom positions freely.\n- The torsion updates are carefully defined so that they possess properties described in Propositions 1 and 2.\n- A confidence model is trained as a classification model that predicts whether the RMSD of the generated pose is less than 2A.\n- SE(3)-invariant models are used for the score model and the confidence model. This is important to distinguish two reflections of the same compound (enantiomers).\n- The experimental results show the advantages of the proposed method in terms of binding pose prediction and inference runtime.\n- Additional experiments as well as all the training details are provided in the supplementary materials.\n\nWeaknesses:\n- The only problem I see in the definition of the product space is that it still allows for the steric clashes (either with the protein or other ligand atoms during the torsional rotations). In Figure 5, you argue that self-intersections are not observed for your model. Do you have any intuition why these phenomena do not occur for DiffDock?\n- If the confidence model is trained in a classification setup, then the output probabilities do not account for the uncertainty of this model. Do you think it could break the ranking for the unseen binding pockets and ligand poses? Could you elaborate on why you decided to use classification with the threshold of 2A?\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity.** The paper is very clear, both in terms of the paper motivation and model presentation. The experimental results and their interpretation are comprehensible. The figures and the animation in the anonymously shared repository nicely present the idea of the paper.\n\n**Quality.** All the experimental details are provided. The main table contains both classical molecular docking tools (4 of the most widely used docking softwares) and recent generative models (EquiBind and TANKBind). The standard deviation of the performance metrics is provided for DiffDock.\n\n**Novelty.** The novelty of this research work is high. The field of neural docking is not well-explored yet, with only a few recent attempts such as EquiBind and TANKBind. DiffDock reformulates the neural docking task as a generative problem and uses the most recent advances in generative modeling, the diffusion models. It is noteworthy that DiffDock is implemented in a way that ensures that all the intermediate structures are valid (at least in terms of bond lengths and flat aromatic structures) because the diffusion is performed in a product space of the degrees of freedom. The theoretical part of the paper is strongly supported by the proofs of the key findings.\n\n**Reproducibility.** The model description is detailed and contains the key formulas needed to reimplement the method. A pseudocode for the training and inference is provided in the supplementary materials. The set of final hyperparameters is also provided in the supplementary materials. The code is anonymously shared to ensure the full reproducibility.",
            "summary_of_the_review": "Based on the above comments, I recommend the acceptance of this paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2065/Reviewer_5meX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2065/Reviewer_5meX"
        ]
    },
    {
        "id": "00j1bYZYT1",
        "original": null,
        "number": 4,
        "cdate": 1667051230827,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667051230827,
        "tmdate": 1669090708636,
        "tddate": null,
        "forum": "kKF8_K-mBbS",
        "replyto": "kKF8_K-mBbS",
        "invitation": "ICLR.cc/2023/Conference/Paper2065/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a new way for molecule docking, which is to use diffusion model to form the docking pose prediction as a generation problem. In this work, the prediction is mainly based on the 3D translation group, rotation group and torsion angle change. The authors first critique the regression-based ligand propose prediction. Then define the ligand pose transformations, and the diffusion process, and then the training, model arch. The experiments on PDBBind dataset show that the method is strong with good verification results. The docking accuracy is highly improved and the running time is improved compared with some other methods. \n\nOverall speaking, this paper is strong in terms of performance, but I have lots of concerns.",
            "strength_and_weaknesses": "Strengths:\n1. The authors think of the pose prediction task as a generation task and use the advanced diffusion model to perform the task definition. They also talked about the potential problem of the regression-based method. The regression-based method can not fit the overall multiple correct poses in a pocket, while the generative-based model can handle and provide different samples. A confidence model is used to keep the choice of the best ones of predictions.\n2. The authors consider the rotation, translation, and torsion angle change as the key messages that are variant during the generation, which largely reduces the freedom space of the ligand pose generation. \n3. The experiments are strong and effective compared to previous works, both in accuracy and running time. \n\nWeaknesses:\n1. Overall speaking, this paper is not very easy to read and follow (at least for me). The organization is good but not the details. The authors are experts in this domain (this paper is already put on arxiv and the authors are known), but the writing in this paper contains lots of parts that may not be friendly to the general readers. I can understand that there are lots of constraints or domain knowledge that the authors know, but for a paper, it should be easy for the readers to understand. Why I feel hard is that lots of items (words) and knowledge should be discovered by the ML readers. For a reviewer like me (I should say that I know basic knowledge about docking but am not so familiar, at least not familiar as authors), it is really hard for me to capture all of the detailed things that the authors are saying. In comparison, I read TankBand, which is much easier to follow and understand. I have also read the previous work Equiband. I strongly encourage the authors can use much simpler descriptions of the method. By the way, a simple and effective method is acknowledged in the ML committee I think. \n2. For some details, there lacks of explanations at all. For example, the m+6 degrees, 6 refers to the rototranslations, what is the detail of this 6? Product space, group space, aleatoric uncertainty, epistemic uncertainty, authors look like to define lots of new items. I am not sure whether these are common knowledge or defined by the authors only. I do feel that these make the readers hard to follow. Even for the diffusion method, details are missing. It's hard to say that 4.3 contains the necessary information for diffusion generation. Lots of details are put in the appendix. This is limited by the page constraints of ICLR. But if this is the reason, a journal that is without page length constraints is better? In the current main text, the training and inference is also not clear, which are placed in the appendix. As for section 3, I am not sure whether this really impresses me, the authors put the whole section to criticize the regression method. What I understand best is that the regression method can not handle the multiple correct poses problem, and the prediction is only the mean pose of these poses. The variance is not enough compared to the generation method. In my view, all of these can be said about the difference between the general regression model and the diffusion model. VAE, flow, diffusion, these models are all good at variance prediction. Is that necessary to put the whole section here, and the cases in figure 2 are somehow cherry-picked? \n3. In appendix, the training and inference procedure, the authors talk much about the problem of the different gaps caused by the initial conformation c. In my view, the description can be shortened since contains much about intuitively speaking, and conceptually speaking. Too much description also confused me instead of letting me understand better (only in my view when I read this part).\n4. When I read the details of the implementation, I have more concerns. The protein model is initialized of ESM2, a strong protein pre-trained model, but the authors are not mentioned in the main text at all. This strongly pre-trained model may help a lot. Besides, the module ending is also different, the authors include a lot of knowledge features of the molecule, for example, the number of rings and the details of the rings. there are all different from previous works. I am not sure whether these are the main contribution to the accuracy or the diffusion model. I would like to see fair comparisons of the model and encoding ways. \n5. For the small model and the large model, the small model is only used for the hyperparameter search? Even like this, it seems that the training time is also long, 18 days on 4 A6000 cards. And, why the inference is conducted on an A100 card then? ",
            "clarity,_quality,_novelty_and_reproducibility": "This paper takes the diffusion for ligand pose prediction. \nI would to see more about the difference between current methods for molecule generation/conformation generation. What are the main unique advantages/differences compared to previous works in applying diffusion? \nSee above.",
            "summary_of_the_review": "N/A",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2065/Reviewer_pHbo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2065/Reviewer_pHbo"
        ]
    }
]