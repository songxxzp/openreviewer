[
    {
        "id": "xTL3Ljf7Tp",
        "original": null,
        "number": 1,
        "cdate": 1665975685293,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665975685293,
        "tmdate": 1666179567840,
        "tddate": null,
        "forum": "ymt1zQXBDiF",
        "replyto": "ymt1zQXBDiF",
        "invitation": "ICLR.cc/2023/Conference/Paper3414/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper tackles the problem of quantity-quality trade-off in pseudo-labeling based semi-supervised learning. Specifically, the authors develop a truncated Gaussian function to weight samples based on their confidence, which can be viewed as a soft version of the confidence threshold. They also enhance the utilization of weakly-learned classes by proposing a uniform alignment approach. The experiments on various types of datasets demonstrate the effectiveness of the proposed method.",
            "strength_and_weaknesses": "Pros:\n\n1. This paper is written in a clear way.\n\n2. The idea of this work is reasonable, and the details of the proposed algorithm are provided.\n\n3. The experiments are convincing.\n\nI do not have major concerns on this work. I only have several questions:\n1. This work targets the quantity-quality trade-off problem in semi-supervised learning, which is meaningful. I agree that in each iteration, this problem does exist. But for the entire learning process which consists of many iterations, I\u2019m not sure whether this is still an important problem. In traditional pseudo-labeling methods, only the unlabeled examples with high confidence are utilized for each iteration. This will decrease the quantity, but the quality will be high, as most of them are with correct labels. Then, when the iterations proceed, the learning performance will be gradually improved with a large probability. However, if we spend too much efforts on the quantity-quality trade-off in each iteration, I\u2019m afraid that this might hurt the accuracy as well as decrease the efficiency from the global view of learning. Therefore, I hope the authors can give more explanations on this point. \n2. For pseudo-labeling methods, the authors are suggested to mention whether their method is transductive or inductive, or is applicable to both conditions. \n3. Some typos should be fixed. For example, in the caption of Fig.1, \u201c(b) Quality of pseudo-labels\u201d should be \u201c(c) Quality of pseudo-labels\u201d. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally well-written. The idea is also novel. The code is provided.",
            "summary_of_the_review": "I do not have major concerns on this paper. I only have several minor concerns as listed above. I hope the authors can provide the reply regarding my previous minor concerns.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3414/Reviewer_QAQp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3414/Reviewer_QAQp"
        ]
    },
    {
        "id": "rIOz1J5CEW",
        "original": null,
        "number": 2,
        "cdate": 1666525249996,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666525249996,
        "tmdate": 1666525249996,
        "tddate": null,
        "forum": "ymt1zQXBDiF",
        "replyto": "ymt1zQXBDiF",
        "invitation": "ICLR.cc/2023/Conference/Paper3414/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper points out the inherent quantity-quality trade-off problem of pseudo-labeling with confidence thresholding exists in recent semi-supervised learning (SSL) methods. It then proposes a soft adaptive sample weighting scheme using a truncated Gaussian function to utilize both high quantity and quality of pseudo-labels. Meanwhile, a uniform alignment technique is designed for pseudo-labeling, which exploits original predictions to compute pseudo-labels and normalized predictions to compute sample weights.",
            "strength_and_weaknesses": "Pros:\n* The consideration of the quantity-quality trade-off is very interesting and novel.\n* The proposed solution is simple but effective. Imbalanced setting is also taken into consideration in this paper.\n* The evaluation is conducted on image and text datasets, together with imbalanced settings. The performance is also promising.\n\nCons:\n* Even with the summary of formulations in Table 1, why the proposed SoftMatch could achieve both high quality and quantity is not well-explained.\n* More recent studies towards adaptive thresholding and imbalanced setting in SSL should be discussed and compared, e.g., [1-2].\n* Why the truncated version of Gaussian function is used should be explained (although the ablation results show it\u2019s the best choice).\n* It would be better if the learned truncated Gaussian function and the real confidence distribution could be illustrated on real-world datasets (for several epochs). \n* It is claimed that the proposed uniform alignment could alleviate the distribution of generated pseudo-labels to be imbalanced. Then [3] should be included for performance comparison. Besides, the visualization of the pseudo-label distribution (w.r.t. classes) is helpful to understand the effect of uniform alignment, especially on imbalanced datasets.\n* Why only 3 random seeds are used in Table 2? In the original FixMatch paper, the number of random seeds is 5.\n* It is not clear on which dataset and with which number of labeled data the ablation studies are conducted.\n\nRef:\n\n[1] Class-Imbalanced Semi-Supervised Learning with Adaptive Thresholding, ICML22.\n\n[2] Smoothed Adaptive Weighting for Imbalanced Semi-Supervised Learning: Improve Reliability Against Unknown Distribution Data, ICML22.\n\n[3] Debiased Learning from Naturally Imbalanced Pseudo-Labels, CVPR22.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Generally good. But many issues should be solved to improve the clarity.",
            "summary_of_the_review": "The main idea is very interesting to me, and the performance is good. However, the clarity and experiments should be improved.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3414/Reviewer_ZV9Z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3414/Reviewer_ZV9Z"
        ]
    },
    {
        "id": "ysrtH4Dpse",
        "original": null,
        "number": 3,
        "cdate": 1666617559407,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666617559407,
        "tmdate": 1668565005494,
        "tddate": null,
        "forum": "ymt1zQXBDiF",
        "replyto": "ymt1zQXBDiF",
        "invitation": "ICLR.cc/2023/Conference/Paper3414/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes SoftMatch to improve both the quantity and quality of pseudo-labels in semi-supervised learning. Basically, the authors designed a truncated Gaussian function to weigh the unlabeled samples and remedied the imbalanced problem by encouraging a low entropy distribution within a batch.",
            "strength_and_weaknesses": "Strength:\n1. It is interesting that the authors understood the limitation of pseudo-labels from the view of quantity-quality trade-off, and some experimental evidence was presented by comparing with FixMatch and FlexMatch.\n2. The weight function for unlabeled samples adjusted the importance of the contributions of different samples during training, which is intuitively better compared with na\u00efve pseudo-labels.\n\nWeaknesses:\n1. The quantity-quality trade-off shown in Fig. 1(a) seems not fair. For Fixmatch, how many unlabeled samples are selected by a hard threshold is dependent on the training process. Experimentally, only a small proportion of unlabeled data will be selected at the beginning of model training, and it should select the most unlabeled data once the model converges. Otherwise, the model performance would not be guaranteed. Similar to Flexmatch. Although the motivation sounds interesting, the experimental observation is not clear or convincing to me.\n2. Following 1, I felt a bit confused about why SoftMatch here is a curve instead of a point.\n3. From Section 2.2, the quantity and quality functions f(p) and g(p) are only used for analysis instead of the SoftMatch method. From Table 1, I can sense the difference between them, but I cannot tell the advantages of SoftMatch directly.\n4. Following 3, the comparison between Pseudo-label and FixMatch in Table 1 is unclear to me. E.g., Pseudo-Label also has the sample selection, but the weight equals a const lambda_max.\n5. Eq. (2) can be viewed as a soft version of sample selection, but in what case it is needed or outperforms other strategies is not clear after I read the paper.\n6. The weight is normalized at a batch level with EMA stabilizing the training, thus it shares the same insight with [1]. However, such a branch of work has not been mentioned.\n7. From the experiments, the improvement of SoftMatch on standard SSL benchmarks is quite limited but it showed some potential in imbalanced class cases, which is however not the key challenge from the introduction of this work.\n\n[1] Sinkhorn label allocation: Semi-supervised classification via annealed self-training, ICML 2021.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly presented and well organized. The overall quality needs improving and the novelty is not enough as there have been numerous brilliant SSL techniques. I didn't carefully check the reproducibility but I didn't doubt it.",
            "summary_of_the_review": "This work needs further improvement from both a thorough investigation of SSL and clearer demonstrations to the main contributions.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3414/Reviewer_ZqdU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3414/Reviewer_ZqdU"
        ]
    },
    {
        "id": "C3QvsvrpQ0",
        "original": null,
        "number": 4,
        "cdate": 1666625032054,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666625032054,
        "tmdate": 1666625032054,
        "tddate": null,
        "forum": "ymt1zQXBDiF",
        "replyto": "ymt1zQXBDiF",
        "invitation": "ICLR.cc/2023/Conference/Paper3414/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper focuses on the traditional Semi-Supervised Learning (SSL) problem. The authors first revisit the popular pseudo-labeling methods via a unified sample weighting formulation and demonstrate the inherent quantity-quality trade-off problem of pseudo-labeling with thresholding, which may prohibit learning. To this end, The authors propose SoftMatch to overcome the trade-off by maintaining both high quantity and high quality of pseudo-labels during training, effectively exploiting the unlabeled data. The authors derive a truncated Gaussian function to weight samples based on their confidence, which can be viewed as a soft version of the confidence threshold. The authors further enhance the utilization of weakly-learned classes by proposing a uniform alignment approach.\n\n",
            "strength_and_weaknesses": "Strengths:\n\n1. This paper demonstrates the importance of the unified weighting function by formally defining the quantity and quality of pseudo-labels, and the trade-off between them.\n2. This paper proposes SoftMatch to effectively leverage the unconfident yet correct pseudo-labels, fitting a truncated Gaussian function in the distribution of confidence, which overcomes the trade-off. \n3. This paper demonstrates that SoftMatch outperforms previous methods on various image and text evaluation settings.\n\n\nWeaknesses:\n\n1. One issue of the existing SOTA SSL methods is the issue of efficiency (e.g., Fixmatch is time-consuming for training). Based on figure 2, the proposed SoftMatch has a similar issue.\n2. What is the motivation for Uniform Alignment (UA)? Why the model prediction is aligned to a uniform distribution?\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-presented and organized. The proposed idea is simple but effective. The authors provide an excellent code for experiment result reproduction.",
            "summary_of_the_review": "See *Strength And Weaknesses*\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3414/Reviewer_Kfxk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3414/Reviewer_Kfxk"
        ]
    }
]