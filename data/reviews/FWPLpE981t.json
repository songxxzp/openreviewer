[
    {
        "id": "BkHlqySo6j",
        "original": null,
        "number": 1,
        "cdate": 1666272958654,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666272958654,
        "tmdate": 1666272958654,
        "tddate": null,
        "forum": "FWPLpE981t",
        "replyto": "FWPLpE981t",
        "invitation": "ICLR.cc/2023/Conference/Paper2621/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors propose a method to generate counterfactual explanations that are *valid, actionable, sparse, diverse, plausible,* and computationally *scalable*. They achieve this by learning an amortized local counterfactual distribution conditioned on the original data point. To learn it, they train a categorical counterfactual generator from which they sample the attributes to be modified with a selector that models a Bernoulli distribution. To enforce sparsity, they regularize the L1 norm of the selector. The proposed method achieves high validity and diversity rates compared with previous state of the art while having a relatively low computational cost.",
            "strength_and_weaknesses": "Strengths\n=======\n* The proposed method is sound\n* The paper is clear and very well written, I really liked Table 1\n* The computational cost is small\n* I liked the OOD datasets experiment\n* The authors provide the code\n\nWeaknesses\n=========\n* The diversity measure is ill-defined (here and in previous state of the art). For instance, imagine an instance defined by N attributes and for which changing attribute number 1 generates a counterfactual. Now we can generate an arbitrary number of counterfactuals by modifying attribute number 1 and any other attribute (to increase hamming distance). However all these counterfactuals provide the same information (that the classifier is sensitive to attribute 1). I suggest you add some comment about this in the paper.\n* From the paper, it is difficult to obtain all the details to reproduce their method. For instance, how is the selector instantiated? Is it just a sigmoid on top of a neural network? How is that neural network defined? Could you add implementation details (in general)?\n* Research-wise, this work does not introduce any new ideas (previous ideas are properly cited), this work is rather on the application side.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity\n=====\n* The submission is clear and easy to understand. It lacks some implementation details but that could be easily fixed.\n\nQuality\n=====\n* The overall quality is good. \n\nNovelty\n======\n* Research-wise, this work does not introduce any new ideas (previous ideas are properly cited), this work is rather on the application side.\n\nReproducibility\n===========\n* The authors provide the code but the reproducibility could improve by providing more implementation details in the paper.\n\n",
            "summary_of_the_review": "The method is sound and the text is clear. My main concern is whether the author's contribution is significant enough for ICLR, I would appreciate if the authors could comment on that. The submission could also be improved by adding implementation details and a discussion about the limitations of this work. Thus, I temporarily recommend a score of 5 until these points are discussed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2621/Reviewer_Xqce"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2621/Reviewer_Xqce"
        ]
    },
    {
        "id": "o-ItBoHGc7",
        "original": null,
        "number": 2,
        "cdate": 1666276118788,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666276118788,
        "tmdate": 1666276347838,
        "tddate": null,
        "forum": "FWPLpE981t",
        "replyto": "FWPLpE981t",
        "invitation": "ICLR.cc/2023/Conference/Paper2621/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a method to generate counterfactual explanations based on two components: (i) a feature selector and (ii) and an end-to-end network. While (i) makes sure that relevant features are selected, (ii) enables the model to enforce additional constraints (e.g., dealing with categorical variables).",
            "strength_and_weaknesses": "Strengths:\n1. The addressed problem is relevant, timely and interesting to the XAI community.\n2. The paper is fairly well written.\n3. The methods\u2019 evaluation is extensive.\n\nWeaknesses:\n1. The overview of related work as well as the contextualization of the proposed solution with respect to related work are weak.\n2. The paper accumulates many ideas from previous works on counterfactual explanations; various aspects discussed in the paper are not novel and have already been proposed in previous papers:\n\n(i) Amortized inference has been used in the following works: \nGuo et al (2021),\nDan Ley et al (2022),\nVerma et al (2022).\n\n(ii) Dealing with heterogenous tabular data has been extensively studied in:\nKarimi et al (2020)\nPawelczyk et al (2020) - Sampling categorical & Bernoulli data have also been used by Pawelczyk et al in their auto-encoder \nPawelczyk et al (2022) - Dealing with categorical variables.\n\n(iii) Dealing with diverse counterfactuals was initially studied in Mothilal et al., (2020)\n\n3. The discussion does not really critically address limitations or related improvement strategies. E.g.: What are possible extension strategies for handling domain constraints or expert knowledge? Do you see any tensions between diversity and privacy?...\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The work is fairly well written, and the proposed method is clearly described. Unfortunately, the discussion of related work as well as the contextualization of the proposed solution with respect to related work are weak. The paper accumulates many ideas from previous works on counterfactual explanations. Various important aspects discussed in the paper are not novel and have already been proposed in previous papers.\n\nDetailed feedback:\nThe improvements of the proposed framework over existing explanation baselines are not clear. The authors compare with a variety of methods that all have different goals (for example F-VAE and CRUDS versus FastAR). Therefore, I would suggest comparing with methods that primarily use (i) amortized inference to generate counterfactuals, and (ii) diversity constraints. \n\nThe only method that uses diversity constraints is DICE, but here the authors have not compared with the method suggested by Mothilal et al., (2020), but instead with a method that uses random search to find counterfactuals (that has been provided in the DICE library). To give the author\u2019s a concrete idea of how a more meaningful evaluation could look like, I suggest considering the work by Pawelczyk et al (2021), who have split their evaluation according to the assumptions made by the underlying methods.\n\nFinally, the work could be improved by focusing on fewer aspects and addressing them in innovative ways; instead, the proposed method addresses too many challenges at once by simply combining a wealth of already existing techniques into one greater system. \n",
            "summary_of_the_review": "Overall, the work lacks novelty and originality as well as critical discussions around limitations and shortcomings.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "Yes, Privacy, security and safety"
            ],
            "details_of_ethics_concerns": "Since diversity of counterfactual explanations is an important aspect of the work, privacy-related risks should be discussed.",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2621/Reviewer_DTNp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2621/Reviewer_DTNp"
        ]
    },
    {
        "id": "hJ3VPKIQ3X",
        "original": null,
        "number": 3,
        "cdate": 1666659325477,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666659325477,
        "tmdate": 1666659325477,
        "tddate": null,
        "forum": "FWPLpE981t",
        "replyto": "FWPLpE981t",
        "invitation": "ICLR.cc/2023/Conference/Paper2621/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Counterfactual generation is a multi-model problem in the sense that satisfying all the constraints simultaneously is considered a challenging task. In this paper, the authors propose a stochastic feature-based learning approach to meet all the constraints. The proposed method discretizes each continuous feature and learns the generator and selector to generate diverse counterfactual samples. The generator learns a categorical distribution for feature-based perturbation. The selector serves to select feature-based selection distribution. They are multi-nomial and Bernoulli distributions, respectively. And they are both parameterized by a neural network. The loss is built based on the cross-entropy loss from the prediction and the target counterfactual class and an L1 norm that encourages sparsity. The proposed method are  compared with the most popular methods on 4 popular tabular data sets.",
            "strength_and_weaknesses": "Strength:\n1) The proposed method addresses multiple constraints that counterfactual generation generally faces at the same time. \n2) The optimization is amortized by two neural networks. \n3) The evaluation metrics include various aspects of counterfactual generations. The results support the claim overall. \n4) The discretization of continuous features looks interesting. \n\nWeaknesses:\n1) The metric, Manifold distance, is only measuring L1 distance among the nearest samples. I think one of the most important plausibility measurements is how much overlap the counterfactual sample lies in the target class in terms of distribution distance. L1 or L2 distance seems limited in regard to measuring plausibility. \n2) The discretization of numerical features seems interesting to me. However, the trade-off of using discretization is unclear. In particular, how do we choose the level c_i? Does the choice of c_i affect the metrics? And are those comparisons evaluated in the discretized space or the original space?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and easily follow in general. The idea is clearly stated and presented with experiments. The proposed method is interesting and, to some extent, novel. The code is provided for reproducibility. ",
            "summary_of_the_review": "The paper proposes a novel method that can generate diverse counterfactual samples for understanding a pre-trained black-box classifier. The proposed method introduces two neural networks, a generator and a selector, that take the discretized input space. Although the discretization of the input space looks novel to me, the novelty is limited. The loss function that trains the generator and selector takes cross-entropy loss between the predicted label and target class label, and the L1 norm, which is not new at all.  ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2621/Reviewer_nrfX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2621/Reviewer_nrfX"
        ]
    },
    {
        "id": "ah6AE4DaLN",
        "original": null,
        "number": 4,
        "cdate": 1667561627298,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667561627298,
        "tmdate": 1667561627298,
        "tddate": null,
        "forum": "FWPLpE981t",
        "replyto": "FWPLpE981t",
        "invitation": "ICLR.cc/2023/Conference/Paper2621/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The goal of the paper is to generate counterfactual explanation (CFs) of classification models. The paper points our several problems with existing CF generation methods, many of which are rooted in the fact that these methods are not able to handle categorical features particularly well. The previous methods also work in a posthoc manner which affects their runtime performance. The paper aims to solve these problems by training the CF generator. The crucial design choice is to discretize all feature as categoricals and learn their distributions. Usage of softmax ensures that the post-processing of one-hot encoded features does not lead to invalid CFs. The paper also shows experiments with several datasets showing better performance than existing methods.",
            "strength_and_weaknesses": "**Strengths:** Usage of softmax to ensure validity of one hot encoded features is a neat idea.\n\n**Weaknesses:** Overall, the proposed methodology does not seem to solve the issues with plausibility. I also think some choices seem quite adhoc and need better justification. Please see detailed comments below:\n\n1. As far as I could see, the distribution of each categorical feature is being learnt independently which may lead to unrealistic combinations (for instance, very young people with decades of work experience). The paper does not discuss how this issue should be resolved.\n\n2. It is also not clear if discretizing numerical features is a very good idea. How would this scale to high dimensional datasets? How should the number of discretization buckets be chosen?\n\n3. On a related note, discretized numerical features are converted back to the original representation by assigning them the middle value. Does this lead to any accuracy issues (since the precise feature value is lost)?\n\n4. The usage of Bernoulli is an interesting idea but it also adds a few more knobs (every feature $i$ has a corresponding $\\pi_i$). How could one handle sparsity at the scale of all the features?\n\n5. The experimental setup makes a few assumptions that seem a bit questionable. I am not sure why selecting a random perturbation method (DiCE Random) is a good strategy. Similarly, assigning only 3 seconds for a single CF generation seems a bit unfair to posthoc CF generation methods. It is also not very clear to me why numerical and categorical plausibility is considered separately in Table 1 when there might be dependencies between them.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is mostly easy to follow.\n\nQuality: As mentioned in the previous section, usage of softmax to handle one-hot encoded features is a neat trick. However, the paper does not provide justification into why discretizing all features is a good idea and how the performance would be with high dimensional datasets.\n\nNovelty: The Gumbel-softmax trick is well known but to the best of my knowledge, this is the first time this trick is used for generating CFs. \n\nReproducibility: The paper provides implementation details (e.g., model architecture) in appendix, and also provides a link to the code repo. ",
            "summary_of_the_review": "Overall, the paper uses intriguing ideas to get around various issues for generating CFs. However, many choices seem adhoc and could be better justified. It is also not clear how well the setup would work with high dimensional datasets where discretization might lead to very large number of features. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2621/Reviewer_67mR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2621/Reviewer_67mR"
        ]
    }
]