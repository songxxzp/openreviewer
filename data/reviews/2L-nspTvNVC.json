[
    {
        "id": "yfCQuA0ogyM",
        "original": null,
        "number": 1,
        "cdate": 1666538846261,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666538846261,
        "tmdate": 1668708787106,
        "tddate": null,
        "forum": "2L-nspTvNVC",
        "replyto": "2L-nspTvNVC",
        "invitation": "ICLR.cc/2023/Conference/Paper4279/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors proposed an approach for learning embedding function and a probabilistic model on top of it for task-incremental online learning. The method has two update steps, first updating the model parameters based on the log-marginal likelihood of the probabilistic model and then update a memory bank of class representative examples by optimizing the kl divergence between a current posterior and a candidate posterior which considers data from the current task. The authors presented an instance of this algorithm with Gaussian distributions. The authors presented results of their method on CIFAR-10/100 and miniImageNet datasets in two settings, disjoint tasks (in terms of classes), and a shifting window.",
            "strength_and_weaknesses": "Strengths:\n* A simple method that seems to work well compared to the baselines.\n* The method was evaluated in two settings, disjoint tasks and a shifting window which shows that it is relatively robust.\n* The paper is easy to follow and understand.\n* Code was provided, which is noteworthy.\n\nWeaknesses/Questions:\n* Although I am not an expert in the field, it seems that the true novel part is the KL divergence loss for selecting the memory bank. I would imagine that there were other strategies for making this selection in the continual, life-long, or incremental learning setups, so why this strategy is better than others? \n* Following the last question, Given that the authors chose a Gaussian class conditional distribution with unit covariance, I can imagine that the resulting selection strategy appeared in other papers as a frequentist loss function. Have the authors checked that?\n* Lastly on the same subject, why did the authors assume a unit covariance? is it a realistic assumption? I would imagine that even an isotropic covariance matrix that requires inference on an additional parameter per class will be more suitable.\n* I wonder what is the computational overhead of the two-step learning algorithm (i.e., learning the embedding and learning the probabilistic model on of them at each iteration), can you quantify that using wall-clock time or FLOPS?\n* To me it seems that most baselines are outdated, how does the method compare to newer ones?\n* It seems that the authors missed an important related work [1, 2] that share some of the assumptions of this work (for instance, [1] also assume that classes are grouped in a Gaussian ball in the feature space). In general, I wonder how this method or alternative methods that use GPs will work on the tasks presented in this paper. This seems like an important baseline.\n* Which of the baselines learn the embedding function and which isn't? It seems like important information and I didn't find an answer to that.\n\n[1] Achituve, I., Navon, A., Yemini, Y., Chechik, G., & Fetaya, E. (2021, July). GP-Tree: A Gaussian Process Classifier for Few-Shot Incremental Learning. In International Conference on Machine Learning (pp. 54-65). PMLR.\n\n[2] Titsias, M. K., Schwarz, J., Matthews, A. G. D. G., Pascanu, R., & Teh, Y. W. (2019, September). Functional Regularisation for Continual Learning with Gaussian Processes. In International Conference on Learning Representations.",
            "clarity,_quality,_novelty_and_reproducibility": "* The paper is written clearly for the most part.\n* The novelty of the paper is limited.",
            "summary_of_the_review": "I think that the paper is nice, but I am not sure that in terms of novelty, the approach, and the compared baselines it is good enough to be accepted. I am willing to change my mind in light of new information from the authors.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4279/Reviewer_juyJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4279/Reviewer_juyJ"
        ]
    },
    {
        "id": "tHDfRO6ltT",
        "original": null,
        "number": 2,
        "cdate": 1666682528988,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666682528988,
        "tmdate": 1666682528988,
        "tddate": null,
        "forum": "2L-nspTvNVC",
        "replyto": "2L-nspTvNVC",
        "invitation": "ICLR.cc/2023/Conference/Paper4279/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper addresses the problem of lifelong learning, specifically without a fixed backbone by using a Bayesian approach. The approach shows good results in a challenging setting.  ",
            "strength_and_weaknesses": "Strengths:\n- The paper is well written and easy to follow\n- The approach is relatively novel. The main focus in continual learning is on fixed backbone, also the shifted setting got relatively little attention.\n- The results seem promising compared to other baselines.\n\nWeaknesses:\n- Not enough comparisons, cifar10 with only 10 classes is not a good benchmark for this method and cifar100 is a relatively easy benchmark. Would be better to compare on other benchmarks like CUB. Also use only a scaled-down version of resnet18\n- Overall results aren't that good, maybe because the difficult setting but also could be due to the network used. Would be more convincing if it would work with a larger network",
            "clarity,_quality,_novelty_and_reproducibility": "The method is clear, novel, and reproducible.",
            "summary_of_the_review": "The paper addresses an important challenge and gets improved results compared to other approaches",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4279/Reviewer_e2L5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4279/Reviewer_e2L5"
        ]
    },
    {
        "id": "1gJEwS41Y6",
        "original": null,
        "number": 3,
        "cdate": 1667549861692,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667549861692,
        "tmdate": 1669410259747,
        "tddate": null,
        "forum": "2L-nspTvNVC",
        "replyto": "2L-nspTvNVC",
        "invitation": "ICLR.cc/2023/Conference/Paper4279/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes using an empirical Bayesian framework to simultaneously learn an embedding model ($f_\\phi$) and a probabilistic model (parameterized w/ $\\theta$) for the continual learning setting. To that end, $f_\\phi$ is updated using a variant of experience replay through a running memory of samples, where the memory samples are updated with each task such that the KL divergence between the true posterior for $\\theta$ and the posterior with the new memory is minimized. While updating the embedding network, the authors use marginal log-likelihood wrt $y$ of a subset of data conditioned on the rest. The paper presents one instance of the proposed framework referred to as DeepCCG which uses conditional Gaussian model as the probabilistic model. Several experiments show the DeepCCG performs better than a few selected baselines in two different (disjoint and shifting window) task incremental settings. ",
            "strength_and_weaknesses": "Strengths\n\n- The proposed DeepCCG seems to do reasonably well in the task-incremental setting compared to some of the considered baselines.\n- The experiment design of using a moving window to simulate task overlap has not been explored before.\n\nWeakness\n\n- *Missing related work*: There is an entire class of methods that do expansion-based [1-5] continual learning that have not been discussed in the related work. [1-4] also use a Bayesian framework (though for expansion) for continual learning. These methods also learn the entire model without using any pre-trained/frozen embedding network. This class of methods should be discussed in the related work.\n- *Replay Baseline*: Replay based on generative models [5-6] has not been considered as a baseline.\n- The writing and the presentation in the paper can be improved significantly. In terms of presentation, section 4 seems like an over-generalization of the methodology presented in section 5. Since the paper only discusses a simple variant of the general framework, which uses a class conditioned Gaussian to define the probabilistic model, section 4 seems a bit redundant. \n- Some of the claims over-state the contribution, for e.g. Pg 5 section 4 (last para): \"our general approach can be used in task-agnostic settings as well\" -- The task-agnostic continual learning is a much more challenging setting than task incremental. Without any empirical evidence, this claim is not well supported. \n- The sample selection strategy based on the KL divergence of the two posteriors in equation 11 assumes that the training data in each task is same across the tasks? From equation 11, it seems that given a new task with large number of samples, the new memory would be biased towards the new task, which could easily cause catastrophic forgetting of previous tasks. However, the paper only assumed settings with equal number of samples across all tasks.\n- The paper only considers the task-incremental setting, which is known to be a relatively easier setup than other challenging continual learning settings, including class-incremental and task-free continual learning. \n\n\nOther Minor concerns:\n- The notation in the paper can be improved:\n  - In equation 1, the marginalized likelihood is a function of the embedding network. Making this precise in the notation (e.g. $p_\\phi (y|x,t_{x,y})$) would make the discussion that follows in section 4 clearer.\n- In section 6.1 under benchmarks: \"in shifting windows ... there is no overlap between any two of the task\" -- Is this a typo? There is overlap with shifting windows, right? \n\n\n[1] A Neural Dirichlet Process Mixture Model for Task-Free Continual Learning, (Lee et al., (2020))\n[2] Continual Learning using a Bayesian Nonparametric Dictionary of Weight Factors (Mehta et al., (2021))\n[3] Bayesian structure adaptation for continual learning, (Kumar et al. (2020))\n[4] Hierarchical Indian Buffet Neural Networks for Bayesian Continual Learning, (Kessler et al, (2020))\n[5] Efficient Feature Transformations for Discriminative and Generative Continual Learning, (Kumar et al., (2021))\n[6] Deep Generative Replay, (Shin et al. (2017))\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity and Quality: The writing and presentation in the paper can be improved significantly. The section 4 and section 5 can be combined to clarify that the probabilistic model and the embedding network are updated separately.  There are also many grammatical errors that can be fixed.\n\nNovelty: The novelty seems limited given that the probabilistic model is based on a simplified class-conditional Gaussian model (LDA) which was also used in Ostapenko et al. (2020). Moreover, the idea of using a subset of samples to determine the conditional marginal log-likelihood (Equation 3) was also explored in Lofti et al., (2022), although its application in continual learning seems new.\n\n",
            "summary_of_the_review": "Based on the above weaknesses and concerns, my recommendation is to reject the paper in its current state. While the idea of using DCCG w/ experience replay is interesting, there are some major concerns in terms of clarity and presentation. The baselines and related work can also be improved significantly.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4279/Reviewer_rHsD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4279/Reviewer_rHsD"
        ]
    },
    {
        "id": "FPVwRI07-Z",
        "original": null,
        "number": 4,
        "cdate": 1670500551654,
        "mdate": 1670500551654,
        "ddate": null,
        "tcdate": 1670500551654,
        "tmdate": 1670500551654,
        "tddate": null,
        "forum": "2L-nspTvNVC",
        "replyto": "2L-nspTvNVC",
        "invitation": "ICLR.cc/2023/Conference/Paper4279/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes a deep class conditional model for the online task's incremental learning. The primary motivation of the paper is to learn the feature embedder since a fixed feature extractor is not useful in the dynamic environment. In this work, the model leverages the replay buffer to overcome the catastrophic forgetting and the buffer samples are selected by maximizing the posterior between the subset of samples and task samples. They used jointly the buffer and batch samples to update the embedder network parameter. Finally, the samples are classified by learning the prototype/mean of the class.",
            "strength_and_weaknesses": "Pors:\n\n1: The model is simple and requires a small memory buffer to overcome the catastrophic forgetting. \n\n2: Easy to follow and ablation for the sample selection strategy w.r.t. reservoir shows the improvement. Sample selection method is intuitive and it may be useful in the other replay based approach. However, practical time complexity may be a bottleneck.\n\n3: For the reproducibility, they provided the code.\n\nCons:\n\n1: The paper handles the easiest setting of the continual learning (CL) where task id are provided during inference, which is not practically useful. In this setting, a simple expansion based approach [a,b,c,d] without any replay, model achieves the performance near the upper-bound without using the pretrained backbone. In this paper, none of these methods are compared. Replay is required for the comparatively much complex setting, like class incremental learning or task-free continual learning.\n\n2: The model is not end-to-end, it learns the embedder and classifier separately. The embedder learns the class specific cluster representation and class conditional Gaussian learns the prototype classifier. Also, learning only the mean is too simple and it may not handle the complex scenarios. \n\n3: The sample selection strategy requires finding the subset of samples to maximize the posterior. Is there any optimization based model to select this subset of samples? If not, it\u2019s like a brute-force model and sample selection is too costly.\n\n4: Novelty is limited conditional marginal likelihood was explored in earlier work, sample selection approach seems novel but the complexity of it may be a bottleneck.\n\n5: The baselines are weak and no recent model are included. How the author created the baseline for the previous work and upper-bound? The implementation details of the baseline are missing, do the author did the proper hyperparameter search for the baseline? \n\n[a] Calibrating CNNs for Lifelong Learning, NeurIPS-20\n\n[b] Ternary Feature Masks: zero-forgetting for task-incremental learning, CVPRW-21\n\n[c] Supermasks in Superposition, NeurIPS-20\n\n[d] Continual Learning using a Bayesian Nonparametric Dictionary of Weight Factors, AISTATS-21\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper has clear writing, novelty is limited and proper baseline of close work and recent works are missing.\nThe code is provided hence reproducibility may not be an issue.",
            "summary_of_the_review": "The paper uses the simplest setting of CL and without replay recent model shows the result close to the upper-bound.\n\nRecent comparison with the similar and recent work is missing \n\nPaper has some novelty, but that is not significant for the publication. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4279/Reviewer_U88A"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4279/Reviewer_U88A"
        ]
    }
]