[
    {
        "id": "hWQj3u2tG30",
        "original": null,
        "number": 1,
        "cdate": 1666499459167,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666499459167,
        "tmdate": 1666531275724,
        "tddate": null,
        "forum": "tF_iDkYA_Z5",
        "replyto": "tF_iDkYA_Z5",
        "invitation": "ICLR.cc/2023/Conference/Paper2414/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a simple and effective gradient deconfliction algorithm, called GradOPS, for multi-task learning (MTL). Concretely, GradOPS projects the gradient associated with one task onto the subspace orthogonal to the span of the other task-specific gradients, achieving non-conflicting gradients for different tasks. Theoretical analysis of the convergence of GradOPS is provided, followed by extensive experiments on several multi-task learning datasets. Overall, this paper demonstrates the effectiveness of the proposed novel algorithms, both from theoretically and practically.",
            "strength_and_weaknesses": "Strengths:\n1. The proposed algorithm is simple and effective. I am very happy to see that such simple algorithm can achieve non-conflicting gradients and improved performance for multi-task learning problems.\n2. Figure 1 is a good example to illustrate the differences between the proposed GradOPS and existing MTL algorithms. \n3. Theoretical analysis of the convergence of GradOPS is provided, ensuring that the output of GradOPS can converge to a Pareto stationary point.\n4. Authors also give a full discussion of the advantages of the proposed GradOPS in Section 3.3.\n5. I find almost no typos in the paper.\n\nWeaknesses and Suggestions:\n1. More clarity on Figure 1. I appreciate the illustration of Figure 1. However, I believe that it can be improved in terms of the clarity and beauty. For instance, the caption of Figure 1 in Page 2 should include the calculation of the aggregated gradient G = \\sum_{i=1}^{3}g_{i}, instead of letting readers seek the detailed aggregation rule of G in Subsection 3.1 in Page 4. Besides, different arrows with different colors in Figure1 represents different gradients, and it will be better to clarify them in the caption. Finally, the notation of GradOPS-modified g_{1}^{\u2018} looks not good enough. It should be g_{1}^{\u2018} instead of g^{\u2018}_{1} in Figure 1(b)(c)(d), to keep notation consistence with g_{1} in Figure 1(a).\n2. The theoretical results should be placed in the main paper, and in particular, the assumptions of the convergence of the proposed algorithm in Theorem 1 & 2 should be expressed explicitly in the main paper (e.g. in the bottom of page 4). For example, the convergence of GradOPS in Theorem 1 requires the Lipschitz properties of the gradient and the small step size of GD. Such assumptions are quite essential to derive the final theoretical results, and should be clarified in the main paper (e.g. at least with the claim \u201cthe convergence of GradOPS is provided in Theorem 1, under mild assumptions of neural network and the step size of GD\u201d). A counterexample is that, if we use ReLU activation function in deep neural network, the smooth assumption of neural network could not be satisfied and the convergence of GradOPS in Theorem 1 could not be guaranteed.\n3. As far as I can tell, the proof of Theorem 1 and Theorem 2 is easy (and hence is correct), so the derived results should not be stated as Theorem. It will be better to call them as Proposition.\n4. More explanations on the architecture of the deep neural networks (DNN) in experiment Part. As far as I can see, this paper uses different deep neural networks as backbones for different datasets, and authors also point out the name of these networks in the main paper. However, the components of DNN is very important in our experiments, and so I will suggest the authors to give more explanations on the components of DNN in the Appendix C (e.g. the kernel size of convolutional network, and the activation function in DNN).\n5. Other minor suggestions: (1) Eqs.4 and 5 can be merged and put in one line for concise. (2) Avoid orphan line before Section 3.1. in Page 4 and the orphan line at the top of Page 9. (3) Typos: in caption of Figure 3, \u201cthe final updated direction\u201d.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: not bad. \nQuality: the writing can be improved. \nNovelty and Reproducibility: good.\n",
            "summary_of_the_review": "Thank authors for their detailed responses. In terms of others\u2019 review and authors\u2019 feedback, I remain my score as \u201cweak accept.\u201d",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "I have no ethics concerns.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2414/Reviewer_tv3z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2414/Reviewer_tv3z"
        ]
    },
    {
        "id": "1Py3I3AdYo",
        "original": null,
        "number": 2,
        "cdate": 1666604530388,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666604530388,
        "tmdate": 1666940884342,
        "tddate": null,
        "forum": "tF_iDkYA_Z5",
        "replyto": "tF_iDkYA_Z5",
        "invitation": "ICLR.cc/2023/Conference/Paper2414/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Training multitask learning models can be difficult at times due to the existence of conflicting gradients. That is, when computing the gradient of the model's parameters, different tasks present different gradients which can differ in magnitude and direction, counteracting each other when added up, and leading to parameter updates that obtain unsatisfactory results. \n\nIn this paper, the authors argue the necessity and importance of the absence of gradient conflict during training, and provide a method to explicity ensure this setting. The method, GradOPS, generates a new set of gradients by first transforming the original gradients into an orthogonal set of vectors, and then subtracting their contribution (i.e. projection) from the original gradients, making sure that the resulting gradients do not conflict the original ones. Finally, these gradients are added up, weighted by their contribution to the final update direction (and a hyperparameter).\n\nThe authors then conduct three experiments on a multitask binary-classification, NYUv2, and a recommendation system, proving their method effective compared with other MTL approaches.\n",
            "strength_and_weaknesses": "**Strengths**\n- S1: I like the distinction between strong and weak non-conflicting gradients, although I find the explanations a bit too hand wavy for my taste.\n- S2: The proposed method does not depend on the task ordering, which I find quite important.\n- S3: Using scalar projections to measure the \"dominance\" of one task in the training process is quite interesting.\n- S4: I really like the use of Mean Rank to compare methods in the experiments.\n\n**Weaknesses**\n\nProposed method\n- W1: I have serious concerns understanding the proposed method and the intuition behind it:\n  - As of Eq. 1, $u_i$ is not defined for $i \\neq 1$.\n  - For $i \\neq 1$, $u_2 = 0$ always.\n  - It is not clear to me why this method should work. For example, if there are more tasks than parameters, then the basis generated by GS would span the entire parameter space. Then Eq. (2) would produce $g_i = 0$ for all tasks, unless for some subtle reason in the algorithm, $u_i$ is always different from 0. \n   - I fail to understand the reason behind the double normalization in Eq. 4 and 5, rather than weighting $R_i$ directly in Eq. 4.\n- W2: One of the advantages of GradOPS is that \"it solves all conflicts among tasks,\" meaning that the resulting vectors $g'_i$ hold $\\langle g'_i, g_j \\rangle \\geq 0$ for all $i$ and $j$. I fail to see this as a milestone by itself, since this could very well be achieved by multiplying all gradients by 0. Why is this important? And why are the new update directions meaningful?\n- W3: While the introduction of the parameter $\\alpha$ is introduced with the advantage of exploring more solutions, there is no control or intuition for the practitioner on which values of $\\alpha$ set to get to a desired trade-off.\n\nExperiments\n- W4: While the experiments are repeated ten times, there are no standard deviations and no best averaged results were marked in bold, rather than running any statistical test to check for significant changes.\n- W5: Results on the NYUv2 dataset are significantly worse than those reported in the literature, for example, in RotoGrad [1] and RLW [2].\n\nLiterature review: \n- L1: Literature review is missing some conflicting gradient methods that do not fit in the MOO vs. projection discussion: e.g. GradDrop [3] randomly drops elements of the task gradients, and RotoGrad [1] applies rotation matrices in the heads to align task gradients.\n- L2: Some comments feel a bit off. For example, saying that IMTL-G is a state-of-the-art method is rather questionable.\n\n**Questions:**\n- Q1. How were the MR and $\\Delta m$ computed? Individually for each run, or over the averaged results?\n- Q2: Which values of $\\alpha$ were selected for CAGrad and GradNorm?\n\n[1] - Spotlight, ICLR 2022 - [RotoGrad: Gradient Homogenization in Multitask Learning](http://arxiv.org/abs/2103.02631)\n\n[2] - ArXiv - [A Closer Look at Loss Weighting in Multi-Task Learning](http://arxiv.org/abs/2111.10603) \n\n[3] -  NeurIPS 2021 - [Just Pick a Sign: Optimizing Deep Multitask Models with Gradient Sign Dropout](https://proceedings.neurips.cc//paper_files/paper/2020/hash/16002f7a455a94aa4e91cc34ebdb9f2d-Abstract.html)",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity** I find the paper well written in general. However, writing could be improved a bit, e.g., by replacing expressions such as \"What's more.\"\n\nMoreover, I find quite concerning the usage of the word \"gradient\" along the entire text, as it is not clear to me that this modified gradients are still gradients. I also find some statements too strong for my taste (without further justification or citation), such as \"Existing MOO methods only seek weak non-conflicting G towards certain trade-offs, _which is directly responsible for task performance._\"\n\n**Quality** Disregarding all the concerns I've presented in the section above, I find the quality of the paper ok.\n\n**Novelty** The proposed method is rather novel.\n\n**Reproducibility** The experiments are not reproducible since there is no code provided and the proposed method is not well-defined.",
            "summary_of_the_review": "Overall, I find the idea of the paper (robustifying, in some sense, projection-based methods to improve conflicting gradients) appealing, and it could be a nice direction to pursue. The paper also have some cool reflections regarding conflicting gradients.\n\nHowever, the proposed method has some questionable design choices and technical flaws that need further investigation/clarification, including the motivation of why the proposed procedure leads to sensible directions to follow during optimization.\n\nThis, added to some concerns on the experimental part, makes me believe that the manuscript needs a bit more of work, and hence leans me towards rejection.\n\n",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2414/Reviewer_CAmc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2414/Reviewer_CAmc"
        ]
    },
    {
        "id": "VVUVWpjFeq",
        "original": null,
        "number": 3,
        "cdate": 1666784955720,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666784955720,
        "tmdate": 1666784955720,
        "tddate": null,
        "forum": "tF_iDkYA_Z5",
        "replyto": "tF_iDkYA_Z5",
        "invitation": "ICLR.cc/2023/Conference/Paper2414/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This manuscript proposes a novel projection-based method for tackling the issues of gradient conflict in the multi-task learning problem, GradOPS. The work improves previous projection-based methods like PCGrad by projecting conflict gradients onto an orthogonal subspace. In this way, it can not only resolve all conflicts in more than two tasks but also effectively searches for diverse solutions with different trade-off preferences among different tasks.",
            "strength_and_weaknesses": "Strengths:\n\n1. The underlying idea of this work is well-motivated. It hypothesizes a reasonable theory about the \u201cconflicting gradients\u201d issue in multi-task learning and follow-up with a simple algorithm.\n2. The concept definition of \u201cstrong non-conflicting\u201d and \u201cweak non-conflicting\u201d provide a clear description of the core issue, which in turn strongly serves as the basis for method design.\n3. The proposed method is simple and general, it can be easily applied to various gradient-based approaches. Furthermore, the paper writing is professional and rigorous.\n\nWeaknesses:\n\n1. Although this work provides a novel projection-based approach, the core idea does not improve too prominently from previous work (Yu et al., 2020; Wang et al., 2020), in fact, PCGrad can also be generalized to the case of T > 2 as well (and the experimental results did not significantly exceed PCGrad, shown in Table 1, 2). Moreover, compared to PCGrad, the theoretical analysis of this paper is relatively weak.\n2. The experimental results are somewhat disappointing, which makes the proposed method less convincing. For instance, the results in Table 1 and Table 2 are not exactly better than the baseline method (MGDA). In addition, the performance of GradOPS shown in Table 3 is highly dependent on a good choice of \u03b1 values, which may mean that the method is not so general for different types of datasets.\n3. There is no comparison with the state-of-the-art algorithm, in fact, the NashMTL (Navon et al., 2022) has surpassed the previous method, suggesting that the authors supplement the corresponding comparison experiments.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-organized and somewhat novel; however, there are some weaknesses required to address.",
            "summary_of_the_review": "This paper is well-organized and somewhat novel; however, there are some weaknesses required to address.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2414/Reviewer_FaLj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2414/Reviewer_FaLj"
        ]
    },
    {
        "id": "NV4nW94usf",
        "original": null,
        "number": 4,
        "cdate": 1666935271471,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666935271471,
        "tmdate": 1670881722449,
        "tddate": null,
        "forum": "tF_iDkYA_Z5",
        "replyto": "tF_iDkYA_Z5",
        "invitation": "ICLR.cc/2023/Conference/Paper2414/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "To address the task interference in multi-task learning, this paper presents an innovative method to obtain deconflicted gradients among tasks. This is done through projecting the gradient of a task to the subspace that is orthogonal to that spanned by the gradients of all other tasks. The authors provide the convergence analysis of the method and tested the method using two benchmark datasets and one large-scale recommendation dataset. ",
            "strength_and_weaknesses": "Strength\n+ The proposed method produces deconflicted gradients that are not in confliction with any original gradients. \n+ The deconflicted gradients make it much easy to define an overall updating gradient that does not conflict with any individual task specific gradient while weighting tasks during learning. \n+ Code will be provided\n+ Presentation of the manuscript is clear\n\nWeakness\n-  Regarding the discussion underneath Eq. (2), since g_i\u2019 is located in the subspace that is orthogonal to that spanned by all g_j\u2019s, should be g_i\u2019\u2022 g_j = 0? \n- The underlying assumption of existence of all g_i\u2019 is that all g_i\u2019s should be linearly independent among them. A discussion of such assumption in reality would strength the approach.\n-  Resulting from using different \\alpha values on test set are provided. However, no discussion is made how \\alpha would be tuned in practice. Use results from the \\alpha value leading to the best test performance to compare with other methods is not a fair comparison. \n- Recent related work should be discussed and compared, for example:\nJavaloy, A., & Valera, I. (2022). RotoGrad: Gradient Homogenization in Multitask Learning. ICLR, 1\u201324. http://arxiv.org/abs/2103.02631\n- My biggest concern of this paper is the weak empirical results, with minimal difference in the results among compared the methods (especially, table 1 and 3), which does not support the advantage of the proposed method claimed by the authors.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Good",
            "summary_of_the_review": "The idea is interesting and the method is technically sound. However, several weaknesses as listed, especially, the weak empirical results dampened my enthusiasm of this paper. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2414/Reviewer_JvTK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2414/Reviewer_JvTK"
        ]
    },
    {
        "id": "Xn9Fc7pqVQ",
        "original": null,
        "number": 5,
        "cdate": 1667162998827,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667162998827,
        "tmdate": 1667162998827,
        "tddate": null,
        "forum": "tF_iDkYA_Z5",
        "replyto": "tF_iDkYA_Z5",
        "invitation": "ICLR.cc/2023/Conference/Paper2414/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new method for resolving the gradient conflicts encountered in multi-task learning problems. Gradient conflict means when two gradients have a negative cosine similarity. The idea is based on [1] to project gradients of tasks to be orthogonal to all the other tasks if there is any gradient conflict between the two tasks. The difference is that in [1] gradient is projected iteratively based on pairs of tasks. In this work, the gradient is projected to the subspace that is orthogonal to the span of all other gradients. The paper also explores tuning the weight of gradient aggregation after resolving all gradient conflicts, so that it allows controlling the balance over different tasks. The experiments show that the proposed method is able to optimize for different Pareto optimal solutions and the results are competitive.\n\n[1] Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol Hausman, and Chelsea Finn. Gradient surgery for multi-task learning. Advances in Neural Information Processing Systems, 33:5824\u20135836, 2020.",
            "strength_and_weaknesses": "Strength: \n1. The method proposed is guaranteed to resolve all gradient conflicts. \n2. The method allows an easy way to control the weights of gradients from different tasks, which is nice to have to explore different Pareto optimal solutions to the problem. \n\nWeaknesses:\n1. The idea of projection is not new but based on Yu et al. 2022. \n2. Not sure if strictly enforcing no gradient conflicts by projecting to the orthogonal subspace loses too much information about the gradient. In the worst-case scenario where there are a lot of gradient conflicts, this method will destroy a lot of the original gradient information by iterative projecting the gradients to a new orthogonal subspace. I would be more convinced if there is some evidence on how this procedure destroys or keeps most of the gradient information as compared to Yu et al. \n3. I would love to see how Yu et al. performs with a similar kind of gradient re-weighting, though it would be non-trivial since there could be gradient conflicts in Yu et al.\u2019s method (i.e. not all cosine similarity between g_i and G are positive, maybe use an exponential of the cosine similarity). As it seems like when alpha = 0, (i.e. gradient averaging after resolving the gradient conflicts), the proposed method does not have a clear advantage over Yu et al. It is the flexible re-weighting that makes it interestingly competitive. I wonder if that is also true by applying a similar re-weighting idea to Yu et al.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and the idea is clearly illustrated with visualizations and descriptions of how the algorithm works. The experiments are quite extensive, the method is compared with several state-of-the art baselines. The idea of projecting gradient is not completely new, but more based on Yu et al. and extending it to projection to orthogonal subspace. ",
            "summary_of_the_review": "Overall, I think the paper presents an interesting perspective on how to do flexible re-weighting of gradients based on the cosine similarity of the independent task gradient and the aggregated gradient. The idea of gradient projection is not completely new but inherited from Yu et al. I have some reservations about whether it makes the most sense to project gradient to be orthogonal to all other gradients to resolve the conflict, as it can lose a lot of the gradient information. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2414/Reviewer_wEFB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2414/Reviewer_wEFB"
        ]
    }
]