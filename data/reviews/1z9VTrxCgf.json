[
    {
        "id": "5_Ycbr2zWZS",
        "original": null,
        "number": 1,
        "cdate": 1666183837970,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666183837970,
        "tmdate": 1666183837970,
        "tddate": null,
        "forum": "1z9VTrxCgf",
        "replyto": "1z9VTrxCgf",
        "invitation": "ICLR.cc/2023/Conference/Paper3073/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a semantic manipulation framework, combining low-level and high-level conditions, for object removal, object replacement, semantic relationship change and object addition. Quantitative and qualitative experiments validate the effectiveness of this design.",
            "strength_and_weaknesses": "### Strengths\n1. Each of the four mentioned problems is well-defined and carefully processed in SIMBIL. Compared with existing methods, the method shows superior performance in semantic understanding and image manipulation.\n2. The resource requirement of SIMBIL is more relaxed, without reliance on human annotations and external large datasets, thus being more user-friendly.\n3. The paper is easy to follow and the system is easy to reproduce.\n\n### Weaknesses\n1. The comparison is not so convincing as the involved competing methods are not specifically trained on the datasets as SIMBIL does. It remains questionable whether SIMBIL will be still the best if other methods are well-finetuned or re-trained.\n2. The visualized results of SIMBIL in Fig.4 and Fig.5 are far from satisfying. We observe obvious unappealing artifacts or the prediction is quite different from the ground truth, e.g., the replaced object in Fig.4 (the 2nd case) should be a ball instead of a cube.\n3. The paper introduces a well-designed system, but the technical novelty is quite limited. The background-guided internal learning is quite ad-hoc for object removal. Besides, the system requires the GT scene graph for manipulation, which is impractical in real-world cases. Though scene graph generation methods could be adopted, we do not know the degree of performance drop so that the robustness of the system should be evaluated.\n4. Some typos should be fixed. For example, the 2nd line 'Benefits from ... outline ...' should be 'Benefiting from ... outlining ...'.",
            "clarity,_quality,_novelty_and_reproducibility": "This work gives us some new insights into image manipulation, which is interesting. The paper is well-organized and explained clearly.",
            "summary_of_the_review": "The paper develops a unified system for multiple image manipulation tasks, demonstrating its high flexibility. But the authors should compare different methods in a more rigorous manner, and the visual results should be further improved. More technical novelties are required.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3073/Reviewer_mRHW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3073/Reviewer_mRHW"
        ]
    },
    {
        "id": "8NqpVi6M3of",
        "original": null,
        "number": 2,
        "cdate": 1666621335551,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666621335551,
        "tmdate": 1666621335551,
        "tddate": null,
        "forum": "1z9VTrxCgf",
        "replyto": "1z9VTrxCgf",
        "invitation": "ICLR.cc/2023/Conference/Paper3073/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes SIMBIL to manipulate the image in high-level and low-level aspects. High-level manipulation requires less manual effort from the user compared to manipulating raw image pixels. The low-level internal learning approach is scalable to images of various sizes without reliance on external visual datasets for training. The experiments show the good performance of this paper.\n",
            "strength_and_weaknesses": "# Strength\n1. This paper use scene graphs to build the relationship between objects. And the users can manipulate the image with the scene graphs, which is more flexible than the low-level control method.\n2. The SIMBIL can automatically predict RoI for the object addition and semantic relationship change tasks. This strategy helps the users not select the specific regions of the object and improves the robustness of SIMBIL.\n3. The background-guided internal learning is reasonable, which can help the complete content consistent with the background even with the large holes.\n\n# Weakness\n1. Is the correct scene graphs essential for the performance of image manipulation? The authors should compare the different scene graph prediction methods. \n2. If the image has no multi-object, is the SIMBIL can work well? For example, there is a sky in an image, and the sky has many clouds, dose the scene graphs can build the relationship between these clouds?\n3.  For object removal, the edge-connect is not the SOTA. The authors should compare the SOTA method [1,2].\u00a0\n4. The novelty of SIMBIL is lacking. The main difference between the proposed methods and SIMSG is background-guided internal learning. I think this is not enough for the ICLR. As I mentioned above, if SIMBIL uses the SOTA object removal method, I think the performance may be better. \n\n[1] Suvorov, Roman, et al. \"Resolution-robust large mask inpainting with fourier convolutions.\"\u00a0Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2022.\n\n[2] Li, Wenbo, et al. \"MAT: Mask-Aware Transformer for Large Hole Image Inpainting.\"\u00a0Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: fair\nQuality: fair\nNovelty: poor \nReproducibility: fair",
            "summary_of_the_review": "See the weakness.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3073/Reviewer_Pno2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3073/Reviewer_Pno2"
        ]
    },
    {
        "id": "LBHhdHzx387",
        "original": null,
        "number": 3,
        "cdate": 1667101088186,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667101088186,
        "tmdate": 1667101088186,
        "tddate": null,
        "forum": "1z9VTrxCgf",
        "replyto": "1z9VTrxCgf",
        "invitation": "ICLR.cc/2023/Conference/Paper3073/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper edits images with the guidance of a modified scene graph. Building on image deep prior, this paper takes the foreground and background separation into account for better synthesis quality. Experiments on CLEVR and visual genome illustrate the performance of the proposed method.",
            "strength_and_weaknesses": "**Strength**\n- This paper makes attempts to edit an image with a modified scene graph.\n\n- Experiments compare with many recent methods and a user study is given.\n\n**Weakness**\n\n- The contributions of this paper could be strengthened. For now, it is hard to find significant novelty and insights in the scene graph modification and RoI prediction part. As for the background-guided learning strategy, it simply separates the foreground and background and uses them for image generation. The overall technical novelty is weak.\n\n- The deep image prior, as a single image-based method, performs much worse than the ones learned from a large-scale image dataset. Thus, it is not convincing that the authors mainly base on and compare with the deep image prior work in Sec. 3.3.\n\n- The scene graph modification only contains four simple forms, making the use of a scene graph (as a scene graph can model very complicated scenes) questionable. Maybe a simple input triplet or a referring expression will work.\n\n- I would like to see more relationship change results for complicated natural images. \n\n- The visual results are unsatisfactory and contain noticeable artifacts. For example, the *remove* results are much worse compared with the reported results in state-of-the-art papers (the results of LDM are obviously wrong). The authors should check their experiment settings and make sure the compared results are correct.\n\n- The organization and presentation of this paper could be improved. I am confused about the relationship between object removal and scene graph editing.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The authors are encouraged to improve the clarity and quality of this paper. The novelty of this paper is below the quality bar of an ICLR paper. As a straightforward improvement on DIP, this paper could be easily reproduced by modifying the DIP code.",
            "summary_of_the_review": "Considering the weak technical contributions and potential problematic implementation of other methods, I do not suggest this paper for acceptance.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3073/Reviewer_8S2u"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3073/Reviewer_8S2u"
        ]
    },
    {
        "id": "jwTKuNc5_vr",
        "original": null,
        "number": 4,
        "cdate": 1667580971071,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667580971071,
        "tmdate": 1667580971071,
        "tddate": null,
        "forum": "1z9VTrxCgf",
        "replyto": "1z9VTrxCgf",
        "invitation": "ICLR.cc/2023/Conference/Paper3073/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new framework, named SIMBIL, for semantic image manipulation. The framework contains three components, including a segmentation module to extract the target object according to the modified scene graph, a RoI prediction module to determine the new location of the target object, and a background-guided internal learning to complete the \u201chole\u201d in the original location of the target object. ",
            "strength_and_weaknesses": "Strength\n1. The idea of manipulating image by modifying its scene graph is new and has potential.\n2. The proposed background-guided internal learning makes sense and alleviates the drawbacks of existing schemes.\n3. The results on the validation benchmark are promising and surpass prior semantic image manipulation methods.\n\n\nWeaknesses\n1. There are some inaccuracies or self-contradictions in the description of high-level ideas of the proposed method. For example, \n(a) In Sec.1, the authors state \u201clow-level manipulation spans image inpainting, object removal\u2026 do not need to understand the semantic meaning of an image\u201d, which should be wrong. First, addressing tasks like image inpainting and object removal via neural networks requires semantic information. For example, for inpainting, it is necessary to understand the semantic information around the missing area to perform meaningful completion.\nSimilarly, before removing an object, it is necessary to know its semantic information to accurately segment the entire object. Second, the word \u201clow-level\u201d may be confusing here. \u201clow-level\u201d usually refers to tasks that are not related to image content/semantics, such as image denoising and deblurring. These tasks do not need to know what the image content is. Therefore, it is more accurate to use words like \"pixel-level manipulation\" rather than \u201clow-level manipulation\u201d.\n\n(b) In Sec.2, the authors state \u201cimage manipulation can be seen a special case of image synthesis\u201d, which may be inaccurate. Image manipulation not only includes synthesis, many other operations, such as image enhancement, cropping, and denoising, are all image manipulations. Besides, some statements like \u201cUnlike methods based on generative networks, SIMBIL \u2026 directly manipulating raw pixels\u201d are difficult to understand (as SIMBIL also uses background-guided internal learning to generate pixels).\n\n(c) In Sec.3, the authors state \u201cwe perform four tasks of semantic manipulation: object addition, \u2026, and object removal\u201d, which conflicts with the statement in (a) above because \u201cobject removal\u201d becomes a \u201csemantic manipulation\u201d here.\n\n2. It is not clear how the proposed components form object replacement flow. Specifically, whether the proposed framework adding the target object before or after completing the missing background?\n\n3. The rationale for using RoI Prediction for Relationship Change may be further discussed. Specifically, for object Relationship Change, modifying the scene graph requires a huge effort because many graph edges need to be modified (e.g., in Fig.2, moving the blue cylinder needs to change five edges carefully). Instead, the operation of directly dragging/resizing the segmented object to the specified position should be faster and more accurate (e.g., in Fig.2, users may directly drag the blue cylinder to a certain position in a precise manner). After that, the scene graph may be updated according to the user interactions in some way.\n\n\n4. Since the discussed limitations like artificial boundary and biased background are also appear in other tasks like image inpainting / generation. More task-specific limitations may be discussed. For example, as the proposed methods require scene graph as an input. In practice, a complete scene graph requires huge efforts to create, especially scenes with lots of objects. Hence, how robust the proposed method when inputting an incomplete scene graph?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The proposed method has a certain novelty and achieves promising results. However, insights and in-depth analytical discussions behind the proposed method are missing.\nBesides, the writing of the article needs to be improved. There are some misinterpretations of basic knowledge, some sentences that are difficult to understand, and some self-contradictory descriptions.\n",
            "summary_of_the_review": "The paper proposed an interested method with great results. But the writing of the paper should be improved, and more analysis may be included. I would like to see in the rebuttal (a) the authors' answers to the above questions and (b) the authors' ideas for improving the manuscript to remove incorrect or contradictory descriptions, which determine the final score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3073/Reviewer_BfVZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3073/Reviewer_BfVZ"
        ]
    }
]