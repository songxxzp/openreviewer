[
    {
        "id": "84IJWIObfF",
        "original": null,
        "number": 1,
        "cdate": 1666754782252,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666754782252,
        "tmdate": 1671008931315,
        "tddate": null,
        "forum": "17RDXeF-skZ",
        "replyto": "17RDXeF-skZ",
        "invitation": "ICLR.cc/2023/Conference/Paper6496/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper aims to learn a set of classifiers to take care of different predictive signals in the dataset. They propose that the \"diversity\" of the ensemble is important and the conditional independence is an effective way to realize this goal.",
            "strength_and_weaknesses": "Pros:\n* The proposed fast adaption method for ensemble learning can addresses distribution shift and shortcut learning simultaneously. These two issues are common and realistic in practice.\n\nCons:\n* Based on the description in this paper, I find the separate predictive signals are very similar to multi-view learning. Both of them are to use the different perspectives of a dataset to perform learning tasks. More discussions about the similarities and differences between these two settings are required. If the methods of multi-view learning could be extended to this problem.\n\n* The motivations are not clear. For example, they claim that considering the independence of latent factors conditioned on labels is better. However, I cannot get its advantages over unconditioned independence from this paper. \"Dimensions of z can be dependent by virtue of their correlation to y\" may be a reason. However, this explanation is too abstract, and more high-level analyses and practical examples will be better. As a way to realize the conditional independence, why do they choose the conditional mutual information? What are its advantages? If other metrics that are related to independence would make the method fail?\n\n* The experiment design is problematic. The title of this paper emphasize the \"distribution shift\". However, in experiments, they mainly verify the effectiveness for shortcut learning,  and the distribution shift is not verified specifically. They should perform additional experiments on the datasets of domain adaptation or OOD generalization. Besides, due to the similarity with multi-view learning, comparing CoDE with the corresponding methods is necessary.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity needs to be further improved. The quality and originality are fine.",
            "summary_of_the_review": "Please refer to Strength And Weaknesses.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6496/Reviewer_iHMc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6496/Reviewer_iHMc"
        ]
    },
    {
        "id": "AwiqRVOrSS",
        "original": null,
        "number": 2,
        "cdate": 1666789540213,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666789540213,
        "tmdate": 1666789540213,
        "tddate": null,
        "forum": "17RDXeF-skZ",
        "replyto": "17RDXeF-skZ",
        "invitation": "ICLR.cc/2023/Conference/Paper6496/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper discusses a method for learning diverse ensembles \u201cConditionally Independent Deep Ensembles (CoDE)\u201d and benchmarking its performance with shortcut learning datasets (i.e. ColoredMNIST, Waterbirds). The main objective is to enforce variability of the signals picked  avoiding to rely always on the same and/or strongest signal. \n\nAuthors aim to enforce conditional independence  on the output distributions (there are good properties of doing so as stated by authors i.e. being computationally cheaper). Also authors focus on enforcing confident predictors. That takes the form of two loss components: \n\n(i) CMI - a conditional mutual information component that is computed on pairwise predictors/networks\n(ii) R - a \u201cconfident\u201d-prediction regularization\n\nBoth are controlled by scalar factors to weight their importance.\n\nIn terms of literature counterparts, authors reference two main papers: Pace et al. (2020) and Rame & Cord (2021) ",
            "strength_and_weaknesses": "Results on the ColoredMNIST dataset (table 1) raises some questions to me (i) does the train column refer to metrics of testing on the train set? and if so, does it show a tendency of \u2018competing\u2019 methods to overfit? -(ii) The difference of performance with TC-Ensemble Pace et al. is small, is there perhaps a computational benefit in comparison? (iii) the work by Pace et al. (2020) is included in the table but Rame & Cord (2021) not \u2013 being one of the closest references it would help to see its benchmark as well, or understand why it may not be applicable.\n\nThe model has a few possible variations: being sequential/joint, which is addressed by results in table 2. However, the two proposed loss components are not further studied beyond the hyperparameter comments on the appendices.\n\nIn terms of the data generation process or the impact of enforcing variability of the ensemble learnt it is not further linked to the results i.e. (i) is it a valid assumption or (ii) does the classifiers learnt show signs of being independent.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written. The data generation process description is detailed and informative. The notation is consistent.\n\n",
            "summary_of_the_review": "Overall, I initially recommend rejecting this submission as results are not very strong in showing performance or computational cost improvement. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6496/Reviewer_aogU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6496/Reviewer_aogU"
        ]
    },
    {
        "id": "Oa67aHlFuPK",
        "original": null,
        "number": 3,
        "cdate": 1667191533298,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667191533298,
        "tmdate": 1667191533298,
        "tddate": null,
        "forum": "17RDXeF-skZ",
        "replyto": "17RDXeF-skZ",
        "invitation": "ICLR.cc/2023/Conference/Paper6496/-/Official_Review",
        "content": {
            "confidence": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.",
            "summary_of_the_paper": "This paper quantifies a notion of diversity for deep ensembles that facilitates efficient estimation. The authors show that it is sufficient to enforce conditional independence on the output distributions of the classifiers. This leads to their main contribution concerning the regularizing metric: conditional mutual information (CMI), efficiently computed in classification problems. The authors name this approach Conditionally Independent Deep Ensembles (CoDE).  The authors evaluate CoDE on benchmark datasets for shortcut learning.",
            "strength_and_weaknesses": "Strength:\n- The main strength of this paper lies in the clear exposition and development of CoDE.\n- The definitions of invariance and diversity specific to CoDE are novel.\n- The CoDE optimization problem is new, and its solution is efficient.  \n- The numerical results are promising. \n\nWeakness:\n- Novelty of the CoDE objective is unclear in light of the earlier work on conditional mutual information.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and novel.",
            "summary_of_the_review": "The authors' main contribution is the development of CoDE approach and the objective for efficient learning in CoDE.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6496/Reviewer_q3rX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6496/Reviewer_q3rX"
        ]
    }
]