[
    {
        "id": "E2ddv8CSHM",
        "original": null,
        "number": 1,
        "cdate": 1666128399618,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666128399618,
        "tmdate": 1669408655995,
        "tddate": null,
        "forum": "9Y0P3YoERSy",
        "replyto": "9Y0P3YoERSy",
        "invitation": "ICLR.cc/2023/Conference/Paper6283/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper tackles the problem of detection of \u201cillicit\u201d activities. The main proposal is \u201cThe Ganfather\u201d, a Generative Adversarial Network (GAN) that automatically crafts samples conforming to a given \u201cillicit activity\u201d which \u2013 if not detected \u2013 will cause harm to the owners of an information system. By training a detector on the generated \u201cillicit activities\u201d, it is possible to develop a detector that protects the information system against such malicious samples. The proposal, for which no theoretical analysis is provided, is empirically evaluated on two datasets representing typical scenarios affected by illicit activities: money laundering, and recommender systems.",
            "strength_and_weaknesses": "STRENGTHS:\n+ Potentially of use to practitioners\n\n\nWEAKNESSES\n- Misleading contributions\n- Unfair claims\n- Poor evaluation\n- Lack of theoretical foundations\n- No novelty\n- Lack of comparison with prior work\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the presentation of the paper is inappropriate for ICLR.\n\nThe quality of the English text is mediocre: the manuscript is readable, but the writing is superficial at best.\n\nFigures and Tables are of poor quality.\n\nThe topic addressed by the manuscript is source of abundant literature but appropriate for ICLR.\n\nThe references are not appropriate, and there are many related works missing.\n\nThe contribution is not significant.\n\nThe experiments are partially reproducible: the data are public, but the code is not publicly released.\n",
            "summary_of_the_review": "The paper cannot be accepted to ICLR, and I am confident of my decision. Truly, I believe the paper requires a complete re-write, starting from its conceptualization: put simply, the contributions of \"The GanFather\" - as presented in the paper - are unfair and misleading. Probably, the authors should simply begin by performing a detailed review of existing literature on \u201cautomatic\u201d evasion of ML systems / generation of adversarial (or \u201cout of distribution\u201d) samples, as there are hundreds of papers that propose similar systems. Below I will list some additional issues that affect the paper. \n\n**Misleading contributions (no labels).**\nIt is unfair to claim that the proposed method requires \u201cno label\u201d as a contribution. First, because the \u201cGanfather\u201d is simply a GAN, which\u2014by definition\u2014requires no labels. Second, because the problem of labels is that they must be created via the human supervision: although, yes, the GanFather does not require supervision in the form of \u201clabels\u201d, it still requires supervision to define the \u201cintended behavior [of the illicit activity]\u201d (quoted from the introduction). Hence, the absence of labels is a \"fake\" contribution.\n\n**Misleading contribution (automated attack generation).**\nProposing methods that \u201cautomatically generate attacks\u201d is (1) not novel and (2) not a contribution per-se. There are literally thousands of approaches that aim to automatically generate attack samples, which may leverage either basic classifiers [C], or GANs [B], or Reinforcement Learning [A].\n\n**Misleading contribution (detection).**\nIt is unfair to claim that the proposed method can \u201cautomatically learn from attacks\u201d as a contribution. Indeed, the process of \u201cre-training\u201d on evasive samples is well-known in literature [A]. This also applies for the contribution denoted as \u201cExpose and augment current defence system:\u201d (which is a 1:1 overlap with the second one)\n\n**Misleading contributions (generality).** \nIt is unappropriate to claim \u201cgenerality\u201d when the method is provided \u201cas is\u201d (there is a significant lack of theoretical analyses supporting its scientific soundness) and when such supposed \u201cgenerality\u201d is empirically evaluated on just two settings. What is worse, is that such experiments are shallow: I would have at least expected some sort of statistical validation, but there is no trace of such testings.\n\n**The contributions are not contributions.**\nIrrespective of the above, the \"contributions\" listed in the Introduction are not actually contributions, but rather properties of the proposed \"The GANFather\" method. The question is: does \"The GANFather\" perform better than existing methods? Unfortunately, the answer to this question cannot be answered because there is no hard-comparison with any \"automatic generation\" method. A proper comparison could be made by using any \"GAN\"-based method to generate some \"illicit activities\", and then showing that such activities would be either easily detected; or would not be good enough to make a detector \"as robust\" as those generated by \"The GANFather\".\n\n**Lack of theoretical analysis.**\nAs a direct consequence of the above issue, there is no theoretical argument supporting not only the \u201cgenerality\u201d, but also the rationale behind the proposed \u201cGanfather\u201d method. The description is provided in Section 2.1.1, but it only consists in a single equation (with several terms never introduced), with no justification whatsoever as to why it would even remotely work. What is worse is that the paper attempts to propose such a method as \u201cnovel\u201d: as a matter of fact, no work is cited in Section 2.1 (aside from (Arjovsky et al. 2017) to regulate the GAN loss). I will be blunt and state the following: the claimed generality is passable as a \u201cwe use GANs to solve this problem, and hence our method is general; however, the specific application of our method requires domain expertise and significant tuning and supervision\u201d which is unfair, unscientific and definitely not appropriate for ICLR.\n\n**Misleading evaluation of \u201creal-world\u201d**\nThe abstract states that the paper \u201cevaluates the method in two real-world use cases\u201d. I was hoping that the evaluation was truly performed on some \u201creal world\u201d deployment. However, these use-cases simply use \u201cbenchmark\u201d datasets collected from the real-world \u2013 which is hardly passable as an \u201cevaluation on a real-world use case\u201d. With such premises, any evaluation can be claimed to be a \u201creal-world use case\u201d.\n\nSome additional issues:\n\n\u2022\tThe first paragraph of the Introduction is illogical: \u201cIllicit activities frequently target digital systems and services. Importantly, these illicit activities are adversarial: an attacker and a defence system constantly adapt to each other\u2019s behaviour.\u201d First, \u201cillicit activities\u201d do not \u201ctarget\u201d anything: it is attacker who \u201ctarget\u201d digital systems and perform \u201cillicit activities\u201d with such systems. Second, the term \u201cadversarial\u201d is misleading, and it is not true that \u201cattacker and defence system constantly adapt\u201d (I dare say in most domains there is no adaptation by the \u201cdefence\u201d at all). I suggest revising this paragraph entirely.\n\n\u2022\tThe second paragraph of the Itntroduction does not logically follow the previous one. What is the need of \u201cfor instance\u201d? To me, this paragraph should follow something along the lines of \u201cDespite providing many advantages, information systems are vulnerable to cyber attacks.\u201d The same applies for the third paragraph of the Introduction.\n\n\u2022\tThe paper states that \u201cRecent estimates indicate undetected money laundering activities of C0.7\u20133 trillion annually (Lannoo & Parlour, 2021)\u201d. I checked (Lannoo & Parlour, 2021) and I couldn\u2019t find a single occurrence of \u201c0.7\u20143 trillion\u201d. Rather, I found \u201cMoney laundering is estimated to cost the global economy between USD800 billion and USD2 trillion annually, according to the United Nations Office on Drugs and Crime report 2020\u201d. \n\n\u2022\tThe following sentence in the Introduction should be revised \u201cFor example, a one-star decrease in restaurant ratings can lead to a 5 to 9 percent decrease in revenue (Luca, 2016)1. Detecting malicious agents is far from trivial. A critical challenge relates to class imbalance, as illicit activity is rare. Additionally, labelled datasets are often unavailable or incomplete due to the absence of natural labels and the cost of feedback, primarily generated through manual labelling.\u201d The transition between the example and the technical problems is too abrupt.\n\n\u2022\tThe paper really looks like a \u201cdraft\u201d. The term acronym \u201cAML\u201d is first mentioned in Section 2, but never introduced before (I originally believed it stood for \u201cAdversarial Machine Learning\u201d, but later found out it referred to \u201cAnti-Money Laundering\u201d). Parentheses are sometimes opened and not closed (e.g., beginning of Section 2.1). Equation 1 has several terms that are never mentioned, such as $G, O, D, A$.  The same applies for equation 2: what is $\\mathcal{S}_{in}$? \n\n\u2022\tWhat is the goal of generating \u201cout of distribution\u201d samples if such samples are not realistic in the first place? I am referring to the statement in Section 4.1: \u201cWhereas De Cao & Kipf (2018) concerns generating realistic data that verifies some conditions (e.g., as our method could achieve leveraging the optional alert system), The GANfather generates out-of-distribution data to tackle adversarial domains)\u201d\n\n\n\nEXTERNAL REFERENCES\n\n[A]: Apruzzese, G., Andreolini, M., Marchetti, M., Venturi, A., & Colajanni, M. (2020). Deep reinforcement adversarial learning against botnet evasion attacks. IEEE Transactions on Network and Service Management, 17(4), 1975-1987.\n\n[B]: Usama, M., Asim, M., Latif, S., & Qadir, J. (2019, June). Generative adversarial networks for launching and thwarting adversarial attacks on network intrusion detection systems. In 2019 15th international wireless communications & mobile computing conference (IWCMC) (pp. 78-83). IEEE.\n\n[C]: Garg, S., & Ramakrishnan, G. (2020, November). BAE: BERT-based Adversarial Examples for Text Classification. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) (pp. 6174-6181).\n\n======== \n\nUpdate after authors' response:\n\nI appreciate the authors' efforts in improving the paper and toning down some of its original \"overclaims\". The paper now is more truthful as to what it does. I will increase my score substantially: from a 1 to a 6. ",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6283/Reviewer_hdrh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6283/Reviewer_hdrh"
        ]
    },
    {
        "id": "0VPRZeDgeqy",
        "original": null,
        "number": 2,
        "cdate": 1666659273441,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666659273441,
        "tmdate": 1666659273441,
        "tddate": null,
        "forum": "9Y0P3YoERSy",
        "replyto": "9Y0P3YoERSy",
        "invitation": "ICLR.cc/2023/Conference/Paper6283/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces an adversarial method without label requirements, to enhance the detection of illicit activity in various domains.This method comprises a generator that produces meaningful attacks and a discriminator to detect them.This meaningful attacks can reveal \u00a0defensive weaknesses for the discriminator to correct.The method \u00a0is evaluated with a suite of experiments in money laundering and recommendation systems .",
            "strength_and_weaknesses": "Strengths:\n\n1. Compared with classical GANs,the loss of the author\u2019s generator \u00a0is a linear combination of the loss of three components,including the optimisation objective,the GAN and the alert system .this makes the author\u2019s framework can produce out-of-sample data without label requirements.\n    \n2. In two real-world \u00a0cases, money laundering, and recommendation systems.the generator of framework can produce meaningful attacks ,the discriminator can obtain near-perfect classification by training.\n    \n\nWeaknesses:\n\n1. The method is \u00a0not well demonstrated either by theory or practice.For example, in section 2.1.1,the paper points that the loss of generator of the framework is a linear combination ,where the weights are three hyperparameters controlling. It lacks \u00a0theoretical proof in this paper.\n    \n2. This method has poor versatility because the structure of generator and the optimisation objective of the framework need to be customized.\n    \n3. In the experiments,the discriminator can obtain near-perfect classification,but the author do not provide convincing evidence of the correctness of the proposed approach or its utility compared to existing approaches.\n    ",
            "clarity,_quality,_novelty_and_reproducibility": "original work",
            "summary_of_the_review": "The author provides very limited theoretical and empirical results.This submission looks more like a working draft rather than a conference paper.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6283/Reviewer_kgFf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6283/Reviewer_kgFf"
        ]
    },
    {
        "id": "sCUYX6TC1BF",
        "original": null,
        "number": 3,
        "cdate": 1666748262960,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666748262960,
        "tmdate": 1666748262960,
        "tddate": null,
        "forum": "9Y0P3YoERSy",
        "replyto": "9Y0P3YoERSy",
        "invitation": "ICLR.cc/2023/Conference/Paper6283/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a GAN based approach to generate attacks and also claim to enhance the detection of illicit activity in various domains. They use three type of loss functions to train a generator to generate the attacks. The domain they focus on is money laundering and recommendation systems. The authors claim there methods applies to other settings",
            "strength_and_weaknesses": "The idea here is not novel as there are a number of papers that use a GAN like structure for generating OOD samples (or adversarial examples) - see references below, of course, mostly focussing on image domain. This paper does not work on image domain, which is actually a strength of the paper.\n\nBut, I did not see any insights that are generalizable or even some domain specific hard structural problem that is addressed (i.e., the loss functions used are quite natural and probably too simple). I am not sure why these objective were chosen, is there some citation to support these? I was also hoping to see some quantitative measure of how good the attack is, which in the paper is just shown qualitatively\n\nI do not understand the part about discriminator - a line in the paper says that \"the discriminator eventually learns to distinguish synthetic attacks from real data\", but isnt a GAN supposed to eventually make the discriminator not be able to distinguish (by learning a good generator)? Along same lines, I do not understand what is going on in Figure 4? It seems rather like adversarial training that a neural network is trained with OOD data and is able to then detect those. But, then the generator can be trained again to bypass this new discriminator?\n\nBaluja, S., & Fischer, I. (2018). Learning to Attack: Adversarial Transformation Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 32(1).\nLiu, A., Liu, X., Fan, J., Ma, Y., Zhang, A., Xie, H., & Tao, D. (2019). Perceptual-Sensitive GAN for Generating Adversarial Patches. Proceedings of the AAAI Conference on Artificial Intelligence, 33(01)\nXiao, C., Li, B., Zhu, J. Y., He, W., Liu, M., & Song, D. (2018). Generating adversarial examples with adversarial networks. In 27th International Joint Conference on Artificial Intelligence, IJCAI 2018 (pp. 3905-3911). International Joint Conferences on Artificial Intelligence.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written clearly and I have not checked the code for reproducibility, but the authors present enough details.\n\nI believe the novelty is limited - see weaknesses listed.\n",
            "summary_of_the_review": "My recommendation is based on my perception of limited novelty and lack of new generalizable principles to be taken away from this work.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6283/Reviewer_x8ad"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6283/Reviewer_x8ad"
        ]
    }
]