[
    {
        "id": "1FbhrzVCGu",
        "original": null,
        "number": 1,
        "cdate": 1666537864852,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666537864852,
        "tmdate": 1670646979068,
        "tddate": null,
        "forum": "9rRhMKNOkeT",
        "replyto": "9rRhMKNOkeT",
        "invitation": "ICLR.cc/2023/Conference/Paper4789/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper tackles the problem of concept-based explanations for deep neural network OOD detectors. The authors build on Yeh et al. (2020)\u2019s argument on concept completeness and propose to use two metrics: detection (concept) completeness and concept separability. Following such metrics, the authors then design an algorithm for learning such desired concept-based explanations. ",
            "strength_and_weaknesses": "Strength \n\n+ The paper is very well written and well organized. It is a good read. \n\n+ Providing concept-based explanations to OOD detector is an interesting topic. \n\nWeaknesses\n\n- The notion of detection completeness is not entirely new. As shown in Definition 1 and 2, it builds on the classification completeness in Yeh et al. (2020). \n\n- The proposed method has a limited scope in that it only focuses on explaining OOD detector. \n\n- There are no direct comparisons between the proposed method and Yeh et al., which this paper heavily builds upon. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper builds heavily on Yeh et al. (2020) which is also related to concept-based explanation of neural networks with emphasis on the completeness desideratum, which is one of the two proposed metrics in this paper.  Specifically, the only difference between the original classification completeness of Yeh et al. and the paper is to replace the classification accuracy with an AUC score. The formulations on the concept space as well as the SHAP related evaluation also follow closely Yeh et al. \n\nOne key difference from Yeh et al. is the definition of concept separability score. The authors augment the regularization term from Yeh et al. with two other regularization terms $J_{norm}$ and $J_{mse}$, along with the LDA objective to encourage separability. Such a design makes sense to me, though compared to the original Yeh et al., the technical contribution tends to be limited. \n\nWhile this paper focuses on OOD detection, I wonder if it would could also improve results in the simple classification case. The authors claim that Yeh et al. has potential issues in terms of reconstructing the features and may lead to degradation in performance. It would therefore be interesting to see if this is true. \n\nThe SHAP-based evaluation seems to also follow directly Yeh et al. While the novelty is limited, it is nice to see that the proposed method works well in combination with SHAP. \n\nThe definition of patch and receptive field is a bit vague. Why do you call it a $a_l \\times b_l$ patch? Do you feed patches into a network rather than the whole image? \n",
            "summary_of_the_review": "This paper tackles the problem of concept-based explanations for deep neural network OOD detectors. The authors build heavily on Yeh et al. (2020), with the key differences that (1) they introduce an additional metric, i.e., concept separability, (2) instead of focusing on classification, they focus on OOD detection. Other aspects of the paper including the completeness scores and SHAP-based evaluation are very similar to Yeh et al. Given the limited technical merit, I would place this paper marginally below the threshold. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4789/Reviewer_H68v"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4789/Reviewer_H68v"
        ]
    },
    {
        "id": "c1SV3IZfUw",
        "original": null,
        "number": 2,
        "cdate": 1666701096437,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666701096437,
        "tmdate": 1666701096437,
        "tddate": null,
        "forum": "9rRhMKNOkeT",
        "replyto": "9rRhMKNOkeT",
        "invitation": "ICLR.cc/2023/Conference/Paper4789/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes concept-based learning and an explanation for OoD Detection. The authors propose metrics to capture detection completeness and separability, which are used for the learning process. The evaluation of multiple datasets demonstrates the potential usefulness of the proposed techniques for OoD explanation.",
            "strength_and_weaknesses": "Strength:\n\n- Important topic and work on OoD detection explanations\n- Proposed techniques are general and could be applicable to various contexts, without the whitebox requirement\n- Feasible solution with promising results\n\nWeakness:\n\n- Unclear about the robustness of the learned \u201cconcepts\u201d\n- Not very clear how to design the concept space or concept learning architecture\n- Although High level and simple concept explanations are possible, it is not clear how such explanations could be helpful to guide the OoD detection developers in an actionable and constructive way.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is mostly well-organized and written. The concept-based explanation also has its novelty on the OoD detection contexts, authors also make certain technical contributions to adapt concept-based explanations to the OoD contexts, which should be sound and feasible. \n\nThe evaluation also mostly supports the authors\u2019 claims.",
            "summary_of_the_review": "Overall, I like the idea of this paper and think it works on an important problem, which does not receive enough attention previously. This paper makes an early step in explaining OoD detectors in relatively general settings without the requirement of white box. However, I still have a few concerns posted in the weakness part, that hope the authors could address during the rebuttal phase and add relevant discussion in the next version.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4789/Reviewer_v8DY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4789/Reviewer_v8DY"
        ]
    },
    {
        "id": "gvtV7yaJM87",
        "original": null,
        "number": 3,
        "cdate": 1666885509923,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666885509923,
        "tmdate": 1666885509923,
        "tddate": null,
        "forum": "9rRhMKNOkeT",
        "replyto": "9rRhMKNOkeT",
        "invitation": "ICLR.cc/2023/Conference/Paper4789/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a method to interpret out-of-distribution detection using learnt high-level concepts.",
            "strength_and_weaknesses": "Strengths\n- To my knowledge, this is the first work to study the notion of concept-based explanations for OOD detection.\n- The idea of LDA on the concept layer is clever and simple.\n- The proposed metrics are easy to understand. Detection completeness and concept separability naturally follow.\n\nWeaknesses\n- I would have expected more examples of what a concept-based explanation for an OOD detector means. Figure 1 is unconvincing. Please provide more qualitative evidence of the utility of concept-based explanations in the OOD setting.\n- While the authors acknowledge the lack of a human subject experiment, it is not clear from the prose alone if concept-based explanations are even necessary (let alone helpful) for OOD detectors. I, among others, am unsure why concepts for OOD detectors. How does it help? A carefully designed user study would right this. It would also warrant a method that would lead to higher adoption and impact down the line.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper could be more clear as to why concepts for OOD detectors are sensible. \nNovelty: The idea depends heavily on existing concept-based explanation work, carefully applied to the OOD setting.\nQuality: The evaluation is adequate.\nReproducibility: Adequate.",
            "summary_of_the_review": "The paper poses an interesting question of how to use concepts to generate explanations from OOD detectors. While the evaluation and idea is adequate, it is hard for me to recommend accept without a convincing user study or extensive qualitative examples of why such an explanation makes sense. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4789/Reviewer_qdMm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4789/Reviewer_qdMm"
        ]
    },
    {
        "id": "L7O5Z3dKfOL",
        "original": null,
        "number": 4,
        "cdate": 1666977694301,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666977694301,
        "tmdate": 1666977694301,
        "tddate": null,
        "forum": "9rRhMKNOkeT",
        "replyto": "9rRhMKNOkeT",
        "invitation": "ICLR.cc/2023/Conference/Paper4789/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper addresses the problem of explaining the decisions of an out-of-distribution (OOD) detector by using concept-based representations. In order to learn concept-based explanation, the authors propose two measures, namely the concept detection completeness and the concept separability, which they optimize during training of OOD detectors.  ",
            "strength_and_weaknesses": "__Strenghts__\n- the problem addressed is relevant, and ground motivations for the research are discussed\n- the paper is well written and carefully constructed, easy-to-follow and clear\n- the new metrics are technically sound\n- experiments in combination with existing methods\n\n__Weaknesses__\n- In my opinion, the main concern/weakness is in the way the authors analyse and interpret the results: the authors stress the fact that existingmethods are not able to guarantee concept separability and detection completeness, which are metrics that they define in this work. On the contrary, the method based on learning concepts by optimizing these metrics is performing better. There is no surprise in these results, as previous methods are not optimized for the considered metrics. Thus, it seems to me that the experimentations (in the way it is presented) is unfair. \n\n- Another weakness is in the lack of details about the deployement of their approach within existing approaches: it seems a concept-based learning component (optimized with the proposed metrics) is deployed within intermediate layers, but no details about the 'where' in the network (which layer) it is used, and how it may change if deployed in different parts. \n\n- Connected to above, if this can be deployed in different parts of the network, I imagine that different concepts are learned, of different semantics. How does it relate with the 'high-level' concepts that the authors aim at learning? Also, how the 'high-level' is defined?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear, stating the addressed problem and the relation with existing works well. The conclusion section is not really reporting conclusions, but rather discussing limitations and societal impact of the work, leaving the reader pending final and concise answers to the posedresearch questions.\n\nThe quality of the paper and the research itself, including the novelty, is high, which inclines my evaluation towards the positive side. However, the experimental analysis and observations made with respect to existing works are unfair (see above). The authors should have focused on better highlighting the usefulness of the proposed concept-world and canonical-world representations, and the validation of the proposed metrics.\n\nThe work lacks reproducibility: I did not find mentions that the code will be available, neither details about the layers in between the proposed appraoch is deployed, and what effects this might have on the learned concepts and the overall explainability of the OOD detections. In its current form, the paper makes difficult to re-implement or even deploy the proposed approach to replicate the experiments.",
            "summary_of_the_review": "The paper presents a novel idea, which is presented highlighting its relevance. The research is motivated and carefully constructed. The experimental analysis, although with several existing methods and on relevant datasets, brings to unfair statements in comparison with other methods, and lacks addressing strongly the validity of the proposed measures. Also, a more thorough analysis of the learned concepts should be provided: how are they relevant and what do they cover?\nOverall is a good work, but I would like to see the response of the authors to my questions and doubts.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4789/Reviewer_YcEH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4789/Reviewer_YcEH"
        ]
    }
]