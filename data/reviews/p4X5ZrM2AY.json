[
    {
        "id": "RYJe1rms3t",
        "original": null,
        "number": 1,
        "cdate": 1666169847096,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666169847096,
        "tmdate": 1668762829149,
        "tddate": null,
        "forum": "p4X5ZrM2AY",
        "replyto": "p4X5ZrM2AY",
        "invitation": "ICLR.cc/2023/Conference/Paper5304/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes to investigate the empirical performances of neural contextual bandit algorithms. LinUCB is used as a baseline. The algorithms are tested on four type of problems: UCI classification dataset, MSLR-Web10K dataset, Japanese fashion dataset, and Yahoo front page dataset.\nThe conclusion of the paper is that in comparison to LinUCB, neural contextual bandit algorithms can capture nonlinear information.\n",
            "strength_and_weaknesses": "The empirical evaluation is made on several datasets. However, the authors spend 5 pages for describing the state-of-the-art, and that is a lot for a nine pages paper. Moreover, some of the described algorithms have pseudo-regret upper bounds, but they are not given. In the case of bandit algorithms, it is however a strong argument since they are often used in \u201ccold start\u201d.\nFinally, despite the fact that they are nonlinear contextual bandit algorithms, and some of them are cited (Kernel UCB, Generalized linear bandit), they are not tested. It is a pity, knowing that the main conclusion of the paper is that neural contextual bandit algorithms can capture nonlinear information.\n\nSome missed references:\nEfficient Bandit Algorithms for Online Multiclass Prediction, ICML 2008 (Banditron is the first attempt to use neural networks in contextual bandit problem)\nEfficient optimal learning for contextual bandits, UAI 2011 (oracle based contextual bandit)\nA Neural Networks Committee for the Contextual Bandit Problem, ICONIP 2014 (first attempt to use neural networks in contextual bandit problem that practically works).\nRandom Forest for the Contextual Bandit Problem, AISTATS 2016 (contextual bandit based on a non-linear model).\nTaming the Monster: A Fast and Simple Algorithm for Contextual Bandits, ICML 2014 (oracle based contextual bandit)\n\nMinor comment:\nDeep neural networks are not recent (page 1).\n",
            "clarity,_quality,_novelty_and_reproducibility": "While the authors spend a lot of time to describe the literature, the experiments are insufficiently described.\n\nIn Learning to rank, Japanese fashion and Yahoo datasets, the number of arms is not provided to the reader. Moreover, some of the tested problems seem particular. For instance variable number of arms in Learning to rank or Japanese fashion (the reviewer does not understand at all this experiment), combinatorial number of arms in Yahoo dataset (20 arms chosen from ?).\nThe authors should accurately describe each experiment, and how they have adapted each algorithm to each problem. For instance UCI datasets corresponds to contextual bandits with the observation of a single context at each time step, while Japanese Fashion dataset look likes to a structured bandit problem (a context per arm), while Yahoo dataset seems to be an hybrid problem (a context per arm and a general context at each time step).\nIn figure 5, why is cumulative relative CTR decreasing? \nWhy is the number of hidden units not the same for all experiments? How are they chosen?\nFinally, it lacks a metric (for instance ranking of algorithms) and a statistical test to sum up the results.\n",
            "summary_of_the_review": "Rather than spending 5 pages to describe state-of-the-art, the author should accurately describe their experiments.\n________________________________________________________________________________________________________\nI thank the authors for their answers. \nI raised my score, but I do not vote for acceptance. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5304/Reviewer_22TM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5304/Reviewer_22TM"
        ]
    },
    {
        "id": "jh25yZ8NQV0",
        "original": null,
        "number": 2,
        "cdate": 1666292817012,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666292817012,
        "tmdate": 1666292817012,
        "tddate": null,
        "forum": "p4X5ZrM2AY",
        "replyto": "p4X5ZrM2AY",
        "invitation": "ICLR.cc/2023/Conference/Paper5304/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposed a empirical evaluation of neural contextual bandits algorithms. ",
            "strength_and_weaknesses": "I feel this paper is better suitable for a workshop paper rather than a full conference paper. This paper didn't provide any new algorithm / theory / dataset. The large body of approximate Thompson sampling algorithms (\"Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling\") are not compared. \n\nThe main criticism of neural contextual bandits algorithm is the mismatch between algorithm and theory. I feel experiments should carefully check if the assumption of NTK is not satisfied, will the algorithm still work?",
            "clarity,_quality,_novelty_and_reproducibility": "not reproducible. no code.",
            "summary_of_the_review": "An nice empirical evaluation but no new message.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5304/Reviewer_Zjj4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5304/Reviewer_Zjj4"
        ]
    },
    {
        "id": "4igYU9ehtGC",
        "original": null,
        "number": 3,
        "cdate": 1666474409456,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666474409456,
        "tmdate": 1666474409456,
        "tddate": null,
        "forum": "p4X5ZrM2AY",
        "replyto": "p4X5ZrM2AY",
        "invitation": "ICLR.cc/2023/Conference/Paper5304/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Authors compare multiple neural contextual bandit algorithms on multiple data sets along with non-neural baselines.",
            "strength_and_weaknesses": "Strength: \n  * This type of empirical investigation is important and undersupplied in the literature.  \n\nWeakness:\n  * Empirical evidence is conditional, so to draw broad conclusions, a massive number of datasets need to be used, e.g. Bietti et al [1] consider more than 500.\n\n> The neural bandit algorithms might fail if the number of data is insufficient, like the datasets from UCI machine learning, or the context feature is too simple to provide enough knowledge to learn.\n\nThe beautiful thing about using many datasets is you can do meta-data analysis, so instead of just saying something like this, you can quantify it (e.g., what properties of datasets allow one to predict which algo is best?)\n\n[1] https://arxiv.org/abs/1802.04064",
            "clarity,_quality,_novelty_and_reproducibility": "Quality issues described above.\n\nThe exposition is clear.  If you scale up the number of datasets, you will have to elide details to appendices.  Furthermore you will have to take a uniform approach to dataset processing.\n\nFor reproducibility, you should provide a link to a public repository with scripts that, when invoked, do *everything*: 1) downloading data sets, 2) downloading code dependencies, etc. leading to 3) producing any graph that appears in the paper.  Empirical evidence is conditional and therefore transparent reproducibility is priority numero uno. ",
            "summary_of_the_review": "Quite simply, if you can increase the number of datasets used to at least 100, I would accept.  Also great would be to quantify claims about when algo FOO is best with meta-data analysis.\n\nIf the response is something like:\n  * it would take too long to run the algorithms on a large number of datasets ... well ... that's important to know!\n  * there's no single architecture that works well on all the datasets ... well ... that's important to know!\n\nI strongly encourage the authors to continue this line of work, as previously stated, it is undersupplied in the literature.  However, you need to up your game: empirical papers require more comprehensive effort.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5304/Reviewer_sUDB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5304/Reviewer_sUDB"
        ]
    },
    {
        "id": "PbXxamkKfDq",
        "original": null,
        "number": 4,
        "cdate": 1666577562152,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666577562152,
        "tmdate": 1670806995818,
        "tddate": null,
        "forum": "p4X5ZrM2AY",
        "replyto": "p4X5ZrM2AY",
        "invitation": "ICLR.cc/2023/Conference/Paper5304/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper provides an empirical study of the neural bandit algorithms, which are the type of bandit algorithms that combine the benefit of deep neural networks, along with the simplicity of the classical linear bandit algorithms. It chooses the linear model: LinUCB as the reference algorithm, and studies how the recently proposed neural bandit models, i.e., NeuralLinear, NeuralLinear-LikelihoodMatching, NeuralUCB , Neural-LinUCB, NeuralTS, and NPR compares with the reference, under different datasets. \n",
            "strength_and_weaknesses": "Strength:\n\n- Neural Bandits are popular bandit algorithms these days, with the representation power from deep models. These paper studies an important aspect, i.e., how different algorithms perform under various environments, which should be relevant to the community.\n\n- The paper is easy to read and follow.\n\n- I like the Section 2.3, which seems to provide a nice overview/summary of different neural bandit algorithms. \n\nWeakness:\n\n- I appreciate the authors' efforts on performing the experiments on various datasets, to verify the pros and cons of different algorithms. However, at least for me, Section 3 is not informative. The current structure seems like the following: introduce different datasets first, followed by the setup, finally summarized the results from the figures. The results seem only contain some facts without any analysis/reasoning about why certain algorithms perform well under this setting, even say hypothesis. It then would be very hard for the readers to learn from this paper. \n\n- There are actually lots of interesting aspects from the figures, but are not pointed out/analyzed by the authors. For example, it is kind of well-known TS performs better than UCB empirically. However, from Fig.2 and Fig.3, it seems not the case if we use the representation learned by neural networks as the contextual features. It would be great if the authors could digest and summarize the results in a deeper way, that would also increase the impact of the paper.\n\n- Though the number of datasets seems sufficient, I feel the scenarios it covers is limited. For example, it would be interesting to see the case, when the number of arms is large, this is pretty relevant for practical scenarios such as recommender systems. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n\n-[pro] I found the Section 1 and 2 of the paper is easy to read and follow. I do like the overview of the methods.\n-[con] The experiments section needs to re-organized. Instead of structuring based on the datasets, it would be beneficial to re-organized based on the problem instance, or the structure of the environment. \n\nQuality/Novelty:\n\nThe paper does put some efforts in performing various experiments, but I feel it does not do a good job in analyzing and summarizing the results, which make the paper seems have very few takeaways, and little novelty. \n\nReproducibility:\n\nThe variance is reported, while the code is not attached. ",
            "summary_of_the_review": "This paper studies an important topic, i.e., the empirical performance of various neural bandit algorithms. Extensive experiments are done, but the empirical results are not well-analyzed and summarized, which makes the empirical results very hard to digest. As this is a pure empirical paper, this aspect discounts the paper's impact a lot. \n\n-------------- After Rebuttal -------------\nIt seems my concerns are not addressed, so i will keep my score. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5304/Reviewer_qgBu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5304/Reviewer_qgBu"
        ]
    }
]