[
    {
        "id": "pgxNkWrO0J",
        "original": null,
        "number": 1,
        "cdate": 1666413483149,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666413483149,
        "tmdate": 1666413483149,
        "tddate": null,
        "forum": "FwlV6h4KxVE",
        "replyto": "FwlV6h4KxVE",
        "invitation": "ICLR.cc/2023/Conference/Paper2241/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Hi, I'm currently on a medical leave and won't be able to perform ICRL review duties. sorry for the late notice.",
            "strength_and_weaknesses": "Hi, I'm currently on a medical leave and won't be able to perform ICRL review duties. sorry for the late notice.",
            "clarity,_quality,_novelty_and_reproducibility": "Hi, I'm currently on a medical leave and won't be able to perform ICRL review duties. sorry for the late notice.",
            "summary_of_the_review": "Hi, I'm currently on a medical leave and won't be able to perform ICRL review duties. sorry for the late notice.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2241/Reviewer_tuFF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2241/Reviewer_tuFF"
        ]
    },
    {
        "id": "pEI3a781YiW",
        "original": null,
        "number": 2,
        "cdate": 1666619820518,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666619820518,
        "tmdate": 1666619820518,
        "tddate": null,
        "forum": "FwlV6h4KxVE",
        "replyto": "FwlV6h4KxVE",
        "invitation": "ICLR.cc/2023/Conference/Paper2241/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper tackles the task of domain shift in Visual Document Understanding (VDU) involving entity recognition, key-value extraction, and document visual question answering. DocTTA (document test time adaption) method is introduced which takes a pre-trained model from the source domain and adapts it to the target domain using self-supervised learning (masked visual language modeling and pseudo labelling).\n",
            "strength_and_weaknesses": "Strength:\n- The paper is well-motivated and clearly written in most parts. This is an interesting problem with the proposed approach very relevant to the community. \n- The authors promise the availability of corresponding code and a detailed description of hyperparameters which would be essential for reproducibility if open-sourced. \n- Ablation study on domain adaptation (Table 3) for different components of the system is interesting with pseudo labelling playing an important role. \n\nWeakness:\n\n- Some model-generated examples would provide more insight. \n- Human evaluation is not provided. \n- Even though the results are promising at the initial level, there is a huge performance difference compared to the models which are trained on target data (Table 1 and Table 2). In Table 2, the ANLS score is approx half compared to the train-on-target models.   \n- It would help to clarify what kind of OCR techniques were used (industrial like GCS or open-sourced models). How would the results compare when different grades of OCR models are used? An ablation study in this regard could definitely help. \n- It seems the relevant baselines haven\u2019t been used where the DANN and BN are works from 2015 and this field has evolved a lot in recent years. \n\n\nQuestions:\n- Could the authors explain how the results compare with zero-shot models? Is the source-only model used in zero-shot settings in Tables 1 and 2? If yes, it would help to clarify that in the text. \n- In continuation of the point above, when it is mentioned on Page 5, that the closed-set assumption is used, how would the zero-shot model with no assumption like this compare to the proposed approach?  \n- Could the authors clarify what ECE means on Page 6?\n\n\nSuggestions/Comments:\n- It would help to explain DocTTA right at the beginning in the abstract itself so that the reader knows what to expect in the rest of the paper and not just Section 3.  \n- It is unclear where Train-on-target used the same model architecture (LayoutLMv2BASE) as the source-only and DocUDA/DocTTA methods. It would help to clarify this in the text.  \n- An example (maybe pictorial) of the layout XB (6-dimension vector) on Page 5 could definitely help articulate the method. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Please see strengths and weaknesses for more details. Availability of promised corresponding code would ideally make the work reproducible. The paper is written clearly in most parts while the proposed idea is original.  ",
            "summary_of_the_review": "The proposed idea is well motivated and novel and the experiments show promising directions. However, the paper could be tweaked a bit to provide more detailed descriptions. Please see strengths, weaknesses, suggestions and comments.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2241/Reviewer_F7R6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2241/Reviewer_F7R6"
        ]
    },
    {
        "id": "U7rS4W1hzXi",
        "original": null,
        "number": 3,
        "cdate": 1666625882013,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666625882013,
        "tmdate": 1666625939807,
        "tddate": null,
        "forum": "FwlV6h4KxVE",
        "replyto": "FwlV6h4KxVE",
        "invitation": "ICLR.cc/2023/Conference/Paper2241/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a framework for performing test time adaptation of a model trained in a source domain to a target domain, without use or labeled data in the target domain. The main contribution of the paper is applying this framework to a model for document image representation, leveraging standard masked langage modeling (traditionally used in to learn models for document representation) with a pseudo-labelling selection strategy. To evaluate this new setting in document understanding, new datasets are created by splitting standard document datasets into a source and a target domain. Experiments are performed on these proposed datasets, comparing the proposed method with state-of-the-art domain adaptation and test-time adaptation approaches.\n",
            "strength_and_weaknesses": "Strengths\n- The paper addresses a setting which has not much explored in document understanding, transfering a model learned in a source domain to a target domain. This is a relevant problem in document understanding due to privacy issues or difficulty in getting annotation for new documents.\n- The proposed framework takes advantage of the specificity of document understanding integrating a masked language modeling task in addition to the generation and selectoin of pseudo-labels.\n- A new set of datasets specific to the task of test-time adaptation are created and released\n- Experiments show that the proposed method help to signifficantly improve the results in the target domain in all cases and that all components of the framework contribute to this improvement.\n\nWeaknesses\n- Apart from integrating masked language modelling, the difference of the proposed framework with previous TTA methods is not clear. The difference and contribution with respect to other methods to generate and select pseudo labels should be made more explicit, specially in relation to reference (Rizve et al. 2021). It seems that the contribution of the paper lies mainly on integrating documen specific MVLM.\n- The comparison with other methods in the state-of-the-art does not help to evaluate the actual contribution of the proposed method. It is not clear whether better results are due only to the MVLM strategy, to a better selection of pseudo labels, or to a combination of both. I understand that the proposed MVLM strategy could be integrated with most of the existing methods for TTA. Then, it would be more insightful either performing the comparison by also integrating MVLM into these existing methods or evaluating the proposed method without it, in order to decouple the effect of both strategies. Actually, results in tables 2 and 3 seem to show that DocTTA without the specific MVLM would perform worse thant SoA TTA methods\n- The dataset split between source and target domains seem, in some of the cases a bit arbitrary and not very realistic. The motivation behind such splits is not well motivated. Why is it appropriate to split FUNSD by text density and SROIE by blur and other artifacts. Why creating new categories in DocVQA that do not correspond to document types? In addition, details on how these splits were created are not provided. Were they created manually or automatically? Which criteria were used to filter or annotate documents in each split? Is there already any difference on the performance of the original full model on each of the splits?\n- The splits in the target domain do not contain training, validation and test sets. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and well written. The novelty of the paper is not clear specially with respect to existing TTA methods. Main novelty could be in integrating the specific MVLM for the case of TTA in documents. Code will be released upon publication for reproducibility. ",
            "summary_of_the_review": "The paper proposes an adaptation of TTA methods to the case of document understanding, where this issue has not been much explored. The proposed method seems to rely on standard tecniques for TTA and integrating the specific MVLM objective when retraining the model in the target domain. In this sense, novelty and signifficance of contribution seems limited. The rationale behind the splits for each dataset is not well motivated and comparison with SoA should take into account somehow the effect of specific MVLM task. Overall, I consider that it is not clear the contribution of the paper both methodologically and experimentally.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2241/Reviewer_eUpw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2241/Reviewer_eUpw"
        ]
    }
]