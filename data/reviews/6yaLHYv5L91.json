[
    {
        "id": "-60ul_EBFcg",
        "original": null,
        "number": 1,
        "cdate": 1666338200710,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666338200710,
        "tmdate": 1666338200710,
        "tddate": null,
        "forum": "6yaLHYv5L91",
        "replyto": "6yaLHYv5L91",
        "invitation": "ICLR.cc/2023/Conference/Paper5130/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper studies the use of various data augmentation in boosting the attack transferability of adversarial examples. Overall, the paper is clear and the experimental results and analysis support the claim.",
            "strength_and_weaknesses": "__Strength__\n\n__[S1]__ The paper is easy to follow.\n\n__[S2]__ The method is simple, practical and effective.\n\n__Weakness__\n\n__[W1] Lack of novelty.__ The paper studies the use of data augmentation in improving the attack transferability of adversarial examples. Apparently, all the data augmentation schemes are based on established works. There are no new theories or methods about data augmentation and attack transferability are introduced.\n\n__[W2] Lack of comparison with related works.__ The paper should discuss and compare the method with existing works, e.g. [Huang et al., 2019], [Wang et al., 2021], [Wu et al., 2021].\n\n__[W2] Insufficient experiments.__ The study is only conducted on the ImageNet-compatible dataset using MI-FGSM on Inception- and ResNet-based models. It is unknown if the findings will be the same on other datasets (e.g. CIFAR-100), attack methods (e.g. I-FGSM) and architectures (e.g. VGG).\n\n__Ref.__\n\n[Huang et al., 2019]: Enhancing Adversarial Example Transferability with an Intermediate Level Attack.\n\n[Wang et al., 2021]: Enhancing the Transferability of Adversarial Attacks through Variance Tuning.\n\n[Wu et al., 2021]: Improving the Transferability of Adversarial Samples with Adversarial Transformations.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is easy to follow. The analysis is sound and reasonable. However, a large part of the study is based on established work (see W1). Also, the paper does not compare or discuss their method with existing works (see W2).",
            "summary_of_the_review": "Overall, this paper proposes a simple way to combine different data augmentation methods to improve the attack transferability of adversarial samples. Due to the lack of novelty and comparison with related works, I tend to vote for rejecting the submission.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5130/Reviewer_fNhP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5130/Reviewer_fNhP"
        ]
    },
    {
        "id": "5eobjCNl6Fv",
        "original": null,
        "number": 2,
        "cdate": 1666597967395,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666597967395,
        "tmdate": 1666597967395,
        "tddate": null,
        "forum": "6yaLHYv5L91",
        "replyto": "6yaLHYv5L91",
        "invitation": "ICLR.cc/2023/Conference/Paper5130/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes to enhance the transferability of adversarial examples by doing adversarial attacks using multiple data augmentation parallelly. ",
            "strength_and_weaknesses": "Pros:\n\n1. The paper study a novel problem of how data augmentation affects adversarial attacks' effectiveness. \n\n2. The work considers multiple model architectures to test its proposed method. \n\nCons:\n\n1. Lack of clarity\n- 1(a) Section 3.3. The author says \u201cIn parallel composition, augmentation methods are applied independently on the input, and their outputs are aggregated (i.e., taking their union)\u201d. I cannot understand, what means by \"their outputs are aggregated (i.e., taking their union)\". Do you feed the model with the union of augmented images? Or randomly choose one augmentation to apply?\n- 1(b) Section 5.1. The section title says \"COLOR-SPACE AUGMENTATIONS OUTPERFORM THE STATE OF THE A RT\". This title does not match the argument in this paragraph. What this paragraph says is actually, composing COLOR-SPACE AUGMENTATIONS with the SOTA method (DST) is better than the SOTA (DST-MI-FGSM)\n- 1(c) Section 5.2. The author says \"The results reflected a mostly monotonic relationship between transferability and augmentations.\" But the results seem to be not displayed in this paper. \n- 1(d) Section 5.4 The author says \"As can be seen from Table 5, the methods least conducive for transferability (NeuTrans and Sharp) ...\" I do not find any evidence saying that NeuTrans and Sharp have the least transferability. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper has a fair novelty in its method. However, the paper has a pool of clarity that prevents the reader from fully understanding the proposed method and appreciating this work. ",
            "summary_of_the_review": "Based on the pool clarity, I am afraid that the current submission does not reach the bar of acceptance. If the clarity is improved in the rebuttal, I will consider re-evaluating this manuscript. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5130/Reviewer_T7Qz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5130/Reviewer_T7Qz"
        ]
    },
    {
        "id": "Hdf8CFLeKpY",
        "original": null,
        "number": 3,
        "cdate": 1666930163463,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666930163463,
        "tmdate": 1669617509867,
        "tddate": null,
        "forum": "6yaLHYv5L91",
        "replyto": "6yaLHYv5L91",
        "invitation": "ICLR.cc/2023/Conference/Paper5130/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this work, the authors study in detail the effect of a diverse set of data-augmentation techniques on the transferability of adversarial attacks in the black-box setting. The paper presents a large systematized empirical study of the effect of adversarial transferability with the use of augmentations such as Color Jitter, Fancy Principle Component Analysis, Channel shuffle, Greyscale, random erasing, sharpening, CutMix, neural transfer and AutoAugment. In particular, the paper finds that the composition of several such augmentations generally yields increased transferability.",
            "strength_and_weaknesses": "Strengths:\n1) The paper clearly motivates the study of augmentation to boost adversarial transferability, and covers contributions of past works in a clear, concise manner which helps place the findings uncovered in a systematic framework.\n2) The paper presents a fairly detailed set of empirical evaluations on a wide range of deep networks with different architectures, on a 430-class subset of ImageNet with 1000 images that is commonly used to assess adversarial transferability. The inclusion of both normally trained and adversarially trained models in the evaluations helps establish the results in a detailed manner.\n3) The proposed combination of augmentations is largely seen to outperform the current state of the art, which largely serves as a baseline, especially considering that DST-MI-FGSM is a subset of the final augmentations utilized.\n\n\n\nWeaknesses:\n1) With the large number of possible augmentations available, the paper primarily focuses on the parallel composition of augmentations, as opposed to the serial case as done in prior works (eg. as in DST-MI-FGSM). However, given that this is a key aspect of the paper, more details could have been provided in Section-3.3 to better understand the associated pros and cons. \n2) For example, it appears that parallel augmentations apriori require additional forward and backward passes as opposed to serial composition. Could the authors kindly clarify if the parameter of interest \u201cm\u201d in Algorithm1 is kept constant for the proposed approach as compared to prior works? Or is the sampling over the distribution D done independently for different augmentations in the parallel-composition setting?\n3) Furthermore, given that the prior methods such as DST-MI-FGSM are subsumed by the proposed approach, a more thorough complexity analysis needs to be included. Thus, the running time required for generating the attacks using UltimateCombo could be reported for a subset of the models considered.\n4) While the empirical results presented are indeed interesting, the paper could have possibly devoted more attention to analyzing why such compositions are more effective. For example, a slightly more detailed discussion as currently provided in Section-5.4 could have been included with respect to cosine similarity of gradients post parallel-composition, and the direction towards mitigating the effect of overfitting during the use of a single surrogate model as compared to an ensemble.\n5) While the majority of the results are presented on the ImageNet subset, additional evaluations over other standard datasets such as CIFAR-10 or CIFAR-100 could be included, given that it has served as a benchmark for adversarial defense research for the past few years (though some prior works on adversarial transferability exclude these as well). This could also potentially help weed out results that are overly-specific to the case of ImageNet based images, and help generate a better understanding towards the compositional nature of augmentations.\n\n\nMinor Typos-\n Page3: \u201c set of these defense.\u201d -> \u201d set of these defenses.\u201d\nPage5: \u201cThe main difference from e is that\u201d -> \u201cThe main difference from RE is that\u201d\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper overall is well-written and presents most of the matter in a clear, concise manner. While the key contributions are an extension of prior works, the empirical evaluations presented are fairly thorough. ",
            "summary_of_the_review": "The paper presents a systematic study regarding the composition of augmentations to boost adversarial transferability. Indeed, it finds a performative subset such that enhanced transferability is observed over prior state-of-the-art approaches, which are largely subsumed by the proposed composition. However, as mentioned in the weaknesses section, more details could be provided to clarify key aspects of the proposed approach, alongside complexity comparisons to prior approaches. I would be willing to raise my score further if these points could be addressed in detail.\n\n\nPost-Rebuttal Update:\nA note has been added titled \"Post-Rebuttal Comments and Modification to Recommendation\" in the thread below. I would like to update my score to be \u201c3: reject, not good enough\".\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5130/Reviewer_KVr6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5130/Reviewer_KVr6"
        ]
    },
    {
        "id": "R9J1H94EFN",
        "original": null,
        "number": 4,
        "cdate": 1667243111452,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667243111452,
        "tmdate": 1667243111452,
        "tddate": null,
        "forum": "6yaLHYv5L91",
        "replyto": "6yaLHYv5L91",
        "invitation": "ICLR.cc/2023/Conference/Paper5130/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Driven by the success of data augmentation in improving the transferability of adversarial samples, this paper conducts an empirical investigation about the best combination of different data augmentations towards boosting the adversarial transferability. Experiments across ten data augmentations lead to a new composition that outperforms previous data augmentation methods.",
            "strength_and_weaknesses": "**Strength**\n\n1. An empirical investigation about the combination of the best practices in data augmentations for boosting adversarial transferability can provide useful insights for the community.\n\n**Weakness**\n\n1. The novelty of this paper is very limited. It manually combines existing data augmentations to generate a better augmentation strategy without providing theoretical analysis or an automatic solution, which is more like a technical report. The technical contributions cannot match the bar of ICLR.\n\n2. The paper wastes too much contents on background knowledge about adversarial attacks and data augmentations, and starts to introduce the experimental results, which are the major contributions of this paper, from the 6th page. The presentation style can be better organized.\n\n3. The experimental results are not solid enough. Only one dataset with 1000 images is considered, while the datasets like CIFAR-10/100/SVHN/ImageNet, which are commonly adopted in the literature, are not included. In addition, only one perturbation strength (16/255) is considered. It is highly desired to conduct experiments across different datasets, perturbation strengths, and defensive methods, otherwise the accuracy gap between the proposed methods and baselines in Table 1/2 may be overturned via tuning the hyperparameters of adversarial example generation.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper wastes too much contents on backgrounds, which hurts the presentation clarity, and the novelty is very limited. The reproducibility is good as the codes are provided via an anonymous link.",
            "summary_of_the_review": "Considering the limited novelty and the lack of necessary experiments as elaborated in the weakness section, I tend to reject this paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5130/Reviewer_DKMA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5130/Reviewer_DKMA"
        ]
    }
]