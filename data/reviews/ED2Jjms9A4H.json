[
    {
        "id": "LjOCA5VQ0H",
        "original": null,
        "number": 1,
        "cdate": 1666593259727,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666593259727,
        "tmdate": 1666593259727,
        "tddate": null,
        "forum": "ED2Jjms9A4H",
        "replyto": "ED2Jjms9A4H",
        "invitation": "ICLR.cc/2023/Conference/Paper3/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work presents a framework for efficient exploration based on the idea of fragmentation and recall. An agent exploring an environment maintains a local map/model in its short-term memory (STM). At each time step, the agent can compute how well the current observation and the model's prediction of it match. If there is a high mismatch or surprise, a *fragmentation* event occurs, where the agent saves the current local model into a long-term memory (LTM) and initiates a new model. The locations where fragmentation occur are known as fracture points. At such fracture points, the agent is able to *recall* previously stored models, corresponding to overlapping fragments or local models, from its LTM and use these to guide further exploration. \n\nThis framework is applied to (i) spatial exploration (FarMap) in 2D grid world type environments , and (ii) curiosity-driven RL (FarCuriosity) in Atari games. In both these settings, the experimental results demonstrate that the fragmentation and recall approach performs better than the respective baselines. ",
            "strength_and_weaknesses": "This work is a proof-of-concept for the fragmentation and recall approach to efficient exploration.\nThe empirical results presented here demonstrate the advantage of this approach. In the spatial exploration task, FarMap achieves comparable map coverage as an improved Frontier-based exploration baseline, but faster and at a substantially lower memory cost. In the RL setting, FarCuriosity obtains higher extrinsic reward than Random Network Distillation (RND) in Atari games with heterogenous environments. \n\nWhile the initial results presented here are promising, it is not clear how this approach would scale to more complex settings. For instance, in the FarMap setting, the local observation is a top-down view of the environment and has the same structure as the local predictive spatial map.  If the input observation stream is an egocentric view from a 3-D environment, how would it be handled? \n\nIt is not clear how the size of the local predictive map $(H, W)$ grows. Also, it is not clear how the observation $o_t$ is transformed to $o_t^{\\prime}$. It looks like the size of the current map and the agent's position need to be tracked for this. However, the agent's position might not always be known/cannot be tracked accurately, e.g., when actions are stochastic/noisy.  \n",
            "clarity,_quality,_novelty_and_reproducibility": "This work presents an interesting approach to efficient exploration and model-building. However, I believe there are aspects of the presentation that can be improved to make this a more engaging read. \n- In figure 2, it is not clear what the observation and its transformed version are. The fact that they are ego-centric top down views with a 120 degrees FOV becomes clear only in Section 4. Also, the shortest-path to the subgoal is a white arrow, and not black as mentioned in the caption. \n- It would also be useful to specify how $o_t$ is transformed to $o_t^{\\prime}$\n- In the FarMap setting, it would be helpful to clearly define terms like cell, visible cell, known cell, occupied cell. Further, is not clear what the action space is. \n- It would also be helpful to concretely describe the connectivity graph, i.e., what the nodes and edges correspond to - fragments, fracture points?\n- For the results in figure 5, how is memory usage computed? \n ",
            "summary_of_the_review": "This work presents an interesting approach to efficient exploration based on the idea of fragmentation and recall. While the initial results are promising, I find the current instantiation of the local predictive spatial map limiting. In addition, I think the presentation could be improved to make this a more engaging paper. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3/Reviewer_m2i7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3/Reviewer_m2i7"
        ]
    },
    {
        "id": "7wMHFmbDSu",
        "original": null,
        "number": 2,
        "cdate": 1666632969073,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666632969073,
        "tmdate": 1669106123271,
        "tddate": null,
        "forum": "ED2Jjms9A4H",
        "replyto": "ED2Jjms9A4H",
        "invitation": "ICLR.cc/2023/Conference/Paper3/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose the utilization of the concept of Fragmentation-and-Recall to solve spatial and reinforcement learning problems. In the former case, which they call FarMap, they address the use case of exploration in sub-map based SLAM and in the latter case, which they call FarCuriosity, the problem of catastrophic forgetting in curiosity-driven RL.\n\nIn both cases, the exploring agent focuses on a sub-part of the map or state-space, constructing a local model of exploration (saved in a Short-Term Memory or STM). Once it encounters a novel (also termed \u201csurprising\u201d) new state (called a fragmentation point in the paper), it either stores the sub-map (local map) explored so far to a Long-Term Memory (LTM) or retrieves a sub-map from LTM that is consistent to the new observation. Finally, further exploration is guided through defining sub-goals for the agent either as new points in the LTM or through selecting previous fragmentation points to be reached.\n\nThe authors provide experimental results for both cases, using procedurally generated maps for the FarMap application and targeted Atari games in the FarCuriosity case, where they highlight the pros and cons of their method compared to baseline algorithms.\n",
            "strength_and_weaknesses": "**Strengths:**\n- The paper is well-written, and the high-quality figures and system schematics really communicate the intuition behind the paper ideas\n- There is extensive and correct use of references, as well as comparison to previous work\n- The idea of fragmentation and recall in curiosity-driven Reinforcement Learning is both novel and useful\n\n**Weaknesses:**\n- In my opinion, the authors are not clearly demonstrating the necessary novelty step over Klukas et al. (2021), with respect to the FarMap application. \n- Also, I find it confusing that two applications (FarMap and FarCuriocity) are described in parallel. Why not focusing on one (maybe the most novel is the FarCuriosity) and provide more evaluation experiments there?\n- Even though the authors provide a sensitivity analysis / ablation study for some of the hyper-parameters of the algorithm, it is not clear how these should be tuned (i.e., what would be their boundaries) in a new application / use case.  \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very well- and clearly written, apart from some points I comment below. In addition, the high-quality schematics and Figures help to convey the message and the main intuition behind the algorithms and the use cases addressed. In addition, I find the FarCuriosity application very interesting and useful for addressing the exploration problem in many reinforcement learning settings and problems.\n\nMy main point of objection is that the authors do not clearly show (in my opinion) how their work is novel in the FarMap case compared to the previous work of Klukas et al. (2021). In the related work section, in the comparison with Submap-Based SLAM approaches they state: \u201cHowever, FarMap divides space based on properties of the space (how predictable the space is based on the local map or model), and does so in an online manner using surprisal\u201d but I fail to see how this idea is so fundamentally different compared to the findings of Klukas et al. (2021) that would justify expanding it in half the paper. Maybe it would make more sense that the authors focus on the FarCuriosity angle more in the paper?\n\nAnother point regarding reproducibility is the selection of some of the hyper-parameters in the configuration of the algorithms. First of all, what is the threshold \\psi mentioned after equation 4? Is this the threshold \\rho mentioned later? Also, how the selection (or potential good values) of \\epsilon, \\rho and number of samples (25) before fragmentation is allowed, would be chosen in a new application? How do you ensure a \u201cgood\u201d fragmentation?\n\nA few points about the experiments:\n- Please elaborate a bit more why the approach does not perform well on the Tennis game in Atari? Is it a matter of tunning the hyper-parameters that control the fragmentation point selection?\n- I would have also expected Go-Explore and Savinov et al. (2019) as baselines in the experiments. \n- Why don\u2019t you run experiments on Pitfall and Montezuma\u2019s Revenge as those have also been extensively studied in RND.\n- Fig. 11 was actually very nice to see. I wanted to propose such a visualization and was happy to find it in the appendix. You might want to move it to the main paper.\n\nMinor points:\n- While first reading the paper I asked myself the following questions / I struggled with the following points:\n    - Heterogeneous environments: please formally define when an environment is \u201cheterogeneous\u201d (maybe formally in the paper but also by intuition in the abstract already)\n    - What do you mean with \u201cspatial\u201d? \uf0e0 The difference between FarMap and FarCuriosity does not become clear from the beginning\n- The first two paragraphs in the introduction are too long. I like motivation over such findings, but it takes too long to get to the point of the paper\n- In section 3.1 the way a sub-goal is selected is provided in Eq. 5 in the appendix, but I think it would help text clarity if it is included in this Section.\n- Since the classification of environments into homogenous and heterogenous is not a standard term in the RL community, I would suggest that the definition given in the appendix should be moved and discussed in the main text for clarity. \n- To add to the previous point, I think the comparison with RND shown in Figure 11, as well as the small discussion on Tennis game could be included in the main text as they provide useful insights on the properties of the algorithm.\n\nLanguage/Grammer:\n- Abstract: On the other hand, \u2026 (On the one hand missing before)\n- a location a where fragmentation $\\rightarrow$ swap a/where\n- Subgoal is decided $\\rightarrow$ col.\n- local map in STM or [the] connectivity graph\n- while the latter helps [to] find\n- we first find the all frontiers $\\rightarrow$ all the frontiers",
            "summary_of_the_review": "The paper is well written and in a good shape although it may benefit from some re-arrangement and early explanations of crucial concepts. The experimental results on both FarCuriosity and FarMap outperform existing approaches. However, especially for FarMap I am not an expert in the field to judge related work and state of the art to use as baselines. But more importantly, I do not see a major improvement of FarMap ofer Kuskal et al. (2021). On the other side, for FarCuriosity the explanation/discussion (there are a few open questions about the design choices) and the experimental section (I would have expected some specific baselines and environments) could be more thoroughly elaborated. \n\n\n**Post-Rebuttal**\n\nI would like to thank the authors for their response. I updated my recommendation to 6 as I also share some of the criticism of the other reviewers. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3/Reviewer_HdLq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3/Reviewer_HdLq"
        ]
    },
    {
        "id": "TToibmayfB",
        "original": null,
        "number": 3,
        "cdate": 1666779285324,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666779285324,
        "tmdate": 1666779285324,
        "tddate": null,
        "forum": "ED2Jjms9A4H",
        "replyto": "ED2Jjms9A4H",
        "invitation": "ICLR.cc/2023/Conference/Paper3/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work introduces the Fragmentation-and-Recall framework that can be applied for exploration in spatial and general reinforcement learning problems. The idea behind the proposed framework is the fragmentation of the space based on a surprising signal. In this way, agents create local maps (or curiosity modules in the case of RL)  stored in a long-term term and recalled when the agent returns to the state where the fragmentation happened. In this way, local information can be reused by the agent. Authors have applied the framework in the settings of spatial exploration (*FarMap*) and general reinforcement learning exploration (*FarCuriosity*).",
            "strength_and_weaknesses": "**Strengths**\n\n- The proposed Fragmentation-and-Recall framework is general and can be applied in both the spatial exploration (*FarMap*)  and general reinforcement learning exploration  (*FarCuriosity*) settings. \n- By using local maps and model fragments we can avoid catastrophic forgetting in learning heterogeneous environments.\n- Experiments have been conducted in procedurally-generated spatial environments and on reinforcement learning benchmarks, showing that the proposed method is more efficient regarding memory usage.\n\n**Weaknesses**\n\n- Many of the Fragmentation-and-Recall framework components should be described in more detail.\n- The proposed *FarMap* does not outperform Frontier++. Actually, Frontier++ performs much better compared to the  *FarMap* as the map size increases.\n- Experiments at hard-exploration environments are missed (i.e. Montezuma\u2019s revenge)\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The main idea behind the proposed  Fragmentation-and-Recall framework is space fragmentation by using a surprisal signal. I found the general idea of this work interesting as it allows agents to create local maps that can be reused in the future. As aforementioned, the main weakness of this paper is its clarity a lot of points are missed that could help the reader to understand the proposed framework in depth.\n- First of all, the way used to create the local map is vague, i.e. the spatial transformation is not presented at all. \n- Also, it is not clear if $M_{t-1,C}^{cur}$ is considered as a vector at Eq.(1).\n- Another point that is not clear is the prevention of quite small local maps. How we can avoid the creation of a huge number of local models?\n- It is not clear how the agent explores the local map. How a local map is expanded?\n- The definition of memory-usage is not clear. How do you compute it?\n- Standard deviation or the 90% percentiles should be provided in Fig. 5. Also, the same kind of plots should be provided for the different groups of environment sizes. \n- The performance of the FarCuriosity should be examined in hard-exploration environments, such as Montezuma\u2019s revenge. \n- How the performance of the FarCuriosity is affected by the number of curiosity modules?\n- Source code should be provided. Otherwise, the reproducibility of the results is quite hard or even impossible.  ",
            "summary_of_the_review": "In general, the proposed Fragmentation-and-Recall framework is somehow novel and can be applied in both spatial exploration and general reinforcement learning exploration settings. The main limitation of this work is its clarity, as a lot of useful information is missed or doesn't present in depth. Also, the empirical analysis should be considered real maps in the case of spatial tasks and more hard-exploration environments in the RL context.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3/Reviewer_FqLm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3/Reviewer_FqLm"
        ]
    },
    {
        "id": "h0o7XNX8l8M",
        "original": null,
        "number": 4,
        "cdate": 1667519652440,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667519652440,
        "tmdate": 1669075671980,
        "tddate": null,
        "forum": "ED2Jjms9A4H",
        "replyto": "ED2Jjms9A4H",
        "invitation": "ICLR.cc/2023/Conference/Paper3/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a function approximation framework for mapping and exploration in RL. The function approximation scheme uses multiple local models that predict the next observation, and new local models get created when a prediction error is above a user-defined threshold. The local model used at each step is determined by the similarity of the current observation to the observation stored in memory for each local model. The mapping procedure also creates a graph of the local models to allow for exploration across local regions. In the reinforcement learning setting, the local models' intended benefit is overcoming catastrophic forgetting, which occurs when using a single neural network to predict intrinsic reward signals. ",
            "strength_and_weaknesses": "The idea forgoes the current trend of having monolithic forms of function approximation and tries to address an important problem with many algorithms. However, some key issues need to be addressed before the paper is ready for publication. The primary issue is that the experiments do not substantiate the claims or provide meaningful insights into the algorithms. I will detail these below. \n\nFor the FarMap and FarCuriosity experiments, each method is run on multiple environments to show that the new methods outperform the existing ones. There are several issues with the experimental setup. The first is that only one selection of hyperparameters is considered. As has been pointed out several times (Henderson et al. 2018, Jordan et al. 2020, ml ones), this leads to arbitrary comparisons in claiming that one method outperforms another. So these experiments cannot say one method is better than another outside of these specific hyperparameter choices. This experiment is of little value because the hyperparameters need to be tuned for different environments. \n\nAnother issue in the experiments is the comparison of memory usage. The % of memory used is not an informative metric because it depends on the system's memory (more of a minor issue). It would be better to show the actual memory usage. Also, the amount of memory used by each method highly depends on the implementation. There can be numerous code optimizations to reduce the memory of each method. It is worth considering a metric independent of the actual implementation to provide a fair comparison. Showing the actual memory usage of a specific implementation in addition to the other metric would provide a realistic context of what one could expect. Similar to the other experiments, the results here also depend on the hyperparameters, and their effect must be considered. \n\nTo address the hyperparameter issues, one could consider experiments to answer other questions that would be more helpful than a performance comparison. A few possible questions: 1) how does changing the number steps before fragmentation impact the number of local maps, and 2) how sensitive is the behavior of the algorithm to epsilon? These are important questions if you want someone to be able to use the algorithm successfully. \n\nFigure 5: Standard error is not an accurate representation of confidence. Also, how was it computed because the number of trials is not 1500, as stated on page 7? The run of the algorithm on different problems is not an i.i.d sample, so you cannot lump them all together to compute the variance. \n\nIn Table 1, if you want to compare the performance of each algorithm, you should use confidence intervals to identify if one method is better than another, not the empirical measure. Based on the large standard deviations, it is unclear whether one method is better than another. Remember to correct for multiple comparisons amongst the algorithms when making these comparisons. \n\nPage 8: \"On the other hand, RND generates a higher intrinsic reward (higher prediction error) as training progresses, implying that this method suffers from catastrophic forgetting\"\nThe experiments are not a valid test of catastrophic forgetting taking place. If you want to measure catastrophic forgetting, then measure it with an experiment. This statement is simply a guess at what is going on. However, this is a great hypothesis that should be tested, i.e., does RND accurately predict the intrinsic reward signal at previously seen states later in training? Then follow it up with a question based on your approach. Does splitting the function approximator at points of high prediction error provide longer-term memory of the intrinsic reward signal? Performance-based experiments can only be used to test the differences in performance, not underlying factors like catastrophic forgetting. \n\nA few questions:\nPage 5: is the backward direction backward in time? Because the agent could be facing any direction. Defining the method with math would make things more precise and avoid confusion. \n\nIn what sort of problems is the FarMap applicable? The prediction of the observation is not a true model of what occurs, e.g., the agent could move left or right, and the local map could not predict the outcome. Additionally, would it not induce many fragmentations if the colors change in the map with a high frequency? \n\nWhat feature extractor was used in the RL experiments?\n\nReferences:\nHenderson, P., Islam, R., Bachman, P., Pineau, J., Precup, D., and Meger, D. Deep reinforcement learning that matters. In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), pp. 3207\u20133214, 2018.\n\nJordan, S., Chandak, Y., Cohen, D., Zhang, M., & Thomas, P. (2020, November). Evaluating the performance of reinforcement learning algorithms. In International Conference on Machine Learning (pp. 4962-4973). PMLR.\n\nLucic, M., Kurach, K., Michalski, M., Gelly, S., and Bousquet, O. Are gans created equal? A large-scale study. In Advances in Neural Information Processing Systems 31., pp. 698\u2013707, 2018.\n\nMelis, G., Dyer, C., and Blunsom, P. On the state of the art of evaluation in neural language models. In 6th International Conference on Learning Representations, ICLR. OpenReview.net, 2018.\n",
            "clarity,_quality,_novelty_and_reproducibility": "In general the paper clarity is ok, but should be better. Mainly this could be achieved by being more precise in many minor statements throughout the paper. See some of the notes below. \n\nThis work has similar feeling to work on growing basis functions in RL. See Samejima and Omori (1999), Whiteson et al. (2007), Ure et al. (2012), and Mitchley (2015) for examples of this work. Specific these works grow new basis functions to expand the function approximator's ability to better predict the value function or transition dynamics based on having large prediction errors. It is very similar to the fragmentation idea presented in this work. \n\n\n\nMisc notes:\nAt the start of section 3, there are many repeated points. It would be beneficial to be more direct and introduce the method with a mathematical description and not rely solely on words. \n\nPage 5: What is a frontier cell? It was not yet defined and not defined until much later. \n\nPage 6: What does it mean for a set of states to be diverse? \n\nIn Figure 6, use different units to make the numbers more readable.\n\nPage 8: \"we present the empirical results that verify the problem of catastrophic forgetting of intrinsic rewards in reinforcement learning.\" The problem of catastrophic forgetting is not a problem in reinforcement learning per se. It would be more accurate to say it is a problem with function approximations used in RL. Tabular methods do not have a catastrophic forgetting problem. \n\nMitchley, M. R. (2015). Adaptive Value Function Approximation in Reinforcement Learning using Wavelets (Doctoral dissertation, University of the Witwatersrand, Faculty of Science, School of Computational and Applied Mathematics).\n\nSamejima, K., & Omori, T. (1999). Adaptive internal state space construction method for reinforcement learning of a real-world agent. Neural Networks, 12(7-8), 1143-1155.\n\nUre, N. K., Geramifard, A., Chowdhary, G., & How, J. P. (2012, September). Adaptive planning for Markov decision processes with uncertain transition models via incremental feature dependency discovery. In Joint European conference on machine learning and knowledge discovery in databases (pp. 99-115). Springer, Berlin, Heidelberg.\n\nWhiteson, S., Taylor, M. E., Stone, P. (2007). Adaptive tile coding for value function approximation (No. AI-TR-07-339).",
            "summary_of_the_review": "The topic of the paper is worth further study, but due to poor experimentation this paper is not yet ready for publication. \n\n--update--\nAfter discussing with the authors and seeing changes to the paper, it has improved, but still lacks experiments that demonstrate the method is behaving as intended. I updated my score to a 5 marginally below the threshold. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3/Reviewer_RmS4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3/Reviewer_RmS4"
        ]
    }
]