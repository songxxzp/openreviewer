[
    {
        "id": "Z7ibjohllz7",
        "original": null,
        "number": 1,
        "cdate": 1666626843023,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666626843023,
        "tmdate": 1666626843023,
        "tddate": null,
        "forum": "tVrRejrC-RZ",
        "replyto": "tVrRejrC-RZ",
        "invitation": "ICLR.cc/2023/Conference/Paper4676/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper focuses on  generalizing the action/prediction representation that leverages multi-step predictions and that we find to be better suited to a suite of challenging 3D-exploration tasks in DM-HARD-8. We show experimentally that our approach can work with a variety\nof RL agents, and obtain state-of-the-art performance on Atari and DM-HARD-8.\n\nThe paper extends previous work,  limited to short-term memory (current episode), to address a wide range of timescales determined by the choice of discount. The authors propose an online clustering algorithm that is able to approximate the density of visited states.",
            "strength_and_weaknesses": "Strengths:\nThis is a challenging area, and the paper has clear novelty.\n\n\nWeaknesses:\n\nOverall, the ideas are interesting but the paper is poorly written and has inadequate experiments. The experiments should include a clear comparison with the standard Markov assumptions of RL and the general methods included here.\n\nTheoretically, the paper is muddled and confusing. The authors need to distinguish the standard RL assumption of Markov models, vs. the exploration length allowed. This is unclear in the paper. The authors attempt to define \"history\" to incorporate exploration length allowed, but it is difficult to understand if this is actually the case.\n\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The authors need to better clarify the distinctions between the contributions. They note \"The first contribution of this paper is a general solution to (ii).\" This is confusing. So does the \"embedding function on observations or trajectories that encodes a meaningful notion of similarity\"  include and estimate of smoothed visitation counts?\n\nHighly non-standard notion of \"Interaction Process between an Agent and its Environment\". As defined, the history is infinite. Most work presumes a Markov property to bound the history. This raises an instant computational problem. Is it not critical to bound the history for computational or practical reasons?\n\nThe authors later imply that infinite histories are uninformative: \n\"When the embedding space is complex and too large, the vanilla visitation count becomes uninformative because each embedding is potentially different from all the atoms. To overcome this problem, soft-visitation counts are computed.\"\n\nHowever, later on, the authors fix the history: \"At a high level, RECODE stores a fixed number of weighted atoms (typically 5 \u00b7 104 or 2 \u00b7 105 depending on the domain) that are interpreted in the following as cluster-centers, along with their counts.\"\n\nFurther confusion is introduced in that the authors train a classifier g that, given the embeddings of *two* consecutive observations f(o_t), f(o_t+1), outputs an estimate p(a_t|o_t, o_t+1) = g? (f(o_t), f(o_t+1)).\n\nGiven this, it is difficult to understand the formal basis for this approach and its relationship to what is implemented, and why decisions are made.\n\n\n\nIt is confusing to introduce distributed learning \"Note that contrary to the usual episodic memory used in Badia et al. (2020b;a), the memory is never reset, and it is shared between all actors when using a distributed RL agent.\"\nPlease just stick to explaining things without adding distracting details.",
            "summary_of_the_review": "The ideas are interesting and have novelty, but the paper is poorly written and has inadequate experiments. The experiments should include a clear comparison with the standard Markov assumptions of RL and the general methods included here.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4676/Reviewer_vYnp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4676/Reviewer_vYnp"
        ]
    },
    {
        "id": "8RAHVtbFJcW",
        "original": null,
        "number": 2,
        "cdate": 1666649413845,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649413845,
        "tmdate": 1666649413845,
        "tddate": null,
        "forum": "tVrRejrC-RZ",
        "replyto": "tVrRejrC-RZ",
        "invitation": "ICLR.cc/2023/Conference/Paper4676/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work proposes Robust Exploration via a Clustering-based Online Density Estimation (RECODE) algorithm. RECODE calculates an exploration bonus that any RL agent can use as an intrinsic reward signal to explore unknown environment areas. To compute intrinsic reward signal the visitation counts of observations is considered. For this purpose, an online clustering algorithm is applied over learned representations of observations that estimates visitation counts for clusters of observations that are close to each other.  Experiments have been conducted on hard-exploration tasks of Atari and DM-HARD-8 suits.\n",
            "strength_and_weaknesses": "\n**Strengths**\n\n- The proposed RECODE algorithm can estimate a simple exploration bonus that can be considered by any RL agent\n-  The idea of using an online clustering algorithm over learned representations of observations to estimate visitation counts for clusters of observations close to each other is quite interesting.\n- Experiments have been conducted on hard-exploration tasks of Atari and DM-HARD-8 suits, showing that *RECODE* algorithm can explore the environment efficiently.\n\n**Weaknesses**\n- The idea of grouping similar observations and keeping visitation counts for clusters is not quite novel. The main novelty of this work can be considered to be the representation learning of from the observations.\n- Some parts of the paper are not well presented and therefore hard to be followed by the reader. Specifically, Section 4 which describes the representations learning process should be revised carefully.\n- It is not verified by the presented empirical results that the RECODE algorithm outperforms the MEME algorithm.",
            "clarity,_quality,_novelty_and_reproducibility": "The idea of using grouping together similar observations and keeping visitation counts for clusters is quite interesting but its novelty is limited.\n\nAnother weakness of this paper is that many of its parts are not presented clearly:\n- First of all, it is not clear how the representation model is trained to compute the observations embeddings. \nI found even Figure 2 a little bit confusing - Does c_t correspond to the cluster-center counts? It could be appreciated if authors can explain the representations learning process more clearly. \n- Eq. 1 does not return the visitation count of an embedding $e$.\n- Figure 10. referred to the main manuscript but it is presented in the supplementary material \n\nAccording to the presented empirical results, the MEME algorithm outperforms RECODE algorithm in most of the examined Atari games. Why RECODE is preferable compared to the MEME algorithm?",
            "summary_of_the_review": "This work proposes an interesting idea to drive agents to explore unknown environment areas, but its novelty is incremental. Apart from that, some details are missed, and that makes it hard for the reader to understand all the details and reproduce the results if needed. Finally, the experiments do not validate the superiority of the  RECODE algorithm over the MEME algorithm in each examined environment. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4676/Reviewer_TrKY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4676/Reviewer_TrKY"
        ]
    },
    {
        "id": "-QAgGlni6tg",
        "original": null,
        "number": 3,
        "cdate": 1666661169957,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666661169957,
        "tmdate": 1666661169957,
        "tddate": null,
        "forum": "tVrRejrC-RZ",
        "replyto": "tVrRejrC-RZ",
        "invitation": "ICLR.cc/2023/Conference/Paper4676/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a new clustering-based non-parameteric way of estimating the state visitation density, and uses it to construct a reward to encourage more exploration of less-visited states. The paper also proposes a way of converting the state input into some embedding space. Overall, both ideas seem to have some novelties and merits despite the experiment section can be improved as detailed below.",
            "strength_and_weaknesses": "**Strength**:\n\n* Estimating the state visitation via clustering-based non-parameteric way is intuitive. \n* The results in the figure show that the proposed method achieves similar performance as SOTA on several hard-exploration Atari games. When the tasks contain noisy observations, the proposed method surpasses the SOTA.\n\n**Weaknesses**:\n\n* The paper lacks an intuitive explanation of the detailed RECODE algorithm. There is barely any discussions on why the algorithm is designed as it is. It's not easy to understand when there is only a (rather complex) pseudocode block describing the algorithm.\n* Similarly, in the experiment section, there is no comparison against other exploration algorithms or density estimation algorithms to show the effect of RECODE. The paper compares RECODE and MEME. But it would be more insightful to compare just on the exploration part of the algorithm. Does RECODE leads to different coverage or exploration pattern than other count-based or curiosity-based exploration methods?\n* As for representation learning, it's important to do an ablation study on how good the proposed casual action-state masking method is compared to other representation learning methods such as contrastive learning on observation input, forward/inverse dynamics model learning, reconstruction on observation input, etc. When doing ablation studies, other factors (such as the exploration method) should be controlled to be the same.",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the paper has some novel ideas, but it lacks some ablation studies that will really strengthen the paper.",
            "summary_of_the_review": "The paper has a potential to demonstrate a novel algorithm. While it shows that it achieves a similar performance as the SOTA on atari games, it does not deliver enough ablation studies to help readers understand how good each component is, and what the new exploration algorithm brings, what the new insights are, why these design choices, etc.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4676/Reviewer_zKdb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4676/Reviewer_zKdb"
        ]
    }
]