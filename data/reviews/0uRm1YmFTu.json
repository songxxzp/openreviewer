[
    {
        "id": "NEJALnXbCB",
        "original": null,
        "number": 1,
        "cdate": 1666584094795,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666584094795,
        "tmdate": 1669695105304,
        "tddate": null,
        "forum": "0uRm1YmFTu",
        "replyto": "0uRm1YmFTu",
        "invitation": "ICLR.cc/2023/Conference/Paper2345/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes feature conformal prediction, which considers a prediction set over feature space rather than output space. In particular, the proposed novel conformal prediction is proved to satisfy the coverage guarantee under some assumptions. Moreover, the paper provides that the feature conformal prediction is provably more efficient than the vanilla CP. The efficacy (in terms of coverage guarantees and efficiency) of the feature conformal prediction is evaluated over five UCI datasets and one semantic segmentation dataset (along with one synthetic data for semantic segmentation). ",
            "strength_and_weaknesses": "**Strengths**:\n* Suggests an interesting extension for conformal prediction. \n\n**Weaknesses**:\n* Convincing arguments on the necessity of Feature CP compared to Vanilla CP is unclear.\n* Incorrect statements appear; assumptions are implicit in theorem statements. \n\n\n**Weakness1**: The paper claims that Feature CP is more efficient than the vanilla CP (e.g., \u201cif we instead employ conformal prediction on the more meaningful feature space, albeit all images have the same uncertainty on this intermediate space, the pixels would exhibit effectively different uncertainty in the output space after a non-trivial non-linear transformation\u201c). But, this justification is unclear. \n\n1. Before achieving the efficiency of prediction sets, Feature CP needs to satisfy the coverage guarantee as in the vanilla CP. This is proven in Theorem 4. However, Theorem 4 seems to have Equation (3) solved exactly, which is not clear. If that\u2019s true, please clearly specify in Theorem 4. If not, it would be useful to highlight this. Otherwise, this hidden assumption undermines Theorem 4. \n\n2. I think Theorem 5 is the crux of this paper, as it explains why Feature CP can be more efficient than Vanilla CP. First, the notation $\\alpha$ is reused in the theorem statement, which is very confusing as $\\alpha$ is reserved for a desired coverage in CP. Please use another term if it is not intended. Also, I believe this theorem implicitly assumes a special score function, i.e., a norm of a vector. If so, please explicitly state in the theorem statement. Apart from this, I\u2019m not sure if the cubic condition can be even satisfied in real datasets. Based on the proof, it looks like the paper made this assumption to prove the statement. If not, why is the cubic condition natural? In short, to my current understanding, Theorem 5 only holds under limited setups, thus I\u2019m not sure if this can strongly support that Feature CP is more efficient than Vanilla CP. \n\n3. Figure 2 and Table 1 empirically show that Feature CP is more efficient than Vanilla CP. But, the score function by Vanilla CP is too naive; for any test sample, it always returns the same length (as in Algorithm 1 \u201cEnsure\u201d line). One easy way to address this issue is considering the standard deviation of the prediction (e.g., Equation (1) in [R1] \u2014 this is a widely used trick to convert a point estimator to an uncertainty estimator by adding one more header for standard deviation prediction in a neural network). Can Feature CP outperform this simple baseline?\n\n[R1] http://proceedings.mlr.press/v128/vovk20a/vovk20a.pdf\n\n**Weakness 2**: The coverage guarantee in Equation (1) is not valid. The probability is taken over also a calibration set (e.g, Equation (1) in Tibshirani et al., 2019). The same issue appears in Theorem 4 (but fortunately, it does not affect the proof).  \n\nAs mentioned in Weakness 1, each theorem statement would be better if it explicitly includes required assumptions if there is any (e.g., a requirement of a norm-style score function in Theorem 5). \n\nIn related work, the statement \"Different from the above techniques, conformal prediction is appealing due to its simplicity, computationally free, and model-free properties.\u201d is not true for calibration work. Most calibration approaches (e.g., temperature scaling) is simple, computationally free, and model-free; they simply solve a different problem. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: the paper is mostly clearly written \u2014 I mentioned unclear points in the weakness discussion.\n\nQuality: The claim is supported by theories and empirical results \u2014 I mentioned related concerns in the weakness discussion. \n\nNovelty: I like the novel idea of applying CP in feature space; this may fertilize interesting ideas. \n",
            "summary_of_the_review": "I think applying CP in feature space is very interesting. But, currently I\u2019m not fully convinced on the claim that Feature CP is more efficient than Vanilla CP, as discussed. Thus, I lean towards rejection, but hope to hear the author's opinions and additional results (if any). \n\n\n=== After rebuttal\n\nThanks for the response. Most of my concerns are addressed, and the benefit outweighs the remaining concerns (e.g., on the justification of the cubic conditions). So, I raised my score \u2014 I like the idea of forming sets in feature space (but we can use only differentiable score functions, like DNNs, which is worth highlighting).",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2345/Reviewer_2teK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2345/Reviewer_2teK"
        ]
    },
    {
        "id": "Yi22geNf_zE",
        "original": null,
        "number": 2,
        "cdate": 1666667020232,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666667020232,
        "tmdate": 1666667216911,
        "tddate": null,
        "forum": "0uRm1YmFTu",
        "replyto": "0uRm1YmFTu",
        "invitation": "ICLR.cc/2023/Conference/Paper2345/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper propose to construct predictive interval through confidence set on features. It is assumed that a predictor $\\hat\\mu$ can be written as $\\hat g \\circ \\hat f$, where  $\\hat f$ is estimated feature. This paper proposes to use conformal inference with a new conformity score to obtain a confidence set for feature $f$. Theoretical guarantees show that the new confidence interval is provably more efficient than the baseline conformal predictive interval under \u201ccubic conditions\u201d, which is validated empirically. Empirical experiments corroborate the merits of the proposed method.",
            "strength_and_weaknesses": "- Overall, it is a well written paper and the proposed method looks promising.\n- The methodology of this paper hinges on the choice of maps $\\hat g$ and $\\hat f$ such that the predictor $\\hat \\mu$ can be represented as $\\hat\\mu = \\hat g \\circ \\hat f$. While the choice of $\\hat g$ and $\\hat f$ may be clear for some architectures, it may be that unclear or even arbitrary for others. Take a multilayer perceptron or CNN for example, it is unclear how many last layers should be treated as $\\hat g$. Different choice of $\\hat g$ could lead to a different set of surrogate features, and the structure of the set of surrogate features could change the outcome of Algorithm 2. More specifically,\n(a) How stable is the set of surrogate features with respect to the choice of $\\hat g$? I wonder if for some choice of $\\hat g$ we can\u2019t find any surrogate features other than $\\hat f$, so the only conformal score possible is zero.\n(b) If the set of surrogate features can vary by different choice of $\\hat g$, would this lead to different conformal scores after running Algorithm 2? I think it may be good to consider MLP of various widths, and set different number of last layers of the MLP as $\\hat g$ and see if the conformal scores estimated by Algorithm 2 vary a lot.\n(c) If the there is a general guideline for selecting $\\hat g$?\n- It looks that Algorithm 2 finds a feature $\\hat u$ that minimize the difference between $Y$ and $\\hat g(u)$, but I am unsure whether the $\\hat u$ returned by Algorihtm 2 would be closest to $\\hat f$. For example, a large learning rate may cause $u$ to be far from the initializer $\\hat f$. However, a small learning rate may lead to slower convergence. Hence, in practice, how would one select the learning rate that achieve a good tradeoff between the distances of $\\hat g(u)$ to $Y$ and $u$ to $\\hat f$?\n- I am a little bit concerned about the computational cost, because Algorithm 2 has to be done for every test output Y. The computational cost would be high if there is a large number of test points to be considered. Particularly, I guess for the Band Detection method, one would first specify a find grid for Y and run Algorithm 2 for every grid point. The computational cost should be high.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written. The work is original.",
            "summary_of_the_review": "The idea of performing conformal inference in feature space considered by this paper is a promising idea, although I do not think this paper has contributed much to the core concepts of conformal inference. For the application in deep learning, I believe there are some major questions that need to be addressed before this paper can be accepted.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2345/Reviewer_9LYb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2345/Reviewer_9LYb"
        ]
    },
    {
        "id": "CE1Zb-Lp5OZ",
        "original": null,
        "number": 3,
        "cdate": 1666796570181,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666796570181,
        "tmdate": 1670768310050,
        "tddate": null,
        "forum": "0uRm1YmFTu",
        "replyto": "0uRm1YmFTu",
        "invitation": "ICLR.cc/2023/Conference/Paper2345/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper looks at a different way to perform conformal prediction by proposing a new score function as well as guarantees that their proposed method achieves smaller interval lengths. They prove that under some conditions (not very well explained) their proposed method can achieve smaller interval lengths compared to standard CP.\n\nThey validate their method on various datasets \n",
            "strength_and_weaknesses": "I will split my review into strengths as well as weaknesses in this review.\n\nI will start off with the strengths:\n- The paper proposed a new way to thinking about conformal prediction by looking at perturbation in the feature space to construct a score function.\n- This is a new way to construct a score function to the best of my knowledge and interesting given their experimental results.\n- Given that they work in the feature space the problem hence lies in how to convert these to the output space and they propose two methods to do so.\n- Experimental results look really good especially Table 1 ~40 -> ~1 seems like a huge improvement while keeping the coverage.\n\n\nThe weakness of the papers are the following:\n- Firstly the explanations of the cubic conditions for theorem 5 are not very intuitively explained and I am left to just guess whether these conditions ever hold in practice. Could you please clarify how you determine if any of these conditions ever hold in practice? The reason I am asking this is that proofs can become trivial if one gives themselves too strong conditions and hence I will rely on other reviewers' expertise on this theoretical part of the paper.\n- Next, I am confused to how to use your algorithm in the classification setting. Looking at eq 3 wouldn't there be many $v$ for which we have the discrete label Y? In that case how do we choose which $v$ and therefore which score? I might have misunderstood sth, so please clarify this part please. My concern is that given that there is an optimization step, in alg 2 how do you determine how many steps to go and the step size? These seem to be user choices which I hope the authors can point me towards in the appendix or in this rebuttal.\n- The authors never discuss or even give intuition into how \" (LiPRA) (Xu et al., 2020)\" works and hence should be added. Please let me know if I missed it in the appendix or main script\n-EXPERIMENTS: Could the authors elaborate on Table 1 and how they achieved such amazing results on length 40 -> 1 . Especially I am curious why the l_inf norm was used throughout the paper and not standard L2. The authors mention this \"Secondly, an intuitive explanation relates to our usage of l\u221e to form the non-conformity score during the training.\" I don't understand this part, and hence a clarification on the loss functions or pointing me to the appendix would be helpful in understanding the results.\n- EXPERIMENTS: Fig 4 seems pointless without the interval lengths? Could you please point me to the interval lengths with varying alpha in case I missed it?\n- EXPERIMENTS: Table 1 literally contradicts your assumption that your lengths should be smaller. The std are overlapping in the table and hence I wonder if the method doesn't even work on synthetic data how can it possibly work on real data?\n- EXPERIMENTS: Lastly, my concern also lie in the way the authors chose the layers on which the compute the scores. The authors have some experiments in the appendix showing the picking different layers does impact the performance of their method, however, I don't see a comparison to standard CP. Does that mean if you choose the wrong layer standard CP is better? and if yes can you tell me which part of theorem 5 would be violated in that case? Could the authors please add experiments where the layer choice has been well justified and a more thorough ablation study has been done on how to choose the layer in the first place?\n\n\nOverall, i quite like the idea and would happily increase me score if the above have been answered.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written in terms of the methodology, however, the theory part is hard to digest and there are no intuitions on what the conditions are for theorem 5 to hold. In terms of reproducibility, I would like to hear the author's responses to my above questions in case I missed something in the main/appendix.\nThe paper is also novel in the sense that they consider different score functions for conformal prediction ",
            "summary_of_the_review": "I have clearly outlined my thoughts as well as concerns in the above review. \nI am more than happy to increase my score in case the authors are able to clarify the misunderstanding as well questions I have outlined above.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2345/Reviewer_5bhg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2345/Reviewer_5bhg"
        ]
    },
    {
        "id": "kPdSRL_bvMx",
        "original": null,
        "number": 4,
        "cdate": 1666834155309,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666834155309,
        "tmdate": 1666834155309,
        "tddate": null,
        "forum": "0uRm1YmFTu",
        "replyto": "0uRm1YmFTu",
        "invitation": "ICLR.cc/2023/Conference/Paper2345/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose feature conformal prediction for semantic feature spaces by leveraging the inductive bias of deep representation learning.\n",
            "strength_and_weaknesses": "Strength:\nThe authors aim to improve the original conformal prediction (CP) method by leveraging the idea of semantic feature spaces. The idea is novel and useful. They provided a solid theory on both the effective aspect (coverage) and efficiency (confidence band length). In addition, they compared their method with vanilla CP in various scenarios, validating their claims. They also provided many examples to demonstrate their theoretical statements.\n\nWeaknesses:\n\n1. The idea of conducting CP in semantic feature spaces is really interesting. However, the authors had little discussion on how we split f and g. The two functions f and g should be indistinguishable. I have this concern because it seems very important to choose an appropriate feature space. \n\n2. There are several \"surrogate\" steps throughout the method. They used $\\hat{u}$ to replace the ground truth label, utilized the gradient descent method to calculate the non-conformity score, and employed \"Band Estimation\" and \"Band Detection\" to approximate the confidence band in output space. As for the theoretical guarantees, do the authors need the assumption of the surrogate estimators? \n\n3. Numerically, the authors could consider comparing their method with more baselines. There are a lot of improvements to vanilla CP in the literature. Beating only the original one may not be convincing enough.  \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written in a clear way, with both methods, theory, and numerical studies supported. \n\nOne point with respect to the clarity is that the authors should clarify which norm they are using in the paper, for example, Section 4.1 etc. ",
            "summary_of_the_review": "Overall, the paper is well written with both theoretical and numerical guarantee. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2345/Reviewer_MB3r"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2345/Reviewer_MB3r"
        ]
    }
]