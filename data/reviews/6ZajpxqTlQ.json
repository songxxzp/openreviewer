[
    {
        "id": "EKyA5m3mGQ",
        "original": null,
        "number": 1,
        "cdate": 1666497721215,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666497721215,
        "tmdate": 1666497721215,
        "tddate": null,
        "forum": "6ZajpxqTlQ",
        "replyto": "6ZajpxqTlQ",
        "invitation": "ICLR.cc/2023/Conference/Paper1651/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a two-stage attention-based method (TAM) to solve large-scale routing problems.\n\nAlthough existing learning-based solvers suffer from their scalability (e.g., # of nodes is typically less than a thousand), TAM is trained to split the large input instance into small sub-problems with keeping global constraints. Importantly, TAM can be attached to existing solvers to improve solution qualities. The technical contribution is by attention-based problem splitting, and then sub-problems can be efficiently solved by existing heuristics or learned data-driven methods.\n\nExperimental results are reported to support and discuss TAM. Many experimental results support the performance of the proposed approach emperically.",
            "strength_and_weaknesses": "[Strength]\n- TAM can be attached with any sub-problems solvers (existing heuristics like LKH3 and data-driven methods like AM).\n- TAM possibly accelerates existing heuristics (e.g., AM v.s. TAM+AM) by improving their solution qualities.\n- Ablation studies for reward and mask functions are meaningful (i.e., designing rewards is an essential step for learning-based methods).\n\n[Weakness]\n- Technical contributions are a bit incremental.",
            "clarity,_quality,_novelty_and_reproducibility": "- The general idea is well explained at a higher level in Fig.1 and Fig.2. The introduction of MDP beyond the existing AM method (Kool et al. 2019) is given and explained in Eq.1 to Eq.4. Technical contributions on rewards and mask functions a explained in Eq.5 to Eq.7. In my opinion, authors clearly explained the idea. On possible drawback is the training part is almost included only in Appendix, although the authors followed as standard learning framework on RL.\n\n- The quality of the proposed method is reasonable, i.e., it is based on well explained concepts in the paper and standard expreimental evaluations are done.\n\n- The reproducability is now not easily evaluated for me. One reason is the proposed experiments used many related methods (e.g., AM, LKH3, TAM, ...). Another reason is no explict explanations on algorihtms (e.g., pseudo-codes). This could be improved by providing some supplemental materials.",
            "summary_of_the_review": "The paper proposes a two-stage attention-based method (TAM) to solve large-scale routing problems. In recent years, simliar problems have been investigated by several researchers, but the proposed paper seems to succeed to solve larger instances. The proposed method seemes to be technically sound, a bit incremental improvement, but a large experimental advantages can be observed by experiments on synthethic and real instance data. Importantly the advantages seems to be large, and the result (i.e., solutions of routing problems) could be much better than existing approaches.\n\nBased on these observations, I feel that the proposed paper is above the baseline.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1651/Reviewer_6VLJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1651/Reviewer_6VLJ"
        ]
    },
    {
        "id": "QpMIPnBe5V",
        "original": null,
        "number": 2,
        "cdate": 1666629689377,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666629689377,
        "tmdate": 1666629991427,
        "tddate": null,
        "forum": "6ZajpxqTlQ",
        "replyto": "6ZajpxqTlQ",
        "invitation": "ICLR.cc/2023/Conference/Paper1651/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The current study, as a strategy to effectively solve large-scale CVRP, presents a strategy for generating TSP sub-problems by clustering nodes and simultaneously solving the generated TSP problems. In particular, the sequential node selection approach has been used to decompose nodes.",
            "strength_and_weaknesses": "The decomposition strategy is a methodology that has been dealt with a lot on the OR side. A literature review of decomposition methods is required. Additionally, more recently, the NCO community has been using a decomposition strategy to deal with large-scale VRP issues. It is difficult to evaluate this paper without including these papers in the literature review and comparing them with these methods.\n\nThe current study insists that employing decomposing strategy in a constructive way (i.e., constructive heuristics) is novel in that most decomposing strategies are employed in an iterative manner (i.e., improving heuristics). However, I think it's hard to claim novelty just by suggesting a way to find a solution in a different way. For it to be truly advantageous, it is when the quality of the solution derived by such a process approaches the optimum. From that point of view, I think the strategy of finding a good solution by repeatedly decomposing and solving sub-problems can be more effective.\n",
            "clarity,_quality,_novelty_and_reproducibility": "\n<Methodology>\n\n1. It is understandable that the dimension of the action that selects a cluster is large, so the current study proposes to use a sequence-to-sequence model. However, it is not clearly explained how to reduce the influence on the order. The factorial of the number of nodes generates the same reward. Isn't this redundancy affecting learning? In other words, shouldn't the attribute of permutation invariance be assigned to the learned policy?\n\n\n2. In general, when decomposing nodes, clustering-based methodologies such as k-means seem to be used a lot. Compared to these methodologies, what are the advantages of decomposing-based methodologies based on sequence to sequence model? Even when the number of clustering increases, is it possible to effectively cluster by reflecting the relationships between nodes?\n\n3. In Equation 4, why is the summation of the product up to n + l? What is n?\n\n\n\n\n<Experiments>\n\n1. Comparison with other decomposing strategies is necessary. Comparing the proposed method with a non-decomposing strategy is not fair. Because the current study proposes an effective decomposing strategy, it should compare with other effective decomposing strategies that can solve the large-scale CVRP. In addition, the performance criterion should be the optimality gap measuring the difference between the produced solution by the proposed method and the true optimum. Because many papers share the best-known solutions for large-scale CVRPs, the study should use this optimal solution as the oracle reference. The current experiment results look like a just ablation study showing the effectiveness of using the decomposing strategy.\n\n\n2. At what size did AM and POMO learn? Isn't it an unfair comparison to learn them on small size and then solve them on a large size? These models are not intended to achieve transferability over size. If that is the case, wouldn't it be better to compare the performance with other methods designed to achieve size transferability?  \n",
            "summary_of_the_review": "Although the proposed methodology is interesting, it is necessary to quantify how much more effective the proposed decomposition strategy is compared to other decomposition strategies.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1651/Reviewer_7d5S"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1651/Reviewer_7d5S"
        ]
    },
    {
        "id": "qHPUrF1GTv",
        "original": null,
        "number": 3,
        "cdate": 1666678623961,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666678623961,
        "tmdate": 1666678623961,
        "tddate": null,
        "forum": "6ZajpxqTlQ",
        "replyto": "6ZajpxqTlQ",
        "invitation": "ICLR.cc/2023/Conference/Paper1651/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a framework for learning to solve VRP. The core idea is to first learn a policy that can divide the routes into sub-routes where each sub-route is covered by a single vehicle. The one can use efficient TSP solvers for each of the sub-route, and also solve them in parallel. Experiments show that the proposed approach is able to learn the solving from small-scaled datasets, and generalize the results to large graph with more than 5000 nodes.\n",
            "strength_and_weaknesses": "Strength:\n\n- The problem tackled by the paper is an important combinatorial optimization that is actively used in daily work. \n- The proposed divide-and-conquer paradigm is reasonable and effective. \n- The empirical results show that the paper is able to achieve better results compared to some existing solvers. Also the paper is able to incorporate existing TSP solvers as subroutines and combine the power of both learning and existing human designed heuristics.\n\nWeakness:\n\n- The paper tackles a limited version of the CVRP. In practice the problem might be more complicated that it is hard to first divide the nodes while still obtaining feasible solutions. For example, in practice there would be constraints like 1) a driver could not drive more than certain hours; 2) certain packages should be delivered to a certain location within a given time period. \n\n- Compared to LKH3 or ORTOOLS the proposed approach obtained comparable or better results with a shorter amount of time. However in practice it is not clear if the proposed approach would further improve with more time. In other words it would be interesting to see the time-solution quality trade-offs of this method and other iteration-based solvers.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well motivated. The experiments are relatively comprehensive and convincing. The idea is simple but effective, which has practical values. The code is not provided though. As the implementation seems to be nontrivial, the reproducibility might be an issue.\n",
            "summary_of_the_review": "Overall a practical paper for VRP with two-stage approaches. It is a nice combination of learning and existing heuristics. The paper can potentially be improved with more analysis of the results, and directions on handling practical constraints when deploying VRP to real-world problems.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1651/Reviewer_o9TS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1651/Reviewer_o9TS"
        ]
    },
    {
        "id": "5X3nC-HAFi",
        "original": null,
        "number": 4,
        "cdate": 1667581606180,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667581606180,
        "tmdate": 1670861549168,
        "tddate": null,
        "forum": "6ZajpxqTlQ",
        "replyto": "6ZajpxqTlQ",
        "invitation": "ICLR.cc/2023/Conference/Paper1651/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "An RL algorithm, TAM, is proposed to solve large-scale VRP problems.  TAM learns how to split the problem into smaller problems and then solve the smaller problems which are instances of TSP by well-performed heuristic algorithms like LKH3. The splitting problem is defined as an RL problem in which the state of the system is the current partial solution which is obtained by the chosen sub-routes of the VRP problem. The action is choosing an unvisited sub-route which is the set of customers/nodes that a vehicle could serve in one round of service. The reward is the minimal distance of the chosen sub-route. To get that, for a given sub-rout, the minimum distance is obtained by using an optimal algorithm or any fast heuristic (here a learned model by RL is used to exploit the power of parallel computation by GPUs). \nThe goal is to minimize the total travel length.\nTo assign the nodes to the sub-routes, the same algorithm as the AM model, proposed by Kool et. al (2019) is used where the masking operator is added to the decoder to assign the nodes into the sub-routes. To use the GPU for solving the TSP problem in the sub-routes, the padding mechanism is used. For each sub-route problem, the trained RL models of sizes 20, 50, and 100 are available and the model which is closest to the size of each sub-route problem is used. \n\nI really enjoyed reading the paper and the results are impressive to some extent.  \n",
            "strength_and_weaknesses": "Strength\nA new RL algorithm is proposed to solve large-scale VRP problems. \n\nWeakness\nThe numerical experiments and benchmarks could be improved. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is mostly clear and well written. \nThe algorithm is described well and should be reproducible. \nThe idea of the paper is not novelty and it is explored before. But, the overall framework seems working well, which was not the case in previous papers.  ",
            "summary_of_the_review": "I only have two questions from the authors which upon getting satisfying answer, I'll raise my vote. \n\nQ1- I did not get \"If the capacity of unused vehicles cannot serve the rest demand, then the current vehicle can not visit the depot\". I am not sure why the capacity of the rest of the network is considered. If you are choosing a given set of nodes to assign them to a sub-route, then, you can easily check the sum of demand of those nodes. Once the sum of demands of those nodes gets bigger than the capacity of the vehicle, you stop assigning the nodes to the vehicle. Given this, why do you need the new masking operator? This procedure should end with the same result as the suggested masking operator, though it is cheaper and more intuitive. \n\nQ2- In the presented results in Table 1, I do not see the optimal solution. For some of the presented instances, you can get the optimal solution with the branch & price algorithm presented in [1]. Besides, the main comment on the numerical experiment is on the benchmark set. If you want to show the true value of your algorithm you need to demonstrate the performance of your algorithm on the CVRPLIB problem set (http://vrp.atd-lab.inf.puc-rio.br/index.php/en/) and instance in [3, 4]. The ultimate benchmarking would involve comparing your results with the state-of-the-art algorithm, like [2, 4, 5], which has some of the best results on that problem set. \n\n\n[1] Pessoa, Artur, Ruslan Sadykov, Eduardo Uchoa, and Fran\u00e7ois Vanderbeck. \"A generic exact solver for vehicle routing and related problems.\" Mathematical Programming 183, no. 1 (2020): 483-523.\n\n[2] Vidal, Thibaut. \"Hybrid genetic search for the CVRP: Open-source implementation and SWAP* neighborhood.\" Computers & Operations Research 140 (2022): 105643.\n\n[3] Uchoa, E., et al. (2017). New benchmark instances for the capacitated vehicle routing problem. European Journal of Operational Research, 257(3), 845\u2013858.\n\n[4] Arnold, F., et al. (2019). Efficiently solving very large scale routing problems. Computers & Operations Research, 107(1), 32\u201342.\n\n[5] Christiaens, J., & Vanden Berghe, G. (2020). Slack induction by string removals for vehicle routing problems. Transportation Science, 54(2), 299\u2013564.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1651/Reviewer_cdJ3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1651/Reviewer_cdJ3"
        ]
    }
]