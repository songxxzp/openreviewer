[
    {
        "id": "YnihnvxZ2P",
        "original": null,
        "number": 1,
        "cdate": 1666368347971,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666368347971,
        "tmdate": 1666368347971,
        "tddate": null,
        "forum": "cDVL245jZa",
        "replyto": "cDVL245jZa",
        "invitation": "ICLR.cc/2023/Conference/Paper3707/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes a data augmentation technique to improve the performance of the existing state-of-the-art methods in the incremental few-shot semantic segmentation setting. \nThe proposed technique, called GAPS, augments the few-shot samples by pasting the new classes' pixels onto a subset of exemplar images coming from the previous training steps. There are three critical aspects of this technique. First, exemplar selection: the subset of exemplar images is selected by uniformly sampling the images considering the similarity with the class prototype. Second, where to paste the new classes: the images are selected based on the similarity to the context of the new classes ranked with a VGG pre-trained on Places-365. Third, how frequently apply copy and paste: the paper proposes a dynamic strategy called virtual Repeated Factor Sampling.\nThe results show that GAPS is able to improve state-of-the-art methods by a substantial margin on both Pascal-5 and COCO-20 settings, either using one or five shots. \n",
            "strength_and_weaknesses": "Strengths:\n1. The paper investigates a novel and understudied scenario that is more realistic than earlier benchmarks.\n2. The study gives a comprehensive summary of similar works as well as comparisons and contrasts between them.\n3. The study expands the present benchmark with new experiments involving only one labeled instance of the new classes, demonstrating that the GAPS can address the issue of missing annotations.\n\nWeaknesses:\n1. The ablation study may be extended to other settings and may provide more insights about the paper choices. In particular, it may start from a baseline that uses exemplars without pasting the new classes on them, to show that pasting is important to improve performance and that the gain is not only given by the regularization effect of using exemplars (as proposed by GDumb [a]). Moreover, the paper should clarify if, while disabling the diversity guidance, the exemplars are sampled uniformly for the old classes or if they are randomly sampled on the full dataset. \n2. From the ablation study, context sampling appears to marginally improve the results. Moreover, it is not clear how the performance will change by using a pre-training dataset different from Places-365, such as ImageNet or ADE20K. Furthermore, can it be trained directly on the base dataset of the considered setting or can the method use the segmentation network itself (for example, using an auxiliary classifier on the encoder features)? \n3. The paper baselines appear to be very naive. In particular, the paper reports the results for Fine-Tuning, MiB, and PIFS without considering exemplars, introducing an unfair comparison with respect to GAPS. The baselines should be reported both without exemplars (as in the original paper) and with them (indeed, without the proposed copy-and-paste strategy).\n\n[a] Prabhu, Ameya, Philip HS Torr, and Puneet K. Dokania. \"Gdumb: A simple approach that questions our progress in continual learning.\" European conference on computer vision. Springer, Cham, 2020.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and properly structured.\nThe paper provides multiple details to reproduce the code.\n\n",
            "summary_of_the_review": "Overall, the paper proposes a new interesting data-augmentation technique for exemplar-based Incremental Few-Shot semantic segmentation. However, the paper misses some important comparisons, both in the ablation studies and in the main tables.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3707/Reviewer_2ZbE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3707/Reviewer_2ZbE"
        ]
    },
    {
        "id": "AqILXAXQlI",
        "original": null,
        "number": 2,
        "cdate": 1666641526528,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666641526528,
        "tmdate": 1666641526528,
        "tddate": null,
        "forum": "cDVL245jZa",
        "replyto": "cDVL245jZa",
        "invitation": "ICLR.cc/2023/Conference/Paper3707/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes a few-shot incremental semantic segmentation methods via guided copy-paste synthesis. To  achieves this, authors provide three kinds of guidance, i.e., diversity-guide, context-guide, and frequency-guide. Ablation study and comparison with baseline model show clear performance improvement with copy-paste synthesis.",
            "strength_and_weaknesses": "Strength:\n (1) This paper introduces copy-paste as a synthesis technique to few-shot incremental segmentation.\n (2) Experiments show clear improvement on performance with the proposed method.\n\nWeaknesses:\n(1)  My main concern is the novelty of the paper, copy-paste technique is more about a data augmentation methods, which has already been shown effective in many segmentation task, it is not novel enough to be accepted as an ICLR paper.\n(2) The paper is not clear at least for me, especially figure 1 and figure, it's really hard for readers to understand the task, although the idea is clear.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-structured, but it is no well-written, such as figure1 doesn't reflect the task, eq.3 mentioned in paper does not exist. The novelty of this paper is not enough, main idea is about a copy-paste technique applied to incremental few-shot segmentation. There are still much space for polishing the paper.",
            "summary_of_the_review": "This paper introduces a copy-paste techniques to incremental few-shot segmentation, and designs three guidance to generate more representation training images. The novelty is a concern, because  copy-paste in segmentation is more about a data augmentation technique, which has already been proved to be effective.  Extensive experiments show clear performance improvement with such technique.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3707/Reviewer_bVGy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3707/Reviewer_bVGy"
        ]
    },
    {
        "id": "LywXPUUtBOS",
        "original": null,
        "number": 3,
        "cdate": 1666709896171,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666709896171,
        "tmdate": 1666709896171,
        "tddate": null,
        "forum": "cDVL245jZa",
        "replyto": "cDVL245jZa",
        "invitation": "ICLR.cc/2023/Conference/Paper3707/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents a copy-paste data augmentation strategy for the few-shot incremental semantic segmentation task.  It starts with a base learning stage to train an initial segmentation network with fully-annotated images. In the subsequent incremental learning stages, the proposed method develops a guided sample selection strategy to build a memory-replay buffer and to generate fully-labeled training examples with the copy-paste technique from the buffer and a small set of images with novel classes annotated. The guided sample selection strategy considers three factors: diversity in difficulty levels, context similarity, and class frequency balance. The authors integrate their strategy with several incremental segmentation pipelines and evaluate them on two few-shot segmentation benchmarks, PASCAL-5i and COCO-20i.  ",
            "strength_and_weaknesses": "Strengths:\n- The paper introduces the copy-paste data augmentation strategy to the few-shot incremental semantic segmentation, which seems to be a novel combination. \n- The proposed guided sample selection method for memory construction and data synthesis improves the performance of several baseline methods.\n- The paper is most clearly written and easy to follow.   \n\nWeaknesses:\n- While the proposed data augmentation strategy helps few-shot learning, its technical novelty in the incremental semantic segmentation (ISS) is rather limited, as it is an add-on module and has to rely on the base ISS methods. \n- The construction of the memory-replay buffer has several limitations and will affect the quality of the data augmentation in ISS: \n1) Only the base stage has fully-annotated images that can be used for the target images in the copy-paste operation, and all the images from the incremental stages are partially labeled, which are unusable for that purpose. As a result, when the incremental learning evolves, the memory has to add samples of new classes and remove some base-stage images due to the capacity limit. Eventually, the memory buffer would be less useful. \n2) The diversity-guided selection procedure in Sec 3.2 considers each class separately in sampling. However, for semantic segmentation, it is common that each image has regions of multiple classes. It is unclear how such a method can balance different classes. This is also a problem for the class-frequency-guided selection, as each image can have multiple classes. Another issue is that this method did not take into account the region sizes as it only considers the image-level sampling factor. \n- There are several concerns on the experimental evaluation, which make the conclusion less convincing:\n1) Both benchmarks are mainly used in the few-shot segmentation literature, which are a bit small in terms of data set size and number of classes. Similar to SSUL and other ISS works, the method should be evaluated on more diverse ISS task settings and larger dataset, such as ADE. \n2) For the few-shot side, while this work adopts a different evaluation protocol (as described in Sec. 4.2), it would be more informative if it also uses the protocol in Cermelli et al 2021 for a fair comparison. Moreover, unlike the standard ISS, the training process of the few-shot setting typically has a large variance due to different training samples annotated. Thus it should report both the mean and standard deviation in the final results. \n3) The gaps in the ablation study are relatively small. It would more convincing if the standard deviation can be provided. It is unclear how significant such improvements are in the few-shot learning setting.       ",
            "clarity,_quality,_novelty_and_reproducibility": "Please see above for detailed comments on clarity, quality, and novelty. ",
            "summary_of_the_review": "While the proposed copy-and-paste strategy seems interesting for the few-shot ISS task, there are several concerns on this work, including the novelty of the method for ISS, the effectiveness of the memory for data synthesis in ISS and the insufficient experimental evaluation. As a result, my preliminary rating leans toward the negative side. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3707/Reviewer_oYb5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3707/Reviewer_oYb5"
        ]
    }
]