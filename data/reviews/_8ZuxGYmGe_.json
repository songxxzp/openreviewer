[
    {
        "id": "xrEAKEQzeCg",
        "original": null,
        "number": 1,
        "cdate": 1666628905869,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666628905869,
        "tmdate": 1666628905869,
        "tddate": null,
        "forum": "_8ZuxGYmGe_",
        "replyto": "_8ZuxGYmGe_",
        "invitation": "ICLR.cc/2023/Conference/Paper1039/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "In this paper, the authors improve multi-view representation learning by splitting documents and aligning viewer tokens along with different parts. The experiments conducted on three datasets demonstrate that the proposed CAMVR performs better than MVR. The analysis also shows that CAMVR has better interpretability. ",
            "strength_and_weaknesses": "Strengths\n* Important research topic.\n* Publicly available datasets.\n* Well-written and easy-to-follow.\n\n\nWeaknesses\n* The idea of aligning special tokens along with different parts in the document is not novel in the retrieval field. For example, [a] aligns special tokens along with different sentences. The authors should also consider comparing this line of existing studies.\n* The semantic meaning of viewer tokens can become different after using the proposed arrangement. There may not be different viewer tokens for a specific span or at fair positions attending all documents. \n* Following the previous point, many of the experiments and analysis are unfair to the original MVR because it has no such capability of doing that thing. The authors should compare valid methods like [a] for fair experiments.\n\n[a] Jiang, J. Y., Xiong, C., Lee, C. J., & Wang, W. (2020, November). Long Document Ranking with Query-Directed Sparse Transformer. In Findings of the Association for Computational Linguistics: EMNLP 2020 (pp. 4594-4605).",
            "clarity,_quality,_novelty_and_reproducibility": "* For clarity, the paper is well-written and easy-to-follow.\n* For novelty and technical quality, the proposed idea is not novel, and the experiments do not have enough technical quality to validate the proposed idea and have fair comparisons. \n* As mentioned in weakness, the paper does not provide the information about reproducibility.\n",
            "summary_of_the_review": "In sum, I would recommend \u201c3: reject, not good enough\u201d because the paper is not novel, and has some flaws in the experiments.\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1039/Reviewer_tgtb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1039/Reviewer_tgtb"
        ]
    },
    {
        "id": "XknkP1bg2C-",
        "original": null,
        "number": 2,
        "cdate": 1666666121086,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666666121086,
        "tmdate": 1666666121086,
        "tddate": null,
        "forum": "_8ZuxGYmGe_",
        "replyto": "_8ZuxGYmGe_",
        "invitation": "ICLR.cc/2023/Conference/Paper1039/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes to improve information retrieval models by introducing a new way of multi-representation learning, CAMVR. CAMVR extends MVR approach that added multi-view tokens at the beginning of the text inputs; instead, CAMVR adds the multi-view tokens in between the segments of text inputs, encouraging each multi-view representation to capture local information. Combined with the new loss function to prevent the collapsing multi-view representation problem, CAMVR were able to provide diverse document representations and demonstrated good performance in the common IR benchmark datasets.\n",
            "strength_and_weaknesses": "**Strength**\n* Simple and practical approach.\n* Provides multiple analysis to examine the multi-views indeed are not collapsing.\n\n**Weakness**\n* Novelty could be questioned for some reviewers because it does feel it\u2019s quite a simple extension of MVR paper.\n* There is no principled way of splitting the text even though splitting can play a critical role in the proposal. Input text was arbitrarily split with a toolkit (NLTK) and it does not seem to be based on solid assumptions.\n* Table 5 shows using 4 representations does not outperform other single-representation models (e.g. RocketQA/DPR-PAQ), which is a bit surprising. Only by using more than 8, it was able to outperform. Any discussions?\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity/Quality**\n* Paper\u2019s clarity and quality are in doubt. Paper has multiple typos and sections that require substantial polishing. For example, (13) does have a floating \u201ci\u201d variable and the connection to the per-view loss to the full loss function is not described. (7) has a form of the main loss function, but it is in the \u201cPreliminary\u201d section. Figure 4 has a typo. RAMVR->CAMVR. I encourage authors to improve the paper's clarity further.\n* Even though snippet splitting can play a critical role in CAMVR, authors did not disclose information regarding the split. Authors just meant the split was by NLTK toolkit, but I am not sure how they exactly splitted. Please provide details.\n* Important experiment details are missing. Authors should disclose models that they used in Section 4. (e.g. whether the model was pretrained, size, etc). I feel that the paper was rushed for the submission.\n\n**Novelty**\nCAMVR is a direct extension of MVR paper [1]. It essentially adds two minor contributions 1) inserting view tokens in between text segments unlike MVR, 2) adding the diversity loss function to prevent all multi-view representations to collapse. Both of the techniques do feel a minor addition to the original MVR paper.\n\n[1] Zhang, Shunyu, et al. \"Multi-View Document Representation Learning for Open-Domain Dense Retrieval.\" arXiv preprint arXiv:2203.08372 (2022).\n\n",
            "summary_of_the_review": "As discussed above, the paper provides a simple practical approach in IR. However, the novelty is thin and paper does require further polishing.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1039/Reviewer_b6Pg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1039/Reviewer_b6Pg"
        ]
    },
    {
        "id": "WoD5-zOZ2e",
        "original": null,
        "number": 3,
        "cdate": 1666669357332,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666669357332,
        "tmdate": 1666669357332,
        "tddate": null,
        "forum": "_8ZuxGYmGe_",
        "replyto": "_8ZuxGYmGe_",
        "invitation": "ICLR.cc/2023/Conference/Paper1039/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper aim at overcoming the drawback of multi-view representation models for dense-vector based open domain retrieval or question answering. A context-adaptive multi-view representation learning framework is proposed to avoid the collapse of representations in different views by adaptively aligning each viewer token with each document snippet. The answer snippets for positive documents are specified in a supervised-learning setting and the representations are able to attend to local snippets, this additionally enhances the interpretability for each view representation. The experimental results on multiple reading comprehension and question answering datasets show that the proposed approach outperforms state-of-the-art methods. \n\n\n\n",
            "strength_and_weaknesses": "Strength\n\n1. This paper focuses on an interesting and impactful problem, that is the multi-view representations tend to collapse into the same one when the percentage of documents answering multiple queries in training data is low. Resolving this problem is critical to reading comprehension and question answering tasks. \n\n2. The proposed context-adaptive multi-view representation model is reasonable and empirically effective. \n\nWeakness:\n\n1. Missing technical details:\n(1) Are the results, for example, in Table 1 statistically significant? It'd be great t-test results could be presented, in order to make the conclusion of this paper more convincing. \n(2) It seems the proposed method introduces a hyper-parameter, that is the number of snippets to divide a document. More discussions would be interesting. \n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well motivated to learn distinguished representations for multi-views. The diagrams explicitly illustrate the difference between the proposed method and prior methods in terms of the model architecture. \n\nThe idea of aligning each viewer token with different document snippets is intuitive. However, given the prior work MVR (Zhang et al., 2022), the novelty of this paper is thin. The method proposed in this paper seems incremental to existing work. \n\nThe paper discusses how the parameters and hyper-parameters are set, hence the results should be reproducible. ",
            "summary_of_the_review": "This paper studies the collapse problem that multi-vector models have in learning identical representations in different views. A simple and effective method is proposed to learn multi-view representations that attend to the local snippets of a document. \n\nIn general, the proposed method is well-motivated and reasonable. However, the paper has not presented critical technical details, including how significant are the results statistically and how exactly a document is divided into multiple short snippets by NLTK toolkit. \n\nThe contribution of this paper is incremental given prior works have presented many insights such as how to apply hard negatives. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1039/Reviewer_dw1C"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1039/Reviewer_dw1C"
        ]
    }
]