[
    {
        "id": "N0yCu1U1OAl",
        "original": null,
        "number": 1,
        "cdate": 1666480076332,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666480076332,
        "tmdate": 1666480076332,
        "tddate": null,
        "forum": "g7U9jD_2CUr",
        "replyto": "g7U9jD_2CUr",
        "invitation": "ICLR.cc/2023/Conference/Paper503/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a 3D human generative model which can learn to generate full body from 2D image collections. It proposes to decompose the human body into 16 parts and represent each part with a separate network. It also adapts several strategies for efficient training and sampling.  It also provides  evaluations and shows improvements over  pervious SOTAs in both generated geometry and texture quality. \n\n",
            "strength_and_weaknesses": "Strength:\n1.  the overall pipeline is well-designed and with promising performances.  The involving of SMPL as human  human priors and porposed pose-guided sampling strategy are adaptive and efficient. \n\n2.  given the evaluation metrics, the proposed method outperforms SOTA of 3D body generative model by a large margin. \n\n3.  detailed ablation for the method design and pose sampling. \n\nWeaknesses:\n1.  technical side, the novelty is kind limited, as it is not totally new to use a multi-nerf based methods to represent objects/scenes (it would also be better to add discussion about early works like BlockNerf in the related work).   \n\n2. the results of the interpolation and inversion are interesting but no baseline was provided and the results are a bit blur. \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is in general well-written and easy to follow. With the details provided in the paper, one should be able to implement with sufficient tuning. It might be hard to reproduce the exact results but the author promised to release the code. ",
            "summary_of_the_review": "Overall, I think the proposed method is sound with promising performance. Although it is not new to represent with multi-nerf, the method is well-designed and with efficient adaption. Hence I am in favor for acceptance.  ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper503/Reviewer_bCYZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper503/Reviewer_bCYZ"
        ]
    },
    {
        "id": "B-ML1sDrbwP",
        "original": null,
        "number": 2,
        "cdate": 1666623790398,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666623790398,
        "tmdate": 1666623790398,
        "tddate": null,
        "forum": "g7U9jD_2CUr",
        "replyto": "g7U9jD_2CUr",
        "invitation": "ICLR.cc/2023/Conference/Paper503/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents a method to learn 3D human from 2D image collections. By leveraging a 3D-aware generative model, the authors propose to integrate a compositional representation and a prior by SMPL, and an improved training strategy to enable digital human generation. The authors show that it is possible to sample high-resolution depth and color images of 3D human in a much better quality compared to the previous works. ",
            "strength_and_weaknesses": "** Strength ** \n\n- The proposed method contributes toward improving 3D-aware generative human modeling, which is an active research direction. \n\n- The experiments are compelling for both qualitative and quantitative results. \n\n\n** Weakness ** \n\n1) The compositional representation is a minor improvement compared to existing techniques in NeRF and volume rendering. Applying it for human modeling is a good application, though. \n\n2) It is known that FID/KID of 3D-aware generative models is worse compared to 2D GAN models. It would be good to demonstrate whether this is still the case for human generation. \n",
            "clarity,_quality,_novelty_and_reproducibility": "- It is good to clarify and note in the paper how FID is computed in Table 2, where the resolution of the baseline and remaining methods differ. It would be fair to compute the FID with a single resolution, e.g., the baseline results should be upsampled. \n",
            "summary_of_the_review": "- The paper demonstrates a good application of 3D-aware generative model for human generation, with the additional tweaks such as the compositional representation, SMPL prior, and pose-guided sampling to enable high-quality results. At the moment I am positive despite that I still have some minor concerns that would be good to address or discuss in the rebuttal period. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper503/Reviewer_zbyZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper503/Reviewer_zbyZ"
        ]
    },
    {
        "id": "FwnQkCOZNp",
        "original": null,
        "number": 3,
        "cdate": 1666681233942,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666681233942,
        "tmdate": 1666692323982,
        "tddate": null,
        "forum": "g7U9jD_2CUr",
        "replyto": "g7U9jD_2CUr",
        "invitation": "ICLR.cc/2023/Conference/Paper503/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper tackles the problem of 3D-aware human generation from 2D images. To generate at a high resolution, EVA3D proposes to \nuse compositional multiple NeRFs to do the generation. To overcome difficulties in training with imbalanced human dataset, the paper proposes several training strategies. Results on several human dataset demonstrate the effectiveness of the proposed method. ",
            "strength_and_weaknesses": "## Strengths\n\nThe proposed approach is interesting and effective. Even though some techniques are not new, e.g., LBS mapping is commonly used in human reconstruction, to integrate them into generative model training is novel.\n\n## Weakness\n\nI do not find major issues in the paper. However, there are some questions I wish authors can clarify or add to make this paper stronger. See below.\n\n## Questions\n\n**1. Clarification about \"Baseline\" in Tab. 2**\n\nCan authors clarify the difference between the \"Baseline\" in Tab. 2 and StyleSDF in Tab. 1? I am a little bit confused because the performance differs quite a lot. My understanding is that Tab. 2's \"Baseline\" includes the mapping with LBS. Is this correct?\n\n**2. For the effectiveness of composition**\n\nIn Tab. 2, to demonstrate the efficacy of composition, authors show the results between $512^2$ and $256^2$. This comparison is great to show the power of composition for high resolution. However, I feel like it may be a more direct comparison if authors can show the results from just $256^2$ with composition.\n\n**3. For the issues arising from composition**\n\nFrom qualitative results, e.g., Fig. 4 in the supplementary, it seems like the composition can impose apparent artifacts around the edge of the bounding box. For example, there are apparent lines around the neck. It would be great if authors can provide more discussion and analysis of this.\n\n**4. For the training strategies**\n\nThe proposed training strategies, i.e., pose-guided training and LBS mapping from observation space to canonical space, are essentially generalizable to all baseline methods (StyleSDF and EG3D). Meanwhile, the Delta prediction can also be applied to StyleSDF. It would build a stronger paper if authors can utilize these training strategies in baselines's training. \n\nThis is somehow related to the effectiveness of composition in Question 2: the above experiments would give clearer view of how the composition works compared to baselines's representations.\n\n**5. Lacked references**\n\n- Schwarz et al., VoxGRAF: Fast 3D-Aware Image Synthesis with Sparse Voxel Grids. NeurIPS 2022.\n- Zhao et al., Generative multiplane images: making a 2D GAN 3D-aware. ECCV 2022.\n",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarify: the paper is clearly written and easy to follow.\n- Quality: the results are of high quality.\n- Novelty: it is novel to integrate techniques mentioned in the paper into a generative model training pipeline.\n- Reproducibility: authors state that the code will be public.",
            "summary_of_the_review": "The proposed approach is interesting. The paper is clearly written. Meanwhile, effectiveness of some techniques can be further discussed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper503/Reviewer_eUx6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper503/Reviewer_eUx6"
        ]
    }
]