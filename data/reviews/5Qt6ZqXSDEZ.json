[
    {
        "id": "tFzdzqtZ0M",
        "original": null,
        "number": 1,
        "cdate": 1666453655344,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666453655344,
        "tmdate": 1669471023213,
        "tddate": null,
        "forum": "5Qt6ZqXSDEZ",
        "replyto": "5Qt6ZqXSDEZ",
        "invitation": "ICLR.cc/2023/Conference/Paper5017/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies the problem of machine unlearning and improves oracle complexity for stochastic convex optimization (SCO) under both smooth and non-smooth setting. The key idea is a new prefix-sum unlearning sub-routine that enables one to use Variance reduction Frank-wolfe and dual averaging algorithm for SCO.\n\nResult. For smooth SCO, the paper gives an $O(\\frac{1}{\\sqrt{n}} + \\frac{\\sqrt{d}}{n\\rho})$ accuracy answer with expected runtime $O(\\rho n)$ per update using variance reduced Frank Wolfe. For non-smooth SCO, it gives $O(\\frac{1}{\\sqrt{n}}) + \\frac{d^{1/4}}{\\sqrt{n\\rho}})$ accurate answer with $O(\\rho n)$ per update, using dual averaging. Dimension independent results have also been obtained for the special case of generalized linear model.",
            "strength_and_weaknesses": "Strength. The paper provide improved oracle complexity for stochastic convex optimization (SCO) of the machine unlearning task. The prefix-sum idea seems simple, but it is good enough for one to use powerful tool from SCO. Meanwhile, I expect the prefix-sum subroutine could be useful for other applications of machine unlearning\n\n\nWeakness. There is no major weakness. ",
            "clarity,_quality,_novelty_and_reproducibility": "The prefix-sum idea seems to be new in the area of machine unlearning.",
            "summary_of_the_review": "The paper gives improved rate for stochastic convex optimization of machine unlearning with some interesting ideas. I would vote for acceptance.\n\nQuestion for authors. Are there any lower bounds known for SCO of machine unlearning?\n\n\n-----------\n\nPost rebuttal\n\nI have read the rebuttal and my evaluation remains.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5017/Reviewer_44f4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5017/Reviewer_44f4"
        ]
    },
    {
        "id": "h25M6593OyA",
        "original": null,
        "number": 2,
        "cdate": 1666563059945,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666563059945,
        "tmdate": 1668991413400,
        "tddate": null,
        "forum": "5Qt6ZqXSDEZ",
        "replyto": "5Qt6ZqXSDEZ",
        "invitation": "ICLR.cc/2023/Conference/Paper5017/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper provides a framework for efficient machine unlearning for stochastic convex optimization. In particular, the work builds upon the prior paper by Ullah et al. (2021) and generalize it to handle prefix sum queries. As for concrete applications, this enables machine unlearning for variance-reduced  stochastic convex optimization (SCO) methods and dual averaging schemes. ",
            "strength_and_weaknesses": "The paper claims a set of efficient algorithms for exact machine unlearning of SCO methods that are widely used in ML practice.  I believe this is a well-motivated question and the technical contributions here are novel and non-trivial. \n\nHowever, I am concerned about the technical clarity of the presentation. Overall, I find the paper lack of some conceptual exposition to be accessible to non-experts of the area. In fact, much of the materials rely upon using the prior work Ullah et al. (2021). I believe for those who are not familiar with Ullah et al. (2021), the technical sections of the paper would be hard to parse. \n\nMost importantly, the main algorithm from Section 4 (on prefix sum queries) is mostly described by the pseudocode. I find it hard to understand it at a conceptual level. Why and how does it perform unlearning? What does the noise-adding mechanisms do here? I think the issue stems from not having sufficient exposition on the coupling nature of the problem and the technique of reflection coupling.  (It appears that the techniques are borrowed from Ullah et al. (2021), which I have not read.)  I suggest the author(s) add a technical overview section earlier in the paper. \n\nThe paper does not give empirical validation of their methods, though I do not consider it a major weakness, as this work is theoretical in nature. \n\nSome other minor comments: \n---- \nIn what sense is \u201clinear queries\u201d (Definition 8) is \u201clinear in the data-points\u201d, as claimed in the introduction? In Definition 8, the function p_j can be non-linear in z_j. In fact, if p_j is the gradient of the loss function, it can easily be non-linear in z_j (for many ML models and choices of the loss function). \n\nAfter Definition 6 it should be mentioned that the bounded sensitivity condition is satisfied in variety of applications. \n\nI think Appendix B requires more exposition. What does Algorithm 6 do at an intuitive level?  What is the LearnLinearQueries function? In fact, I suggest the author(s) expand this section and put it into the main paper as a warm up before delving into the prefix sum queries. \n\nThe paper should also discuss related work in more detail. In addition to Ullah et al. (2021) that this work builds upon, there\u2019s been a flurry of recent work on machine unlearning. This includes, for example, Descent-to-Delete: Gradient-Based Methods for Machine Unlearning by Seth Neel, Aaron Roth, Saeed Sharifi-Malvajerdi (ALT 21)\n\nMechanical suggestions\n---\n1. In the additional prelim section, I suggest the author(s) to elaborate on reflection coupling, especially its formal guarantees. (The original paper claims the result in the setting of Brownian motion, which seems different from what\u2019s going on here.)\n2. End of page 2: Frank Wolfe -> \u201cFrank-Wolfe\u201d\n3. Section 5: \u201c[...], and thus fits into the framework\u201d\n4. Algorithm 6, the Load() function is undefined?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The main technical contribution of the work is novel and original. In terms of clairty, I believe the paper requires more polishing to be readable. ",
            "summary_of_the_review": "Given the quality of the presentation, I cannot recommend accept. However, I can see that the paper could be improved a lot if the author(s) put some efforts on writing during the rebuttal period.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5017/Reviewer_qNGF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5017/Reviewer_qNGF"
        ]
    },
    {
        "id": "FU4tdMUZGEU",
        "original": null,
        "number": 3,
        "cdate": 1666566501621,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666566501621,
        "tmdate": 1668834690037,
        "tddate": null,
        "forum": "5Qt6ZqXSDEZ",
        "replyto": "5Qt6ZqXSDEZ",
        "invitation": "ICLR.cc/2023/Conference/Paper5017/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose a general framework for machine unlearning via (structured) adaptive algorithms. In machine unlearning, given a model trained via dataset S, one attempts to build algorithms which can efficiently remove any point z from the dataset post-training in such a way that the altered model is indistinguishable from training on $S \\setminus \\{z\\}$. The main goal is to build algorithms where the cost of unlearning is significantly less than the cost of simply retraining the model. The study of machine unlearning is practically motivated by data privacy laws and `the right to be forgotten,\u2019 in particular the General Data Protection Regulation (GDPR), and California Consumer Privacy Act (CCPA), which require (in limited circumstances) that a company must delete stored personal data on request.\n\nIn this work, the authors generalize the prior techniques of Ullah et al. (COLT 2021) for machine unlearning via (noisy) SGD via total variation stability to hold for a general class of adaptive algorithms built on either \"linear\" or \"prefix-sum\" queries, two well-studied classes of algorithms within optimization and privacy. In particular, they show how to modify any such algorithm into one in which unlearning costs only a $\\rho$-fraction as many queries as retraining (for arbitrary $\\rho > 0$). The main contribution is the algorithm and analysis for prefix queries, which is roughly based on combining Ullah et al.\u2019s TV-stability techniques with the binary tree mechanism of Dwork, Naor, Pitassi, and Rothblum (STOC 2010). The authors also study an extension of these methods to the streaming setting, where multiple insertions and deletions in such a manner in an online fashion.\n\nFinally, authors give a number of applications of this general framework based on known algorithms in the literature, namely for stochastic convex optimization (SCO) via Frank-Wolfe and Dual Averaging, and dimension-independent bounds for GLMs via the above and Johnson-Lindenstrauss (as in Arora et al. 2022). These techniques provide the best known unlearning algorithms for SCO, improving the known convergence rate from $\\frac{1}{\\sqrt{n}} + (\\frac{\\sqrt{d}}{n\\rho})^{2/3}$ to $\\frac{1}{\\sqrt{n}} + (\\frac{\\sqrt{d}}{n\\rho})$, thus showing unlearning has no asymptotic cost up to relative complexity $\\sqrt{d/n}$. The authors also give applications of the linear query method to federated learning and k-means.",
            "strength_and_weaknesses": "Strengths:\n\n1. The authors introduce the first general framework for (exact) machine unlearning for adaptive algorithms using linear and prefix query algorithms\n2. They give improved minimax rates for unlearning in stochastic convex optimization, a ubiquitous paradigm.\n3. They give many applications (federated learning, k-means, various SCO settings\u2026), and generalize to streaming setting\n4. The paper is generally well written (with some exceptions detailed below)\n\n\nWeaknesses\n\n1. While machine unlearning is motivated by data privacy/rights as a general concept, the exact model studied in this paper is not clearly well motivated. Approximate machine unlearning (or any say computationally indistinguishable method) seems substantially more useful. Furthermore, while the authors claim that GDPR and CCPA require companies to fully retrain models in this sense, as far as I can tell these laws say nothing of the sort, and only include vague instructions that personal data should be removed upon request. I find the introductory paragraph to be very misleading in this sense. This said, there is legal precedence for requiring model re-training in a 2021 Federal Trade Commission decision, but this is a specific instance and should be cited as such. It seems very plausible that approximate unlearning would be accepted in general.\n2. Many of the results seem to be straightforward generalizations or combinations of prior work and techniques, though proving the prefix query theorem does require some involved technical calculations. Furthermore, since no lower bounds are given in the paper it is hard to tell how substantial the rate improvements are.\n3. A more minor complaint is that the notion of relative unlearning complexity needs better motivation. Of course the idea of algorithms whose unlearning time is faster than retraining is natural, but it seems like the denominator comparison should maybe be to the best possible rate. For instance, one could have a very poor unlearning algorithm with very good relative complexity, where it would be better to just run a different method from scratch.\n4. No accuracy guarantee is given for the general framework, and has to be shown on a by-algorithm basis. The authors state informally that accuracy should be preserved for noise-tolerant algorithms, but if one is giving a general framework for application this should be formalized.\n5. While the level of detail given in the main body is ok for the short version, there needs to be additional background and exposition somewhere in the paper. It should not be necessary to be familiar with any specific prior work to understand the paper. I'd also recommend defining even very basic terms (at least briefly) such as query release, for non-familiar readers.\n\nTypos: \n\nPage 5: In 2. Efficient Unlearning Model should \u201cdoes\u201d be \u201cdoesn\u2019t\u201d?\n\nPage 7: Line 11 does not seem to be rejection sampling. Perhaps line 13?",
            "clarity,_quality,_novelty_and_reproducibility": "The work is fairly well-written (with exceptions observed above), and has reasonable quality applications. The framework introduced for adaptive query algorithms is original, though it draws heavily on analysis techniques and algorithms from prior work.",
            "summary_of_the_review": "This is a nice follow up work to Ullah et al. 2021, the idea of building a general framework of machine unlearning for adaptive query algorithms is a good idea, and the authors give a number of applications. On the other hand, it is not clear that the model of unlearning (and complexity measure) the authors study is interesting or well-motivated, and at a technical level it is also not clear much additional insight is given over prior works. As it stands, I am not sure this work is quite above the bar of ICLR.\n\nEdits: See rebuttal and response, raising to above bar.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5017/Reviewer_NHVJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5017/Reviewer_NHVJ"
        ]
    },
    {
        "id": "LvcwTeNQW2o",
        "original": null,
        "number": 4,
        "cdate": 1666695013344,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666695013344,
        "tmdate": 1666695013344,
        "tddate": null,
        "forum": "5Qt6ZqXSDEZ",
        "replyto": "5Qt6ZqXSDEZ",
        "invitation": "ICLR.cc/2023/Conference/Paper5017/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors consider the problem of unlearning. The aim is to do more efficiently than retraining from scratch. The authors propose to construct a prefix-sum-like tree during learning/training to keep intermediate results. These results can then be queried to construct a model that will look like the one without a certain data point (i.e., the one that was requested to be deleted).",
            "strength_and_weaknesses": "Strengths:\n- the problem of unlearning is really interesting and important\n- the authors aim to propose a method that is more efficient than training from scratch\n- the idea of decomposing into prefix-sum-like learning is nice\n\nWeaknesses:\n- the definition of exact unlearning used by authors is not common\n- the paper is extremely dense in notation and content\n- the method seems to work only for unlearning one point though the authors allude it may be extended\n- the method is expensive in terms of space as it seems one need store a model for every data point\n- no experimental results",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is difficult to read as it is heavy on content and notation. I was not sure why noise needed to be added. It seems it is not for DP purposes. Is it to make learning fall into distribution that would be close to unlearning? Though I appreciate the tree and the figure, it did not make things much clearer. It would be best to define all parameters and use fonts that fit.\n\nQuality: The authors use unlearning definition which is not quite what one would call exact unlearning: exact unlearning is the model one obtains if the data point is deleted and retraining happens. It seems definition 1 is a probabilistic guarantee. That is learning process is made probabilistic so that unlearning of probabilistic nature would be an appropriate counterpart. Please consider definitions in Thudi et al. USENIX Security 2022.\n\nNovelty: The idea of decomposing some training algorithms into prefix-sum is nice. It would be good to compare with Bourtoule et al as sharding seem to also isolate points and recompute those shards where the deleted point was used. Though authors say this work does not provide theoretical guarantees it seems to not use a data point at all hence, may provide exact unlearning as well.\n\nReproducibility: N/A as this is a theoretical paper.",
            "summary_of_the_review": "I believe the paper is not ready to be published due to its presentation (the method description) and how it positions itself (i.e., is this exact unlearning, how it compares to retraining from scratch, how it compares to sharding approach by Bourtoule et al. It may be that in considers inly certain training tasks but it would be best to be clear about it.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5017/Reviewer_VmwR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5017/Reviewer_VmwR"
        ]
    }
]