[
    {
        "id": "EBDmtUlJsr",
        "original": null,
        "number": 1,
        "cdate": 1666386097639,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666386097639,
        "tmdate": 1666386097639,
        "tddate": null,
        "forum": "P8DHF1Y_dph",
        "replyto": "P8DHF1Y_dph",
        "invitation": "ICLR.cc/2023/Conference/Paper2245/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors address the problem of large solution spaces by decomposing problems into smaller subproblems and training agents to consider all feasible actions for the subproblems, hopefully enhancing transferability of solutions to new problems.  They develop a generative model to produce all feasible actions and evaluate it on a 2D grasping problem.\n",
            "strength_and_weaknesses": "Strengths:\n - The idea of generating all feasible actions is an interesting one, and has intuitive appeal to facilitate skill transfer.\n - The authors present novel approaches to estimate gradients in various sampling contexts.\n - The authors present novel approaches to reduce bias in training the critic.\n - Empirical results are encouraging. \n\nWeaknesses:\n - Typo on page 8: \"RKL, has\" -> \"RKL has\"\n - The legend of Figure 3(b) covers some numbers\n",
            "clarity,_quality,_novelty_and_reproducibility": "The work seems original and interesting, and after more development, could be broadly applicable. \n\nQuestions:\n\n(1) In Section 4.2, do you choose your high-uncertainty actions probabilistically, or take the one with the smallest margin?  On a related note, this approach sounds a lot like an active learning problem; could you substitute a different AL algorithm here? \n\n(2) When you contrast JS/FKL to ME, you note that they have similar failure rates but more diverse outputs from JS/FKL.  What kind of tradeoff do you think is acceptable between failure rate and diversity?  I.e., how much higher of a failure rate (over ME) would you accept to claim that the higher diversity of outputs worthwhile? \n\n(3) The idea of generating all actions sounds a little like the idea of \"diverse density\" from multiple-instance learning.  Are there any results from that family of algorithms that might be useful here? \n",
            "summary_of_the_review": "I think that this is a paper worthy of publication in ICLR, though my confidence is not high.  It clearly defines a problem and concisely presents their approaches. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2245/Reviewer_RMrn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2245/Reviewer_RMrn"
        ]
    },
    {
        "id": "um-ZX_gSWF7",
        "original": null,
        "number": 2,
        "cdate": 1666636227463,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666636227463,
        "tmdate": 1666636227463,
        "tddate": null,
        "forum": "P8DHF1Y_dph",
        "replyto": "P8DHF1Y_dph",
        "invitation": "ICLR.cc/2023/Conference/Paper2245/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces an RL method designed to generate all possible actions. I assume this is done to help exploration of the space in order to learn a better policy. The approach is evaluated on a grasping task.",
            "strength_and_weaknesses": "The paper works on an interesting and important problem of finding/exploring all actions. The paper is well written and motivates the problem nicely.\n\nThe biggest weakness is the lack of experiments. There is only one experiment, and its setup, environment, action space, etc. are not defined. Further, there is no comparison to other methods, other than a few proposed in the paper. This makes it difficult to judge the work and its contribution.\n\nIt is also unclear how much the proposed approach helps vs other things used (imitation learning, etc.)",
            "clarity,_quality,_novelty_and_reproducibility": "I'm unsure of the novelty of the approach, lots of works have studied exploration ideas in RL, but this is not an area I am too familiar with.\n\nThe writing is well done and explains the idea and method well. I'm not sure if it will be reproducible from the paper, as it is heavy on equations but has no implementation details or experimental setup explanation. The paper states a github link will be given, but at the moment, only the paper is available.",
            "summary_of_the_review": "The paper proposes a method to generate all possible actions and is evaluated on a grasping setup. The paper is well written, but the experiments are weak/minimal.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2245/Reviewer_bb3F"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2245/Reviewer_bb3F"
        ]
    },
    {
        "id": "CGgRiqejLgL",
        "original": null,
        "number": 3,
        "cdate": 1666642367345,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666642367345,
        "tmdate": 1666642367345,
        "tddate": null,
        "forum": "P8DHF1Y_dph",
        "replyto": "P8DHF1Y_dph",
        "invitation": "ICLR.cc/2023/Conference/Paper2245/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a method to train a generative neural network to generate all feasible actions of a sub task by interacting with an environment. The trained generator provides a distribution that matches a uniform distribution over all feasible actions. The authors derive the general optimization target for arbitrary f-divergences using a combination of kernel density estimates, resampling, and importance sampling. An application of a 2D robotic grasping problem is presented in this experiment to show the proposed algorithm outperforms other related methods. ",
            "strength_and_weaknesses": "The problem considered in this paper is to generate all feasible actions for a certain task which is hard to obtain for complex tasks. The author propose a novel learning method for generative neural network in order to generate feasible actions. In order to solve the problem, the authors further propose a gradient estimator for the gradient of f-divergence. The proofs are rigorous and correct. \n\nWeakness: I found this paper a bit hard to follow since some theories are not well explained in the paper. It would be great if the authors can provide more comprehensive explanation for the result you used in the paper. ",
            "clarity,_quality,_novelty_and_reproducibility": "The proposed method is novel. The theoretical proofs look correct to me. ",
            "summary_of_the_review": "This paper considers a very important problem in real application. The proposed method is novel and well supported by theoretical and experimental results. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2245/Reviewer_JUVt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2245/Reviewer_JUVt"
        ]
    },
    {
        "id": "AiG_IQ3uCL",
        "original": null,
        "number": 4,
        "cdate": 1666669445022,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666669445022,
        "tmdate": 1666669445022,
        "tddate": null,
        "forum": "P8DHF1Y_dph",
        "replyto": "P8DHF1Y_dph",
        "invitation": "ICLR.cc/2023/Conference/Paper2245/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents an approach to discover the feasible actions for a given state in an environment. The algorithm proposes actions, which end in a single step in either success or failure, as determined here by a hand-designed heuristic. The generated actions are multimodal in nature and show limited generalization to out-of-distribution tasks. The method is tested on a robotic gripping task with 3-4 shapes. The results demonstrate that, in this domain, the proposed method can discover more modes of the feasible action distribution than the baselines.",
            "strength_and_weaknesses": "The strengths of the paper are:\n1. It is theoretically well motivated and sound. The authors explore various f-divergences to find the best one for this setting.\n2. The analysis of the various modes and grasping success for different methods is thorough for the chosen domain.\n3. As far as I can tell, their approach is novel.\n\nThe two biggest areas for improvement are:\n1. Lack of comparison with any relevant literature - grasping is well studied problem and comparison with some method in literature besides author-crafted baselines is required. The authors explore a few variations of their own method as well as compare to some sanity-check baselines but  the grasping success % can be compared to other methods in literature. I also found the related works section lacking in references to grasping literature and instead referencing peripheral works such as LLMs.\n2. Unclear writing - It is unclear which problem the method is solving, that of generating feasible actions or discovering skills or both. Skills are typically referring to a sequence of actions whereas the case considered here is closer to CB with a single state/action. It seems the terms \"multimodal action distributions\" and \"skills\" are being conflated and further clarification is needed. Moreover, while in the abstract the claim is to learn \"reusable and transferrable skills\", there is no discussion later in the paper about the reusability or transferability of the action modes discovered.\n\nSmaller points of feedback:\n\n3. It is unclear what happens in environments where the hand-designed heuristic for judging success/failure is not present. The method is only tested on a single environment of 2D grasping and could benefit from being tested on at least one other problem to get an idea of how well it works as a general method for feasible action generation.\n4. The role of the \"critic\" network is not clearly explained. Why is it that the learned critic can generalize over environment samples better, and hence provide better gradients, than directly training the KDE on them?\n5. What is the role of the imitation learning dataset used to bootstrap the critic? An ablation on how much data is needed there would be interesting to see.\n6. A study of the sample complexity in terms of environment interactions would be a relevant result.\n7. Results for the figure 8 shape are missing from figure 3.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Quality and novelty are high as stated above.\nThe paper as it is is lacking in clarity of motivation and terminology as well as comparisons. \nThe method is clearly explained with enough details to allow for reproducibility.",
            "summary_of_the_review": "This is a novel and sound method for multimodal action discovery and with proper comparison, clearer writing, and demonstrating the method's generality on at least one other domain it can be a strong contribution.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2245/Reviewer_fUjg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2245/Reviewer_fUjg"
        ]
    }
]