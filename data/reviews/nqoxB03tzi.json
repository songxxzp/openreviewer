[
    {
        "id": "ojMFeuNKreS",
        "original": null,
        "number": 1,
        "cdate": 1666562415307,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666562415307,
        "tmdate": 1666562415307,
        "tddate": null,
        "forum": "nqoxB03tzi",
        "replyto": "nqoxB03tzi",
        "invitation": "ICLR.cc/2023/Conference/Paper3640/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Motivated by a recent findings on the properties of prune at initialization (Su et al., 2020, Frankle et al., 2021), this paper proposes a new way of studying PaI methods. It suggests new metrics -- the number of effective paths\" and \"the number of effective nodes\" -- which are proxies to the performance of pruned network according to the authors' claim. The authors conjecture that a good balance between these two metrics are needed to let the pruned network have a good performance. Motivated by this so-called \"node-path balancing principle\", this paper suggests a simple method to improve SynFlow. ",
            "strength_and_weaknesses": "* Strength\n    * This paper focuses on an interesting problem of analyzing the intriguing property of PaI methods. \n\n* Weakness\n    * The conjecture made by the authors is not supported by theory. \n    * The empirical results are not supported by theory. For example, the empirical observation talks about two regimes (the normal sparsity and the extreme sparsity), but we do not know why 99% is a good threshold making different behaviors.\n    * Algorithm 1 is proposed based on the conjecture, but I would say it is a small variant of Synflow and not optimized for the purpose of balancing two metrics. Does the success of Algo 1 imply that we really need the balance of two metrics? I see only little connection btw Node-path balancing principle and the design of algorithm 1. \n\n\n* Question\n\n> Page 5, \"These observations indicate that increasing the number of effective paths (SynFlow) or effective nodes (PHEW) alone is not sufficient in the design of PaI methods.\"\n\nI didn't fully get why the observation in Fig.2 implies this. From the figure, we cannot say SynFlow and PHEW are not a good option, I guess?\n\n> Page 6, \"From observations in Section 3.3 where both effective paths and nodes play critical roles in performances of subnetworks.\"\n\nI guess this is not grammatically correct. Maybe the authors mean \"From observations in Section 3.3, both effective paths and nodes play critical roles in performances of subnetworks\"?\n\n> Algorithm 1 line 6\n\nIsn't it $t < T_{max}$, to be consistent with the description \"in the first Tmax pruning iteration, we use random pruning after each (\u2206t \u2212 1) steps\"? \n\n> Is node-path balancing principle necessary for having a good performance?\n\nA recent PaI method [R1] passes the sanity check of layer wise shuffling and performs similar or better than IMP. I am curious whether this method has balanced node/path. If [R1] does not have balanced node/path, maybe the node-path balancing principle is not a necessary condition for good PaI?\n\n[R1] Rare Gems: Finding Lottery Tickets at Initialization",
            "clarity,_quality,_novelty_and_reproducibility": "* The paper writing is okay, but needs some improvement. \n* This paper is providing a novel approach, but the algorithm is not that new.  \n\n\n\n",
            "summary_of_the_review": "This paper is suggesting new direction of understanding PaI in terms of effective node/path in the network, but we cannot have much insight or logic from their discussion & results. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3640/Reviewer_4Ufw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3640/Reviewer_4Ufw"
        ]
    },
    {
        "id": "OOiTEdcLVQs",
        "original": null,
        "number": 2,
        "cdate": 1666654202564,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666654202564,
        "tmdate": 1666654202564,
        "tddate": null,
        "forum": "nqoxB03tzi",
        "replyto": "nqoxB03tzi",
        "invitation": "ICLR.cc/2023/Conference/Paper3640/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper investigates pruning at initialization through the lens of 'effective nodes' and 'effective paths'. Effective paths are defined as paths that exist from input node to output node and effective nodes as nodes that participate in at least one of these paths. The paper argues that these 2 objectives must be simultaneously met if one is to successfully prune at initialization. ",
            "strength_and_weaknesses": "Strengths:\n- The idea of dividing the pruning at initialization problem into these two objectives is novel\n- The paper is mostly easy to follow\n\nWeaknesses:\n- The new objectives are not supported by much more than heuristic arguments\n- The explanation in section 3.3 that attempts to explain the layerwise shuffling phenomenon through the lens of these two objectives is underdeveloped and should be expanded to allow readers to understand how the trade-off between the two objectives explains these results\n- The experimental results where the paper attempts a first pass at using these two objectives to prune at initialization are unconvincing (understandably the authors do clarify that this is not the goal of the paper, but considering lack of theoretical justification for the objectives, the experiments should instead instill faith in these two objectives)\n",
            "clarity,_quality,_novelty_and_reproducibility": "The key idea of this paper to think of pruning at initialization as a two objective problem is sufficiently novel and somewhat justified in the context of prior work. The main flaw of this paper is that it does not do enough to convince the reader that these two objectives can indeed be used to understand pruning at initialization. ",
            "summary_of_the_review": "The paper presents a novel idea for pruning at initialization in the form of the two objectives, however, lack of theoretical justification or strong empirical results makes the proposal unconvincing. Perhaps the authors could supplement the experiments with simpler toy experiments where they can explicitly optimize for the two objectives, this might help convince readers of the usefulness of the objectives. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3640/Reviewer_8VAP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3640/Reviewer_8VAP"
        ]
    },
    {
        "id": "AWaRhKmf4_c",
        "original": null,
        "number": 3,
        "cdate": 1667198639915,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667198639915,
        "tmdate": 1667198639915,
        "tddate": null,
        "forum": "nqoxB03tzi",
        "replyto": "nqoxB03tzi",
        "invitation": "ICLR.cc/2023/Conference/Paper3640/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents a new pruning approach called, node-path balancing principle, based on the intuition that both effective nodes and effective paths need to be preserved high such that training sparse neural networks from scratch can be performed well.\nThe method is essentially done by tuning the schedule of (random) pruning for the obtained connectivity in the subnetwork.\nThis intuition is obtained based on recent works on pruning including the shuffling mask effect.\nThe authors summarize their findings in two different regimes, regular and extreme sparsity levels, that while effective nodes are more important than effective paths for regular sparsity, it may not be the case for extreme sparsity levels.\n",
            "strength_and_weaknesses": "Strength\n- The writing is very clear, and the main idea and intuition behind are delivered well to readers.\n- The intuition behind the proposed method makes sense and based upon previous research findings in the literature.\n- The experiments are conducted systematically.\n\nWeaknesses\n\n- The proposed method introduces additional hyperparameters (\\Delta_t and T_\\text{max}) which can be suboptimally set in practice or expensive to perform. It is also hard to compare with others without solid fair hyperparameter searching. In terms of algorithmic or methodological advances it is simply considered as another schedule for iterative magnitude based pruning but with some resetting. When it comes to comparisons, it is hard to tell which one is better than which and things are not conclusive.\n- The proposed method being not better than PHEW in terms of the subnet accuracy (for regular sparsity levels) weakens the main argument on the importance of node-path balancing, which is somewhat critical.\n- Perhaps not the most critical issue, but it would have been better to add experiments on more diverse and larger data sets and network models since the paper relies on empirical evidence.\n- The results on effective paths and effective nodes divided by regular and extreme sparsity levels seem somewhat inconsistent and remain based on hypothetical intuition level without direct or provable evidence. The divider threshold between can be thought of as favoring the interpretation of the proposed method without a clear setup as to how the threshold has to be chosen.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper  is presented in a clear manner and thus delivers its point well. This work builds a lot on previous works and settings derived from them, so the ideas or experiments are not entirely novel or original.\n",
            "summary_of_the_review": "I believe the paper investigates an important aspect based on good intuition. However, the methodology developed seems to be quite obvious, and the resulting algorithm is not backed up with strong empirical evidence.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3640/Reviewer_EqZe"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3640/Reviewer_EqZe"
        ]
    },
    {
        "id": "64iElTjt3WS",
        "original": null,
        "number": 4,
        "cdate": 1667544694858,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667544694858,
        "tmdate": 1667544694858,
        "tddate": null,
        "forum": "nqoxB03tzi",
        "replyto": "nqoxB03tzi",
        "invitation": "ICLR.cc/2023/Conference/Paper3640/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Neural network pruning (also referred as pruning at initialization(PaI)) task involves balancing the tradeoff between model complexity and accuracy. This makes it a challenging task. In this paper, authors have proposed a few guidelines to design PaI methods that involve leveraging configuration of subnetwork 1) number of effective paths 2) number of effective nodes. Authors provide new insights to the working mechanism of PaI methods, and open new research directions on neural network pruning methods. Authors find that width of subnetworks and node-path balancing plays an important role in designing PaI subnetworks. Experiments were conducted using PaI methods like SNIP, SynFlow, and PHEW on different architectures( ResNet, VGG) and datasets (CIFAR, Tiny-Imagenet).",
            "strength_and_weaknesses": "Authors have well drafted the related work/background section, clearly outlining past work in neural network pruning, importance of nodes and connection configurations, extreme sparse network design. Empirical evaluation in the paper is very detailed - for example, sections on layerwise shuffling, impact on regular/extreme sparsities are intriguing.  Iterative pruning algorithm/Node-Path balancing principle described in the paper found to be very effective in optimizing the number of activated nodes and paths.\n\nIterative pruning algorithm to find a pruning mask described in the paper sounds to be similar to existing work in this literature and paper doesn\u2019t sound innovative from a theoretical point. Some subsections seek more details - for example, what is the motivation to introduce additional hyperparameters described in section 4, and statements like \u201cfindings indicate that pruning neural networks in the regular sparsity regime should give more consideration to the number of effective neurons since the information flow is conserved by the sufficient number of input-output paths.\u201d. Providing qualitative analysis around scheduler ablation experiments can help understand the empirical numbers better. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Underlying motivation of the paper is clear and approaches suggested in the paper makes sense.\nQuality/Novelty: Innovation in the paper sounds more empirical and less theoretical. Iterative pruning algorithm discussed in the paper doesn\u2019t sound innovative. Adding more details on hyperparameters would have helped understand a few sections. However, findings in the paper would be very helpful to the researchers working on designing PaI methods.",
            "summary_of_the_review": "This paper provides helpful empirical insights for designing pruning at initialization(PaI) methods. Experiments show the impact of the topology of subnetworks - specifically subnetwork configurations like 1) number of effective paths 2) number of effective nodes in designing PaI methods, and how to balance these metrics in regular sparsity vs extremely sparse scenarios. Experiments were conducted using PaI methods like SNIP, SynFlow, and PHEW on different architectures( ResNet, VGG) and datasets (CIFAR, Tiny-Imagenet). Please refer to strengths/weaknesses section for more details. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3640/Reviewer_uZiV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3640/Reviewer_uZiV"
        ]
    }
]