[
    {
        "id": "vC4-DiQ3dlu",
        "original": null,
        "number": 1,
        "cdate": 1666466450423,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666466450423,
        "tmdate": 1669039809747,
        "tddate": null,
        "forum": "wtQxtWC9bra",
        "replyto": "wtQxtWC9bra",
        "invitation": "ICLR.cc/2023/Conference/Paper5750/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes an benchmark (dataset and procedure) to evaluate the bias of human performance in the face recognition problem. To offer more information, the paper reports a set of similar tests on machine performance. ",
            "strength_and_weaknesses": "Strengths:\n - I totally agree with the paper that there is need in the research to evaluate the bias and compare the human performance with machine performance for the face recognition problem. Contribution here are welcomed\n- release of curated database with reference methods evaluated should help the field.\n- the paper is well presented and clear\n\nWeaknesses:\n1. The main issue of such paper is the following: how it was established the ground truth? By human annotation?! One key aspect of the paper is that it reports a 67%-83% accuracy of human observers accuracy. On other hand the limited number of persons in the authors team provides the ground truth. It is quite hard to take this as an established ground truth especially since there no is strong indication that experts (i.e. authors here) behave much better than normal persons. It is further said several time in the paper, that \"one\" of the authors revised the data to make sure that no errors are further passed. Yet a person has up to 83% accuracy and quite often 70%. Based on the data provided, curation by machine learning is preferred. \nAt the end of the paper it is noted: \"The labels and the means of collecting those labels is very important, and should almost always involve human review. We found that existing datasets\u2019 labels (often which used computer-generated labeling methods) were widely insufficient and riddled with errors which have downstream implications on analysis.\" I believe that this is true but is also applicable to the ground truth of this data, since there is no information that consensus of large number of experts was used.\n \nIn other words, in my view, the main limitation of the paper is that ground truth is not established accurately. A large number of observers should have been used and average where there is consensus should be placed as labels. \n\n2. The paper does not report the number of incorrect labels in LFW. From the data reported in the paper and in the supplementary material, it seems that the amount of errors was small and most of curation was about removing non-public persons. Unfortunately, in this way the contribution w.r.t the dataset is harder to establish.\n  ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and reproducible. There is novelty, but the problem lies in the accuracy of data.",
            "summary_of_the_review": "The paper aims to a direction where contributions are welcomed, and there is an auditorium at ICLR. The main  problem is that the accuracy of the data was not well established and in this case is critical.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "The paper starts by acknowledging that automatic face recognition has \"been criticized in recent years for their intrusive privacy concerns and differential treatment of various demographic groups.\" It accepts that is a sensitive manner.\nThe human evaluation has been carried with ethic approval  of the hosting university which is a strong argument for ethic and societal moral fairness.\n\nThe paper uses two databases that were criticized for using persons without public consent. Yet in the curation process, the authors \" undertook the \"task of labeling and categorizing individuals who they do not know and have not received consent from for this task\".\n\nOverall, I believe that the paper addresses ethical concern regarding the face recognition as best as possible.  ",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5750/Reviewer_VUfd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5750/Reviewer_VUfd"
        ]
    },
    {
        "id": "6dehOB9O0IL",
        "original": null,
        "number": 2,
        "cdate": 1666566143374,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666566143374,
        "tmdate": 1666566143374,
        "tddate": null,
        "forum": "wtQxtWC9bra",
        "replyto": "wtQxtWC9bra",
        "invitation": "ICLR.cc/2023/Conference/Paper5750/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors aim to answer two questions in this paper, \"How and to what extent do humans exhibit\nbias in their accuracy in facial recognition tasks?\" and \"How does this compare to machine learningbased models?\"  To address these questions the authors present improvements to the LFW and CelebA dataets as well as present an analysis showing that both humans and models result in lower accuracy on dark skinned and female subjects and humans obtain higher accuracy on the tasks when their demographics match the subjects in the data.  They also find that while academic models are comparable in gender bias compared to humans, they are significantly more biased against darker skin tones than humans.",
            "strength_and_weaknesses": "\nThe paper is clear and the work is well motivated.  It is certainly important to gauge model performance compared to humans.\n\nIt is great that the authors identify the weakness of these face datasets and present cleaned annotations and scrubbing of images that may not be desired in the set.\n\nFor some use cases, low quality images may be desired.  It may be preferable to include them but add a quality label to the annotations.  What are the specific thresholds used to decide to omit these images?\n\n\"old-timey\" should be better defined so as not to be subjectively determined.\n\nIf black and white and old-timey images were removed due to the being too easy to recognize as paired then this should be validated but no quantitative check is presented.\n\n\"We found that many questions could be answered without considering face features at all, and these\nwere removed. For example if the subject is wearing identical attire and/or standing in front of an\nidentical background in two images.\"  Again, this needs to be shown to be true quantitatively if the authors are referring to the models ability to match faces.  Many models will not use background features making the issue not as important as presented.\n\n\"While the Fitzpatrick scale is not perfect, it is the best systematic option currently for ensuring a\nbroad representation.\"  Not sure this is still true with the existence of the Monk scale which was specifically created for this task while Fitzpatrick was not, although Fitzpatrick is far more commonly used.\n\nWhat is the usefulness of the birth date if the date of image capture is not provided?\n\nIt would be helpful for future projects if more details on the process and workflow to manually check/verify the annotations in the data were provided.  Lessons learned and the final selected approach would be helpful for other researchers that are interested in a similar process.\n\nIt would be much better for the reader if results comparing the models and humans were presented in graphs, figures and tables to provide more detail than what is in Table 2.  This would also allow for high-level take-aways on the details to be better digestible.  A lot of specific statistical results are presented in the text but this should be reflected in figures as well.  Some details can be moved to an appendix if needed.\n\nIt would also be helpful to understand the per-human performance.  Some participants may be better at the tasks than others.  The human results would likely form a distribution of performance and this should be captured and compared to the per-model, and academic group as well as commercial group, model distribution.  The uncertainty from these distributions needs to be considered as we are comparing over multiple variables.\n\nOdds ratio is not commonly used by the face rec community so a better description may be helpful\n\nadditional metrics such as FMR and FNMR, or FAR and FRR, should be presented.  It would help to understand where the errors are occurring and if the disparities are a result of one type of error or the other.  This is also useful for comparing human to model performance.\n\nTypo at end of section 5: \" In this case, we see a bias towards question gender in favor of males\"",
            "clarity,_quality,_novelty_and_reproducibility": "The approach is clearly presented but lacks some details that would make the dataset scrubbing and annotation tasks fully reproducible.  This is a model vs human analysis paper so no training to replicate.  There have been other papers that have compared human to model performance so not completely novel but does present a larger study with more specific tasks than presented prior.\n\nIn general, the paper is lacking in quality that meets the standard of the conference as key metrics are missing and results should be more clearly presented and with more detail.",
            "summary_of_the_review": "The paper is clear and the problem is a good one to address but it lacks some key details and presentation limitations that reduce its score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5750/Reviewer_WUnQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5750/Reviewer_WUnQ"
        ]
    },
    {
        "id": "Ye2v9Fec8bE",
        "original": null,
        "number": 3,
        "cdate": 1666608866006,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666608866006,
        "tmdate": 1666608866006,
        "tddate": null,
        "forum": "wtQxtWC9bra",
        "replyto": "wtQxtWC9bra",
        "invitation": "ICLR.cc/2023/Conference/Paper5750/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Bias in face recognition is a significant area of research that has/will have a meaningful impact on analyzing and managing disparities in downstream applications. The authors of this paper propose enhancements to the existing face datsets such as LFW and CelebA by improving the available metadata and also devise experiments to measure the bias exhibited by humans and models during identification and verification tasks.\n",
            "strength_and_weaknesses": "Strengths: \n1. Well-written and structured\n2. Experimentally strong\n3. Results \n\nWeaknesses: \n1. Missing technical novelty. \n2. No mention of how the existing model architectures were revised for the task on hand. \n3. It is not clear if the apparent bias in data (eg certain age groups were more populated than others) while training/validating and testing.",
            "clarity,_quality,_novelty_and_reproducibility": "Detailed and well-written. Adding in missing details will help with reproducibility.",
            "summary_of_the_review": "Overall, a well-written paper. The findings are interesting but may not be extrapolated as suggested by the authors.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5750/Reviewer_TNQq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5750/Reviewer_TNQq"
        ]
    },
    {
        "id": "nh-hKskXvi",
        "original": null,
        "number": 4,
        "cdate": 1667262494166,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667262494166,
        "tmdate": 1667262494166,
        "tddate": null,
        "forum": "wtQxtWC9bra",
        "replyto": "wtQxtWC9bra",
        "invitation": "ICLR.cc/2023/Conference/Paper5750/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a study that compares disparities and bias between humans and machines in performing face verification and recognition in challenging conditions. The authors use two datasets named LFW and CelebA for these studies. Human experiment consists of randomly sampled subjects answering verification/identification questions and machine experiments were run using existing academic and commercial models.    ",
            "strength_and_weaknesses": "Strengths:\n- To the best of my knowledge, this is the first time such a study is done to compare human and machine bias on face verification/identification. \n- It looks like the authors have done a good job of curating the datasets by removing poor quality images and correcting the inconsistencies in its metadata. \n\nWeaknesses:\n- Other than curating the datasets, I do not see much scientific contribution of this work. All the algorithms used for conducting experiments are existing algorithms.\n- The results observed in the paper are expected results. I am not sure how these findings help in further improving the research in the face identification/verification area.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Other than curating the datasets, I do not see much scientific contribution of this work. All the algorithms used for conducting experiments are existing algorithms. \n\nThere are several grammatical errors in the paper. Also, it was hard to follow the writing in many sections of the paper.",
            "summary_of_the_review": "Overall I think the study presented in paper lacks novelty and the presented results are expected.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5750/Reviewer_NNHX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5750/Reviewer_NNHX"
        ]
    }
]