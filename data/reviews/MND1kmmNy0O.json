[
    {
        "id": "2iIMAqg2kk",
        "original": null,
        "number": 1,
        "cdate": 1666587215671,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666587215671,
        "tmdate": 1666672111303,
        "tddate": null,
        "forum": "MND1kmmNy0O",
        "replyto": "MND1kmmNy0O",
        "invitation": "ICLR.cc/2023/Conference/Paper4461/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper investigates different approaches to solve math word problems (MWPs), specifically on the GSM8K dataset. The authors compare training with 1) final answer correctness only (ORM), 2) each intermediate step's correctness (PRM), and 3) with different reward models for ORM and PRM. The authors find that 1) ORM and PRM achieve similar final answer correctness; 2) PRM and PRM fine-tuned models learn to emulate step-by-step generated solutions; 3) PRM (or similar approaches) is required to improve the correctness of each intermediate solution step; and 4) allowing the model to abstain significantly improves performance (on the not-abstained solutions).",
            "strength_and_weaknesses": "### strengths\nI believe the paper is on an important direction. A systematic evaluation of different approaches for MWP solving is very much appreciated and needed.\n\n\n### weaknesses\nI wish the results and analyses can go a bit deeper than what have been presented. The main 4 results appear in the paper multiple times and, along with the detailed experiment setup (which I appreciate), can be more succinct (or move some to appendix to highlight the major findings). The authors investigations seem to center around two approaches to fine-tune the model (e.g., output vs. process-based rewards). I think a few other settings can also be considered, such as whether there is a prompt for fine-tuning/inference (similar to few-shot) and the number of examples used in the prompt. Or compare different decoding schemes. \n\nAs a scientific investigation paper, I expect deeper analyses, in addition t o simply presenting the observations, to enable finding more insights (at present, most of the results in the paper are somewhat expected). For example (a few suggestions):\n- ORM and PRM give roughly the same final-answer correctness. Could the authors design an experiment to investigate why this is the case, e.g., empirical evidence to support the hypothesis it is \"simpler for ORM to recognize when steps are correct than it is to check the answer by internally computing the final answer itself\"?\n- The authors claim ORM seems to learn to emulate the PRM. How does it do that, even without explicitly being supervised on the correctness of each intermediate step? ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and well presented. ",
            "summary_of_the_review": "The depth (both technical and experimental aspects) of the paper feels more like a workshop paper (or can be written more succinctly to summarize the main findings). If the authors intend to present their work as a scientific investigation, I encourage the authors to more systematically consider the scientific questions and experimental evaluations. I look forward to deeper insights that the authors can bring on the different approaches that current/existing methodologies are tackling MWP solving and how these approaches compare to each other. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4461/Reviewer_GLbN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4461/Reviewer_GLbN"
        ]
    },
    {
        "id": "huJRuAzCjf",
        "original": null,
        "number": 2,
        "cdate": 1666681931468,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666681931468,
        "tmdate": 1666681931468,
        "tddate": null,
        "forum": "MND1kmmNy0O",
        "replyto": "MND1kmmNy0O",
        "invitation": "ICLR.cc/2023/Conference/Paper4461/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The papers study the finetuning of LLMs for solving maths problems. In particular, comparing training partial vs overall correctness. While the evaluation shows that both produce similar global accuracy, partial correctness requires feedback of that kind. The paper considers multiple existing alternatives for both kinds of signals. A group of them manage to get significant improvement, but there is not a clear combination that helps, perhaps because some of the methods are similar. ",
            "strength_and_weaknesses": "Strengths\n- Scholarship on methods for training for correctness.\n- Some combinations of methods produced significant improvements.\n- Good attempt to synthesize the empirical observations\n\nWeaknesses\n- The organization of sections 2.3 to 2.5 is a bit confusing. Perhaps there are too many combinations in each block of Table 1. Even when I attempt to re-read, I remain confused about how the vertical caption \"RM rerank\" is related to the RM using majority, ORLM or PRM. \n\t- The legend of Fig 3 is also revealing. There are three axis combines in partial combinations, but only some combinations appear. \n\t- I'd consider working backwards from the findings, and reducing the number of experiments to show. That might imply moving some results to the appendix and keeping only short comments in the main body on how other methods give similar results.\n- I find it hard to know if the multiple decisions/hyper-parameters per method could be affecting the validity of the results.\n- The observation that the models get away with correctness while failing at intermediary steps might be explained by an easier chance to introduce artifacts/shortcuts that improve the accuracy.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written. I think the lack of clarify comes from the selection of results. The work is novel as organized experiments using mostly existing methods.\n\nQuestions:\n- It is possible to solve the problem with actions in a different order. If so, does that affects the claim of the paper?\n",
            "summary_of_the_review": "The paper considers the kind of supervision for MATH reasoning problems using LLM. The line of work is important, but I'm afraid it's hard to get concrete lessons from the paper. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4461/Reviewer_pkRc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4461/Reviewer_pkRc"
        ]
    },
    {
        "id": "kpJLCuTtQZ",
        "original": null,
        "number": 3,
        "cdate": 1666762190423,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666762190423,
        "tmdate": 1666762190423,
        "tddate": null,
        "forum": "MND1kmmNy0O",
        "replyto": "MND1kmmNy0O",
        "invitation": "ICLR.cc/2023/Conference/Paper4461/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "\nMost of the recent work on language models for solving math word problems relies on prompting engineering. Instead, this paper studies how to finetune the language models for solving math word problems with outcome-based and process-based approaches. The paper develops two metrics: race error rate and final-answer error rate. The paper implements multiple outcome-based and process-based approaches and conducts experiments on a recently proposed dataset, GSM8K. The best model could improve the previous best results from 16.8% to 12.7% final-answer error and from 14.0% to 3.4% trace error.\n",
            "strength_and_weaknesses": "**Strengths**\n\nThe paper comprehensively compares process- and outcome-based approaches on the math word problem dataset, GSM8K. It reports many impressive results of outcome-based and process-based approaches on final-answer error rates and trace errors. These results are meaningful for the follow-up work to develop models with both low error rates and trace errors. Figure 3 is very informative and shows that the trace errors are associated with final answer errors, especially when final answer errors are low.\n\n\n**Weaknesses/Feedback**\n\n**1. The methods have limited modeling novelty.** \n\nIt is good to see that the paper conducts the *first* comprehensive comparison between process- and outcome-based approaches trained on the math word problem-solving task. The paper conducts extensive experiments on the two types of approaches, and there are a lot of interesting findings. However, it seems that the paper does not propose a new method.\n\n**2. All the experiments are conducted on only one dataset.** \n\nI understand that there are some limitations for other datasets, and conducting experiments on new datasets leads to extra costs. However, whenever the annotation pipeline is set up, the additional costs of conducting experiments on new datasets are acceptable. It is worthwhile to conduct the experiments on smaller datasets. A recently proposed MWP dataset, TabMWP (https://arxiv.org/abs/2209.14610), might be a good benchmark for the experiments in the revised paper, which is annotated with multi-step reasoning steps.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-organized and easy to follow. However, the paper appears to have made only a minor contribution to modeling novelty. ",
            "summary_of_the_review": "The paper is interesting to me, but there are two main concerns: the methods have limited modeling novelty, and all the experiments are conducted on only one dataset. It would be helpful to see revisions regarding these two concerns.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4461/Reviewer_ytw5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4461/Reviewer_ytw5"
        ]
    }
]