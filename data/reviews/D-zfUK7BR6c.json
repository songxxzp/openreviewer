[
    {
        "id": "Y034h9pHHLV",
        "original": null,
        "number": 1,
        "cdate": 1666413401072,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666413401072,
        "tmdate": 1666413401072,
        "tddate": null,
        "forum": "D-zfUK7BR6c",
        "replyto": "D-zfUK7BR6c",
        "invitation": "ICLR.cc/2023/Conference/Paper193/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Hi, I'm currently on a medical leave and won't be able to perform ICRL review duties. sorry for the late notice.",
            "strength_and_weaknesses": "Hi, I'm currently on a medical leave and won't be able to perform ICRL review duties. sorry for the late notice.",
            "clarity,_quality,_novelty_and_reproducibility": "Hi, I'm currently on a medical leave and won't be able to perform ICRL review duties. sorry for the late notice.",
            "summary_of_the_review": "Hi, I'm currently on a medical leave and won't be able to perform ICRL review duties. sorry for the late notice.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper193/Reviewer_n4R4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper193/Reviewer_n4R4"
        ]
    },
    {
        "id": "hHsNjKtALw",
        "original": null,
        "number": 2,
        "cdate": 1666605034271,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666605034271,
        "tmdate": 1666605034271,
        "tddate": null,
        "forum": "D-zfUK7BR6c",
        "replyto": "D-zfUK7BR6c",
        "invitation": "ICLR.cc/2023/Conference/Paper193/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The proposed approach exploits an empirical property of the latent space of multimodal embedding (essentially image & text) revealed in (Liang et al., 2022): the fact that the two modalities are embedded in different parts in the latent space, inducing a modality gap. The paper extends the results by empirically stating that the two embedded modalities are correlated by a quasi constant shift, easing cross-modal transferability, and that the data manifolds are orthogonal to the modality gap.The multi-modal correlation is used to analyze the quality of vision based prediction on three tasks: discovering hard examples described by sets of attributes (error slices), scoring attributes by their impact on performance using Shapley  values, and by fine tuning a given model using text data augmentation. \n",
            "strength_and_weaknesses": "== Strengths ==\n- The paper is well written and easy to follow.\n- Well justified exploitation of multimodal embedding and of their empirical properties \n- Application on three rather original tasks using cross-modal transferability\n\n== Weaknesses ==\n- The findings (structure of the embeddings) are empirical and not justified by the (contrastive) learning scheme.\n- The three tasks are more illustrations of the multimodal embedding properties than complete studies: they are not fully developed or analyzed.\n",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity and quality\n\nThe results show how the embedding structure can be exploited on three cross-modal tasks. However, I found their analysis a little short: for instance, the literature about feature importance is quite large, even in a multimodal setting [1] and the approach should have been compared to others.\n\n[1] Joshi, G., Walambe, R., & Kotecha, K. (2021). A review on explainability in multimodal deep neural nets. IEEE Access, 9.\n\nThe geometric structure is only verified empirically. As such, more rigorous statistical testing could have been developed, for instance a chi-2 to test if the modality gap is constant.\nAbout the \u201cconstant\u201d modality gap: is there a theoretical justification of it? How general is this phenomenon? Is it a consequence of using contrastive learning ?\n\n- Novelty\n\nAnalyzing the geometrical structure of large scale multimodal embeddings, as far as I know, has been seldom done, with the exception of (Liang et al., 2022) from which the paper is built. \n\n- Reproducibility\n\nAn anonymous GitHub link with the code is provided.\n",
            "summary_of_the_review": "The paper pursues the analysis of the modality gap initiated by (Liang et al., 2022) and discusses another finding: the almost constant distribution of this modality gap and its geometry with respect to the data manifolds. It proposes three original tasks that exploit the results. They are, however, mostly empirical, and could have been verified with better statistical justification; the analysis of the tasks is also not very thorough.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "The paper discusses the potential use of multimodal embedding for model accountability or auditing, but also the risk of using it to generate biases.\n",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper193/Reviewer_Wtjn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper193/Reviewer_Wtjn"
        ]
    },
    {
        "id": "_ywwTeUNIPZ",
        "original": null,
        "number": 3,
        "cdate": 1666629210823,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666629210823,
        "tmdate": 1673294113084,
        "tddate": null,
        "forum": "D-zfUK7BR6c",
        "replyto": "D-zfUK7BR6c",
        "invitation": "ICLR.cc/2023/Conference/Paper193/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Based on observation in Liang el al., 2022 on the modality gap, the paper further proves that the modality gap in multi-modal settings has not influence on the prediction of classifiers, and thus enables cross-modal transferability. The papers further shows that texts can be used as a proxy for image inputs, and provides a method (DrML) to use natural language to identify data subsets (error slices) and the most influential attribute. Their approach is validated on 3 benchmark datasets and shows at some certain level being more convenient than given baselines since this method can diagnose models without requiring diverge visual data collection/creation. The paper further presents a method to rectify undesirable model behaviours based on generating a larger language dataset related to the error slice and continue model training on these.",
            "strength_and_weaknesses": "Strengths\n\n[S1] Ideas are presented with full examples and explanation then it makes paper easy to follow.\n\n[S2] The main contribution of the paper is the theoretical and empirical verification  of the ability to use text as a proxy for image inputs.\n\n[S3] The novelty of the idea to use natural language (which is deemed to be inherently interpretable) to diagnose machine learning models and at the same time addressing the problem of lacking diverge real life vision data.\n\nWeaknesses\n\n[W1] Prior knowledge needed to select a suitable attribute set A. \n\n[W2] Missing comparison to SoA. \n\nDetails\n- The way of choosing attribute set A initially could be a concern. It seems that the degree of diversity and size of the generated text input set partially depends on the chosen of attribute set A. Without any prior knowledge of spurious correlation within the dataset, it would be hard to choose a really 'related' set A. For example, in the dataset WaterBird, it is widely known the spurious correlation is the bird class and the background, then the attribute was picked are 'bird species\u2019 and \u2018places\u2019. In the case of unknown prior knowledge, one might fail to point out the expensive attributes.\n- It is hard to judge whether the method has \u2018diagnosed\u2019 vision classifiers thoroughly. The authors compare to GDRO which (requires annotations) and  focuses on increasing the worst-group accuracy, which is not addressed by Rectify. Only generating more data on error slice and keep continue training is not expected to help when a model is already biased. There are other works that the authors reference, such as Just Train Twice (Liu et al, 2021), which also do not require annotations.",
            "clarity,_quality,_novelty_and_reproducibility": "The ideas in paper are delivered clearly and easy to follow. The proof of theory part for me is enough, clear and correct.\n \nTable 6 is a bit hard to follow since both, error slice and the best accuracy are highlighted in bold.\nAlso in Table 6, I am not sure if DRO\u2019s performances is taking from original paper or by author\u2019s own implementation. The authors use 3 public datasets (WaterBird, FairFace, dSpitesV), and provides the source code which makes their work reproducible. ",
            "summary_of_the_review": "The paper introduces a novel idea of how to use natural language to diagnose vision classifiers. This method can be understood easily by practitioners, and addresses the lack of out-of-distribution data in one modality. However, there are still some concerns w.r.t. to the method and comparison to SoA.\nTo the best of my knowledge, this is the first work being able to use natural language to discover error slice of vision classifier and extending language data instead of vision data to correct data bias problem. Other works do research on multi-modal and the phenomenon of modality gap but not emphasize on purpose of diagnosing model. My biggest concern is that author does not provide any proper reasons how they could pick the attribute set. The choice of the attribute set may affect the method performance significantly. In their experiments on the effectiveness of the rectifying method, the paper misses the comparison to related work, they use only one other method (GDRO), while stronger baselines are available.\n\nEdited after author rebuttal: \nI appreciate the authors effort on addressing my concerns and their improvements of the paper. Specifically, the authors added a comparison to SoA (experiments) and a discussion on attribute selection (in the appendix). I adjusted my rating. I would appreciate a short note on the manual need for attribute selection in the main body of the paper. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper193/Reviewer_yEKt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper193/Reviewer_yEKt"
        ]
    },
    {
        "id": "a5JMb1FpJL",
        "original": null,
        "number": 4,
        "cdate": 1667021887407,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667021887407,
        "tmdate": 1667021887407,
        "tddate": null,
        "forum": "D-zfUK7BR6c",
        "replyto": "D-zfUK7BR6c",
        "invitation": "ICLR.cc/2023/Conference/Paper193/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper explains why cross-modal transferability happens even if there is a modality gap. Authors have shown this empirically on various datasets and have also theoretically proved it as well. By proving this, they demonstrate that text can be a good proxy for images. Based on this assumption, they introduce a new framework, DrML, which can discover error slices, identify influential attributes and correct misbehavior of the model.\n\n",
            "strength_and_weaknesses": "**Strength**\n- They prove that the phenomenon of pervasive cross-modal transferability occurs when the modality gap meets certain conditions by empirically and theoretically.\n- It was made human-interpretable by explaining the model's error using languages as well as images.\n- The proposed framework further rectifies the behavior of the models. \n\n**Weakness**\n- The explanation of the process of correcting the misbehavior of the model using language may need more detail.\n- Few parts of the proposed framework are not justified well (Details are in Clarity 2.)\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity : I could clearly understand, except for a few parts.\n- I don\u2019 t know the exact meaning of the term \u201cclosing the modality gap\u201d. I wonder if it simply means reducing the modality gap or includes other meanings.\n- I wonder what the process of figuring out influential attributes means in your framework, DrML. As far as I understand, it seems that the model is rectified using error slices but I don't know how the influential attribute is used. Is this just to provide additional information to humans?\n\nQuality : The main claims are well-supported by various experiments and theoretical proof.\n\nNovelty : This paper looks to contribute some new ideas.\n\nReproducibility : Most of required information for reproducibility is provided.\n",
            "summary_of_the_review": "This paper demonstrates their assumptions about cross-modal transferability in several ways, and experiments are also conducted on several datasets. Also, they introduce a new framework, DrML, that can rectify the model\u2019s misbehavior. In sum, I think the proposed idea looks novel and may shed new light on diagnosing models. However, there are some questionable points when understanding this paper. I think it could be accepted if these are improved.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper193/Reviewer_LGzN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper193/Reviewer_LGzN"
        ]
    }
]