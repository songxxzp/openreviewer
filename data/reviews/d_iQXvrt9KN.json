[
    {
        "id": "TLexUZo2WCi",
        "original": null,
        "number": 1,
        "cdate": 1666530854222,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666530854222,
        "tmdate": 1666530854222,
        "tddate": null,
        "forum": "d_iQXvrt9KN",
        "replyto": "d_iQXvrt9KN",
        "invitation": "ICLR.cc/2023/Conference/Paper1778/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Word segmentation is an essential preprocessing step in languages like Chinese that requires tokenization and boundary insertion. Most of studies in Chinese word segmentation focus on the encoder and do not refine the decoder part, to tokenize the segments into more fine-grained words. More accurately, the authors introduce another network called \"Multi-grained decoder module\" on top of the conventional CWS model architecutre. The authors tackles OOV problems in Chinese and experimentally show that the proposed approach of \"Boundary-Enhanced Decoder\" is effective in extensive experiments.",
            "strength_and_weaknesses": "Strengths\n- The idea is straightforward and relatively simple\n- The results support the author's claim that the proposed approach works better\n\nWeakness\n- even though we see consistent improvement across dataset, the model's performance already looks saturated. From the human perspectives, e.g. +0.15 is significant difference? Did you do significant test against the baselines?",
            "clarity,_quality,_novelty_and_reproducibility": "- In Table 2, we can see accuracy get better by introducing the proposed approach, though do you have any comparison accuracy scores of the previous work?\n- How did you create Chinese vocabulary inn your experiment? You should clarify it even if you use BERT model's vocabulary.\n- The authors claim that the proposed approach addresses the OOV issue in Chinese, but I am not clear how to be resolved. Do you have a good example for this claim?",
            "summary_of_the_review": "This paper proposes a simple and effective approach to improve Chinese word segmentation. By introducing a new network on top of the decoder, the authors addresses the OOV issue as well as words segmentation. The experimental results show that the proposed approach bring 0.05%-0.69% improvement on average F1 and OOV average F1 scores on multiple benchmark datasets. The authors only compare their results agains the vanilla Chinese word segmentation approaches and show the effectiveness, however, they also need to report the performance comparison agains the previous work.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1778/Reviewer_2k3q"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1778/Reviewer_2k3q"
        ]
    },
    {
        "id": "5_RJZCVpUbH",
        "original": null,
        "number": 2,
        "cdate": 1666589381202,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666589381202,
        "tmdate": 1666589381202,
        "tddate": null,
        "forum": "d_iQXvrt9KN",
        "replyto": "d_iQXvrt9KN",
        "invitation": "ICLR.cc/2023/Conference/Paper1778/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposes an approach for Chinese word segmentation that is happening in the final prediction layer. First, a binary prediction is performed for each position as a preliminary judgement of word segmentation. Then, the binary decision is transformed as a span-wise decision representing a masking for self-attention mechanism. Finally, a CRF is used to assign tags, i.e., E, S, M, B, to perform word segmentation. Experiments are carried out on four standard Chinese word segmentation tasks and show consistent gains when using various vector representations, e.g., BERT.",
            "strength_and_weaknesses": "Strength\n\n* This work is interesting in that the task is decomposed into two steps, one for rough segmentation which is transformed as making for interpreting representations inputs with explicit boundaries before the final prediction.\n\n* Small gains on top of conventional word embeddings, e.g., BERT.\n\nWeakness\n\n* It is a bit hard to follow the descriptions in this paper, and needs further work on improving presentation including mathematical notations.\n\n* It is not clear how p is derived in Equation 11, which is probably representing a probability of a span. Note that p is used as a probability of segmentation in Equation 10 which is basically a binary decision, and i is used as a position and j is meant to represent the index to the training instance. However, the meaning for i and j seem to be different from previous equations.\n\n* Given that the binary prediction is helpful in this work, it is not clear why this work still relies on BMES notation. Probably it would be good to report a model which simply do binary prediction.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Some parts of this paper is unclear and needs further rework on improving the quality. In particular, an important part, i.e., the probability of span used for masking, is missing, that seems to be critical in the proposed model. Thus, this work is harder to reproduce.",
            "summary_of_the_review": "This work presents an interesting work on Chinese word segmentation that combines binary decision to perform rough segmentation before the fine grained segmentation by CRF. However, this work has a clarity issue and needs further experiments to justify the results.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1778/Reviewer_xn6T"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1778/Reviewer_xn6T"
        ]
    },
    {
        "id": "pHsFBJSXU7",
        "original": null,
        "number": 3,
        "cdate": 1666668951096,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666668951096,
        "tmdate": 1666668951096,
        "tddate": null,
        "forum": "d_iQXvrt9KN",
        "replyto": "d_iQXvrt9KN",
        "invitation": "ICLR.cc/2023/Conference/Paper1778/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper addresses the decoder improvements in Chinese Word Segmentation (CWS). The authors state the contribution of the previous CWS models are limited in the encoder.\n\nThey proposed the optimization of the decoder of Boundary-Enhanced Decoder (BED). Based on the conventional CRF decoder, the BED model introduces Boundary-Enhanced Decoder, which is composed of two modules: boundary detection module and fine-grained decoder module. Boundary detection module determines the end of the words. Multi-grained decoder module includes coarse-grained segmentation, a transformer encoder, and a normal decoder layer.\n\nI do not consider that the improvement of the encoder part is novel for sequence labeling including CWS. In sequence labeling, many approaches are adopted including hierarchical softmax or refinement of attached labels (non-autoregressive). Considering these preceding studies, it is questioning, the improvement of the decoder is novel in CWS.\n",
            "strength_and_weaknesses": "- The strength: authors achieve the better results with the proposed BED, although the improvements are relatively limited.\n\n- The weakness is that it is questionable that the improvement of the decoder is novel. The related work is limited for the improvement of the decoder in CWS.\n",
            "clarity,_quality,_novelty_and_reproducibility": "- The boundary detection module is also related to transition-based approaches that iteratively perform the shift and append transitions to determine the boundaries of words. This paper doesn't follow board CWS approaches in related work.\n\n- Possible Typo\nCaption for Figure2:\n\nFine-grained Decoder Module -> Multi-grained Decoder Module ?\n",
            "summary_of_the_review": "I'm not certain that the proposed model is novel and significant enough to reach the high-bar of the ICLR conference. I rather prefer this paper is also reviewed in a specific domain of the community.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1778/Reviewer_wqVM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1778/Reviewer_wqVM"
        ]
    },
    {
        "id": "zjmbHKe236",
        "original": null,
        "number": 4,
        "cdate": 1666871870564,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666871870564,
        "tmdate": 1666872670214,
        "tddate": null,
        "forum": "d_iQXvrt9KN",
        "replyto": "d_iQXvrt9KN",
        "invitation": "ICLR.cc/2023/Conference/Paper1778/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "CWS models are subjected to OOV words. This paper proposes an optimized decoder for the CWS model called Boundary-Enhanced Decoder (BED), which looks for easily tokenized positions, divides a whole sentence into several parts first, and then tokenizes each\npiece into more fine-grained words. This more intuitive approach can further improve the performance of the word segmentation model.",
            "strength_and_weaknesses": "Strength:\n1. The motivation of this paper is very clear to optimize decoder for the CWS model to better tackle OOV problem.\n2. The paper is easy following.\n\nWeaknesses:\n1. The innovation of this paper is not very strong. It aims to optimize decoder for the CWS model and announce that \"it is the first study trying to optimize the decoder part in a CWS model\". However, a lot of previous work on CWS indeed consider decode constraint and transition based CWS work could be viewed as a typical work managing decoder.\n2. A lot of related papers are also missing as point 1 states that some previous related work is not mentioned.\n3. The experimental part is not very convincing. The comparison is not solid too. I didn't see previously work numbers well compared.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The innovation of this paper is not very strong. It aims to optimize decoder for the CWS model and announce that \"it is the first study trying to optimize the decoder part in a CWS model\". However, a lot of previous work on CWS indeed consider decode constraint and transition based CWS work could be viewed as a typical work managing decoder.",
            "summary_of_the_review": "I think this paper need to be revised and polished on both motivation part and experimental part.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1778/Reviewer_1QHU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1778/Reviewer_1QHU"
        ]
    }
]