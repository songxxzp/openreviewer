[
    {
        "id": "kU0QsgirW8",
        "original": null,
        "number": 1,
        "cdate": 1666591267948,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666591267948,
        "tmdate": 1666591267948,
        "tddate": null,
        "forum": "hT1S68yza7",
        "replyto": "hT1S68yza7",
        "invitation": "ICLR.cc/2023/Conference/Paper4496/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The author found that the neural responses of macaques to facial visual stimuli are very similar to the w-space of styleGAN3. Specifically, the neural response of the macaques' brain can be decoded into w-space using linear mapping, and the corresponding generation faces are similar to the perceived stimuli. Also, the reconstructing looks similar when applying the same linear operations on the brain activity and the latent.",
            "strength_and_weaknesses": "Strength:The author finds evidence that the neural face manifold and the disentangled w-latent space conditioned on StyleGAN3 are similar in how they represent the high-level semantics of the high-dimensional space of faces. Especially, the StyleGAN3 has never been optimized on neural data.\n\nWeaknesses: \n1) Why the author use a AlexNet pretrained on object recognition task rather than on the face recognition task? What is the different between the cosine similarity from the AlexNet and the VGGFace?\n2) For the conclusions in the summary, \u201cThis provides strong evidence that the neural face manifold and the disentangled w-latent space conditioned on StyleGAN3 (rather than the z-latent space of arbitrary GANs or other feature representations we encountered so far) share how they represent the high-level semantics of the high-dimensional space of faces\u201d, the author should add some qualitative comparison to make a visual support. Also, the qualitative comparison can give the reader a visual feeling of the difference in image space caused by the difference in six decoding performance evaluation metrics.\n3) The gap between the z-latent and w-latent in the \u201cAlexnet sim\u201d and \u201cVGGFace sim\u201d are much more lower than in the \u201cLat. sim.\u201d and the \u201cLat. corr.\u201d, how does the author explain this phenomenon? How much does the difference in \u201cAlexnet sim\u201d and \u201cVGGFace sim\u201d affect the reconstruction image quality? If the visualized difference is not obvious, it will weaken the conclustion that \u201cThis provides strong evidence that the neural face manifold and the disentangled w-latent space conditioned on StyleGAN3 (rather than the z-latent space of arbitrary GANs or other feature representations we encountered so far) share how they represent the high-level semantics of the high-dimensional space of faces\u201d in the abstract. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The experiments are not based on a public dataset and no implementation was released, which makes difficulty of reproduction.",
            "summary_of_the_review": "This paper provides evidence that the neural face manifold and the disentangled w-latent space conditioned on StyleGAN3 are similar in how they represent the high-level semantics of the high-dimensional space of faces. But more comparison are suggest to be added between the reconstruction quality of z-latent and w-latent.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4496/Reviewer_1pMd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4496/Reviewer_1pMd"
        ]
    },
    {
        "id": "HFgUHMKVCU",
        "original": null,
        "number": 2,
        "cdate": 1666671285044,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666671285044,
        "tmdate": 1666671285044,
        "tddate": null,
        "forum": "hT1S68yza7",
        "replyto": "hT1S68yza7",
        "invitation": "ICLR.cc/2023/Conference/Paper4496/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper is about \"Neural coding\", that is to characterize the biological brain recognization. They used a StyleGAN3 to synthesis several high solution images, and show those images to a 7 years old macaque , and recorded its multi-unit brain activity. Finally, they use several latent similarity metric to compute distant z and w space. Finally, they conclude that StyleGAN3 W space is better than Z space in decoding performance. ",
            "strength_and_weaknesses": "Pro: \nThe idea to evaluate StyleGAN3 W space and Z space by using a macaque is interesting. \nThe experiments are extensive and solid. \nCon:\nI believe this paper is more experimental. There is not much novelty. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The experiments and writing are clear and sound. It might be hard to reproduce the result, since it needs a macaque.\n",
            "summary_of_the_review": "It is my first time to  know \"neural coding\" field. \nThe experiments that to explore brain actively with neural representation is interesting. \nAlthough the there is a face that StyleGAN3 W space is more disentangled than Z space, the experimental shows its closer relationship to brain perceived stimuli is exciting.  \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4496/Reviewer_4n7A"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4496/Reviewer_4n7A"
        ]
    },
    {
        "id": "VUgdajX6Uew",
        "original": null,
        "number": 3,
        "cdate": 1667022696165,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667022696165,
        "tmdate": 1669673197270,
        "tddate": null,
        "forum": "hT1S68yza7",
        "replyto": "hT1S68yza7",
        "invitation": "ICLR.cc/2023/Conference/Paper4496/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the encoding and decoding of faces in the (macaque) brain. To study decoding, they generate faces by sampling a random vector from the latent space of a GAN. They show the faces to a macaque monkey and record the neural response. A linear model is trained to map the neural response to the latent vector that produced the face image. On test data, they find that the recovered vector can be used to produce a high quality image of a face that matches the original face qualitatively and quantitatively. To study encoding, they map the activations of a trained vision model (AlexNet, VGG16) to the neural response. They find that correlation with the neural response increases with depth in the machine model.",
            "strength_and_weaknesses": "# strengths\n- New macaque monkey data.\n- This seems like the first attempt at reconstructing faces from intracranial data. (Is it?) If so, that should be mentioned somewhere\n- The reconstructed images are impressive\n\n# weaknesses\n- I have concerns about the originality of this work. Decoding high quality faces from brain signals has been previously accomplished (Dado et al. 2021, VanRullen and Reddy 2019, G\u00fc\u00e7l\u00fct\u00fcrk and G\u00fc\u00e7l\u00fc 2017). The decoding and encoding techniques, namely the use of GAN latent spaces, have already been discussed in previous works. In this work, the authors use a slightly different model (StyleGAN3 vs StyleGAN), but the overall methods remain the same.\n- The analysis of reconstructed faces in terms of attributes is also introduced in these previous works. (The authors do acknowledge this)\n- I think the paper could be much improved if the relationship with previous works were more clearly explained.\n- The novel contribution of this work seems mainly to be the newly collected data. But even this is only done for one subject.\n- The difference between the $w$ latent space and $z$ latent space could be explained more clearly. It's mentioned that the $w$ latent space is obtained by passing the $z$ latent space through an MLP, but since it results in much better reproductions (relative to $z$), could the authors explain a little bit more about what makes the two spaces different?\n\n## references\n- Dado et al. 2021 Hyperrealistic neural decoding: Reconstructing faces from fMRI activations via the GAN latent space (https://www.biorxiv.org/content/10.1101/2020.07.01.168849v3.full)\n- VanRullen and Reddy 2019 Reconstructing faces from fMRI patterns using deep generative neural networks https://www.nature.com/articles/s42003-019-0438-y\n- G\u00fc\u00e7l\u00fct\u00fcrk and G\u00fc\u00e7l\u00fc et al. 2017 Reconstructing perceived faces from brain activations with deep adversarial neural decoding",
            "clarity,_quality,_novelty_and_reproducibility": "- originality: many previous works should be mentioned (see above section). As it stands, I don't think this paper adds a lot of novelty.\n- clarity: Clarity is good. Some figures (figure 7) have hard to read portions.\n- reproducability: The authors have said they will release the data, including the macaque data and code\n- quality: The reconstructed images are impressive. But confidence in the significance of these results could be improved by a more complete discussion of the permutation test results. (See below) \n\n# questions/minor comments\n- figure 8B: typo - \"Brunet\" --> \"Brunette man\"\n- Section 2.3.2 $Y_i$ is defined, but I can't see where it is ever used?\n- figure 7A: Hard to see the texture of VGG16\n- If it's simple to produce, could we see a plot of all electrode locations?\n- The authors mention a permutation test in section 3.1? Could we see the full results of the permutation test? What is the average closeness of the random latent vector to the ground truth? ",
            "summary_of_the_review": "The reconstruction results are impressive, but have already been accomplished in many previous works. The decoding techniques are not significantly different than what was introduced in prior work, although the data is new. But even then, the data consists only of neural recordings for a single subject.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4496/Reviewer_1cBk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4496/Reviewer_1cBk"
        ]
    }
]