[
    {
        "id": "7a9z0lJhZla",
        "original": null,
        "number": 1,
        "cdate": 1665838342695,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665838342695,
        "tmdate": 1665838342695,
        "tddate": null,
        "forum": "jny79Mfgkno",
        "replyto": "jny79Mfgkno",
        "invitation": "ICLR.cc/2023/Conference/Paper1177/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This submission studies an architecture to learn from data with missing values. The architecture is based on chaining two transformations with an attention module that enables modeling the set of observed values. The model learns by randomly masking the training data to ensure learning from different subsets of the variables.\n\nThe authors introduce information-theoretical considerations to justify the approach, reasonning on properties of embeddings in the presence of missing values.\n\nThe authors then empirically demonstrates their theoretical considerations and validate their approach on many datasets from openML with MCAR, MAR and MNAR simulated missingness by comparing the prediction accuracy to LightGBM.\n",
            "strength_and_weaknesses": "\nModeling prediction in the presence of missing values, with suitable architectures is an important problem.\n\nI feel that there are some implicit, or poorly-stated, assumptions behind the theoretical claims. For instance, it seems that I can create counter examples to prop 2: for a 5-dimensional feature space (X0, X1, X2, X3, X4), using Y = 1 is X0 is missing and 0 if not and f(U) = sum_U. I have then a non-zero mutual information I(U_i, Y) each time U_i contains X0, and elsewhere a zero mutual information, but this is quite independent of the value of f(U).\n\nReading the code source, I see 18 hyper-parameters for LSAM: regularization, optimization, and architectural hyperparameter (for f and g). How were they made for each experiment? In particular: what was the train-test-validation split strategy?\n\nThe fact that LSAM+iterative works as well as LSAM seems to me a bit contradictory with the spirit of LSAM, if I have understood things well. Indeed, I thought that the spirit of LSAM what to optimize jointly the representation of the missing values and the subsequent predictor.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "I found the paper hard to follow, as I could only slowly develop understanding of where the authors were trying to go, and after reading it fully, I still feel that I am second-guessing some of the assumptions and choices of the authors.\n\nThe manuscript starts heavy on the formalism, but light on the theoretical results. Where are the proof of prop 1 and 2?\n\nWith regards to novelty, I find that the paper has some novelty, but is not clearly positioning itself. Overall, it lacks clear formulations of both prior art and contribution.\n\nThe work should position itself with regards to the results of Le Morvan et al. \"What\u2019sa good imputation to predict with missing values?.\" NeurIPS 2021, as they are very relevant to the theoretical points made forward in the beginning of the paper.\n\nWith regards to reproducibility, the authors share the code, which should ensure reproducibility.\n",
            "summary_of_the_review": "The ideas of the papers are interesting, but they are not very well formulated, established, and positioned.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1177/Reviewer_ezY7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1177/Reviewer_ezY7"
        ]
    },
    {
        "id": "4ni9iJyUqP",
        "original": null,
        "number": 2,
        "cdate": 1666631429897,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666631429897,
        "tmdate": 1666631429897,
        "tddate": null,
        "forum": "jny79Mfgkno",
        "replyto": "jny79Mfgkno",
        "invitation": "ICLR.cc/2023/Conference/Paper1177/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The author proposed a framework that treats model fitting with missing values as a latent space regularization problem using measure theoretical arguments. Specifically, the author translates the effect of missing values in the data space into the decreased mutual information between the latent variables and target variables. The author shows two propositions that mutual information is closely connected to the distances of latent variables in the latent space.\nIn the end, the author proposed an attention model as the encoder to map the observation into a latent variable with a feature embedding network. \n\nEmpirically, the author evaluates the proposed method for classification problems with a synthetic dataset and a benchmark dataset, showing improved results without imputation.",
            "strength_and_weaknesses": "Training models without imputation is an interesting point of view and using a measure theoretical point of view is novel to the best of my knowledge. But, I have to admit I am not sure I fully understand this paper. The clarity is a severe issue. Using measure theory to explain the missing mechanism should be fairly mathematical including the formal definition of the term used in the paper, claims made by the paper (or some references). However, most of the claims made by the paper are described in words, which is good for intuition but not good for formal explanation. Due to this, I got confused when I read this paper and still not clear on some of the claims made by the author. \n\nFor instance, in section 4, I am not sure why using latent space regularization helps remove the bias from missing mechanisms. Where are the proofs of propositions 1 and 2? I am not sure I understand the argument for countable additivity. \n\nIn section 5 paragraph 1, you mentioned defining a general function $f_\\theta$ (since this is not has a subscript $k$, I assume it is shared for all ensembles.) but in the second paragraph, you define a feature-specific embedding network. Is the feature embedding network used to distinguish different ensembles? If so, these two are inconsistent. From algorithm 1, I assume $x$ contains some missing entries, how does the embedding network handle the missing part? In addition, why the transformer has to be trained on randomly generated subsets at each training step? Can this method be used for regression tasks, since the argument of mutual information is based on the cross-entropy loss function?\n\nIn section 2, you mentioned that without missingness, the measure is uniform. Just to double-check, the subset $u$ is the set containing variable indices (e.g. {1,3,5})?\n",
            "clarity,_quality,_novelty_and_reproducibility": "As I have mentioned in the previous section, I think the clarity of the paper should be much improved for the general audience. Personally, I think the writing quality of this paper is not good. \n\nI have trouble understanding the paper so I cannot safely judge the novelty. But according to algorithm 1, there is no significant novel part in the model formulation and training objectives. I guess the potential contribution is casting the missing value problem using measure theoretical language. But the author did not write it in a clear, digestible way.\n ",
            "summary_of_the_review": "My main concern about this paper is the clarity and writing quality. Since I am not sure I fully understand the paper, I cannot judge the novelty or whether the contribution is significant. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1177/Reviewer_XuHA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1177/Reviewer_XuHA"
        ]
    },
    {
        "id": "WTsiGrwmCkG",
        "original": null,
        "number": 3,
        "cdate": 1666651132387,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666651132387,
        "tmdate": 1666651706024,
        "tddate": null,
        "forum": "jny79Mfgkno",
        "replyto": "jny79Mfgkno",
        "invitation": "ICLR.cc/2023/Conference/Paper1177/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the supervised learning problem under missing data, and proposed a solution without the need for imputation based by utilizing an attention based latent space model for dealing with missingness in tabular datasets. The authors shows that certain regularization occurs for the latent space representation of missing data with high cardinality subsets that are regularized to the higher information. Based on this insight, this paper then proposed a training algorithm based on transformers. ",
            "strength_and_weaknesses": "Pros:\n\n- This research follows the recent findings of supervised learning under missing data, and takes an approach that does not reply on imputation models\n- I found that the information regularization perspective of latent space of missing data very interesting. I think additional works can be done based on this idea., especially on the theoretical side.\n\nCons:\n\n- Clarity could be further improved. I understand that this paper focuses on supervised learning problem under missing data (i.e., prediction) as opposed to inference (i.e., multiple imputation) problems. However, this is not absolutely clear by just reading the title and abstract. The term \"dealing with missing data\" is too broad and confusing; and the presentation of the paper could further benefit from a more pronounced narrative. \n\n- The conclusions/implications of the cited literature are not accurately presented. For example, regarding (Bertsimas et al. 2021), the authors claimed that \"This strategy (simple mean imputation and then regress) can lead to consistent predictions in the setting of MCAR, but is not appropriate where data is MAR or MNAR\" . This is very incorrect, as (Bertsimas et al. 2021) clearly proved and stated that \"mean-imputation-then-regress is asymptotically consistent\", and \"the missingness mechanism (MAR or NMAR) does not impact asymptotic Bayes optimality\". Although the authors could mention the limitation of such approach under finite data regime (which needs to support by empirical evaluations as well, which is lacking at the moment), the statement regarding consistency is clearly wrong. \n\n- Lack of novelty and a lot of similar recent advantages in literature are ignored. For example, apart from impute then regress, there are also approaches that adopt the joint generative-discriminative approaches based on latent representations, such as Ipsen et al, 2022, Ma et al., 2019,  Ipsen et a., 2021 just to name a very few, which naturally satisfies latent regularization effect that this paper proposed. These approaches are also based on the so-called set function encodings of latent space that maps $U_k$ into $z$, which is quite comparable to the proposed transformer approach. The authors claimed that \"our work is the first description and theoretical justification for utilizing an attention based latent space model for dealing with missingness in tabular datasets\", which is not entirely true. For example, in Lewis et al 2021, transformers are already used to encode $U_k$ into $z$, and the learnt $z$ can be used for any downstream tasks such as prediction, imputation and acquisition, and can be trivially extended to fully supervised setting of this paper, as argued by Ipsen et al, 2022.  \n\n- Theoretical analysis. I appreciate that the authors provided analysis on the regularization/clustering effect of latent space, however this analysis is a little pale to justify the proposed algorithm, especially considering the highly related works mentioned above. This also make the connections between Section 4 and 5 a bit far-fetched. Further theoretical analysis on consistency and identification will be appreciated.\n\nOther minor issues & questions.\n\n- In algorithm 1, it appears that the model training requires access to fully observed (at least MCAR) data, which seems quite limited. Could the authors clarify?\n\n\n\nReferences\n\n- Josse, Julie, et al. \"On the consistency of supervised learning with missing values.\" arXiv preprint arXiv:1902.06931 (2019).\n- Ipsen, Niels, Pierre-Alexandre Mattei, and Jes Frellsen. \"How to deal with missing data in supervised deep learning?.\" ICLR 2022\n- Ma, Chao, et al. \"Eddi: Efficient dynamic discovery of high-value information with partial vae.\" arXiv preprint arXiv:1809.11142 (2018).\n- Ipsen, Niels Bruun, Pierre-Alexandre Mattei, and Jes Frellsen. \"not-MIWAE: Deep generative modelling with missing not at random data.\" arXiv preprint arXiv:2006.12871 (2020).\n- Lewis, Sarah, et al. \"Accurate Imputation and Efficient Data Acquisitionwith Transformer-based VAEs.\" NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications. 2021.",
            "clarity,_quality,_novelty_and_reproducibility": "See above.",
            "summary_of_the_review": "I believe this paper contains some interesting ideas that could be further explored. However, given its current state (misleading factual mistakes, lack of novelty) I am not convinced to recommend acceptance to the main conference.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1177/Reviewer_4QuC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1177/Reviewer_4QuC"
        ]
    },
    {
        "id": "UXPtqF8Qsq",
        "original": null,
        "number": 4,
        "cdate": 1666703458140,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666703458140,
        "tmdate": 1666703458140,
        "tddate": null,
        "forum": "jny79Mfgkno",
        "replyto": "jny79Mfgkno",
        "invitation": "ICLR.cc/2023/Conference/Paper1177/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The papers introduces a framework for reasoning about model fitting and inference from observed variables when dealing with missing data. The main point seems to be the interpretation of the latent space representation using the mutual information between subsets which contain different elements of the dataset. A consequence of this interpretation is to intervene in the latent space using an attention-based representation. This makes the method to perform better than one baseline based on ensemble decision trees (LightGBM).",
            "strength_and_weaknesses": "**Strengths:** The technical formulation of the problem as a measure-theory alike method is a valid point. I also liked the perspective where one identifies the bias induced by the missing samples in the latent space. There is also a reasonable amount of empirical results, however, the number of baselines considered is somehow small in my opinion.\n\n**Weaknesses:** In general, I had a difficult time to identify the main contributions of the work, or at least to see what are the main differences with respect to previous ideas in the literature. The idea of fitting models that only use the information of observed variables under missing samples seems to not be correctly introduced wrt other previous works (i.e. MiWAE, PartialVAE or Eddi), or at least indicating what are the differences and what is new here. Additionally, the introduction of the measure theory formulation does not seem to provide a key advantage in the analysis, as in the end the authors use the mutual information between subsets for later using the attention method. From the theoretical aspect of missing data, I also feel that Le Morvan, 2021 should be cited as it is stated in the paper that there are no universally fair imputation methods (which somehow prevents the work from focusing in imputation). On the algorithmic part, it was also difficult to me to perceive what is special or at least, to understand the connection with the theoretical development. \n\nFinally, I liked the design of the synthetic experiment, but the presentation of the results is not clear or sufficiently rigorous. I really would have preferred to see the metrics tables in the main manuscript, rather than all of them in the appendix. Details about the datasets used for benchmarks, number of samples and rates of missing data is also not clearly available.\n\n\nMiWAE -- https://arxiv.org/pdf/1812.02633.pdf\n\nPartialVAE -- http://bayesiandeeplearning.org/2018/papers/75.pdf \n\nEddi -- https://arxiv.org/pdf/1809.11142.pdf\n\nLe Morvan, 2021 -- https://arxiv.org/pdf/2106.00311.pdf",
            "clarity,_quality,_novelty_and_reproducibility": "The paper has a reduced impact due to the lack of clarity. This makes difficult to identify the main novelty and quality of the technical contribution. Perhaps, those are the most important flaws that I see.",
            "summary_of_the_review": "Good direction with interesting connections between missing data models and measure theory. In particular the use of the mutual information to identify potential effects in the latent space. However, there is a general noise around the contributions that make them less clear and difficult to assess. I recommend weak rejection, but I am open to discuss/understand better what are the main contributions, the differences wrt SOTA methods and related work.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1177/Reviewer_cGGK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1177/Reviewer_cGGK"
        ]
    },
    {
        "id": "BiJ08DizM7",
        "original": null,
        "number": 5,
        "cdate": 1666827358165,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666827358165,
        "tmdate": 1666827358165,
        "tddate": null,
        "forum": "jny79Mfgkno",
        "replyto": "jny79Mfgkno",
        "invitation": "ICLR.cc/2023/Conference/Paper1177/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper considers the problem of training models capable of making predictions while there are missing values in input data.\nThe authors proposed a method that uses the attention mechanism as it can take an arbitrary number of features. \nExperiments are conducted to investigate the learnt latent feature and the performance of the methods on various datasets. ",
            "strength_and_weaknesses": "(+) Making predictions with missing data is quite a challenging and undouble overlooked problem. This paper provides a working solution to address the problem with the attention mechanism.\n\n(-) Regarding the missing data problem, this paper primarily focuses on the proposed method's framework. A systematic view of related work (e.g. density-based, vae-based, etc.) is not present in the discussion or the experiments. (See details below).\n\n(-) While the proposed method acts as a working solution, this paper doesn't provide enough insights or justification of the method to either the problem or other candidate methods. The readers might not be convinced if the technique is the right choice (See details below). ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity (3/5): This paper is reasonably written, and a reader with related background should get the idea without significant issues. Some mathematical notations can be improved for better clarity. While formalising the problem with measure theory might be preferable to some readers, it introduces many convoluted notations (i.e. the random variable for missing dimension index), and most of these concepts are not linked and later used in the paper. \n\nQuality (2/5): This paper is limited in its discussion and analysis of other solutions for the considered research problem and therefore doesn't provide a comprehensive justification for its contribution. Methods of dealing with missing values can trace to some early density-based approaches (http://mlg.eng.cam.ac.uk/zoubin/papers/nips93.pdf) to recent deep-based approaches (https://arxiv.org/abs/1807.03653). See (https://arxiv.org/pdf/2206.07769.pdf) for a more detailed list. The proposed method should at least be discussed with more related methods to indicate its advantages and application scenarios (at the moment, the proposed method is only motivated as a low-cost solution compared to the ensemble method). Also, the authors are unclear on whether the proposed method can adequately solve the conditions given in def 1 to def 3, while these definitions are provided and discussed at the beginning.\n\nNovelty (2/5): This paper claims its novelty in the introduction of attention block in the proposed method, but it should be aware that similar ideas have been used before for missing data imputation (i.e. https://openreview.net/pdf?id=N_OwBEYTcKK). Furthermore, at the moment, the attention block seems to be a plug-in part after masking the previously learned feature from each dimension. I wonder if the author can indicate if attention usage here differs from other typical attention/transformer applications.\n\nReproducibility (4/5): The method should be quickly followed by the texts and algorithm 1, and experiments are based on public datasets. Therefore there should be a significant issue in reproducing most experiments. Public methods and experiment access would make things better. ",
            "summary_of_the_review": "Although the authors provide a working solution to the prediction problem with missing data, this paper doesn't give enough insight into the method. It cannot justify the method from existing approaches. So the paper is not considered as publishable as the readers might feel as unconvinced as the reviewer.\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1177/Reviewer_Xkfr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1177/Reviewer_Xkfr"
        ]
    }
]