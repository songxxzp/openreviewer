[
    {
        "id": "sPUqHPYsgTQ",
        "original": null,
        "number": 1,
        "cdate": 1666539407141,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666539407141,
        "tmdate": 1666539407141,
        "tddate": null,
        "forum": "RKiWwhocuiU",
        "replyto": "RKiWwhocuiU",
        "invitation": "ICLR.cc/2023/Conference/Paper464/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The problem of domain generalization in the context of small samples is discussed. This is particularly important in digital pathology.\nNovel probabilistic extensions of classical MMD and contrastive semantic alignment loss provide additional features. Evaluations on standard pathology datasets show reasonable performance improvements.",
            "strength_and_weaknesses": "Strengths: Domain generalization for small sample cases is an important problem, especially in digital pathology. Probabilistic extensions of MMD and contrastive semantic loss make the paper more interesting. The domain of digital pathology is ideal for testing the efficacy of the proposed approach. Experimental results are convincing.\nWeaknesses: The authors are not the first to come up with a measure to evaluate the discrepancy between mixture distributions (i.e., source domains). Please refer to Y. Balaji, R. Chellappa and S. Feizi, \u201cNormalized Wasserstein for Mixture Distributions with Applications in Adversarial Learning and Domain Adaptation\u201d, Proc. Intl. Conf. on Computer Vision, Seoul, South Korea, Oct. 2019 for a related work.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written well. Novelty comes from looking at probabilistic extensions of classical MMD and contrastive semantic alignment loss. Experiments are clearly explained. Overall a good paper.",
            "summary_of_the_review": "This paper addresses an important challenge in digital pathology, domain generalization when sample size is small. The proposed approach is solid with good experimental results and reasonable improvements over SOTA.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper464/Reviewer_s3JK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper464/Reviewer_s3JK"
        ]
    },
    {
        "id": "fsh66Y0ZR69",
        "original": null,
        "number": 2,
        "cdate": 1666662291117,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666662291117,
        "tmdate": 1668734257133,
        "tddate": null,
        "forum": "RKiWwhocuiU",
        "replyto": "RKiWwhocuiU",
        "invitation": "ICLR.cc/2023/Conference/Paper464/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "As the title suggests, this paper explores domain generalization for small data through a probabilistic maximum mean discrepancy (MMD) approach. For this purpose a domain-invariant representation is being learned from multiple domains (sources) where the assumption is that these domains inherently have insufficient samples (a.k.a small data). For the training and evaluation purpose the paper explores their claims in the medical image processing domain (skin lesion classification, epithelium-stroma classification, spinal cord gray matter segmentation) where such data limits are more clear.  They also studied and ablated each component of the proposed method including but not limited to the effectiveness of domain-invariant loss, use of global vs. local alignment, use of Bayesian layer and such. ",
            "strength_and_weaknesses": "**Strength:**\n- The paper in general is very well-motivated and the target problem is relevant to both the ML and Medical AI community.\n- They evaluate and ablate the method in multiple settings. \n\n**Weakness:** (see below for more details) \n- Paper can benefit from the redesign of experiment to better support and showcase the claim of the paper around small data.\n- Some details around experimental protocol and details are either missing or not presented concretely. \n- Results are marginal and I cannot observe significant improvement specifically for small datasets. \n\n**Suggestion to improve paper:**\n- One of my main concerns is around the evaluation protocol of the paper. For each application, we are dealing with multiple datasets and dataset size ranges. For example skin lesion classification task includes 7 public dataset with different dataset size as mentioned in the paper, for example UDA and PH2 includes 601 examples and 200 examples consequently. What has not been mentioned in the paper is that for example HAM1000  includes 10015 dermascopic images and more critical details around other dataset are also missing. In this experimental setting paper claims the method improves performance for small data setup where we are dealing both with the domination danger of larger dataset and also limits and boundaries of improvement is not clear.  For paper claims, I am more interested in the question of how many samples is enough to reach the baseline performance? So coming up with unification is very important, picking up the smallest dataset size, and analyzing everything in the fixed dataset size or fraction (e.g. performance with 10 samples, vs. performance with 200 samples). Such experiments are standard in representation learning literature. Does the larger dataset dominate the learned space?\n- Even in the current setting I would expect to see significant improvement given the proposed method for SON, UDA and PH2 but all I am seeing is marginal improvement given standard deviation on five runs.  With this experimental protocol at best, the paper is a domain generalization paper for medical image processing, and any claim around small data should be addressed and assessed concisely. \n- More importantly, as the paper mentioned some of at least skin lesion dataset suffers from class imbalance, long tail issue, and effect of any method should get analyzed per class and fairness consideration should be addressed. \n\n**Minor Editorial:**\n- Improving tables and image captions can help with the quality and readability of the tables. (e.g. bold and underline, number of runs to obtain std for table 2, do they run significant tests, if so, highlighting significant improvements, and more.)\n- Figure 3 is very small, moving some results to the appendix does not hurt the paper or using alternative visualizations such as bar graphs help with the quality of results.\n- Last paragraph of related work, page 3, \u201cwe noticed \u2026\u201d can benefit from a rewriting. \n",
            "clarity,_quality,_novelty_and_reproducibility": "- The paper is in general well-written and easy to understand. There are some aspects such as table captions and details around experiments that can be improved. \n- The paper is more of incremental nature (i.e. Xiao et al. (2021)), however there are novel components specifically exploring a novel application in a data/application intensive manner. \n- There are missing details around implementation and experimental setup. In each experiment it is not clear what are the train dataset(s) and how hyperparam selection has been done. There are pointers all around the main paper and appendix which are hard to follow, however this could significantly improve. I would also suggest adding a similar to Table 6 breakdown for all of the tasks. \n- Dataset sizes are missing in some cases.\n- Datasets are majorly public, so having the implementation/open source package (I cannot find any link to any source code) and more details around experiments (see above) reproducibility should be feasible.  \n- There is no statistically significant test analysis, although some results such as Table 5 and 1 is reporting standard deviation and ran for five times. \n",
            "summary_of_the_review": "Although I appreciate that the paper presents various experiments, the evaluations and numbers do not support the claim of the paper around small data (no significant improvement in dataset with less data), also the evaluation and experiment protocol can improve drastically (i.e. controlled sampled size). Moreover, clarity and reproducibility of paper can be improved by reorganizing some sections and presenting experimental protocol upfront and in a concise manner. \n\nAfter Rebuttal: As most of my concerns has been answered, I increased my score. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "The paper uses the skin datasets that suffer from long-tail issues and results for such dataset and application should get analyzed per classes (to address any biases introduced for any specific class or ethnicity and race). If the access to such meta-data is not feasible authors should address concerns around fairness and bias upfront. \n\n\nAfter Rebuttal: An ethics statement has been added as requested. Thanks. ",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper464/Reviewer_BRdo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper464/Reviewer_BRdo"
        ]
    },
    {
        "id": "jL2gymnqKMH",
        "original": null,
        "number": 3,
        "cdate": 1666703797940,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666703797940,
        "tmdate": 1669511249460,
        "tddate": null,
        "forum": "RKiWwhocuiU",
        "replyto": "RKiWwhocuiU",
        "invitation": "ICLR.cc/2023/Conference/Paper464/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper deals with the problem of domain generalization in the case that we have only insufficient source domain examples and proposes a new loss function called probabilistic maximum mean discrepancy (p-MMD). The proposed loss function introduces a kernel function \\kappa for kernel means of latent embeddings and applies a standard MMD for the kernel \\kappa. If the kernel \\kappa and a kernel k for latent embeddings z are both Gaussian, the proposed loss function can be computed by the kernel k.",
            "strength_and_weaknesses": "[Strength]\n\nS1. The problem dealt with in this paper is significant. Domain generalization is one of the fundamental problems in machine learning and computer vision, and in some cases, we cannot obtain sufficient training examples for training machine learning models for this purpose. Technically solid methods with thorough experimental evaluations will draw attention from a broad range of researchers and engineers.\n\nS2. The use of level-2 kernels for extending the standard MMD is interesting. The proposed p-MMD might be useful for other tasks emphasizing probabilistic distributions.\n\n[Weakness]\nW1. The proposed method lacks \"why\". I understand that the proposed method extends the standard MMD by introducing a kernel function for kernel means and it seems to be novel as far as I know. However, I am unsure why the proposed method can boost the performance on few-resource domain generalization.\n\nW2. The current main content lacks sufficient experimental conditions. For example,\n- What is the source / target domain data in the experiment presented in Section 4.1? --> This makes the task setting totally unclear.\n- How many training examples are available in the experiment presented in Section 4.1? --> I could not understand whether the current experimental setting can be regarded as \"few resources\" or not.\n- How many competitors include the Bayesian framework in them? --> I could not understand which contributes to the performance improvement, Bayesian neural networks or probabilistic MMD.",
            "clarity,_quality,_novelty_and_reproducibility": "[Clarity]\nThe current manuscript is well-written and easy to follow, except for the experimental conditions.\n\n[Quality]\nAlthough the proposed method has a potential, I am not sure whether the proposed method is a better solution for the targeted problem.\n\n[Reproducibility]\nI should say that the current manuscript does not have sufficient reproducibility due to the lack of detailed experimental conditions.",
            "summary_of_the_review": "I am not so positive about this paper due to the weaknesses presented in this review, namely (1) the mismatch between the targeted problem and the proposed method and (2) the lack of significant experimental conditions. I believe that the proposed probabilistic MMD would be useful for some tasks. I strongly recommend the authors reconsider problems for which the proposed method is suitable.\n\nAfter author feedback: I acknowledge the feedback; however, I would keep the original review score.\n- I agree with Reviewer BRdo in terms of the redesign of experiments.\n- Significant experimental conditions should be clearly presented in the main content. Or, some pointers to the appendices should be presented in the main content.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper464/Reviewer_6Mag"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper464/Reviewer_6Mag"
        ]
    },
    {
        "id": "1skN9olMgVU",
        "original": null,
        "number": 4,
        "cdate": 1666728398260,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666728398260,
        "tmdate": 1666728398260,
        "tddate": null,
        "forum": "RKiWwhocuiU",
        "replyto": "RKiWwhocuiU",
        "invitation": "ICLR.cc/2023/Conference/Paper464/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes to learn a domain-invariant representation based on the probabilistic framework by mapping each data point into probabilistic embeddings. For this, a probabilistic MMD and a probabilistic CSA loss are proposed.",
            "strength_and_weaknesses": "The paper proposes some new methodology and shows promising results on medical datasets. But it is missing a discussion on potential drawbacks of this approach such as e.g. slower inference time. It is also missing comparison against baselines on datasets such as VLCS, TerraIncognita and DomainNet. While some of these might not showcase the strength of the proposed approach, but the expectation should be that the approach performs similarly on these compared to existing baselines.",
            "clarity,_quality,_novelty_and_reproducibility": "The writing overall seems clear but does require more proofreading. I'm not very familiar with other works in this field so cannot judge on the novelty of the approach.",
            "summary_of_the_review": "Overall the paper seems to propose a novel approach with promising results. The quality of the paper can be improved by addressing potential shortcomings and an even more thorough evaluation on other benchmark datasets.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper464/Reviewer_RmYa"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper464/Reviewer_RmYa"
        ]
    }
]