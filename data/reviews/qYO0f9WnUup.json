[
    {
        "id": "e1pSHCXcThd",
        "original": null,
        "number": 1,
        "cdate": 1666599300498,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666599300498,
        "tmdate": 1666599300498,
        "tddate": null,
        "forum": "qYO0f9WnUup",
        "replyto": "qYO0f9WnUup",
        "invitation": "ICLR.cc/2023/Conference/Paper5851/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper investigates the robustness of dynamic neural networks, focusing specifically on early exit networks. It does so by exploring how attacks generated using static networks transfer to dynamic networks and how the structure of dynamic networks provides another attack surface. In their majority most works appearing in the literature dynamic networks have been utilized to improve real-time performance. However, they have not been investigated under the spotlight of robustness. In this regard I find that this work provides some interesting findings which have not been explored previously.  ",
            "strength_and_weaknesses": "Strengths:\n- I like the questions raised in this paper and believe they provide a new direction for research in dynamic neural networks. \n- The experiments use some standard deep learning models like VGG and ResNet, and explore different scenarios e.g., either dynamic or static model as surrogate etc.\n- Some interesting findings such as that the more exits increase the robustness of the model.\n\nWeaknesses:\n- The related works section needs to be expanded significantly in order to provide the reader with a more complete picture especially with the available works on dynamic neural networks. \n- The list of references is also quite limited considering that adversarial attacks are a very popular topic and dynamic neural networks have been investigated for some years. \n- The evaluation datasets include only cifar-10 and 100. It is not clear of using other benchmark such as ImageNet which have higher resolution would impact the results since now a much larger attack surface is available. \n- It would have been nice to see a theoretical framework specific for dynamic neural network that would provide some additional foundations besides the empirical findings. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall the paper is easy to read and clearly sets the research questions that it addresses. \n\nThe following is not properly justified. Does this follow an established understanding by the community?\n\u201cOne of the reasons for this behavior is the lower variance of the DyNNs. DyNNs use lower number of parameters, hence the feature space for adversarial samples of DyNNs is smaller than the feature space for adversarial samples of SDNNs.\u201d\n\nIt would be interesting to show the adversarial examples generated by DyNNs vs static networks. Are there particular differences that could be visually interesting?\n\nThe Appendix contains some useful information that should be in the main manuscript. For instance, Figure 7 and Algorithm 1. I suggest the authors carefully review the structure of the paper in order to try and include the additional content within the page limit. \n",
            "summary_of_the_review": "The paper investigates the robustness of dynamic neural networks against adversarial attacks. It provides a new focus for dynamic neural networks and highlights the new attack surface that they provide. While this paper has some shortcomings and can be improved in some areas I would recommend it based on the new aspects that it tries to highlight. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5851/Reviewer_X4b3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5851/Reviewer_X4b3"
        ]
    },
    {
        "id": "SAV-K26N32J",
        "original": null,
        "number": 2,
        "cdate": 1666600759468,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666600759468,
        "tmdate": 1669420864114,
        "tddate": null,
        "forum": "qYO0f9WnUup",
        "replyto": "qYO0f9WnUup",
        "invitation": "ICLR.cc/2023/Conference/Paper5851/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The work studies the robustness of dynamic neural networks (DyNNs) from four perspectives: 1) comparison of the black-box robustness between static and DyNNs; 2) The inference time of adversarial samples in DyNNs; 3) Dynamic mechanisms with the best robustness; 4) synthesize samples to reduce the effectiveness of DyNNs. ",
            "strength_and_weaknesses": "### Strength:\n\n1. The paper is well-written with summarized findings in each section (3-6).\n2. Experiments are conducted in different architectures and datasets.\n3. Sufficient implementation details are provided.\n\n### Weakness:\n\n1. Why do the authors only consider early-exit DyNNs? \"more popular\" seems not convincing.\n2. The logical relationship between these four perspectives of DyNNs' robustness is not clear, which results in this paper being more like a technical report rather than a conference paper.\n3. The literature on adversarial attacks missing a lot of important works. e.g., Auto-Attack, C&W attack, etc.\n4. Finding 1 in Section 3 \"With respect to black-box attacks, early-exit DyNNs are more robust than SDNNs\" is really debatable. 1) missing white-box robustness evaluation 2) Only FGSM and PGD attack is not reliable for assessing robustness. With more advanced attacks, e.g., Auto-Attack, does this finding also hold?\n",
            "clarity,_quality,_novelty_and_reproducibility": "None",
            "summary_of_the_review": "None",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5851/Reviewer_bhB9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5851/Reviewer_bhB9"
        ]
    },
    {
        "id": "0c4XACBGRV9",
        "original": null,
        "number": 3,
        "cdate": 1666627913525,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666627913525,
        "tmdate": 1666627913525,
        "tddate": null,
        "forum": "qYO0f9WnUup",
        "replyto": "qYO0f9WnUup",
        "invitation": "ICLR.cc/2023/Conference/Paper5851/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents an empirical study of the adversarial robustness of dynamic neural networks (DyNNs) with early-exits. The authors find that DyNNs are more robust than SDNNs, and DyNNs can be used to generate adversarial samples efficiently. The authors also proposes a novel adversarial attack method specifically designed for DyNNs.",
            "strength_and_weaknesses": "Strengthes:\n1. The adversarial robustness of DyNNs is an important research problem. Some of the findings are new and can be interesting to the community.\n2. The paper is overall well-written and easy to follow.\n3. The experiments are well conducted and well supports the findings in the paper.\n\nWeaknesses:\n1. Missing related work on DyNN with improved adversarial robustness [Zhou et al. 2020]. This work also investigated the adversarial robustness of DyNNs and introduced a novel early-exit criteria for improved robustness. This makes the novelty of some findings less strong. However, [Zhou et al. 2020] does not conduct extensive experiments and the throughout empirical analysis in this paper can still be beneficial.\n2. The proposed early-attack method is not very well motivated. It's unclear in which scenario one would expect the prediction of last layer to be unchanged because this will not influence the final prediction anyway.\n\n[Zhou et al. 2020] BERT Loses Patience: Fast and Robust Inference with Early Exit\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Good\nQuality: Good\nNovelty: OK\nReproducibility: Good",
            "summary_of_the_review": "This paper conducts an interesting empirical study about the adversarial robustness of DyNNs. It misses an important related work and is thus somewhat overclaiming the novelty of the findings. Nevertheless, some findings are still interesting and can be helpful.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5851/Reviewer_nmxr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5851/Reviewer_nmxr"
        ]
    }
]