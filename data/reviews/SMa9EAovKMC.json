[
    {
        "id": "caL6Hn8LioU",
        "original": null,
        "number": 1,
        "cdate": 1666606227290,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666606227290,
        "tmdate": 1666606227290,
        "tddate": null,
        "forum": "SMa9EAovKMC",
        "replyto": "SMa9EAovKMC",
        "invitation": "ICLR.cc/2023/Conference/Paper2890/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The manuscript cleverly combines the ability of:\n 1. theorem provers like Isabelle to accept `sorry` statements, in which unproved statements can be accepted as if true;\n 2. large language models to fill in masked text.\n\nIt proposes a 'draft, sketch and prove' methodology that draws on the large corpus of informal (human) mathematics, converting it into a formal proof sketch with a large language model.  This sketch is then used to guide an automated theorem prover.\n\nIf I understand correctly, the methodology can use of erroneous (informal) proof sketches to generate correct proofs, as ML techniques generally make use of noisy training data to generate correct classifications.\n\nThe methodology seems to expand the class of informal mathematical problems that can be formalized and formally solved.  \n\nAs the agenda seems ambitious and fruitful, I expect that it will lay the foundations for further advances, dropping the cost of mathematics, and extending the range of mathematical results for which we can establish proofs.",
            "strength_and_weaknesses": "**Strengths**\nSee above\n\n**Weaknesses**\n1. I would like to see existing SOTA results.\n1. if you could fit it, a plot of success v the number of steps in Appendix C would be nice.\n\n**Next steps I would like to see in future work**\n1. it would be particularly nice if DSP found new or 'better' proofs (akin to Newell, Shaw & Simon's Logic Theory Machine on Russell & Whitehead).\n1. I would like to see consideration of multiple proofs of the same result: Nipkow's 2009 JAR article formalized two of Geanakoplos' three proofs of Arrow's impossibility theorem, to explore how easy different proofs mode could be formalized.  (I would _love_ to see style transfer eventually: prove this result in the style of von Neumann, or Erd\u0151s.)\n1. Can the structure of proofs be better exploited?  For example, Hilbert-type proofs correspond to trees.  Isabelle-type proofs are more complex due to local assumptions.  (Was this the concluding reference to HyperTree?)\n1. Thomas Hales' had a 'formal abstracts' project a few years ago, in which he sought to formalize abstracts of mathematical papers, easing searches across notation and terminology.  Could DSP help?",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\n- the paper was well written.\n\n**Quality**\n- this seems high quality, thorough work.\n\n**Novelty**\n- I have not seen this done before: to me, this seems a big advance.\n\n**Reproducibility**\n- no system details released.  Either code or a user interface would be helpful.",
            "summary_of_the_review": "To me, this paper seems to represent in generating mathematical proofs at lower cost. I can see it launching significant research projects (q.v. possible future work, above).",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2890/Reviewer_AVNg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2890/Reviewer_AVNg"
        ]
    },
    {
        "id": "i2iWNk5Ni6",
        "original": null,
        "number": 2,
        "cdate": 1666636263847,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666636263847,
        "tmdate": 1666636410239,
        "tddate": null,
        "forum": "SMa9EAovKMC",
        "replyto": "SMa9EAovKMC",
        "invitation": "ICLR.cc/2023/Conference/Paper2890/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposed a novel and nice procedure for automating interactive theorem proving, which combines state-of-the-art approaches to ML for (interactive) theorem proving. The key idea is to have a proof written in natural language (either provided by a human user or generated by a language model) translated into a formal sketch which is a skeleton of a proof script that can potentially be verified by the underlying theorem prover when all the details are filled in. An automated theorem prover, which can either be a high-level tactic of the underlying system, or an external learning based system, is then used to close the gaps in the sketch.\n",
            "strength_and_weaknesses": "Strength:\n\n+ The paper is well written and easy to follow. I enjoyed reading it.\n\n+ The approach is technically sound, conceptually simple (which is good) and empirically working. Even better, the design of entire process is quite natural: first coming up with a proof in natural language and then turning it into a formal proof, organized in a way that subgoals can be easily automated, which is exactly what a human ITP expert would do.\n\n+ The paper nicely assembles existing approaches from subareas of ML for theorem proving (i.e., theorem proving in natural language, autoformalization, and learning-based automation for ITP) to make a complete procedure that provides high-level automation for interactive theorem proving.\n\nWeakness:\n\n- The good performance is probably not that surprising. Both Minerva (used for drafting) and Codex (used for sketching) might have seen the problems somewhere on the internet, formal or informal version in different forms (e.g., comments or code from different provers, or math overflow etc). After all, the competetion problems are famous.\n\nMinors:\n\n- It is [reported](https://github.com/openai/miniF2F/issues/103) that some problems in MiniF2F are not well formalized and some are wrong. The performance should perhaps be interpreted carefully. But apparently this isn't the authors fault.\n\n- In related work the authors wrote: \"... perform search over the generated subgoals using powerful search methods such as MCTS\". Recently there have also been approaches (e.g., [1][2]) proposed where learnable search could be useful for formal reasoning. Citations are missing. \n\n[1] Wu et al. 2021, TacticZero: Learning to Prove Theorems from Scratch with Deep Reinforcement Learning\n\n[2] Jonathan Laurent, Andr\u00e9 Platzer 2022, Learning to Find Proofs and Theorems by Learning to Refine Search Strategies: The Case of Loop Invariant Synthesis",
            "clarity,_quality,_novelty_and_reproducibility": "The presentation is very clear and of good quality. The approach is a novel and elegant combination of existing approaches. I believe the results are reproducible if Minerva and Codex are both publicly available. ",
            "summary_of_the_review": "The paper proposed a nice procedure for high-level automation for interactive theorem proving, integrating state-of-the-art approaches to ML for (interactive) theorem proving as its subroutines. The empirical evaluation validates the approach. I recommend accepting the paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2890/Reviewer_AYPt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2890/Reviewer_AYPt"
        ]
    },
    {
        "id": "u_b1XlCOPO0",
        "original": null,
        "number": 3,
        "cdate": 1666642066019,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666642066019,
        "tmdate": 1666642066019,
        "tddate": null,
        "forum": "SMa9EAovKMC",
        "replyto": "SMa9EAovKMC",
        "invitation": "ICLR.cc/2023/Conference/Paper2890/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes to guide the formal theorem prover using informal proofs. The key idea is to convert the informal proofs to formal proof sketches by prompting LLM as a few-short learner. On the miniF2F-test dataset, this approach improves the performance of the Sledgehammer + heuristics prover of Isabelle from 20.9% to 39.3% with human informal proofs and 37.3 with LLM-generated informal proofs.",
            "strength_and_weaknesses": "This paper studies a promising direction of ATP,  to guide theorem provers using informal proofs. \nThe use of proof sketches is reasonable. The steps of prompting LLMs are technically sound.\nThe proposed approach requires no additional training on ground-truth proofs but achieves impressive results. \n\nOne question is that what if replace with the Sledgehammer + heuristics prover as the Thor prover? How much improvement can we get from Thor?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is easy to follow. The idea is novel to convert informal statements, to informal proofs, to formal sketches, and finally to formal proofs. ",
            "summary_of_the_review": "This paper proposes an interesting approach on how to make use of informal proofs for ATP. I recommend accepting this paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2890/Reviewer_7zK6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2890/Reviewer_7zK6"
        ]
    },
    {
        "id": "u4BGNTxPZu",
        "original": null,
        "number": 4,
        "cdate": 1667600230570,
        "mdate": 1667600230570,
        "ddate": null,
        "tcdate": 1667600230570,
        "tmdate": 1667600230570,
        "tddate": null,
        "forum": "SMa9EAovKMC",
        "replyto": "SMa9EAovKMC",
        "invitation": "ICLR.cc/2023/Conference/Paper2890/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a large language models (LLM) to automatically generate formal proofs of mathematical statements. The idea is to use Codex or Minerva model to generate an informal proof (a proof in a natural language) and then use it as a sketch to generate a formal proof. Each claim in the sketch is a some kind of proposition, which is then proved by an off-the-shelf prover, like Sledgehammer. The approach is based on the ability of LLMs to do few-shot learning. A prompt to the model contains a formal statement to be proved, generated informal statement and informal proof, and several examples of tuples <informal statement, informal proof, formal statement, formal proof>. To provide appropriate examples, the authors gathered a dataset of parallel informal-formal proofs for the problems from the MiniF2F dataset and sample 3 random examples to make the prompt.\n\nThe approach was tested on validation and test splits of the MiniF2F dataset. In the experiments, the proposed approach outperforms the baselines. The ablation study demonstrates the benefit of using sketches and aligning them with formal proofs. Also, the results show that larger models have higher proof rates.",
            "strength_and_weaknesses": "+ While using LLMs for auto-formalization seems novel enough, this is the first work where LLM is applied to generate the whole proof. The idea of guiding formal proof generation with informal proof sketches is novel. The experimental section justifies that sketching indeed helps generate more correct proofs. The study in this paper demonstrates that the model makes use of the alignment between formal and informal proofs. This is the main contribution of the paper.\n\nThe paper also contains some analysis of how the prover's performance depends on the correctness of informal proofs. It turns out that the prover can fix some simple errors in informal proof and even ignore the informal proof if it is incorrect. This observation is interesting and suggests that the model can perform some kind of formal mathematical reasoning.\n\nThe paper is generally well written, experimental section demonstrates state-of-the-art results on the MiniF2F dataset, ablation study justifies the usefulness of the guidance by the informal proofs and the alignment between informal and formal proofs. The approach is built on top of existing pre-trained models and seems easy to implement if the models are available. \n\nCons:\n1. The examples play an important role and should be carefully constructed. In the paper, the authors try to use appropriate examples: first of all, all of them are from the MiniF2F dataset, secondly, whenever the problem type is known (from the problem name, e.g. it contains \"number theory\") they use the corresponding examples. So, the approach cannot be easily applied to other datasets.\n2. More analysis of the model should be conducted. Figure 3, \"Human informal proof drafts\" implies that it is also important to have good examples as different proof attempts differ only in provided examples. How close are the examples of successful proofs to the statement compared to failed proofs?\nIt is also interesting to separate the effect of chosen examples from the effect of generated informal proofs.\nFor example, we can use the same 3 examples for all proof attempts and only change the informal proofs.\n3. The method requires access to the LLM which is not widely available and limits the reproducibility of the approach.",
            "clarity,_quality,_novelty_and_reproducibility": "1. It is not completely clear how informal proofs are generated. How input prompt is constructed? Does it include examples or does it consists of just the formal statement? Is it fixed across proof attempts or each attempt uses different informal proof? It is mentioned that greedy decoding is used for the Codex model. Does it allow generating different outputs for a fixed input prompt (usually greedy decoding provides deterministic output)?\n2. It is interesting to compare the computational resources required for one proof search. While the approach makes much fewer calls to the LLM generator, we have to run Sledgehammer several times during the proof search, so it is unclear whether the approach reduces the computation time.\n3. Another interesting question here is data leakage. From the paper (Wu et al. 2022. Autoformalization with large language models) we can conclude that it is unlikely that the MiniF2F dataset was in the training dataset of Codex, but there is still a possibility that informal statements and proofs are contained in the training dataset of Codex.",
            "summary_of_the_review": "The paper introduces a novel idea to guide formal proof generation with generated informal proof using large language models in a few-shot setting. The idea was justified by the experiments and ablation study. However, more analysis of the proposed approach should be conducted to make a clear picture of what part of the approach and to what extent affects the final result.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2890/Reviewer_9yAP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2890/Reviewer_9yAP"
        ]
    }
]