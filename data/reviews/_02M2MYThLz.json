[
    {
        "id": "LU-0MltxIRZ",
        "original": null,
        "number": 1,
        "cdate": 1666661812838,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666661812838,
        "tmdate": 1666661812838,
        "tddate": null,
        "forum": "_02M2MYThLz",
        "replyto": "_02M2MYThLz",
        "invitation": "ICLR.cc/2023/Conference/Paper2760/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper deals with online filtering of discretely observed nonlinear diffusion processes which has rich applications in fields such as security pricing and modeling in finance. The authors propose a computational framework to approximate the Doob\u2019s h-transforms that are typically intractable by solving the underlying backward Kolmogorov equations using nonlinear Feynman-kac formulas and neural networks. \nSimulations and numerical experiments show that this approach can be orders of magnitude more efficient than sota particle filters in difficult regimes. \n",
            "strength_and_weaknesses": "Strong\n\n1. A novel computational framework with nonlinear feynman-kac formulas and neural networks to approximate these Doob\u2019s h-transforms;\n\n2. Detailed background, method and related work expressions to better learn the motivations and solutions of the major novel ideas;\n\nWeak:\n\n1. Currently, could find less information about the neural networks used and how representative learning is performed \u2013 this paper aligns more with statistics and applied mathematics;\n\n2. More real-world datasets such as security pricing or portfolio changing experiments are preferred to be the application fields to better testify the ideas/algorithms proposed in this paper.\n\n\nDetailed questions and comments:\n\n1. Figure 1, 2, are curves \u2013 is it feasible to also list tables with specific numbers to learn the exact improvements (ranges) and differences?\n\n2. The OU process (Ornstein-uhlenbeck) is frequently used in real-world domains such as finance, do we have further experiments on real-world datasets and comparisons with baseline algorithms?\n\n3. \u2018neural networks\u2019 are mentioned around 30 times in this paper, prefer to learn the detailed architecture of the neural network and the complexity of it.\n\n4. In the reference, I can hardly find machine learning related references or articles, or even representative learning related. So this paper is more suitable for statistics or mathematics.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The motivations and proposed methods are clearly expressed with rich equations. The experiments can be enriched to better align with real-world applications.\nThe reproducing ability is limited \u2013 to first fully understand the equations and then code on them is not a trivial work.\n",
            "summary_of_the_review": "The overall solution to online filtering of discretely observed nonlinear diffusion processes is a promising direction in so many real-world applications. This paper provides approximations by leveraging neural network and Keynman-kac formulas which is interesting.\n\nThe work can be further improved by applying to real-world datasets and the network network\u2019s architecture should be described and compared in detail for ablation study.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2760/Reviewer_FHwj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2760/Reviewer_FHwj"
        ]
    },
    {
        "id": "T3L1SyoegB",
        "original": null,
        "number": 2,
        "cdate": 1667234986777,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667234986777,
        "tmdate": 1667234986777,
        "tddate": null,
        "forum": "_02M2MYThLz",
        "replyto": "_02M2MYThLz",
        "invitation": "ICLR.cc/2023/Conference/Paper2760/-/Official_Review",
        "content": {
            "confidence": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.",
            "summary_of_the_paper": "This paper studies how to simulate conditional diffusion processes -- where given some observations, we wish to study what the resultant state of the unobserved proportions of the diffusion process may be. To solve this issue, the authors propose a  Computational Doob's transform, leveraging neural networks to more accurately observed the proportions of the diffusion process",
            "strength_and_weaknesses": "Disclaimer -- I found this paper rather challenging to read -- it seems to be targeted towards a more applied math audience rather than a deep learning/ICLR audience and I am unsure of what exactly is being learned by the neural network / training objective. \n\n# Strengths\n\n**Significance.** This paper appears to solve a significant issue where we seek to effectively determine unobserved portions of a diffusion process.\n\n**Clarity.** The paper seems to be relatively well written.\n\n# Weaknesses\n\n**Research Area.** I'm not sure if this paper is targeted to the ICLR audience. I had large amounts of difficulty reading the paper and could not understand what exactly was being learned.\n\n**Clarity.** The paper has a large number of mathematical formula and was very dense to read. It may be nicer to provide a high level overview of what the paper is trying to as well as the existing challenges and what explicitly the work is trying to tackle.",
            "clarity,_quality,_novelty_and_reproducibility": "I had a hard time understanding what was going on in the paper, but I also lack background in this area.",
            "summary_of_the_review": "I don't really understand this paper -- I'm giving the paper a borderline accept but am complete unsure of my assessment.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2760/Reviewer_AGRQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2760/Reviewer_AGRQ"
        ]
    },
    {
        "id": "u1AtX077FS",
        "original": null,
        "number": 3,
        "cdate": 1667498054475,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667498054475,
        "tmdate": 1667498707841,
        "tddate": null,
        "forum": "_02M2MYThLz",
        "replyto": "_02M2MYThLz",
        "invitation": "ICLR.cc/2023/Conference/Paper2760/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new filtering methodology based on computational Doob's h-transform. The novelty is to get more efficient proposals, at least aim at it.",
            "strength_and_weaknesses": "Strength: Getting good proposals within particle filtering is an important problem\n\nWeaknesses: I think there were many (see below), mainly\n\n(i) Lack of clear and coherent description of the problem\n(ii) Experiments are low dimensional and are not interesting",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is not written in a clear way, the reason to use the control formulation and going to the point of using neural networks to approximate it is not explained. In terms of novelty, this kind of work is quite commonplace in particle filtering. The authors shared their code anonymously, I think that is very good.",
            "summary_of_the_review": "This paper has a number of problems before it can be published in a venue like ICLR. I think the current version is simply not interesting to the researchers in this field (ICLR crowd) - even to particle filtering people.\n\nThe paper phrases the problem of getting a good proposal as a control problem and approximates the relevant quantities using complex function approximators using neural networks. The claim is that the resulting method is more efficient under some extreme situations, like outliers or high-dimensions.\n\nThis paper could be an interesting contribution, it lacks very crucial experimental evidence:\n\n(i) While there is a sentence about runtime being two minutes and being less costly than BPF with \"many particles\", this claim was not made quantitative by *showing* that this is the case. This is not how computational efficiency claims are made.\n\n(ii) The dimensions are tested up to 32 are quite low. The claim in the earlier parts of the paper about efficiency in high-dimensions are completely unsupported. There are simply no true high-dimensional experiments, nothing like some of the published literature on PFs.\n\n(iii) \"Informative observations\" were tested by changing likelihood variance but another claim in the abstract \"when the observations are extreme under the model\" was not tested properly. What kind of extremes are we talking about? Is there a certain statistical setting for these extremes? This was not in the main text and might be pushed somewhere in the appendix, despite it looks like there was lots of space to use in the main text (e.g. page 8).\n\nGiven that there is almost no convincing experimental result, I won't discuss theoretical setting. It looks like this paper was rushed for the deadline and there was no time for experiments. It definitely needs comprehensive and rigorous updating and is not suitable for publication at this stage.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2760/Reviewer_rVdn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2760/Reviewer_rVdn"
        ]
    },
    {
        "id": "D8WxfkGLnEQ",
        "original": null,
        "number": 4,
        "cdate": 1667516734800,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667516734800,
        "tmdate": 1667516734800,
        "tddate": null,
        "forum": "_02M2MYThLz",
        "replyto": "_02M2MYThLz",
        "invitation": "ICLR.cc/2023/Conference/Paper2760/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a mathematically-grounded method for solving nonlinear filtering problems in a particle-based manner. The method is based on Auxiliary Particle Filters and, compared to Bayesian Bootstrap Filter [1], requires substantial mathematical and ML engineering efforts to be practically implemented. The authors show the validity of the approach by modeling several synthetic nonlinear filtering routines. \n\n[1] Salmond et. al. Novel approach to nonlinear/non-Gaussian Bayesian state estimation, 1993\n",
            "strength_and_weaknesses": "Strength: The mathematical foundations of the proposed method are interesting, but the problem of nonlinear filtering also seems to have important applications. \n\nWeaknesses: From my point of view, the paper under consideration has a relatively poor experimental section. Actually, the authors consider several synthetic nonlinear filtering problems and compute the metrics which only indirectly assess the quality of the proposed nonlinear filtering approach. Therefore, I still don't know if the method outperforms the competitive ones. I understand that it is difficult to find nonlinear filtering problems with known ground truth. That is why a better way is to consider some real-world nonlinear filtering applications with domain - specific metrics (probably not directly related to the nonlinear filtering itself) and evaluate the proposed approach on such a task. \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Quality and Clarity. The paper is more-or-less well-written. Yet there are some questions and points to improve regarding the paper flow:\n\n1) The paper's contributions should be explicitly stated somewhere at the beginning of the paper. \n\n2) It seems that the equation (6) contains a misprint (as I understand). The conditional measure in the integral $p_{T-t}(d \\boldsymbol{x}_T | \\boldsymbol{x})$ should be substituted with $p_{t}(d \\boldsymbol{x}_T | \\boldsymbol{x})$\n\n3) What are the distributions $\\eta_{\\boldsymbol{X}}$ and $\\eta_{\\boldsymbol{Y}}$ introduced on page 5?\n\n4) It is clearer and more convenient to introduce the CDT algorithm as a listing with pseudocode. \n\n5) The online filtering section also requires a listing with the proposed algorithm for nonlinear filtering. \n\n6) I have some questions regarding metrics used to compare different nonlinear filtering models. How are they defined? In particular, it needs to be clarified how to estimate the marginal likelihood $\\hat{p}(y_1, \\dots, y_K)$? What is an Effective Sample Size? Another question: Why is $\\mathbb{E}(\\log \\hat{p}(y_1, \\dots, y_K)$ called ELBO?\n\nNovelty: To the best of my knowledge, the proposed approach is definitely novel. The closest method is the bayesian bootstrap filter which is based on a much simpler mathematical foundation. The paper utilises some ideas from previous works, but their combination is rather unique and original. \n\nReproducibility: I didn\u2019t run the code provided, but it seems to be clearly written, and I have no particular doubts regarding reproducibility. \n",
            "summary_of_the_review": "The proposed method is theoretically interesting and mathematically rich. However, the applications section should be expanded with more convincing experiments, including real-world applications.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2760/Reviewer_dabH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2760/Reviewer_dabH"
        ]
    }
]