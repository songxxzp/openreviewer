[
    {
        "id": "_D55Twpagze",
        "original": null,
        "number": 1,
        "cdate": 1665978578455,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665978578455,
        "tmdate": 1666490595790,
        "tddate": null,
        "forum": "lw1WKaIL3LR",
        "replyto": "lw1WKaIL3LR",
        "invitation": "ICLR.cc/2023/Conference/Paper5522/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work identifies a limitation of multicalibration, relates multicalibration and differential calibration, and proposes a new metric of calibration, dubbed proportional multicalibration (PMC). Then it proposes an algorithm to achieve PMC and illustrate the performance of the proposed algorithm in simulated and hospital admission settings.  ",
            "strength_and_weaknesses": "Strengths:\n\nThis work is clearly written and addresses an important problem, calibration, that is relevant to model performance evaluation, trustworthiness, and algorithmic fairness. It is a blend of theoretical and computational contributions. The work is novel and provides new insight into the relationship between different definitions of calibration and addresses some of their limitations. The figures are very clear, and professional, and confidence intervals are computed. In general a strong contribution to the ICLR conference. \n\nWeaknesses:\nWhile due to limited time, I could not go through all the derivations and proofs in the appendices, and I found several mistakes in the proofs provided in the main text and computations. I might have made a mistake, but if I am not mistaken this work need to be reviewed comprehensively to make sure that there are no other mistakes in the proofs. \n\n\nMajor issues:: \n\n1. \"Proportionally multicalibrated models thereby obtain robust fairness guarantees that are independent of population risk categories.\" This is actually not strictly correct. In the proof of Theorem 3, we have $=\\frac{r\\delta}{1-\\delta} \\le \\frac{\\delta}{1-\\delta}$. While this is not incorrect, this is not the strongest upper bound, one can alternatively write $=\\frac{r\\delta}{1-\\delta} \\le \\frac{r_{max} \\delta}{1-\\delta}$ that is both stronger than the claim made in Theorem 3 and makes this bound dependent on population risk categories. Hence, under $\\alpha$-PMC, error in MC can depend on the population risk category. \n\n2. Theorem 1. \nAfter  plugging the lower and upper bounds into Eq. (2), we get $e^{\\epsilon} \\le \\frac{r_i + \\alpha}{r_j - \\alpha} $ not $e^{\\epsilon} \\ge \\frac{r + \\alpha}{r - \\alpha}$. Therefore, the maximum of this ratio will be  ${\\epsilon}  \\le \\ln(\\frac{r_{\\rm max} + \\alpha}{r_{\\rm min} - \\alpha})$  not ${\\epsilon} \\le \\log(\\frac{r_{\\rm min} + \\alpha}{r_{\\rm min} - \\alpha})$. Please also use $\\ln$ as $\\log$ is often reserved for log-10 based. Also, the inequalities should be $ \\le$, not $\\ge$. If it is $\\ge$ then $\\epsilon$ can be any large number and does not provide a meaningful bound on differential calibration. \n\n3. In a similar vein, in Theorem 2, the r in the denominator and nominator can be different and do not need to be the same, hence they do not cancel and the bound is still a function of $r$.\n\n4. I cannot replicate the numbers $6$% and $20$%, neither with the new formula nor with the old formula. Can you walk me through how these numbers are computed? \n \n\nMinor Issues: \n\n4. In Figure 3 (and results), the results are sensitive to the choice of $\\alpha$, and as the authors mentioned the optimal choice of $\\alpha$ might differ. I could not understand how the $\\alpha$ is chosen for each model (MC and MPC).\n\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Discarding the mistakes, the work is high quality and novel. \n\nClarity: \n\nSection 2.1. \"Given an individual\u2019s attributes $x = (x_1, . . . , x_d)$, it will be useful to refer to subsets we wish to protect, e.g. demographic identifiers.\" It is unclear what the authors want to say. \n\nSection 2.1. \"To do so, we define $A = \\{A_1, . . . , A_p\\}$, $p \\le d$, such that $A_1 = \\{x_{1i}\n, . . . , x_{1k}\\}$ is a finite set of values taken by attribute $x_1$.\" First of all, I do not understand what the authors want to say here (what are i and k? for example), second this notation is never used in this work. \n\nSection 2.3, second line. \"for all $S \\in C$\" should be \"for all $S \\in C$ and $r \\in [0, 1]$\"\n\nIn the last sentence before section 2.4, the references should be inside parentheses. \n\n",
            "summary_of_the_review": "While this paper is interesting and the contribution is novel and important, the current work requires another major review to make sure the proofs and math work out and there are no mistakes. Therefore, I recommend rejection. \n\nIf I misunderstood the proofs, please correct me. I would be glad to change my score.  ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5522/Reviewer_PsRB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5522/Reviewer_PsRB"
        ]
    },
    {
        "id": "imm-fx0315q",
        "original": null,
        "number": 2,
        "cdate": 1666552623601,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666552623601,
        "tmdate": 1666784339907,
        "tddate": null,
        "forum": "lw1WKaIL3LR",
        "replyto": "lw1WKaIL3LR",
        "invitation": "ICLR.cc/2023/Conference/Paper5522/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors introduce the notion of **proportional multicalibration** (PMC): a criteria that measures whether a model is both multicalibrated (MC) and fair (in the sense of differentiable calibration (DC) which is an extension of sufficiency). As a reminder, multicalibration refers to a notion of calibration by group and by bin (of confidence scores). And differential calibration, which is a notion introduced by the authors, ensures that any two groups in a collection have the same expected score for each bin (of confidence scores).\n\nThey show theoretically (Th.2 and Th. 3) that PMC implies **both** multicalibration and differential calibration. A post-processing algorithm is then provided to proportionally multicalibrate confidence scores. Finally, experiments on an hospital admission task using MIMIC IV show that the proposed algorithm decreases the MC, DC as well as PMC losses without decreasing the AUROC. \n",
            "strength_and_weaknesses": "**Strength**\n- The paper adresses a problem related to fairness with important practical implications.\u2028  \n- Completeness: the proposed measure is motivated theoretically, an algorithm is given to implement it practically, and experiments on simulated and real data are provided.\n\n**Weaknessess**\n-  I have a major concern regarding the theoretical results (Th. 1, 2, and 3). I am not sure that they are correct.\u2028  \n Let\u2019s take theorem 1, which states that multicalibration implies differential calibration. In the proof, $r$ is the expected confidence score over a group S in a bin I, and $p^*$ is the expected outcome over a group S in a bin I. In the proof, it seems to me that $p^\\star$ and $r$ are considered equal for all bins and groups. However, we have dependencies $r = r(I, S)$ and $p^* = p^*(I, S)$. So plugging into equation (2) would involve the quantities $r(I, S_i)$, $r(I, S_j)$, $p^*(I, S_i)$ and $p^*(I, S_j)$, so that the conclusion does not follow.  \nExactly the same comments apply to Theorem 2, which states that proportional multicalibration implies differential calibration.  \nFor Theorem 3, which states that proportional multicalibration implies multicalibration, the proof is done for the case $p^\\star > r$. I think the case $p^* < r$ should also be considered, otherwise the proof is not complete and the Theorem could be incorrect.\n\n- It is unclear to me how the hyperparameters have been chosen for the experiments ($\\alpha$, $\\lambda$, $\\gamma$, $\\rho$). This is however important to be able to evaluate the experiments correctly.\n\n- The main paper lacks a more thorough discussion/comparison of MC vs PMC in the experimental part. As it seems that MC with small values of $\\alpha$ can do as well as PMC for the various performance losses, I understand that in practice, the main advantage of PMC vs MC would be in terms of computational time budget. Do I understand correctly? It would be useful to discuss this in more depth in the main paper.\n",
            "clarity,_quality,_novelty_and_reproducibility": "I find the paper a little lacking in rigour and pedagogy overall. For example:  \n- I do not understand how the parameters ($\\alpha$, \u2026) have been chosen for the experiments on MIMIC (+ cf weaknesses).\n- It is unclear to me what is plotted in Figure 1.\n- The main paper is not self-contained. The losses used to measure experimental performances are only provided in Appendix. Tables  (eg Table 3) are referred to in the main text without specifying that they are in Appendix.\n- Theorem 4 states they there exists an algorithm for proportional multicalibration in a polynomial number of steps, then Algorithm 1 is presented as an algorithm which satisfies Theorem 4. It would sound more natural to me to introduce Algorithm 1, and then have a Proposition which states that it converges in a polynomial number of steps.\n\nIn terms of novelty, the proposed measure (proportional multicalibration) is new, and the post-processing algorithm proposed is a direct extension of the one for multicalibration.\n\nTypos:   \n* efficinet (just before paragraph 1.1\n* Outcomes y are random samples from $p^*(y|x)$ instead of $p^*(x)$?\n* MC similar on boosting -> MC similar to boosting",
            "summary_of_the_review": "The paper is interesting but penalised by too many unclear points (notably related to the correctness of the theorems, choice of hyperparameters, usefulness of PMC vs MC), that prevent me from being convinced by the paper.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5522/Reviewer_RcCa"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5522/Reviewer_RcCa"
        ]
    },
    {
        "id": "_3TJRVzdC4",
        "original": null,
        "number": 3,
        "cdate": 1666825753373,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666825753373,
        "tmdate": 1666825753373,
        "tddate": null,
        "forum": "lw1WKaIL3LR",
        "replyto": "lw1WKaIL3LR",
        "invitation": "ICLR.cc/2023/Conference/Paper5522/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "Multicalibration requires calibration of a predictor even conditioned on membership in S where S comes form a family of protected subsets. Formally, we require $E[y] = E[f(x)]$ conditioned on x belonging to S and $f(x) \\approx p$. If we relax this to allow $E[(y - f(x))] = \\alpha$, conditioned on $f(x) \\approx p$, we have $E[y] = p(1 \\pm \\alpha/p\\mu(p))$ where $\\mu(p)$ is the probability that $f(x) \\approx p|x \\in S$. \n\nThis paper posits that to achieve the fairness notion of sufficiency, one cares that we have a good multiplicative guarantee across all protected sets. Doing so requires\n1. The set $S$ to be reasonably large, so that $\\Pr(x \\in S) \\geq \\gamma$.\n2. The event $f(x) \\approx p|x \\in S$ to be reasonably large, in other words that $\\mu(p) \\geq \\delta$.\n3. The value $p$ itself is not too small.\n\nUnder these  conditions, multicalibration guarantees that condition of $S$, for most values $p$ (all but $\\alpha$ fraction), the expected value of $y$ is multiplicatively close to our predictions.\n\nThis paper proposes a new notion called proportional MC that achieves this guarantee. But it seems that it can  be achieved by setting parameters differently in the original definition, so I am not convinced that this is really a new notion (or that one is needed).  Indeed, if you look at Definition 1 and 3, you can infer 3 from 1 by taking $\\alpha = f(\\alpha, \\lambda,\\rho)$. In other words, sufficiently small error in the standard notion ensures the multiplicative notion that is desired here.\n\nAt a higher level, having only sample access means that the best guarantees one could hope for are of the form $$ E[I(x, f(x))(y -f(x))] \\leq \\alpha$$\nwhere $I$ is some event that depends on $x, f(x)$. Here it is $x \\in S, f(x) \\approx p$. If we wish to get multiplicative closeness under conditioning, we need:\n1. A lower bound $\\mu $ on how large E[I(x, f(x))] can be.\n2. Take the multi calibration error $\\alpha$ small enough so that $\\alpha/\\mu$ is meaningful. \n\nThis suffices the ensure that $E[y|I]$ and $[f(x)|I]$ are close. Here, since they want to error to be comparable to $p$, we also lower bound $p$. \n\n\n\n\n\n\n\n",
            "strength_and_weaknesses": "See above.",
            "clarity,_quality,_novelty_and_reproducibility": "See above.",
            "summary_of_the_review": "The message that this paper makes that if one wants strong sufficiency guarantees, one has to be mindful of possibly low probability events is a good one. But I don't think this calls for a new definition, rather just a judicious setting of parameters in the existing one. \n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5522/Reviewer_Csmw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5522/Reviewer_Csmw"
        ]
    },
    {
        "id": "c8_7nOmwcmF",
        "original": null,
        "number": 4,
        "cdate": 1667110792673,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667110792673,
        "tmdate": 1667110792673,
        "tddate": null,
        "forum": "lw1WKaIL3LR",
        "replyto": "lw1WKaIL3LR",
        "invitation": "ICLR.cc/2023/Conference/Paper5522/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes an interesting new notion of \"Proportional multicalibration\" for algorithmic fairness. Proportional multicalibration (PMC) builds on the notion of multicalibration (MC). MC requires that the predictor is calibrated for each (identifiable) group within the data, as opposed to simply requiring calibration over the entire population. The notion of MC has been well-studied at this point, and has been found to be useful in practical contexts as well.\n\nThe authors point out a potential flaw in MC. MC is defined to allow an additive calibration error (following on the standard notion of calibration, which is also defined additively). The authors claim that this could be problematic since it allows for a larger relative calibration error for groups which have smaller probability estimates. PMC aims to correct for this, by requiring that the relative calibration error be bounded for all the groups. PMC also satisfies a notion of differential-calibration with better guarantees than MC.\n\nThe authors substantiate their theoretical results with an interesting experiment on real-world hospital data.",
            "strength_and_weaknesses": "Strengths:\n\n1. The authors point out a potentially important issue with calibration scores (the fact that they could lead to larger errors for groups with lower probability estimates). PMC seems like a good way to correct for this,\n\n2. The authors establish an interesting connection between MC and notions of sufficiency and the new notion of differential calibration. The notion of sufficiency seems quite related to the concept of \"Outcome indistinguishability\" (https://arxiv.org/abs/2011.13426) and it would be nice if the authors elaborate a bit more on this connection.\n\n3. I quite liked the fact that the authors evaluated their results on real-world data which comes close to capturing the problem the paper aims to solve.\n\nWeaknesses:\n\n1. The paper has a number of strengths, but I'm not fully convinced of the papers claim about the superiority of PMC to MC. To me, the choice of relative error vs additive errors seems to be closer to a normative judgement, or at the very least the two need to be compared with respect to how they affect decision making in the use cases. Can I not make the claim that the proposed relative error notion is unfair, since it allows for a larger (additive) error for groups which do have higher probabilities? Could a decision maker not end up having less trust in the model's predictions if it has higher errors for those groups? Additive error almost seems like a simpler to understand notion (since the error remains the same for all predicted probabilities), and I could be convinced to believe that it could lead to better downstream decision making because of this property. Perhaps the authors can point out contexts where calibration itself is more meaningfully defined as a relative notion rather than an additive notion? If these settings exists, then PMC naturally comes out as a better solution than MC.\n\n2. I think it would be good if the authors commented a bit more on the fact that PMC seems to have lower accuracy than MC in the real-world experiment (I appreciate that the authors include this result). Is PMC trading-off increasing fairness guarantees for accuracy?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is very well-written and easy to read. Some minor typos:\n\n1. Page 4: That its-> That is. 1st sentence of 2.4: \"MC constraints\". \n\nNovelty: The key claims made in the paper appear to be novel to me. The paper uses a lot of algorithmic machinery from previous papers on MC, but I believe that is not the key point of this paper.\n\nReproducibility: Detailed code and instructions to run the experiments are provided.",
            "summary_of_the_review": "In summary, I quite liked reading this paper and I think it has interesting ideas. Even at the current stage, it would be an interesting addition to the ICLR program. Perhaps the authors could comment a bit more on the weaknesses I wrote earlier?",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5522/Reviewer_oBPB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5522/Reviewer_oBPB"
        ]
    }
]