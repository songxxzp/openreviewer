[
    {
        "id": "UsuYYmE-b1",
        "original": null,
        "number": 1,
        "cdate": 1665975230391,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665975230391,
        "tmdate": 1665975733560,
        "tddate": null,
        "forum": "XDJwuEYHhme",
        "replyto": "XDJwuEYHhme",
        "invitation": "ICLR.cc/2023/Conference/Paper1647/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper works on contrastive self-supervised learning (SSL) and gives several bounds between the assumed latent class structure of the dataset in terms of different parts of the loss functions. For example, bounds of angles between two cluster centers $\\mu_j^\\top\\mu_k$ (Theorem 1, Theorem 3, Theorem 4), size of the regions where the representation of the input x is different from its view (Theorem 2)), in terms of different loss terms, such as (1) feature alignment within augmentation, and (2) divergence metric across views of different samples. Note that (1) and (2) are largely defined in (Wang and Isola, 2020), and the paper claims that they further study a third term $R_\\epsilon$ that represents by the role played by data augmentation, through the lens of a newly proposed concentration metric for augmentation data, i.e., $(\\sigma, \\delta)$-augmentation. Experiments verify the relationship of the downstream KNN classification performance and the concentration of learned feature for each latent class (Eqn. 3).",
            "strength_and_weaknesses": "Strength\n1. The paper works on an important problem in contrastive learning: how the data augmentation plays the role in learning good representation. \n2. The paper builds theoretical connections between different parts of loss functions to be optimized and the corresponding latent class structure. \n3. The paper is well-written with clear motivations and explanation. \n\nWeakness\n1. Claim in the intro doesn't quite match the content. \n\nWhile the author claims that they also consider a third factor concerning the concentration of data augmentation, in addition to the existing two factors, i.e., alignment and diversity / uniformity in the sphere, as in (Wang and Isola, 2020). In the analysis, it seems that the contrastive loss is still decomposed into two terms, and concentration of data augmentation serves as the additional terms in the upper bounds in theorems. It would be great if the paper can be revised to make the contribution more clear and precise. \n\n2. No comparison between InfoNCE, Barlow Twins and t-InfoNCE.\n\nFrom the analysis, it looks like all losses have two components that can bound the property of latent class models. Then a natural question is what's the pros and cons of InfoNCE, versus Barlow Twins and t-InfoNCE? In which scenarios one is better than others? It would be great if the authors could give empirical guidance. \n\n3. More experiments can be done to verify the points. \n\nThe experiments in Tab. 1-2 are largely common sense: researchers in SSL know that large augmentation helps downstream tasks, without referring to the proposed theory. While Fig. 3 is good, more ablation studies are needed to verify components of the theory. It would be great if the authors could provide experiments on synthetic datasets with the analyzed loss functions (InfoNCE, Barlow Twins and t-InfoNCE), in which the data exactly follow the latent classes assumption with ground truth (and known) concentration, and verify the theory in more details. \n\n4. Issues in mathematical rigidity. \n\nThe are some issues in the definition. $\\cap_{k=1}^K A(C_k) = \\emptyset$ doesn't mean $A(C_k)$ and $A(C_j)$ are pairwise disjoint. \n\nThe nearest neighbor classifier (last equation in Page 3) CANNOT be reformulated to be linear classifier, because what if several class centers $\\{\\mu_k\\}$ are co-linear (i.e., there exists a common vector $v$ so that $\\mu_k = \\lambda_k v$) , then linear classifier can only predict the two \"end-points\" (i.e., $\\arg\\max_k \\lambda_k$ and $\\arg\\min_k \\lambda_k$) since the score of other classes will already be dominated by the two end-points. However, NN can predict these classes with ease. \n\nSome notations are really confusing. E.g., the definition of $\\mathcal{L}_1$ and $\\mathcal{L}_2$ should be different for InfoNCE (Eqn. 5) and for Barlow Twins, yet they use the same notation, making it hard to understand. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is relatively novel, clear with reasonable quality. \n\nThe paper can be reproduced relatively easily. ",
            "summary_of_the_review": "Overall the paper has pros and cons and I am on the boundary. If authors address my concerns, I will raise the score. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1647/Reviewer_Lkqf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1647/Reviewer_Lkqf"
        ]
    },
    {
        "id": "FwrHLgSJjZK",
        "original": null,
        "number": 2,
        "cdate": 1666549397854,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666549397854,
        "tmdate": 1669235111812,
        "tddate": null,
        "forum": "XDJwuEYHhme",
        "replyto": "XDJwuEYHhme",
        "invitation": "ICLR.cc/2023/Conference/Paper1647/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the authors analyzed the Self-supervised learning frameworks such as SimCLR, MoCo, and Barlow Twins in perspective of augmentations. (sigma-delta) augmentation was defined to indicate how close the augmented data with the same class are. The authors suggested three important properties to analyze the performance of SSL: alignment, divergence, and concentration. Common SSL losses, InfoNCE, and Cross-Correlation loss can be split into smaller components which are represented as the optimization terms of the alignment and divergence properties. In experiments, various augmentation settings with different strengths were used for comparing the downstream performance with them. In CIFAR-10 and CIFAR-100, the model trained with stronger augmentations can be more robust than with weaker ones. The stronger augmentation can imply a more concentrated cluster of each class.\n",
            "strength_and_weaknesses": "## Strengths\n+ Theoretical analyses on the effect of augmentations are less often than ones on the negative samples recently. This paper may give some insights into further research on both positive and negative samples in SSL.\n+ There were few attempts to analyze the mechanism of SSL frameworks without negative samples such as BYOL and Barlow Twins (BT). To prove the robustness of SSL models, the integrated perspective which includes both InfoNCE and non-InfoNCE-based frameworks will be needed and this paper can be the pioneer of it.\n+ The authors defined the three important properties which can represent the status of distribution of the features. Their concept can be widely used to further researchers who analyze similar problems.\n\n## Weaknesses\n- I think that lack of information on recent works may decline their work's novelty. Recently, some papers analyzed the relationship between SSL loss function and supervised learning loss with the collision phenomena such as [1]. In [1], the authors showed that the upper bound of supervised learning loss contains the intra-class variance term which is similar to the concentration property in this paper. I carefully suggest including more recent works which tried to solve a similar problem.\n- The authors used popular, but somewhat old-fashioned augmentations to validate their claims. One of the main results of this paper is stronger augmentations will bring higher performance. However, another recent work [2] said the dramatic distortion of the data can harm the essential information for the downstream tasks (in this case, classification), and it will degrade the performance in the end. This implies that their claim can be right in their experiment settings, but it may not be applied always. Conducting more experiments with other datasets or stronger augmentations such as adversarial attack-based augmentations can be a good way to justify the authors' claims.\n- The authors analyzed alignment and divergence properties in theoretical ways. However, there are no experiments that support their theory. Instead, there are only experiments for the empirical study of concentration property. In general, we cannot be sure that a property is always preserved when the model is trained with a loss with it. This means that there may still exist some performance drops caused by the former two properties (alignment and divergence) in the experiments on the concentration property. I suggest adding more analyses to show the trained model satisfies the former two properties in every augmentation set.\n\n[1] Ash, Jordan, et al. \"Investigating the Role of Negatives in Contrastive Representation Learning.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2022.\n\n[2] Yang, Kaiwen, et al. \"Identity-Disentangled Adversarial Augmentation for Self-supervised Learning.\" International Conference on Machine Learning. PMLR, 2022.",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity\n- The authors defined alignment and divergence properties with well-defined formulas and showed InfoNCE and Cross-Correlation loss can be interpreted with these two terms. However, this paper only includes the empirical analysis of the concentration property, which may be more essential. Also, these experiments did not support the author's claims enough.\n\n### Quality\n- The paper included plenty of information to analyze the SSL framework in a theoretical way. Especially, the authors tried to prove the Cross-Correlation loss in BT, which is rarely discussed in previous works. I think the quality of this work can be much improved if the authors add more explanations and experiments to support their claims.\n\n### Novelty\n- As mentioned above, the three properties to measure the SSL's performance will bring valuable insights to further researchers. Recently, there are some other analyses on the InfoNCE loss, and updating recent works in this paper can make this work more novel.\n\n### Reproducibility\n- The authors used popular frameworks and well-known augmentation techniques in computer vision. The proofs of their claims are represented in the appendix, so the reader can follow them to understand the authors' claims.\n",
            "summary_of_the_review": "The authors defined (sigma-delta) augmentation and three important properties to measure the SSL model's performance. InfoNCE and Cross-Correlation loss functions can be separated into two components that optimize the alignment and divergence properties respectively. To show the correlations between concentration property and augmentation, the authors conducted several experiments with various augmentation sets with different intensities. Updating more recent works and adding more exact analyses or experiments on each property can dramatically enhance this work's novelty.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1647/Reviewer_R8Eq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1647/Reviewer_R8Eq"
        ]
    },
    {
        "id": "Lgb5C8lH7M",
        "original": null,
        "number": 3,
        "cdate": 1666959749014,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666959749014,
        "tmdate": 1666959749014,
        "tddate": null,
        "forum": "XDJwuEYHhme",
        "replyto": "XDJwuEYHhme",
        "invitation": "ICLR.cc/2023/Conference/Paper1647/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper study the generalisation capabilities of contrastive self-supervised learning models, showing that the data augmentation strategy is key to generalisation. They decompose the problem of learning visual representations with siamese networks into 3 crucial parts, alignment of positive samples, divergence of class centers, and concentration of augmented data. By defining the problem formally, they derive upper bounds on the performance of a downstream classifier, that depends on the expressivity of the chosen data augmentation.\n",
            "strength_and_weaknesses": "Strength:\n\n1) The problem is clearly stated and properly mathematically defined, which allows a formal analysis on the role of alignment, divergence, and data augmentation in the downstream performance of some popular self-supervised learning algorithms. The paper provide theoretical understanding on why these components are essential and suffisant to learn meaningful representations.\n\n2) The proposed framework could be used to analyse other self-supervised methods based on an explicit collapse prevention term in the loss, by simply showing how the quantity $\\mu_k^T \\mu_l$ is bounded by the term. Garanties on the performance of the downstream classifier can be derived automatically.\n\n3) Showing experimentally the correlation between $\\mathrm{Err}(G_f)$ and $1 - \\sigma$ is nice. Having more experimental results on the relation with $\\delta$ as well would be even better.\n \n\n\nWeaknesses:\n\n1) Some self-supervised learning methods are hard to modelize in the proposed framework. For exemple BYOL and SimSiam which have no explicit collapse prevention mechanism in their loss function. How would you derive similar bounds for these methods ?\n\n2) It is hard to tell how tight the bounds are in practice. Could you derive practical insights from your theoretical analysis ? For exemple design better data augmentations ?\n\n3) The experimental analysis and the experimental results of Table 1 and Table 2 are very basic and already known results.\n\n\nRemarks and Questions:\n\n1) How would you tackle the case where the $A(C_k)$ intersect ?\n\n2) What is the intuition behind the \"Main part\" in Definition 1 ? Is it a critical detail ?\n\n3) \"Thus, the semantic distance can be partially characterised by the proposed augmented distance\". I believe semantic is much more complex than visual ressemblance. Making this assumption would not work for less fine-grained classification tasks where two samples from the same class are not necessarily visually similar. This might be an inherent shortcoming of these methods based on learning invariances to data augmentations. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: the paper is mathematically heavy but clear and easy to follow as motivations, intuitions behind the theorems and exemples are provided.\n\nNovelty: the paper clearly position itself in the theoretical self-supervised learning literature, and provide useful and new insights that are valuable for the community",
            "summary_of_the_review": "The theoretical contribution of the paper is significant and valuable as the proposed framework could be used as a basis to analyse other self-supervised learning methods. However it is unclear how it could lead to practical insights that could improve these algorithms. For these reasons I recommend the score of 6.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1647/Reviewer_kpZM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1647/Reviewer_kpZM"
        ]
    },
    {
        "id": "M97_OMkskUz",
        "original": null,
        "number": 4,
        "cdate": 1666976220718,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666976220718,
        "tmdate": 1666976220718,
        "tddate": null,
        "forum": "XDJwuEYHhme",
        "replyto": "XDJwuEYHhme",
        "invitation": "ICLR.cc/2023/Conference/Paper1647/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper develops a new theoretical understanding of generalization for self-supervised contrastive methods. In particular, a $(\\sigma, \\delta)$ formulation is proposed to quantify the strength of data augmentation. A generalization bound on KNN error is derived based on the $(\\sigma, \\delta)$ formulation. Three key factors: alignment, divergence, and concentration were proposed, which are closely related to the generalization performance. Then the authors relate the first two factors with various contrastive objectives and prove that such different objectives all implicitly optimize the two factors. Finally, empirical experiments on CIFAR10 and CIFAR100 are conducted to study the effect of the third factor. The authors observe that the generalization performance is highly correlated to the third factor.\n",
            "strength_and_weaknesses": "Strength:\n- This paper is well motivated. I can easily get the idea and insights from the theorems. This paper well explains the main phenomenon of contrastive learning that only aligning positive samples is able to gather the samples from the same latent class into a cluster.\n- The $(\\sigma, \\delta)$ formulation of data augmentation is novel. It provides a new yet simple modeling of augmented data compared to the previous graph modeling in Haochen et al [1]. More interestingly, the analysis of this paper can be directly applied to the realistic losses (eg. SimCLR, Barlow Twins, t-InfoNCE) used in practice, while [1] only suits their spectral contrastive loss.\n- Based on the proposed $(\\sigma, \\delta)$ formulation, the generalization analysis of contrastive learning becomes much more natural. Three vital factors are derived from the main result (Thm 1): alignment, divergence, and concentration. The first two factors extend the well-known alignment and uniformity in [2], and match people's intuition better. The third concentration factor is a key concept of this paper. It reveals the prerequisite for contrastive learning to work, since it does not depend on learning algorithms.\n- Section 4 is quite interesting in the sense that the analysis dissects various contrastive learning objectives from the view of the proposed theoretical framework. Various interesting insights emerge, such as why logsumexp is crucial to InfoNCE, and how to properly understand multiple contrastive losses commonly used in practice. Especially for Barlow Twins, it is very interesting to see that optimizing the statistical objective actually optimizes the geometric structure of embedding space. \n- Although the concentration factor is drived from the upper bound of KNN error, it still can provide some predictions for real downstream performance. For example, it is surprising to see that $1-\\sigma$ correlates with KNN error so well (Fig 3) in real-world experiments. It also provides an explaination for the observation in SimCLR paper that \"crop&color\" is the best (due to the sharp concentration). Moreover, the concentration concept can help to understand why (c) color dropping has a great impact on performance (Table 1).\n\nWeaknesses:\n- Compared with [2], the authors claim that the divergence condition can be loosened by better alignment and concentration properties. It seems this is a key difference from [2] but lacks of explainations. Can you provide more explanations on this to help me understand correctly? \n- In Table 1&2, if I further increase the strength of augmentation, will the performance decrease? If so, can your theory explain it?\n- Additional experiments on large-scale datasets such as ImageNet (especially Fig 3 setting) would be better. But the existing experiments are okay for a theory paper.\n- I wonder if the theory can be extended to other self-supervised algorithms such as BYOL [3], MAE [4]. Is the theory applicable to multi-modal contrastive algorithms such as CLIP [5] or only applicable to vision data?\n\n[1] Jeff Z HaoChen, Colin Wei, Adrien Gaidon, and Tengyu Ma. Provable guarantees for self-supervised deep learning with spectral contrastive loss. Advances in Neural Information Processing Systems, 34, 2021.\n[2] Tongzhou Wang and Phillip Isola. Understanding contrastive representation learning through align\u0002ment and uniformity on the hypersphere. In International Conference on Machine Learning, pp. 9929\u20139939. PMLR, 2020.\n[3] Jean-Bastien Grill, Florian Strub, Florent Altch\u00e9, Corentin Tallec, Pierre H Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Daniel Guo, Mohammad Gheshlaghi Azar, et al. Bootstrap your own latent: A new approach to self-supervised learning. arXiv preprint arXiv:2006.07733, 2020. \n[4] Kaiming He, et al. Masked autoencoders are scalable vision learners.\u00a0Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.\n[5] Alec Radford, et al. \"Learning transferable visual models from natural language supervision.\"\u00a0International Conference on Machine Learning. PMLR, 2021.\n",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity: This paper is well-written and easy to follow.\n- Quality: I read the full paper, including all the theorems, lemmas and most of the proof in appendix. The hypothesis is sound and the math is solid.\n- Novelty: This paper proposes a new theoretical framework for understanding contrastive learning. The formulation of data augmentation is novel and simple. Various interesting insights emerge in Section 3 and 4.\n",
            "summary_of_the_review": "Overall, the paper provides a different perspective on the theoretical analysis of the generalization guarantees of contrastive learning by modeling the concentration of augmented data. It also reveals the important role of augmentation in contrastive learning. The hypothesis is sound and the mathematical proof looks good to me. The insights from theorems are very interesting, including the three key factors of generalization, why decorrelating the components of representation results in alignment and divergence, why logsumexp is crucial to InfoNCE, why \"crop&color\" is the best composition of data augmentation, etc. I really enjoy reading this paper. I believe that this work can enhance people's understanding of contrastive learning, and provide guidance on selecting augmentations and improving existing contrastive learning methods. Self-supervised learning field is usually algorithm-driven and hence seeks more theoretical understanding. Therefore, I strongly recommend to accept this paper. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1647/Reviewer_qUte"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1647/Reviewer_qUte"
        ]
    },
    {
        "id": "Qhox2IYCjyc",
        "original": null,
        "number": 5,
        "cdate": 1666982468743,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666982468743,
        "tmdate": 1666983577985,
        "tddate": null,
        "forum": "XDJwuEYHhme",
        "replyto": "XDJwuEYHhme",
        "invitation": "ICLR.cc/2023/Conference/Paper1647/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies and quantifies the generalization capability of contrastive learning approaches. Specifically, the paper derives the upper bound of downstream error by introducing the $(\\sigma, \\delta)$-augmentation. The theorems quantify the generalization capability regarding the alignment, divergence, and augmentation concentration.",
            "strength_and_weaknesses": "### Strengths\n\n(+) The studied problem of contrastive learning generalization is very interesting and significant.\n\n(+) The theorems look solid and insightful. Examples and intuitive explanations are provided for a better understanding.\n\n(+) The paper is well-organized and easy to follow.\n\n### Weakness\n\n(-) The empirical contribution may be limited since many results are very intuitive and have been (empirically) discovered by existing works. It would be better if some new augmentation approaches or practical guidance based on the theorems can be provided. E.g, are there any optimization approaches to generate augmentations that guarantee the highest concentration subject to that divergence and alignment are achieved?\n\n### Suggestions and questions\n\n- The authors briefly discuss existing theoretical works in contrastive learning. Although they are based on different groundings, I can see there may be some common conclusions or insights. The authors discuss the difference between their theory and the \u201calignment and uniformity\u201d-based studies. It would be a great additional contribution if the author can include some discussions or analyses to align more works from different grounding, e.g., MI-based and expansion-based.\n\n- Would it be possible to give a formal definition or description of the latent classes? Are they simply based on the semantics of data?\n\n- Can the (\\sigma, \\delta)-augmentation cover all kinds of augmentations in practice, i.e., for some augmentations, there is no such a set and \\sigma for some \\delta? What would happen to the conclusion in this case, if exist?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is overall well written with good readability.\n\nQuality: The theorem looks solid with experimental justifications. But I didn't check the proof thoroughly.\n\nNovelty: The idea of alignment and uniformity has been studied in existing works. But the work focus on the effect of augmentation and has some novelty.\n\nReproducibility: n/a",
            "summary_of_the_review": "I overall enjoyed reading this paper. The theoretical part is informative and solid. But there are some limitations in the empirical contribution and the practical guidance of the theorems.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1647/Reviewer_LX5M"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1647/Reviewer_LX5M"
        ]
    }
]