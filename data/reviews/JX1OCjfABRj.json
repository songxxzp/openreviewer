[
    {
        "id": "5JucfcNt0QA",
        "original": null,
        "number": 1,
        "cdate": 1666665057000,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666665057000,
        "tmdate": 1666665057000,
        "tddate": null,
        "forum": "JX1OCjfABRj",
        "replyto": "JX1OCjfABRj",
        "invitation": "ICLR.cc/2023/Conference/Paper2200/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a method to perform adversarial training with adaptive epsilon per training sample. Several heuristics are proposed to determine epsilon per sample. The benefit is improved accuracy-robustness trade-off.",
            "strength_and_weaknesses": "Strength: This paper is working on a meaningful problem. Finding adaptive epsilon per training sample could be the key to break the accuracy-robustness trade-off and do well on both clean and perturbed data.\n\nWeaknesses:\n\n1. The proposed heuristics involve substantial approximation.\nFirst of all, the proposed loss function (5) is already a heuristic, -- it's assuming that the optimal epsilon_i is such that the derivative of perturbed-loss with respect to epsilon_i is equal to lambda. There is no guarantee that the derivative of perturbed-loss with respect to epsilon is a good metric to use to determine optimal epsilon.\nOn top of that, the proposal is not to solve (5) directly but rather to use a crude heuristic described in section 3.3, equation (7) and the paragraph after it. There are more heuristics in section 4 but experimental results suggest that they are worse than that in section 3.3.\nWith such approximation on top of approximation, it's unclear whether the final algorithm is a meaningful solution to the original problem.\n\n2. In the main results tables 2 and 3, the \"Standard\" rows are substantially worse than the numbers reported in (Madry et al., 2017). Please explain. If compared with the original numbers in (Madry et al., 2017), it seems that the proposed method is only marginally better. Also for TRADES, tables 2 and 3 suggest that the proposed method is only marginally better. Results in table 4 are strong and it's worth adding detailed analysis on what makes CIFAR100 more favorable for the proposed method.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity is good.\n\nQuality is fair.\n\nNovelty is fair.\n\nReproducibility is good.",
            "summary_of_the_review": "This paper is addressing a meaningful problem. However, the proposed method is a crude heuristic and may need improvement, and there are some questionable numbers in the experimental results.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2200/Reviewer_CG7K"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2200/Reviewer_CG7K"
        ]
    },
    {
        "id": "_nK6rHxDse0",
        "original": null,
        "number": 2,
        "cdate": 1666669193518,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666669193518,
        "tmdate": 1667789067446,
        "tddate": null,
        "forum": "JX1OCjfABRj",
        "replyto": "JX1OCjfABRj",
        "invitation": "ICLR.cc/2023/Conference/Paper2200/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper advocate assigning adaptive perturbation constraint $\\epsilon$ to adversarial examples, during the inner maximization in adversarial training. Experiment results show that the SAAT method can improve the adversarial robustness compared with several existing methods.",
            "strength_and_weaknesses": "How to find a suitable epsilon is a widely studied problem, including some methods mentioned in the paper, and [1]. [1] tested the effect of different epsilon variation strategies on robustness, including Constant, Linear, Cosine, and their version of period reset. This paper also adopts a linear schedule, hope the authors discuss and compare their method with [1].\nThe main mechanism of the proposed method is \"Specifically, if the PGD attack fails to find an adversarial image xi + \u03b4i that can be misclassified, it implies \u03b5\u2217i is too small. Thus, we set \u03b5\u2217i = \u03b5\u2217i + \u03b7. Otherwise, we set \u03b5\u2217i = \u03b5\u2217i \u2212 \u03b7, where \u03b7 is a pre-specified fixed step size.\" Actually, the method is not novel from my perspective, and it provides little insight. \n\nSome questions about the experiments:\n1. The result of the AA attack against AT and TRADES in Table 4 seems too low, some papers have tested under similar settings, and performs better results [2, 3]. Could the authors have a little check?\n2. What about the performance of TRADES + SAAT?\n3. How the robustness will increase when training on a larger model, e.g., WRN-34-10? And what about the effective improvement in robustness when training with additional data?\n\n\n[1] Liu C, et al. On the loss landscape of adversarial training: Identifying challenges and how to overcome them. In NeurIps 2020.\n\n[2] Dong Y, et al. Exploring Memorization in Adversarial Training. In ICLR 2022.\n\n[3] Wu D, et al. Adversarial weight perturbation helps robust generalization. In NeurIps 2020.",
            "clarity,_quality,_novelty_and_reproducibility": "The novelty of this paper is limited from my perspective.",
            "summary_of_the_review": "The contribution is limited, and the empirical comparisons are not convincing to me.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2200/Reviewer_qfVT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2200/Reviewer_qfVT"
        ]
    },
    {
        "id": "FBW9wc0_Ja",
        "original": null,
        "number": 3,
        "cdate": 1666670262557,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666670262557,
        "tmdate": 1666670262557,
        "tddate": null,
        "forum": "JX1OCjfABRj",
        "replyto": "JX1OCjfABRj",
        "invitation": "ICLR.cc/2023/Conference/Paper2200/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes a new method for searching for optimal perturbation radii for adversarial training, which is shown to be more efficient than existing works.  ",
            "strength_and_weaknesses": "Strength\n- Well written. \n- Propose an efficient approach for searching for adaptive perturbation radii for each data point. It has better performance thant the compared methods. \n\nWeakness\n- Regarding the robustness performance, the compared methods are far from SOTA. The current robustenss performance of the proposed approach is not significant. \n- It is claimed that the adaptive radii could help allievate the accuracy-robustness trade-off. However, according to the experimental results,  the natural accuracy does not change much except the cifar100 dataset. Could you explain why the case in this dataset? ",
            "clarity,_quality,_novelty_and_reproducibility": "See the above. ",
            "summary_of_the_review": "Personally I appreciate the approach proposed by the authors, but the performance is not that significant. Thus I suggest weak acceptance. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2200/Reviewer_LAk2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2200/Reviewer_LAk2"
        ]
    }
]