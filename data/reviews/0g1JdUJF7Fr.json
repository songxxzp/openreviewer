[
    {
        "id": "Gx028eSCoGP",
        "original": null,
        "number": 1,
        "cdate": 1666560944080,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666560944080,
        "tmdate": 1666560944080,
        "tddate": null,
        "forum": "0g1JdUJF7Fr",
        "replyto": "0g1JdUJF7Fr",
        "invitation": "ICLR.cc/2023/Conference/Paper1706/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work theoretically investigate the unpaired techniques based on Generative Adversarial Networks (GANs) which arise in  super-resolution tasks, and find two observations: first the learned SR map is always an optimal transport map; second, the learned map is biased. The observations are supported by theoretical proofs and empirical experiments. The work proposes an algorithm for unpaired SR which learns an unbaised OT map for the perceptual transport cost. This method reduces the need for complex hyperparamter selection and additional regularizations. The proposed model provides a nearly state-of-the-art performance on unpaired AIM19 datasest.\n\nThe contributions are:\n1. the work investigate the GAN optimization objectives regularized with content loss, and prove the solutions are always OT maps, but biased;\n2. the work provide an algorithm to fit an unbiased OT map for perceptual transport cost and applied it for the SR problem, establishes connections between the proposed model and regularized GANs using IPMs as a loss.\n",
            "strength_and_weaknesses": "The strength of the work are:  it has unique observations on conventional GANs for unpaired SR problem, and proves the solutions of GANs are OT maps, but biased, then provides an unbiased solution; The mathematical model and formulations are elegant and powerful, the algorithm is effective; the experimental results show the proposed method achieves SOTA in SR applications; it is a good example of combing rigorous mathematical model with real world applications.\n\nThe weakness is that the minmax optimization proposed by the work can find the saddle points, which may not correspond to optimal solutions, this step needs further exploration.",
            "clarity,_quality,_novelty_and_reproducibility": "The work is very well written, the problem statement, the mathematical formulation, key lemmas and main proofs are very clean the elegant, the deduction is easy to follow, the experimental results are well analyzed and convincing. The observations are novel, it discovers the intrinsic connection between SR problem and OT theory. The authors provide source codes, it is easy to reproduce.",
            "summary_of_the_review": "This work theoretically investigate the unpaired techniques based on Generative Adversarial Networks (GANs) which arise in  super-resolution tasks, and find two observations: first the learned SR map is always an optimal transport map; second, the learned map is biased. The observations are supported by theoretical proofs and empirical experiments. The work proposes an algorithm for unpaired SR which learns an unbaised OT map for the perceptual transport cost. This method reduces the need for complex hyperparamter selection and additional regularizations. The proposed model provides a nearly state-of-the-art performance on unpaired AIM19 datasest.\n\nThese observations are novel, it discovers the intrinsic connection between SR problem and OT theory. The work is very well written, the problem statement, the mathematical formulation, key lemmas and main proofs are very clean the elegant, the deduction is easy to follow, the experimental results are well analyzed and convincing.  The authors provide source codes, it is easy to reproduce. In summary, the work is inspiring and promising, it has both theoretical and practical values.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "This work focuses on fundamental research, it focuses on theoretical aspect. Furthermore, it points out that conventional method may produce biased medical images, which may lead to wrong diagnosis. So this work improves the conventional method and overcome the problem.",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1706/Reviewer_nWwQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1706/Reviewer_nWwQ"
        ]
    },
    {
        "id": "WSWFhJ0QIIm",
        "original": null,
        "number": 2,
        "cdate": 1666621927550,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666621927550,
        "tmdate": 1666621927550,
        "tddate": null,
        "forum": "0g1JdUJF7Fr",
        "replyto": "0g1JdUJF7Fr",
        "invitation": "ICLR.cc/2023/Conference/Paper1706/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper introduces  an algorithm for unpaired  super-resolution which learns an unbiased OT map for the perceptual transport cost.  Unlike the existing GAN-based alternatives, this proposed  algorithm has a simple optimization objective reducing the need for complex hyperparameter selection and an application of additional regularizations.\n\nContributions: \nThis paper provides an algorithm to fit an unbiased OT map for perceptual transport cost and apply it to the unpaired image SR problem. In addition, it investigate the GAN optimization objectives regularized with content losses.",
            "strength_and_weaknesses": "This paper has a sufficient theoretical analysis, but its weaknesses is that the empirical evaluation is not sufficient.\nOnly two methods FSSR (Fritsche et al., 2019) and DASR (Wei et al., 2021) have been compared on the dataset AIM 2019, and both methods use two GANs. There are many existing SR methods based on a single WGAN. What is the reason why this paper does not compare with them?\nIn addition, the following issues still need to be further explained.\n1. As shown in equation 12, the proposed method fits a one-to-one optimal mapping (transport map) for super-resolution which, in general, might not exist.  To solve this problem, what special settings are required in real world super-resolution tasks?\n2. The author declares that the proposed OTS is different from the regularized IPM GAN, Because in OST,  the OT map T is a solution to the inner optimization problem, while in IPM GAN the\ngenerator T is a solution to the outer problem.  But from algorithm 1, there is no difference between finding inf first and finding sup first.\n3. The author declares  ' in OTS the optimization over potential f is unconstrained, while in IPM GAN it must belong to F '.  \n     This is not fair.  On the one hand, both potential functions need to be realized by neural networks. On the other hand, for  regularized IPM GAN, distance measure is also optional, but the two algorithms referred to in this paper are  Wasserstein-1.",
            "clarity,_quality,_novelty_and_reproducibility": "It is interesting to see that the authors expand the Dual form of OT to address unpaired SR task. For the technical side, the algirithom proposed in this paper extends the applications of existing SR practice.\nAnd, the paper is well-organized and clearly written. \nHowever, the final inequality of Equation10 requires more detailed proof. Intuitively, even for sufficiently small \u03f5, the inequality is not obvious.",
            "summary_of_the_review": "This paper introduces  an algorithm for unpaired  super-resolution which learns an unbiased OT map for the perceptual transport cost.  This proposed algirithom extends the applications of existing SR practice.\nThe approach is technically relatively sound with some small flaw.  the paper is well-organized and clearly written. \nMore experimental evaluations are helpful to prove the effectiveness of the algorithm.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1706/Reviewer_mWTP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1706/Reviewer_mWTP"
        ]
    },
    {
        "id": "T7zyudZx9Mc",
        "original": null,
        "number": 3,
        "cdate": 1666647739423,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666647739423,
        "tmdate": 1666647739423,
        "tddate": null,
        "forum": "0g1JdUJF7Fr",
        "replyto": "0g1JdUJF7Fr",
        "invitation": "ICLR.cc/2023/Conference/Paper1706/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper introduces some new ideas and findings, by analyzing GAN-based models that learn constrained mappings between domains, through the perspective of optimal transport. This is important, since such GANs are used extensively for a variety of tasks, e.g. 'inverse' problems like super-resolution, denoising and debluring.\n\nSince the setting is an 'unpaired' one, in addition to the goal of having the 'generated' target distribution close to the 'real' one (this is enforced by the discriminator), there is a need to constrain the generator to keep the output close to the input, which is achieved by a 'cost' (e.g. 'content') function for minimizing such differences.\n\nIn this setting, they show that the learned generator (T) is an optimal transport map between the input distribution (e.g. LR images) and the image of T (the generated distribution), under the 'content' cost function. Furthermore, they show that the generator (or transport map) is biased, in the sense that perfect optimization will necessarily not lead to the true target distribution, but rather will be 'biased' towards the input distribution.\n\nAs an alternative, they suggest directly optimizing for an optimal transport map between source and target distributions, under the content cost. Several derivations and reasonable assumptions, lead to a formulation and GAN-type optimization scheme, which is verified empirically in several settings. ",
            "strength_and_weaknesses": "Strengths:\n1) The relations between the standard GAN formulation/optimization and different versions of optimal-transport schemes with respect to the 'content' cost are very interesting and mostly new. Most importantly, in my opinion, is that they give a new way of thinking about and analyzing different approaches under this setup.\n2) The introduction is written very well, in term of background, context and motivation. Also, the main derivations, while being very formal, are clearly and well explained.\n\nWeaknesses:\n1) The first observation regarding GAN (Lemma 1 - that it is a particular OT map) is pretty trivial, although interesting. I wouldn't agree that the main observation (Thm1 - that map/generator is biased towards the input) is surprising. In fact, the addition of the 'content' cost of closeness between the input and output obviously constrains the output in such a way, which is probably inevitable in the 'unpaired' setup.\n2) There is a problem with the logic that follows Lemma 3 - It wrongly claims that \"Lemma 3 states that one can solve a saddle point problem (12), obtain an optimal pair (f\u2217, T\u2217), and use T \u2217 as an OT map from P, Q\". It was shown that the true T* can be chosen as optimal along with the true f*, but this doesn't show that the map obtained along with f* is actually that one and not another. The following sentence \"For general P, Q, the arg infT set for an optimal f\u2217 might contain not only OT map T \u2217 but other functions as well. However, our experiments (M7) show that this is not a serious issue in practice\" only acknowledges this problem, but doesn't explain how it is dealt with.\n3) It seems like the final obtained algorithm is not truely different from the standard GAN optimization. There are 3 main differences that are highlighted between the optimization problems, but it seems that in the optimization is the same in terms of the same alternating generator and discriminator loss updating, exept that the 'content' loss has a weight (lambda) of 1.\n4) In terms of the results, overall - the method is shown to work, but is in par with other methods including the baseline GANs. The claim that one does not have to pick the lambda parameter isn't very influencial, since the GAN results work well with a particula choice of lambda.\n5) In terms of framing, I didn't find anything that was specific to super-resolution (and in fact the method is also demonstrated on a deblurring task). The analysis and solution are relevant to a much wider set of tasks over the unpaired setting of two domains. \n6) GAN training suffers from know stability issues. There should be some reference to this aspect of the optimization as well.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally well written.",
            "summary_of_the_review": "The paper was very inspiring and interesting to read, especially in terms of the OT point of view on GAN.\nHowever, I am not convinced that the analysis leads to a result that is significant enough in terms of its ability to overcome GAN's weaknesses, especially since the algorithm itself does not seem to differ significanlty from GAN (see above).\nThe bias of the generator is certainly not the only important factor in GAN quality and the different formulation might effect performance in other ways. The bias claim is empirically condsidered only in Section B of the appendix, only in terms of the color distribution variance, while the qualitative and quantitave results on that data (Aim19 dataset) are not better than those of the other methods.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1706/Reviewer_GsaW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1706/Reviewer_GsaW"
        ]
    },
    {
        "id": "Ehs10b435_2",
        "original": null,
        "number": 4,
        "cdate": 1666651766267,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666651766267,
        "tmdate": 1666651766267,
        "tddate": null,
        "forum": "0g1JdUJF7Fr",
        "replyto": "0g1JdUJF7Fr",
        "invitation": "ICLR.cc/2023/Conference/Paper1706/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper analyzed the results of optimal transport regularized GANs, and claimed that the optimal transport map for optimal transport regularized GANs are biased. The authors proposed to use the method in Rout et al. 2022 (OTM) for the image Super Resolution (SR) problem. Experiments are conducted on a face dataset (CelebA?) and the AIM dataset. ",
            "strength_and_weaknesses": "## Strength: \n\n1. This paper provides details to analyze the transport plan of optimal transport regularized GANs. The observation is that the solution is biased. \n2. The connection and difference between the Regularized IPM GANs and the OTM are analyzed. \n3. The authors applied the OTM to the image Super Resolution (SR) problem. \n\n## Weakness\n\n1. The theoretical results are not novel. \n    1. In Sec. 5, the authors proved that adding a regularization term, the $\\mathcal{R}\\_c(T)$ in Eq. (5) will not be able to recover the true target distribution $\\mathbb{Q}$. This does not seem that novel to me because regularization technique is a well-known technique in machine learning. Adding a regularization term to a loss will prevent the loss term ($\\mathcal{D}$) from decreasing to zero, such that the $T^*_{\\\\#}\\mathbb{P}$ does not equal to $\\mathbb{Q}$. This is expected. In general, the purpose of the regularization term is to prevent overfitting or stabilize training GANs. \n\n     2. The theoretical results in Sec. 6 are not novel. Almost all results could be found in [1]. If one retain the constants of Eqs. (8) - (11) in [1] and replace $\\frac{1}{2} || x - y ||^2$ by $c(x, y)$ and replace $\\psi(y)$ by $v(y)$ in [1], one will find that Lemma 3 in this paper is equivalent to Eq. 12 (Lemma 4.1) in [1]. As also mentioned in [1], \"we focus on the quadratic ground cost $\\frac{1}{2} || x - y ||^2$. Nevertheless, our approach extends to other costs $c(\\cdot,\\cdot)$\". In adddition, Algorithm 1 in this paper is almost the same as Algorithm 1 in [1] by using the identity embedding $Q$, and a general cost $c(\\cdot,\\cdot)$ in Algorithm 1 of [1].  Unfortunately, the authors did not even mentioned [1] in the whole Sec. 6. \n\n2. The authors made incorrect claim \u201cThe solution of the regularized GAN is an OT map\u201d in Lemma 1. The authors tend to mix the optimal transport GAN or Wasserstein GAN as the whole GAN family. However, these GANs are just part of the GAN family. The authors analyzed Biased Optimal Transport in GANs in Sec. 5. However, I want to mention that not all GANs use the optimal transport or the Wasserstein distance, nor do all the GANs uses the optimal transport regularizer as wrote in Eq. (5). Therefore, it is inappropriate to claim that minimizer of a regularized GAN problem is always an OT map as mentioned in the abstract and Lemma 1. \n\n3. The experimental results are not good. On the AIM dataset, the proposed OTS variants do not perform well as the DASR method in Table 3. Also, why not compare with other SR methods such as DASR on the face (CelebA?) dataset?\n\nReferences: \n\n[1] Rout et al., Generative modeling with optimal transport maps, ICLR 2022. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The writing of the paper is not good and needs a major revision. The authors mix the GANs and SR methods in the writing the paper. I would say that all the theoretical analysis throughout this paper are general and not restrict to the SR problem. However, the authors keep mentioning the LR or SR here and there (Corollary 1 for example). This confuses readers and one would think the analysis is specific to the SR problem. \n\nThe description of the experimental results of Table 3 is not clear. In Table 3, there are OTS (ours MSE) and OTS (ours, VGG), but in the text, there is only OTS, I\u2019m not sure which OTS in Table 3 are the authors referring to. \n\nThe authors should cite the papers that use Eq. (5) for training GANs. \n\nIt is necessary to mention in Theorem 1 that $\\epsilon$ is sufficient small enough to make the claim hold. \n\nIt is necessary to mention in Algorithm 1 that whether one needs to minimize or maximize the objective, not just mention \"using\".\n\nMinor:\n\n$\\mathcal{D}(\\mathbb{Q} + \\epsilon \\Delta \\mathbb{Q})$ should be $\\mathcal{F}(\\mathbb{Q} + \\epsilon \\Delta \\mathbb{Q})$ in Theorem 1. \n",
            "summary_of_the_review": "This paper lacks novelty and the experimental results are not good. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1706/Reviewer_xhtM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1706/Reviewer_xhtM"
        ]
    }
]