[
    {
        "id": "MfcNDQ7ggx",
        "original": null,
        "number": 2,
        "cdate": 1666530107084,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666530107084,
        "tmdate": 1666530107084,
        "tddate": null,
        "forum": "IsCg7qoy8i9",
        "replyto": "IsCg7qoy8i9",
        "invitation": "ICLR.cc/2023/Conference/Paper5562/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes a new benchmark for federated domain generalization (FedDG) which explores more realistic challenges under the federated learning scenario. The benchmark designs a fair and diverse comparison on the data heterogeneity and communication costs. The experimental results show the challenges on the FedDG stay unsolved in the realistic experiment setting.",
            "strength_and_weaknesses": "Strengths:\n1. The DG problem under FL is important and lack of discussion, the proposed benchmark can better promote the research of new algorithms.\n2. The experimental settings for statistical heterogeneity challenge under FL is novel and practical.\n3. Sufficient experimental results and reproducible code.\n\nWeaknesses:\n1. The compared domain generalization methods are old and not representative, which leads to an unconvincing conclusion of this paper.\n2. There are lots of FL methods which also focus on the statistical heterogeneity problem and need to be included in the benchmark.\n3. The description of proposed experimental setting is not intuitive, making it hard to understand and does not give a clear framework for comparison.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The experimental settings for statistical heterogeneity challenge are novel, but the clarity and the organization of the presentation needs to be improved. This paper has open source the code, which seems to be reproducible.\n",
            "summary_of_the_review": "The advantages of this work are that the overall benchmark design is innovative and much needed by the academic community, but the disadvantage is that it does not use the recent SOTA method as a comparison, which is insufficient to support the seriousness and necessity of the DG problem under the FL scenario. The lack of comparison of methods from non-iid heterogeneous perspective in the FL field makes the conclusions of this paper less convincing. And the design of the experiment needs to be presented in a clearer and more structured way.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5562/Reviewer_qSGW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5562/Reviewer_qSGW"
        ]
    },
    {
        "id": "4mTg1bvgwt_",
        "original": null,
        "number": 3,
        "cdate": 1666616045750,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666616045750,
        "tmdate": 1666633632065,
        "tddate": null,
        "forum": "IsCg7qoy8i9",
        "replyto": "IsCg7qoy8i9",
        "invitation": "ICLR.cc/2023/Conference/Paper5562/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper is focused on benchmarking algorithms for domain generalization (DG) in the federated learning (FL). They evaluate 9 algorithms on three datasets (PACS, iWildCam and Py150). In particular, authors compare centralized DG algorithms and two FL algorithms for DG (FedADG and FedDG). The paper studies the ability of these methods to handle different challenges of DG-FL such as statistical heterogeneity among clients, number of clients, number of communication rounds. The results show more work is needed to design algorithms in the large client setting even for simple datasets as well as to handle local data statistical heterogeneity.",
            "strength_and_weaknesses": "Strengths:\n-  Domain generalization (DG) in federated learning (FL) is an important problem and has not been a systematic comparison of the methods. This paper presents the first such study.\n- The paper presents major challenges that need to be overcome to address DG-FL problems and shows the inability of the existing methods to do so. This is important work needed to advance the field.\n- Using homogeneous and heterogeneous splits (as measured by lambda) presents a systematic way to measure how well the algorithm can adapt to heterogeneous  environments.\n\nWeaknesses:\n- For benchmark papers, it is extremely important that the paper is well written, well structured and reads well. However, this is not currently the case. There is a lot of information, but the paper does not organize information in a succinct and clear way making it hard to follow. For example, problem setup is never fully defined; part of experiments with varying lambda are in one paragraph, the other in another; it is not clear how centralized DG are extended to FL setting; many tables are not referred to in the paper; it is not explained why centralized DG methods can not be extended to be applicable to lambda=0 setting and so on. These are just a few examples, but the overall impression of the paper is that much more effort is needed to have a well organized and structured paper. \n- The methods are tested only on three benchmark dataset. More analysis is needed to make the comparison truly comprehensive\n- Similarly, more recent FL algorithms should be included for the comprehensive analysis.\n\nMinor: \n- In the paragraph Challenges from more realistic datasets, it should be Fig. 2 (c),\n(d) not (b), (c)\n- In paragraph 4.1 the authors write that they analyze two values of the lambda parameters, but the figure shows three.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper presents the first systematic comparison of the DG-FL methods and as such its analysis is important and it brings new interesting insights. However, the clarity and quality of the paper needs to be significantly improved.",
            "summary_of_the_review": "Overall, the analysis presented in the paper is of high importance to the community and has the potential to bring new advances in the DG-FL by outlying unsolved challenges of the current methods. However, more work and effort is needed to make this paper strong and comprehensive which is necessary for these types of benchmarking papers.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5562/Reviewer_oUmB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5562/Reviewer_oUmB"
        ]
    },
    {
        "id": "xlJ95tWZOg",
        "original": null,
        "number": 4,
        "cdate": 1666633875085,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666633875085,
        "tmdate": 1670967577403,
        "tddate": null,
        "forum": "IsCg7qoy8i9",
        "replyto": "IsCg7qoy8i9",
        "invitation": "ICLR.cc/2023/Conference/Paper5562/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed a benchmark for domain generalization (DG) algorithms in federated learning (FL). The authors considered more realistic settings with larger client numbers and different heterogeneity levels compared to prior works. The benchmarks included two new datasets for DG in FL and multiple existing DG algorithms. \n",
            "strength_and_weaknesses": "Strengths\n\nThe first paper to benchmark DG in FL settings and considered different setups and difficulties in the benchmark. The list of algorithms included in the benchmark is also comprehensive.\nThe paper is written clearly and easy to follow.\n\nWeaknesses\n\nOnly image datasets were considered in the benchmarks while there are many existing works for DG in the text domain [1,2,3]. Also, only two datasets were considered more realistic which seems to be small as a benchmark. \nSome parts of the results are not clear, e.g. why does $\\lambda=0.1$ give better performance than $\\lambda=1$ for some algorithms in Table 4?\n\nReferences:\n\n[1] Gururangan, S., Marasovi\u0107, A., Swayamdipta, S., Lo, K., Beltagy, I., Downey, D., & Smith, N. A. Don\u2019t Stop Pretraining: Adapt Language Models to Domains and Tasks. ACL 2020.\n\n[2] Gururangan, S., Lewis, M., Holtzman, A., Smith, N. A., & Zettlemoyer, L. Demix layers: Disentangling domains for modular language modeling. arXiv 2021.\n\n[3] Chronopoulou, A., Peters, M. E., & Dodge, J.  Efficient hierarchical domain adaptation for pretrained language models. arXiv 2021.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity and quality is good. This is also the first attempt to benchmark DG in FL. The benchmark should be reproducible as the authors will provide a link to the code and dataset.\n",
            "summary_of_the_review": "I am leaning towards weak reject as I think the benchmark needs to be more comprehensive as discussed in the weaknesses above.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5562/Reviewer_fDMj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5562/Reviewer_fDMj"
        ]
    },
    {
        "id": "T-4Z8a1Lr6f",
        "original": null,
        "number": 5,
        "cdate": 1666842466403,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666842466403,
        "tmdate": 1669569626274,
        "tddate": null,
        "forum": "IsCg7qoy8i9",
        "replyto": "IsCg7qoy8i9",
        "invitation": "ICLR.cc/2023/Conference/Paper5562/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a benchmark for Federated Learning in the context of domain generalization. The authors thoroughly evaluate a number of popular DG algorithms on this benchmark. ",
            "strength_and_weaknesses": "Strengths\n- The benchmark considers a relevant setting\n- The evaluations are detailed covering a variety of methods\n- The work highlights the difficulties in this setting\n\n*Weakness*\n- The intersection of DG and FL has been considered by several authors recently.. The  following related references and methods are not discussed or compared:\n   - Tension et al \u201cGradient Masked Averaging for Federated Learning\u201d \n   - Yuan et al \u201cWhat do we mean by generalization in Federated Learning\u201d \n- The wide array of approaches are appreciated but there are limited details on how these are adapted to the federated setting. Some of these algorithms e.g. MMD, FISH,  seem like they would require access to the different domains at each iteration thus it\u2019s not clear to the reviewer how they are implemented here since clients should not share data. \n- Although the performance is evaluated it is not discussed if these approaches come with additional communication or training time overhead. FL is often concerned with these constraints. Related to the previous point are there additional information besides the models transmitted across clients in the various methods?\n- The datasets are interesting however in addition to these it might be good to include at least one popular dataset from the FL literature such as FEMNIST (which has been studied in OOD settings in other work) or CIFAR \n",
            "clarity,_quality,_novelty_and_reproducibility": "*Clarity/Quality*\nThe paper is overall reasonably well written. A clarity issue about how the DG methods are ported to FL is noted.\nThe reviewer also noted that the appendix is referenced \n\n*Reproducibility*\nCode is available\n\n*Novelty*\nThe benchmark is relevant and the evaluation is more extensive than previous work, but previous work in this topic does exist.\n",
            "summary_of_the_review": "The paper presents a useful benchmark and highlights the challenges of existing DG methods extended to FL in the context of this benchmark. The evaluation of some existing algorithms is of interest.  Some related work are not fully discussed. The reviewer also currently has some concerns about what data information is transmitted across clients and servers in the methods evaluated.\n\nUpdate: The authors made  substantial changes to the paper text that have greatly clarified the setting under study, thus have largely addressed my concerns. I am thus increasing my score ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5562/Reviewer_UVoT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5562/Reviewer_UVoT"
        ]
    }
]