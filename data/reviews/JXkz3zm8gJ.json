[
    {
        "id": "y5oMYd30R8",
        "original": null,
        "number": 1,
        "cdate": 1666248799392,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666248799392,
        "tmdate": 1666248799392,
        "tddate": null,
        "forum": "JXkz3zm8gJ",
        "replyto": "JXkz3zm8gJ",
        "invitation": "ICLR.cc/2023/Conference/Paper2277/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposed a generative pre-training approach, termed G.pt, that learns to optimize the parameters of neural networks. Specifically, this approach first constructs a dataset of network checkpoints (along with their corresponding metrics) sampled from a hundred thousand training runs, and then trains a conditional diffusion model on this dataset to learn the distribution of network parameters that fulfill the desired metric. After training, given the target metric and the randomly initialized (or unseen) parameters, we can find the optimized network parameters by directly sampling from the conditional diffusion model. Compared to the conventional SGD type optimization methods that relies on at least thousands of parameter updates, the proposed method is claimed to perform well with \u201ca single parameter update\u201d.\n",
            "strength_and_weaknesses": "Strengths:\n- This work is clearly written, and the presentations of the proposed idea and experiment settings are overall very easy to follow. \n- The idea of training a conditional diffusion model in the (parameter, metric)-space to perform the learning to learn tasks looks novel to me.\n- Experiments on a fairly reasonable range of settings (MNIST, CIFAR-10, and Cartpole) demonstrated that the proposed method can learn the distribution of network parameters conditioned on the desired metric (note that its value cannot surpass the best from the dataset). Also, experiments showed some nice properties of the proposed method, including scaling the model and data size improves the performance, measured by the prompt alignment score, and sampling diverse outputs for the same metric.\n\nWeaknesses:\n- Although I liked the idea of generative pre-training that learns to optimize the parameters, given the claimed properties and current experimental results, my major concern is whether the proposed method is really useful for solving downstream problems. For instance, if the proposed method cannot extrapolate to the metric values beyond the limits of the checkpoint dataset, what extra value does it add on top of the pre-trained checkpoints? Because in practice, especially the classification and RL tasks, we mostly just care about when and how we achieve the better scores (e.g., accuracies and rewards). The claimed favorable properties also seem not add significant value in this regard. Instead of converging to a better local minima, why do we care about how the network ends up with multiple given \u201cmediocre\u201d local minima from unseen initializations? Can we find some use cases to show the practical significance of the proposed method?\n- I realized the authors emphasized many times about \u201cfrom unseen neural network parameters\u201d. I\u2019m a little confused: Does it just mean we initialize the network parameters that are not from the training set?\n- Another confusing part is that the proposed method is claimed to optimize the parameters \u201cin just one update\u201d. I\u2019m not sure what the one update exactly means. If we use the DDPM sampling, which is an iterative process with usually hundreds of function evaluations, how can we say \u201cone update\u201d? When comparing with the conventional SGD methods, I think we should consider the DDPM sampling steps.\n",
            "clarity,_quality,_novelty_and_reproducibility": "I\u2019m satisfied with the overall writing quality and originality of the work. I raised some concerns about the clarity and the significance in the weaknesses above. I think the work provided sufficient details for reproducing the main results.\n",
            "summary_of_the_review": "Overall, I liked the idea but I have major concerns about the practical significance of the proposed method. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2277/Reviewer_rREn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2277/Reviewer_rREn"
        ]
    },
    {
        "id": "NPKxDrGLT1y",
        "original": null,
        "number": 2,
        "cdate": 1666553392446,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666553392446,
        "tmdate": 1666553392446,
        "tddate": null,
        "forum": "JXkz3zm8gJ",
        "replyto": "JXkz3zm8gJ",
        "invitation": "ICLR.cc/2023/Conference/Paper2277/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work trains a generative model (conditional diffusion Transformer) called G.pt over NN checkpoints of supervised + reinforcement learning (RL) tasks such that given a prompt of (initial input parameter vector, target loss/error/return), the generative model outputs an updated parameter vector that achieves the desired metric. The paper explores classification on MNIST and CIFAR-10 for MLPs and CNNs, as well as an MLP on a Cartpole task. This approach performs favorably to existing optimizers \u2013 G.pt acts as a learned optimizer such that initially, each step of G.pt corresponds to thousands of gradient update steps of traditional optimizers such as Adam and SGD.",
            "strength_and_weaknesses": "Strengths:\n- The idea is really interesting and the paper was fun to read! \n- There were a lot of empirical design decisions that had to be made in order to make the approach work (e.g. how to tokenize each layer of the NN, how to modify the conditional Transformer-based diffusion model, permutation augmentation in weight space to facilitate generative pre-training, etc.) and the paper did a good job outlining each step, as well as justifying the reasons behind each choice.\n- The results are impressive. Though one could argue that the tasks are relatively simple, I thought the paper did a great proof of concept that G.pt is a promising approach for learning to learn.\n\nWeaknesses:\n- The authors did a good job addressing the limitations of the work in Section 6, where they outlined how G.pt does not quite handle extrapolation of loss/error values not present in the training data very well.\n- This is not quite a weakness per se, but I thought Appendix A was interesting in terms of constructing an alternate view of the generative process of the joint over (model parameters, losses). It would\u2019ve been helpful for me for the authors to elaborate upon this discussion point a bit more, either in the main text or in the Appendix. Intuitively, it seems as though the dependence between the loss (\\ell) and model parameters (\\theta) should go in the opposite direction (e.g. p(\\ell \\vert \\theta), with a prior over model parameters p(\\theta)) rather than the other way around, since the loss is a function of the model parameters and the input. Things are a bit different here since the diffusion model is being \\emph{prompted} with fixed loss values and initial model parameters. Would the authors comment on this?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity/quality: The paper was clear and easy to follow, and the quality of the experimental results was quite high. I also liked the additional investigation that the authors did in terms of looking at memorization/generalization, as well as exploring the additional source of randomness in the NN weight initializations.\n- Novelty: The approach was quite novel. While the idea of learned optimizers is not new, most people have tried to tackle the problem from directly pre-training on a variety of datasets/tasks. I thought the prompting idea to get the model to target a desired test loss was creative and interesting.\n- Reproducibility: The paper included sufficient levels of detail in terms of how to preprocess the inputs, how to construct the dataset of (model parameter, loss) pairs, and hyperparameters for each setting.\n",
            "summary_of_the_review": "The authors introduce G.pt, a generative model of NN checkpoints as a way to efficiently learn how to optimize NNs to target a desired loss/return value. They propose how to make this idea work well in practice with different approaches of tokenizing each NN layer, encoding the loss/model parameters, performing data augmentation, adapting the underlying diffusion model, and outlining the pretraining procedure. They then empirically explore G.pt\u2019s performance on MNIST and CIFAR-10 classification as well as learning a policy to perform Cartpole, and also demonstrate that the model is not straightforwardly memorizing models it has seen before. The submission is high quality, interesting, and novel. I anticipate this being of broad interest to the community, and therefore recommend acceptance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2277/Reviewer_iYN2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2277/Reviewer_iYN2"
        ]
    },
    {
        "id": "YKhIFZreINF",
        "original": null,
        "number": 3,
        "cdate": 1666747348741,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666747348741,
        "tmdate": 1666747348741,
        "tddate": null,
        "forum": "JXkz3zm8gJ",
        "replyto": "JXkz3zm8gJ",
        "invitation": "ICLR.cc/2023/Conference/Paper2277/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "First, the authors built a dataset consisting of neural network checkpoints that perform specific tasks, such as MNIST classification, including its loss and error. The proposed data-driven optimizer, G.pt, is a neural network model trained using this dataset. Specifically, if the parameters of the initial checkpoint, the initial loss, and the target loss are given as inputs, then G.pt outputs a new parameter set that can achieve the target loss. Finally, by using the MNIST, CIFAR-10, and Cartpole datasets with a small architecture (e.g., two-layer MLP with 10 hidden units), the authors validated the effect of G.pt compared to an existing gradient-based optimizer (e.g., Adam optimizer).",
            "strength_and_weaknesses": "Strength\n1. I am not sure whether this research topic is promising, but it is definitely interesting. Also, I believe this paper can serve as the first step towards this research direction.\n2. The proposed method is straightforward, and the experimental results are surprising.\n3. Unlike the existing gradient-based optimization algorithms, G.pt can optimize non-differentiable objectives, such as classification errors.\n\nWeakness\n1. The proposed method can be used only for small models, and such a model has limitations in minimizing generalization errors. Therefore, when deploying a deep learning model, I do not know when it is better to use G.pt instead of an existing optimizer. Could the authors provide an additional discussion about when the proposed optimizer is beneficial compared to existing optimizers?\n2. It is interesting that G.pt can easily find multiple parameter sets with the same loss, but there is no discussion of why they are necessary.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written, easy to understand, and the proposed method is straightforward. I think this paper has novelty and originality in that it presents a new research topic, 'learning to optimize neural networks'.",
            "summary_of_the_review": "The ideas and research topics of the paper are interesting, and the experimental results are also impressive. However, there are obvious limitations in terms of applicability, so I believe that further discussion is necessary in this regard.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2277/Reviewer_bACh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2277/Reviewer_bACh"
        ]
    },
    {
        "id": "XOQon8_R5sO",
        "original": null,
        "number": 4,
        "cdate": 1666845874935,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666845874935,
        "tmdate": 1666845874935,
        "tddate": null,
        "forum": "JXkz3zm8gJ",
        "replyto": "JXkz3zm8gJ",
        "invitation": "ICLR.cc/2023/Conference/Paper2277/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper uses a diffusion Transformer to map a pair (initial parameter, target loss) to a distribution over parameters that achieve the specified performance. The model is trained with a pre-training dataset of neural network checkpoints.",
            "strength_and_weaknesses": "Pros\n- The overall idea is interesting: posing performance-conditional parameters as a conditional generative modeling problem lets us leverage advances in diffusion models and is an interesting alternative to e.g. learned optimizers.\n\nCons\n- There doesn\u2019t seem to be any practical benefit for the method, because your pre-training dataset already includes a lot of checkpoints for your specific setting, and your experiment in figure 5 shows that the method does not extrapolate to unseen losses (no runs improve upon \u201cData Best\u201d). For raw performance, the result of running G.pt has no benefit over simply using the best checkpoint in the dataset.\n- I may be misunderstanding the method, but is anything explicitly preventing this model from simply memorizing checkpoints?\n\nThis isn\u2019t a request for additional experiments, but I think evidence of generalization across network architecture or dataset would address my concerns about the method.",
            "clarity,_quality,_novelty_and_reproducibility": "The writing is clear. The proposed method is quite novel.",
            "summary_of_the_review": "My main concern with this paper is that I don't see a practical benefit for the method (see \"Strength and Weaknesses\" above). I do think the idea is creative and interesting.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2277/Reviewer_Wayk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2277/Reviewer_Wayk"
        ]
    }
]