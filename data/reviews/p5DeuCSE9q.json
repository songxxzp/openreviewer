[
    {
        "id": "w06ntgj1ryR",
        "original": null,
        "number": 1,
        "cdate": 1666535862219,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666535862219,
        "tmdate": 1666535862219,
        "tddate": null,
        "forum": "p5DeuCSE9q",
        "replyto": "p5DeuCSE9q",
        "invitation": "ICLR.cc/2023/Conference/Paper5113/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper combines RBPN and TecoGAN to solve the Video Super-Resolution task. Experiments show that the performance is better than RBPN and TecoGAN.",
            "strength_and_weaknesses": "Weaknesses:\n1) The paper is poorly written. Many typos can be found in the paper. For example, in Fig. 1, there is a \"text\" appearing in the box of \"Projection Module\".\n2) The proposed method is just a combination of existing methods, i.e., RBPN and TecoGAN. It is too trivial.\n3) The performance is not compared with existing VSR methods except RBPN and TecoGAN. The comparisons with RBPN and TecoGAN should be regarded as a part of the ablation study.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Poor\n\nQuality: Poor\n\nNovelty: Poor\n\nReproducibility: Good, as it is just the combination of two methods.",
            "summary_of_the_review": "The paper is of poor quality. The idea is a combination. The experiments are not thorough and convincing enough.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5113/Reviewer_LUmB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5113/Reviewer_LUmB"
        ]
    },
    {
        "id": "x7e1aWY2sqP",
        "original": null,
        "number": 2,
        "cdate": 1666624041622,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666624041622,
        "tmdate": 1666633715623,
        "tddate": null,
        "forum": "p5DeuCSE9q",
        "replyto": "p5DeuCSE9q",
        "invitation": "ICLR.cc/2023/Conference/Paper5113/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes a new Video Super Resolution (VSR) method based on generative adversarial networks (called RBPGAN) to improve temporally coherent, spatially details, and human perception. In particular, the generator uses a reduced recurrent back-projection network, and the discriminator measures the temporal consistency. Some experiments are provided to demonstrate the effectiveness of the proposed method.",
            "strength_and_weaknesses": "Strength: This paper proposes a new GAN-based VSR method to address the important issues of temporally coherent, spatially details and human perception.\n\nWeaknesses: The writing of this paper should be improved. The details of the proposed method are not clear. The experiment section should be improved.",
            "clarity,_quality,_novelty_and_reproducibility": "1. The writing of this paper should be improved. In the introduction, it would be better to describe the motivations, challenges and difficulties.\n\n2. The paper misses many related works. In the reference, the authors only provide about 10 papers. Some important related works [1-8] about VSR should be discussed. The authors should make a sufficient survey on VSR.\n\n    [1] Video super-resolution transformer. arXiv 2021\n\n    [2]  Vrt: A video restoration transformer. arXiv 2022\n\n    [3] Basicvsr: The search for essential components in video super-resolution and beyond. CVPR 2021.\n    \n    [4] Basicvsr++: Improving video super-resolution with enhanced propagation and alignment. CVPR 2022.\n\n    [5] Recurrent Video Restoration Transformer with Guided Deformable Attention. NeurIPS 2022.\n\n    [6] Towards Interpretable Video Super-Resolution via Alternating Optimization. ECCV 2022\n\n    [7] Omniscient video super-resolution. CVPR 2021.\n\n    [8] Investigating Tradeoffs in Real-World Video Super-Resolution. CVPR 2022\n\n3. The novelty of this paper should be highlighted. The discriminator of the model is based on TecoGAN. Could you discuss the difference between them?\n\n4. In Sections 3.1 and 3.2, the authors should provide the formal formulations for the generator and the discriminator.\n\n5. In Figure 1, the authors should provide a brief introduction to the proposed architecture. In the TecoGAN discriminator, why use the same frame in Target Triplets?\n\n6. The authors use five losses to train a model. These losses have been used in different SR methods. How to tune the weights of the losses in the training?\n\n7. The experiments are not sufficient and not convincing. The authors should compare with more SR methods, such as real SwinIR [9] and RealBasicVSR [8].\n\n    [9] Swinir: Image restoration using swin transformer. ICCVW 2021\n",
            "summary_of_the_review": "The writing should be improved, the technical details and more experiments should be provided.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5113/Reviewer_jYRg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5113/Reviewer_jYRg"
        ]
    },
    {
        "id": "R2zhFs3lIBi",
        "original": null,
        "number": 3,
        "cdate": 1666628513308,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666628513308,
        "tmdate": 1666628513308,
        "tddate": null,
        "forum": "p5DeuCSE9q",
        "replyto": "p5DeuCSE9q",
        "invitation": "ICLR.cc/2023/Conference/Paper5113/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new CNN-based method that deals with video super-resolution problems. The proposed method consists of a generator and a discriminator. The generator combines Single Image Super-Resolution and Multiple Image super-Resolution on target frame and its neighboring frames. The discriminator uses triplet loss to enhance the capability of discriminating scaled output from the generator. Experiments show that the proposed method outperforms other baselines. \n\n",
            "strength_and_weaknesses": "Strength\n1. This paper provides a comprehensive literature review. \n\n\nWeakness\n1. In section 3.1 generator , the described encoder and decoder cannot be located in Figure 1. It is quite confusing how the proposed method arrange the SISR and MISR modules in the network. \n2. The Figure 1  does not provide the details of each projection module. By reading the figure and the method section, it is difficult to understand how the network should work. \n3. In Section 3, it does not validate the reason why the proposed network should work and to what extent it works. \n\n\n4. There are many typos in the submitted manuscript. \n(1). A comma is missing in Eq.(1) . The log with base 10 is not properly typed. \n(2). Almost all the equations in the article are missing punctuations. \n(3). Sentence after Eq.(5): Here the forward results are represented with g_t -> represented by g_t.\n(4). 4th point of Section 5 Loss functions, The first sentence is not properly written and formatted.\n(5). Section 6 Experiments, first paragraph, the past tense and present tense are mixed together. \n(6). The caption of Figure 1 should come with : The proposed architecture. ",
            "clarity,_quality,_novelty_and_reproducibility": "\nThis paper clearly describes the strong motivation, current challenge of the problem, and the necessity of proposing such a new method. \nThis paper has provided a comprehensive literature review, covering all the campaigns in the video super resolution community. \n\nHowever, the proposed method section is too short and the description is not quite informative. \nThe clarity of the paper is not quite good.  Since the description for the method itself is quite confusing, it is difficult to judge the originality of the work. \n",
            "summary_of_the_review": "In summary, this paper fails to clearly describe the proposed method combining both texts and figures. Hence, it is quite difficult to judge the validity and the effectiveness of the work. The authors are suggested to provide a detailed explanation of the proposed method and also to give reasons of the network design. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5113/Reviewer_6Vz2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5113/Reviewer_6Vz2"
        ]
    },
    {
        "id": "tIaynMw75m0",
        "original": null,
        "number": 4,
        "cdate": 1667541636189,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667541636189,
        "tmdate": 1667541636189,
        "tddate": null,
        "forum": "p5DeuCSE9q",
        "replyto": "p5DeuCSE9q",
        "invitation": "ICLR.cc/2023/Conference/Paper5113/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper trains RBPN model for video super-resolution. The authors employ TecoGAN discriminator and their ping-pong loss to improve temporal consistency of the super-resolved video. The authors use perceptual loss and warping loss, too.\n",
            "strength_and_weaknesses": "- Novelty\n\nThere is not much novelty in this work.\nThe generator architecture is from RBPN, discriminator is from TecoGAN, the loss functions are widely used popular terms. \n\n- Experimental Results\n\nWhile the authors claim they achieve state-of-the-art performance in perceptual quality, there is no visual comparison with the other methods. In Table 5, the proposed method achieves good LPIPS and SSIM, however, I believe this is not a fair comparison. There is trade-off relation between fidelity-based metrics and perceptual quality metrics. Such perception-distortion trade-off is well known in image/video restoration community. The proposed method far lacks in PSNR.\n\nY. Blau and T. Michaeli, \u201cThe Perception-Distortion Tradeoff,\u201d CVPR 2018\n\n\n\n- Concerns\n\nThe authors directly copy the sentences from RBPN paper.\nFor example, in section 8, \n\n\u201cThe reduced Recurrent Back-Projection Network in our model treats each context frame as a separate source of information. These sources are combined in an iterative refinement framework inspired by the idea of back-projection in multiple-image super-resolution. This is aided by explicitly representing estimated inter-frame motion with respect to the target, rather than explicitly aligning frames\u201d\n\nThis is an except from the abstract of Haris et al., 2019. This is considered plagiarism.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Writing quality is not very good and there are many typos, latex grammar errors.\nNovelty is poor, there are no new ideas or techniques.\nImplementation details are not described in detail.\n",
            "summary_of_the_review": "I don\u2019t find many reasons to accept this paper.\nThe paper lacks novelty and the experimental results are hard to claim the benefits over the previous methods. \nFurthermore, I seriously concern about plagiarism the issue. The authors copied sentences from the previous work which they bring the core architecture.\n",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "Yes, Research integrity issues (e.g., plagiarism, dual submission)"
            ],
            "details_of_ethics_concerns": "The authors bring sentences from one of the previous work, RBPN.\nI doubt this is a mistake or coincidence.\n\nPlease refer to the strengths & weaknesses.",
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5113/Reviewer_aKDa"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5113/Reviewer_aKDa"
        ]
    }
]