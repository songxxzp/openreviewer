[
    {
        "id": "0NnqaAdGFQf",
        "original": null,
        "number": 1,
        "cdate": 1666223149560,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666223149560,
        "tmdate": 1666223149560,
        "tddate": null,
        "forum": "pd1P2eUBVfq",
        "replyto": "pd1P2eUBVfq",
        "invitation": "ICLR.cc/2023/Conference/Paper1031/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work proposed a new method called Asyrp (asymmetric reverse process) to discover the semantic directions in the latent space of pre-trained diffusion models. Specifically, this work first theoretically and empirically showed that a shift added to the UNet noise prediction results in almost the same reverse process trajectory. To this end, an asymmetric reverse process is proposed to manipulate the real image by controlling the latent variable. Besides, this work found that the bottleneck (or the deepest) feature map in the UNet, termed h-space, has the most salient properties than other latent spaces, and thus considered to learn implicit neural directions in the h-space. Finally, in order to achieve the best tradeoff between editing strength and generation quality, this work designed a full editing process, consisting of three phases: editing with Asyrp, traditional denoising, and quality boosting.\n",
            "strength_and_weaknesses": "Strengths:\n- This work is clearly written and it is overall very easy to follow. \n- I liked the idea of discovering the semantic directions in the h-space of existing diffusion models, since the state-of-the-art diffusion models use the UNet backbone. Compared with the noise space which has been considered in previous works, the h-space is more compact and contains higher semantic information. Moreover, the work semantically demonstrated in various experiments several nice properties of h-space: homogeneity, linearity, robustness and rough consistency across timesteps. \n- Other important components in the proposed method, including asymmetric reverse process, implicit neural directions, three-stage generative process design, have also shown via experiments the respective effectiveness in contributing to the success of the proposed method.\n- The experiments were conducted across different diffusion model architectures and different datasets to show the general applicability of the proposed method, and also demonstrated that it outperformed the previous fine-tuning method DiffusionCLIP.\n\nWeaknesses:\n- In the proof of Theorem 1, it assumed that $\\beta_t \\approx 0$. This might be true only when $t \\to 0$. As $\\beta_t$ monotonically increases from $t=0$ to $T$, I wonder if this assumption still holds when $t$ is large. I think more justifications are needed here to clarify the possible confusions.\n- In experiments, many \u201cless-diverse\u201d datasets have been considered, such as CelebA-HQ, LSUN bedroom/church, AFHQ-dog. I wonder why not consider more diverse datasets, such as ImageNet? In particular, we know diffusion models have achieved good generation results on ImageNet. Compared with previous latent space traversal works based on StyleGAN that cannot work on ImageNet, this result will show a big advantage of the proposed method.\n-  Since we already have many StyleGAN-based methods (StyleCLIP, StyleGAN-NADA, etc.) for latent semantic discovery, how does the proposed method based on diffusion models compare with them? I can tell that for the diffusion-model-based method, we still need many more tricks (e.g., asymmetric process, three-stage scheduling, implicit direction, etc.) to make it work reasonably well. I\u2019m not saying that we have to beat those methods in this paper, but even not, it will still be interesting to see the pros and cons of both two methods and to provide guidelines for further improvements.\n",
            "clarity,_quality,_novelty_and_reproducibility": "I\u2019m satisfied with the work's overall quality, clarity, and originality. There are some clarity-related questions: \n- In Sec 3.2, I\u2019m sure if it is reasonable to call $D_t$ the drift, which confuses me by thinking about the drift coefficient in the SDE formulation.\n- In Sec 3.4, when we use a custom sub-sequence for the reverse process, why do we choose this normalization $S / \\tilde{S}$? \n",
            "summary_of_the_review": "Overall, I liked the idea of discovering the latent semantics in diffusion models and I think the experiments well support the claimed contributions in the work. Since I still have some concerns about the theory and experiments (see the weaknesses above), I put my initial rating as \u201cweak accept\u201d. I\u2019m open to increasing my score if the rebuttal well addresses my concerns.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1031/Reviewer_6SAm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1031/Reviewer_6SAm"
        ]
    },
    {
        "id": "d5yWfNVhDp",
        "original": null,
        "number": 2,
        "cdate": 1666265180534,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666265180534,
        "tmdate": 1666265180534,
        "tddate": null,
        "forum": "pd1P2eUBVfq",
        "replyto": "pd1P2eUBVfq",
        "invitation": "ICLR.cc/2023/Conference/Paper1031/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors introduce an algorithm that manipulates images using diffusion models.\nThey do so by manipulating the representation in the bottle-neck U-net layer of the diffusion model over several (but not all) timesteps. The loss function that they optimize is the same as for DiffusionCLIP.",
            "strength_and_weaknesses": "### Strengths\n\nThe visual results are striking. There are plenty of examples of different attributes for editing. A user study (n=80) was conducted and showed very clearly superior performance to DiffusionCLIP. The algorithm can be applied to pretrained diffusion models.\n\n\n### Weaknesses\nTheorem 1 seems to be formulated a bit sloppy... $ \\tilde{x}_t \\approx  x_t $\nisn't really saying anything. Defining a bound $||\\tilde{x}_t -  x_t|| \\leq \\delta$ and then showing that $\\delta$ is small would be better suited.\nFor the proof in appendix B, I would prefer if all symbols were defined in that section. In equation (13) you introduce $\\beta$ and $\\eta$ without stating their relation to previous terms.\nIn general, theoretical motivation for the procedure and parameter choices is lacking a bit.\n\nThe only quantitative evaluation is the user study. Results for DiffusionCLIP seem a bit lower quality than in the original paper.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "### Novelty\nTraversing the latent space of a diffusion model causing semantic changes by manipulating the image representation is a novel contribution.\n\n### Clarity\nThe procedure, though a bit convoluted, is clearly explained, and graphics support the understanding of the algorithm. Images in Figures 1 and 2 could be enlarged a bit to ease readability.\n\n### Reproducibility\nThe algorithm is in pseudo-code in the appendix and the authors also provide code that will be published with their contribution. I have not checked the code, but if functional, reproducibility is provided.\n\n### Quality\nThe results look great. The procedure is nicely explained. I also appreciate the background section 2.\n\n### minor mistakes\nThere are some minor language mistakes. For example:\n- in 2.1: that learns data distribution $\\rightarrow$ that learns a data distribution\n- in 2.1: is variance schedule $\\rightarrow$ is the variance schedule \n- in 3.1: given a pretrained and frozen diffusion models $\\rightarrow$ given a pretrained and frozen diffusion model\n- in 6: image editing on semantic latent space $\\rightarrow$ image editing in the semantic latent space\n- in A:  On the other hands $\\rightarrow$ On the other hand\n- in A:  incorporating diffusion models with scorebased model $\\rightarrow$ incorporating diffusion models with scorebased models\n- in A:  However it requires noise-dependent $\\rightarrow$ However it requires a noise-dependent\n- ...",
            "summary_of_the_review": "Overall, I think this is a nice contribution that carefully explains the authors' procedure and provides visually striking experimental results. The contribution is novel and presents a significant step towards practical image editing with diffusion models. With additional theoretical justifications, this would be even better. I would recommend it for publication at ICLR.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1031/Reviewer_KRCt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1031/Reviewer_KRCt"
        ]
    },
    {
        "id": "uwjNbb7dGnm",
        "original": null,
        "number": 3,
        "cdate": 1666585966610,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666585966610,
        "tmdate": 1666725857284,
        "tddate": null,
        "forum": "pd1P2eUBVfq",
        "replyto": "pd1P2eUBVfq",
        "invitation": "ICLR.cc/2023/Conference/Paper1031/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper discovers a semantic latent space (termed h-space) for pretrained diffusion models. The proposed h-space is a shift/residual in the middle-layer feature of the UNet, and is discovered via finetuning. The authors propose asymmetric reverse process (Asyrp) for both finetune and sampling. The proposed h-space has several nice properties: homogeneity, linearity, robustness, and consistency across timesteps.",
            "strength_and_weaknesses": "## strengths\n- Finding a semantic latent space for pre-trained diffusion models is an important problem and is relatively less studied. The proposed Asyrp is a promising endeavor in this direction.\n- The proposed h-space has several nice properties: homogeneity, linearity, robustness, and consistency across timesteps.\n- The empirical study in generative process design suggests an interesting analysis for editing flexibility.\n\n## weakness and detailed questions\n- Theorem 1 seems a little bit weak to me, it says that $\\Delta x_{t-1} \\approx 0$ given a shift $\\Delta \\epsilon_t$. However, this conclusion is trivial given the well-known result from DDIM Eq. 13. The resulted loss function Eq. 7 seems same as the GPU-efficient finetuning in DiffusionCLIP [1].\n- In Eq. 7, is $x_t^{edit}$ $P_t^{edit}$?\n- Can we think of the proposed training of Asyrp as a constrained version of DiffusionCLIP (only the middle layer of UNet can be finetuned)? If so, how does the generative process of Asyrp compare to DiffusionCLIP, i.e. unmodified (symmetric) DDIM sampling?\n- Linear combination (Figure 8) is quite interesting. How does this compare to a linear combination of scores (as in DiffusionCLIP)? This comparison would be interesting since it saves multiple UNet forward passes.\n- This won't impact my rating. I am curious is it possible to extend the proposed h-space in text-to-image diffusion models such as StableDiffusion?\n\n[1] Kim, Gwanghyun, Taesung Kwon, and Jong Chul Ye. 2021. \u201cDiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation.\u201d arXiv [cs.CV]. arXiv. http://arxiv.org/abs/2110.02711.\n",
            "clarity,_quality,_novelty_and_reproducibility": "- The paper is well-written for the most part.\n- The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.\n- Results should be reproducible as the code is provided.",
            "summary_of_the_review": "I am willing to amend my score is my major concerns are addressed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1031/Reviewer_4Ber"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1031/Reviewer_4Ber"
        ]
    },
    {
        "id": "91ewEqM099K",
        "original": null,
        "number": 4,
        "cdate": 1666799918620,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666799918620,
        "tmdate": 1668593640957,
        "tddate": null,
        "forum": "pd1P2eUBVfq",
        "replyto": "pd1P2eUBVfq",
        "invitation": "ICLR.cc/2023/Conference/Paper1031/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes asymmetric reverse process (Asyrp) to exploit the semantic latent space of pre-trained diffusion models. With the guidance of CLIP, the proposed method can find semantically meaningful directions in the latent space for image editing. ",
            "strength_and_weaknesses": "Strength:\n(1) As far as I know, this paper is the first work to directly find the semantic directions in pre-trained diffusion models.\n(2) The empirical results look impressive.\n\nWeaknesses:\n(1) The choice of h-space needs more clarification. The Figure 15 and Appendix C.3. could not explain everything. My questions are: [1] Are images in Figure 15 training images or test images? [2] If they are training images, why does the layers other than layer 8 have bad performance? I imagine they are all able to minimize the loss in Eq. 7. [3] If they are test images, why does layer 1-6 does not change the generated images at all? At least there should be some changes.\n(2) The implicit neural direction looks unnecessary. Could the authors provide more ablation study to compare using $f_t$ and $h_t$? Moreover, I cannot understand the results in Figure 6 (a). Since $\\epsilon$ has a higher dimension than $h$, I can hardly imagine it yields higher loss when optimizing Eq. (7). \n(3) There are too many magic numbers in Section 4, making me doubt the generalizability of the proposed generative process. Though the authors claim that these magic numbers work across the five datasets, I still think quantitative results should be provided on analyzing the sensitivity of these magic numbers.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Could the authors discuss the relationship between CLIP-guided Diffusion and your theorem 1? It is a little bit weird to me since CLIP-guided diffusion does work, but your theory suggests the contrary? \n\nQuality & Novelty: See the above section.\n\nReproducibility: The authors provide enough details in the appendix for reproduction. I think I can reproduce it by myself.",
            "summary_of_the_review": "Overall, the goal of the paper is intriguing, but the paper contains a number of heuristics without enough strict ablation study and quantitative results, making the claims doubtful.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1031/Reviewer_pRhF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1031/Reviewer_pRhF"
        ]
    }
]