[
    {
        "id": "o0Eo0MCfQeK",
        "original": null,
        "number": 1,
        "cdate": 1666747421492,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666747421492,
        "tmdate": 1669934565761,
        "tddate": null,
        "forum": "K1KJ0NbFu1h",
        "replyto": "K1KJ0NbFu1h",
        "invitation": "ICLR.cc/2023/Conference/Paper4313/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes an optimal transport-based method to learn dictionaries that generalize over datasets (this is a domain adaptation problem). They propose two approaches: one to reconstruct the samples based on the learned barycenters, and another based on an ensemble of classifiers that are learned based on the dictionary atoms. They provide a toy example of how the method is able to learn a set of dictionaries based on a group of Gaussian-distributed data. They apply their method to learning dictionaries across several datasets and evaluate domain adaptation. They show the outperformance of their method in multi-source domain adaptation and how it performs better than the baselines in both shallow and deep feature generators. At last, they visualize the embedding of the method and how it better encodes similar data close to one another compared to latent based on Wasserstein distance.",
            "strength_and_weaknesses": "Strengths: The paper proposes a novel OT-based framework to enable domain adaptation. The approach has advantages over prior works. I recommend its acceptance.\n\nWeaknesses: The paper lacks clear motivation in the abstract and introduction. The organization of the paper makes it hard to distinguish between what is prior work and their work. For example, section 2 says preliminaries, but the authors mention \"we propose ...\" several times within this section. Please clarify.\n\nHere are some questions that answering may improve the paper and are key to my review:\n\n- How this work differs from the two prior works mentioned in the contribution paragraph?\n- The paper lacks a clear motivation. Abstract has no information on what problem this framework may solve and their motivation for pursuing such a model. Why someone should use their method? For example, based on the preliminaries subsection 2.2, is their model trying to address iid assumption made by the majority of the models that may not be valid on a certain application or during the test? This comment of mine is mainly to improve the clarity of the paper. \n- Are WJDOT and WBT SOTA? or they are OT-based SOTA? Please clarify.\n- What is the complexity of the proposed method compared to other OT methods? In addition, how about a speed comparison?\n- Please include C in Table 1 (right). Why is it not included?\n- How is the performance compared to autoencoders for Figure 7?\n- The ensemble method is not very clear on how it is used for reconstruction. Please elaborate.\n\nHere are some terms that may improve the paper:\n\n- Is there a constraint on the dictionary in optimization formulation (1)?\n- I like the toy example. To highlight the advantages of the proposed method, I suggest including a baseline of form OT and dictionary learning in Figure 5.\n- What are the dictionaries in Figure 5 left? Possible to visualize them on the same figure?\n\n\nMinor points:\n\n- I suggest removing the red box around the words.\n- There is an extra () for year of the citations. It should be (name, year). You can use \\citep instead of \\citet.\n- The third line after (1) is not a complete sentence. Please rephrase.\n- The second line, Section 3, please cite previous works.\n- Is the method in Figure 3b DaDiL-E and R?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear on the technical aspects and result presentation. It is a novel method to provide domain-adapted dictionaries. Although the method builds upon previously OT-based methods, it has novel contributions and theoretical analysis to the embedding distance between the two datasets based on the learned dictionaries.",
            "summary_of_the_review": "The paper proposes an OT-based approach to learning dictionaries across datasets that offer better domain adaptation compared to the baselines. The experimental results are detailed and nicely done. My reservations are coming from clarification on how their method differs from other OT frameworks and the inclusion of domain adaption as motivation into the abstract and intro which is missing in this version. I recommend acceptance of this paper as marginally above.\n\n\n----- after the authors' response\n\nDue to the raised concerns by another reviewer, I have reduced my score.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4313/Reviewer_fvrm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4313/Reviewer_fvrm"
        ]
    },
    {
        "id": "HkW03vcIpcn",
        "original": null,
        "number": 2,
        "cdate": 1667416276291,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667416276291,
        "tmdate": 1669184884277,
        "tddate": null,
        "forum": "K1KJ0NbFu1h",
        "replyto": "K1KJ0NbFu1h",
        "invitation": "ICLR.cc/2023/Conference/Paper4313/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work develops a novel method for applying Wasserstein barycenters to learn a dictionary for a collection of point clouds. Their method works by optimizing an objective over the support of the dictionary distributions and the dictionary weights with a Wasserstein barycenter loss. In particular, the cost function in the labeled data case forces points with the same labels to be mapped to one another. They apply this method to the problem of multi-class domain adaptation where they use the learned dictionary to transfer labels from a target dataset to an un-labeled dataset, and achieve some state-of-the-art results.",
            "strength_and_weaknesses": "Strengths:\n- Studies an important problem, that of domain adaptation with optimal transport\n- Proposes a new method based on using Wasserstein barycenters to form dictionaries of a larger set of point distributions\n- Achieves some state of the art empirical results for multi-class domain adaptation\n- Many parts are well-written, despite the fact that much mathematical notation is not defined before it is used\n\nNeutral:\n-While there is some mathematical justification given for their method, it doesn't require novel theory to accomplish. Also, there are some issues with correctness\n\nWeaknesses:\n- The barycentric coordinates definition is equivalent to 1NN: the minimizer in equation 11 is simply just a point mass on the $\\hat{P}_k$ which is closest to $\\hat{Q}$. The definition in Bonneel et al is distinct from yours, because it also includes a minimization over $\\hat{Q}$\n- The proof of Theorem 3.2 is incorrect: the last inequality on page 16 goes in the opposite direction, so the proof of Theorem 3.2 as written is incorrect\n- Figure 3 doesn't make sense because it is not learning a dictionary since $K = N$ there\n- It isn't clearly explained how the $alpha_T$ weights for the target distribution $\\hat{Q}_T$ are computed\n\nBonneel, N., Peyr\u00e9, G., & Cuturi, M. (2016). Wasserstein barycentric coordinates: histogram regression using optimal transport. ACM Trans. Graph., 35(4), 71-1.",
            "clarity,_quality,_novelty_and_reproducibility": "See above.\n\nWriting feedback:\n- Footnote on page 4 seems like a quote, if so it should be in quotes\n- Sum in equation 9 should be over $\\ell$ not $i$\n- Algorithm 1 is written in a confusing manner, particular the \"sample\" lines. As I understand it, you are sampling only at the beginning (before the for loop begins) and then moving the support points along gradient descent. This should be made more clear\n- Should have parentheses around $1/L$ in line 7 of Algorithm 1\n- Notation is generally confusing and not clearly defined (if defined at all): for example in statement of Theorem 3.2, $\\ell$ is not quantified, and the $\\alpha$'s are not defined. Even the $\\alpha^*$ is not clearly defined, as it depends on $\\hat{Q}$ but that is not made explicit. Or also equation 13 involves undefined terms and no explicit high-probability quantification (should read \"... holds with probability at least $1 - \\delta$)\n- Figure 5 has no explanation of what the loss is\n- $\\pi^c$ in first inequality on page 16 should be $\\pi^2$\n- Section 3.2 could use more explanation of what the actual method of producing the labels is, if only a reference back to equation 8 in section 2. I found that part confusing",
            "summary_of_the_review": "This work studies an important problem and proposes a fairly natural and yet still novel solution. The empirical performance of their solution is strong. However, their theoretical results have some correctness issues (particularly Theorem 2), and otherwise some of their presentation (particularly the statements of their theoretical results, as well as the definitions of their classification procedures in section 3.2) are opaque. For these reasons, I think their work is just below the criteria of acceptance.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4313/Reviewer_6SsD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4313/Reviewer_6SsD"
        ]
    },
    {
        "id": "9HO0U-4HPj",
        "original": null,
        "number": 3,
        "cdate": 1667544043682,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667544043682,
        "tmdate": 1667544043682,
        "tddate": null,
        "forum": "K1KJ0NbFu1h",
        "replyto": "K1KJ0NbFu1h",
        "invitation": "ICLR.cc/2023/Conference/Paper4313/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes using Wasserstein barycenters as a dictionary to recover multiple datasets and uses it for domain adaptation.\nIt shows that their approximation with the learned dictionary is bounded. Empirical results show that the proposed method marginally improved the DA classification accuracy.",
            "strength_and_weaknesses": "Strength:\n\nThe bounds in Theorem 3.1, 3.2, and 3.3 are novel to me.\n\nExploring Wasserstein dictionary learning for multi-source domain adaptation is a direction worth to explore.\n\n\nWeaknesses\n\nThe paper does not offer much beyond what Schmitz et al. did in their Wasserstein Dictionary Learning paper. At least it's not clear to me the contribution of this paper.\n\n\nThe paper is hard to read and understand. \n\n* 1. Introduction is basically a historic review of OT which is not informative and mostly irrelevant to the scope of the paper.\n* 2. Preliminaries are mathematical basics plus some history for dictionary learning, domain adaptation, and OT. They are a collection of previous knowledge in these areas and authors presented them without a flow in between. Some history and citations are stalling readers and are redundant for readers to understand the rest of the paper.\n\n* 3.1 Wasserstein Embedding distance as a proxy for the empirical Wasserstein distance. I appreciate authors' effort on Theorem 1 & 2 but I don't follow the intension of this proxy. I didn't find it being used in the rest of the paper and it doesn't seem to be a theoretical foundation for 3.2 either. \n\n* 3.2 is not clear. Authors jumped too quickly from problem statement to justifying their solution. No reasoning is given linking the problem and the solution. And it's not clear at least to me that how Theorem 3.3 which is yet another bound can justify \"this strategy\". \"We want to learn a dictionary of labeled distributions\": how do we use the dictionary for tasks on the target domain?\n\n* 4.2 Because it's not clear in 3.2 how a dictionary is used for domain adaptation, it's hard to understand 4.2 except a bare table showing high numbers.\n\n* 4.3 \"In this experiment, we want to learn a dictionary over 50 artworks\": I don't quite follow the reason to learn dictionaries of artworks as RGB images. \"which shows that we are able to capture the Wasserstein geometry faithfully\". This seems like a toy example for validation of the learned embeddings. I don't find it informative given we already have 4.1. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is not clear.\n\nThe quality IMHO is below the expectation of an ICLR paper.\n\nI didn't find novelty, but that might be because the paper is hard to read.\n\nThe results in Sec 4 seem reproducible given the description of the algorithm.",
            "summary_of_the_review": "I recommend rejection at this point. The paper does not offer new insights into understanding the connection between dictionary learning and OT and it's hard to read.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4313/Reviewer_LdfT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4313/Reviewer_LdfT"
        ]
    }
]