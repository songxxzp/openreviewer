[
    {
        "id": "OhEP681JJL",
        "original": null,
        "number": 1,
        "cdate": 1666349858050,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666349858050,
        "tmdate": 1670495874211,
        "tddate": null,
        "forum": "CnG8rd1hHeT",
        "replyto": "CnG8rd1hHeT",
        "invitation": "ICLR.cc/2023/Conference/Paper1360/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes an approach to automated feature generation which is split into two subroutines. After new candidate features are generated, in the first subroutine the set of newly generated features is pruned via an adaptation of successive halving which is dubbed successive pruning. In the second stage a boosting approach is followed based on the effect of a feature to reduce the loss of a learner.\n",
            "strength_and_weaknesses": "[+] Interesting and novel approach to automated feature engineering.\n[+] In the (quite limited) empirical study the proposed approach seems to perform very well.\n\n[-] While the proposed approach is indeed very intriguing and it seems to be a reasonable approach (also with respect to observed performance), the paper falls short on providing theoretical justifications for the made design choices. More specifically, the proposed method is only described as it is but not much is stated about why the two stage approach was followed nor was there some motivation on the concrete techniques employed.\n\n[-] The empirical study is quite limited. In total, 7 datasets were considered plus some Kaggle competitions. While such a small number of datasets might be enough to demonstrate the existence of advantages, it is not enough to state whether it really outperforms all the state-of-the-art methods.\n\n[-] Moreover, since OpenFE is a heuristic, it most likely will have some shortcomings. No such shortcomings are observed nor discussed. In particular, no limitations of the approach are discussed throughout the paper.\n\n[-] Another open question is on base of which datasets the method was developed. If it was with respect to the evaluated datasets there might be a positive bias in the data.\n\n[-] Furthermore, it was not stated how the datasets were picked and why other datasets were not considered.\n",
            "clarity,_quality,_novelty_and_reproducibility": "- The approach itself combines and adapts already existing methods to the setting of feature engineering. To the best of my knowledge the exact use and application of these methods is novel.\n- While the language of the paper is mostly clear and quite readable, Section 4 could benefit from some proofreading. \"has benefit provably.\", \"Due to space limit\", \"one may think each training data as a transaction\", \"[...] (each user may have many transactions in this table. These transactions form a group).\".\n- The variables max_order in Algorithm 1 and q in Algorithm 2 are not defined.\n- For permutation feature importance a wrong reference is given: (Breiman, 2001). In this paper nothing is stated about permutation feature importance.\n- Bold claims are made about outperforming human experts. However, but the pub. rank is never 1 in the results which I interpret as that there exist expert approaches that perform better and human experts are not outperformed. It is not clearly stated how this conclusion is drawn.\n- Several parts of the paper are outsourced to the appendix. If I counted correctly the appendix is referenced 19 times throughout the paper. For me as a reader, this makes the paper quite hard to follow and I wonder whether a 9-page conference paper is the right format for this work.\n",
            "summary_of_the_review": "To sum up, I have the overall impression that the paper is not yet ready for publication, especially not at such a prestigious venue as ICLR. While the proposed method is reasonable and the overall idea is novel, the paper falls short on the justifications for design decisions, scope of the experimental study, and discussion of limitations. Significant parts are outsourced to the appendix making the overall content hard to grasp. All in all, I recommend to reject the paper but I would like to encourage the authors to further pursue their work and revise the paper since the paper would make a great contribution also with the open source implementations of other approaches.\n\n\nEdit after rebuttal: My concerns vanished after the authors gave their rebuttal along with more experimental results. However, I am still missing some discussion of the limitations which might be hard to spot due to the outstanding performance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1360/Reviewer_kN28"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1360/Reviewer_kN28"
        ]
    },
    {
        "id": "VJTxtFfahzs",
        "original": null,
        "number": 2,
        "cdate": 1666399183466,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666399183466,
        "tmdate": 1668762241466,
        "tddate": null,
        "forum": "CnG8rd1hHeT",
        "replyto": "CnG8rd1hHeT",
        "invitation": "ICLR.cc/2023/Conference/Paper1360/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes an evaluation method to eliminate redundant candidate features following the expand-and-reduce framework for automated feature generation. The proposed method achieves state-of-the-art performance on seven benchmarks and outperforms human exports for the first time. Moreover, a theoretical analysis is provided to prove the advantage of feature generation over the base feature, strengthening this task's importance and facilitating future research.",
            "strength_and_weaknesses": "The main strengths of this paper are as follows:\n1. The author has done sufficient experiments, to illustrate the effectiveness of the proposed method. Also, by reproducing the main methods of this task, this paper provides convenience for future work.\n2. This paper gives theoretical proof for the advantage of feature generation over the base feature set. \n3. The proposed method is well explained and the overall logic is smooth.\n\nThe main weaknesses of this paper are as follows:\n1. The method proposed in this paper is still restricted to the existing expand-and-reduce framework, so the innovation of the overall method is limited. One possible optimization direction is to eliminate part of the features when constructing the candidate set.\n2. The writing of this article is a little redundant. As a result, the important ablation study section has to be put in the appendix.\n3. In the experiments section, the definition of the experts is not clear enough. Especially when claiming to outperform human experts, the exact definition of the comparison object needs to be specified.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The overall writing of this paper is clear but a little redundant, since the method is mentioned too many times before being officially introduced. Still, the framework has been well explained and supported by the experiments. Moreover, the mathematical derivation is complex but logical.",
            "summary_of_the_review": "The method proposed in this paper is not the most innovative, but the authors contribute to this field by theoretically proving the advantage of feature generation. Overall, the paper is marginally below the acceptance threshold of ICLR2023. \n\n======================================================================================================\nThanks for the responses. My main concerns have been answered and resolved by the authors, including the completeness of datasets, the overall clarity, the complexity and runtime of OpenFE, and a detailed explanation of the Kaggle competition. Also, according to the supplementary results on 20 datasets, OpenFE achieves a better overall performance than FETCH. Considering the authors\u2019 response, the contributions of open-source implementations, and some issues that did exist in the first submission, I have decided to change my recommendation to 6: marginally above the acceptance threshold.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1360/Reviewer_mToT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1360/Reviewer_mToT"
        ]
    },
    {
        "id": "Nkfcjoyjzq",
        "original": null,
        "number": 3,
        "cdate": 1667532001573,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667532001573,
        "tmdate": 1667532001573,
        "tddate": null,
        "forum": "CnG8rd1hHeT",
        "replyto": "CnG8rd1hHeT",
        "invitation": "ICLR.cc/2023/Conference/Paper1360/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors introduce a feature generation and model boosting methodology, dubbed \"OpenFE\". \n\nOpenFE proceeds by \n1. Generating a set of possible features, by ways of atomic operations (elementary operations, as well as \"grouped\" operations that apply mean/min/max operations over subsets of the data corresponding to the same categorical feature).\n2. Pruning the bulk of redundant features based on (Jamieson & Talwalkar, 2016).\n3. Ranking remaining features by their relative importance (the top k acting as the final set of extracted features).\n\nThe authors verify OpenFE on seven datasets, as well as by comparing OpenFE to competitors on a past Kaggle benchmark. \n",
            "strength_and_weaknesses": "# Strengths\n- The paper is well written, and addresses a crucial problem in real-world ML applications.\n- Experimental results across several datasets show that OpenFE outperforms competing feature generation baselines, such as DCN-v2 and TabNet.\n- The authors consider a variety of ablation experiments to verify the importance of the different OpenFE components.\n- The authors reimplement and open-source baselines considered in this paper.\n\n# Weaknesses\n- I believe that the main weakness of this work lies in its overall clarity. The authors provide a high-level description of OpenFE, but spend too little time discussing the specifics. For example, \n   + How important is it to increase the highest order of potential features in OpenFE? How does this trade off with the overall runtime?\n   + Similarly, the authors provide a theoretical analysis of when feature generation can provably improve model performance. However, the assumptions that are made about the training data - crucial to the analysis and overall scope of the result - are left entirely to the appendix. I would recommend providing a quick summary of the assumptions and why they are required for the proof in the main paper.\n- The authors do not provide an analysis of the overall runtime of OpenFE, despite the potential size of the explored feature space and resulting algorithms being major impediments to automated feature extractions. I recommend the authors include some formal analysis, including the complexity of OpenFE, as well as (ideally) some guarantees on the two feature refinement subprocesses. Would it be possible to state anything in terms of how well Algorithm 2 approximates its optimal output?\n- The authors compare their works on a Kaggle competition, but focus on comparing to methods that did not rank first in that competition. Although this may be reasonable (algorithmic constraints, etc.), doing so must be justified. What is the difference between the model that placed 42nd and the model that placed first? Do I understand correctly that they were proposed by the same team?\n\n# Questions for the authors\n- Could you confirm that in Table 3, the OpenFE results describe Gradient-Boosted Trees with augmented features learned with OpenFE (but without using expert features)?\n- Could sub-components of OpenFE also be combined with existing feature generation methods?",
            "clarity,_quality,_novelty_and_reproducibility": "# Clarity\nAlthough the paper is well written, the proposed OpenFE method is not described in sufficient detail within the main paper. Similarly, the experimental results are difficult to put into context, as the baselines and the extent to which they resemble OpenFE are not sufficiently described (are there baselines that also generate new features? Which baselines simply consider pruning the feature space)?\n\n# Quality\nExperimental results across a variety of datasets showcase that OpenFE outperforms the considered baselines by a significant amount, while remaining comparatively computationally cheap (cf. Table 8). \n\n# Novelty\nThis works combines previous work into separate steps that make up OpenFE. Although this is not as of itself a bad thing, the novelty could potentially be improved by further theoretical analysis and worst-case bounds as discussed earlier.\n\n# Reproducibility\nThe authors provide the source code for OpenFE.",
            "summary_of_the_review": "This is an interesting paper, but the overall clarity of the proposed method is insufficient in the paper's current state. Although empirical results show the value in OpenFE, it is difficult to put them in context. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1360/Reviewer_YEEM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1360/Reviewer_YEEM"
        ]
    }
]