[
    {
        "id": "0xWJ9yTq86N",
        "original": null,
        "number": 1,
        "cdate": 1666353356894,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666353356894,
        "tmdate": 1668504293704,
        "tddate": null,
        "forum": "Y5SEe3dfniJ",
        "replyto": "Y5SEe3dfniJ",
        "invitation": "ICLR.cc/2023/Conference/Paper4215/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper explores encoding high-resolution weather data using implicit neural representation (INR). In INR, a neural network takes as input a coordinate (here, transformed latitute, longitude, time and pressure) and output the compressed values (weather data here) at that coordinates. The approach is compared to several baselines and evaluated both in terms of compression error and in terms of performance of a model trained on the compressed data. The proposed approach significantly outperform the baselines. The paper also contains an ablation study.",
            "strength_and_weaknesses": "On the plus side,\n* Weather data is an interesting application. The need for compression is also well motivated in the paper.\n* I like the that the authors explain the specificities of weather data and how it impact their model.\n* Compression is evaluated both in terms of reconstruction error and accuracy of a neural network trained on decompressed data. Results are good.\n\nOn the negative side,\n* Experiments are a bit limited in scope. Only four data sets and one weather variable are considered. Unless I am mistaken, this means only four encoding were done. I appreciate that the data sets of different characteristics and I am aware encoding time is long. The largest time frame considered is 24 hours. The results are good, but they did not convince me the proposed approach could extended to years of historical data, an application mentioned by the authors. I think discussing this point would be interesting. \n* Another application mentioned by the author is to compress simulation data. It would be interesting to compare compression time with simulation time.\n* The use of GELU is not really motivated and not included in the ablation study. \n\n-----------\n**Update**\nI had misunderstood the scope of the experiments. The authors pointed this out and were kind enough to add additional experiments. They also answered the other points I raised. I believe this work is worth publishing.\n",
            "clarity,_quality,_novelty_and_reproducibility": "* The paper is well written and clear.\n* The neural architecture used is based on Tancik (2006). There are some significant differences as the data points lie on the sphere rather than on a grid. I believe this to be of independent interest for the machine learning community.\n* The experiments are ok (see above for more details). \n* The code is provided, so reproducibility is good. I did not try running the code.",
            "summary_of_the_review": "For me this paper describes an interesting application, could have widespread use to compress weather data and some limited novelty on the machine learning side, so I find the content interesting. However, the limited scope of the experiments makes it impossible to know how it will behave on larger data sets such as all historical weather data.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4215/Reviewer_U9H2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4215/Reviewer_U9H2"
        ]
    },
    {
        "id": "RAmyJVJgpy-",
        "original": null,
        "number": 2,
        "cdate": 1666367060210,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666367060210,
        "tmdate": 1666367060210,
        "tddate": null,
        "forum": "Y5SEe3dfniJ",
        "replyto": "Y5SEe3dfniJ",
        "invitation": "ICLR.cc/2023/Conference/Paper4215/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a compression method for weather and climate worldwide data using a deep learning model combined with a Fourier transformation in order to enforce periodicity of the sphere data. The compression ratio is very high, from 300 to 3000, and the residual error comparable to methods with compression ratios drastically lower. However, the computation time is still high and high frequency features, such as hurricanes, are not always reconstructed. The tests were made on ERA5 reanalysis data, which is the open source widely used meteorological data set. ",
            "strength_and_weaknesses": "Strengths: \n- compression ratio (300 to 3000)\n- spherical transformation, which is indeed very important for earth data\n- usefulness of the method: while at first I was skeptical on the usefulness of such an approach for climate data, as clearly ERA5 will never be only stored in a degraded version, I was convinced by the usage of machine learning applications (and probably also others), where these amount of data are usually untractable for a local storage+usage.\n- comparison with state-of-the-art and on different settings\n- current limits of the method clearly analyzed\n\nSome clarifications would be valuable for the paper, and in particular the following points:\n- I think that in order to be used, this kind of approach would need to have an uncertainty quantification, at least based on the frequency of the signal to recover,  or based on the type of data, etc. in order for the user to be able to know when it can trust it and when in can't. How would you do it? \n- The compression consists in training a neural network. Do you think this is robust enough to work with all size, input field, etc.? Do you think this could be used by a non-machine learning expert?\n- In which type of applications would your error be negligible? It is good to have a very high compression, but the final quality needs to be satisfactory for targeted applications at least (since the hurricanes are for example not the case).\n- The compressed data representation are the neural network weight values directly. Could your compression be used directly to feed a machine learning model, or would users have to decompress the data before using it?\n- Would your method, and in particular the first part about the coordinate transformation, work in the case of non-worldwide data, i.e. only a part of the globe?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is easy to read, the limits are clearly explained and the comparison with state-of-the-art also present. \nThe codes are present and seems to be easy to run.",
            "summary_of_the_review": "Though I am not a specialist in compressing data, I did use climate datasets for machine learning applications and I think this paper is worth publishing.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4215/Reviewer_5Wg4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4215/Reviewer_5Wg4"
        ]
    },
    {
        "id": "3ARCD3QLh4",
        "original": null,
        "number": 3,
        "cdate": 1667151577310,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667151577310,
        "tmdate": 1668700648106,
        "tddate": null,
        "forum": "Y5SEe3dfniJ",
        "replyto": "Y5SEe3dfniJ",
        "invitation": "ICLR.cc/2023/Conference/Paper4215/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The  authors proposes  their compression approach for multidimensional weather data leveraging Neural Networks. The authors argue that this could provide compression ratios from 300x to 3,000x which is quite important in complex high resolution data regime. They evaluate this on the ERA5 weather dataset benchmarked against the SZ3 baseline. The author's experiment on different network architectures and  provide a case study on a specific hurricane event.",
            "strength_and_weaknesses": "Strength:\n* The empirical evaluation and ablation studies are reasonably well detailed, showcasing how this is applied in real world scenarios.\n* The paper is well organized, motivated and details the related work.\n\nWeakness:\n* Some of the important details are quite unclear.\n     *It's quite unclear on what the described \"target\" scalar value is. How is the ground truth information sourced from? \n     * Why are the Fourier features used?\n     * Perhaps, I'm missing an obvious detail in information theory. How is the precision recovered during decompression  when converting model weights from float16 to float32?\n* Are the RMSE, RMAE metrics over grids the best choice of metrics? Is there a metric that compares blurriness of the decompressed output with the ground truth?\n* The technical novelty of the introduced Neural Network itself isn't quite significant.\n\n       \n",
            "clarity,_quality,_novelty_and_reproducibility": "On a high level the paper is clear to follow and seems novel as detailed in the related work and methods section. There are a few implementation details which are unclear (listed above), which make this difficult to reproduce.",
            "summary_of_the_review": "Overall, the work proposes an reasonably novel technique in an important domain. The authors conduct sufficient empirical evaluation. However, there are details which are not described clearly along with the technical novelty of the Neural network model.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None that I can see, the authors have satisfactorily addressed this towards the end of the paper.",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4215/Reviewer_Kcey"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4215/Reviewer_Kcey"
        ]
    }
]