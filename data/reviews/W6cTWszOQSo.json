[
    {
        "id": "cm41t0gKbbc",
        "original": null,
        "number": 1,
        "cdate": 1665968713952,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665968713952,
        "tmdate": 1665968713952,
        "tddate": null,
        "forum": "W6cTWszOQSo",
        "replyto": "W6cTWszOQSo",
        "invitation": "ICLR.cc/2023/Conference/Paper1634/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a generative model for volumetric meshes (i.e., tetrahedral meshes). The generation process has two steps: a diffusion model (DDPM) first generates a voxelized shape, which serves as a template and is then deformed to the final volumetric meshes via optimization. The loss terms for the optimization are carefully chosen to get rid of of defects like flipping and high distortion. Experiments on ShapeNet dataset shows that the method can generate high quality volumetric meshes.",
            "strength_and_weaknesses": "Strength:\n\n- The proposed method is technicaly sound and has its novelty. Genrateing voxels using a diffusion model and then deforming the voxelized shape via optimization to get the final tetrahedral mesh is new to this field. The optimization formulated using neural network term (i.e., data term) and regularization terms looks very effective.\n- The ablation study is pretty good, especially for the optimization part which contains many loss terms. As I read through the paper, I accumulated many questions in mind regarding the design choices. Most of them are well addressed in the ablation study.\n\nWeaknesses:\n\n- Though the method does achieve some state-of-the-art performance, technically it has some clear drawbacks including\n  - The quality of the generated volumetric meshes is limited by the quality and resolution of the initial voxelized shape. In addition, the topology is determined by the voxelized shape.\n  - Each module is trained/optimized separately, making the method less elegant.\n- The advantage of \"NVMG\" over \"NVMG (w/ NDC)\" seems small (Table 1). The numbers might be misleading, so Figure 6 is a good example to show the actual advantage. I'd like to see more example like Figure 6 and an explanation why NDC cannot handle these cases.\n- Missing timing statistics. Since the last step is an optimization process which needs to be carried out at inference, run time becomes important. How long does it normally take?\n- Main results (Table 1) only have numbers for Chair and Airplane categories. I see there are additional examples for Lamp and Bench in the appendix. Why not listing their numbers in the main text? I think it's better to include them for completeness.\n\nAdditional comments:\n\n- Sec. 3.2 first line, \"a coarse representation the shape of interest\" -> \"a coarse representation of the shape of interest\"\n- Sec. 4.1 the sentence \"Supp. material reports more evaluations.\" seems redundant.\n- Sec. 4.1.1, \" so in the hard cases\" -> \"In the hard cases\"\n- I'd like to see more discussion about DMtet and what's the unique advantage of the proposed method over it. DMtet also aims to generate tetrahedral meshes via learning and its representation seems to be successful in some downstream applications (https://nvlabs.github.io/nvdiffrec/).\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very clear and easy to follow. The contribution is somewhat new but not that significant. ",
            "summary_of_the_review": "Leveraging deep generative models to synthesize volumetric meshes is of course an interesting problem. Though the proposed method is far from the ideal way to do this (it's separated trained, limited by voxel template, fixed topology), I think this work is a solid step forward and the evaluation looks adaquate. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1634/Reviewer_E4fj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1634/Reviewer_E4fj"
        ]
    },
    {
        "id": "BKPH5QGXkx",
        "original": null,
        "number": 2,
        "cdate": 1666528814688,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666528814688,
        "tmdate": 1666528814688,
        "tddate": null,
        "forum": "W6cTWszOQSo",
        "replyto": "W6cTWszOQSo",
        "invitation": "ICLR.cc/2023/Conference/Paper1634/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a generative model of meshes which are volumetric, ie. with an inner structure.\nAs opposed to recent implicit surfaces (based on SDF or occupancy), it directly outputs a mesh. It relies on a 2 steps process:\n- 1: a diffusion model generates voxel grids.\n- 2: a voxel grid refinement, using a neural network to project voxel vertices to their closest surface points.\n\nThe second step requires handcrafted regularization techniques to avoid flipped faces and preserve the mesh quality. Overall, the pipeline demonstrates good generative properties in terms of coverage.",
            "strength_and_weaknesses": "A strength of the paper is to employ a diffusion process to generate voxel grids. This is, to my knowledge, the first time this elegant framework is used to that end. The regularization techniques proposed for the refinement step are well ablated (smoothing, orientation, noisy reprojection)\n\n\nMy main concern is on the whole motivation for directly producing meshes with neural networks, as opposed to most state of the art methods (DeepSDF, DefTet, GET3D, Convolutional Occupancy Networks, \u2026), to which authors do not compare. These methods also perform better qualitatively.\nAuthors only provide unclear and vague statements to support it, such as in the introduction\u2019s first paragraph: \u201cthe implicit representation needs to be converted into explicit representations such as meshes, which by itself is not a completely solved problem\u201d. I really don\u2019t agree with the last part: Marching Cubes provides smooth and regular meshes off the shelf, and has been made differentiable for applications requiring to pass gradients from vertices to upstream implicit parameters (see Remelli et al. NeurIPS 202 (MeshSDF) or Atzmon et al. NeurIPS 2019).\nDirectly regressing meshes obviously has a very negative impact on shape quality, and requires many handcrafted regularization tricks which complexify the method. Authors need to suggest and demonstrate reasonable applications benefitting from the direct generation of meshes compared to implicit nets.\n\nSimilarly, I do not get the point of getting an inner mesh structure, whereas it is presented as a key feature of the presented pipeline - but never used for any concrete application. What is the benefit of having an inner mesh structure compared to just a surface? How to assess the quality of inner mesh structures, quantitatively? Why would a naive dense grid be bad?\n\nIf the main focus of the paper is about generative properties, then a comparison with randome latent code sampling of an implicit model (DeepSDF) is required. Authors would need to show better \u201csampling properties\u201d of the proposed diffusion model.\n\n\nMinor concerns are:\n- the \u201cRobust reprojection\u201d consists in adding noise to points during reprojection. Authors show that it empirically helps, but provide no theoretical explanation for it.\n- all the regularizations employed during the reprojection step are termed as \u201cphysically robust\u201d but do not involve any physics.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall clear, and reproducible. The main novelty consists in applying a diffusion process to a 3D grid of voxels (instead of 2D grid of pixels). But this comes at the price of a very coarse resolution, and thus poor qualitative results.",
            "summary_of_the_review": "This paper proposes to use a recent deep learning technique (diffusion) to modernize an old representation (deep explicit meshes), but it still is not on par with more modern and simpler ideas (implicit fields). Since no motivation is given for sticking to explicit meshes, I vote for rejection.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1634/Reviewer_KpX3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1634/Reviewer_KpX3"
        ]
    },
    {
        "id": "9YxtRBqWInx",
        "original": null,
        "number": 3,
        "cdate": 1666621669391,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666621669391,
        "tmdate": 1666621669391,
        "tddate": null,
        "forum": "W6cTWszOQSo",
        "replyto": "W6cTWszOQSo",
        "invitation": "ICLR.cc/2023/Conference/Paper1634/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a generator, abbreviated as NVMG, for generating volumetric meshes. With the help of the diffusion model, the voxelized shape can be generated from a randomly sampled vector, which will be divided into tetrahedral mesh. Then the initial tetrahedral mesh is deformed to the final result under the guidance of neural closest point predictor and the regularization of several carefully designed terms, including smooth term for uniform structure, orientation term to prevent defects and data term for distortion suppression. The proposed method can generate tetrahedral mesh randomly or from an input image. It can also perform shape editing through editing the voxel representation. ",
            "strength_and_weaknesses": "Strength:\n-- This paper proposes a novel pipeline for tetrahedral mesh generation.\n-- The paper has conducted adequate comparisons and evaluations, and showed generation results and editing results, which demonstrate the usability of the proposed method. \n--The results are good.\n\nWeaknesses\n-- Some details need to be verified. See my comments below.\n-- It seems that the voxel generation based on diffusion model adopts the existing method (Zhou et al., 2021). Is there any further improvement?\n-- As for the voxel-conditional neural nearest point predictor, given the voxelized shape generated in the first stage, it predicts the nearest point on the real surface for each voxel vertex, which is equivalent to predicting the correspondence of the initial tetrahedral mesh to the real surface for further deformation. So how to deal with the ambiguity, that is, some similar models have the similar voxel representation, or even the same voxel representation. How does the network deal with this situation?\n-- Although the authors give the optimization terms for mesh deformation, they do not explain how the optimization is carried out. For example, is the iteration required? what solver is used? What is the value of \\lambda_a, \\lambda_b and \\lambda_c in equation (7)?\n-- Minor issues:\nIn Section 3.3, \u2018this naive projection does work well\u2019 should be \u2018this naive projection does not work well\u2019\n-- Missing related work:\nAtlasNet: A Papier-M\u00e2ch\u00e9 Approach to Learning 3D Surface Generation, CVPR 2018\nLearning elementary structures for 3D shape generation and matching, NIPS 2019\nSDM-NET: deep generative network for structured deformable mesh, ACM TOG\nTM-NET: Deep Generative Networks for Textured Meshes, ACM TOG\nO-CNN: Octree-based Convolutional Neural Networks for 3D Shape Analysis, ACM TOG\nAdaptive O-CNN: A Patch-based Deep Representation of 3D Shapes, ACM TOG\n",
            "clarity,_quality,_novelty_and_reproducibility": "The description of the paper is clear, and the quality, including the writing and the results are good. The method proposed in the paper is a novel pipeline for tetrahedral mesh generation, which can be used for mesh generation, mesh editing, and mesh mixture. The method contains three modules, and a code release will be helpful for reproduction.",
            "summary_of_the_review": "This paper proposes a new method with good results, although some details of the method need to be further clarified. I tend to accept this paper.\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1634/Reviewer_873W"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1634/Reviewer_873W"
        ]
    },
    {
        "id": "BzEyysbL7ha",
        "original": null,
        "number": 4,
        "cdate": 1666759118358,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666759118358,
        "tmdate": 1666760263657,
        "tddate": null,
        "forum": "W6cTWszOQSo",
        "replyto": "W6cTWszOQSo",
        "invitation": "ICLR.cc/2023/Conference/Paper1634/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a method for synthesizing high-quality tetrahedral meshes. The method starts with a voxel grid generator and then produces a regualarized tet mesh from it. For the voxel grid, the authors use an existing diffusion-based model. For tet-meshing, the authors first employ a neural network trained to predict the closest point on the actual surface given the voxel grid and a query point, and then recover this surface from the closest-point function by optimizing a set of losses including regularizing losses. The authors claim that the resulting meshes are better than baselines on selected metrics, especially in terms of robustness and freedom from artifacts.\n",
            "strength_and_weaknesses": "The method is straightforward (conditioned on the DDPM which is complex but not a contribution of this paper) and appears to work quite well.\n\nMy main concern is that the contribution is quite limited. The main feature is a different way of recovering a volumetric mesh from a voxel grid. The heavy lifting in the _generation_ part is done via a prior method, viz the voxel generator. It is clear that the results are better than the ones that directly produce meshes (e.g. Fig 8), and the point that converting voxels to meshes is a better choice than synthesizing meshes directly is well taken. But the magnitude of the technical contributions beyond this point is a bit less clear. There is clear utility in having a better voxel-to-tet-mesh method. But the paper conflates this with the generation aspect and makes it harder to evaluate. Is the voxel-to-mesh method really that much better than NDC or NMC? Is this properly evaluated in a wholistic way?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is quite clear and the work is good-quality and (to the best of my knowledge) original, modulo my comments about the magnitude of the contribution above.\n",
            "summary_of_the_review": "I think the paper itself is reasonably sound. My main concern is regarding the scope/magnitude of the contribution, as detailed above.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1634/Reviewer_nDNc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1634/Reviewer_nDNc"
        ]
    }
]