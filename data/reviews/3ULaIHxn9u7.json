[
    {
        "id": "Dfkbo7T65t",
        "original": null,
        "number": 1,
        "cdate": 1666657732110,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666657732110,
        "tmdate": 1666657732110,
        "tddate": null,
        "forum": "3ULaIHxn9u7",
        "replyto": "3ULaIHxn9u7",
        "invitation": "ICLR.cc/2023/Conference/Paper6056/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a method for imitation learning with heterogeneous observations. Specifically, the dynamics mismatch and the support mismatch are handled using importance weighting and rejection. Experiments show the effectiveness of the proposed IWRE method on both Atari and MuJoCo tasks.",
            "strength_and_weaknesses": "Strength:\n\nThe proposed method is explained with details. Both dynamics and support set mismatch are handled with the proposed novel algorithm. Experiments show evidence for the improved covering rate in expert data by the learned policy. Explanations for the experimental results are thorough.  \n\n\nWeakness:\n\nFor the t-SNE plot in Fig. 5, is it true that the support set of $\\pi_1$ also has some part outside the expert data? How is this part handled by the method? This does not seem to be captured by Fig. 4. \n\nAdding ablation studies with only importance weighting or the rejection will help to understand their effects better. However, no such ablation study is conducted in the current paper.\n\nThe fonts in the figures are too small to read.\n\nIn Fig. 6 (a), the ChopperCommand results are a bit weird. Is it too easy or too hard to learn? It seems the reward becomes large very quickly but decreases along the training. Why is this happening? Please explain more in the paragraph.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper has good clarity.\n\nThe proposed algorithm is novel.\n\nThe method is reproducible.\n",
            "summary_of_the_review": "The paper proposes an effective and novel algorithm for handling both dynamics and support set mismatch in imitation learning. The experiments justify the claims that the proposed method helps with a better coverage of the expert data as well as the effectiveness in facing the heterogeneous observations. Some questions need to be answered well in the paragraph. Adding ablation studies will make it a better work.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6056/Reviewer_ntXD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6056/Reviewer_ntXD"
        ]
    },
    {
        "id": "TZrUNNqcGw",
        "original": null,
        "number": 2,
        "cdate": 1666746989320,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666746989320,
        "tmdate": 1666746989320,
        "tddate": null,
        "forum": "3ULaIHxn9u7",
        "replyto": "3ULaIHxn9u7",
        "invitation": "ICLR.cc/2023/Conference/Paper6056/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a method for imitation learning (IL) when the expert and agent operate from different observation spaces. The paper proposes a new algorithm for dealing with this setting, which relies on two components: an importance weighting correction which modifies the standard GAIL objective, and a rejection mechanism to address potential support mismatch between expert and policy distributions. The algorithm is evaluated on 5 Mujoco and 3 Atari environments.\n\nThe algorithm operates in two stages. First, GAIL is run in the expert's MDP to learn a decent, but not necessarily optimal policy. Then, the same policy is run in the expert and learner MDPs (this is assumed to be possible), giving a dataset of aligned trajectories. This is then used to compute the importance weighting correction factor. Finally, a classifier is trained to filter out the non-expert parts of the policy, which is used for the rejection sampling mechanism.",
            "strength_and_weaknesses": "# Strengths:\n- The goal of learning from demonstrations gathered in a different observation space is definitely interesting\n- To my knowledge, this combination of importance weighting and rejection sampling is novel.\n\n\n# Weaknesses:\n- I'm not convinced by the setup they're considering here. They make assumptions which seem unrealistic to me: in particular, they assume it is possible to interact with *both* the expert and agent MDPs to some extent. This is necessary for gathering what they call the evolving dataset, which is a set of trajectories where the observations in both MDPs are aligned. I find this to be a strong assumption, and one which other methods (e.g. [1]) do not make - they assume expert trajectories are given and only interaction with the learner's MDP is allowed.\n\nFor this reason, although I think the general goal of IL from heterogeneous observations is very interesting (for example, learning from YouTube videos where the perspective of the expert is different from that of the agent), this paper makes overly strong assumptions that one can gather trajectories from both MDPs. This strong assumption limits the significance and impact of this work. Also, the fact that they are only considering discriminator-based approaches and not others (e.g. non-adversarial ones such as RED [2] or DRIL [3]) limits the applicability.\n\nAlso, the algorithm proposed is fairly complicated: there are two different learning phases with GAIL subroutines as well as training a classifier on intermediate data. I believe the community would be more open to adopting a simpler, more end-to-end approach.\n\n[1] https://arxiv.org/pdf/1703.01703.pdf\n[2] http://proceedings.mlr.press/v97/wang19d/wang19d.pdf\n[3] https://openreview.net/pdf?id=rkgbYyHtwB",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n- The writing is decent, however I think the paper would be easier to understand if pseudocode for the full algorithm were presented in the main paper rather than the appendix.             \n\nQuality/Clarity: \n- As mentioned above, the algorithm is quite complicated - I believe a simpler algorithm would be preferable and easier to build upon. Overall the experiments seem sound given the assumptions made by this work.             \n\nNovelty:\n- To my knowledge, this combination of importance weighting and rejection sampling is novel. \n\nReproducibility:\n- The authors do not mention any code release in their reproducibility statement. ",
            "summary_of_the_review": "Overall, I do not recommend acceptance for this paper due to:\n- the overly strong assumptions made by this work, which somewhat undermine the otherwise interesting setting they consider\n- the complexity of the algorithm            ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6056/Reviewer_j2UZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6056/Reviewer_j2UZ"
        ]
    },
    {
        "id": "Xc1qXsPf5u",
        "original": null,
        "number": 3,
        "cdate": 1666999856859,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666999856859,
        "tmdate": 1666999856859,
        "tddate": null,
        "forum": "3ULaIHxn9u7",
        "replyto": "3ULaIHxn9u7",
        "invitation": "ICLR.cc/2023/Conference/Paper6056/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The bulk of existing work on imitation learning focuses on settings in which the expert demonstrator and learner operate under the **same observation space**; however, in many real-world settings, this isn\u2019t realistic. The work formalizes the problem of heterogeneously observable imitation learning (HOIL) and present an algorithm \u2014 Importance Weighting with Rejection (IWRE) to address this.\n\nConcretely, given a set of expert demonstrations in a given observation space, the HOIL setting this work looks at decomposes learning into collecting a set of (suboptimal) \u201cmatching correspondence\u201d data online, running a policy that allows one to correlate expert observations with learner observations (even when there\u2019s no explicit overlap in observables \u2014 e.g., Atari ALE RAM state vs. visual features). The proposed IWRE framework then tries to address two key problems in this learning setup via an online IRL-like procedure (similar in nature to GAIL); first, the problem of optimality/dynamics mismatch \u2014 the \u201cexpert demonstrations\u201d are assumed to be optimal, while the correspondence data is not; as a result, directly imitating from the union of both datasets would result in a bad policy. To get around this, similar to prior work in offline RL, this work proposes using importance sampling (the IW in IWRE) to correct for this mismatch, prioritizing the expert demonstrations.\n\nThe second problem IWRE addresses is that of a support mismatch; the \u201ccorrespondence matching\u201d data is again problematic because its suboptimality might mean that the corresponding data only sees a fraction of the state space. As a result, IWRE uses rejection sampling to drive the learner\u2019s behavior policy towards the support of the actual expert observation distribution (exploiting a learned discriminator that partitions the expert demos and correspondence demos), therefore circumventing this issue.\n\nThe IWRE approach is evaluated on a set of (albeit somewhat synthetic) environments from the Atari Arcade Learning Environment (expert observations \u2014 frames, learner observations \u2014 RAM state), and Mujoco Continuous control (expert/learner see disjoint halves of the Mujoco observation space). Compared to traditional imitation learning baselines and reinforcement learning upper bounds (for ceiling results), the IWRE approach is strong, performant, and seems to generalize across environments.\n",
            "strength_and_weaknesses": "I really like this approach, and the motivation behind the HOIL problem. I think it\u2019s definitely true in many robotics settings that there is a mismatch in observation spaces between the expert and the learner, and addressing this is important.\n\nIWRE as an algorithm is also well-motivated, and follows naturally from a large body of prior work; combining importance weighting and rejection sampling in this setting is natural and novel, and clearly the results speak for themselves.\n\nThe one weakness I have of this work is with the evaluation; technically, to prove the viability of the algorithm, the existing \u201csynthetic\u201d observation splits in the Atari and Mujoco environments make sense, but I\u2019d really love to see a more realistic evaluation where heterogeneous observations are actually ecologically viable \u2014 perhaps in settings in robotic manipulation for example.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is clearly written, with high-quality explanations and derivations of the approach. The care given to describing the heterogeneous observation setting and how it differs from settings studied in prior work are additionally very helpful. This problem setting and proposed algorithm are both novel.\n",
            "summary_of_the_review": "I believe this to be strong work, with an evaluation that demonstrates the viability of the proposed approach and difficulty of the problem setting. However, I\u2019d love to see more ecologically viable/realistic evaluations, rather than the somewhat synthetic tasks studied in this work.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6056/Reviewer_w9cE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6056/Reviewer_w9cE"
        ]
    },
    {
        "id": "9oYaFtLtwCF",
        "original": null,
        "number": 4,
        "cdate": 1669959937732,
        "mdate": null,
        "ddate": null,
        "tcdate": 1669959937732,
        "tmdate": 1670926968568,
        "tddate": null,
        "forum": "3ULaIHxn9u7",
        "replyto": "3ULaIHxn9u7",
        "invitation": "ICLR.cc/2023/Conference/Paper6056/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper aims to solve a branch of imitation learning scenario that the expert\u2019s and the learner\u2019s feature (observation) spaces are different. This scenario is quite difficult compared with existing imitation learning work under the same observation space. Moreover, the related works relied on the expert\u2019s and learner\u2019s observations can be obtained during the whole learning process, which can be costly in many real-world applications. So this paper tried to solve this problem with limited observations coexistence.\n\nAt first, this paper formulated the learning problem as heterogeneously observable imitation learning (HOIL), where some expert demonstrations and an auxiliary policy were given under the expert\u2019s observation space, and the target was to learn a policy under the learner\u2019s observation space. Since these two spaces can be arbitrarily different, they needed the auxiliary policy to sample some data containing both two observations as the bridge between the expert demonstrations and the learned policy. Later on, they limited the number of observation coexistence to lower the cost.\n\nBy analyzing this problem, they found the underlying challenges, i.e., the dynamics mismatch and the support mismatch. These two mismatches appeared due to the imperfection of the auxiliary policy. To solve this problem, they proposed an algorithm of importance weighting and rejection (IWRE), where the IW solved the dynamics mismatch and the RE solved the support mismatch.\n\nTo evaluate the performance of IWRE, they did some experiments on MuJoCo and Atari benchmarks. Compared with the ablation, domain-adaptation imitation learning methods, and other heterogeneous observation methods, IWRE obtained the best performance among these environments.",
            "strength_and_weaknesses": "Strengths\uff1a\n* This paper studied a challenging but more general learning scenario, with weaker assumptions than related works. Also, the HOIL problem is well-defined.\n\n* For the algorithm part, the analysis of the dynamics mismatch and the support mismatch is quite convincing, with clear mathematical formulations and visualization empirical studies. Meanwhile, the motivated IWRE makes sense.\n\nWeaknesses\uff1a\n\nThe notations of this work are somehow heavy in this paper. It would be better to simplify some notations.",
            "clarity,_quality,_novelty_and_reproducibility": "The writing of this paper is clear and easy to follow. The related works are well discussed, and the experiment is sufficient. The combination of importance weighting and rejection learning is quite novel in the reinforcement learning and imitation learning communities. The paper contained enough details for reproducibility.",
            "summary_of_the_review": "This paper studied a challenging but more realistic imitation learning scenario, in which the expert\u2019s and the learner\u2019s observations are heterogeneous. Also, the authors proposed a novel and reasonable method IWRE to solve this problem. The contributions of this work are sufficient. So I recommend this paper be accepted.\n\nAfter rebuttal:\n\nI have gone through the responses and discussions between the co-reviewers and the authors. I think the authors have clearly answered the questions of other reviewers, and thus believe this paper is a good submission. So I increased my score and stand for accepting it.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6056/Reviewer_N1Ya"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6056/Reviewer_N1Ya"
        ]
    }
]