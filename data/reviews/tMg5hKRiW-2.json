[
    {
        "id": "npK-j_dZIlN",
        "original": null,
        "number": 1,
        "cdate": 1666647243053,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666647243053,
        "tmdate": 1666647243053,
        "tddate": null,
        "forum": "tMg5hKRiW-2",
        "replyto": "tMg5hKRiW-2",
        "invitation": "ICLR.cc/2023/Conference/Paper2937/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the problem of investigating the depth of GNN. The authors propose a novel and interesting method to extend the depth of GNNs from a positive integer to a real value. It is claimed that negative depth enables high-pass frequency filtering functionality for graph heterophily while positive value enables low-pass filter and is to model homophily. Experimental studies have been conducted on both homophilous and heterophilous graphs and the results show that the proposed method can achieve comparable or better performance in both types of graphs compared to baselines.",
            "strength_and_weaknesses": "Strength:\n- Both problems of GNN depth and adaptive GNN for modeling homophily and heterophily are interesting and important. \n- The proposed method to extend positive integer depth to real value is novel.\n- The experimental results of the method demonstrate the effectiveness of the proposed method compared to previous baselines.\n\nWeakness:\n- The claims are based on empirical results and theoretical analysis is not provided.\n- Experimental results demonstrate the effectiveness of the proposed method, it is also important to show the efficiency of the method, e..g, presenting the complexity or comparing running time.\n- More insights can be provided to better show the correlations between homophily/heterophily and positive/negative depth, for example, analyzing the learn representations rather than just reporting the overall classification accuracy in the downstream task.\n- The size of the benchmark dataset is relatively small to show the ability of generalization. I suggest conducting experiments on larger datasets such as OGB.\n- In the experimental studies, some representative methods can be compared including (1) GAT, as an attention method, and (2) some recent work on adaptive GNN for modeling homophily and heterophily, for instance, GBK-GNN [1].\n\n\n[1] GBK-GNN: Gated Bi-Kernel Graph Neural Networks for Modeling Both Homophily and Heterophily",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: overall the paper is well-organized but some parts are hard to follow, e.g., how to learn the depth d is not introduced very clearly.\n\nQuality: the work is of average quality.\n\nNovelty: The proposed method to extend the depth of GNNs from the positive integers to real values is novel.\n\nReproducibility: it should be possible to implement the method and reproduce the results from the description given in the paper.",
            "summary_of_the_review": "This paper studies an interesting and important problem. Overall this paper is well-organized. Experiments from different aspects have been conducted. Although experimental studies can be further improved by providing more insight into investigations and comparing the proposed method to more representative methods, the method is novel from the methodological perspective and effective from the experimental perspective. Thus, I will recommend a weak acceptance of the paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2937/Reviewer_Qq6e"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2937/Reviewer_Qq6e"
        ]
    },
    {
        "id": "KmFmhfyHq6P",
        "original": null,
        "number": 2,
        "cdate": 1666686914087,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666686914087,
        "tmdate": 1669072336304,
        "tddate": null,
        "forum": "tMg5hKRiW-2",
        "replyto": "tMg5hKRiW-2",
        "invitation": "ICLR.cc/2023/Conference/Paper2937/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors define GCN\u2019s depth as a trainable continuous parameter within (\u2212\u221e,+\u221e) and propose RED-GCN which can automatically search for the optimal depth without the prior knowledge regarding whether the input graph is homophilic or heterophilic.",
            "strength_and_weaknesses": "## Strength\nThe idea of setting the depth as trainable continuous value and the concept of eigengraph are interesting.\n\n## Weaknesses\n1. The writing needs to be improved.\n2. Some experiments and comparisons are missing.\n\n\n## Questions and Comments\n\n1. \u201cApparently, high frequency eigenvectors and their corresponding eigengraphs have advantage on capturing graph heterophily\u201d This is not apparent, need more explanation.\n\n2. \u201cHigh frequency eigengraphs should accordingly take larger.  weights when modeling heterophilic graphs, while low frequency ones should carry larger weights when dealing with homophilic graphs.\u201d This is similar as [5]. \n\n3. Equation (7) is actually lazy random walk affinity matrix and see [5] for the generalized lazy random walk matrix.\n\n4. Red-GCN is essentially a linear model without any non-linearity?\n\n5. The reported results of FAGCN, GPRGNN and H2GCN in table 2 are not the same as the results in the original papers and not consistent with my personal experience.\n\n6. Some missing comparisons, e.g. ACM-GCN [1], LINKX [2], BernNet [3] and GloGNN [4].\n\n[1] Luan S, Hua C, Lu Q, et al. Is Heterophily A Real Nightmare For Graph Neural Networks To Do Node Classification?[J]. arXiv preprint arXiv:2109.05641, 2021.\n\n[2] Lim D, Hohne F, Li X, et al. Large scale learning on non-homophilous graphs: New benchmarks and strong simple methods[J]. Advances in Neural Information Processing Systems, 2021, 34: 20887-20902\n\n[3]  He M, Wei Z, Xu H. Bernnet: Learning arbitrary graph spectral filters via bernstein approximation[J]. Advances in Neural Information Processing Systems, 2021, 34: 14239-14251.\n\n[4] Li X, Zhu R, Cheng Y, et al. Finding Global Homophily in Graph Neural Networks When Meeting Heterophily[J]. arXiv preprint arXiv:2205.07308, 2022.\n\n[5] Luan S, Zhao M, Hua C, et al. Complete the missing half: Augmenting aggregation filtering with diversification for graph convolutional networks[J]. arXiv preprint arXiv:2008.08844, 2020.\n",
            "clarity,_quality,_novelty_and_reproducibility": "quality: medium\nclarity: mediem\noriginality of the work: medium\nReproducibility: NA",
            "summary_of_the_review": "This is a borderline paper and if the authors can address my concerns satisfactorily, I will consider raise my score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2937/Reviewer_NDJu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2937/Reviewer_NDJu"
        ]
    },
    {
        "id": "mmNvqhhZ5fF",
        "original": null,
        "number": 3,
        "cdate": 1666705914842,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666705914842,
        "tmdate": 1666707250521,
        "tddate": null,
        "forum": "tMg5hKRiW-2",
        "replyto": "tMg5hKRiW-2",
        "invitation": "ICLR.cc/2023/Conference/Paper2937/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a novel graph convolutional network to address the over-smoothing and heterophily issue. The proposed model is equipped with a trainable depth parameter $d$ and a selection of the spectrum of the graph signal. Based on such modeling, this paper discovers a connection between negative GCN depth and graph heterophily. The experimental results on 11 graph datasets show the proposed model outperforms baseline methods.",
            "strength_and_weaknesses": "Strengths,\n\nS1: This paper models the depth of GCN as a trainable parameter by eigen decomposition.\n\nS2: Experiments validate the effectiveness of the trainable depth, especially negative depth for disassortative graphs.\n\nWeaknesses,\n\nW1: Adaptive and continuous depth is not new for GCN, e.g., in Graph Neural Diffusion (GRAND).\n\nW2: Negative depth may not be a correct choice, which loses most of the topology information.\n\nW3: This paper does not analyze the expressive power of the proposed model. \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written and well-organized. It is easy to follow the proposed ideas and technological details.\nThe novelty of this paper is incremental because spectrum decomposition is not new for graph analysis.  \nAlthough the proposed model achieved better performance than baselines in experiments, it is not clear what and how new information/patterns are captured by the model.",
            "summary_of_the_review": "I recommend a weak reject for this paper because of its limited novelty and the lack of analysis of expressive power.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2937/Reviewer_gHVm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2937/Reviewer_gHVm"
        ]
    },
    {
        "id": "DgG8Rbrcm_",
        "original": null,
        "number": 4,
        "cdate": 1666707881885,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666707881885,
        "tmdate": 1666707881885,
        "tddate": null,
        "forum": "tMg5hKRiW-2",
        "replyto": "tMg5hKRiW-2",
        "invitation": "ICLR.cc/2023/Conference/Paper2937/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this work, by redefining GCN\u2019s depth d as a trainable parameter continuously adjustable within positive infinity and negative infinity, a simple and powerful GCN model RED-GCN is proposed to retain the simplicity of GCN and meanwhile automatically search for the optimal d without the prior knowledge regarding whether the input graph is homophilic or heterophilic.",
            "strength_and_weaknesses": "Strength: The problem is interesting and usefull for GCN designing.\nWeaknesses: The motivation and the physical meaning of the negative depth value are not clear. When the depth of GCN is negative, what dose it mean?",
            "clarity,_quality,_novelty_and_reproducibility": "The problem is interesting and the proposed method is novel. But the physical meaning of negative results is not clear.",
            "summary_of_the_review": "The problem is interesting and the proposed method is novel. But the physical meaning of negative results is not clear.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2937/Reviewer_ZTa3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2937/Reviewer_ZTa3"
        ]
    }
]