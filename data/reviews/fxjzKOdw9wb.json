[
    {
        "id": "egN4d8u4BZH",
        "original": null,
        "number": 1,
        "cdate": 1666605432452,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666605432452,
        "tmdate": 1669025582021,
        "tddate": null,
        "forum": "fxjzKOdw9wb",
        "replyto": "fxjzKOdw9wb",
        "invitation": "ICLR.cc/2023/Conference/Paper2322/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper explores automatic data augmentation by introducing a simple yet effective Fourier sampling. It provides dynamic, smooth, and diverse augmentation, especially for videos with a time dimension. Many experiments on large-scale, small-scale, and fine-grained video action tasks are conducted and it shows an almost consistent improvement over multiple benchmarks.",
            "strength_and_weaknesses": "Strength:\n-The motivation is straightforward and well-presented. The solution is simple yet effective and it can be seamlessly applied to the existing auto-augmentation methods such as RA, UA, and TA. \n-The experiments are enough to prove the effectiveness of the proposed Fourier sampling for dynamic augmentation. Extensive ablation studies are provided in the appendix.\n\nWeaknesses:\n-The baselines on experiments are somewhat weak. For example, Swin-Tiny and Uniformer-S in Table1 and SlowOnly in Table 3/4 have relatively low performance at the beginning. Stronger baselines are expected.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well organized and the technical novelty is satisfactory.\nSince it is implemented upon RA, UA, and TA, it should be easily reproduced.",
            "summary_of_the_review": "Considering the extensive experiments the authors provide, the effectiveness of the proposed sampling though simple is well proven. I feel positive for this paper at this moment.\n\nAfter reading the rebuttal, I feel that my concerns have been well addressed. More strong baselines have been included to make this paper more solid.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2322/Reviewer_Ntrm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2322/Reviewer_Ntrm"
        ]
    },
    {
        "id": "Tq79g6a9-a",
        "original": null,
        "number": 2,
        "cdate": 1666626965499,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666626965499,
        "tmdate": 1666626965499,
        "tddate": null,
        "forum": "fxjzKOdw9wb",
        "replyto": "fxjzKOdw9wb",
        "invitation": "ICLR.cc/2023/Conference/Paper2322/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper tackles the problem of data augmentation for training video models. It argues that existing augmentation techniques just mostly extend image augmentation strategies and don't fully utilize the temporal dynamics of videos. The paper proposes a new data augmentation framework specifically designed for videos (DynaAugment) that changes the magnitude of augmentation operations for each frame with the help of Fourier Sampling. The experiments are conducted on a diverse set of video datasets including large-scale, small-scale, and fine-grained. DynaAugment improves results in every scenario in combination with existing image-based data augmentation techniques.",
            "strength_and_weaknesses": "**Strengths**:\n\n1) The paper is very well-written with good structure and nice visualizations. The motivation behind DynaAugment is clear and fitted to the nature of the video domain.\n2) The proposed method is based on a strong theoretical framework (Fourier Sampling) with the application for general dynamic data augmentation with smooth and diverse properties.\n3) The ablation study shows the benefits of the chosen methodology for dynamic variations over other possible alternatives.\nOn the large and diverse set of video datasets DynaAugment outperforms image-based data augmentation techniques using even different backbones including CNNs and transformers. The most significant improvement is shown on small-scale and fine-grained datasets of the most practical interest.\n4) DynaAugment is also useful for transfer learning other than video action recognition tasks such as action localization, action segmentation, video object detection, and self-supervised learning\n5) DynaAugment helps in the case of corrupted videos showing better results than other data augmentations.\n\n**Weaknesses**:\n1) A little bit of limited technical novelty which consists mainly of temporally-smoothed parameterized data augmentation.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity and the quality of the paper presentation are on a high level. It has nice visualizations with an easy-to-follow structure. The paper and its supplementary materials contain a detailed description of the models and experiments. So I would say that the work and the results are reproducible. However, the paper has a little bit of limited technical novelty. ",
            "summary_of_the_review": "I have a favorable opinion of the paper and I think the paper deserves the acceptance rating. \n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2322/Reviewer_RUAa"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2322/Reviewer_RUAa"
        ]
    },
    {
        "id": "LVzhxqC_FeH",
        "original": null,
        "number": 3,
        "cdate": 1666666224015,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666666224015,
        "tmdate": 1666666224015,
        "tddate": null,
        "forum": "fxjzKOdw9wb",
        "replyto": "fxjzKOdw9wb",
        "invitation": "ICLR.cc/2023/Conference/Paper2322/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a simple yet effective video data augmentation framework, called DynaAugment, to improve the robustness and accuracy of several video recognition tasks, e.g., action classification, action segmentation, action localization, video object detection. The proposed data augmentation framework respects and simulates the real-world video's temporal variations, instead of naively extend the image augmentation methods, and thus it enjoys good diversity and temporal smoothness. Specifically, a novel sampling function called Fourier Sampling is presented to simultaneously achieve the two goals, i.e., diversity and smoothness. With extensive ablation studies and experiments on multiple downstream tasks such as action recognition and corrupted video classification, impressive superiority of the proposed method is demonstrated.",
            "strength_and_weaknesses": "Strengths:\n\n1. The work is fundamental and meaningful to the video research community, since most of video downstream tasks involve data augmentation strategies.\n2. Good insight and meaningful motivation. And clear illustration of the main idea.\n3. Extensive and consistent experimental support, including most of the commonly-used benchmark datasets. Remarkably, some of the experiments are interesting and novel. E.g., classification on corrupted videos. \n4. Clear writing style and good presentation.\n",
            "clarity,_quality,_novelty_and_reproducibility": "[Clarity] The clarity of the manuscript is good.\n[Quality] The overall quality of this paper is impressive.\n[Novelty] The novelty of this submission has reached the acceptance standard of ICLR, in my opinion.\n[Reproducibility] It is hard to judge the reproducibility of the submission since no code is provided. Based on the implementation details, the re-implementation of the method should not be that hard.\n",
            "summary_of_the_review": "The overall quality of this submission is good. Please see \"Strengths and Weaknesses\" above.\nI tend to accept this paper.\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2322/Reviewer_LMkg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2322/Reviewer_LMkg"
        ]
    },
    {
        "id": "7wr4a0YLpcf",
        "original": null,
        "number": 4,
        "cdate": 1666692416144,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666692416144,
        "tmdate": 1666692416144,
        "tddate": null,
        "forum": "fxjzKOdw9wb",
        "replyto": "fxjzKOdw9wb",
        "invitation": "ICLR.cc/2023/Conference/Paper2322/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a generalisation of commonly used image augmentation to video, paying specific attention to temporal consistency and smoothness of the said augmentations. Efficacy of the proposed generalisation is supported by strong empirical results on a wide range of video understanding tasks.",
            "strength_and_weaknesses": "**Strengths**\n* Well-written paper and well-motivated method.\n* Convincing extensive experiments on a wide range of video recognition tasks.\n* Simple widely applicable method.\n\n**Weaknesses**\n* Open source implementations of the proposed augmentations *in a range of existing frameworks* (e.g. numpy, tensorflow, etc) would greatly help adoption of the proposed methods.",
            "clarity,_quality,_novelty_and_reproducibility": "Simple, clear, novel idea. Open source code would help with reproduction.",
            "summary_of_the_review": "Clear simple video augmentation technique that is demonstrated to consistently improve model performance in upstream and downstream tasks.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2322/Reviewer_wBSm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2322/Reviewer_wBSm"
        ]
    }
]