[
    {
        "id": "4eFpY4oo8Fb",
        "original": null,
        "number": 1,
        "cdate": 1665995979462,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665995979462,
        "tmdate": 1669172813647,
        "tddate": null,
        "forum": "SVl1w1u3InX",
        "replyto": "SVl1w1u3InX",
        "invitation": "ICLR.cc/2023/Conference/Paper6141/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes CASR: a framework that generates complex sequences by iteratively editing previously generated sequences. The problem is well-motivated: in complex scenarios, we might need multiple rounds of editing to generate correct sequences. CASR achieves this goal by feeding a transformer model with input X and prediction from last iteration. The model achieves good performance over both conventional AR and NAR baselines. Compared to template-based methods, CSAR is more flexible and avoids additional exposure bias ",
            "strength_and_weaknesses": "Strength:\n\n1. Well-motivated problem and clear presentation.\n2. The proposed CSAR is effective compared to vanilla AR and NAR models.\n3. The evaluation and analysis are somewhat comprehensive. \n\nWeakness:\n\nThe major concern I have regarding this submission is that some critical related works are missing.\n\nIn particular, this line of related work, according to my knowledge, started from Deliberation Networks 2016[1], which is similar to CSAR except that it only focuses on the decoder (the previous prediction will go through the decoder multiple times to be refined). Another recent model that I found similar to CSAR is Draft and Edit 2020 [2], which is basically a CASR with T=2, and uses VAE as the backbone. Many other similar models can be found in Deliberation Networks' citation. \nIn short, I believe this line of research is highly correlated with this submission and has to be discussed. I can see that there are still differences between CSAR and these works, but those have to be thoroughly discussed in the paper. \n\nFurthermore, although the existing evaluation is already quite comprehensive, compared to related works above is necessary. Such that we can perceive what is the advantage of CSAR over other iterative models. \n ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written.\nThe evaluation is solid.\n\nThe major novelty of CASR, as discussed in the Introduction is 1) we no longer need templates/rules to generate intermediate sequences 2) we will not introduce exposure bias because of (1).\nHowever, if we consider those iterative methods(see Weakness), they have those advantages too. In terms of model structure, CASR is also quite similar to previous works. From this perspective, this submission's novelty is somewhat marginal. ",
            "summary_of_the_review": "Given those discussed in Weakness and Novelty, I think this submission is not ready for acceptance yet, but I am happy to raise my score if my concerns are addressed.  ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6141/Reviewer_B3Ea"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6141/Reviewer_B3Ea"
        ]
    },
    {
        "id": "Gdg7rD-qDR7",
        "original": null,
        "number": 2,
        "cdate": 1666312549323,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666312549323,
        "tmdate": 1666312549323,
        "tddate": null,
        "forum": "SVl1w1u3InX",
        "replyto": "SVl1w1u3InX",
        "invitation": "ICLR.cc/2023/Conference/Paper6141/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper deals with tasks where left-to-right generation is not the best strategy. The authors propose a refinement framework named CASR \u2013 which models p(i-th-timestep output token at t-th refinement step | input to task, output of model at the (t-1)-th refinement step, the prefix/history of output tokens at t-th refinement step). So when training CASR, the input contains the models\u2019 predictions at the previous refinement step as well as the input to the task, and the output is the reference answer. At test-time, iterative refinement is applied. \n\nExperiments are done on WebQSP, MTOP, KVRET, Sudoku (see Section 2.2 for details). The authors have also done ablation studies on architecture choices (e.g., how to encode the input to the CASR model, how to initialize weights of the model at each refinement step, fine-tuning vs. using adapters, etc.). CASR is effective, and achieves SoTA results on KVRET. \n",
            "strength_and_weaknesses": "The comparison of the authors\u2019 approach vs. iterative refinement and progressive generation is quite clear in Table 1. The table helps understanding greatly. \n\nAblation studies are quite comprehensive and inspiring. The analysis on attention is interesting. \n\nReproducibility is great, given that the code is provided. \n\n\n\nI\u2019m not convinced at why using the previous refinement round\u2019s output as input to the CASR model is necessary. Experiments on iterative refinement using a regular refinement model would be helpful. Regular refinement: train regular refinement model (inputs: generated output from original model; outputs: reference output); then, do one-round refinement after the original model and use these outputs as the input to the refinement model; then, do one-round refinement using this updated model (after the original model), and use these outputs as input to the refinement model; etc. Please correct me if I\u2019m missing important details. (*)\n\nThe second paragraph on page 2 (starting with \u201chowever\u201d) is lacking. The authors believe that if there are right-side dependencies \u201cwhich together lead to multi-hop dependency chains,\u201d then \u201cleft-to-right is not the best order for generation.\u201d There needs to be citation or empirical proof. First, left-to-right generation with multiple refinement steps could lead to good results. Second, if we have a perfect model that scores each sequence, and a good decoding strategy (e.g., sampling many candidates and then reranking), then left-to-right generation can solve the tasks like Sudoku and WebQSP. The issue may be that our model is not perfect at scoring sequences, so we may need to rely on other strategies. Anyhow, the authors\u2019 writing that \u201cbecause there are multi-hop dependency chains, left-to-right is not the best order\u201d should be more nuanced and in depth. \n\nRelated to the above: Have the authors attempted better decoding strategies like sampling 100 candidates and rerank, or beam search with large beam size? It\u2019s not clear whether the authors have definite proof that left-to-right decoding doesn\u2019t work and refinement is necessary. (*)\n",
            "clarity,_quality,_novelty_and_reproducibility": "Line 5 of the third paragraph on page 2: Sun et al. should be cited using citet instead of citep.\n\nThe authors use Wu et al. (2016) as L2R\u2019s citation, which is a bit weird because left-to-right generation existed many decades ago (e.g., Hochreiter, 1998). \n\nWhat do the authors mean by \u201cadditional exposure bias\u201d at the end of the fourth paragraph on page 2? Additional to what? \n\nIt\u2019s not clear how hard/easy is defined on the second line of the first paragraph of page 3.   \n\n\nReproducibility is great, given that the code is provided. ",
            "summary_of_the_review": "The idea is interesting. Results on the chosen tasks (though quite specific) are great. Ablation studies are comprehensive and inspiring. I would want to see two more baselines -- labeled (*) above; or have the authors justify why the two baselines are not necessary. Currently I'm leaning toward weak accept. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6141/Reviewer_rnaL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6141/Reviewer_rnaL"
        ]
    },
    {
        "id": "CGByGpCDtoD",
        "original": null,
        "number": 3,
        "cdate": 1666673680404,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666673680404,
        "tmdate": 1666673680404,
        "tddate": null,
        "forum": "SVl1w1u3InX",
        "replyto": "SVl1w1u3InX",
        "invitation": "ICLR.cc/2023/Conference/Paper6141/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a novel approach [CASR] for sequence generation where multiple language models are connected in an iterative manner and predictions of a previous timestep are taken as an input to the model at future timestep [different from vanilla RNN]. The rationale is that sequence generation problems only specify \u201cdifficult\u201d FINAL sequences which need to be solved, and the intermediate order to solve \u201csimpler sequences\u201d is defined by heuristics [Tan et Al]. \n\n",
            "strength_and_weaknesses": "**Strengths**\n\n- The authors demonstrate that a network can itself learn the simpler sequences it needs to solve, and that there is a natural order of progression from solving \u201csimpler\u201d sequences to complex ones. Furthermore, they empirically reveal that this progression is different from the simple left-to-right solving order that sequence generation usually takes. \n\n- The manuscript is well crafted, with convincing experiments and detailed ablations. Authors claim SOTA [70%] on KVRET F1 metric. \n\n**Weaknesses**\n\n- The basic training process [Algo 2] has a limitation that the language model at each timestep needs to be trained fully [line 3] before moving on to the next timestep. This prevents the network to be E2E trainable, leaving CASR prone to parameter-effficient tuning. [3.3].\n\n- Authors define the notion of density measuring the attention magnitude at each sequence token [5.2]. Increasing density at each recurrent step, seems to show that the prediction made by the model becomes more informative. I am curious as to whether the density becomes maximum when the network converges to optimal solution. Please clarify this.\n\n- On sudoku, the restart strategy lags behind Continue strategy by a huge difference ~20% (table 4). But we don\u2019t observe this trend in other three datasets, well recognized in the community (Table 3).  Could the authors please mention their intuitions on these observations?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Authors have released the code for this work anonymously. ",
            "summary_of_the_review": "This work makes a SINGLE minor change to the mathematical formulation of Tan et Al [Figure 1], but still improves empirical results on only 1 out of 3 datasets studied. [Sudoku is a toy dataset from Kaggle which authors don\u2019t show other methods against]. Due to lack of novelty in technical contribution, but still beating SOTA on 1 dataset, this work has incremental contributions. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6141/Reviewer_Nx7n"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6141/Reviewer_Nx7n"
        ]
    }
]