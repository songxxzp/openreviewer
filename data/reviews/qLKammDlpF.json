[
    {
        "id": "P-53WCzFC9",
        "original": null,
        "number": 1,
        "cdate": 1666580738791,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666580738791,
        "tmdate": 1666580738791,
        "tddate": null,
        "forum": "qLKammDlpF",
        "replyto": "qLKammDlpF",
        "invitation": "ICLR.cc/2023/Conference/Paper4689/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces a new paradigm to cluster incomplete vectors using subspaces as proxies to exploit the geometry of the Grassmannian. The authors leverage this new perspective to develop an algorithm to cluster and complete data in a union of subspaces via a fusion penalty formulation. The analysis with synthetic and real-data experiments is conducted to serve as proof of concept.",
            "strength_and_weaknesses": "Strength:\n\n1. The core idea that to cluster incomplete data using subspaces as proxies is novel. \n\n2. This paper is well-written and clearly organized.\n\n3. Detailed theoretical derivations and analyses are provided.\n\nWeaknesses\n\n1. The scenario to which the article applies, and the problem it solves, are unclear. What is incomplete data, and what is the relationship between incomplete data and HRMC?\n\n2. The article provides detailed mathematical proofs, but I think they are too much at the expense of readability. I carefully read the article twice but still had difficulties following it.\n\n3. There are not enough experiments to prove the efficiency of the proposed method, and the paper did not provide codes or other supplementary materials for replication.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well written and clearly organized. The clarity, quality, novelty is good.\nBut the paper did not provide codes or other supplementary materials for replication. The Reproducibility is not good.\n",
            "summary_of_the_review": "This paper introduces a novel paradigm that optimizes on the Grassmannian to complete and cluster incomplete data in a union of subspaces. The core idea is novel and neat, and the paper is well-written. However, there is some unnecessarily technical writeup, some parts appear redundant. And the experimental results section is not sufficient.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4689/Reviewer_vG2m"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4689/Reviewer_vG2m"
        ]
    },
    {
        "id": "93m2O-5oUMY",
        "original": null,
        "number": 2,
        "cdate": 1666669123405,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666669123405,
        "tmdate": 1670092595011,
        "tddate": null,
        "forum": "qLKammDlpF",
        "replyto": "qLKammDlpF",
        "invitation": "ICLR.cc/2023/Conference/Paper4689/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes an approach for \"high-rank matrix completion\", a combination of matrix completion with clustering on a union of subspaces. It designs an optimization problem that pushes the (incomplete) observation's subspace to contain a possible completion of the observation, while pushing for different subspaces to get close to each other. Optimization is done by gradient descent on the product of grassmanian manifold, and there is a local convergence theorem. Several numerical experiments are conducted with promising results.",
            "strength_and_weaknesses": "Strength: This paper builds on well-grounded results in Riemannian manifold optimization. Subspace clustering and matrix completion is solved together, and it doesn't require the number of clusters as an input. It doesn't have low-rank assumption on matrix completion. Experimental results in the low sampling regime are promising.\n\nWeakness: The paper seems to have crammed a lot of material to fit the page limit. It may have been a better fit for a journal where they can define, derive, and present the results much more rigorously and carefully.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity can be improved, especially in section 4. Even though the idea of regularization using geodesic distances defined on the Grassmannian manifold is not new, the choice of these particular metrics applied to this particular problem seems novel and original.",
            "summary_of_the_review": "While I still think this paper might be a better fit for a journal, the problem formulation is novel and it has interesting theoretical and experimental content that tackles a difficult problem with many applications.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4689/Reviewer_CCam"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4689/Reviewer_CCam"
        ]
    },
    {
        "id": "lJq0TfTshs",
        "original": null,
        "number": 3,
        "cdate": 1667272642772,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667272642772,
        "tmdate": 1667272642772,
        "tddate": null,
        "forum": "qLKammDlpF",
        "replyto": "qLKammDlpF",
        "invitation": "ICLR.cc/2023/Conference/Paper4689/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper tackles the high rank matrix completion problem in which only partial observations are present and the underlying data comes from the union of subspaces.  \n\nThe fundamental difficulty with all existing approaches is that they rely on assessing distances (e.g., euclidean, or in the form of inner products) between partially observed vectors To circumvent this problem, this paper introduce a new paradigm to cluster incomplete vectors, using subspaces as proxies, thus avoiding the need to calculate distances or inner products or other notions of similarity between incomplete vectors, as other methods require. In this approach, each (incomplete-data) point is assigned its own (full data) subspace, and the objective is to simultaneously minimize over the Grassmann manifold two terms: (1) the chordal distance between each point and its assigned subspace, to guarantee that the subspace stays near the observed entries, and (2) the geodesics between subspaces of all data, to encourage the subspaces from points that belong together to fuse (i.e, represent the same space). These two terms (1) and (2) constitute the 'fusion' between two different types of distances in the non-convex optimizaiton problem.\n\nIn a nutshell, this work introduces the idea of fusion penalties in the Grassmann manifold, for the problem of high-rank matrix completion.",
            "strength_and_weaknesses": "The paper is quite interesting and well written. The idea of fusion (specifically, in this example combining the chordal and geodesic terms in the optimization function) is interesting.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "* Note that the template doesn't seem to be the original ICLR one\n\nClarity: the paper is very clearly and well written. I enjoyed reading it! It's style is somewhat a atypical (in a good way!) in terms of its structure and presentation. I appreciate that 1) the authors are upfront about the regimes in which their algorithm doesn't perform as well; and 2) they provide quite a bit of technical details on possible future work. \n\nQuality: the paper is of high quality, it has very good articulation of the underlying intuition as well as provide very thorough and self contained review of the related literature \n\nNovelty: the idea of fusion gradients on the Grassmanian is novel and interesting \n\nReproducibility: the authors provide some details and practical details on running the algorithm on real data (e.g. sketching) but I would have liked to see concrete details such as code. Hopefully this can be addressed during the review process. \n ",
            "summary_of_the_review": "In summary, I find the paper interesting and novel, hence  worthy of a conference publication.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4689/Reviewer_MfUS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4689/Reviewer_MfUS"
        ]
    },
    {
        "id": "Fcp0gevPJo",
        "original": null,
        "number": 4,
        "cdate": 1667368789052,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667368789052,
        "tmdate": 1667368789052,
        "tddate": null,
        "forum": "qLKammDlpF",
        "replyto": "qLKammDlpF",
        "invitation": "ICLR.cc/2023/Conference/Paper4689/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes to solve the high-rank matrix completion problem by learning a fusion (or a collection) of subspaces. Since the subspaces form the Grassmann manifold, the paper poses the problem as a learning problem on the Grassmann manifold. It proposes a particular cost function that minimizes the distances between all the n subspaces, which correspond to n data points. No technical results are presented. Convergence of the standard stochastic gradient method on manifolds is discussed (which is a known result). Empirical results show some benefits but they are not clear to me. ",
            "strength_and_weaknesses": "Pros:\nThis is an interesting problem.\n\nCons:\nI found a number of arguments in the paper very problematic. This is apart from the lack of theoretical basis of the arguments presented in the paper (which by the way appear very hand wavy at best).\n\nIn Page 1, it is mentioned \u201cthe geodesics between subspaces of all data, to encourage the subspaces from points that belong together to fuse (i.e, represent the same space)\u2026\u201d as a contribution. However, no results are shown to see whether the modeling actually allows all n points to converge to the same. There seems to be a mis-match between the text statement and the actual work.\n\nNo motivation for the loss function, especially the fusion cost term. Why is it a good choice? Ablation studies are missing.\n\nAs the paper alludes to \u201chigh-rank\u201d completion problems, literature survey should be done on what are precise difficulties and what works already exist. \n\nThe baselines are not properly explained. Furthermore, the legend of those are mismatching to those in the text. Also, it would make sense to include [39] as a baseline by considering all the pairs as the paper considers [39] it to be \u201ctightly related\u201d. \n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper lacks quality and novelty. The paper clearly does not give due consideration to the literature on high rank matrix completion problem and the distinction that it tries to make. ",
            "summary_of_the_review": "I consider the paper requires much improvements in order to be considered a viable submission. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4689/Reviewer_6KMp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4689/Reviewer_6KMp"
        ]
    }
]