[
    {
        "id": "j_fnQQZNLV",
        "original": null,
        "number": 1,
        "cdate": 1666474013724,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666474013724,
        "tmdate": 1666474013724,
        "tddate": null,
        "forum": "vE93gf9kYkf",
        "replyto": "vE93gf9kYkf",
        "invitation": "ICLR.cc/2023/Conference/Paper507/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes a new active learning approach by taking into consideration augmentations during the Active Learning acquisition phase. The paper argues that the existing active learning baselines do not effectively utilize unlabeled samples, particularly during the early stages of acquisition. To fix this, the authors propose to use augmentations both for training over the labeled samples as well as for acquisition over the unlabeled samples. Importantly, the way augmentations are used differs for the labeled and the unlabeled samples. For labeled samples, we want to have label-preserving augmentations that ensure consistency in the model's output across augmentations. However, for unlabeled samples we want the augmentations to be informative enough to enrich the distribution of the unlabeled data, making it easier for the active learning strategy to acquire the best samples for labeling, in other words, the augmentations that provide the maximum least information across the unlabeled samples. The paper thus optimizes for the strength of the augmentations (or the number of augmentations) separately over the labeled samples and the unlabeled samples using the above-mentioned criteria. Once the augmentation strengths are chosen, the authors propose different strategies in which the augmentation over the unlabeled samples can be used for the acquisition, both for score-based and representation-based acquisition functions. Via extensive study, the authors show that their proposed approach performs better than the different Active Learning baselines over different datasets and across different labeled data sizes. In addition the paper also proposes a theoretical justification behind their approach.",
            "strength_and_weaknesses": "Strengths - \n\n1. I like the motivation mentioned in the paper about separating the role of augmentations over the labeled and unlabeld set. \n2. The ablation study does show that indeed the strengths of augmentation over unlabeled set is higher than labeled set, which justifies the reasoning of the paper. \n3. I also like that the paper shows the comparison against having a fixed augmentation strength, where it is shown that certain combination of fixed augmentation strength can be non-optimal and hence the proposed approach of optimizing for the augmentation strength is better. \n\nWeakness - \n\n1. My main weakness of the paper is that since it is also considering augmentations over the unlabeled set, a fairer comparison would be the semi-supervised learning approaches such as [1] which achieve much superior results with much fewer samples. The existing Active Learning approaches do not play with the unlabeled samples generally and thus their setup is much simpler and unfair to compare with other semi-supervised learning setups. In contrast, the proposed approach here explicitly optimizes the augmentation strength over unlabeled samples, making their setup complex. If indeed an ML practitioner wants to use unlabeled data for their model, they instead can rely on using semi-supervised learning instead of the proposed approach here which involves multiple steps. The paper's worth would be improved much more if the authors show that their method can be added on top of the semi-supervised approaches such as [1] too.\n\n2. While I like the comparison done in the appendix with RandAugment, it seems that the proposed approach is not very better than RandAugment (only 1-2%). Further, the authors optimize for RandAugment over labeled samples. What happens if we instead use the RandAugment policy that's been optimized over larger datasets such as ImageNet and then use the same policy across all the datasets mentioned in the paper?\n\n3. How do the authors select their best performing CAMPL, as there are different search axes, which active learning to use and also which aggregation mode to use during including the augmentations in the Active learning approach. Do the authors have a separate validation set and then select the best variant by its performance over the validation set? I could not see any reference to the validation set in the paper. In particular when comparing against RandAugment, is the validation set same for learning the best RandAugment policy and for selecting the best CAMPL approach?\n\n4. Since the proposed approach involves multiple steps, I believe the time taken for this would be much larger than other active learning approaches, however, I could not find a mention of it. Can authors also compare the time taken for their approach against the baseline Active learning approaches?\n\nReferences - \n[1]FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence. Sohn et al.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally well-written and easy to follow. The idea is also novel.",
            "summary_of_the_review": "To summarize, while I agree that the paper's idea is good and novel I have my concerns with the experimental setup. The paper would do great if the proposed approach could be applied over semi-supervised approaches also. I also have some concerns over the comparison with a fixed augmentation strategy, RandAugment. \n\nI would be willing to update my ratings if my above concerns are addressed.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper507/Reviewer_mJxF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper507/Reviewer_mJxF"
        ]
    },
    {
        "id": "cLTSuURLif",
        "original": null,
        "number": 2,
        "cdate": 1666683407849,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666683407849,
        "tmdate": 1666683407849,
        "tddate": null,
        "forum": "vE93gf9kYkf",
        "replyto": "vE93gf9kYkf",
        "invitation": "ICLR.cc/2023/Conference/Paper507/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a method, CAMPAL, for better enhancing active learning with data augmentations. To achieve this, they provide a strength controlling mechanism for augmentations integrated into active learning, as well as a newly developed augmentation-acquisition procedure. The author also provides strong empirical results on several benchmarks, together with theoretical guarantees. The paper brings an overlooked research interest for active learning, fully investigating the role of data augmentations when integrating them into active learning.",
            "strength_and_weaknesses": "The paper proposes a new augmentation-acquisition framework for active learning, namely CAMPAL, to better enhance active learning with data augmentations. The author empirically and theoretically verified the effectiveness of CAMPAL. The point that the augmentation flows impacts AL differently on labeled and unlabeled data pool is also interesting.\nThe strengths are:\n1.\tThe proposed method is novel and well-motivated, and is clearly written in this paper.\n2.\tThis paper fully investigates an overlooked research problem in active learning, and illustrates its importance with significant performance boosts.\n3.\tThe authors also provide a theoretical guarantee of the proposed method.\nThe weaknesses are:\n1.\tThis emphasizes the efficacy of CAMPAL when labeled data are scarce. How about the efficacy of CAMPAL in a normal setting, i.e. with 10%~40% labeled samples from the dataset?\n2.\tHow do you define the image similarity $\\rm{sim}(x,\\tilde{x})$ in the score-based acquisition in Section 2.3? Please elaborate on it.\n3.\tAs shown in Figure 3 and Table 3, the performance boost on CIFAR-100 brought by CAMPAL is not as significant as that on SVHN, and CIFAR-10. It would be better to give out an explanation for this phenomenon.\n4.\tIn equation (2) in Section 2.2, the term $\\frac{\\lambda_{2}}{\\mathcal{T}^{(s)}(x)}$ is confusing, maybe it is $\\frac{\\lambda_2}{|\\mathcal{T}_{\\rm mix}^{(s)}(x)|}$.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly rewritten with high quality. The novelty is also guaranteed with its newly-developed augmentation flows constructed distinctly on labeled and unlabeled data towards their own objectives. The reproducibility is also guaranteed with the code given.",
            "summary_of_the_review": "The paper proposes a new augmentation-acquisition framework for active learning, CAMPAL, to better enhance active learning with data augmentations. The proposed method is quite effective on several benchmarks, especially with scarce labeled data at the first few active learning cycles. The data augmentation is important and effective in active learning, but very few works have been devoted to this problem. Therefore, this paper is great to fully investigating the impacts of data augmentations on active learning.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper507/Reviewer_VeMh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper507/Reviewer_VeMh"
        ]
    },
    {
        "id": "k2d5zzoHyc",
        "original": null,
        "number": 3,
        "cdate": 1667111902904,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667111902904,
        "tmdate": 1667111902904,
        "tddate": null,
        "forum": "vE93gf9kYkf",
        "replyto": "vE93gf9kYkf",
        "invitation": "ICLR.cc/2023/Conference/Paper507/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a heuristic pipeline to improve existing active learning methods using controllable augmentation.",
            "strength_and_weaknesses": "Strength:\n1. The proposed method applies to a wide range of augmentation methods and acquisition methods.\n2. The authors clearly explain the heuristics in the proposed algorithm. \n\nWeakness:\n1. My primary concern is about the comparison against semi-supervised learning. Given the same quota of labeled samples, active learning should outperform semi-supervised learning --- while active learning (AL) can actively select the training subset, semi-supervised learning (SSL) passively takes the training subset. However, I find the proposed algorithm significantly underperforms the MixMatch, the benchmarking method in SSL. For example, given 2000 samples, CutMix achieves an error rate of 7.03% for CIFAR-10 and 3.04% for SVHN (See Appendix B); in contrast, the proposed algorithm only gets 19.63% for CIFAR-10 and 14.34% for SVHN (See Table 1). It raises a natural question of why people would like to use AL instead of SSL. \n2. The technical descriptions in Section 2.2 are somewhat hand-waving. The authors did not describe the math definitions of different types of augmentations. Also, it is unclear how to solve the optimization problems in (1) and (2). Whether these problems are solved in closed form or iteratively? Are they solved repeatedly once the labeled set is expanded or once at the beginning of the algorithm? Minor: I guess the denominator in (2) actually means the cardinality of the augmentations.\n3. The theoretical explanations are disconnected from the actual algorithm. The paper does not justify why the proposed algorithm meets the assumptions/conditions in theory. For example, why the augmentations used in the paper is \"moderately weak\" (Assumption 2)? What does it mean by \"properly selected\" in Theorem 4? Without rigorous development, the theory will not shed light on the algorithm.",
            "clarity,_quality,_novelty_and_reproducibility": "I find the paper writing is fairly hand-waving --- numerous rigorous definitions and technical details. But, most importantly, the theoretical explanation seems disconnected from the proposed algorithm.",
            "summary_of_the_review": "Overall, I think the paper lacks technical rigor (see Weakness for details) --- unfortunately, I cannot recommend acceptance. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper507/Reviewer_ev91"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper507/Reviewer_ev91"
        ]
    }
]