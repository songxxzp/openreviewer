[
    {
        "id": "E7ncQLPOVy",
        "original": null,
        "number": 1,
        "cdate": 1666541208047,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666541208047,
        "tmdate": 1668635788933,
        "tddate": null,
        "forum": "5cFfz6yMVPU",
        "replyto": "5cFfz6yMVPU",
        "invitation": "ICLR.cc/2023/Conference/Paper4576/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new graph neural network O-GNN for reasoning over molecular graphs that specifically encodes ring structures and claims and shows that this improves upon regular GNNs in terms of number of layers required. This is achieved by extending regular message passing GNNs by updating  ring encodings (using simple feed-forward networks) along with the usual update of node and edge encodings.\n",
            "strength_and_weaknesses": "(+) I think it is worth to study molecular ring encoding in an ICLR paper since it concerns an important part of molecules, an important target domain, and representation learning.\n\n(+) The proposed inclusion as first-order components into the MPNN makes totally sense to me and is nice since simple and straightforward.\n\n(-) From an ML perspective, I don't think, the topic and model are investigated fairly. In this form, I would consider the paper to target a more general audience and it could be presented, e.g., at a chemistry venue. More specifically, I am missing a more detailed evaluation and comparison how it improves upon the regular GNN. For example:\n- How do the samples look like (in terms of numbers and size of rings) on which the proposed model is particularly better than other models. Are there samples with rings which the other models get right and how do they look like?\n- Molecular rings tend to not as many atoms and we have technology to construct deeper GNNs. The question is how and if the proposed model improves over those as well (e.g., what happens after 12 layers in Figure 3).\n- Rings can be considered as motifs so it would be interesting to include some GNNs considering motifs into the evaluation.\n\nNote that there is a small section \"The performance for different number of rings.\", but I think much more such analysis should be given.\n\n================================================================================\n\nMinor Comments\n\n- Sec 3.2 (theoretical analysis) seems unnecessary to me. It's a lot of definitions and reading where, in my opinion, you don't learn much in the end given that it's rather obvious that encoding the rings directly adds expressivity.\n\n- p. 3 \"We initlaize\"\n\n- p. 2: (I think)\n\"BACKGROUND AND PRELIMINARY\" -> \"PRELIMINARIES\"\n\"Notations:\" -> \"Notation:\"\n\n- below Eq (1), the entire paragraph about GNNs is redundant for this paper I would say.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and presents a novel idea (as far as I can judge). I think in terms of quality, it's lacking due to the evaluation issues I mention above. Code is not provided, yet the model description is clear and straightforward and one could reimplement it.",
            "summary_of_the_review": "Altogether, I think the authors have a good idea but do not justify it in terms of investigation and evaluation for an ML venue focusing on representation learning. A detailed analysis would probably make the paper rather different and go beyond minor corrections. I tend to rejection at the current point. I am open to discussion since I think the paper makes an interesting contribution.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4576/Reviewer_4qh9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4576/Reviewer_4qh9"
        ]
    },
    {
        "id": "jY6VVPupYiG",
        "original": null,
        "number": 2,
        "cdate": 1666662837043,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666662837043,
        "tmdate": 1668996337033,
        "tddate": null,
        "forum": "5cFfz6yMVPU",
        "replyto": "5cFfz6yMVPU",
        "invitation": "ICLR.cc/2023/Conference/Paper4576/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors propose a ring-enhanced GNN called \\mathcal{O}-GNN to learn ring representations for molecular modeling. The ring representations are updated by concatenating the atom representations and bond representations in the ring, as well as the overall compound representation. Experiments on 11 public datasets present good performance of \\mathcal{O}-GNN.\n",
            "strength_and_weaknesses": "Strength:\n1. \\mathcal{O}-GNN achieves better performance than baseline methods for both molecular property prediction and retrosynthesis prediction tasks.\n2. It is interesting to model rings separately in the molecules since rings play an important role in molecular properties.\n\nWeaknesses:\n1. The innovation of the model is not good enough. It simply updates the ring representations by concatenating atom and bond representations.\n2. The theoretical analysis is not convincing. In fact the ring representations are obtained by aggregating the representations of multi-hop nodes on the ring. A similar discriminatory ability can be achieved by sampling multiple nodes in the k-neighborhood to update the central node.\n3. The proposed method is used for molecular modeling but ignores the equivariant constraints among atoms, bonds and rings.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The presentation of this paper is clear, and code is provided for reproduction. However, the novelty is limited.\n",
            "summary_of_the_review": "In this paper, the authors propose to improve the discriminative ability of GNN in the field of molecular modeling by updating the ring representations. Although the proposed model performs better than the baseline approach on several public available datasets, there is still space for improvement in model innovation. In addition to the weaknesses mentioned above, I have the following concerns:\n\n1. I'm curious how the proposed method overcomes the oversmoothing problem by stacking so many layers?\n2. Why not consider more other types of subgraphs, such as hinge.\n3. Some operations should be supported by adding references or experiments.\n* Why is it necessary to concatenate compound representations when updating atom, bond and ring representations?\n* Why not use the learned compound representations for graph classification tasks but use the average pooling results of atomic representations?\n4. In Table 1, why does graphormer-large perform worse than graphormer-base?\n5. In Table 2\uff0cis there any explanation as to why wo ring's O-GNN works better than baseline?\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4576/Reviewer_Q5iY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4576/Reviewer_Q5iY"
        ]
    },
    {
        "id": "sA5BeqhM8Nv",
        "original": null,
        "number": 3,
        "cdate": 1666710211756,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666710211756,
        "tmdate": 1668672182987,
        "tddate": null,
        "forum": "5cFfz6yMVPU",
        "replyto": "5cFfz6yMVPU",
        "invitation": "ICLR.cc/2023/Conference/Paper4576/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In the context of predictive tasks which involve molecules, the paper presents a GNN variant called $\\mathcal{O}$-GNN that explicitly models rings in compounds, besides the usual atom/bond modeling. The paper presents a theoretical analysis that justifies why it is preferable to account for rings in molecules, as well as a series of experiments to show that the model performs well in practical usage. Notably, this model is able to outperform the winner of the KDDCup on the PCQM4Mv1 benchmark (although on the validation set).",
            "strength_and_weaknesses": "**Strengths**\n\n- It makes sense from a chemical point of view to have a separate modeling \"circuit\" for rings in molecules.\n- Really impressive results across different tasks.\n\n**Weaknesses**\n\n- Not really well-written (although well-organized).\n- I am a bit confused by some of the experimental results. The PCQM4Mv1 and MolNet benchmarks are somewhat okay. On FS-Mol, $\\mathcal{O}$-GNN replaces a backbone transformer-based residual network. However, the results using \"$\\mathcal{O}$-GNN without rings\" as a backbone are not shown, so it is not clear if the improvement is due to the use of GNN or because of the ring modeling. A similar pattern happens in the drug-drug interaction prediction task.\n- The theoretical analysis shows that few layers of $\\mathcal{O}$-GNN are at least as expressive as many more layers of a regular-GNN. But this does not necessarily qualify as an advantage in practice, unless **1)** $\\mathcal{O}$-GNN layers uses fewer parameters than a regular GNN with the same expressivity; **2)** $\\mathcal{O}$-GNN is faster to train than a regular GNN with the same expressivity. To put it in a different way, why do I have to use few layers of $\\mathcal{O}$-GNN, when I can get the same expressivity with many regular-GNN layers (and perhaps also using fewer parameters or being computationally faster)? I wonder if the authors can provide evidence that using $\\mathcal{O}$-GNN is really more advantageous than using regular-GNN once the expressivity is similar.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\n\nThe work is well structured. However, I cannot say the same about the writing quality. It seems to be written in a hurry, and it is riddled with typos and generally poor wording. I was tempted to signal the typos, but they were so many I had to desist.\n\n**Quality**\n\nI'd say medium, considering that the clarity is low.\n\n**Novelty**\n\nExplicitly modeling rings in molecular GNNs is the main contribution of this paper, which to my knowledge has not been done up until now. So, this work qualifies as novel (unless I'm mistaken, will dig more deeply into the literature before the rebuttal phase begins).\n\n**Reproducibility**\n\nThe code is provided in an anonymous repo. Though I haven't replicated the experiments, it's nice to see that the authors were kind enough to make their code available. ",
            "summary_of_the_review": "**Disclaimer**\n\nI did not check the proofs.\n\n**Overall judgment**\n\nWith the doubts I have exposed above, I consider this paper borderline, and I'm giving a 5 for the moment. I'd really like the author to respond to my points in order to be able to raise my score. Also, I **highly** recommend getting this paper proofread for the rebuttal. It would be a shame if I had to leave my score as-is just because nothing was done to improve the writing.\n\n**Questions/comments to authors**\n\n- I think an image will help the reader understand the \"two isomorphic sub-graphs lying on different rings\" in Section 1. Also, this statement is a bit misleading since two graphs with different rings are not isomorphic. Do you mean isomorphic in structure, but not in the node/bond features that make up the ring? I think this difference is addressed in Section 3.2, however, reading up to this point, the reader is confused.\n- In Eq. 4, why the ring representation at the previous layer $h_r^{(l-1)}$ is inside the $\\texttt{MLP}$, when the other representations (Eq. 2, 4, 5) are outside it?\n- For the graph classification tasks, why do you do an average pooling to get the graph representation, when you have all the compound representations at each layer already available?\n\n\n**Minors**\nPage 7: define multi-task learning as MT and random forest as RF in the text, so they are readily understandable when looking at Figure 4.\n\nPage 7: although it is clear from context, you should specify that $\\Delta$-AUPRC is a metric where higher values are better. You should also explain what a \"support set\" is.\n\n\n\n**EDIT**\n\nAfter 1st rebuttal, I am changing my score to 6 given the impressive effort put by the authors to answer my enquiries.\n\n\n**EDIT**\n\nAfter a successful rebuttal, I am now convinced this paper deserves acceptance, and I'm therefore raising my score to 8.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4576/Reviewer_X4DK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4576/Reviewer_X4DK"
        ]
    }
]