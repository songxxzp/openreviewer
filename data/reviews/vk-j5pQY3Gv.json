[
    {
        "id": "0d65dmJi_n",
        "original": null,
        "number": 1,
        "cdate": 1666620548551,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666620548551,
        "tmdate": 1670580578077,
        "tddate": null,
        "forum": "vk-j5pQY3Gv",
        "replyto": "vk-j5pQY3Gv",
        "invitation": "ICLR.cc/2023/Conference/Paper965/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper handles noisy pseudo-labeling in domain adaptation for action recognition. The paper shows that the previous contrastive learning-based methods can be noisy and improves the model performance with robust cross-domain positives. Experiments are conducted on two benchmarks.\n",
            "strength_and_weaknesses": "\nStrength\n---\n- The paper analyzes the noisy pseudo labeling for domain adaptation in action recognition and proposes a way to solve this with Gaussian data augmentations and target nearest neighbors.\n- From a simple gaussian distribution, the method synthesizes the target features and uses these for cross-domain alignment.\n\nWeakness\n--- \n- The novelty is somewhat limited as the proposed components are borrowed from previous works (e.g., SimSiam). And the neighborhood clustering concept is also presented in [1], which is not referenced in this paper.\n- Extensive comparison is needed. For example,  the benefit of synthesizing features is not very clear. How are the proposed cross-domain components compared to the previous cross-domain alignment methods? In addition, Instead of using the cross-domain alignment in this paper, how does the classical pseudo-labeling performs? How does the pseudo labeling in Sahoo et al. 2021 work compared to the cross-domain component in this paper? It is not clear that the proposed components are better than previous alignment methods.\n-  As mentioned, the paper is missing some references for relevant works (e.g., feature generation [1], contrastive alignments for DA [2, 3, 4]).\n\n[1] Li, Shuang, et al. \"Transferable semantic augmentation for domain adaptation.\"\u00a0*Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*\n. 2021.\n[2] Saito, Kuniaki, et al. \"Universal domain adaptation through self supervision.\"\u00a0*Advances in neural information processing systems*\n\u00a033 (2020): 16282-16292.\n[3] Kim, Donghyun, et al. \"Cds: Cross-domain self-supervised pre-training.\"\u00a0*Proceedings of the IEEE/CVF International Conference on Computer Vision*\n. 2021.\n[4] Harary, Sivan, et al. \"Unsupervised Domain Generalization by Learning a Bridge Across Domains.\"\u00a0*Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*\n. 2022.",
            "clarity,_quality,_novelty_and_reproducibility": "It is easy to read and understand. However, novelty is somewhat limited.",
            "summary_of_the_review": "While the method outperforms existing SOTA methods, the novelty is somewhat limited since the proposed components are from previous works. And more extensive experiments are needed.\n\n-- POST REBUTTAL --\nThank the authors for the response. My concerns are partially addressed. I still believe that the idea of neighborhood clustering is not new to domain adaptation. Even though there is a difference from NC[2], the proposed clustering does not seem very novel. Other implementation details seem to be engineering optimization with limited novelty. However, this work is meaningful as it provides extensive experimental results and analysis, which can contribute to the research community. Therefore, I increase my score to 6",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper965/Reviewer_srUr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper965/Reviewer_srUr"
        ]
    },
    {
        "id": "YxNydntlai4",
        "original": null,
        "number": 2,
        "cdate": 1666629610784,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666629610784,
        "tmdate": 1666629610784,
        "tddate": null,
        "forum": "vk-j5pQY3Gv",
        "replyto": "vk-j5pQY3Gv",
        "invitation": "ICLR.cc/2023/Conference/Paper965/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper points out the existing limitations of current contrastive-based VDA methods, including limited variations of positives within the same domain, inaccurate cross-domain positive pairs, and inevitable false negatives. To address the above limitations, the authors introduce target-domain nearest neighbors and synthetic features from the target domain based on class centroids to perform VUDA in a non-contrastive manner. The proposed method is well-motivated, and its experimental results demonstrate its performance.",
            "strength_and_weaknesses": "Strength:\nThis paper begins with an easy-to-follow analysis of what hinders existing contrastive-based methods, which motivates the following proposed methods. Overall, the proposed modifications are simple-yet-effective and well-motivated. The experimental results can further justify the effectiveness of the proposed methods.\n\nWeakness:\nSome details need to be further discussed. \na)\tAuthors claim that \u201cintra-domain positives provide the least performance gains\u201d indicates \"their limitation in variations\", while this causation is not convincing purely based on the comparison in Figure 1 (a). One could argue that such inferior performance is simply due to other reasons, e.g., the lack of minimizing domain discrepancy compared to cross-domain methods. It would be better for authors to provide more justification for this statement. \nb)\tWhile Figure 1 presents an intuitive analysis of the limitations of existing contrastive-based methods based on HMDB->UCF, I wonder whether these empirical observations also exist in other adaptation scenarios. More specifically, for Figure 1 (b), the higher purity of vanilla NN can be due to the fact that UCF is a relatively less challenging dataset (i.e., source only can already achieve 88.8). It is also known that multiple samples from UCF101 are clipped from the same raw video, which could also be the main reason why NN here is more accurate. Therefore, such observation on UCF101 may not work for other more challenging datasets. \nc)\tIn Table 2, authors present the performance of their method utilizing RGB and RGB+Flow for comparison, while only introducing RGB+Flow results from previous methods. To make a fair comparison, authors should also, from my perspective, include the RGB results from previous methods in Table 2. \nd)\tSome minor formatting issues can be observed (e.g., Table 2 appears earlier than Table 1, and a citation error in Table 1 where MSTN^* Ganin et al. (2016) should be MSTN^* Xie et al. (2018)).",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the quality of this paper is good. The proposed methods are well-motivated in general, while part of the motivation requires a more detailed justification. The paper is well-written and easy to follow with certain novelty. Sufficient technical details are provided for future reproduction.",
            "summary_of_the_review": "This paper presents a simple-yet-effective method for VDA, which leverage some machine-learning techniques to address the limitations of previous methods. The paper is presented clearly with sufficient details and analysis, while part of the motivation requires further justifications. Based on the quality of this paper, I would recommend a \u201cmarginally above the acceptance threshold\u201d. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper965/Reviewer_4bRo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper965/Reviewer_4bRo"
        ]
    },
    {
        "id": "2tItRCDyoO",
        "original": null,
        "number": 3,
        "cdate": 1666667557966,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666667557966,
        "tmdate": 1666668267175,
        "tddate": null,
        "forum": "vk-j5pQY3Gv",
        "replyto": "vk-j5pQY3Gv",
        "invitation": "ICLR.cc/2023/Conference/Paper965/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work is the first to strengthen that limited variations in intra- domain positives, pseudo-label noise in inter-domain positives, and false negatives are the three under-explored key problems. Motivated by these concerns, this paper proposes a unified solution by introducing more informative and robust intra-domain and cross-domain positives without relying on negative samples for video DA. This model achieves state-of-the-art performance on several challenging cross-domain benchmarks for video DA. ",
            "strength_and_weaknesses": "Strength:\n- This paper has several interesting findings like \"MLP head is crucial for intra-domain positives optimization but largely hampers the convergence for cross-domain positives\". The proposed method is with adequate insights from these findings. \n\n- This work introduces the bottlenecks of existing contrastive-based video DA methods.\n\nWeakness:\n- It seems that this work can be applied to existing video da models. I suggest the author should do further ablation study to testify whether this unified model can be applied to other video da models like TA3N. \n- This work needs more ablation studies to support the proposed findings. Are these findings similar in different video DA benchmarks? \n- This work only conducts experiments on two small cross-domain datasets UCF-HMDB and Kitchens. These two benchmarks only have a few classes. Validating the method in large-scale cross-domain datasets with more classes will make your conclusions more convincing. ",
            "clarity,_quality,_novelty_and_reproducibility": "The reviewer agrees that the work tackles an essential problem for video domain adaptation. However, several parts need further clarification by the authors to conclude the contributions of the work.",
            "summary_of_the_review": "This paper has proposed a novel contrastive-based unified video DA method without relying on negatives by mining informative and robust intra-domain positives and cross-domain positives. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper965/Reviewer_cfxm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper965/Reviewer_cfxm"
        ]
    },
    {
        "id": "KnsZpZQrddD",
        "original": null,
        "number": 4,
        "cdate": 1667586386101,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667586386101,
        "tmdate": 1670904911660,
        "tddate": null,
        "forum": "vk-j5pQY3Gv",
        "replyto": "vk-j5pQY3Gv",
        "invitation": "ICLR.cc/2023/Conference/Paper965/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper tackles unsupervised domain adaptation for the video recognition task. The paper raises concerns with the use of contrastive methods for aligning source and target domain features. Those concerns involve intra-domain positives, false positives in a cross-domain matches that hinder the contrastive learning process and negatively affect the adaptation. The proposed solution is to utilize intra-domain positives and mine robust cross-domain positives that reduces likelihood of pseudo-label noise. The proposed solution is shown to be superior than the state-of-the-art methods, by experiments on several cross-domain action recognition benchmarks.",
            "strength_and_weaknesses": "**Strengths:**\n- The paper raises some interesting points on the way state-of-the art models are trained for domain adaptive action recognition in a contrastive learning. The paper suggests that impurity of the pseudo-label and cross-domain FP/FN hinder contrastive learning, that results in a sub-optimal domain alignment.\n- The proposed solution moves away from the contrastive learning and modifies it to include intra-domain positives and reduce reliance on negative samples. Furthermore, rather than following existing strategy of creating cross-domain positives, a new strategy is proposed that synthesizes positives for a source-domain anchor that likely reduces the pseudo-label noise.\n- There are more minor observations for improvements such as value of MLP in contrastive learning for intra-domain and cross-domain optimization.\n- Experimental analysis is exhaustive, includes state-of-the art methods for comparison and shows reasonable improvements with proposed strategy.\n- Ablation studies also provide interesting insights into the individual component of the method and effects of hyper-parameters used on the final performance.\n\n\n**Concerns:**\n- One of the aspect of the method includes the use of fitting a Gaussian distribution on the target domain features, which is more or less similar to the strategy used here [1]. I would like to know more about how proposed method is different/better than [1] both intuitively and empirically. This would provide more information on the overall contribution of the work.\n- The proposed solution revolves around reducing the FN/FP influence of the cross-domain alignment, but this intuition is never verified directly empirically. It would be beneficial to have FN/FP numbers before and after the use of proposed approach to further solidify the points raised in the introduction.\n- Similarly, there should be an empirical analysis to show how the proposed synthesis strategy is reducing pseudo-label noise. The paper claims that such synthesis will weakens the noise, but is never empirically verified.\n\n**Typos:**\n- \"robust intra-domain and cross-domain positives without *replying* on negative samples\nfor video DA problem.\" --> relying\n\n**References:**\n[1] Ding, Ning, et al. \"Source-Free Domain Adaptation via Distribution Estimation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall the paper has explained the proposed idea with good clarity and performed extensive evaluation to show efficacy of the proposed approach.",
            "summary_of_the_review": "Overall, the paper provides good contribution to the domain adaptation for the task of video action recognition. There are some concerns raised in the review, addressing them should provide more clarity on the final decision.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper965/Reviewer_9Kq9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper965/Reviewer_9Kq9"
        ]
    }
]