[
    {
        "id": "nsJpdozPBIx",
        "original": null,
        "number": 1,
        "cdate": 1666233013062,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666233013062,
        "tmdate": 1666233013062,
        "tddate": null,
        "forum": "oPnpibcro8",
        "replyto": "oPnpibcro8",
        "invitation": "ICLR.cc/2023/Conference/Paper470/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new keypoint representation learning method through novel losses inspired by information theory. One of the losses encourages the keypoints to represent the scene without information loss, and the other guides the keypoints to represent well the dynamics of the video through conditional entropy and the keypoints in the previous frame. In addition, they proposed overlapping loss to prevent the multiple keypoints from representing near regions and active status loss to represent the scene with sparse keypoints.\n\nThey empirically show their method outperforms baselines (Transporter [1] and Video Structure [2]). In particular, they show their method can represent the scene with a smaller number of keypoints and better transportation (e.g., when some of the objects in the scene move, only the relevant keypoints track). \n\n[1] Tejas D Kulkarni, Ankush Gupta, Catalin Ionescu, Sebastian Borgeaud, Malcolm Reynolds, Andrew Zisserman, and Volodymyr Mnih. Unsupervised learning of object keypoints for perception and control. Advances in Neural Information Processing Systems, 32, 2019.\n\n[2] Matthias Minderer, Chen Sun, Ruben Villegas, Forrester Cole, Kevin P Murphy, and Honglak Lee. Unsupervised learning of object structure and dynamics from videos. Advances in Neural Information Processing Systems, 32, 2019.",
            "strength_and_weaknesses": "Strength\n- Well-designed model and losses. I could agree with why they propose and applies the losses.\n- Good visualization, especially for transportation and sparse keypoints usage in Figures 5 and 6.\n- Investigating Imitation learning. Usually, keypoint representation learning or similar representation learning papers, such as Object-Centric Learning, validate their method for detection, segmentation, or prediction [3,4,5]. Still, they evaluate their approach, not just detection and prediction, but also imitation learning.\n- Mentioning their limitations because their model uses local image entropy.\n\n[3] Locatello, Francesco, et al. \"Object-centric learning with slot attention.\" Advances in Neural Information Processing Systems 33 (2020): 11525-11538.\n\n[4] Dittadi, Andrea, et al. \"Generalization and robustness implications in object-centric learning.\" arXiv preprint arXiv:2107.00637 (2021).\n\n[5] Singh, Gautam, Fei Deng, and Sungjin Ahn. \"Illiterate dall-e learns to compose.\" International Conference on Learning Representations. 2021.\n\nWeaknesses\n- Overall, the paper is well-written and easy to follow, but section 2.2.2 is not easy, at least for me. \n    - In Figure 3, you mentioned The target information $E(T_t)$ is the sum of the conditional entropy E(I_t|I_{t-1}) and the patch around the keypoint at time $t-1$, but in paragraph, $E(T_t)$ is described differently. It looks like the summation of the patch around the keypoint at time $t$ and the new information not represented through the keypoint at time $t$.\n    - In Figure 3, $E(S_t)$ looks like many regions with high entropy are not represented through keypoints. What is the original scene? From the entropy figure, it is not easy to understand.\n    - It is hard for me to follow that \"In a temporal sequence of frames, optimized keypoint information transport means that we can reconstruct the information of the current frame $E(I_t)$ using information from previous frames $E(I_{t\u22121})$ and the keypoint information from both frames.\"\n    - You mentioned being inspired by [1]. When comparing with the loss in [1], you apply the new term, $E(I_t | I_{t-1}) \\bigodot (1-h_i^{(t)})$. It can be analyzed like the new information (dynamics) but not represented through keypoints at time $t$. Why must it be applied to be the target information?\n- They propose a set of multiple losses, but they didn't do the ablation studies on what happens if one or some of the losses are not used. It can be interesting and show the role of each loss empirically, so I hope to be updated in the revised version.\n- The main baselines are Transporter [1] and Video Structure [2]. Could you make an additional section to discuss the difference in detail?",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, this paper is well-written except the section 2.2.2 for me. The quality of this paper is also good, but if more analyses, such as the ablation studies for the losses, were reported, it should be much better. The novelty is good enough when seeing their manuscripts and experimental results for transportation and sparsity on the usage of keypoints. They mention that they will share their code upon acceptance.",
            "summary_of_the_review": "This paper proposes a new method for keypoint representation learning inspired by information theory. Through the proposed objective, they show better detection and prediction performance. Moreover, they also show the sparsity of using the keypoint representation and more stable transportation on the video dataset. However, at least for me, the explanation for the transportation loss is not clear, and the absence of the ablation studies of each loss makes me less understand their method.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper470/Reviewer_PH7P"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper470/Reviewer_PH7P"
        ]
    },
    {
        "id": "SjvhHjuD2A",
        "original": null,
        "number": 2,
        "cdate": 1666530098214,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666530098214,
        "tmdate": 1670388701789,
        "tddate": null,
        "forum": "oPnpibcro8",
        "replyto": "oPnpibcro8",
        "invitation": "ICLR.cc/2023/Conference/Paper470/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work proposes an information-based unsupervised keypoint discovery method. Unlike other works that transport the CNN features between image frames, this work proposes to transport the information represented by the entropy of pixel color computed in a local region, and the authors argue that it provides a better inductive bias for unsupervised keypoint detection. To verify the hypothesis, they provide a quantitative and qualitative evaluation of synthetic and real-world datasets and demonstrate improvements over baselines on all tasks. ",
            "strength_and_weaknesses": "Strengths:\n\n- The research topic of unsupervised keypoint detection is of significance to the community.\n- The method is original, and the evaluation results do demonstrate a consistent improvement over baselines on several tasks.\n- The proposed parallel entropy layer is novel and could be useful for future works.\n- The evaluation is well-designed. It includes a range of tasks including object detection and tracking, dynamic prediction, real-world object discovery, and imitation learning, which thoroughly demonstrate the quality of learned keypoints.\n- The authors also introduce a new set of metrics to evaluate object detection and tracking quality, which can be considered one contribution.\n- The additional video material provided in the anonymous link and supplementation are much appreciated, they provided a clear insight into the benefits of the method.\n\nWeakness:\n\nThe main weakness of the paper is the lack of some key ablation studies, which make the claim that the method represents the scene better than the baselines less convincing. \n\n- In addition to using local pixel entropy as input, the method also introduces several regularization terms in the training objective. It is possible that the improved performance comes from these new loss terms which are not included in the baseline models, they include:\n    1. Minimizing the norm of the distance traveled by each keypoint in the IT loss to regularizing excessive keypoints\u2019 movement\n    2. The overlapping loss that encourages the keypoint to spread over the image\n    3. The additional activation status variable, and the corresponding active status loss that control (reduce if possible) the number of active keypoint\n    \n    These additional terms could be considered contributions of the paper, but they should be separated from the main claim that the information-based method is better than the CNN-based method. Therefore, two sets of experiments can be considered in the paper, (1) the ablation on the proposed method to show the effect of each regularization term, or (2) incorporating these terms in the baseline models when comparing them with the proposed method.\n    \n- The qualitative results show a clear advantage of the proposed method which is very impressive. That is, for the proposed method, the movement of an object only affects the keypoints attached to its body, but for the baseline models, it also causes the movement of many keypoints surrounding the object. However, it is unclear if this behavior is due to architectural design, namely the receptive filed and transporting resolution.\n    1. Receptive filed. In the baseline model, e.g., transporter, the CNN features that the model learns to transport has a receptive field of 24 (input size is 64x64) for each position (computed based on the implementation the paper use [1]), so each pixel contains the information of a large area of the image. This might explain why the surrounding keypoints will also follow the movement of the object - they capture part of the object\u2019s information. On the other hand, the image entropy is designed to represent local information, the entropy region size is three. Is it possible that the baselines can enjoy similar improvement with a careful receptive field design?\n    2. Resolution. Based on transporter implementation [1], the resolution of the feature map to transport is 16x16, and the input image resolution is 64x64, both are smaller than the counterpart of the proposed method and could inevitably cause loss of information. Please provide some investigation into this factor.\n\n[1] [https://github.com/pairlab/v-cdn](https://github.com/pairlab/v-cdn)",
            "clarity,_quality,_novelty_and_reproducibility": "- The paper is clear and well-written.\n- To the best of reviewer\u2019s knowledge, the proposed method and the introduced evaluation metric are novel.\n- For reproducibility, the authors provide some of the hyper-parameters for the proposed model, but it is not sufficient to reproduce the experiment result. It is also not clear how to implement the parallelized entropy layer, it would be nice if the authors could release the code for future research.\n\nFor Clarity\n\n- One small thing: It would be nice to provide a theoretical derivation on how to approximate a joint pixel-wise entropy as the max over the two marginals, i.e., how one can have $E\\left(I_t, I_{t-1}\\right)=\\max \\left(E\\left(I_t\\right), E\\left(I_{t-1}\\right)\\right)$",
            "summary_of_the_review": "The problem this paper is addressing is of significance to the community. The proposed method is novel, and the evaluation results also show improvement over the baselines. The main concern is the lack of certain key experiments and ablation studies that are required to justify the claim and the advantage over existing works. The score could be increased if the above concerns are properly addressed.\n\n---\n## Post-rebuttal updates (edited):\n\nI'm grateful to the authors for the comprehensive feedback and extra experiments in the revision. \n\n1. The extra experiments on the additional loss terms for keypoint detection and tracking reveal that the information contributes significantly to the performance. In fact, in some cases, the model performs better without the additional loss terms, which is interesting. It would be nice to include this setting in other metrics and experiments as well. \n2. I also appreciate the additional findings on Transporter-modified. The results indicate that Transporter performance could be enhanced by fine-tuning its architecture, which seems to imply that a deeper investigation into the model design is required to reveal the cause of the performance difference. \n\nAdditionally, after reviewing the other reviewers' comments, I concur with Reviewer NNTd that the paper is theoretically overstated. For example, it is unclear to me how the proof in Appendix C.2 can justify the approximation $E\\left(I_t, I_{t-1}\\right)=\\max \\left(E\\left(I_t\\right), E\\left(I_{t-1}\\right)\\right)$. Neither the assumption that two consecutive frames are independent nor the statement that the joint will be equal to the max of two marginal are theoretically sound. It appears to be an empirical discovery rather than a result of mathematical analysis. \n\nDespite the writing being theoretical sugar coating, the performance difference between the model and baselines demonstrated in the experiments and the website videos still clearly indicate that this is a promising approach in unsupervised keypoint detection. Therefore, I am leaning towards acceptance and have increased the score to 6.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper470/Reviewer_Nich"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper470/Reviewer_Nich"
        ]
    },
    {
        "id": "SfF-4qTAh53",
        "original": null,
        "number": 3,
        "cdate": 1666828027616,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666828027616,
        "tmdate": 1666828027616,
        "tddate": null,
        "forum": "oPnpibcro8",
        "replyto": "oPnpibcro8",
        "invitation": "ICLR.cc/2023/Conference/Paper470/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper presents a novel method for learning to represent images with keypoints, that can be used for many downstream tasks, like object detection and tracking and learning dynamics.\n- A fixed number of keypoints are extracted from a neural network from each frame.\n- An information transporter (similar to Kulkarni et al., 2019) is trained so the keypoints reconstruct local entropy patterns of neighboring frames\n- novel performance metrics are introduced and the proposed method outpuerforms the competition on these metrics as well as on the standard metrics.",
            "strength_and_weaknesses": "Strengths:\n\nThe method well on multiple tasks and performs better than the competing methods.\n\nWeaknesses:\n\nThe title exaggerates the contributions: \"An information-theoretic approach to unsupervised keypoint representation learning \"\n- The reader expects a theory that explains something not yet known, provide some optimality etc. There is no theorem, nor proof.\n- When entropy is minimised or maximised, one wants to achieve some property for the associated random variable, and there is an explanation why that property is desired for the task. Here this is not the case the \"local entropy\" acts as a hand crafted saliency feature.\n\nThe explanation about the entropy is a forced analogy\n- The losses and equations are not wrong, but the equations would make more sense if they described reconstructing a saliency pattern. E.g. CE(I_t|I_{t\u22121}) = max(E(I_t)-E(I_{t\u22121}), 0) could be interpreted as the novel saliency on the next frame and there is no need to approximate the joint entropy with the maximum.\n- From a saliency perspective using heat maps make sense, the keypoints are used to reconstruct the pattern. Where do they come from an information theoretic perspective? All losses and explicite functional relationships (e.g. heatmaps) should be derived top-down from the theory and assumptions.\n\nSome important content is delegated to the appendix, it could be better placed in the main text\n- (E) Ablation study of the losses\n- (C) Evaluation metrics. As this is listed as a contribution, this should be part of the main text\n\nThe ablation studies are limited. It would be important to see some results with different design choices, e.g. number of keypoints\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n\nThe notations and the figures are unclear, it makes the paper hard to read\n- \"pixel-wise entropy image E(I) for an RGB input image I \\in R^{HxWxC}\". So the Entropy image is a function that takes an image and outputs an image R^{HxW}. But \"local entropies E(I(x, y)) ...\" suggests that the entropy image function takes individual pixels as inputs. eq1 is similarly confusing.\n- The notations are overloaded in a confusing way, eg. eqn2, where the heatmap is indexed twice \"h_i^(t)(x_i, y_i)\". h could be considered as a heatmap function h(x_i^(t), y_i(t)), or as the heatmap image computed from the keypoint h_i^t, either would be good, but it is confusing now in the paper.\n- On fig1 it is hard to see what is a function and what is a variable, especially between the \"Masked entropy\" and \"M_a^(t)\" image the arrows do not join, I am just guessing they are multiplied elementwise there. Also the losses could be show on fig1\n\nNovelty:\nFor me using local entropy and training with the proposed loss is novel.\n\nQuality:\nThe experimental results are strong, but there are severe problems withe the paper (see weaknesses)\n\nReproducibility:\nCode is available, reproducing the results should not take too much effort\n",
            "summary_of_the_review": "The paper is a mixed bag: strong results and bad presentation. There are two possibilities:\n1) There is an theory, from which the losses can be derived. Then this is not presented, and the explanations are insufficient.\n2) The local entropy is just a saliency feature. In this case the explanation is incorrect.\n\nIn both scenarios the paper is not ready for publication.\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper470/Reviewer_NNTd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper470/Reviewer_NNTd"
        ]
    },
    {
        "id": "ozHiZy5TsKK",
        "original": null,
        "number": 4,
        "cdate": 1667066477971,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667066477971,
        "tmdate": 1667066477971,
        "tddate": null,
        "forum": "oPnpibcro8",
        "replyto": "oPnpibcro8",
        "invitation": "ICLR.cc/2023/Conference/Paper470/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes an unsupervised keypoint discovery method, especially for videos. To this end, authors propose to build an entropy layer to measure the information, and a deep learning model to predict keypoint. The model is learned in an unsupervised manner, by maximizing the information in a single frame and across frames. Authors demonstrate that the keypoints can be used for many downstream vision tasks such as detection, tracking and dynamic learning.",
            "strength_and_weaknesses": "### Strength\n* Unsupervised learning of keypoints is an important and difficult task. It avoids the requirement of extensive labels and can help many downstream tasks like matching, tracking etc.\n* The proposed method learns reliable keypoint on both static and moving objects, and the number of active keypoints is compact.\n* The proposed method works well on both synthetic objects and realistic complex scenarios. \n### Weaknesses\n* The novelty is not very strong. Some similar works on unsupervised saliency/keypoint learning have already been proposed and need to be discussed in this paper. For example, [a] has a segmentation network to predict masks (instead of keypoints) training in an unsupervised way, and [b] proposed to learn object parts in an unsupervised way. These two papers are not identical this the submission but share some similarities.\n* The ME loss, the overlapping loss and the active status loss seem to work on single images instead of videos. I am curious how well it works on static images.\n\n\n[a] SCOPS: Self-Supervised Co-Part Segmentation\n[b] Interpretable Convolutional Neural Networks",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity\nMostly okay.\n### Quality\nGood\n### Novelty\nSee comments in \"Weaknesses\".\n### Reproducibility\nI feel it should be good.",
            "summary_of_the_review": "Overall I feel the paper above the acceptance bar, but there are still a bit more can be discussed and investigated, see in \"Weaknesses\".",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper470/Reviewer_srpG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper470/Reviewer_srpG"
        ]
    }
]