[
    {
        "id": "R1b34F_wO-B",
        "original": null,
        "number": 1,
        "cdate": 1666319113351,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666319113351,
        "tmdate": 1666319113351,
        "tddate": null,
        "forum": "e1WfacHtbj",
        "replyto": "e1WfacHtbj",
        "invitation": "ICLR.cc/2023/Conference/Paper2383/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The submission shows that simple randomization-based learning of deep ensembles improves on training a single model when performing selective classification, regardless of the selective classification method that is employed. Given some assumptions that seem to hold in most of the classification scenarios considered in the submission, it is proven that this must indeed be the case. Another, empirical, finding of the submission is that simple selective classification based on a threshold on the maximum class probability is preferable to other methods, including the current state-of-the-art.",
            "strength_and_weaknesses": "+ selective classification is an interesting and important problem\n+ results challenge what is considered the state of the art\n+ convincing empirical findings with theoretical support\n\n- the proposed method is not new and the improvements observed with ensemble learning are unsurprising\n- no discussion of work on estimating epistemic uncertainty, which seems a highly relevant topic\n\nQuestions and comments:\n\nAre the numbers after \"+/-\" in Table 1 standard deviations? How were these obtained?\n\n\"there has been no systematic study of ensemble methods in selective classification\" - repeated verbatim in two adjacent sentences\n\n\"selective risk ... are\"\n\n\"which detects samples different greatly from a given dataset\" - rephrase\n\n\"to the overconfident problem\" - rephrase\n\n\"For definite samples, given the predictive probability distribution of one member model...\" - I could not follow the reasoning here\n\n\"AURCs of the individual model\"\n\n\"for the better performance of the ensemble than the individual selective classifier\" - rephrase\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The submission is well written and great effort has been taken to spell out all steps of the arguments. The main finding of the submission, that ensemble learning enables more accurate selective classification than using a single model, is unsurprising, but the theory presented in the submission appears to be novel. It is also interesting to see that selective classification based on maximum probability, the most obvious approach, outperforms the state-of-the-art when care is taken to use the same experimental setup for both approaches.",
            "summary_of_the_review": "Although the main finding of the submission, that randomization-based ensembles outperform individual models, is unsurprising, particularly considering the experiments reported by Lakshminarayanan et al., it may be useful to have the additional theoretical justification for this method that the submission presents. This justification, based on some assumptions that seem reasonable (and seem to hold in pertinent benchmark problems), appears to be novel. For practitioners, it is also useful to see that selective classification based on maximum probability beats the state of the art in the experiments presented in the submission.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2383/Reviewer_KH7o"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2383/Reviewer_KH7o"
        ]
    },
    {
        "id": "jVBObl1S3W",
        "original": null,
        "number": 2,
        "cdate": 1666540065279,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666540065279,
        "tmdate": 1666540065279,
        "tddate": null,
        "forum": "e1WfacHtbj",
        "replyto": "e1WfacHtbj",
        "invitation": "ICLR.cc/2023/Conference/Paper2383/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper the authors address the selective classification problem with the goal of reducing the selective risk (a non-convex function of the model prediction). A selective classifier is a pair (f, g), where f is a classifier, and g: X -> {0, 1} is a selection function, that allows to abstain {= 0} on some difficult input. In this paper the approach combines several weak selective classifiers (ensemble wit M = 2 to 5 members). \nThe contribution is to prove that an ensemble has a lower selective risk than the individual model under a range of coverage.\nThe method has been tested on image classification (CIFAR-10/100 and SVHN) and text classification (MRPC, MNLI, QNLI) tasks. The backbones used are a VGG-16 and BERT-base networks respectively. The method is compared against selective classification approaches.\n",
            "strength_and_weaknesses": "**Strength**\n\n- Classification with abstention has gained a lot of attention in recent years. It is an important topic.\n- Interesting comparison between methods.\n\n\n\n**Weaknesses**\n\n- Novelty.\n\n- Table 1: it is not clear whether the results are presented with the same level of coverage. If the coverage level is different, it is difficult to compare the values. (It is recommended to add the coverage in the table, or to specify and use a fixed coverage).\n\nEnsemble techniques are presently hard to realize in the context of DNNs, for which it could be very costly to train sufficiently many ensemble members [1] [2].\n\n- What is a sufficient number of ensemble members? \n\nFigure 6 shows that the AURC  for the SR method on the test set decreases as the number of members in the ensemble increases. What is the accuracy of the model and coverage at M=20 for SR? \n\n- The big backbone is designed to have twice as many filters in every convolutional layer (VGG-16) why the authors didn't consider a ResNet-50/101?\n\n\n\n[1] Kush R Varshney. A risk bound for ensemble classification with a reject option. In Statistical Signal Processing Workshop (SSP), 2011 IEEE, pages 769\u2013772. IEEE, 2011\n\n[2] Yoav Freund, Yishay Mansour, and Robert E Schapire. Generalization bounds for averaged classifiers. Annals of Statistics, pages 1698\u20131722, 2004.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear, readable, the images and plots are of good quality. However, there is no technical novelty, the contributions are only marginally significant.",
            "summary_of_the_review": "The paper presents a series of experiments that support the hypothesis that a set of selective classifiers reduces selective risk. At the same time it suggests that the number of members of the ensemble should be low (2-5). Obviously, a high number of member classifiers corresponds to a cost in terms of resources, especially in DL. The paper is clear and readable. There is no technical novelty.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2383/Reviewer_zrP4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2383/Reviewer_zrP4"
        ]
    },
    {
        "id": "nV95gca-x_",
        "original": null,
        "number": 3,
        "cdate": 1666637929792,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666637929792,
        "tmdate": 1666637929792,
        "tddate": null,
        "forum": "e1WfacHtbj",
        "replyto": "e1WfacHtbj",
        "invitation": "ICLR.cc/2023/Conference/Paper2383/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors analyze ensembles in the context of selective prediction. The authors show that under loose assumptions, a selective classifier using the probability assigned to the predicted class to decide whether to abstain from predicting can be improved by ensembling $n$ copies of it (differing only in their random seed). \n\nThe three assumptions required are, paraphrased:\n- A1: When all models agree on a prediction, they are less likely to be incorrect than when they disagree. \n- A2: Each individual model has a non-zero probability of assigning predicting a class with probability one (implying that models can be overconfidently incorrect).\n- A3: The joint PDF of all ensemble members is bounded on ambiguous queries (no prediction has PDF = $+\\infty$).\n\nThese assumptions in hand, the authors show (Prop 1.) that on ambiguous queries, an ensemble _cannot_ assign probability 1 to any class. It follows that (Thm. 2) ensembling will improve the selective risk up to a coverage $\\phi_0 > 0$.\n\nThe authors then evaluate their assumptions on vision and NLP datasets, as well as different ensembling techniques for selective prediction (including, but not restricted to, deep ensembles).",
            "strength_and_weaknesses": "# Strengths\n- The paper is well structured and motivated; the literature review and general positioning of this paper is clear and well situated within the greater context of the field.\n- The paper addresses an important task with clear applications to real life problems (can we automatically detect when to abstain from predicting), and analyzes a well-known, simple technique (ensembling) within this new context.\n- The authors conclusively show under intuitive hypotheses that ensembling will improve selective prediction.\n- Empirical results confirm that the hypotheses are most of the time reasonable; furthermore, empirical results show that ensembling for selective prediction is beneficial even beyond what theoretical results are provided.\n \n# Weaknesses\n- I believe the greatest issue with this work is that the theoretical and empirical results could be more detailed, as the current statements would benefit from greater investigation. For example:\n  * (Thm. 2) How does $\\phi_0$ depend on various ensemble characteristics? Can we bound it away from zero? Under which conditions?\n  * Similarly, I think a deeper analysis of what causes the MRPC dataset to violate the assumptions (which datapoints, and understanding why) would significantly strengthen the paper, especially as the scope of the theoretical results is somewhat limited (next point).\n- The scope of the theoretical results is limited to deep ensembles (i.e., ensembles whose predicted probability vector is obtained via a softmax). It wasn't very clear to me whether this assumption is required on top of the three assumptions detailed earlier -- if so, could the authors clarify why this is?\n- I found some of the notation unclear -- in some cases, the quantities being manipulated are vectors (of length = number of classes), but numerical estimates are scalars. For example, the standard deviation in $\\S$ 6.1. Similarly, is $R_\\text{ind}$ in Thm. 2 the average selective risk of all ensemble members?\n\nMinor: \n- I would recommend reordering Figure 2, so that each subfigure compares different models on a single dataset.\n- This paper could benefit from some quick SPAG proofreading, as there are several minor grammar mistakes throughout the paper.",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the paper is reasonably clear, and the results are novel to the best of my knowledge. \n\nAs mentioned above, I think the major issue is with the scope of the results provided in this paper. Although the results are relevant, the limited application of the theory (to highly specific types of ensembles) and the lack of follow-up on the limitations of the results (ensembling improves only up to a threshold $\\phi_0$; assumptions can be violated; etc.) limit the impact of this work. ",
            "summary_of_the_review": "This is an interesting paper addressing an important question in the ML community. However, this paper could be significantly improved by probing the derived theoretical and empirical results in much more detail. As it stands, the import of this work remains unclear, and it is difficult to place the specific results and limitations within the greater context of the selective prediction problem. \n\nThat being said, I believe that these weaknesses may be easily resolved, making this paper a valuable contribution to the field.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2383/Reviewer_X5Ed"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2383/Reviewer_X5Ed"
        ]
    },
    {
        "id": "oDkyM-SJm8a",
        "original": null,
        "number": 4,
        "cdate": 1666842298054,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666842298054,
        "tmdate": 1666842298054,
        "tddate": null,
        "forum": "e1WfacHtbj",
        "replyto": "e1WfacHtbj",
        "invitation": "ICLR.cc/2023/Conference/Paper2383/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Selective classifiers have the ability to abstain on certain datapoints and consist of two functions - the classification function and the selection function. This paper considers ensembes of selective classifiers by averaging the probability distributions of the classifiers and also defining the selection function in a certain way. They provide some assumptions and theoretically prove that under those assumptions, the ensemble of selective classifiers has better selective risk than each of the individual models for certain values of coverage. They also verify these assumptions on a few datasets. They also find that the simplest ensemble of classifiers with maximum probability as the selection function has the best performance compared to the previous selective classification approaches.",
            "strength_and_weaknesses": "The idea of combining ensembles and selective classification is interesting. \n\nIn assumption 2, why do we need the definite samples probability at confidence approaching 1 to be non-zero? It seems that the entire advantage of ensembles is coming out of the ambiguous samples. \n\nFor the ambiguous samples, assumption 2 says that there are a few ambiguous samples which are predicted with confidence by individual models. Why it can\u2019t be the case that all the models predict the wrong label with confidence approaching 1?\n\nIt is very hard to understand assumption 3 in the paper and it is not clear what the intention of that assumption is. It would be good to explain that in the paper. Also, the authors have verified assumptions 1 and 2 but have not commented on the applicability of assumption 3 for practical settings. Can the authors please comment on that?",
            "clarity,_quality,_novelty_and_reproducibility": "The proof in the paper is hard to read currently. It would also be good to provide some intuition of why we should expect the proof to go through. The ideas are somewhat incremental and I don't think the proofs provide any new technical challenges.",
            "summary_of_the_review": "I think the idea is interesting but the paper lacks clarity and is not well written.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2383/Reviewer_fKnJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2383/Reviewer_fKnJ"
        ]
    }
]