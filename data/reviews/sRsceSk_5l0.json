[
    {
        "id": "LJKaTTPbIV",
        "original": null,
        "number": 1,
        "cdate": 1666581616626,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666581616626,
        "tmdate": 1666581616626,
        "tddate": null,
        "forum": "sRsceSk_5l0",
        "replyto": "sRsceSk_5l0",
        "invitation": "ICLR.cc/2023/Conference/Paper4661/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents a contrastive learning approach by maximizing manifold capacity via a nuclear norm for self-supervised representation learning. Experiments show that the proposed approach is able to yield better linear evaluation performance, extract sementically relevant features, and be more robust to adversarial attack.",
            "strength_and_weaknesses": "The strengths of the paper: \n\n+ It is interesting and somewhat novel to introduce the measure of manifold capacity into contrastive self-supervised representation learning.\n \n\nThe weaknesses of the paper: \n\n- The novelty of introducing the manifold capacity into contrastive learning is somewhat weak. In this paper, the manifold capacity concept at the end of the day again turns out to be optimizing with a loss function of the nuclear norm on the centroids.  Nevertheless, the similar idea of using nuclear norm into contrastive learning has been explored in (Wang et al. TPAMI 2022). The differences from (Wang et al. TPAMI 2022) is not clearly discussed. \n\n- It is correct to relate the mean to the average consine similarity as Eq. (3). However, it seems problematic to interprete the rationale to keep only the first term in Eq. (2) by introducing a norm inequality, i.e., the nuclear norm is bounded from below by the Frobenius norm. Note that the optimization is to maximize the nuclear norm term, it might not guarantee to maximize its lower bound. \n\nMoreover, the reviewer is confused by the mixed expressions in Eq. (4). \n\n- In experiments, the computation time is not mentioned. Compared to the existing method, is there some advantage in computation time?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is relative clear but the presentation could be improved. The perspective of interpreting the nuclear norm from a manifold capacity is new to contrastive self-supervised learning. But emplying the nuclear norm as a loss function to contrastive learning is not novel.  ",
            "summary_of_the_review": "While introducing the nuclear norm from the perspective of measuring manifold capacity is new to contrastive learning, overall the novelty is marginal due to that the nuclear norm as a loss function has been used in contrastive learning.  The empirical evaluation is okay but not that strong. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4661/Reviewer_kyPr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4661/Reviewer_kyPr"
        ]
    },
    {
        "id": "UHPWofOCpE",
        "original": null,
        "number": 2,
        "cdate": 1666603425076,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666603425076,
        "tmdate": 1668668509270,
        "tddate": null,
        "forum": "sRsceSk_5l0",
        "replyto": "sRsceSk_5l0",
        "invitation": "ICLR.cc/2023/Conference/Paper4661/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This is an empirical paper that proposes a new self-supervised learning objective, which consists in minimizing of nuclear norm of the representation of positive examples (~low rank => low variability) while maximizing that of negative examples (more precisely their centroids). This is inspired by recent work on manifold capacity, ie, the number of linear classifiers that can separate point clouds/manifolds. The authors show on small datasets (CIFAR10/100 and STL10) that such objective performs well, and analyze how the geometry (eg distance between positives and negatives) changes during training and across layers. ",
            "strength_and_weaknesses": "**Update**: I've updated my score since he authors added experiments on a non toy ImageNet-100 dataset, but I still find the contributions of the work minor.\n\n**Strengths**\n- **Shedding light on recent theory on manifold capacity** this paper sheds light on recent advancements on manifold capacity that can be of interest to the representation learning community.  These findings are the starting point of the paper (not a contribution) but disseminating these tools to the ML community has its own value given that those works were not published in ML venues. Unfortunately, the paper only provides some high-level informal discussion about those tools.\n- **problem is of interest to the community** representation learning is definitely of interest (even more so if it is easier to analyse theoretically**\n- **well written** the paper is generally well written and clear (besides the fact that it is not self contained as discussed below)\n\n**Weaknesses**\n- **Not self-contained** I had to partially read Chung 2018 and Cohen 2020 to understand the really understand section 2 (what is manifold capacity and why one could care). From the current paper, it is not even clear which definition they use for important terms that are used throughout (eg manifold, manifold radius, manifold effective dimensionality, and capacity).\n- **Unconvincing/small experiments** the method performs similarly to standard SSL on small datasets, it is unclear what to make out of that. Why is that important?\n- **Unclear or minor contributions**\n    - methodology: the paper essentially pretrains using a loss that was previously proposed for evaluation\n    - theory: no theory, not even proper discussion of the theory that inspired them\n    - experiments: the method performs essentially as well as standard SSL on small datasets. It is unclear what are the benefits of the method.\n- **Lack of discussion of previous work** there are many previous works that provides a similar intuition. Eg the following papers and reference therein:\n    - [[1]](https://arxiv.org/abs/2209.06235) this paper characterizes the optimal geometry of representations for maximizing linear probing capacity and generalization (and investigates them in practice). One possible such optimal representation is the sETF, which I believe is also what you are suggesting (ie minima to your loss.\n    - neural collapse literature: there's an entire line of work that analysis the geometry of representations and in particular sETF. Although this is mostly about supervised learning I think it is very related, one example is [[2]](https://arxiv.org/abs/2102.08817) which analysis contrastive learning\n   - [[3]](https://arxiv.org/abs/2106.04156) their loss (eq 6) is pretty related to your loss although their derivation comes from the decomposition of the augmentation graph. \n",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity** the biggest problem concerning clarity is that the paper is not self-contained and the reader needs to read the two previous papers on manifold capacity to truly understand the intuition behind using such a loss. The rest of the paper is clear and well written.\n\n**Novelty** the novelty and contributions seem minor:\n     - methodology: the paper seems to essentially use a metric that had previously been proposed for evaluating representations and optimizing it\n    - theory: there is no new theory \n    - experiments: empirical gains are minor and only on small datasets\n\n\n**Reproducibility**: code and hyperparameters are provided",
            "summary_of_the_review": "I enjoyed reviewing the paper in that it brought to my attention novel work on manifold capacity that was developed outside of ML. Unfortunately, the paper is not self-contained, and provides no theory, and no convincing experiments. Although I do not think that the current version should be accepted, I think that future versions will be of interest to the community. If the main contribution is shedding light on the theory of manifold capacity (which would be fine), the authors should discuss those tools more formally (definitions, main statements). If the contributions go beyond that then the authors should scale up their experiments or provide some theoretical guarantees using the manifold capacity theory.\n\nI am happy to increase my score if actions take action on those suggestions or provide convincing arguments as to why those are not necessary.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4661/Reviewer_Xa59"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4661/Reviewer_Xa59"
        ]
    },
    {
        "id": "SZr-Io8h114",
        "original": null,
        "number": 3,
        "cdate": 1666677019186,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666677019186,
        "tmdate": 1666701446765,
        "tddate": null,
        "forum": "sRsceSk_5l0",
        "replyto": "sRsceSk_5l0",
        "invitation": "ICLR.cc/2023/Conference/Paper4661/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Maximum Manifold Capacity Representation (MMCR) is proposed as a novel self-supervised learning framework by maximize the number of linearly separable object manifolds, which is interesting to see, and different from many SSL methods are inspired by information & entropy criterions. \n\nExperimental results on several computer vision data (e.g., CIFAR-10, STL-100, CIFAR-100) are included for a number of applications, e.g., classification accuracy, manifold capacity analysis, subspace alignment, adversarial robustness, etc. ",
            "strength_and_weaknesses": "Strengths:\n\nIntroduction the concept of manifold capacity to SSL is quite interesting and seems to be the first work in this direction (unless I missed some prior works). By utilizing the nuclear norm with solid theoretical support, this proposed loss function in eq. 2 is well presented as the combination of \"encourage separability\" plus \"manifold compression\". \n\nThis \"implicit manifold compression\" version of MMCR with only the first term , is also encourage object manifold compression and can learn useful representation. Also, the connection to previous work MCR2 is discussed, good to see the similarities and difference from this line of work (probably can have more). \n\nBoth Figure 1 and the analysis in Section 2.2 are good to have, to help understand intuition behind the proposed objective function. \n\nExperimental results on image data across a number of tasks from classification accuracy to manifold structure related analysis, this is helpful to support the contributions. \n\nWeaknesses:\n\nSynthetic data is often helpful to give us insights, and for this paper seems there is no results from simulated data experiments. It should be good to see how exactly \"manifold capacity\" been numerically optimized under simple toy examples.  \n\nGiven all experiments are performed under ResNet-50 as the backbone architecture, should be nice to have some computational complexity discussion for the proposed MMCR method, as this is less clear overall. ",
            "clarity,_quality,_novelty_and_reproducibility": "This work can be considered as an interesting extension of previous manifold capacity work to self-supervised learning and provide us a different way to think about SSL outside the typical information theoretic direction. \n\nAlso good to see author provides the code and data in the supplementary material. ",
            "summary_of_the_review": "This is an interesting work in the SSL domain, the introducing of the concept of manifold capacity is informative, and overall technical contribution seems to be marginal but solid. Perhaps the empirical result is relative limited as no good results from large data set included yet, and my recommendation for this paper is 6 \"marginally above the acceptance threshold\".",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4661/Reviewer_HB7z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4661/Reviewer_HB7z"
        ]
    },
    {
        "id": "bxCXHzAbtM",
        "original": null,
        "number": 4,
        "cdate": 1666691487230,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666691487230,
        "tmdate": 1666691487230,
        "tddate": null,
        "forum": "sRsceSk_5l0",
        "replyto": "sRsceSk_5l0",
        "invitation": "ICLR.cc/2023/Conference/Paper4661/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper introduces the self-supervised learning via maximizing manifold capacity. Specifically, it incorporates the manifold capacity into a contrastive objective. It maximizes the extent of the global image manifold and minimizes every object manifold. The paper approximates the manifold geometries as elliptical to reduces the computation. Experiments on object recognition and robustness to adversarial attacks test the effectiveness of the proposed approach.",
            "strength_and_weaknesses": "Strength:\nMany self-supervised learning methods try to optimize an approximation of the mutual information between representations of different views. The paper uses the manifold capacity to maximize the number of linearly separable object manifolds. It is a new approach that prevents the collapse in the representation space in contrastive learning.\n\nWeakness:\n1.\tIt is better to discuss the relation with dimensional collapse in contrastive learning. Also, it does not compare with the methods addressed the limitation. For example, in the following paper, it uses the subspaces to represent global image manifold and develops new method to prevent the collapse in the representation space.\nLi Jing, Pascal Vincent, Yann LeCun, Yuandong Tian. Understanding Dimensional Collapse in Contrastive Self-supervised Learning. ICLR 2022.\n2.\tIt is better to detail the solution process of (2). For large image sets, how to solve problem (2) efficiently?\n3.\tIt is better to discuss the possibility to use sophisticated manifold geometries instead of elliptical.  ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written. The quality is high, but the novelty of the paper is questionable. It applies the existing manifold capacity to contrastive learning. However, the superiority analysis is not clear. Please see detailed comments above.",
            "summary_of_the_review": "Overall, this paper could be an interesting algorithmic contribution. However, my main concern is the novelty of the paper. Currently, I am leaning toward rejecting the paper. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "I have no ethics concerns for this paper.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4661/Reviewer_Syek"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4661/Reviewer_Syek"
        ]
    }
]